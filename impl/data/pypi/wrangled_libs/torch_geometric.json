{
  "classifiers": [
    "development status :: 5 - production/stable",
    "license :: osi approved :: mit license",
    "programming language :: python",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "[pypi-image]: https://badge.fury.io/py/torch-geometric.svg\n[pypi-url]: https://pypi.python.org/pypi/torch-geometric\n[testing-image]: https://github.com/pyg-team/pytorch_geometric/actions/workflows/testing.yml/badge.svg\n[testing-url]: https://github.com/pyg-team/pytorch_geometric/actions/workflows/testing.yml\n[linting-image]: https://github.com/pyg-team/pytorch_geometric/actions/workflows/linting.yml/badge.svg\n[linting-url]: https://github.com/pyg-team/pytorch_geometric/actions/workflows/linting.yml\n[docs-image]: https://readthedocs.org/projects/pytorch-geometric/badge/?version=latest\n[docs-url]: https://pytorch-geometric.readthedocs.io/en/latest\n[coverage-image]: https://codecov.io/gh/pyg-team/pytorch_geometric/branch/master/graph/badge.svg\n[coverage-url]: https://codecov.io/github/pyg-team/pytorch_geometric?branch=master\n[contributing-image]: https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\n[contributing-url]: https://github.com/pyg-team/pytorch_geometric/blob/master/.github/contributing.md\n[slack-image]: https://img.shields.io/badge/slack-pyg-brightgreen\n[slack-url]: https://data.pyg.org/slack.html\n\n<p align=\"center\">\n  <img height=\"150\" src=\"https://raw.githubusercontent.com/pyg-team/pyg_sphinx_theme/master/pyg_sphinx_theme/static/img/pyg_logo_text.svg?sanitize=true\" />\n</p>\n\n--------------------------------------------------------------------------------\n\n[![pypi version][pypi-image]][pypi-url]\n[![testing status][testing-image]][testing-url]\n[![linting status][linting-image]][linting-url]\n[![docs status][docs-image]][docs-url]\n[![contributing][contributing-image]][contributing-url]\n[![slack][slack-image]][slack-url]\n\n**[documentation](https://pytorch-geometric.readthedocs.io)** | **[paper](https://arxiv.org/abs/1903.02428)** | **[colab notebooks and video tutorials](https://pytorch-geometric.readthedocs.io/en/latest/get_started/colabs.html)** | **[external resources](https://pytorch-geometric.readthedocs.io/en/latest/external/resources.html)** | **[ogb examples](https://github.com/snap-stanford/ogb/tree/master/examples)**\n\n**pyg** *(pytorch geometric)* is a library built upon [pytorch](https://pytorch.org/) to easily write and train graph neural networks (gnns) for a wide range of applications related to structured data.\n\nit consists of various methods for deep learning on graphs and other irregular structures, also known as *[geometric deep learning](http://geometricdeeplearning.com/)*, from a variety of published papers.\nin addition, it consists of easy-to-use mini-batch loaders for operating on many small and single giant graphs, [multi gpu-support](https://github.com/pyg-team/pytorch_geometric/tree/master/examples/multi_gpu), [`torch.compile`](https://pytorch-geometric.readthedocs.io/en/latest/advanced/compile.html) support, [`datapipe`](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/datapipe.py) support, a large number of common benchmark datasets (based on simple interfaces to create your own), the [graphgym](https://pytorch-geometric.readthedocs.io/en/latest/advanced/graphgym.html) experiment manager, and helpful transforms, both for learning on arbitrary graphs as well as on 3d meshes or point clouds.\n\n**[click here to join our slack community!][slack-url]**\n\n<p align=\"center\">\n  <a href=\"https://medium.com/stanford-cs224w\"><img style=\"max-width=: 941px\" src=\"https://data.pyg.org/img/cs224w_tutorials.png\" /></a>\n</p>\n\n--------------------------------------------------------------------------------\n\n* [library highlights](#library-highlights)\n* [quick tour for new users](#quick-tour-for-new-users)\n* [architecture overview](#architecture-overview)\n* [implemented gnn models](#implemented-gnn-models)\n* [installation](#installation)\n\n## library highlights\n\nwhether you are a machine learning researcher or first-time user of machine learning toolkits, here are some reasons to try out pyg for machine learning on graph-structured data.\n\n* **easy-to-use and unified api**:\n  all it takes is 10-20 lines of code to get started with training a gnn model (see the next section for a [quick tour](#quick-tour-for-new-users)).\n  pyg is *pytorch-on-the-rocks*: it utilizes a tensor-centric api and keeps design principles close to vanilla pytorch.\n  if you are already familiar with pytorch, utilizing pyg is straightforward.\n* **comprehensive and well-maintained gnn models**:\n  most of the state-of-the-art graph neural network architectures have been implemented by library developers or authors of research papers and are ready to be applied.\n* **great flexibility**:\n  existing pyg models can easily be extended for conducting your own research with gnns.\n  making modifications to existing models or creating new architectures is simple, thanks to its easy-to-use message passing api, and a variety of operators and utility functions.\n* **large-scale real-world gnn models**:\n  we focus on the need of gnn applications in challenging real-world scenarios, and support learning on diverse types of graphs, including but not limited to: scalable gnns for graphs with millions of nodes; dynamic gnns for node predictions over time; heterogeneous gnns with multiple node types and edge types.\n* **graphgym integration**: graphgym lets users easily reproduce gnn experiments, is able to launch and analyze thousands of different gnn configurations, and is customizable by registering new modules to a gnn learning pipeline.\n\n## quick tour for new users\n\nin this quick tour, we highlight the ease of creating and training a gnn model with only a few lines of code.\n\n### train your own gnn model\n\nin the first glimpse of pyg, we implement the training of a gnn for classifying papers in a citation graph.\nfor this, we load the [cora](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.planetoid.html) dataset, and create a simple 2-layer gcn model using the pre-defined [`gcnconv`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gcnconv.html):\n\n```python\nimport torch\nfrom torch import tensor\nfrom torch_geometric.nn import gcnconv\nfrom torch_geometric.datasets import planetoid\n\ndataset = planetoid(root='.', name='cora')\n\nclass gcn(torch.nn.module):\n    def __init__(self, in_channels, hidden_channels, out_channels):\n        super().__init__()\n        self.conv1 = gcnconv(in_channels, hidden_channels)\n        self.conv2 = gcnconv(hidden_channels, out_channels)\n\n    def forward(self, x: tensor, edge_index: tensor) -> tensor:\n        # x: node feature matrix of shape [num_nodes, in_channels]\n        # edge_index: graph connectivity matrix of shape [2, num_edges]\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index)\n        return x\n\nmodel = gcn(dataset.num_features, 16, dataset.num_classes)\n```\n\n<details>\n<summary>we can now optimize the model in a training loop, similar to the <a href=\"https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation\">standard pytorch training procedure</a>.</summary>\n\n```python\nimport torch.nn.functional as f\n\ndata = dataset[0]\noptimizer = torch.optim.adam(model.parameters(), lr=0.01)\n\nfor epoch in range(200):\n    pred = model(data.x, data.edge_index)\n    loss = f.cross_entropy(pred[data.train_mask], data.y[data.train_mask])\n\n    # backpropagation\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n```\n</details>\n\nmore information about evaluating final model performance can be found in the corresponding [example](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py).\n\n### create your own gnn layer\n\nin addition to the easy application of existing gnns, pyg makes it simple to implement custom graph neural networks (see [here](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html) for the accompanying tutorial).\nfor example, this is all it takes to implement the [edge convolutional layer](https://arxiv.org/abs/1801.07829) from wang *et al.*:\n\n$$x_i^{\\prime} ~ = ~ \\max_{j \\in \\mathcal{n}(i)} ~ \\textrm{mlp}_{\\theta} \\left( [ ~ x_i, ~ x_j - x_i ~ ] \\right)$$\n\n```python\nimport torch\nfrom torch import tensor\nfrom torch.nn import sequential, linear, relu\nfrom torch_geometric.nn import messagepassing\n\nclass edgeconv(messagepassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr=\"max\")  # \"max\" aggregation.\n        self.mlp = sequential(\n            linear(2 * in_channels, out_channels),\n            relu(),\n            linear(out_channels, out_channels),\n        )\n\n    def forward(self, x: tensor, edge_index: tensor) -> tensor:\n        # x: node feature matrix of shape [num_nodes, in_channels]\n        # edge_index: graph connectivity matrix of shape [2, num_edges]\n        return self.propagate(edge_index, x=x)  # shape [num_nodes, out_channels]\n\n    def message(self, x_j: tensor, x_i: tensor) -> tensor:\n        # x_j: source node features of shape [num_edges, in_channels]\n        # x_i: target node features of shape [num_edges, in_channels]\n        edge_features = torch.cat([x_i, x_j - x_i], dim=-1)\n        return self.mlp(edge_features)  # shape [num_edges, out_channels]\n```\n\n### manage experiments with graphgym\n\ngraphgym allows you to manage and launch gnn experiments, using a highly modularized pipeline (see [here](https://pytorch-geometric.readthedocs.io/en/latest/advanced/graphgym.html) for the accompanying tutorial).\n\n```\ngit clone https://github.com/pyg-team/pytorch_geometric.git\ncd pytorch_geometric/graphgym\nbash run_single.sh  # run a single gnn experiment (node/edge/graph-level)\nbash run_batch.sh   # run a batch of gnn experiments, using differnt gnn designs/datasets/tasks\n```\n\nusers are highly encouraged to check out the [documentation](https://pytorch-geometric.readthedocs.io/en/latest), which contains additional tutorials on the essential functionalities of pyg, including data handling, creation of datasets and a full list of implemented methods, transforms, and datasets.\nfor a quick start, check out our [examples](https://github.com/pyg-team/pytorch_geometric/tree/master/examples) in `examples/`.\n\n## architecture overview\n\npyg provides a multi-layer framework that enables users to build graph neural network solutions on both low and high levels.\nit comprises of the following components:\n\n* the pyg **engine** utilizes the powerful pytorch deep learning framework with full [`torch.compile`](https://pytorch-geometric.readthedocs.io/en/latest/advanced/compile.html) and [torchscript](https://pytorch-geometric.readthedocs.io/en/latest/advanced/jit.html) support, as well as additions of efficient cpu/cuda libraries for operating on sparse data, *e.g.*, [`pyg-lib`](https://github.com/pyg-team/pyg-lib).\n* the pyg **storage** handles data processing, transformation and loading pipelines. it is capable of handling and processing large-scale graph datasets, and provides effective solutions for heterogeneous graphs. it further provides a variety of sampling solutions, which enable training of gnns on large-scale graphs.\n* the pyg **operators** bundle essential functionalities for implementing graph neural networks. pyg supports important gnn building blocks that can be combined and applied to various parts of a gnn model, ensuring rich flexibility of gnn design.\n* finally, pyg provides an abundant set of gnn **models**, and examples that showcase gnn models on standard graph benchmarks. thanks to its flexibility, users can easily build and modify custom gnn models to fit their specific needs.\n\n<p align=\"center\">\n  <img width=\"100%\" src=\"https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/docs/source/_figures/architecture.svg?sanitize=true\" />\n</p>\n\n## implemented gnn models\n\nwe list currently supported pyg models, layers and operators according to category:\n\n**gnn layers:**\nall graph neural network layers are implemented via the **[`nn.messagepassing`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.messagepassing.html)** interface.\na gnn layer specifies how to perform message passing, *i.e.* by designing different message, aggregation and update functions as defined [here](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html).\nthese gnn layers can be stacked together to create graph neural network models.\n\n* **[gcnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gcnconv.html)** from kipf and welling: [semi-supervised classification with graph convolutional networks](https://arxiv.org/abs/1609.02907) (iclr 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py)]\n* **[chebconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.chebconv.html)** from defferrard *et al.*: [convolutional neural networks on graphs with fast localized spectral filtering](https://arxiv.org/abs/1606.09375) (nips 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py#l36-l37)]\n* **[gatconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gatconv.html)** from veli\u010dkovi\u0107 *et al.*: [graph attention networks](https://arxiv.org/abs/1710.10903) (iclr 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py)]\n\n<details>\n<summary><b>expand to see all implemented gnn layers...</b></summary>\n\n* **[gcn2conv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gcn2conv.html)** from chen *et al.*: [simple and deep graph convolutional networks](https://arxiv.org/abs/2007.02133) (icml 2020) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn2_cora.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn2_ppi.py)]\n* **[splineconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.splineconv.html)** from fey *et al.*: [splinecnn: fast geometric deep learning with continuous b-spline kernels](https://arxiv.org/abs/1711.08920) (cvpr 2018) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cora.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/faust.py)]\n* **[nnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.nnconv.html)** from gilmer *et al.*: [neural message passing for quantum chemistry](https://arxiv.org/abs/1704.01212) (icml 2017) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/qm9_nn_conv.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mnist_nn_conv.py)]\n* **[cgconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.cgconv.html)** from xie and grossman: [crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties](https://journals.aps.org/prl/abstract/10.1103/physrevlett.120.145301) (physical review letters 120, 2018)\n* **[ecconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ecconv.html)** from simonovsky and komodakis: [edge-conditioned convolution on graphs](https://arxiv.org/abs/1704.02901) (cvpr 2017)\n* **[egconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.egconv.html)** from tailor *et al.*: [adaptive filters and aggregator fusion for efficient graph convolutions](https://arxiv.org/abs/2104.01481) (gnnsys 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/egc.py)]\n* **[gatv2conv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gatv2conv.html)** from brody *et al.*: [how attentive are graph attention networks?](https://arxiv.org/abs/2105.14491) (iclr 2022)\n* **[transformerconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.transformerconv.html)** from shi *et al.*: [masked label prediction: unified message passing model for semi-supervised classification](https://arxiv.org/abs/2009.03509) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/unimp_arxiv.py)]\n* **[sageconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.sageconv.html)** from hamilton *et al.*: [inductive representation learning on large graphs](https://arxiv.org/abs/1706.02216) (nips 2017) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/reddit.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py), [**example3**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py), [**example4**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup_ppi.py)]\n* **[graphconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.graphconv.html)** from, *e.g.*, morris *et al.*: [weisfeiler and leman go neural: higher-order graph neural networks](https://arxiv.org/abs/1810.02244) (aaai 2019)\n* **[gatedgraphconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gatedgraphconv.html)** from li *et al.*: [gated graph sequence neural networks](https://arxiv.org/abs/1511.05493) (iclr 2016)\n* **[resgatedgraphconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.resgatedgraphconv.html)** from bresson and laurent: [residual gated graph convnets](https://arxiv.org/abs/1711.07553) (corr 2017)\n* **[ginconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ginconv.html)** from xu *et al.*: [how powerful are graph neural networks?](https://arxiv.org/abs/1810.00826) (iclr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mutag_gin.py)]\n* **[gineconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gineconv.html)** from hu *et al.*: [strategies for pre-training graph neural networks](https://arxiv.org/abs/1905.12265) (iclr 2020)\n* **[armaconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.armaconv.html)** from bianchi *et al.*: [graph neural networks with convolutional arma filters](https://arxiv.org/abs/1901.01343) (corr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/arma.py)]\n* **[sgconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.sgconv.html)** from wu *et al.*: [simplifying graph convolutional networks](https://arxiv.org/abs/1902.07153) (corr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/sgc.py)]\n* **[appnp](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.appnp.html)** from klicpera *et al.*: [predict then propagate: graph neural networks meet personalized pagerank](https://arxiv.org/abs/1810.05997) (iclr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/citation/appnp.py)]\n* **[mfconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.mfconv.html)** from duvenaud *et al.*: [convolutional networks on graphs for learning molecular fingerprints](https://arxiv.org/abs/1509.09292) (nips 2015)\n* **[agnnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.agnnconv.html)** from thekumparampil *et al.*: [attention-based graph neural network for semi-supervised learning](https://arxiv.org/abs/1803.03735) (corr 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/agnn.py)]\n* **[tagconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.tagconv.html)** from du *et al.*: [topology adaptive graph convolutional networks](https://arxiv.org/abs/1710.10370) (corr 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/tagcn.py)]\n* **[pnaconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.pnaconv.html)** from corso *et al.*: [principal neighbourhood aggregation for graph nets](https://arxiv.org/abs/2004.05718) (corr 2020) [**[example](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pna.py)**]\n* **[faconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.faconv.html)** from bo *et al.*: [beyond low-frequency information in graph convolutional networks](https://arxiv.org/abs/2101.00797) (aaai 2021)\n* **[pdnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.nn.conv.pdnconv.html)** from rozemberczki *et al.*: [pathfinder discovery networks for neural message passing](https://arxiv.org/abs/2010.12878) (www 2021)\n* **[rgcnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.rgcnconv.html)** from schlichtkrull *et al.*: [modeling relational data with graph convolutional networks](https://arxiv.org/abs/1703.06103) (eswc 2018) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgcn.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgcn_link_pred.py)]\n* **[rgatconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.rgatconv.html)** from busbridge *et al.*: [relational graph attention networks](https://arxiv.org/abs/1904.05811) (corr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgat.py)]\n* **[filmconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.filmconv.html)** from brockschmidt: [gnn-film: graph neural networks with feature-wise linear modulation](https://arxiv.org/abs/1906.12192) (icml 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/film.py)]\n* **[signedconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.signedconv.html)** from derr *et al.*: [signed graph convolutional network](https://arxiv.org/abs/1808.06354) (icdm 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/signed_gcn.py)]\n* **[dnaconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.dnaconv.html)** from fey: [just jump: dynamic neighborhood aggregation in graph neural networks](https://arxiv.org/abs/1904.04849) (iclr-w 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/dna.py)]\n* **[panconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.panconv.html)** from ma *et al.*: [path integral based convolution and pooling for graph neural networks](https://arxiv.org/abs/2006.16811) (neurips 2020)\n* **[pointnetconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.pointnetconv.html)** (including **[iterative farthest point sampling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.fps.html)**, dynamic graph generation based on **[nearest neighbor](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.knn_graph.html)** or **[maximum distance](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.radius_graph.html)**, and **[k-nn interpolation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.unpool.knn_interpolate.html)** for upsampling) from qi *et al.*: [pointnet: deep learning on point sets for 3d classification and segmentation](https://arxiv.org/abs/1612.00593) (cvpr 2017) and [pointnet++: deep hierarchical feature learning on point sets in a metric space](https://arxiv.org/abs/1706.02413) (nips 2017) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pointnet2_classification.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pointnet2_segmentation.py)]\n* **[edgeconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.edgeconv.html)** from wang *et al.*: [dynamic graph cnn for learning on point clouds](https://arxiv.org/abs/1801.07829) (corr, 2018) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/dgcnn_classification.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/dgcnn_segmentation.py)]\n* **[xconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.xconv.html)** from li *et al.*: [pointcnn: convolution on x-transformed points](https://arxiv.org/abs/1801.07791) (neurips 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/points/point_cnn.py)]\n* **[ppfconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ppfconv.html)** from deng *et al.*: [ppfnet: global context aware local features for robust 3d point matching](https://arxiv.org/abs/1802.02669) (cvpr 2018)\n* **[gmmconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gmmconv.html)** from monti *et al.*: [geometric deep learning on graphs and manifolds using mixture model cnns](https://arxiv.org/abs/1611.08402) (cvpr 2017)\n* **[feastconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.feastconv.html)** from verma *et al.*: [feastnet: feature-steered graph convolutions for 3d shape analysis](https://arxiv.org/abs/1706.05206) (cvpr 2018)\n* **[pointtransformerconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.pointtransformerconv.html)** from zhao *et al.*: [point transformer](https://arxiv.org/abs/2012.09164) (2020)\n* **[hypergraphconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.hypergraphconv.html)** from bai *et al.*: [hypergraph convolution and hypergraph attention](https://arxiv.org/abs/1901.08150) (corr 2019)\n* **[gravnetconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gravnetconv.html)** from qasim *et al.*: [learning representations of irregular particle-detector geometry with distance-weighted graph networks](https://arxiv.org/abs/1902.07987) (european physics journal c, 2019)\n* **[supergat](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.supergatconv.html)** from kim and oh: [how to find your friendly neighborhood: graph attention design with self-supervision](https://openreview.net/forum?id=wi5kunlqwty) (iclr 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/super_gat.py)]\n* **[hgtconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.hgtconv.html)** from hu *et al.*: [heterogeneous graph transformer](https://arxiv.org/abs/2003.01332) (www 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hgt_dblp.py)]\n* **[heatconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.heatonv.html)** from mo *et al.*: [heterogeneous edge-enhanced graph attention network for multi-agent trajectory prediction](https://arxiv.org/abs/2106.07161) (corr 2021)\n* **[ssgconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ssgconv.html)** from zhu *et al.*: [simple spectral graph convolution](https://openreview.net/forum?id=cyo5t-yjwzv) (iclr 2021)\n* **[fusedgatconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.fusedgatconv.html)** from zhang *et al.*: [understanding gnn computational graph: a coordinated computation, io, and memory perspective](https://proceedings.mlsys.org/paper/2022/file/9a1158154dfa42caddbd0694a4e9bdc8-paper.pdf) (mlsys 2022)\n* **[gpsconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gpsconv.html)** from ramp\u00e1\u0161ek *et al.*: [recipe for a general, powerful, scalable graph transformer](https://arxiv.org/abs/2205.12454) (neurips 2022) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_gps.py)]\n</details>\n\n**pooling layers:**\ngraph pooling layers combine the vectorial representations of a set of nodes in a graph (or a subgraph) into a single vector representation that summarizes its properties of nodes.\nit is commonly applied to graph-level tasks, which require combining node features into a single graph representation.\n\n* **[top-k pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.topkpooling.html)** from gao and ji: [graph u-nets](https://arxiv.org/abs/1905.05178) (icml 2019), cangea *et al.*: [towards sparse hierarchical graph classifiers](https://arxiv.org/abs/1811.01287) (neurips-w 2018) and knyazev *et al.*: [understanding attention and generalization in graph neural networks](https://arxiv.org/abs/1905.02850) (iclr-w 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_topk_pool.py)]\n* **[diffpool](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dense_diff_pool.html)** from ying *et al.*: [hierarchical graph representation learning with differentiable pooling](https://arxiv.org/abs/1806.08804) (neurips 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_diff_pool.py)]\n\n<details>\n<summary><b>expand to see all implemented pooling layers...</b></summary>\n\n* **[attentional aggregation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.attentionalaggregation.html)** from li *et al.*: [graph matching networks for learning the similarity of graph structured objects](https://arxiv.org/abs/1904.12787) (icml 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/global_attention.py)]\n* **[set2set](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.set2set.html)** from vinyals *et al.*: [order matters: sequence to sequence for sets](https://arxiv.org/abs/1511.06391) (iclr 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/set2set.py)]\n* **[sort aggregation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.sortaggregation.html)** from zhang *et al.*: [an end-to-end deep learning architecture for graph classification](https://www.cse.wustl.edu/~muhan/papers/aaai_2018_dgcnn.pdf) (aaai 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/sort_pool.py)]\n* **[mincut pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dense_mincut_pool.html)** from bianchi *et al.*: [spectral clustering with graph neural networks for graph pooling](https://arxiv.org/abs/1907.00481) (icml 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_mincut_pool.py)]\n* **[dmon pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dmonpooling.html)** from tsitsulin *et al.*: [graph clustering with graph neural networks](https://arxiv.org/abs/2006.16904) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_dmon_pool.py)]\n* **[graclus pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.graclus.html)** from dhillon *et al.*: [weighted graph cuts without eigenvectors: a multilevel approach](http://www.cs.utexas.edu/users/inderjit/public_papers/multilevel_pami.pdf) (pami 2007) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mnist_graclus.py)]\n* **[voxel grid pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.voxel_grid.html)** from, *e.g.*, simonovsky and komodakis: [dynamic edge-conditioned filters in convolutional neural networks on graphs](https://arxiv.org/abs/1704.02901) (cvpr 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mnist_voxel_grid.py)]\n* **[sag pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.sagpooling.html)** from lee *et al.*: [self-attention graph pooling](https://arxiv.org/abs/1904.08082) (icml 2019) and knyazev *et al.*: [understanding attention and generalization in graph neural networks](https://arxiv.org/abs/1905.02850) (iclr-w 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/sag_pool.py)]\n* **[edge pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.edgepooling.html)** from diehl *et al.*: [towards graph pooling by edge contraction](https://graphreason.github.io/papers/17.pdf) (icml-w 2019) and diehl: [edge contraction pooling for graph neural networks](https://arxiv.org/abs/1905.10990) (corr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/edge_pool.py)]\n* **[asapooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.asapooling.html)** from ranjan *et al.*: [asap: adaptive structure aware pooling for learning hierarchical graph representations](https://arxiv.org/abs/1911.07979) (aaai 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/asap.py)]\n* **[panpooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.panpooling.html)** from ma *et al.*: [path integral based convolution and pooling for graph neural networks](https://arxiv.org/abs/2006.16811) (neurips 2020)\n* **[mempooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.mempooling.html)** from khasahmadi *et al.*: [memory-based graph networks](https://arxiv.org/abs/2002.09518) (iclr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mem_pool.py)]\n* **[graph multiset transformer](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.graphmultisettransformer.html)** from baek *et al.*: [accurate learning of graph representations with graph multiset pooling](https://arxiv.org/abs/2102.11533) (iclr 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_gmt.py)]\n* **[equilibrium aggregation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.equilibriumaggregation.html)** from bartunov *et al.*: [](https://arxiv.org/abs/2202.12795) (uai 2022) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/equilibrium_median.py)]\n</details>\n\n**gnn models:**\nour supported gnn models incorporate multiple message passing layers, and users can directly use these pre-defined models to make predictions on graphs.\nunlike simple stacking of gnn layers, these models could involve pre-processing, additional learnable parameters, skip connections, graph coarsening, etc.\n\n* **[schnet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.schnet.html)** from sch\u00fctt *et al.*: [schnet: a continuous-filter convolutional neural network for modeling quantum interactions](https://arxiv.org/abs/1706.08566) (nips 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/qm9_pretrained_schnet.py)]\n* **[dimenet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.dimenet.html)** and **[dimenetplusplus](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.dimenetplusplus.html)** from klicpera *et al.*: [directional message passing for molecular graphs](https://arxiv.org/abs/2003.03123) (iclr 2020) and [fast and uncertainty-aware directional message passing for non-equilibrium molecules](https://arxiv.org/abs/2011.14115) (neurips-w 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/qm9_pretrained_dimenet.py)]\n* **[node2vec](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.node2vec.html)** from grover and leskovec: [node2vec: scalable feature learning for networks](https://arxiv.org/abs/1607.00653) (kdd 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/node2vec.py)]\n* **[deep graph infomax](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.deepgraphinfomax.html)** from veli\u010dkovi\u0107 *et al.*: [deep graph infomax](https://arxiv.org/abs/1809.10341) (iclr 2019) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/infomax_transductive.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/infomax_inductive.py)]\n* **deep multiplex graph infomax** from park *et al.*: [unsupervised attributed multiplex network embedding](https://arxiv.org/abs/1911.06750) (aaai 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/dmgi_unsup.py)]\n* **[masked label prediction](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.masklabel.html)** from shi *et al.*: [masked label prediction: unified message passing model for semi-supervised classification](https://arxiv.org/abs/2009.03509) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/unimp_arxiv.py)]\n* **[pmlp](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.pmlp.html)** from yang *et al.*: [graph neural networks are inherently good generalizers: insights by bridging gnns and mlps](https://arxiv.org/abs/2212.09034) (iclr 2023)\n\n<details>\n<summary><b>expand to see all implemented gnn models...</b></summary>\n\n* **[jumping knowledge](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.jumpingknowledge.html)** from xu *et al.*: [representation learning on graphs with jumping knowledge networks](https://arxiv.org/abs/1806.03536) (icml 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/gin.py#l54-l106)]\n* a **[metalayer](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.metalayer.html)** for building any kind of graph network similar to the [tensorflow graph nets library](https://github.com/deepmind/graph_nets) from battaglia *et al.*: [relational inductive biases, deep learning, and graph networks](https://arxiv.org/abs/1806.01261) (corr 2018)\n* **[metapath2vec](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.metapath2vec.html)** from dong *et al.*: [metapath2vec: scalable representation learning for heterogeneous networks](https://ericdongyx.github.io/papers/kdd17-dong-chawla-swami-metapath2vec.pdf) (kdd 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/metapath2vec.py)]\n* all variants of **[graph autoencoders](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.gae.html)** and **[variational autoencoders](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.vgae.html)** from:\n    * [variational graph auto-encoders](https://arxiv.org/abs/1611.07308) from kipf and welling (nips-w 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/autoencoder.py)]\n    * [adversarially regularized graph autoencoder for graph embedding](https://arxiv.org/abs/1802.04407) from pan *et al.* (ijcai 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/argva_node_clustering.py)]\n    * [simple and effective graph autoencoders with one-hop linear models](https://arxiv.org/abs/2001.07614) from salha *et al.* (ecml 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/autoencoder.py)]\n* **[seal](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/seal_link_pred.py)** from zhang and chen: [link prediction based on graph neural networks](https://arxiv.org/pdf/1802.09691.pdf) (neurips 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/seal_link_pred.py)]\n* **[renet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.renet.html)** from jin *et al.*: [recurrent event network for reasoning over temporal knowledge graphs](https://arxiv.org/abs/1904.05530) (iclr-w 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/renet.py)]\n* **[graphunet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.graphunet.html)** from gao and ji: [graph u-nets](https://arxiv.org/abs/1905.05178) (icml 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_unet.py)]\n* **[attentivefp](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.attentivefp.html)** from xiong *et al.*: [pushing the boundaries of molecular representation for drug discovery with the graph attention mechanism](https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959) (j. med. chem. 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/attentive_fp.py)]\n* **[deepgcn](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.deepgcnlayer.html)** and the **[genconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.genconv.html)** from li *et al.*: [deepgcns: can gcns go as deep as cnns?](https://arxiv.org/abs/1904.03751) (iccv 2019) and [deepergcn: all you need to train deeper gcns](https://arxiv.org/abs/2006.07739) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_proteins_deepgcn.py)]\n* **[rect](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.rect_l.html)** from wang *et al.*: [network embedding with completely-imbalanced labels](https://ieeexplore.ieee.org/document/8979355) (tkde 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rect.py)]\n* **[gnnexplainer](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.explain.algorithm.gnnexplainer.html)** from ying *et al.*: [gnnexplainer: generating explanations for graph neural networks](https://arxiv.org/abs/1903.03894) (neurips 2019) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/gnn_explainer.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/gnn_explainer_ba_shapes.py), [**example3**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/gnn_explainer_link_pred.py)]\n* **graph-less neural networks** from zhang *et al.*: [graph-less neural networks: teaching old mlps new tricks via distillation](https://arxiv.org/abs/2110.08727) (corr 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/glnn.py)]\n* **[linkx](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.linkx.html)** from lim *et al.*: [large scale learning on non-homophilous graphs:\nnew benchmarks and strong simple methods](https://arxiv.org/abs/2110.14446) (neurips 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/linkx.py)]\n* **[revgnn](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.groupaddrev.html)** from li *et al.*: [training graph neural with 1000 layers](https://arxiv.org/abs/2106.07476) (icml 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rev_gnn.py)]\n* **[transe](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.transe.html)** from bordes *et al.*: [translating embeddings for modeling multi-relational data](https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-paper.pdf) (nips 2013) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kge_fb15k_237.py)]\n* **[complex](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.complex.html)** from trouillon *et al.*: [complex embeddings for simple link prediction](https://arxiv.org/abs/1606.06357) (icml 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kge_fb15k_237.py)]\n* **[distmult](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.distmult.html)** from yang *et al.*: [embedding entities and relations for learning and inference in knowledge bases](https://arxiv.org/abs/1412.6575) (iclr 2015) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kge_fb15k_237.py)]\n* **[rotate](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.rotate.html)** from sun *et al.*: [rotate: knowledge graph embedding by relational rotation in complex space](https://arxiv.org/abs/1902.10197) (iclr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kge_fb15k_237.py)]\n</details>\n\n**gnn operators and utilities:**\npyg comes with a rich set of neural network operators that are commonly used in many gnn models.\nthey follow an extensible design: it is easy to apply these operators and graph utilities to existing gnn layers and models to further enhance model performance.\n\n* **[dropedge](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_edge)** from rong *et al.*: [dropedge: towards deep graph convolutional networks on node classification](https://openreview.net/forum?id=hkx1qkrkpr) (iclr 2020)\n* **[dropnode](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_node)**, **[maskfeature](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.mask_feature)** and **[addrandomedge](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.add_random_edge)** from you *et al.*: [graph contrastive learning with augmentations](https://arxiv.org/abs/2010.13902) (neurips 2020)\n* **[droppath](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_path)** from li *et al.*: [maskgae: masked graph modeling meets graph autoencoders](https://arxiv.org/abs/2205.10053) (arxiv 2022)\n* **[shufflenode](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.shuffle_node)** from veli\u010dkovi\u0107 *et al.*: [deep graph infomax](https://arxiv.org/abs/1809.10341) (iclr 2019)\n* **[graphnorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.graphnorm.html)** from cai *et al.*: [graphnorm: a principled approach to accelerating graph neural network training](https://proceedings.mlr.press/v139/cai21e.html) (icml 2021)\n* **[gdc](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.gdc.html)** from klicpera *et al.*: [diffusion improves graph learning](https://arxiv.org/abs/1911.05485) (neurips 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py)]\n\n<details>\n<summary><b>expand to see all implemented gnn operators and utilities...</b></summary>\n\n* **[graphsizenorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.graphsizenorm.html)** from dwivedi *et al.*: [benchmarking graph neural networks](https://arxiv.org/abs/2003.00982) (corr 2020)\n* **[pairnorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.pairnorm.html)** from zhao and akoglu: [pairnorm: tackling oversmoothing in gnns](https://arxiv.org/abs/1909.12223) (iclr 2020)\n* **[meansubtractionnorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.meansubtractionnorm.html)** from yang *et al.*: [revisiting \"over-smoothing\" in deep gcns](https://arxiv.org/abs/2003.13663) (corr 2020)\n* **[diffgroupnorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.diffgroupnorm.html)** from zhou *et al.*: [towards deeper graph neural networks with differentiable group normalization](https://arxiv.org/abs/2006.06972) (neurips 2020)\n* **[tree decomposition](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.tree_decomposition)** from jin *et al.*: [junction tree variational autoencoder for molecular graph generation](https://arxiv.org/abs/1802.04364) (icml 2018)\n* **[tgn](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.tgnmemory.html)** from rossi *et al.*: [temporal graph networks for deep learning on dynamic graphs](https://arxiv.org/abs/2006.10637) (grl+ 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/tgn.py)]\n* **[weisfeiler lehman operator](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.wlconv.html)** from weisfeiler and lehman: [a reduction of a graph to a canonical form and an algebra arising during this reduction](https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf) (nauchno-technicheskaya informatsia 1968) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/wl_kernel.py)]\n* **[continuous weisfeiler lehman operator](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.wlconvcontinuous.html)** from togninalli *et al.*: [wasserstein weisfeiler-lehman graph kernels](https://arxiv.org/abs/1906.01277) (neurips 2019)\n* **[label propagation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.labelpropagation.html)** from zhu and ghahramani: [learning from labeled and unlabeled data with label propagation](http://mlg.eng.cam.ac.uk/zoubin/papers/cmu-cald-02-107.pdf) (cmu-cald 2002) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/label_prop.py)]\n* **[local degree profile](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.localdegreeprofile)** from cai and wang: [a simple yet effective baseline for non-attribute graph classification](https://arxiv.org/abs/1811.03508) (corr 2018)\n* **[correctandsmooth](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.correctandsmooth.html)** from huang *et al.*: [combining label propagation and simple models out-performs graph neural networks](https://arxiv.org/abs/2010.13993) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/correct_and_smooth.py)]\n* **[gini](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.functional.gini.html)** and **[bro](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.functional.bro.html)** regularization from henderson *et al.*: [improving molecular graph neural network explainability with orthonormalization and induced sparsity](https://arxiv.org/abs/2105.04854) (icml 2021)\n* **[rootedegonets](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.rootedegonets)** and **[rootedrwsubgraph](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.rootedrwsubgraph)** from zhao *et al.*: [from stars to subgraphs: uplifting any gnn with local structure awareness](https://arxiv.org/abs/2110.03753) (iclr 2022)\n* **[featurepropagation](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.featurepropagation)** from rossi *et al.*: [on the unreasonable effectiveness of feature propagation in learning on graphs with missing node features](https://arxiv.org/abs/2111.12128) (corr 2021)\n</details>\n\n**scalable gnns:**\npyg supports the implementation of graph neural networks that can scale to large-scale graphs.\nsuch application is challenging since the entire graph, its associated features and the gnn parameters cannot fit into gpu memory.\nmany state-of-the-art scalability approaches tackle this challenge by sampling neighborhoods for mini-batch training, graph clustering and partitioning, or by using simplified gnn models.\nthese approaches have been implemented in pyg, and can benefit from the above gnn layers, operators and models.\n\n* **[neighborloader](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.neighborloader)** from hamilton *et al.*: [inductive representation learning on large graphs](https://arxiv.org/abs/1706.02216) (nips 2017) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/reddit.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py), [**example3**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_gat.py), [**example4**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py)]\n* **[clustergcn](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.clusterloader)** from chiang *et al.*: [cluster-gcn: an efficient algorithm for training deep and large graph convolutional networks](https://arxiv.org/abs/1905.07953) (kdd 2019) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cluster_gcn_reddit.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cluster_gcn_ppi.py)]\n* **[graphsaint](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.graphsaintsampler)** from zeng *et al.*: [graphsaint: graph sampling based inductive learning method](https://arxiv.org/abs/1907.04931) (iclr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_saint.py)]\n\n<details>\n<summary><b>expand to see all implemented scalable gnns...</b></summary>\n\n* **[shadow](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.shadowkhopsampler)** from zeng *et al.*: [decoupling the depth and scope of graph neural networks](https://arxiv.org/abs/2201.07858) (neurips 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/shadow.py)]\n* **[sign](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.sign.html)** from rossi *et al.*: [sign: scalable inception graph neural networks](https://arxiv.org/abs/2004.11198) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/sign.py)]\n* **[hgtloader](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.loader.hgtloader.html)** from hu *et al.*: [heterogeneous graph transformer](https://arxiv.org/abs/2003.01332) (www 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py)]\n</details>\n\n## installation\n\npyg is available for python 3.8 to python 3.11.\n\n### anaconda\n\nyou can now install pyg via [anaconda](https://anaconda.org/pyg/pyg) for all major os/pytorch/cuda combinations \ud83e\udd17\nif you have not yet installed pytorch, install it via `conda` as described in the [official pytorch documentation](https://pytorch.org/get-started/locally/).\ngiven that you have pytorch installed (`>=1.8.0`), simply run\n\n```\nconda install pyg -c pyg\n```\n\n### pypi\n\nfrom **pyg 2.3** onwards, you can install and use pyg **without any external library** required except for pytorch.\nfor this, simply run\n\n```\npip install torch_geometric\n```\n\npyg 2.3 requires that at least pytorch 1.11 is installed.\n\n### additional libraries\n\nif you want to utilize the full set of features from pyg, there exists several additional libraries you may want to install:\n\n* **[`pyg-lib`](https://github.com/pyg-team/pyg-lib)**: heterogeneous gnn operators and graph sampling routines\n* **[`torch-scatter`](https://github.com/rusty1s/pytorch_scatter)**: accelerated and efficient sparse reductions\n* **[`torch-sparse`](https://github.com/rusty1s/pytorch_sparse)**: [`sparsetensor`](https://pytorch-geometric.readthedocs.io/en/latest/advanced/sparse_tensor.html) support\n* **[`torch-cluster`](https://github.com/rusty1s/pytorch_cluster)**: graph clustering routines\n* **[`torch-spline-conv`](https://github.com/rusty1s/pytorch_spline_conv)**: [`splineconv`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.splineconv.html) support\n\nthese packages come with their own cpu and gpu kernel implementations based on the [pytorch c++/cuda/hip(rocm) extension interface](https://github.com/pytorch/extension-cpp).\nfor a basic usage of pyg, these dependencies are **fully optional**.\nwe recommend to start with a minimal installation, and install additional dependencies once you start to actually need them.\n\nfor ease of installation of these extensions, we provide `pip` wheels for all major os/pytorch/cuda combinations, see [here](https://data.pyg.org/whl).\n\n#### pytorch 2.1\n\nto install the binaries for pytorch 2.1.0, simply run\n\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+${cuda}.html\n```\n\nwhere `${cuda}` should be replaced by either `cpu`, `cu118`, or `cu121` depending on your pytorch installation.\n\n|             | `cpu` | `cu118` | `cu121` |\n|-------------|-------|---------|---------|\n| **linux**   | \u2705    | \u2705      | \u2705      |\n| **windows** | \u2705    | \u2705      | \u2705      |\n| **macos**   | \u2705    |         |         |\n\n#### pytorch 2.0\n\nto install the binaries for pytorch 2.0.0, simply run\n\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+${cuda}.html\n```\n\nwhere `${cuda}` should be replaced by either `cpu`, `cu117`, or `cu118` depending on your pytorch installation.\n\n|             | `cpu` | `cu117` | `cu118` |\n|-------------|-------|---------|---------|\n| **linux**   | \u2705    | \u2705      | \u2705      |\n| **windows** | \u2705    | \u2705      | \u2705      |\n| **macos**   | \u2705    |         |         |\n\n**note:** binaries of older versions are also provided for pytorch 1.4.0, pytorch 1.5.0, pytorch 1.6.0, pytorch 1.7.0/1.7.1, pytorch 1.8.0/1.8.1, pytorch 1.9.0, pytorch 1.10.0/1.10.1/1.10.2, pytorch 1.11.0, pytorch 1.12.0/1.12.1 and pytorch 1.13.0/1.13.1 (following the same procedure).\n**for older versions, you might need to explicitly specify the latest supported version number** or install via `pip install --no-index` in order to prevent a manual installation from source.\nyou can look up the latest supported version number [here](https://data.pyg.org/whl).\n\n### nightly and master\n\nin case you want to experiment with the latest pyg features which are not fully released yet, either install the **nightly version** of pyg via\n\n```\npip install pyg-nightly\n```\n\nor install pyg **from master** via\n\n```\npip install git+https://github.com/pyg-team/pytorch_geometric.git\n```\n\n### rocm wheels\n\nthe external [`pyg-rocm-build` repository](https://github.com/looong01/pyg-rocm-build) provides wheels and detailed instructions on how to install pyg for rocm.\nif you have any questions about it, please open an issue [here](https://github.com/looong01/pyg-rocm-build/issues).\n\n## cite\n\nplease cite [our paper](https://arxiv.org/abs/1903.02428) (and the respective papers of the methods used) if you use this code in your own work:\n\n```\n@inproceedings{fey/lenssen/2019,\n  title={fast graph representation learning with {pytorch geometric}},\n  author={fey, matthias and lenssen, jan e.},\n  booktitle={iclr workshop on representation learning on graphs and manifolds},\n  year={2019},\n}\n```\n\nfeel free to [email us](mailto:matthias.fey@tu-dortmund.de) if you wish your work to be listed in the [external resources](https://pytorch-geometric.readthedocs.io/en/latest/external/resources.html).\nif you notice anything unexpected, please open an [issue](https://github.com/pyg-team/pytorch_geometric/issues) and let us know.\nif you have any questions or are missing a specific feature, feel free [to discuss them with us](https://github.com/pyg-team/pytorch_geometric/discussions).\nwe are motivated to constantly make pyg even better.\n\n",
  "docs_url": null,
  "keywords": "deep-learning,pytorch,geometric-deep-learning,graph-neural-networks,graph-convolutional-networks",
  "license": "",
  "name": "torch-geometric",
  "package_url": "https://pypi.org/project/torch-geometric/",
  "project_url": "https://pypi.org/project/torch-geometric/",
  "project_urls": {
    "changelog": "https://github.com/pyg-team/pytorch_geometric/blob/master/CHANGELOG.md",
    "documentation": "https://pytorch-geometric.readthedocs.io",
    "homepage": "https://pyg.org",
    "repository": "https://github.com/pyg-team/pytorch_geometric.git"
  },
  "release_url": "https://pypi.org/project/torch-geometric/2.4.0/",
  "requires_dist": [
    "tqdm",
    "numpy",
    "scipy",
    "jinja2",
    "requests",
    "pyparsing",
    "scikit-learn",
    "psutil>=5.8.0",
    "protobuf<4.21 ; extra == \"benchmark\"",
    "wandb ; extra == \"benchmark\"",
    "pandas ; extra == \"benchmark\"",
    "networkx ; extra == \"benchmark\"",
    "matplotlib ; extra == \"benchmark\"",
    "torch_geometric[test] ; extra == \"dev\"",
    "pre-commit ; extra == \"dev\"",
    "torch_geometric[graphgym, modelhub] ; extra == \"full\"",
    "ase ; extra == \"full\"",
    "h5py ; extra == \"full\"",
    "numba ; extra == \"full\"",
    "sympy ; extra == \"full\"",
    "pandas ; extra == \"full\"",
    "captum ; extra == \"full\"",
    "rdflib ; extra == \"full\"",
    "trimesh ; extra == \"full\"",
    "networkx ; extra == \"full\"",
    "graphviz ; extra == \"full\"",
    "tabulate ; extra == \"full\"",
    "matplotlib ; extra == \"full\"",
    "pynndescent ; extra == \"full\"",
    "torchmetrics ; extra == \"full\"",
    "scikit-image ; extra == \"full\"",
    "pytorch-memlab ; extra == \"full\"",
    "pgmpy ; extra == \"full\"",
    "opt_einsum ; extra == \"full\"",
    "statsmodels ; extra == \"full\"",
    "rdkit ; extra == \"full\"",
    "yacs ; extra == \"graphgym\"",
    "hydra-core ; extra == \"graphgym\"",
    "protobuf<4.21 ; extra == \"graphgym\"",
    "pytorch-lightning ; extra == \"graphgym\"",
    "huggingface_hub ; extra == \"modelhub\"",
    "pytest ; extra == \"test\"",
    "pytest-cov ; extra == \"test\"",
    "onnx ; extra == \"test\"",
    "onnxruntime ; extra == \"test\""
  ],
  "requires_python": ">=3.8",
  "summary": "graph neural network library for pytorch",
  "version": "2.4.0",
  "releases": [],
  "developers": [
    "matthias@pyg.org"
  ],
  "kwds": "torch_geometric pytorch edge_features hypergraphconv svg",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_torch_geometric",
  "homepage": "",
  "release_count": 38,
  "dependency_ids": [
    "pypi_ase",
    "pypi_captum",
    "pypi_graphviz",
    "pypi_h5py",
    "pypi_huggingface_hub",
    "pypi_hydra_core",
    "pypi_jinja2",
    "pypi_matplotlib",
    "pypi_networkx",
    "pypi_numba",
    "pypi_numpy",
    "pypi_onnx",
    "pypi_onnxruntime",
    "pypi_opt_einsum",
    "pypi_pandas",
    "pypi_pgmpy",
    "pypi_pre_commit",
    "pypi_protobuf",
    "pypi_psutil",
    "pypi_pynndescent",
    "pypi_pyparsing",
    "pypi_pytest",
    "pypi_pytest_cov",
    "pypi_pytorch_lightning",
    "pypi_pytorch_memlab",
    "pypi_rdflib",
    "pypi_rdkit",
    "pypi_requests",
    "pypi_scikit_image",
    "pypi_scikit_learn",
    "pypi_scipy",
    "pypi_statsmodels",
    "pypi_sympy",
    "pypi_tabulate",
    "pypi_torch_geometric",
    "pypi_torchmetrics",
    "pypi_tqdm",
    "pypi_trimesh",
    "pypi_wandb",
    "pypi_yacs"
  ]
}