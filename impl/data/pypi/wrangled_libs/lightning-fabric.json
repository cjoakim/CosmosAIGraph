{
  "classifiers": [
    "development status :: 4 - beta",
    "environment :: console",
    "intended audience :: developers",
    "natural language :: english",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: scientific/engineering :: information analysis"
  ],
  "description": "\n<div align=\"center\">\n\n<img src=\"https://pl-public-data.s3.amazonaws.com/assets_lightning/fabric_logo.png\" width=\"400px\">\n\n**fabric is the fast and lightweight way to scale pytorch models without boilerplate**\n\n______________________________________________________________________\n\n<p align=\"center\">\n  <a href=\"https://lightning.ai/\">website</a> \u2022\n  <a href=\"https://lightning.ai/docs/fabric/\">docs</a> \u2022\n  <a href=\"#getting-started\">getting started</a> \u2022\n  <a href=\"#faq\">faq</a> \u2022\n  <a href=\"#asking-for-help\">help</a> \u2022\n  <a href=\"https://discord.gg/vptpczkgna\">discord</a>\n</p>\n\n[![pypi - python version](https://img.shields.io/pypi/pyversions/lightning_fabric)](https://pypi.org/project/lightning_fabric/)\n[![pypi status](https://badge.fury.io/py/lightning_fabric.svg)](https://badge.fury.io/py/lightning_fabric)\n[![pypi - downloads](https://img.shields.io/pypi/dm/lightning-fabric)](https://pepy.tech/project/lightning-fabric)\n[![conda](https://img.shields.io/conda/v/conda-forge/lightning_fabric?label=conda&color=success)](https://anaconda.org/conda-forge/lightning_fabric)\n\n</div>\n\n# lightning fabric: expert control.\n\nrun on any device at any scale with expert-level control over pytorch training loop and scaling strategy. you can even write your own trainer.\n\nfabric is designed for the most complex models like foundation model scaling, llms, diffusion, transformers, reinforcement learning, active learning. of any size.\n\n<table>\n<tr>\n<th>what to change</th>\n<th>resulting fabric code (copy me!)</th>\n</tr>\n<tr>\n<td>\n<sub>\n\n```diff\n+ import lightning as l\n  import torch; import torchvision as tv\n\n  dataset = tv.datasets.cifar10(\"data\", download=true,\n                                train=true,\n                                transform=tv.transforms.totensor())\n\n+ fabric = l.fabric()\n+ fabric.launch()\n\n  model = tv.models.resnet18()\n  optimizer = torch.optim.sgd(model.parameters(), lr=0.001)\n- device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n- model.to(device)\n+ model, optimizer = fabric.setup(model, optimizer)\n\n  dataloader = torch.utils.data.dataloader(dataset, batch_size=8)\n+ dataloader = fabric.setup_dataloaders(dataloader)\n\n  model.train()\n  num_epochs = 10\n  for epoch in range(num_epochs):\n      for batch in dataloader:\n          inputs, labels = batch\n-         inputs, labels = inputs.to(device), labels.to(device)\n          optimizer.zero_grad()\n          outputs = model(inputs)\n          loss = torch.nn.functional.cross_entropy(outputs, labels)\n-         loss.backward()\n+         fabric.backward(loss)\n          optimizer.step()\n```\n\n</sub>\n<td>\n<sub>\n\n```python\nimport lightning as l\nimport torch; import torchvision as tv\n\ndataset = tv.datasets.cifar10(\"data\", download=true,\n                              train=true,\n                              transform=tv.transforms.totensor())\n\nfabric = l.fabric()\nfabric.launch()\n\nmodel = tv.models.resnet18()\noptimizer = torch.optim.sgd(model.parameters(), lr=0.001)\nmodel, optimizer = fabric.setup(model, optimizer)\n\ndataloader = torch.utils.data.dataloader(dataset, batch_size=8)\ndataloader = fabric.setup_dataloaders(dataloader)\n\nmodel.train()\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        inputs, labels = batch\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        fabric.backward(loss)\n        optimizer.step()\n```\n\n</sub>\n</td>\n</tr>\n</table>\n\n## key features\n\n<details>\n  <summary>easily switch from running on cpu to gpu (apple silicon, cuda, \u2026), tpu, multi-gpu or even multi-node training</summary>\n\n```python\n# use your available hardware\n# no code changes needed\nfabric = fabric()\n\n# run on gpus (cuda or mps)\nfabric = fabric(accelerator=\"gpu\")\n\n# 8 gpus\nfabric = fabric(accelerator=\"gpu\", devices=8)\n\n# 256 gpus, multi-node\nfabric = fabric(accelerator=\"gpu\", devices=8, num_nodes=32)\n\n# run on tpus\nfabric = fabric(accelerator=\"tpu\")\n```\n\n</details>\n\n<details>\n  <summary>use state-of-the-art distributed training strategies (ddp, fsdp, deepspeed) and mixed precision out of the box</summary>\n\n```python\n# use state-of-the-art distributed training techniques\nfabric = fabric(strategy=\"ddp\")\nfabric = fabric(strategy=\"deepspeed\")\nfabric = fabric(strategy=\"fsdp\")\n\n# switch the precision\nfabric = fabric(precision=\"16-mixed\")\nfabric = fabric(precision=\"64\")\n```\n\n</details>\n\n<details>\n  <summary>all the device logic boilerplate is handled for you</summary>\n\n```diff\n  # no more of this!\n- model.to(device)\n- batch.to(device)\n```\n\n</details>\n\n<details>\n  <summary>build your own custom trainer using fabric primitives for training checkpointing, logging, and more</summary>\n\n```python\nimport lightning as l\n\n\nclass mycustomtrainer:\n    def __init__(self, accelerator=\"auto\", strategy=\"auto\", devices=\"auto\", precision=\"32-true\"):\n        self.fabric = l.fabric(accelerator=accelerator, strategy=strategy, devices=devices, precision=precision)\n\n    def fit(self, model, optimizer, dataloader, max_epochs):\n        self.fabric.launch()\n\n        model, optimizer = self.fabric.setup(model, optimizer)\n        dataloader = self.fabric.setup_dataloaders(dataloader)\n        model.train()\n\n        for epoch in range(max_epochs):\n            for batch in dataloader:\n                input, target = batch\n                optimizer.zero_grad()\n                output = model(input)\n                loss = loss_fn(output, target)\n                self.fabric.backward(loss)\n                optimizer.step()\n```\n\nyou can find a more extensive example in our [examples](../../examples/fabric/build_your_own_trainer)\n\n</details>\n\n______________________________________________________________________\n\n<div align=\"center\">\n    <a href=\"https://lightning.ai/docs/fabric/stable/\">read the lightning fabric docs</a>\n</div>\n\n______________________________________________________________________\n\n## continuous integration\n\nlightning is rigorously tested across multiple cpus and gpus and against major python and pytorch versions.\n\n###### \\*codecov is > 90%+ but build delays may show less\n\n<details>\n  <summary>current build statuses</summary>\n\n<center>\n\n|       system / pytorch ver.        |                                                   1.12                                                    |                                                   1.13                                                    |                                                    2.0                                                    |                                                       2.1                                                        |\n| :--------------------------------: | :-------------------------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------: |\n|        linux py3.9 \\[gpus\\]        |                                                                                                           |                                                                                                           |                                                                                                           | ![build status](https://dev.azure.com/lightning-ai/lightning/_apis/build/status%2flightning-fabric%20%28gpus%29) |\n|  linux (multiple python versions)  | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) |    ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg)     |\n|   osx (multiple python versions)   | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) |    ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg)     |\n| windows (multiple python versions) | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) | ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg) |    ![test fabric](https://github.com/lightning-ai/lightning/actions/workflows/ci-tests-fabric.yml/badge.svg)     |\n\n</center>\n</details>\n\n______________________________________________________________________\n\n# getting started\n\n## install lightning\n\n<details>\n\n<summary>prerequisites</summary>\n\n> tip: we strongly recommend creating a virtual environment first.\n> don\u2019t know what this is? follow our [beginner guide here](https://lightning.ai/docs/stable/install/installation.html).\n\n- python 3.8.x or later (3.8.x, 3.9.x, 3.10.x, ...)\n\n</details>\n\n```bash\npip install -u lightning\n```\n\n## convert your pytorch to fabric\n\n1. create the `fabric` object at the beginning of your training code.\n\n   ```\n   import lightning as l\n\n   fabric = l.fabric()\n   ```\n\n1. call `setup()` on each model and optimizer pair and `setup_dataloaders()` on all your data loaders.\n\n   ```\n   model, optimizer = fabric.setup(model, optimizer)\n   dataloader = fabric.setup_dataloaders(dataloader)\n   ```\n\n1. remove all `.to` and `.cuda` calls -> fabric will take care of it.\n\n   ```diff\n   - model.to(device)\n   - batch.to(device)\n   ```\n\n1. replace `loss.backward()` by `fabric.backward(loss)`.\n\n   ```diff\n   - loss.backward()\n   + fabric.backward(loss)\n   ```\n\n1. run the script from the terminal with\n\n   ```bash\n   lightning run model path/to/train.py\n   ```\n\nor use the launch() method in a notebook. learn more about [launching distributed training](https://lightning.ai/docs/fabric/stable/fundamentals/launch.html).\n\n______________________________________________________________________\n\n# faq\n\n## when to use fabric?\n\n- **minimum code changes**- you want to scale your pytorch model to use multi-gpu or use advanced strategies like deepspeed without having to refactor. you don\u2019t care about structuring your code- you just want to scale it as fast as possible.\n- **maximum control**- write your own training and/or inference logic down to the individual optimizer calls. you aren\u2019t forced to conform to a standardized epoch-based training loop like the one in lightning trainer. you can do flexible iteration based training, meta-learning, cross-validation and other types of optimization algorithms without digging into framework internals. this also makes it super easy to adopt fabric in existing pytorch projects to speed-up and scale your models without the compromise on large refactors. just remember: with great power comes a great responsibility.\n- **maximum flexibility**- you want to have full control over your entire training- in fabric all features are opt-in, and it provides you with a tool box of primitives so you can build your own trainer.\n\n## when to use the [lightning trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html)?\n\n- you want to have all the engineering boilerplate handled for you - dozens of features like checkpointing, logging and early stopping out of the box. less hassle, less error prone, easy to try different techniques and features.\n- you want to have good defaults chosen for you - so you can have a better starting point.\n- you want your code to be modular, readable and well structured - easy to share between projects and with collaborators.\n\n## can i use fabric with my lightningmodule or lightning callback?\n\nyes :) fabric works with pytorch lightningmodules and callbacks, so you can choose how to structure your code and reuse existing models and callbacks as you wish. read more [here](https://lightning.ai/docs/fabric/stable/fundamentals/code_structure.html).\n\n<img src=\"https://pl-public-data.s3.amazonaws.com/assets_lightning/continuum.png\" width=\"800px\">\n\n______________________________________________________________________\n\n# examples\n\n- [gan](https://github.com/lightning-ai/lightning/tree/master/examples/fabric/dcgan)\n- [meta learning](https://github.com/lightning-ai/lightning/tree/master/examples/fabric/meta_learning)\n- [reinforcement learning](https://github.com/lightning-ai/lightning/tree/master/examples/fabric/reinforcement_learning)\n- [k-fold cross validation](https://github.com/lightning-ai/lightning/tree/master/examples/fabric/kfold_cv)\n\n______________________________________________________________________\n\n## asking for help\n\nif you have any questions please:\n\n1. [read the docs](https://lightning.ai/docs/fabric).\n1. [ask a question in our forum](https://lightning.ai/forums/).\n1. [join our discord community](https://discord.com/invite/tfxfetezxv).\n\n\n",
  "docs_url": null,
  "keywords": "deep learning,pytorch,ai",
  "license": "apache-2.0",
  "name": "lightning-fabric",
  "package_url": "https://pypi.org/project/lightning-fabric/",
  "project_url": "https://pypi.org/project/lightning-fabric/",
  "project_urls": {
    "Bug Tracker": "https://github.com/Lightning-AI/lightning/issues",
    "Documentation": "https://pytorch-lightning.rtfd.io/en/latest/",
    "Download": "https://github.com/Lightning-AI/lightning",
    "Homepage": "https://github.com/Lightning-AI/lightning",
    "Source Code": "https://github.com/Lightning-AI/lightning"
  },
  "release_url": "https://pypi.org/project/lightning-fabric/2.1.3/",
  "requires_dist": [
    "numpy >=1.17.2",
    "torch >=1.12.0",
    "fsspec[http] >=2022.5.0",
    "packaging >=20.0",
    "typing-extensions >=4.0.0",
    "lightning-utilities >=0.8.0",
    "torchvision >=0.13.0 ; extra == 'all'",
    "torchmetrics >=0.10.0 ; extra == 'all'",
    "lightning-utilities >=0.8.0 ; extra == 'all'",
    "deepspeed <=0.9.3,>=0.8.2 ; (platform_system != \"Windows\") and extra == 'all'",
    "deepspeed <=0.9.3,>=0.8.2 ; (platform_system != \"Windows\") and extra == 'deepspeed'",
    "torchvision >=0.13.0 ; extra == 'dev'",
    "torchmetrics >=0.10.0 ; extra == 'dev'",
    "lightning-utilities >=0.8.0 ; extra == 'dev'",
    "coverage ==7.3.1 ; extra == 'dev'",
    "pytest ==7.4.0 ; extra == 'dev'",
    "pytest-cov ==4.1.0 ; extra == 'dev'",
    "pytest-timeout ==2.1.0 ; extra == 'dev'",
    "pytest-rerunfailures ==12.0 ; extra == 'dev'",
    "pytest-random-order ==1.1.0 ; extra == 'dev'",
    "click ==8.1.7 ; extra == 'dev'",
    "tensorboardX >=2.2 ; extra == 'dev'",
    "torchmetrics >=0.7.0 ; extra == 'dev'",
    "deepspeed <=0.9.3,>=0.8.2 ; (platform_system != \"Windows\") and extra == 'dev'",
    "torchvision >=0.13.0 ; extra == 'examples'",
    "torchmetrics >=0.10.0 ; extra == 'examples'",
    "lightning-utilities >=0.8.0 ; extra == 'examples'",
    "deepspeed <=0.9.3,>=0.8.2 ; (platform_system != \"Windows\") and extra == 'strategies'",
    "coverage ==7.3.1 ; extra == 'test'",
    "pytest ==7.4.0 ; extra == 'test'",
    "pytest-cov ==4.1.0 ; extra == 'test'",
    "pytest-timeout ==2.1.0 ; extra == 'test'",
    "pytest-rerunfailures ==12.0 ; extra == 'test'",
    "pytest-random-order ==1.1.0 ; extra == 'test'",
    "click ==8.1.7 ; extra == 'test'",
    "tensorboardX >=2.2 ; extra == 'test'",
    "torchmetrics >=0.7.0 ; extra == 'test'"
  ],
  "requires_python": ">=3.8",
  "summary": "",
  "version": "2.1.3",
  "releases": [],
  "developers": [
    "lightning_ai_et_al",
    "pytorch@lightning.ai"
  ],
  "kwds": "pytorch lightning_fabric scaling scale fabric_logo",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_lightning_fabric",
  "homepage": "https://github.com/lightning-ai/lightning",
  "release_count": 26,
  "dependency_ids": [
    "pypi_click",
    "pypi_coverage",
    "pypi_deepspeed",
    "pypi_fsspec",
    "pypi_lightning_utilities",
    "pypi_numpy",
    "pypi_packaging",
    "pypi_pytest",
    "pypi_pytest_cov",
    "pypi_pytest_random_order",
    "pypi_pytest_rerunfailures",
    "pypi_pytest_timeout",
    "pypi_tensorboardx",
    "pypi_torch",
    "pypi_torchmetrics",
    "pypi_torchvision",
    "pypi_typing_extensions"
  ],
  "documentation_summary": "Lightning Fabric, available on PyPI as version 2.2.1 released on March 4, 2024, is a Python package designed to scale PyTorch models efficiently without boilerplate code. It offers expert-level control over the PyTorch training loop and scaling strategy, supporting complex models across various devices and scales. Key features include easy switching between CPU and GPU, state-of-the-art distributed training strategies, mixed precision out of the box, and custom Trainer building capabilities. It requires Python version 3.8 or higher and is licensed under Apache-2.0. The package is developed by Lightning AI and targets developers in the fields of deep learning, AI, and scientific/engineering applications.",
  "embedding": [
    -0.020405907183885574,
    0.0028052744455635548,
    -0.005345257464796305,
    -0.009765581227838993,
    0.014318550936877728,
    -0.0029522599652409554,
    0.0011418273206800222,
    -0.01236113253980875,
    -0.024994725361466408,
    -0.033297620713710785,
    0.007170030381530523,
    0.01604652777314186,
    -0.027403855696320534,
    0.031834933906793594,
    -0.00612679123878479,
    0.013981559313833714,
    0.007593062240630388,
    -0.007643252611160278,
    0.0006202076328918338,
    -0.0121532017365098,
    0.014555161818861961,
    0.0017817525658756495,
    -0.006313211750239134,
    -0.029095983132719994,
    -0.042790740728378296,
    0.017064671963453293,
    0.03401462361216545,
    -0.016003508120775223,
    0.007008704822510481,
    -0.009844452142715454,
    0.03232249617576599,
    -0.007879863493144512,
    -0.014712902717292309,
    0.0008097653044387698,
    -0.021725192666053772,
    -0.007922884076833725,
    0.019086621701717377,
    -0.004126352723687887,
    0.05142345651984215,
    -0.01162261888384819,
    0.03986537083983421,
    0.018656419590115547,
    -0.00889083743095398,
    0.01902926154434681,
    -0.015903128311038017,
    0.0051695918664336205,
    -0.00528072752058506,
    -0.023159198462963104,
    0.003163775894790888,
    -0.004362963605672121,
    0.010625985451042652,
    0.009801431559026241,
    0.00802326388657093,
    0.005829234607517719,
    0.0021241214126348495,
    0.0037570958957076073,
    -0.0035903926473110914,
    0.020405907183885574,
    0.017580915242433548,
    -0.0032067960128188133,
    -0.011766020208597183,
    0.003403971903026104,
    -0.025467948988080025,
    0.007087575271725655,
    -0.013372106477618217,
    -0.0030759430956095457,
    -0.011694319546222687,
    0.014440441504120827,
    -0.016992971301078796,
    -0.005226952023804188,
    0.03129001334309578,
    0.01512876432389021,
    0.004535044077783823,
    -0.03808720037341118,
    0.019531162455677986,
    -0.01669183000922203,
    -0.006248681340366602,
    0.021710852161049843,
    -0.014841962605714798,
    -0.013967219740152359,
    -0.011665639467537403,
    -0.0032229286152869463,
    0.01796809583902359,
    0.007284750696271658,
    0.013178516179323196,
    0.018541699275374413,
    -0.01384532917290926,
    0.0001297327398788184,
    -0.023087497800588608,
    -0.013680418021976948,
    -0.002493378007784486,
    -0.00491147069260478,
    0.02810651995241642,
    0.040066130459308624,
    -0.026715533807873726,
    0.02262861654162407,
    -0.004337868187576532,
    0.014426100999116898,
    0.010267484001815319,
    -0.009514630772173405,
    -0.017796015366911888,
    0.007098330184817314,
    -0.01426119077950716,
    -0.014454781077802181,
    -0.03630903363227844,
    -0.045744795352220535,
    0.003291043918579817,
    -0.006273776758462191,
    0.028421999886631966,
    0.019402101635932922,
    -0.041127294301986694,
    0.04844072461128235,
    -0.019817963242530823,
    -0.040037449449300766,
    -0.011192417703568935,
    -0.0017199110006913543,
    -0.010532774962484837,
    0.006650203373283148,
    -0.003445199690759182,
    -0.021452730521559715,
    0.024234702810645103,
    0.007922884076833725,
    -0.010081063024699688,
    0.012848694808781147,
    0.001962795853614807,
    -0.03088849037885666,
    -0.021223289892077446,
    0.0072381459176540375,
    -0.016634469851851463,
    -0.014153639785945415,
    0.034158024936914444,
    0.0221553947776556,
    0.0036011477932333946,
    -0.008431956171989441,
    -0.01672051101922989,
    -0.0156736858189106,
    -0.016620131209492683,
    -0.02237049490213394,
    -0.04927244782447815,
    0.006671713199466467,
    0.011751679703593254,
    0.014311380684375763,
    -0.008388935588300228,
    -0.016218608245253563,
    -0.016333328559994698,
    0.06481707841157913,
    0.005908105056732893,
    0.01564500667154789,
    -0.014483461156487465,
    -0.00791571382433176,
    0.02935410477221012,
    0.003332271706312895,
    -0.013271726667881012,
    0.007499851752072573,
    -0.003325101686641574,
    0.008051943965256214,
    -0.0076289125718176365,
    0.008862157352268696,
    0.0052556321024894714,
    0.008876497857272625,
    0.02011910453438759,
    0.03737019747495651,
    -0.006689638365060091,
    -0.006101695820689201,
    -0.00994483195245266,
    0.023345619440078735,
    0.03002808801829815,
    -0.014124959707260132,
    -0.006582087837159634,
    -0.007679102476686239,
    0.010324844159185886,
    0.0333549827337265,
    -0.03381386399269104,
    0.01403891947120428,
    0.017910735681653023,
    0.012992095202207565,
    0.01469856221228838,
    -0.0061698113568127155,
    -0.008417615666985512,
    0.009270849637687206,
    0.03693999722599983,
    -0.012769823893904686,
    0.014956683851778507,
    0.04887092858552933,
    -0.00940707977861166,
    -0.012454343028366566,
    -0.01213169191032648,
    -0.01521480455994606,
    -0.0022693146020174026,
    -0.017796015366911888,
    0.011443368159234524,
    0.037112075835466385,
    -0.027002334594726562,
    -1.8082620272252825e-06,
    -0.5740613341331482,
    0.004230318125337362,
    -0.010740705765783787,
    -0.030745090916752815,
    -0.0060013155452907085,
    -0.0014608936617150903,
    0.010396543890237808,
    -0.00042258366011083126,
    -0.008618376217782497,
    0.00907725840806961,
    -0.012597743421792984,
    0.022040674462914467,
    -0.025424927473068237,
    -0.022298794239759445,
    -0.019287381321191788,
    -0.019918344914913177,
    0.009679540991783142,
    -0.017810355871915817,
    -0.011149397119879723,
    0.006008485332131386,
    -0.025539647787809372,
    0.026557791978120804,
    0.0014770262641832232,
    0.011264117434620857,
    -0.0022997872438281775,
    0.00866139680147171,
    0.009643690660595894,
    0.013737778179347515,
    0.055696796625852585,
    -0.0023553550709038973,
    -0.02075006812810898,
    0.015200464986264706,
    0.028995603322982788,
    0.00029329906101338565,
    0.0579051673412323,
    0.002194029279053211,
    -0.02241351455450058,
    0.054004669189453125,
    0.010081063024699688,
    0.041299376636743546,
    -0.03186361491680145,
    -0.01153657864779234,
    0.01426119077950716,
    0.0007913921144790947,
    -0.007309846114367247,
    0.0020757238380610943,
    0.0026116836816072464,
    0.004201638046652079,
    0.002900277264416218,
    -0.0022818620782345533,
    -0.007177200634032488,
    0.00316736102104187,
    -0.002998865209519863,
    -0.02747555635869503,
    0.009758410975337029,
    -0.007152105215936899,
    0.0283646397292614,
    0.025324547663331032,
    0.014361570589244366,
    0.0023947900626808405,
    -0.0021545940544456244,
    0.002893107244744897,
    -0.005209027323871851,
    -0.021667832508683205,
    -0.011586769483983517,
    -0.006919079460203648,
    -0.022714655846357346,
    -0.01287737488746643,
    0.012167541310191154,
    -0.0030490553472191095,
    0.036882635205984116,
    0.0018785479478538036,
    0.019789284095168114,
    -0.006377742160111666,
    0.015300844796001911,
    0.027834057807922363,
    0.03042960911989212,
    0.022886736318469048,
    0.0037427558563649654,
    0.03547731041908264,
    0.007535702083259821,
    0.0011758849723264575,
    -0.004563724156469107,
    -0.03002808801829815,
    0.03441614657640457,
    0.015042724087834358,
    0.022972777485847473,
    -0.02011910453438759,
    0.008345915004611015,
    0.004850525408983231,
    0.0018803405109792948,
    0.021022528409957886,
    -0.011386008001863956,
    -0.04783844202756882,
    0.0007577826036140323,
    0.019602863118052483,
    -0.01554462593048811,
    -0.0004172061453573406,
    -0.002235257066786289,
    -0.01036069355905056,
    -0.0030490553472191095,
    -0.008288554847240448,
    -0.02113725058734417,
    -0.004327113274484873,
    0.02242785505950451,
    0.01469856221228838,
    0.00575753441080451,
    0.0008241054019890726,
    0.008310065604746342,
    -0.03212173655629158,
    -0.01331474632024765,
    -0.01258340384811163,
    -0.021839912980794907,
    -0.01604652777314186,
    0.0262136310338974,
    -0.038574762642383575,
    0.00744966184720397,
    -0.002111573936417699,
    0.0031942485366016626,
    -0.015731045976281166,
    -0.0017127409810200334,
    -0.00994483195245266,
    0.02495170570909977,
    0.00804477371275425,
    0.008898007683455944,
    0.017079012468457222,
    -0.005614134017378092,
    -0.027791038155555725,
    -0.023804500699043274,
    -0.0011274872813373804,
    0.016648810356855392,
    0.01086976658552885,
    0.014913663268089294,
    -0.017896395176649094,
    0.03106057271361351,
    0.021940292790532112,
    0.003147643292322755,
    0.005653569009155035,
    0.02512378618121147,
    -0.01712203212082386,
    -0.008632716722786427,
    0.010260313749313354,
    0.00040645108674652874,
    -0.013372106477618217,
    -0.02152443118393421,
    -0.023761481046676636,
    -0.027590276673436165,
    0.027002334594726562,
    0.001729769865050912,
    -0.002206576755270362,
    -0.028178218752145767,
    -0.01238264236599207,
    -0.009636521339416504,
    0.020448926836252213,
    -0.018254896625876427,
    -0.0011382423108443618,
    -0.010453904047608376,
    -0.03108925186097622,
    0.005277142394334078,
    -0.026901954784989357,
    0.003549165092408657,
    0.03002808801829815,
    -0.004639009479433298,
    0.017050331458449364,
    -0.027332156896591187,
    0.005076381377875805,
    -0.05366050824522972,
    0.03106057271361351,
    -0.013027945533394814,
    -0.02069270797073841,
    -0.012009801343083382,
    -0.03659583628177643,
    -0.0025614933110773563,
    0.03002808801829815,
    0.01004521269351244,
    -0.02075006812810898,
    0.021022528409957886,
    0.003031130414456129,
    7.3436793172732e-05,
    0.003131510689854622,
    -0.0012269715080037713,
    0.017021652311086655,
    -0.04815392568707466,
    0.001995061058551073,
    0.02855106070637703,
    0.03381386399269104,
    0.0002457975933793932,
    0.013866838999092579,
    -0.018527358770370483,
    0.017839035019278526,
    -0.020190805196762085,
    0.013372106477618217,
    -0.0022047844249755144,
    0.021180270239710808,
    -0.016376350075006485,
    0.01152940932661295,
    0.01818319782614708,
    -0.0015854729572311044,
    -0.005115816835314035,
    0.015802746638655663,
    0.0125690633431077,
    0.020033065229654312,
    0.03762831911444664,
    -0.005689419340342283,
    -0.027131395414471626,
    -0.02707403525710106,
    0.009571990929543972,
    0.006549822632223368,
    -0.0005099684349261224,
    0.00012805225560441613,
    0.018326597288250923,
    -0.03146209195256233,
    -0.03825928270816803,
    -0.03450218588113785,
    -0.010016532614827156,
    0.033928584307432175,
    0.006750583648681641,
    0.01436874084174633,
    -0.02556832879781723,
    -0.0041335225105285645,
    0.007273995783179998,
    -0.0018767555011436343,
    0.008854988031089306,
    -0.00251130317337811,
    0.004420323763042688,
    -0.012289431877434254,
    -0.02132366970181465,
    0.025080766528844833,
    -0.0002968840708490461,
    -0.029139002785086632,
    0.010991656221449375,
    0.01013125292956829,
    0.012074330821633339,
    -0.024421123787760735,
    0.01776733621954918,
    0.00438447343185544,
    0.0313473716378212,
    -0.005979805253446102,
    0.05024757236242294,
    -0.02976996637880802,
    0.029067303985357285,
    0.004549384117126465,
    0.030945850536227226,
    -0.013235876336693764,
    0.029913367703557014,
    0.02979864738881588,
    -0.01604652777314186,
    0.004072577226907015,
    -0.00686171930283308,
    -0.026959314942359924,
    -0.0075141917914152145,
    0.019143981859087944,
    -0.0029594299849122763,
    -0.002807067008689046,
    0.012920394539833069,
    -0.008639886975288391,
    0.008639886975288391,
    0.0019036431331187487,
    0.0013524469686672091,
    -0.010661834850907326,
    -0.006323966663330793,
    0.03650979325175285,
    0.0009428589837625623,
    0.007707782555371523,
    0.009787091985344887,
    -0.03473162651062012,
    -0.008310065604746342,
    -0.023187877610325813,
    -0.02367543987929821,
    0.019947024062275887,
    0.0039614420384168625,
    -0.026127591729164124,
    0.03321158140897751,
    -0.033699143677949905,
    0.02855106070637703,
    0.0037606810219585896,
    0.03564939275383949,
    0.039406485855579376,
    -0.0012690953444689512,
    0.011063356883823872,
    -0.010532774962484837,
    -0.04497043043375015,
    0.009679540991783142,
    -0.014770262874662876,
    0.015372545458376408,
    -0.030917171388864517,
    -0.03762831911444664,
    0.021481411531567574,
    -0.005413373000919819,
    0.004201638046652079,
    0.008188175037503242,
    0.0037104906514286995,
    -0.0065964278765022755,
    -0.0029432973824441433,
    -0.0005243084742687643,
    -0.007180785294622183,
    0.02744687721133232,
    -0.023618079721927643,
    -0.004079747479408979,
    -0.023402979597449303,
    -0.0039650266990065575,
    0.02113725058734417,
    -0.015171783976256847,
    -0.019703242927789688,
    0.03272401914000511,
    -0.008898007683455944,
    -0.026987994089722633,
    0.0005153459496796131,
    0.029856007546186447,
    -0.029970727860927582,
    0.016362009570002556,
    -0.0015800955006852746,
    0.007679102476686239,
    -0.023747140541672707,
    0.03576411306858063,
    -0.00016513477021362633,
    0.015558966435492039,
    0.026557791978120804,
    0.04009481146931648,
    0.006797188892960548,
    -0.0043020183220505714,
    -0.010496924631297588,
    -0.013874009251594543,
    -0.0031153783202171326,
    0.04984605312347412,
    0.030917171388864517,
    -0.03083113022148609,
    0.0020595912355929613,
    -0.034559547901153564,
    -0.025080766528844833,
    -0.01002370286732912,
    0.00824553519487381,
    0.01213886123150587,
    -0.015716707333922386,
    -0.009901812300086021,
    0.0009733316255733371,
    0.007693442516028881,
    0.010640325024724007,
    -0.005140911787748337,
    0.011213927529752254,
    -0.0031960410997271538,
    0.0007595751085318625,
    -0.011730169877409935,
    0.0025847959332168102,
    -0.0038072862662374973,
    -0.0013210781617090106,
    0.023790160194039345,
    -0.016318989917635918,
    0.04307754337787628,
    0.013178516179323196,
    0.011314308270812035,
    -0.002079308731481433,
    -0.004481269046664238,
    -0.00496166106313467,
    0.0001265958562726155,
    -0.0019287382019683719,
    -0.0042159780859947205,
    0.04867016524076462,
    -0.010532774962484837,
    0.021395370364189148,
    -0.0014205622719600797,
    0.007048139814287424,
    -0.002470075385645032,
    0.02195463329553604,
    0.014641202054917812,
    0.020577987655997276,
    -0.0020846864208579063,
    -0.015946147963404655,
    0.013357766903936863,
    -0.017709976062178612,
    -0.016405029222369194,
    -0.0069513446651399136,
    -0.022026333957910538,
    0.0021958218421787024,
    0.02201199345290661,
    0.01966022327542305,
    -0.05810592696070671,
    0.007887033745646477,
    0.03215041756629944,
    0.010059552267193794,
    -0.007844013161957264,
    -0.02751857601106167,
    0.017394494265317917,
    -0.015917466953396797,
    -0.006298871710896492,
    -0.03212173655629158,
    -0.0037284158170223236,
    -0.0006574021535925567,
    -0.00047232574434019625,
    -0.01736581325531006,
    -0.018068477511405945,
    0.02280069701373577,
    -0.033899903297424316,
    0.011285628192126751,
    -0.030773770064115524,
    -0.026500431820750237,
    -0.013092475943267345,
    0.004004462156444788,
    0.04585951566696167,
    -0.010396543890237808,
    0.008001754060387611,
    -0.002378657693043351,
    0.013386446982622147,
    0.023962242528796196,
    -0.007994583807885647,
    0.004212392959743738,
    -0.02052062749862671,
    -0.052714064717292786,
    -0.01669183000922203,
    -0.01963154412806034,
    0.02386186085641384,
    -0.018857179209589958,
    0.0018193952273577452,
    0.00942142028361559,
    0.012475852854549885,
    0.006331136915832758,
    0.015458585694432259,
    -0.013185686431825161,
    -0.000395471986848861,
    0.018885860219597816,
    0.011629789136350155,
    0.004273338243365288,
    0.0262136310338974,
    -0.036050911992788315,
    0.0010934296296909451,
    -0.021911613643169403,
    0.012160371989011765,
    -0.0016365594929084182,
    -0.0037678510416299105,
    -0.012016970664262772,
    0.023804500699043274,
    -0.02216973342001438,
    -0.024693584069609642,
    -0.012561893090605736,
    0.0060013155452907085,
    0.0034469920210540295,
    -0.005320162512362003,
    0.01733713410794735,
    0.01320719625800848,
    -0.0018301502568647265,
    -0.0018642079085111618,
    0.014411761425435543,
    -0.004305603448301554,
    -0.01056145504117012,
    0.004699954763054848,
    -0.027002334594726562,
    0.021710852161049843,
    0.02533888816833496,
    -0.018943220376968384,
    0.028278600424528122,
    0.0259698498994112,
    -0.006320382002741098,
    -0.03914836794137955,
    0.017021652311086655,
    0.02115158922970295,
    0.019316062331199646,
    -0.00543846795335412,
    -0.049731332808732986,
    -0.016591450199484825,
    -0.006445857230573893,
    -0.012748314067721367,
    0.0023481850512325764,
    -0.021467071026563644,
    -0.0016338706482201815,
    -0.02870880253612995,
    0.008998388424515724,
    0.016362009570002556,
    -0.002518473193049431,
    -0.0038574764039367437,
    -0.028995603322982788,
    -0.013450977392494678,
    -0.006972854491323233,
    0.017193732783198357,
    0.01964588277041912,
    -0.003101038048043847,
    -0.015702366828918457,
    -0.03737019747495651,
    -0.01099882647395134,
    -0.016878250986337662,
    0.016734851524233818,
    0.016634469851851463,
    0.0034720872063189745,
    0.0126909539103508,
    0.031232653185725212,
    0.054234109818935394,
    0.014913663268089294,
    0.008668567053973675,
    0.017007311806082726,
    -0.03157681226730347,
    0.012310942634940147,
    0.009442930109798908,
    0.006786433979868889,
    -0.003461332293227315,
    -0.0036567156203091145,
    0.012325282208621502,
    0.017595253884792328,
    0.003149435855448246,
    -0.0423031784594059,
    0.013995899818837643,
    0.012167541310191154,
    -0.009191978722810745,
    -0.014928003773093224,
    -0.028866542503237724,
    -0.021266309544444084,
    -0.01818319782614708,
    0.0020560063421726227,
    0.0005700174369849265,
    0.022944096475839615,
    -0.04250394180417061,
    0.0007483719382435083,
    0.03324026241898537,
    0.004603159613907337,
    0.03696867823600769,
    0.020362885668873787,
    0.018742458894848824,
    -0.0017584499437361956,
    0.027834057807922363,
    0.02979864738881588,
    0.018728120252490044,
    -0.014476291835308075,
    -0.00713059538975358,
    -0.039664607495069504,
    -0.005151666700839996,
    0.0017521762056276202,
    0.00687247421592474,
    0.014533651992678642,
    0.000728206243366003,
    0.01796809583902359,
    -0.008955367840826511,
    0.02850804105401039,
    -0.005449223332107067,
    -0.011127887293696404,
    0.01607520878314972,
    -0.02999940700829029,
    0.011299967765808105,
    -0.02999940700829029,
    -0.02072138711810112,
    -0.03493238985538483,
    -0.0026815913151949644,
    0.013945708982646465,
    -0.006775678601115942,
    0.010604474693536758,
    -0.018441317602992058,
    -0.008811967447400093,
    0.023732800036668777,
    0.004976001102477312,
    0.03215041756629944,
    0.002342807361856103,
    0.029540525749325752,
    -0.005284312646836042,
    0.003911251667886972,
    0.015530286356806755,
    -0.03874684497714043,
    -0.0030813205521553755,
    -0.022972777485847473,
    0.016189929097890854,
    0.014325721189379692,
    -0.01756657473742962,
    -0.009278018958866596,
    0.01752355508506298,
    -0.003165568457916379,
    -0.02324523776769638,
    -0.024650564417243004,
    0.03381386399269104,
    0.016878250986337662,
    0.007230975665152073,
    -0.04261866211891174,
    -0.02492302656173706,
    -0.004979586228728294,
    0.004954490810632706,
    -0.013888348825275898,
    -0.006582087837159634,
    0.02492302656173706,
    -0.022356154397130013,
    0.001866000471636653,
    0.012906054966151714,
    0.022083694115281105,
    0.02665817365050316,
    -0.007786653004586697,
    0.02050628699362278,
    0.009794261306524277,
    -0.004198052920401096,
    -0.008381765335798264,
    -0.010009362362325191,
    0.010590135119855404,
    0.01649107038974762,
    -0.0025704558938741684,
    0.005513753276318312,
    0.05776176601648331,
    0.0023553550709038973,
    -0.007951564155519009,
    -0.00047591078327968717,
    0.008604036644101143,
    0.029942046850919724,
    -0.03338366001844406,
    0.0156736858189106,
    -0.00907725840806961,
    -0.0024664904922246933,
    0.03564939275383949,
    -0.01383098866790533,
    -0.004893545992672443,
    -0.011271287687122822,
    0.016820890828967094,
    0.004918640945106745,
    0.016777871176600456,
    -0.02558266930282116,
    -0.01153657864779234,
    0.02095082961022854,
    0.01511442381888628,
    0.0041335225105285645,
    -0.00330717652104795,
    0.0019179831724613905,
    0.018513018265366554,
    -0.02956920489668846,
    -0.009306699968874454,
    -0.012475852854549885,
    -0.015515945851802826,
    -0.0236467607319355,
    0.020133445039391518,
    0.003126133233308792,
    -0.004312773235142231,
    0.042417898774147034,
    -0.0160895474255085,
    0.021925952285528183,
    0.008697247132658958,
    0.021639151498675346,
    -0.02115158922970295,
    0.03461690619587898,
    -0.010138423182070255,
    0.029339764267206192,
    0.01331474632024765,
    0.005309407599270344,
    -0.023990921676158905,
    -0.01753789372742176,
    0.018025455996394157,
    0.00018821329285856336,
    0.0036029403563588858,
    -0.02896692231297493,
    -0.008152324706315994,
    0.022671636193990707,
    -0.004029557108879089,
    -0.02470792457461357,
    -0.0009446514886803925,
    -0.00994483195245266,
    -0.011142226867377758,
    0.007965903729200363,
    -0.0025812110397964716,
    -0.005162422079592943,
    0.007994583807885647,
    -0.03281005844473839,
    0.006470952648669481,
    0.012848694808781147,
    -0.04250394180417061,
    -0.008281385526061058,
    -0.006657373160123825,
    0.0018095364794135094,
    -0.014985363930463791,
    0.02027684636414051,
    0.018685098737478256,
    -0.02133801020681858,
    -0.02450716495513916,
    0.01512876432389021,
    0.015057063661515713,
    -0.01666315086185932,
    0.009586330503225327,
    0.0006305145798251033,
    0.02113725058734417,
    0.026758553460240364,
    -0.012346792034804821,
    2.6705562049755827e-05,
    -0.013458146713674068,
    0.012891714461147785,
    -0.0268732737749815,
    -0.04058237373828888,
    -0.0037570958957076073,
    0.056327760219573975,
    0.004929395858198404,
    -0.024650564417243004,
    -0.009313869290053844,
    -0.024865666404366493,
    -0.023302599787712097,
    0.006883229129016399,
    -0.010174273513257504,
    0.018971901386976242,
    -0.014813282527029514,
    0.013802308589220047,
    0.011221097782254219,
    0.01544424518942833,
    0.014139300212264061,
    0.02493736520409584,
    0.0001521390804555267,
    0.025826450437307358,
    0.006585672963410616,
    0.010188613086938858,
    -0.012246412225067616,
    -0.039033643901348114,
    -0.043421704322099686,
    -0.005266387481242418,
    0.002470075385645032,
    0.02132366970181465,
    0.0026098911184817553,
    -0.005402618087828159,
    0.013013605028390884,
    -0.00907725840806961,
    -0.009873132221400738,
    0.006549822632223368,
    -0.015286505222320557,
    0.009571990929543972,
    0.02976996637880802,
    -0.05119401589035988,
    -0.02368978038430214,
    -0.005047701299190521,
    0.00064754334744066,
    0.001773686264641583,
    -4.5092769141774625e-05,
    -0.002136669121682644,
    0.00019627957954071462,
    -0.012160371989011765,
    -0.007621742319315672,
    0.008926687762141228,
    -0.00971539132297039,
    0.002464697929099202,
    0.015788406133651733,
    -0.007542871870100498,
    0.013737778179347515,
    0.03817324340343475,
    0.014985363930463791,
    -0.005879424978047609,
    -8.043878187891096e-05,
    0.012411322444677353,
    -0.020807428285479546,
    -0.02370412088930607,
    0.04792448505759239,
    -0.03929176554083824,
    0.010518434457480907,
    0.01564500667154789,
    0.016835231333971024,
    0.013070965185761452,
    0.00045977820991538465,
    0.004198052920401096,
    -0.024865666404366493,
    -0.019731923937797546,
    -0.0122750923037529,
    -0.00369973573833704,
    -0.004846940748393536,
    0.008847817778587341,
    0.010274653322994709,
    -0.003402179339900613,
    0.002527435775846243,
    -0.032838739454746246,
    0.020004384219646454,
    -0.042589981108903885,
    0.012117351405322552,
    0.001583680510520935,
    -0.030573010444641113,
    -0.026916293427348137,
    -0.006148301064968109,
    0.008568186312913895,
    0.014519311487674713,
    0.014375911094248295,
    0.21682171523571014,
    -0.00733852619305253,
    0.017652614042162895,
    0.01428270060569048,
    -0.00528072752058506,
    0.01733713410794735,
    0.0051337420009076595,
    0.021596131846308708,
    -0.015759726986289024,
    0.018527358770370483,
    0.008360255509614944,
    0.005653569009155035,
    -0.010238803923130035,
    -0.009744071401655674,
    0.008417615666985512,
    0.004968831315636635,
    -0.02195463329553604,
    -0.022270115092396736,
    -0.016218608245253563,
    0.02410564199090004,
    0.017580915242433548,
    -0.010504094883799553,
    -0.01924436166882515,
    -0.025697389617562294,
    0.019545502960681915,
    -0.014519311487674713,
    -0.007392301224172115,
    -0.0027048939373344183,
    0.0039040816482156515,
    0.0036154878325760365,
    0.0003002450102940202,
    -0.0065928432159125805,
    -0.020233826711773872,
    -6.436222611228004e-05,
    -0.01841263845562935,
    -0.012318111956119537,
    0.007535702083259821,
    -0.009278018958866596,
    0.011400348506867886,
    0.04267602041363716,
    0.023503359407186508,
    -0.011794700287282467,
    0.00125296285841614,
    -0.032838739454746246,
    -0.029856007546186447,
    -0.026299672201275826,
    -0.014476291835308075,
    0.002726403996348381,
    -0.012913225218653679,
    0.006567747797816992,
    -0.01712203212082386,
    -0.020606666803359985,
    0.016849571838974953,
    0.006187736056745052,
    -0.02750423736870289,
    -0.002613476011902094,
    -0.008711586706340313,
    0.021925952285528183,
    0.022757677361369133,
    0.012282262556254864,
    -0.025009065866470337,
    0.018054137006402016,
    0.012396982870995998,
    -0.0031117931939661503,
    -0.04221713915467262,
    0.00481467554345727,
    -0.022141054272651672,
    0.012002631090581417,
    -0.01152940932661295,
    0.006273776758462191,
    -0.022069353610277176,
    -0.007248900830745697,
    -0.01988966390490532,
    -0.013293236494064331,
    -0.015774067491292953,
    -0.035419952124357224,
    0.0019825133495032787,
    -0.008410445414483547,
    0.01004521269351244,
    0.04170089587569237,
    0.004617499653249979,
    0.001896472997032106,
    0.009005558677017689,
    0.01606086827814579,
    -0.024421123787760735,
    -0.007707782555371523,
    0.017796015366911888,
    -0.0217395331710577,
    0.006729073356837034,
    -0.029210703447461128,
    0.0017718938179314137,
    -0.027733677998185158,
    0.013271726667881012,
    0.004549384117126465,
    -0.004241073038429022,
    0.0019807210192084312,
    -0.010625985451042652,
    0.012576233595609665,
    -0.002486207988113165,
    0.00793722365051508,
    -0.031146612018346786,
    0.02300145849585533,
    0.013221535831689835,
    0.003789361100643873,
    -0.015257825143635273,
    0.005101476795971394,
    -0.00428767828270793,
    0.013658908195793629,
    -0.010855426080524921,
    -0.03782907873392105,
    -0.024636223912239075,
    -0.029511844739317894,
    0.012597743421792984,
    -0.025095107033848763,
    0.013859668746590614,
    0.005506583489477634,
    -0.0038897416088730097,
    0.0020631763618439436,
    0.015143103897571564,
    -0.018097156658768654,
    -0.008008924312889576,
    -0.014347231015563011,
    0.006047920789569616,
    -0.021251970902085304,
    -0.023818841204047203,
    -0.019990045577287674,
    -0.008016093634068966,
    0.0048827906139194965,
    -0.005065626464784145,
    0.005194687284529209,
    0.014827623032033443,
    -0.0277049969881773,
    0.012167541310191154,
    -0.0262136310338974,
    0.008811967447400093,
    0.004251827951520681,
    -0.00802326388657093,
    -0.016792211681604385,
    -0.004172957502305508,
    0.0006430621142499149,
    -0.009952002204954624,
    -0.004423908889293671,
    0.013967219740152359,
    -0.020233826711773872,
    -0.0003777709789574146,
    -0.016949951648712158,
    0.010798065923154354,
    0.006356231868267059,
    0.0117373401299119,
    -0.016405029222369194,
    -0.004825430456548929,
    -0.00045820974628441036,
    0.01403891947120428,
    -0.025080766528844833,
    0.004008046817034483,
    -0.010504094883799553,
    -0.011579599231481552,
    -0.010747876018285751,
    0.02976996637880802,
    -0.004262582864612341,
    -0.028694462031126022,
    -0.00765759265050292,
    0.01756657473742962,
    0.015028383582830429,
    -0.024650564417243004,
    -0.03324026241898537,
    -0.1825203001499176,
    0.015917466953396797,
    0.014110620133578777,
    -0.014311380684375763,
    0.03430142626166344,
    0.004488438833504915,
    0.022528234869241714,
    0.024005262181162834,
    -0.0268732737749815,
    0.0008778806077316403,
    -0.0002592414093669504,
    -0.0077149528078734875,
    -0.013157005421817303,
    -0.025252847000956535,
    -0.02092214860022068,
    -0.0038933265022933483,
    -0.04614631459116936,
    0.023933561518788338,
    0.033928584307432175,
    0.02962656505405903,
    0.019975705072283745,
    -0.03461690619587898,
    0.0028178219217807055,
    0.017910735681653023,
    -0.007564382161945105,
    -0.039406485855579376,
    -0.003149435855448246,
    -0.008252705447375774,
    0.016376350075006485,
    -0.025525309145450592,
    -0.004789580125361681,
    -0.007901373319327831,
    0.03576411306858063,
    -0.023402979597449303,
    0.023818841204047203,
    0.014841962605714798,
    0.030544329434633255,
    -0.017380153760313988,
    -0.030716409906744957,
    0.019588522613048553,
    0.025640029460191727,
    0.047895804047584534,
    -0.000550299824681133,
    -0.002143839141353965,
    -0.00942142028361559,
    0.022685976698994637,
    -0.0036961506120860577,
    -0.024578863754868507,
    0.0037499258760362864,
    -0.005714514292776585,
    0.059081051498651505,
    -0.010618815198540688,
    0.004563724156469107,
    0.004194467794150114,
    -0.0002601376618258655,
    0.014741582795977592,
    0.010862596333026886,
    -0.005316577386111021,
    0.02769065834581852,
    -0.009206319227814674,
    0.004818260669708252,
    -0.01047541480511427,
    0.030716409906744957,
    0.008618376217782497,
    -0.02116592973470688,
    -0.02598419040441513,
    -0.0034989749547094107,
    0.023560719564557076,
    -0.013185686431825161,
    0.012440002523362637,
    0.0073241861537098885,
    0.008876497857272625,
    -0.014841962605714798,
    0.006657373160123825,
    0.007994583807885647,
    0.0077149528078734875,
    -0.012167541310191154,
    0.008998388424515724,
    0.03332630172371864,
    -0.0020775164011865854,
    -0.010202953591942787,
    0.04502779245376587,
    -0.00909159891307354,
    0.0053380876779556274,
    -0.016849571838974953,
    -2.3624690584256314e-05,
    0.008388935588300228,
    0.016132568940520287,
    -0.05036229267716408,
    -0.0011857438366860151,
    0.036481115967035294,
    -0.010217293165624142,
    -0.011371668428182602,
    -0.0039040816482156515,
    -0.005384692922234535,
    0.01607520878314972,
    0.028063498437404633,
    -0.009787091985344887,
    0.0029164098668843508,
    -0.006248681340366602,
    0.004567309282720089,
    0.017035992816090584,
    -0.01689259149134159,
    0.008718756958842278,
    0.021897273138165474,
    0.025209827348589897,
    -0.030773770064115524,
    0.009593500755727291,
    0.03739887848496437,
    -0.005377522669732571,
    0.010919956490397453,
    -0.005714514292776585,
    0.01920134201645851,
    0.03438746556639671,
    0.0024306403938680887,
    0.015257825143635273,
    0.010281823575496674,
    -0.013422297313809395,
    0.009493120014667511,
    0.010826746001839638,
    0.040066130459308624,
    -0.003411141922697425,
    -0.004520704038441181,
    0.027977459132671356,
    -0.0052735572680830956,
    -0.015372545458376408,
    -0.11718697845935822,
    -0.045744795352220535,
    0.030573010444641113,
    0.006499632727354765,
    -0.006621523294597864,
    0.00629528658464551,
    -0.023388639092445374,
    0.026514772325754166,
    -0.025410586968064308,
    0.0228150375187397,
    -0.003939931746572256,
    -0.013558527454733849,
    -0.011995460838079453,
    0.01838395744562149,
    -0.01583142764866352,
    -0.015200464986264706,
    -0.014712902717292309,
    -0.005287897307425737,
    -0.008711586706340313,
    0.014096279628574848,
    -0.012848694808781147,
    -0.011687149293720722,
    0.01925870217382908,
    -0.016132568940520287,
    -0.019316062331199646,
    -0.014289870858192444,
    -0.0409838929772377,
    0.014669882133603096,
    -0.006220001261681318,
    0.02031986601650715,
    0.020879128947854042,
    -0.021510090678930283,
    -0.00047367013758048415,
    -0.0036047326866537333,
    0.022987117990851402,
    -0.014304210431873798,
    -0.00760740227997303,
    -0.009571990929543972,
    0.027403855696320534,
    -0.022126713767647743,
    0.0023069572634994984,
    -0.00017981091514229774,
    -0.019402101635932922,
    0.00029419531347230077,
    -0.0013569282600656152,
    0.008740266785025597,
    -0.022585595026612282,
    0.044282108545303345,
    0.01142902858555317,
    -0.022786356508731842,
    -0.020377226173877716,
    -0.004789580125361681,
    0.007944393903017044,
    -0.00350972986780107,
    0.008632716722786427,
    -0.04058237373828888,
    0.02982732653617859,
    0.004825430456548929,
    -0.029942046850919724,
    -0.026916293427348137,
    -0.0004178783274255693,
    0.00812364462763071,
    0.012683783657848835,
    0.016863912343978882,
    -0.005384692922234535,
    -0.01798243634402752,
    -0.017437513917684555,
    -0.0034577471669763327,
    0.005682249087840319,
    -0.015200464986264706,
    -0.0274612158536911,
    0.00034304114524275064,
    -0.008310065604746342,
    0.03341234102845192,
    -0.03722679987549782,
    -0.011386008001863956,
    -0.023962242528796196,
    -0.008051943965256214,
    0.005635643843561411,
    0.03656715527176857,
    -0.03045829012989998,
    0.00042504837620072067,
    -0.018771139904856682,
    -0.01205282099545002,
    0.023130517452955246,
    0.0017369398847222328,
    0.004592404700815678,
    -0.008482146076858044,
    0.008546676486730576,
    -0.0426473394036293,
    0.01776733621954918,
    0.012224901467561722,
    0.04795316234230995,
    0.011952441185712814,
    -0.02093648910522461,
    -0.008568186312913895,
    -0.006108866073191166,
    -0.010833916254341602,
    -0.028020478785037994,
    0.014641202054917812,
    -0.027934439480304718,
    0.004958075936883688,
    -0.07290486991405487,
    0.01920134201645851,
    0.017695635557174683,
    -0.008396105840802193,
    0.008797626942396164,
    -0.02870880253612995,
    -0.009744071401655674,
    -0.012081501074135303,
    0.01752355508506298,
    -0.009342549368739128,
    -0.03493238985538483,
    -0.003681810572743416,
    -0.004832600709050894,
    -0.016849571838974953,
    -0.021294990554451942,
    -0.018943220376968384,
    0.03146209195256233,
    -0.01511442381888628,
    0.02558266930282116,
    -0.0016123605892062187,
    0.00449560908600688,
    0.0016957122134044766,
    0.0341867059469223,
    -0.004456174094229937,
    -0.03547731041908264,
    -0.0008299309993162751,
    0.006786433979868889,
    0.029139002785086632,
    -0.004846940748393536,
    -0.021180270239710808,
    0.015200464986264706,
    -0.0011489973403513432,
    -0.012526042759418488,
    0.021065549924969673,
    -0.0005511961062438786,
    -0.02493736520409584,
    0.01581708714365959,
    0.003310761647298932,
    0.013866838999092579,
    -0.008109304122626781,
    0.0020398737397044897,
    -0.029655246064066887,
    0.012891714461147785,
    0.01651974953711033,
    -0.0009419627604074776,
    -0.00765759265050292,
    0.013580037280917168,
    -0.03189229592680931,
    0.03527655079960823,
    0.02665817365050316,
    0.044913072139024734,
    -0.0015397639945149422,
    -0.0232308991253376,
    -0.017638275399804115,
    -0.010317673906683922,
    -0.033469703048467636,
    0.0036477530375123024,
    -0.007958733476698399,
    -0.005657154135406017,
    0.001135553582571447,
    0.03186361491680145,
    -0.009184809401631355,
    0.019990045577287674,
    -0.002703101374208927,
    0.014985363930463791,
    0.0011893288465216756,
    -0.03825928270816803,
    -0.0073241861537098885,
    0.005990560632199049,
    -0.013687588274478912,
    0.008747437037527561,
    -0.005413373000919819,
    0.008467805571854115,
    -0.012045650742948055,
    0.010274653322994709,
    -0.008109304122626781,
    0.008403276093304157,
    -0.016003508120775223,
    -0.03504711017012596,
    0.040496330708265305,
    0.00654265284538269,
    -0.029511844739317894,
    -0.03197833523154259,
    0.012346792034804821,
    0.01277699414640665,
    0.01670617051422596,
    -0.044081348925828934,
    -0.0053918627090752125,
    -0.01710769347846508,
    0.012009801343083382,
    -0.024994725361466408,
    -0.007528531830757856,
    -0.004011631943285465,
    -9.847588808042929e-05,
    0.016878250986337662,
    -0.0002626023779157549,
    0.0042195627465844154,
    0.01056145504117012,
    0.008238364942371845,
    0.01857037842273712,
    0.008267045021057129,
    0.004054652061313391,
    0.007757972925901413,
    -0.019359081983566284,
    -0.026127591729164124,
    -0.007051724940538406,
    0.014440441504120827,
    -0.01564500667154789,
    -0.008826307021081448,
    0.010016532614827156,
    0.002726403996348381,
    -0.025883810594677925,
    -0.004291263408958912,
    0.02138102985918522,
    -0.00364416791126132,
    0.016032187268137932,
    0.0038861564826220274,
    -0.02242785505950451,
    -0.024435464292764664,
    0.013027945533394814,
    0.02789141796529293,
    0.012755484320223331,
    0.032179094851017,
    0.004653349984437227,
    0.026084570214152336,
    0.04981737211346626,
    0.02006174437701702,
    -0.004664104897528887,
    0.011443368159234524,
    0.0069513446651399136,
    0.002998865209519863,
    0.009256509132683277,
    0.0007232768111862242,
    -0.030114127323031425,
    -0.0034075570292770863,
    -0.00814515445381403,
    0.0012798504903912544,
    -0.0022460119798779488,
    0.0011821587104350328,
    0.08747436851263046,
    -0.004008046817034483,
    -0.018556037917733192,
    -0.007757972925901413,
    -0.014971023425459862,
    0.013752118684351444,
    0.0008707105880603194,
    -0.006915494333952665,
    -0.018928879871964455,
    -0.015372545458376408,
    -0.0058328197337687016,
    0.010181442834436893,
    -0.01987532526254654,
    -0.02386186085641384,
    -0.026744212955236435,
    -0.0014178735436871648,
    0.01108486671000719,
    0.025009065866470337,
    -0.008417615666985512,
    -0.0051695918664336205,
    0.027389517053961754,
    0.013529847376048565,
    0.0038825715892016888,
    -0.015688026323914528,
    -0.03450218588113785,
    -0.01213886123150587,
    0.02556832879781723,
    0.028637101873755455,
    -0.0010934296296909451,
    -0.05173894017934799,
    0.011063356883823872,
    -0.018756799399852753,
    -0.008016093634068966,
    -0.03407198563218117,
    0.0012816429371014237,
    0.019273042678833008,
    -0.012024140916764736,
    0.001882132957689464,
    -0.00045933006913401186,
    0.01796809583902359,
    -0.006775678601115942,
    0.004789580125361681,
    -0.021940292790532112,
    -0.022929757833480835,
    0.0268732737749815,
    0.0011848475551232696,
    0.015300844796001911,
    -0.0005417854408733547,
    -0.056098319590091705
  ]
}