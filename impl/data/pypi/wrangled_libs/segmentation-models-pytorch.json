{
  "classifiers": [
    "license :: osi approved :: mit license",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: implementation :: cpython",
    "programming language :: python :: implementation :: pypy"
  ],
  "description": "image segmentation models with pre-trained backbones. pytorch.\n\n<div align=\"center\">\n\n![logo](https://i.ibb.co/dc1xdht/segmentation-models-v2-side-1-1.png)  \n**python library with neural networks for image  \nsegmentation based on [pytorch](https://pytorch.org/).**  \n\n[![generic badge](https://img.shields.io/badge/license-mit-<color>.svg?style=for-the-badge)](https://github.com/qubvel/segmentation_models.pytorch/blob/master/license) \n[![github workflow status (branch)](https://img.shields.io/github/actions/workflow/status/qubvel/segmentation_models.pytorch/tests.yml?branch=master&style=for-the-badge)](https://github.com/qubvel/segmentation_models.pytorch/actions/workflows/tests.yml) \n[![read the docs](https://img.shields.io/readthedocs/smp?style=for-the-badge&logo=readthedocs&logocolor=white)](https://smp.readthedocs.io/en/latest/) \n<br>\n[![pypi](https://img.shields.io/pypi/v/segmentation-models-pytorch?color=blue&style=for-the-badge&logo=pypi&logocolor=white)](https://pypi.org/project/segmentation-models-pytorch/) \n[![pypi - downloads](https://img.shields.io/pypi/dm/segmentation-models-pytorch?style=for-the-badge&color=blue)](https://pepy.tech/project/segmentation-models-pytorch) \n<br>\n[![pytorch - version](https://img.shields.io/badge/pytorch-1.4+-red?style=for-the-badge&logo=pytorch)](https://pepy.tech/project/segmentation-models-pytorch) \n[![python - version](https://img.shields.io/badge/python-3.7+-red?style=for-the-badge&logo=python&logocolor=white)](https://pepy.tech/project/segmentation-models-pytorch) \n\n</div>\n\nthe main features of this library are:\n\n - high level api (just two lines to create a neural network)\n - 9 models architectures for binary and multi class segmentation (including legendary unet)\n - 124 available encoders (and 500+ encoders from [timm](https://github.com/rwightman/pytorch-image-models))\n - all encoders have pre-trained weights for faster and better convergence\n - popular metrics and losses for training routines\n\n### [\ud83d\udcda project documentation \ud83d\udcda](http://smp.readthedocs.io/)\n\nvisit [read the docs project page](https://smp.readthedocs.io/) or read following readme to know more about segmentation models pytorch (smp for short) library\n\n### \ud83d\udccb table of content\n 1. [quick start](#start)\n 2. [examples](#examples)\n 3. [models](#models)\n    1. [architectures](#architectures)\n    2. [encoders](#encoders)\n    3. [timm encoders](#timm)\n 4. [models api](#api)\n    1. [input channels](#input-channels)\n    2. [auxiliary classification output](#auxiliary-classification-output)\n    3. [depth](#depth)\n 5. [installation](#installation)\n 6. [competitions won with the library](#competitions-won-with-the-library)\n 7. [contributing](#contributing)\n 8. [citing](#citing)\n 9. [license](#license)\n\n### \u23f3 quick start <a name=\"start\"></a>\n\n#### 1. create your first segmentation model with smp\n\nsegmentation model is just a pytorch nn.module, which can be created as easy as:\n\n```python\nimport segmentation_models_pytorch as smp\n\nmodel = smp.unet(\n    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for rgb, etc.)\n    classes=3,                      # model output channels (number of classes in your dataset)\n)\n```\n - see [table](#architectures) with available model architectures\n - see [table](#encoders) with available encoders and their corresponding weights\n\n#### 2. configure data preprocessing\n\nall encoders have pretrained weights. preparing your data the same way as during weights pre-training may give you better results (higher metric score and faster convergence). it is **not necessary** in case you train the whole model, not only decoder.\n\n```python\nfrom segmentation_models_pytorch.encoders import get_preprocessing_fn\n\npreprocess_input = get_preprocessing_fn('resnet18', pretrained='imagenet')\n```\n\ncongratulations! you are done! now you can train your model with your favorite framework!\n\n### \ud83d\udca1 examples <a name=\"examples\"></a>\n - training model for pets binary segmentation with pytorch-lightning [notebook](https://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/binary_segmentation_intro.ipynb) and [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/qubvel/segmentation_models.pytorch/blob/master/examples/binary_segmentation_intro.ipynb)\n - training model for cars segmentation on camvid dataset [here](https://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/cars%20segmentation%20(camvid).ipynb).\n - training smp model with [catalyst](https://github.com/catalyst-team/catalyst) (high-level framework for pytorch), [ttach](https://github.com/qubvel/ttach) (tta library for pytorch) and [albumentations](https://github.com/albu/albumentations) (fast image augmentation library) - [here](https://github.com/catalyst-team/catalyst/blob/v21.02rc0/examples/notebooks/segmentation-tutorial.ipynb) [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/catalyst-team/catalyst/blob/v21.02rc0/examples/notebooks/segmentation-tutorial.ipynb)\n - training smp model with [pytorch-lightning](https://pytorch-lightning.readthedocs.io) framework - [here](https://github.com/ternaus/cloths_segmentation) (clothes binary segmentation by [@ternaus](https://github.com/ternaus)).\n\n### \ud83d\udce6 models <a name=\"models\"></a>\n\n#### architectures <a name=\"architectures\"></a>\n - unet [[paper](https://arxiv.org/abs/1505.04597)] [[docs](https://smp.readthedocs.io/en/latest/models.html#unet)]\n - unet++ [[paper](https://arxiv.org/pdf/1807.10165.pdf)] [[docs](https://smp.readthedocs.io/en/latest/models.html#id2)]\n - manet [[paper](https://ieeexplore.ieee.org/abstract/document/9201310)] [[docs](https://smp.readthedocs.io/en/latest/models.html#manet)]\n - linknet [[paper](https://arxiv.org/abs/1707.03718)] [[docs](https://smp.readthedocs.io/en/latest/models.html#linknet)]\n - fpn [[paper](http://presentations.cocodataset.org/coco17-stuff-fair.pdf)] [[docs](https://smp.readthedocs.io/en/latest/models.html#fpn)]\n - pspnet [[paper](https://arxiv.org/abs/1612.01105)] [[docs](https://smp.readthedocs.io/en/latest/models.html#pspnet)]\n - pan [[paper](https://arxiv.org/abs/1805.10180)] [[docs](https://smp.readthedocs.io/en/latest/models.html#pan)]\n - deeplabv3 [[paper](https://arxiv.org/abs/1706.05587)] [[docs](https://smp.readthedocs.io/en/latest/models.html#deeplabv3)]\n - deeplabv3+ [[paper](https://arxiv.org/abs/1802.02611)] [[docs](https://smp.readthedocs.io/en/latest/models.html#id9)]\n\n#### encoders <a name=\"encoders\"></a>\n\nthe following is a list of supported encoders in the smp. select the appropriate family of encoders and click to expand the table and select a specific encoder and its pre-trained weights (`encoder_name` and `encoder_weights` parameters).\n\n<details>\n<summary style=\"margin-left: 25px;\">resnet</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|resnet18                        |imagenet / ssl / swsl           |11m                             |\n|resnet34                        |imagenet                        |21m                             |\n|resnet50                        |imagenet / ssl / swsl           |23m                             |\n|resnet101                       |imagenet                        |42m                             |\n|resnet152                       |imagenet                        |58m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">resnext</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|resnext50_32x4d                 |imagenet / ssl / swsl           |22m                             |\n|resnext101_32x4d                |ssl / swsl                      |42m                             |\n|resnext101_32x8d                |imagenet / instagram / ssl / swsl|86m                         |\n|resnext101_32x16d               |instagram / ssl / swsl          |191m                            |\n|resnext101_32x32d               |instagram                       |466m                            |\n|resnext101_32x48d               |instagram                       |826m                            |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">resnest</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|timm-resnest14d                 |imagenet                        |8m                              |\n|timm-resnest26d                 |imagenet                        |15m                             |\n|timm-resnest50d                 |imagenet                        |25m                             |\n|timm-resnest101e                |imagenet                        |46m                             |\n|timm-resnest200e                |imagenet                        |68m                             |\n|timm-resnest269e                |imagenet                        |108m                            |\n|timm-resnest50d_4s2x40d         |imagenet                        |28m                             |\n|timm-resnest50d_1s4x24d         |imagenet                        |23m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">res2ne(x)t</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|timm-res2net50_26w_4s           |imagenet                        |23m                             |\n|timm-res2net101_26w_4s          |imagenet                        |43m                             |\n|timm-res2net50_26w_6s           |imagenet                        |35m                             |\n|timm-res2net50_26w_8s           |imagenet                        |46m                             |\n|timm-res2net50_48w_2s           |imagenet                        |23m                             |\n|timm-res2net50_14w_8s           |imagenet                        |23m                             |\n|timm-res2next50                 |imagenet                        |22m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">regnet(x/y)</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|timm-regnetx_002                |imagenet                        |2m                              |\n|timm-regnetx_004                |imagenet                        |4m                              |\n|timm-regnetx_006                |imagenet                        |5m                              |\n|timm-regnetx_008                |imagenet                        |6m                              |\n|timm-regnetx_016                |imagenet                        |8m                              |\n|timm-regnetx_032                |imagenet                        |14m                             |\n|timm-regnetx_040                |imagenet                        |20m                             |\n|timm-regnetx_064                |imagenet                        |24m                             |\n|timm-regnetx_080                |imagenet                        |37m                             |\n|timm-regnetx_120                |imagenet                        |43m                             |\n|timm-regnetx_160                |imagenet                        |52m                             |\n|timm-regnetx_320                |imagenet                        |105m                            |\n|timm-regnety_002                |imagenet                        |2m                              |\n|timm-regnety_004                |imagenet                        |3m                              |\n|timm-regnety_006                |imagenet                        |5m                              |\n|timm-regnety_008                |imagenet                        |5m                              |\n|timm-regnety_016                |imagenet                        |10m                             |\n|timm-regnety_032                |imagenet                        |17m                             |\n|timm-regnety_040                |imagenet                        |19m                             |\n|timm-regnety_064                |imagenet                        |29m                             |\n|timm-regnety_080                |imagenet                        |37m                             |\n|timm-regnety_120                |imagenet                        |49m                             |\n|timm-regnety_160                |imagenet                        |80m                             |\n|timm-regnety_320                |imagenet                        |141m                            |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">gernet</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|timm-gernet_s                   |imagenet                        |6m                              |\n|timm-gernet_m                   |imagenet                        |18m                             |\n|timm-gernet_l                   |imagenet                        |28m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">se-net</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|senet154                        |imagenet                        |113m                            |\n|se_resnet50                     |imagenet                        |26m                             |\n|se_resnet101                    |imagenet                        |47m                             |\n|se_resnet152                    |imagenet                        |64m                             |\n|se_resnext50_32x4d              |imagenet                        |25m                             |\n|se_resnext101_32x4d             |imagenet                        |46m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">sk-resne(x)t</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|timm-skresnet18                 |imagenet                        |11m                             |\n|timm-skresnet34                 |imagenet                        |21m                             |\n|timm-skresnext50_32x4d          |imagenet                        |25m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">densenet</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|densenet121                     |imagenet                        |6m                              |\n|densenet169                     |imagenet                        |12m                             |\n|densenet201                     |imagenet                        |18m                             |\n|densenet161                     |imagenet                        |26m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">inception</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|inceptionresnetv2               |imagenet /  imagenet+background |54m                             |\n|inceptionv4                     |imagenet /  imagenet+background |41m                             |\n|xception                        |imagenet                        |22m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">efficientnet</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|efficientnet-b0                 |imagenet                        |4m                              |\n|efficientnet-b1                 |imagenet                        |6m                              |\n|efficientnet-b2                 |imagenet                        |7m                              |\n|efficientnet-b3                 |imagenet                        |10m                             |\n|efficientnet-b4                 |imagenet                        |17m                             |\n|efficientnet-b5                 |imagenet                        |28m                             |\n|efficientnet-b6                 |imagenet                        |40m                             |\n|efficientnet-b7                 |imagenet                        |63m                             |\n|timm-efficientnet-b0            |imagenet / advprop / noisy-student|4m                              |\n|timm-efficientnet-b1            |imagenet / advprop / noisy-student|6m                              |\n|timm-efficientnet-b2            |imagenet / advprop / noisy-student|7m                              |\n|timm-efficientnet-b3            |imagenet / advprop / noisy-student|10m                             |\n|timm-efficientnet-b4            |imagenet / advprop / noisy-student|17m                             |\n|timm-efficientnet-b5            |imagenet / advprop / noisy-student|28m                             |\n|timm-efficientnet-b6            |imagenet / advprop / noisy-student|40m                             |\n|timm-efficientnet-b7            |imagenet / advprop / noisy-student|63m                             |\n|timm-efficientnet-b8            |imagenet / advprop             |84m                             |\n|timm-efficientnet-l2            |noisy-student                   |474m                            |\n|timm-efficientnet-lite0         |imagenet                        |4m                              |\n|timm-efficientnet-lite1         |imagenet                        |5m                              |\n|timm-efficientnet-lite2         |imagenet                        |6m                              |\n|timm-efficientnet-lite3         |imagenet                        |8m                             |\n|timm-efficientnet-lite4         |imagenet                        |13m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">mobilenet</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|mobilenet_v2                    |imagenet                        |2m                              |\n|timm-mobilenetv3_large_075      |imagenet                        |1.78m                       |\n|timm-mobilenetv3_large_100      |imagenet                        |2.97m                       |\n|timm-mobilenetv3_large_minimal_100|imagenet                        |1.41m                       |\n|timm-mobilenetv3_small_075      |imagenet                        |0.57m                        |\n|timm-mobilenetv3_small_100      |imagenet                        |0.93m                       |\n|timm-mobilenetv3_small_minimal_100|imagenet                        |0.43m                       |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">dpn</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|dpn68                           |imagenet                        |11m                             |\n|dpn68b                          |imagenet+5k                     |11m                             |\n|dpn92                           |imagenet+5k                     |34m                             |\n|dpn98                           |imagenet                        |58m                             |\n|dpn107                          |imagenet+5k                     |84m                             |\n|dpn131                          |imagenet                        |76m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">vgg</summary>\n<div style=\"margin-left: 25px;\">\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|vgg11                           |imagenet                        |9m                              |\n|vgg11_bn                        |imagenet                        |9m                              |\n|vgg13                           |imagenet                        |9m                              |\n|vgg13_bn                        |imagenet                        |9m                              |\n|vgg16                           |imagenet                        |14m                             |\n|vgg16_bn                        |imagenet                        |14m                             |\n|vgg19                           |imagenet                        |20m                             |\n|vgg19_bn                        |imagenet                        |20m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">mix vision transformer</summary>\n<div style=\"margin-left: 25px;\">\n\nbackbone from segformer pretrained on imagenet! can be used with other decoders from package, you can combine mix vision transformer with unet, fpn and others!\n\nlimitations:  \n\n   - encoder is **not** supported by linknet, unet++\n   - encoder is supported by fpn only for encoder **depth = 5**\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|mit_b0                          |imagenet                        |3m                              |\n|mit_b1                          |imagenet                        |13m                             |\n|mit_b2                          |imagenet                        |24m                             |\n|mit_b3                          |imagenet                        |44m                             |\n|mit_b4                          |imagenet                        |60m                             |\n|mit_b5                          |imagenet                        |81m                             |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">mobileone</summary>\n<div style=\"margin-left: 25px;\">\n\napple's \"sub-one-ms\" backbone pretrained on imagenet! can be used with all decoders.\n\nnote: in the official github repo the s0 variant has additional num_conv_branches, leading to more params than s1.\n\n|encoder                         |weights                         |params, m                       |\n|--------------------------------|:------------------------------:|:------------------------------:|\n|mobileone_s0                    |imagenet                        |4.6m                              |\n|mobileone_s1                    |imagenet                        |4.0m                              |\n|mobileone_s2                    |imagenet                        |6.5m                              |\n|mobileone_s3                    |imagenet                        |8.8m                              |\n|mobileone_s4                    |imagenet                        |13.6m                             |\n\n</div>\n</details>\n\n\n\\* `ssl`, `swsl` - semi-supervised and weakly-supervised learning on imagenet ([repo](https://github.com/facebookresearch/semi-supervised-imagenet1k-models)).\n\n#### timm encoders <a name=\"timm\"></a>\n\n[docs](https://smp.readthedocs.io/en/latest/encoders_timm.html)\n\npytorch image models (a.k.a. timm) has a lot of pretrained models and interface which allows using these models as encoders in smp, however, not all models are supported\n\n - not all transformer models have ``features_only`` functionality implemented that is required for encoder\n - some models have inappropriate strides\n\ntotal number of supported encoders: 549\n - [table with available encoders](https://smp.readthedocs.io/en/latest/encoders_timm.html)\n\n### \ud83d\udd01 models api <a name=\"api\"></a>\n\n - `model.encoder` - pretrained backbone to extract features of different spatial resolution\n - `model.decoder` - depends on models architecture (`unet`/`linknet`/`pspnet`/`fpn`)\n - `model.segmentation_head` - last block to produce required number of mask channels (include also optional upsampling and activation)\n - `model.classification_head` - optional block which create classification head on top of encoder\n - `model.forward(x)` - sequentially pass `x` through model\\`s encoder, decoder and segmentation head (and classification head if specified)\n\n##### input channels\ninput channels parameter allows you to create models, which process tensors with arbitrary number of channels.\nif you use pretrained weights from imagenet - weights of first convolution will be reused. for\n1-channel case it would be a sum of weights of first convolution layer, otherwise channels would be \npopulated with weights like `new_weight[:, i] = pretrained_weight[:, i % 3]` and than scaled with `new_weight * 3 / new_in_channels`.\n```python\nmodel = smp.fpn('resnet34', in_channels=1)\nmask = model(torch.ones([1, 1, 64, 64]))\n```\n\n##### auxiliary classification output  \nall models support `aux_params` parameters, which is default set to `none`. \nif `aux_params = none` then classification auxiliary output is not created, else\nmodel produce not only `mask`, but also `label` output with shape `nc`.\nclassification head consists of globalpooling->dropout(optional)->linear->activation(optional) layers, which can be \nconfigured by `aux_params` as follows:\n```python\naux_params=dict(\n    pooling='avg',             # one of 'avg', 'max'\n    dropout=0.5,               # dropout ratio, default is none\n    activation='sigmoid',      # activation function, default is none\n    classes=4,                 # define number of output labels\n)\nmodel = smp.unet('resnet34', classes=4, aux_params=aux_params)\nmask, label = model(x)\n```\n\n##### depth\ndepth parameter specify a number of downsampling operations in encoder, so you can make\nyour model lighter if specify smaller `depth`.\n```python\nmodel = smp.unet('resnet34', encoder_depth=4)\n```\n\n\n### \ud83d\udee0 installation <a name=\"installation\"></a>\npypi version:\n```bash\n$ pip install segmentation-models-pytorch\n````\nlatest version from source:\n```bash\n$ pip install git+https://github.com/qubvel/segmentation_models.pytorch\n````\n\n### \ud83c\udfc6 competitions won with the library\n\n`segmentation models` package is widely used in the image segmentation competitions.\n[here](https://github.com/qubvel/segmentation_models.pytorch/blob/master/halloffame.md) you can find competitions, names of the winners and links to their solutions.\n\n### \ud83e\udd1d contributing\n\n#### install smp  \n\n```bash\nmake install_dev  # create .venv, install smp in dev mode\n```\n\n#### run tests and code checks  \n\n```bash\nmake all          # run flake8, black, tests\n```\n\n#### update table with encoders  \n\n```bash\nmake table        # generate table with encoders and print to stdout\n```\n\n### \ud83d\udcdd citing\n```\n@misc{iakubovskii:2019,\n  author = {pavel iakubovskii},\n  title = {segmentation models pytorch},\n  year = {2019},\n  publisher = {github},\n  journal = {github repository},\n  howpublished = {\\url{https://github.com/qubvel/segmentation_models.pytorch}}\n}\n```\n\n### \ud83d\udee1\ufe0f license <a name=\"license\"></a>\nproject is distributed under [mit license](https://github.com/qubvel/segmentation_models.pytorch/blob/master/license)\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "segmentation-models-pytorch",
  "package_url": "https://pypi.org/project/segmentation-models-pytorch/",
  "project_url": "https://pypi.org/project/segmentation-models-pytorch/",
  "project_urls": {
    "Homepage": "https://github.com/qubvel/segmentation_models.pytorch"
  },
  "release_url": "https://pypi.org/project/segmentation-models-pytorch/0.3.3/",
  "requires_dist": [
    "torchvision (>=0.5.0)",
    "pretrainedmodels (==0.7.4)",
    "efficientnet-pytorch (==0.7.1)",
    "timm (==0.9.2)",
    "tqdm",
    "pillow",
    "pytest ; extra == 'test'",
    "mock ; extra == 'test'",
    "pre-commit ; extra == 'test'",
    "black (==22.3.0) ; extra == 'test'",
    "flake8 (==4.0.1) ; extra == 'test'",
    "flake8-docstrings (==1.6.0) ; extra == 'test'"
  ],
  "requires_python": ">=3.7.0",
  "summary": "image segmentation models with pre-trained backbones. pytorch.",
  "version": "0.3.3",
  "releases": [],
  "developers": [
    "pavel_iakubovskii",
    "qubvel@gmail.com"
  ],
  "kwds": "segmentation_models_pytorch segmentation_models badge qubvel segmentation",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_segmentation_models_pytorch",
  "homepage": "https://github.com/qubvel/segmentation_models.pytorch",
  "release_count": 13,
  "dependency_ids": [
    "pypi_black",
    "pypi_efficientnet_pytorch",
    "pypi_flake8",
    "pypi_flake8_docstrings",
    "pypi_mock",
    "pypi_pillow",
    "pypi_pre_commit",
    "pypi_pretrainedmodels",
    "pypi_pytest",
    "pypi_timm",
    "pypi_torchvision",
    "pypi_tqdm"
  ],
  "documentation_summary": "The HTML text describes the PyPI (Python Package Index) page for \"segmentation-models-pytorch\" version 0.3.3, released on May 28, 2023. This Python library provides neural networks for image segmentation based on PyTorch, offering a high-level API, 9 model architectures for binary and multi-class segmentation, and 124 available encoders with pre-trained weights for improved convergence. It supports popular metrics and losses for training routines. The library requires Python version 3.7.0 or higher and is distributed under the MIT License. The page also includes a warning about JavaScript requirement for full functionality and a browser upgrade notification for IE9 and below.",
  "embedding": [
    -0.010705552063882351,
    0.01954377442598343,
    -0.0005883665871806443,
    -0.03282567858695984,
    0.009013723582029343,
    0.029764944687485695,
    -0.003794328309595585,
    0.00636366056278348,
    -0.017311403527855873,
    -0.03908754885196686,
    0.022885311394929886,
    0.03658841550350189,
    -0.04068811610341072,
    0.0009441945585422218,
    -0.0033380261156708,
    -0.0008902280824258924,
    0.02100394107401371,
    -0.007005993742495775,
    -0.005089524667710066,
    -0.026760369539260864,
    0.013120443560183048,
    -0.00405055982992053,
    -0.012797522358596325,
    -0.025159802287817,
    0.014671871438622475,
    0.030775828287005424,
    0.013457405380904675,
    -0.021677864715456963,
    -0.025960085913538933,
    0.017058681696653366,
    0.01078979205340147,
    -0.016567280516028404,
    -0.022983592003583908,
    -0.015345794148743153,
    0.001179365674033761,
    0.015486194752156734,
    0.016440918669104576,
    -0.03375232219696045,
    0.023446913808584213,
    -0.0033362710382789373,
    0.004275200888514519,
    0.03428584709763527,
    0.004405071493238211,
    -0.008971603587269783,
    -0.01248864084482193,
    0.00754653662443161,
    0.008381920866668224,
    -0.017802806571125984,
    -0.00880312267690897,
    0.009027763269841671,
    0.01923489384353161,
    0.022885311394929886,
    -0.016089918091893196,
    -0.0010705551831051707,
    0.008725902065634727,
    0.006202199961990118,
    0.008964583277702332,
    0.02281511016190052,
    0.0029571892227977514,
    -0.007469316013157368,
    0.027729135006666183,
    -0.011400534771382809,
    -0.055486347526311874,
    0.0004935961333103478,
    -0.010291369631886482,
    -0.016047798097133636,
    -0.015149232931435108,
    0.015036912634968758,
    0.005128134973347187,
    -0.002418401651084423,
    0.03768354281783104,
    0.017086762934923172,
    -0.0020129948388785124,
    -0.01498075295239687,
    0.034173525869846344,
    -0.019305093213915825,
    -0.01601971685886383,
    0.0003494660777505487,
    -0.03119703009724617,
    -0.019164692610502243,
    0.017199082300066948,
    -0.030326547101140022,
    -0.016440918669104576,
    0.03976147249341011,
    0.013457405380904675,
    0.011154834181070328,
    -0.004475271794945002,
    -0.00011703713244060054,
    -0.014924592338502407,
    0.006497041322290897,
    0.027560653164982796,
    0.012650101445615292,
    0.01017202902585268,
    -0.016132038086652756,
    -0.02038617804646492,
    0.02639532834291458,
    -0.02567928470671177,
    0.02987726405262947,
    0.0009582346538081765,
    0.0054721166379749775,
    -0.010558131150901318,
    0.014573590829968452,
    -0.01717100292444229,
    -0.017816845327615738,
    -0.027378132566809654,
    -0.0099263284355402,
    0.005068464670330286,
    0.03546521067619324,
    0.021818265318870544,
    0.023994475603103638,
    -0.034089285880327225,
    0.031168950721621513,
    -0.02268875017762184,
    -0.058799803256988525,
    -0.009182204492390156,
    0.0049736942164599895,
    0.02701309137046337,
    0.013604826293885708,
    -0.0017251733224838972,
    -0.009034783579409122,
    0.018209967762231827,
    0.0189821720123291,
    0.02555292285978794,
    -0.028276696801185608,
    0.02956838347017765,
    -0.008058998733758926,
    -0.0025851274840533733,
    -0.006437371019273996,
    0.0339769646525383,
    -0.03526864945888519,
    0.007736077532172203,
    0.0018111687386408448,
    0.0317867137491703,
    0.005149194970726967,
    -0.02263258956372738,
    0.011435635387897491,
    -0.004043539520353079,
    -0.014194509014487267,
    -0.04315916821360588,
    -0.03613913431763649,
    0.0021937605924904346,
    0.021565543487668037,
    -0.010705552063882351,
    -0.011246094480156898,
    0.0040575796738266945,
    0.03473512828350067,
    -0.01641283929347992,
    -0.01910853199660778,
    -0.006798902992159128,
    0.022969551384449005,
    -0.011772597208619118,
    -0.028164375573396683,
    -0.03667265921831131,
    0.010368590243160725,
    0.03431392461061478,
    0.010859992355108261,
    0.0056897373870015144,
    0.0013969867723062634,
    -0.025581004098057747,
    -0.02343287318944931,
    -0.010888072662055492,
    0.021551504731178284,
    -0.042288683354854584,
    -0.003706577932462096,
    0.01937529444694519,
    0.013997947797179222,
    0.015121153555810452,
    -0.007974758744239807,
    -0.024289317429065704,
    -0.008662722073495388,
    0.005005284212529659,
    0.009427906014025211,
    -0.008325760252773762,
    -0.01791512593626976,
    -0.01871541142463684,
    0.013738206587731838,
    0.01606183685362339,
    -0.0012021808652207255,
    -0.03437008708715439,
    -0.0002818982466123998,
    0.012958982959389687,
    -0.004475271794945002,
    0.013829466886818409,
    0.03703770041465759,
    -0.02572140470147133,
    -0.022801069542765617,
    -0.010824892669916153,
    -0.014131328091025352,
    -0.00720255495980382,
    -0.009252404794096947,
    0.020905660465359688,
    0.019122572615742683,
    0.003048449754714966,
    -0.02567928470671177,
    -0.5625013113021851,
    -0.01830824837088585,
    -0.004387521184980869,
    -0.02073718048632145,
    0.014798231422901154,
    0.018897932022809982,
    0.0027553632389754057,
    -0.01332402415573597,
    -0.014685911126434803,
    0.029512222856283188,
    -0.008438080549240112,
    -0.00023868115385994315,
    0.0019112041918560863,
    -0.003724128007888794,
    -0.008718881756067276,
    -0.013696086592972279,
    0.00010228408791590482,
    -0.02061082050204277,
    -0.007883498445153236,
    -0.007041093893349171,
    -0.007904558442533016,
    0.03613913431763649,
    -0.008445100858807564,
    0.025033440440893173,
    0.007023544050753117,
    0.020498499274253845,
    0.0033696163445711136,
    0.006423330865800381,
    0.03846978768706322,
    0.01005970872938633,
    -0.056553393602371216,
    0.025314241647720337,
    0.007581636775285006,
    -0.01248864084482193,
    0.049364879727363586,
    0.007939658127725124,
    -0.022618548944592476,
    0.033162642270326614,
    0.01392072718590498,
    0.0507408045232296,
    -0.012362279929220676,
    -0.026283007115125656,
    -0.0060477592051029205,
    -0.014657830819487572,
    0.006851552985608578,
    0.03234831616282463,
    0.0061776298098266125,
    0.018083607777953148,
    0.01937529444694519,
    -0.024879001080989838,
    0.02567928470671177,
    0.0014926347648724914,
    -0.0044858017936348915,
    0.008080058731138706,
    0.015584475360810757,
    -0.007265734951943159,
    0.042288683354854584,
    -0.03824514523148537,
    0.027083290740847588,
    -0.008150259032845497,
    0.0003514404525049031,
    0.021368984133005142,
    -0.008459140546619892,
    -0.013668006286025047,
    -0.014047088101506233,
    -0.0016304028686136007,
    0.0016549730207771063,
    -0.02170594595372677,
    -0.016777880489826202,
    -0.03538097068667412,
    0.007806277833878994,
    0.010354550555348396,
    0.014896512031555176,
    -0.003462631721049547,
    0.023601355031132698,
    0.03931219130754471,
    -0.0012837887043133378,
    0.017086762934923172,
    0.0018708390416577458,
    0.030691588297486305,
    0.014699950814247131,
    0.0020077296067029238,
    0.00946300569921732,
    -0.03372424468398094,
    0.01884177140891552,
    0.011793657205998898,
    0.007195534650236368,
    0.0023815464228391647,
    0.009652546606957912,
    0.00818535964936018,
    0.008150259032845497,
    0.0036188275553286076,
    -0.01138649508357048,
    -0.03785202279686928,
    0.006672542076557875,
    0.014713991433382034,
    -0.026016246527433395,
    0.012102538719773293,
    -0.027293892577290535,
    -0.01958589442074299,
    0.013675026595592499,
    -0.0005988966440781951,
    0.0040575796738266945,
    0.010024608112871647,
    0.024850919842720032,
    -0.0008660966996103525,
    -0.01455955021083355,
    0.005015814211219549,
    0.01752200536429882,
    -0.0441138930618763,
    -0.0082695996388793,
    -0.037093859165906906,
    -0.028697898611426353,
    -0.0033836562652140856,
    0.011203974485397339,
    -0.03557753190398216,
    0.030916228890419006,
    -0.0025588024873286486,
    0.011281194165349007,
    0.005419466178864241,
    -0.0035082618705928326,
    -0.00752547662705183,
    0.01879965141415596,
    0.01339422445744276,
    0.025047481060028076,
    0.016483040526509285,
    0.0082695996388793,
    -0.021958665922284126,
    -0.015191353857517242,
    0.01255884114652872,
    0.036419935524463654,
    -0.008178339339792728,
    0.038554027676582336,
    -0.01995093561708927,
    0.03189903497695923,
    0.02664804831147194,
    0.01809764839708805,
    -0.0056195370852947235,
    0.018743490800261497,
    -0.0003159015323035419,
    0.012397379614412785,
    0.004040029365569353,
    -0.01063535176217556,
    -0.02145322412252426,
    -0.03453856706619263,
    -0.00820641964673996,
    -0.021214542910456657,
    0.013211703859269619,
    0.01760624535381794,
    -0.019515695050358772,
    -0.02077930048108101,
    -0.0027729133144021034,
    -0.03156207129359245,
    0.0053527760319411755,
    0.006837513297796249,
    -0.008978623896837234,
    -0.03189903497695923,
    -0.03490360826253891,
    -0.028009936213493347,
    -0.012060418725013733,
    0.0076518370769917965,
    0.04169900342822075,
    -0.0322079174220562,
    0.020624859258532524,
    -0.029371822252869606,
    -0.00025228247977793217,
    -0.03667265921831131,
    0.04071619734168053,
    -0.013983908109366894,
    -0.021635744720697403,
    -0.008058998733758926,
    -0.009785926900804043,
    0.009477046318352222,
    0.01645495928823948,
    -0.003983869217336178,
    -0.0018655740423128009,
    0.010277329944074154,
    0.00041264636092819273,
    0.010045669041574001,
    -0.008971603587269783,
    -0.002163925440981984,
    0.0026974480133503675,
    -0.022787030786275864,
    -0.0014382294612005353,
    0.03568985313177109,
    0.026507647708058357,
    0.016384759917855263,
    0.014896512031555176,
    -0.002908049151301384,
    -0.003538097022101283,
    0.011997237801551819,
    0.017016561701893806,
    0.0010407200315967202,
    0.037402741611003876,
    0.002537742257118225,
    0.02211310714483261,
    0.025173841044306755,
    -0.019262973219156265,
    -0.011533915996551514,
    0.014047088101506233,
    -0.0060582892037928104,
    0.007013014052063227,
    -0.0035521371755748987,
    -0.016525160521268845,
    -0.011400534771382809,
    -0.01999305747449398,
    0.019698215648531914,
    -0.006830492988228798,
    0.010712571442127228,
    0.010937212966382504,
    0.031084710732102394,
    0.002158660441637039,
    -0.02639532834291458,
    -0.015303674153983593,
    -0.0037557182367891073,
    0.018589049577713013,
    -0.0009494596160948277,
    0.002402606653049588,
    -0.0379643440246582,
    0.0037557182367891073,
    -0.008213439956307411,
    0.005731857847422361,
    -0.0063566407188773155,
    -0.006732212379574776,
    -0.012523740530014038,
    0.020512539893388748,
    -0.0010573925683274865,
    0.00568271754309535,
    -0.00878206267952919,
    -0.03299415856599808,
    -0.014938632026314735,
    0.051386646926403046,
    0.009792947210371494,
    -0.013597805984318256,
    0.015107112936675549,
    0.019291052594780922,
    0.034173525869846344,
    -0.017620285972952843,
    0.03917178884148598,
    -0.02219734713435173,
    0.015542355366051197,
    0.020807379856705666,
    0.012516720220446587,
    -0.0003343291173223406,
    0.03243255615234375,
    0.007939658127725124,
    0.010256269946694374,
    0.008290660567581654,
    -0.015401954762637615,
    -0.0007164822309277952,
    -0.0034222665708512068,
    0.010087789036333561,
    -0.014657830819487572,
    0.025384442880749702,
    0.019473575055599213,
    0.003274845890700817,
    0.006479491479694843,
    0.018729450181126595,
    0.0240506362169981,
    0.010803832672536373,
    0.0036855179350823164,
    0.013948807492852211,
    0.021691905334591866,
    -0.01151987537741661,
    0.04372077062726021,
    -0.01795724779367447,
    -0.005180784966796637,
    -0.053324177861213684,
    -0.007974758744239807,
    0.0025061520282179117,
    -0.028894459828734398,
    -0.01193405780941248,
    -0.010438790544867516,
    -0.03251679614186287,
    0.03639185428619385,
    0.009364725090563297,
    0.020849501714110374,
    0.03715001791715622,
    0.010579191148281097,
    0.030831988900899887,
    -0.01721312291920185,
    -0.03818898648023605,
    0.03636377677321434,
    0.01752200536429882,
    -0.004629712551832199,
    -0.019291052594780922,
    -0.0582382008433342,
    0.010010568425059319,
    -0.018869850784540176,
    -0.0009108494268730283,
    0.007356995716691017,
    0.017451804131269455,
    -0.007413155864924192,
    0.008016878738999367,
    -0.0383855439722538,
    -0.01189193781465292,
    0.04425429552793503,
    0.008536361157894135,
    0.007128844503313303,
    0.012769442051649094,
    -0.0067357225343585014,
    0.026535728946328163,
    -0.03203943371772766,
    -0.003216930665075779,
    0.03942451253533363,
    -0.028978699818253517,
    -0.024682439863681793,
    0.0073429555632174015,
    -0.029708784073591232,
    0.001798883662559092,
    0.018069567158818245,
    -0.03150591254234314,
    -0.0035661773290485144,
    -0.008445100858807564,
    0.03703770041465759,
    0.018125727772712708,
    0.005100054666399956,
    -0.01641283929347992,
    0.03512825071811676,
    0.00807303935289383,
    -0.004685872700065374,
    -0.02586180530488491,
    -0.002246410818770528,
    -0.014812272042036057,
    0.030944310128688812,
    0.04928063973784447,
    -0.004250630736351013,
    0.0013838241575285792,
    -0.03111279010772705,
    -0.0028378486167639494,
    -0.026676129549741745,
    0.002864173846319318,
    -0.0052825757302343845,
    -0.0011977932881563902,
    -0.031309351325035095,
    0.014236629009246826,
    0.004885943606495857,
    0.010579191148281097,
    0.017634324729442596,
    -0.003773268312215805,
    0.0113654350861907,
    0.01248864084482193,
    -0.014054108411073685,
    -0.005170254968106747,
    0.003167790360748768,
    -0.006781352683901787,
    0.01440510991960764,
    0.022365828976035118,
    0.03644801676273346,
    0.0011135528329759836,
    0.02228158712387085,
    0.04301876947283745,
    -0.01458763051778078,
    -0.012980042956769466,
    -0.0006418943521566689,
    -0.001634790445677936,
    0.010445810854434967,
    0.011990218423306942,
    -0.00756759662181139,
    0.011540936306118965,
    0.004899983759969473,
    0.025693323463201523,
    -0.01206743810325861,
    0.008817162364721298,
    0.019305093213915825,
    0.032853759825229645,
    0.007251695264130831,
    -0.0009126043878495693,
    -0.010958272963762283,
    -0.013225743547081947,
    -0.005482646636664867,
    -0.0018199437763541937,
    -0.01440510991960764,
    -0.010340509936213493,
    0.018083607777953148,
    0.02396639622747898,
    -0.0507408045232296,
    -0.0330783985555172,
    0.025707364082336426,
    -0.003080039983615279,
    -0.0014584120362997055,
    -0.024036595597863197,
    0.006349620874971151,
    -0.011168873868882656,
    0.008768022060394287,
    -0.03526864945888519,
    -0.007132354658097029,
    0.0017567635513842106,
    -0.0008349452982656658,
    0.013576745986938477,
    -0.010179049335420132,
    0.02289935015141964,
    -0.04447893425822258,
    0.00824853964149952,
    0.011646236293017864,
    -0.014138348400592804,
    -0.01566871628165245,
    -0.037093859165906906,
    0.0138996671885252,
    0.008676761761307716,
    -0.0055317869409918785,
    0.006247830111533403,
    0.013450385071337223,
    0.018771570175886154,
    0.008859283290803432,
    -0.010972312651574612,
    0.0066058519296348095,
    -0.04826975241303444,
    0.006051269359886646,
    -0.03027038648724556,
    0.021130302920937538,
    -0.006669032387435436,
    -0.02020365744829178,
    0.01667959988117218,
    0.03142167255282402,
    0.030158065259456635,
    -0.008508280850946903,
    -0.023713674396276474,
    0.002967719454318285,
    0.019529733806848526,
    0.006086369510740042,
    0.01012990903109312,
    -0.0029536793008446693,
    -0.013401244767010212,
    0.01884177140891552,
    -0.042288683354854584,
    -0.013099383562803268,
    -0.006841022986918688,
    0.011863857507705688,
    0.0027413233183324337,
    0.018420569598674774,
    0.010235209949314594,
    -0.00283609377220273,
    0.013639925979077816,
    0.015781035646796227,
    0.003394186496734619,
    0.007097254507243633,
    -0.013822446577250957,
    -0.007988798432052135,
    -0.019361253827810287,
    0.0052931057289242744,
    0.010803832672536373,
    -0.00111969537101686,
    -0.012404399923980236,
    0.0005980191635899246,
    -0.01717100292444229,
    0.04495629668235779,
    0.010136929340660572,
    -0.023685595020651817,
    0.01575295627117157,
    -0.008325760252773762,
    -0.0026237377896904945,
    -0.02730793133378029,
    0.0011547956382855773,
    -0.010389650240540504,
    0.040266916155815125,
    -0.00036855178768746555,
    -0.023138031363487244,
    0.015401954762637615,
    0.0059284185990691185,
    -0.0031783203594386578,
    0.016384759917855263,
    0.007083214353770018,
    -0.01127417478710413,
    0.02149534411728382,
    0.009104983881115913,
    -0.033920805901288986,
    0.013064282946288586,
    0.011414575390517712,
    -0.02996150590479374,
    -0.007244674954563379,
    0.0042962608858942986,
    0.02378387562930584,
    0.018813690170645714,
    -0.0052509852685034275,
    0.02184634655714035,
    0.011210993863642216,
    0.002987024374306202,
    -0.005114094819873571,
    -0.007616736926138401,
    -0.0264795683324337,
    0.007135864347219467,
    0.019361253827810287,
    0.04548982158303261,
    0.03302223980426788,
    0.02347499318420887,
    0.01010884903371334,
    0.011021452955901623,
    0.00018943122995551676,
    0.003425776492804289,
    0.005100054666399956,
    0.01394178718328476,
    -0.021060101687908173,
    0.010298389941453934,
    -0.003176565282046795,
    0.010186069644987583,
    0.005510726477950811,
    -0.016623441129922867,
    0.004412091337144375,
    0.006988443899899721,
    0.002528967335820198,
    -0.0189681313931942,
    -0.009785926900804043,
    -0.02281511016190052,
    0.0016663805581629276,
    0.0029940444510430098,
    -0.01396284718066454,
    0.011540936306118965,
    -0.04240100458264351,
    0.001766416011378169,
    0.0056616575457155704,
    -0.00829767994582653,
    0.01690424233675003,
    0.018462689593434334,
    0.021734025329351425,
    0.0065461816266179085,
    0.01902429200708866,
    0.0031835853587836027,
    0.014770151115953922,
    -0.009877188131213188,
    -0.006637441925704479,
    -0.047146547585725784,
    -0.020540619269013405,
    -0.0053808558732271194,
    -0.014306829310953617,
    0.013506545685231686,
    0.018560970202088356,
    -0.015219433233141899,
    0.005187805276364088,
    0.010628331452608109,
    -0.0031467301305383444,
    -0.015008832328021526,
    0.009301545098423958,
    -0.03156207129359245,
    -0.005524766631424427,
    -0.013099383562803268,
    -0.031225111335515976,
    -0.019782455638051033,
    0.003020369680598378,
    -0.010459850542247295,
    -0.0056511275470256805,
    0.002469297032803297,
    -0.01081085205078125,
    -0.0009766622679308057,
    0.025314241647720337,
    0.010291369631886482,
    0.06419119238853455,
    0.035858333110809326,
    0.029147181659936905,
    0.01950165443122387,
    0.004503351636230946,
    -0.022646630182862282,
    -0.0033713714219629765,
    -0.014040067791938782,
    -0.015331754460930824,
    0.02021769806742668,
    0.022169267758727074,
    0.000308004004182294,
    -0.014643791131675243,
    0.029456062242388725,
    -0.014334909617900848,
    -0.019136613234877586,
    -0.023264393210411072,
    0.030466947704553604,
    0.02122858352959156,
    0.013408265076577663,
    -0.009680626913905144,
    0.0003828112385235727,
    -0.0010916152969002724,
    -0.0038048583082854748,
    -0.026774410158395767,
    -0.011723456904292107,
    0.012980042956769466,
    -0.025089601054787636,
    -0.022534308955073357,
    0.040968917310237885,
    0.002548272255808115,
    0.01054409146308899,
    0.005005284212529659,
    -0.026002205908298492,
    0.006124979816377163,
    -0.016525160521268845,
    -0.01394178718328476,
    0.003734658006578684,
    0.029821103438735008,
    0.041586682200431824,
    -0.019136613234877586,
    -0.004022479522973299,
    0.04495629668235779,
    -0.009090944193303585,
    -0.0033327611163258553,
    0.0113654350861907,
    0.004254140425473452,
    0.04007035493850708,
    -0.016623441129922867,
    -0.006282930262386799,
    -0.013527605682611465,
    -0.03976147249341011,
    0.006535651627928019,
    -0.0005550214555114508,
    0.0030537147540599108,
    -0.009266444481909275,
    0.00433487119153142,
    0.005889808293431997,
    0.022478148341178894,
    0.003116894979029894,
    -0.02011941745877266,
    0.010670451447367668,
    -0.006430351175367832,
    -0.006679562386125326,
    -0.021649785339832306,
    0.004868393763899803,
    -0.0004922798834741116,
    -0.03498784825205803,
    -0.016609400510787964,
    -0.022379867732524872,
    0.0006721682730130851,
    0.032853759825229645,
    0.01954377442598343,
    -0.014952672645449638,
    -0.011098673567175865,
    0.036251455545425415,
    -0.01711484231054783,
    0.009680626913905144,
    -0.004222550429403782,
    -0.007988798432052135,
    -0.0242752768099308,
    -0.011414575390517712,
    -0.011091653257608414,
    -0.014910551719367504,
    0.008473181165754795,
    0.01752200536429882,
    -0.02621280774474144,
    -0.00530714588239789,
    -0.0009257670026272535,
    0.006314520724117756,
    0.008234499953687191,
    -0.025033440440893173,
    0.013078323565423489,
    -0.003832938615232706,
    5.0291961088078097e-05,
    -0.012235919013619423,
    -0.020358098670840263,
    0.032769519835710526,
    0.011498815380036831,
    -0.007378055714070797,
    -0.014826311729848385,
    -0.016440918669104576,
    0.002413136651739478,
    -0.03451048582792282,
    0.00446825148537755,
    0.02815033681690693,
    -0.04259756579995155,
    -0.013885627500712872,
    -0.004552491940557957,
    0.00720255495980382,
    0.0025675774086266756,
    0.02343287318944931,
    -0.012593940831720829,
    0.00043721648398786783,
    -0.019880736246705055,
    0.026184726506471634,
    0.011477755382657051,
    -0.018785610795021057,
    -0.006012659054249525,
    0.007743097376078367,
    -0.004840313456952572,
    -0.006110939662903547,
    -0.019220853224396706,
    -0.004636732395738363,
    0.004320831038057804,
    0.008859283290803432,
    -0.024682439863681793,
    -0.019880736246705055,
    -0.000197986897546798,
    0.048129353672266006,
    0.01915065199136734,
    0.0006296092760749161,
    -0.008557421155273914,
    -0.00824853964149952,
    -0.034622807055711746,
    -0.012299099937081337,
    -0.00999652873724699,
    0.03877866640686989,
    0.0007379810558632016,
    0.022295627743005753,
    0.01690424233675003,
    0.009870167821645737,
    0.025258082896471024,
    0.024654358625411987,
    -0.015472155064344406,
    0.0036398875527083874,
    0.0019620994571596384,
    0.005057934671640396,
    -0.0064759813249111176,
    -0.008880343288183212,
    -0.04431045427918434,
    -0.02458415925502777,
    0.005914378445595503,
    0.0031151401344686747,
    0.014419149607419968,
    0.03229215741157532,
    -0.023320551961660385,
    -0.01376628689467907,
    0.018897932022809982,
    0.0053106555715203285,
    0.0004935961333103478,
    -0.010291369631886482,
    0.03992995247244835,
    -0.03206751495599747,
    -0.025889884680509567,
    -0.010382629930973053,
    0.01791512593626976,
    0.01151987537741661,
    -0.0017400908982381225,
    0.027153491973876953,
    0.02215522713959217,
    0.012516720220446587,
    -0.011512855999171734,
    -0.00036548051866702735,
    0.014243649318814278,
    0.0008950543124228716,
    0.01752200536429882,
    0.034005045890808105,
    0.007897538132965565,
    0.047595828771591187,
    0.01571083627641201,
    -0.005015814211219549,
    -0.0165391992777586,
    0.016777880489826202,
    -0.008087079040706158,
    -0.016342639923095703,
    0.027967816218733788,
    -0.020905660465359688,
    0.021017981693148613,
    -0.02695693075656891,
    0.030017664656043053,
    -0.007637796923518181,
    0.01198319811373949,
    -0.013885627500712872,
    -0.021944625303149223,
    -0.03057926706969738,
    0.018111687153577805,
    -0.006588302087038755,
    -0.010459850542247295,
    0.0036363776307553053,
    -0.001983159687370062,
    0.019248932600021362,
    0.005633577238768339,
    -0.02184634655714035,
    0.015738915652036667,
    -0.006511081475764513,
    0.0038575087673962116,
    -0.006728702690452337,
    -0.021102221682667732,
    -0.013576745986938477,
    -0.018743490800261497,
    -0.0024394618812948465,
    -0.020807379856705666,
    0.0034521017223596573,
    0.17578165233135223,
    -0.007700977381318808,
    0.01747988536953926,
    0.02638128772377968,
    0.0317586325109005,
    -0.0015742426039651036,
    0.004987733904272318,
    0.019248932600021362,
    0.0011618155986070633,
    0.026142606511712074,
    -0.0007020034245215356,
    -0.015486194752156734,
    0.0011583055602386594,
    -0.008178339339792728,
    0.024696478620171547,
    -0.014531469903886318,
    -0.020554659888148308,
    -0.0511900894343853,
    -0.014391069300472736,
    0.0002788269775919616,
    -0.04071619734168053,
    -0.010888072662055492,
    -0.02555292285978794,
    -0.022211387753486633,
    0.008550401777029037,
    0.001372416620142758,
    -0.028276696801185608,
    -0.004222550429403782,
    0.014278749004006386,
    0.0010810851817950606,
    -0.010319449938833714,
    0.026844609528779984,
    -0.0017330709379166365,
    -0.012235919013619423,
    -0.04071619734168053,
    -0.02493515983223915,
    -0.007118314504623413,
    -0.012629041448235512,
    -0.014896512031555176,
    0.036111053079366684,
    0.01849076896905899,
    -0.0119129978120327,
    0.003478426719084382,
    -0.03243255615234375,
    -0.005289595574140549,
    -0.024963241070508957,
    -0.027701053768396378,
    0.004622692242264748,
    -0.0021235602907836437,
    0.013366145081818104,
    -0.011758556589484215,
    0.002428931649774313,
    0.0330783985555172,
    -0.003164280205965042,
    -0.006539161782711744,
    -0.007016523741185665,
    -0.006265380419790745,
    0.030129985883831978,
    0.039649151265621185,
    0.004148839972913265,
    -0.035858333110809326,
    0.021158382296562195,
    -0.013085342943668365,
    0.02308187261223793,
    -0.015696795657277107,
    0.02691481076180935,
    -0.02374175563454628,
    0.0016277703689411283,
    0.007820317521691322,
    -0.005770468153059483,
    -0.010824892669916153,
    -0.02674632892012596,
    -0.030017664656043053,
    -0.01945953443646431,
    -0.022295627743005753,
    -0.024373557418584824,
    0.03745890036225319,
    -0.011653256602585316,
    0.02320823259651661,
    0.0361952967941761,
    -0.0020919700618833303,
    0.0006607606774196029,
    0.021284742280840874,
    0.02577756531536579,
    -0.01332402415573597,
    -0.009589366614818573,
    0.030607348307967186,
    -0.029315661638975143,
    0.012242939323186874,
    -0.00729381525889039,
    -0.002607942558825016,
    -0.026802489534020424,
    0.018294207751750946,
    0.0021884955931454897,
    -0.010410710237920284,
    0.006760292686522007,
    0.01140755508095026,
    0.02038617804646492,
    -0.0081642996519804,
    -0.007834358140826225,
    -0.02108818292617798,
    0.04804511368274689,
    0.0317867137491703,
    -0.02788357436656952,
    -0.00669711222872138,
    -0.0043664611876010895,
    0.007216595113277435,
    0.029231421649456024,
    0.007876478135585785,
    -0.024303358048200607,
    -0.007279775105416775,
    -0.028360936790704727,
    -0.005265025421977043,
    0.0009477045969106257,
    0.016876161098480225,
    0.010066729038953781,
    -0.014117288403213024,
    -0.02771509438753128,
    -0.010600251145660877,
    -0.0038294284604489803,
    -0.007841377519071102,
    0.007778197526931763,
    0.002541252411901951,
    -0.01738160476088524,
    -0.015317713841795921,
    -0.024640319868922234,
    -0.01618819870054722,
    0.001932264305651188,
    -0.01198319811373949,
    -0.005433506332337856,
    -0.006307500414550304,
    -0.02744833193719387,
    0.024654358625411987,
    0.01791512593626976,
    0.0015057972632348537,
    -0.03288183733820915,
    -0.0014110268093645573,
    0.012306119315326214,
    0.016693640500307083,
    0.018294207751750946,
    -0.037486981600522995,
    0.009736787527799606,
    -0.007820317521691322,
    -0.015640635043382645,
    0.003934728913009167,
    -0.008529340848326683,
    -0.0007256960379891098,
    0.033162642270326614,
    0.012460560537874699,
    0.011168873868882656,
    -0.017353523522615433,
    0.010207129642367363,
    0.01447531022131443,
    -0.012179759331047535,
    0.01733948476612568,
    -0.039340268820524216,
    -0.01830824837088585,
    -0.031056629493832588,
    0.001979649532586336,
    -0.004327850881963968,
    -0.017985327169299126,
    -0.014461269602179527,
    -0.015401954762637615,
    0.009048824198544025,
    -0.02555292285978794,
    -0.02881021983921528,
    -0.1764555722475052,
    0.003366106189787388,
    0.035717934370040894,
    -0.058182042092084885,
    0.012615000829100609,
    -0.007441236171871424,
    0.00473150284960866,
    0.0077711776830255985,
    -0.03057926706969738,
    -0.0036820077802985907,
    0.04425429552793503,
    -0.011196954175829887,
    -0.0034240216482430696,
    -0.03071966953575611,
    0.00043919088784605265,
    -0.015373874455690384,
    -0.01813976839184761,
    0.006261870265007019,
    0.038020502775907516,
    -0.010305410251021385,
    0.025875845924019814,
    -0.025258082896471024,
    -0.004362951032817364,
    0.014784191735088825,
    -0.012320159934461117,
    -0.023376712575554848,
    0.011884917505085468,
    0.02025981806218624,
    -0.0030572249088436365,
    -0.021944625303149223,
    -0.013274883851408958,
    -0.01910853199660778,
    0.013731186278164387,
    0.010431770235300064,
    -0.023952355608344078,
    0.028220536187291145,
    0.028136296197772026,
    -0.027027130126953125,
    -0.028655778616666794,
    0.04638838395476341,
    0.005514236632734537,
    0.020512539893388748,
    -0.010052688419818878,
    -0.014180468395352364,
    -0.0227308701723814,
    -0.00866974238306284,
    0.012657120823860168,
    -0.0366164967417717,
    0.030831988900899887,
    -0.0165532398968935,
    0.02881021983921528,
    -0.011807696893811226,
    0.016890201717615128,
    0.0015970576787367463,
    0.019740335643291473,
    0.006904203444719315,
    -0.010838932357728481,
    -0.007883498445153236,
    0.020933741703629494,
    -0.018083607777953148,
    -0.011660275980830193,
    -0.011210993863642216,
    0.01813976839184761,
    -0.005633577238768339,
    -0.010817872360348701,
    -0.04231676459312439,
    -0.014868431724607944,
    0.02347499318420887,
    -0.025131721049547195,
    0.008634641766548157,
    -0.0021516403649002314,
    -0.0005716939922422171,
    -0.0406038761138916,
    -0.018434608355164528,
    0.033387281000614166,
    0.01063535176217556,
    -0.012980042956769466,
    0.006307500414550304,
    0.029371822252869606,
    -0.01712888292968273,
    0.01458763051778078,
    0.043243408203125,
    -0.012762421742081642,
    0.021411104127764702,
    0.004899983759969473,
    0.015570435672998428,
    -0.009189224801957607,
    -0.0009775396902114153,
    -0.006848043296486139,
    -0.012944942340254784,
    0.010649391449987888,
    -0.014292789623141289,
    0.011800677515566349,
    -0.009589366614818573,
    -0.012032338418066502,
    0.022829150781035423,
    -0.022337747737765312,
    -0.01813976839184761,
    -0.0012864212039858103,
    -0.026493608951568604,
    -0.0026869180146604776,
    0.00533873587846756,
    -0.028922539204359055,
    0.03389272466301918,
    0.031225111335515976,
    0.010235209949314594,
    -0.033387281000614166,
    0.007715017534792423,
    0.00720255495980382,
    -0.007216595113277435,
    0.00636366056278348,
    -0.023095911368727684,
    0.013520585373044014,
    -0.0064268410205841064,
    0.0057388776913285255,
    0.018729450181126595,
    -0.017985327169299126,
    -0.0138996671885252,
    0.021748065948486328,
    -0.002792218467220664,
    0.03945259004831314,
    -0.02691481076180935,
    -0.004496331792324781,
    0.03375232219696045,
    -0.009020743891596794,
    -0.037880104035139084,
    -0.10226785391569138,
    -0.021326862275600433,
    0.010045669041574001,
    0.03159015253186226,
    -0.018378449603915215,
    0.006483001168817282,
    -0.010010568425059319,
    0.042513325810432434,
    -0.020624859258532524,
    0.007792237680405378,
    -0.016174158081412315,
    -0.00999652873724699,
    0.003051959676668048,
    0.009006703272461891,
    -0.008662722073495388,
    -0.0068445331417024136,
    -0.02563716471195221,
    0.003843468613922596,
    -0.04175516217947006,
    0.006953343749046326,
    -0.02479475922882557,
    -0.010389650240540504,
    0.0014943897258490324,
    -0.003051959676668048,
    -0.0058406684547662735,
    -0.016876161098480225,
    -0.037178099155426025,
    0.024696478620171547,
    0.0009161144262179732,
    0.010930192656815052,
    0.009750827215611935,
    -0.05214481055736542,
    0.01941741444170475,
    0.011786636896431446,
    0.01614607870578766,
    0.015430035069584846,
    -0.0344262458384037,
    -0.02334863319993019,
    0.020287897437810898,
    -0.004096189979463816,
    0.016735760495066643,
    0.0033731262665241957,
    -0.0006625156966038048,
    -0.01204637810587883,
    -0.043131086975336075,
    0.005068464670330286,
    -0.03234831616282463,
    0.020063256844878197,
    0.028978699818253517,
    -0.014194509014487267,
    0.0036328674759715796,
    -0.0023920766543596983,
    -0.009168164804577827,
    -0.0029484143014997244,
    0.0019515694584697485,
    -0.013120443560183048,
    0.004299770575016737,
    0.005454566329717636,
    -0.002300816122442484,
    -0.01826612837612629,
    -0.01195511780679226,
    0.005861728452146053,
    0.007392095867544413,
    0.004405071493238211,
    0.007729057222604752,
    0.0013232764322310686,
    -0.003588992403820157,
    -0.0042646704241633415,
    0.030298465862870216,
    -0.017971286550164223,
    -0.025215962901711464,
    -0.0015066748019307852,
    -0.014545510523021221,
    0.006093389354646206,
    -0.029456062242388725,
    -0.01381542719900608,
    -0.007553556468337774,
    -0.026226846501231194,
    0.007420175708830357,
    0.006114449817687273,
    -0.02143918350338936,
    0.004271690733730793,
    -0.003903138916939497,
    -0.014138348400592804,
    0.008627621456980705,
    0.01976841501891613,
    0.003216930665075779,
    -0.013050243258476257,
    0.014180468395352364,
    -0.03824514523148537,
    0.04751158878207207,
    0.0023271413519978523,
    0.04206404462456703,
    -0.00635313056409359,
    -0.007778197526931763,
    0.005616027396172285,
    -0.040042273700237274,
    -0.0009143594070337713,
    0.007272755261510611,
    0.029905345290899277,
    -0.030691588297486305,
    -0.006637441925704479,
    -0.08064614981412888,
    0.033106479793787,
    0.020624859258532524,
    -0.023222273215651512,
    0.019094493240118027,
    0.00017824304813984782,
    -0.009806987829506397,
    -0.009975467808544636,
    0.01601971685886383,
    0.01752200536429882,
    -0.03762738034129143,
    -0.008129199035465717,
    -0.0036328674759715796,
    0.006714662536978722,
    -0.013513565063476562,
    -0.00698142359033227,
    0.020666979253292084,
    -7.815271965228021e-05,
    0.03330304101109505,
    0.004387521184980869,
    -0.013443364761769772,
    -0.012144658714532852,
    0.03251679614186287,
    0.018069567158818245,
    -0.0317586325109005,
    -0.00334855611436069,
    -0.026268966495990753,
    0.01618819870054722,
    -0.01667959988117218,
    -0.004717462696135044,
    0.003467896720394492,
    -0.0034222665708512068,
    -0.01906641200184822,
    0.003934728913009167,
    -0.007813298143446445,
    -0.027546612545847893,
    0.029315661638975143,
    0.005279065575450659,
    0.015275593847036362,
    0.017507964745163918,
    -0.015401954762637615,
    -0.039031390100717545,
    -0.0012688711285591125,
    -0.01447531022131443,
    -0.010523030534386635,
    -0.007700977381318808,
    0.017507964745163918,
    -0.0126852011308074,
    0.00222886074334383,
    -0.0067953928373754025,
    0.05248177424073219,
    0.01769048534333706,
    -0.0013390714302659035,
    -0.038890987634658813,
    -0.008704842068254948,
    0.001296951319091022,
    0.03818898648023605,
    0.003615317400544882,
    -0.0030607348307967186,
    -0.01826612837612629,
    0.03953683003783226,
    0.03389272466301918,
    0.015008832328021526,
    -0.002592147560790181,
    0.018659250810742378,
    -0.0291191004216671,
    -0.029371822252869606,
    -0.006858573295176029,
    -0.007511436473578215,
    -0.030691588297486305,
    0.007630777079612017,
    -0.029062939807772636,
    0.014938632026314735,
    0.014187488704919815,
    -0.002604432636871934,
    -0.01690424233675003,
    0.007265734951943159,
    -0.029231421649456024,
    -0.04144627973437309,
    0.03597065433859825,
    0.011302255094051361,
    -0.007729057222604752,
    0.013015142641961575,
    0.019740335643291473,
    0.03560561314225197,
    -0.03088814951479435,
    -0.02091970108449459,
    0.03720618039369583,
    -0.01645495928823948,
    -0.0007331548258662224,
    -0.0013469690456986427,
    0.024373557418584824,
    0.006581281777471304,
    0.004215530585497618,
    -0.0008248540107160807,
    0.002602677559480071,
    0.006749762687832117,
    0.012481620535254478,
    0.032320234924554825,
    -0.008262580260634422,
    0.011716436594724655,
    -0.00019612220057751983,
    -0.0016146078705787659,
    -0.007420175708830357,
    -0.020554659888148308,
    -0.010143948718905449,
    0.0059284185990691185,
    -0.015682755038142204,
    0.003924198914319277,
    0.001454024575650692,
    0.007504416164010763,
    -0.013422304764389992,
    -0.013850526884198189,
    0.012909842655062675,
    -0.012874742038547993,
    0.027967816218733788,
    0.005173765122890472,
    -0.018673289567232132,
    -0.02638128772377968,
    -0.0067357225343585014,
    0.015738915652036667,
    -0.004868393763899803,
    0.03650417551398277,
    0.00880312267690897,
    0.0275887344032526,
    0.03406120464205742,
    0.0013241538545116782,
    -0.02285723015666008,
    0.03425776585936546,
    0.00572483753785491,
    -0.029624544084072113,
    0.0176483653485775,
    -0.006756782531738281,
    -0.0174237247556448,
    -0.032853759825229645,
    -0.033696163445711136,
    -0.007785217836499214,
    -0.018869850784540176,
    0.030438866466283798,
    0.09822431206703186,
    -0.004531431943178177,
    -0.01624435931444168,
    -0.02157958410680294,
    -0.024598199874162674,
    0.014840351417660713,
    -0.00572483753785491,
    0.012958982959389687,
    0.0021393552888184786,
    0.0019375294214114547,
    -0.037655461579561234,
    -0.022983592003583908,
    -0.023755794391036034,
    -0.0317867137491703,
    -0.014728031121194363,
    -0.0165532398968935,
    -0.026156647130846977,
    0.0075324964709579945,
    -0.006672542076557875,
    0.01620223931968212,
    0.02546868287026882,
    -0.02143918350338936,
    0.0024657868780195713,
    0.010972312651574612,
    -0.03080390952527523,
    0.000982804805971682,
    0.02501940168440342,
    0.013548665679991245,
    0.0046437522396445274,
    -0.05930524691939354,
    0.04315916821360588,
    0.007904558442533016,
    -0.027560653164982796,
    -0.04223252460360527,
    -0.0011284704087302089,
    0.028922539204359055,
    0.002597412560135126,
    0.010143948718905449,
    0.006886653136461973,
    0.012523740530014038,
    -0.004640242550522089,
    0.006472471170127392,
    -0.01396284718066454,
    -0.02763085439801216,
    0.021565543487668037,
    -0.004043539520353079,
    0.0038188984617590904,
    -0.018996212631464005,
    0.000849862874019891
  ]
}