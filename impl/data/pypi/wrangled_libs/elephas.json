{
  "classifiers": [
    "license :: osi approved :: mit license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "distributed deep learning on spark with keras\n# elephas: distributed deep learning with keras & spark \n\n![elephas](https://raw.githubusercontent.com/danielenricocahall/elephas/master/elephas-logo.png)\n\n## \n\n[![build status](https://github.com/danielenricocahall/elephas/actions/workflows/ci.yaml/badge.svg)](https://github.com/danielenricocahall/elephas/actions/workflows/ci.yaml/badge.svg)\n[![license](https://img.shields.io/github/license/mashape/apistatus.svg?maxage=2592000)](https://github.com/danielenricocahall/elephas/blob/master/license)\n[![supported versions](https://img.shields.io/badge/python-3.8%20%7c%203.9%20%7c%203.10-blue)](https://img.shields.io/badge/python-3.8%20%7c%203.9%20%7c%203.10-blue)\n\nelephas is an extension of [keras](http://keras.io), which allows you to run distributed deep learning models at \nscale with [spark](http://spark.apache.org). elephas currently supports a number of \napplications, including:\n\n- [data-parallel training of deep learning models](#basic-spark-integration)\n- [distributed inference and evaluation of deep learning models](#distributed-inference-and-evaluation)\n- [~~distributed training of ensemble models~~](#distributed-training-of-ensemble-models)  (removed as of 3.0.0)\n- [~~distributed hyper-parameter optimization~~](#distributed-hyper-parameter-optimization)  (removed as of 3.0.0)\n\n\n\nschematically, elephas works as follows.\n\n![elephas](https://raw.githubusercontent.com/danielenricocahall/elephas/master/elephas.gif)\n\ntable of content:\n* [elephas: distributed deep learning with keras & spark](#elephas-distributed-deep-learning-with-keras-&-spark-)\n  * [introduction](#introduction)\n  * [getting started](#getting-started)\n  * [basic spark integration](#basic-spark-integration)\n  * [distributed inference and evaluation](#distributed-inference-and-evaluation)\n  * [spark mllib integration](#spark-mllib-integration)\n  * [spark ml integration](#spark-ml-integration)\n  * [hadoop integration](#hadoop-integration)\n  * [distributed hyper-parameter optimization](#distributed-hyper-parameter-optimization)\n  * [distributed training of ensemble models](#distributed-training-of-ensemble-models)\n  * [discussion](#discussion)\n  * [literature](#literature)\n\n\n\n## introduction\nelephas brings deep learning with [keras](http://keras.io) to [spark](http://spark.apache.org). elephas intends to \nkeep the simplicity and high usability of keras, thereby allowing for fast prototyping of distributed models, which \ncan be run on massive data sets. for an introductory example, see the following \n[ipython notebook](https://github.com/danielenricocahall/elephas/blob/master/examples/spark_ml_pipeline.ipynb).\n\n\u1f10\u03bb\u03ad\u03c6\u03b1\u03c2 is greek for _ivory_ and an accompanying project to \u03ba\u03ad\u03c1\u03b1\u03c2, meaning _horn_. if this seems weird mentioning, like \na bad dream, you should confirm it actually is at the \n[keras documentation](https://github.com/fchollet/keras/blob/master/readme.md). \nelephas also means _elephant_, as in stuffed yellow elephant.\n\nelephas implements a class of data-parallel algorithms on top of keras, using spark's rdds and data frames. \nkeras models are initialized on the driver, then serialized and shipped to workers, alongside with data and broadcasted \nmodel parameters. spark workers deserialize the model, train their chunk of data and send their gradients back to the \ndriver. the \"master\" model on the driver is updated by an optimizer, which takes gradients either synchronously or\nasynchronously.\n\n## getting started\n\njust install elephas from pypi with, spark will be installed through `pyspark` for you.\n\n```\npip install elephas\n```\n\nthat's it, you should now be able to run elephas examples.\n\n## basic spark integration\n\nafter installing both elephas, you can train a model as follows. first, create a local pyspark context\n```python\nfrom pyspark import sparkcontext, sparkconf\nconf = sparkconf().setappname('elephas_app').setmaster('local[8]')\nsc = sparkcontext(conf=conf)\n```\n\nnext, you define and compile a keras model\n```python\nfrom tensorflow.keras.models import sequential\nfrom tensorflow.keras.layers import dense, dropout, activation\nfrom tensorflow.keras.optimizers import sgd\nmodel = sequential()\nmodel.add(dense(128, input_dim=784))\nmodel.add(activation('relu'))\nmodel.add(dropout(0.2))\nmodel.add(dense(128))\nmodel.add(activation('relu'))\nmodel.add(dropout(0.2))\nmodel.add(dense(10))\nmodel.add(activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd())\n```\n\nand create an rdd from numpy arrays (or however you want to create an rdd)\n```python\nfrom elephas.utils.rdd_utils import to_simple_rdd\nrdd = to_simple_rdd(sc, x_train, y_train)\n```\n\nthe basic model in elephas is the `sparkmodel`. you initialize a `sparkmodel` by passing in a compiled keras model, \nan update frequency and a parallelization mode. after that you can simply `fit` the model on your rdd. elephas `fit`\nhas the same options as a keras model, so you can pass `epochs`, `batch_size` etc. as you're used to from tensorflow.keras.\n\n```python\nfrom elephas.spark_model import sparkmodel\n\nspark_model = sparkmodel(model, frequency='epoch', mode='asynchronous')\nspark_model.fit(rdd, epochs=20, batch_size=32, verbose=0, validation_split=0.1)\n```\n\nyour script can now be run using spark-submit\n```bash\nspark-submit --driver-memory 1g ./your_script.py\n```\n\nincreasing the driver memory even further may be necessary, as the set of parameters in a network may be very large \nand collecting them on the driver eats up a lot of resources. see the examples folder for a few working examples.\n\n## distributed inference and evaluation\n\nthe `sparkmodel` can also be used for distributed inference (prediction) and evaluation. similar to the `fit` method,  the `predict` and `evaluate` methods\nconform to the keras model api. \n\n```python\nfrom elephas.spark_model import sparkmodel\n\n# create/train the model, similar to the previous section (basic spark integration)\nmodel = ...\nspark_model = sparkmodel(model, ...)\nspark_model.fit(...)\n\nx_test, y_test = ... # load test data\n\npredictions = spark_model.predict(x_test) # perform inference\nevaluation = spark_model.evaluate(x_test, y_test) # perform evaluation/scoring\n```\nthe paradigm is identical to the data parallelism in training, as the model is serialized and shipped to the workers and used to evaluate a chunk of the testing data. the predict method will take either a numpy array or an rdd.\n\n## spark mllib integration\n\nfollowing up on the last example, to use spark's mllib library with elephas, you create an rdd of labeledpoints for \nsupervised training as follows\n\n```python\nfrom elephas.utils.rdd_utils import to_labeled_point\nlp_rdd = to_labeled_point(sc, x_train, y_train, categorical=true)\n```\n\ntraining a given labeledpoint-rdd is very similar to what we've seen already\n\n```python\nfrom elephas.spark_model import sparkmllibmodel\nspark_model = sparkmllibmodel(model, frequency='batch', mode='hogwild')\nspark_model.train(lp_rdd, epochs=20, batch_size=32, verbose=0, validation_split=0.1, \n                  categorical=true, nb_classes=nb_classes)\n```\n\n\n## spark ml integration\n\nto train a model with a sparkml estimator on a data frame, use the following syntax.\n```python\ndf = to_data_frame(sc, x_train, y_train, categorical=true)\ntest_df = to_data_frame(sc, x_test, y_test, categorical=true)\n\nestimator = elephasestimator(model, epochs=epochs, batch_size=batch_size, frequency='batch', mode='asynchronous',\n                             categorical=true, nb_classes=nb_classes)\nfitted_model = estimator.fit(df)\n```\n\nfitting an estimator results in a sparkml transformer, which we can use for predictions and other evaluations by \ncalling the transform method on it.\n\n```python\nprediction = fitted_model.transform(test_df)\npnl = prediction.select(\"label\", \"prediction\")\npnl.show(100)\nimport numpy as np\nprediction_and_label = pnl.rdd.map(lambda row: (row.label, float(np.argmax(row.prediction))))\n\nmetrics = multiclassmetrics(prediction_and_label)\nprint(metrics.weightedprecision)\nprint(metrics.weightedrecall)\n```\n\nif the model utilizes custom activation function, layer, or loss function, that will need to be supplied using the `set_custom_objects` method:\n\n```python\ndef custom_activation(x):\n    ...\nclass customlayer(layer):\n    ...\nmodel = sequential()\nmodel.add(customlayer(...))\n\nestimator = elephasestimator(model, epochs=epochs, batch_size=batch_size)\nestimator.set_custom_objects({'custom_activation': custom_activation, 'customlayer': customlayer})\n```\n\n## hadoop integration\n\nin addition to saving locally, models may be saved directly into a network-accessible hadoop cluster.\n\n```python\nspark_model.save('/absolute/file/path/model.h5', to_hadoop=true)\n```\n\nmodels saved on a network-accessible hadoop cluster may be loaded as follows.\n\n```python\nfrom elephas.spark_model import load_spark_model\n\nspark_model = load_spark_model('/absolute/file/path/model.h5', from_hadoop=true)\n```\n\n## distributed hyper-parameter optimization\n\n<span style=\"color:red\">**update**: as of 3.0.0, hyper-parameter optimization features have been removed, since hyperas is no longer active and was causing versioning compatibility issues. to use these features, install version 2.1 or below.</span>\n\nhyper-parameter optimization with elephas is based on [hyperas](https://github.com/maxpumperla/hyperas), a convenience \nwrapper for hyperopt and keras. each spark worker executes a number of trials, the results get collected and the best \nmodel is returned. as the distributed mode in hyperopt (using mongodb), is somewhat difficult to configure and error \nprone at the time of writing, we chose to implement parallelization ourselves. right now, the only available \noptimization algorithm is random search.\n\nthe first part of this example is more or less directly taken from the hyperas documentation. we define data and model \nas functions, hyper-parameter ranges are defined through braces. see the hyperas documentation for more on how \nthis works.\n\n```python\nfrom hyperopt import status_ok\nfrom hyperas.distributions import choice, uniform\n\ndef data():\n    from tensorflow.keras.datasets import mnist\n    from tensorflow.keras.utils import to_categorical\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = x_train.reshape(60000, 784)\n    x_test = x_test.reshape(10000, 784)\n    x_train = x_train.astype('float32')\n    x_test = x_test.astype('float32')\n    x_train /= 255\n    x_test /= 255\n    nb_classes = 10\n    y_train = to_categorical(y_train, nb_classes)\n    y_test = to_categorical(y_test, nb_classes)\n    return x_train, y_train, x_test, y_test\n\n\ndef model(x_train, y_train, x_test, y_test):\n    from tensorflow.keras.models import sequential\n    from tensorflow.keras.layers import dense, dropout, activation\n    from tensorflow.keras.optimizers import rmsprop\n\n    model = sequential()\n    model.add(dense(512, input_shape=(784,)))\n    model.add(activation('relu'))\n    model.add(dropout({{uniform(0, 1)}}))\n    model.add(dense({{choice([256, 512, 1024])}}))\n    model.add(activation('relu'))\n    model.add(dropout({{uniform(0, 1)}}))\n    model.add(dense(10))\n    model.add(activation('softmax'))\n\n    rms = rmsprop()\n    model.compile(loss='categorical_crossentropy', optimizer=rms)\n\n    model.fit(x_train, y_train,\n              batch_size={{choice([64, 128])}},\n              nb_epoch=1,\n              show_accuracy=true,\n              verbose=2,\n              validation_data=(x_test, y_test))\n    score, acc = model.evaluate(x_test, y_test, show_accuracy=true, verbose=0)\n    print('test accuracy:', acc)\n    return {'loss': -acc, 'status': status_ok, 'model': model.to_json()}\n```\n\nonce the basic setup is defined, running the minimization is done in just a few lines of code:\n\n```python\nfrom elephas.hyperparam import hyperparammodel\nfrom pyspark import sparkcontext, sparkconf\n\n# create spark context\nconf = sparkconf().setappname('elephas_hyperparameter_optimization').setmaster('local[8]')\nsc = sparkcontext(conf=conf)\n\n# define hyper-parameter model and run optimization\nhyperparam_model = hyperparammodel(sc)\nhyperparam_model.minimize(model=model, data=data, max_evals=5)\n```\n\n## distributed training of ensemble models\n<span style=\"color:red\">**update**: as of 3.0.0, hyper-parameter optimization features have been removed, since hyperas is no longer active and was causing versioning compatibility issues. to use these features, install version 2.1 or below.</span>\n\nbuilding on the last section, it is possible to train ensemble models with elephas by means of running hyper-parameter \noptimization on large search spaces and defining a resulting voting classifier on the top-n performing models. \nwith ```data``` and ```model``` defined as above, this is a simple as running\n\n```python\nresult = hyperparam_model.best_ensemble(nb_ensemble_models=10, model=model, data=data, max_evals=5)\n```\nin this example an ensemble of 10 models is built, based on optimization of at most 5 runs on each of the spark workers.\n\n## discussion\n\npremature parallelization may not be the root of all evil, but it may not always be the best idea to do so. keep in \nmind that more workers mean less data per worker and parallelizing a model is not an excuse for actual learning. \nso, if you can perfectly well fit your data into memory *and* you're happy with training speed of the model consider \njust using keras.\n\none exception to this rule may be that you're already working within the spark ecosystem and want to leverage what's \nthere. the above sparkml example shows how to use evaluation modules from spark and maybe you wish to further process \nthe outcome of an elephas model down the road. in this case, we recommend to use elephas as a simple wrapper by setting \nnum_workers=1.\n\nnote that right now elephas restricts itself to data-parallel algorithms for two reasons. first, spark simply makes it \nvery easy to distribute data. second, neither spark nor theano make it particularly easy to split up the actual model \nin parts, thus making model-parallelism practically impossible to realize.\n\nhaving said all that, we hope you learn to appreciate elephas as a pretty easy to setup and use playground for \ndata-parallel deep-learning algorithms.\n\n\n## literature\n[1] j. dean, g.s. corrado, r. monga, k. chen, m. devin, qv. le, mz. mao, m\u2019a. ranzato, a. senior, p. tucker, k. yang, and ay. ng. [large scale distributed deep networks](http://research.google.com/archive/large_deep_networks_nips2012.html).\n\n[2] f. niu, b. recht, c. re, s.j. wright [hogwild!: a lock-free approach to parallelizing stochastic gradient descent](http://arxiv.org/abs/1106.5730)\n\n[3] c. noel, s. osindero. [dogwild! \u2014 distributed hogwild for cpu & gpu](http://stanford.edu/~rezab/nips2014workshop/submits/dogwild.pdf)\n\n## maintainers / contributions\n\nthis great project was started by max pumperla, and is currently maintained by daniel cahall (https://github.com/danielenricocahall). if you have any questions, please feel free to open up an issue or send an email to danielenricocahall@gmail.com. if you want to contribute, feel free to submit a pr, or start a conversation about how we can go about implementing something.\n\n## star history\n\n[![star history chart](https://api.star-history.com/svg?repos=danielenricocahall/elephas&type=date)](https://star-history.com/#danielenricocahall/elephas&date)\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "elephas",
  "package_url": "https://pypi.org/project/elephas/",
  "project_url": "https://pypi.org/project/elephas/",
  "project_urls": {
    "Homepage": "https://danielenricocahall.github.io/elephas/"
  },
  "release_url": "https://pypi.org/project/elephas/5.0.0/",
  "requires_dist": [
    "tensorflow (>2.2,<=2.14)",
    "Flask (>=2.2.3,<3.0.0)",
    "h5py (==3.8.0)",
    "pyspark (<=3.5.0)",
    "Cython (>=0.29.33,<0.30.0)",
    "numpy (==1.23.5)"
  ],
  "requires_python": ">=3.8,<3.12",
  "summary": "distributed deep learning on spark with keras",
  "version": "5.0.0",
  "releases": [],
  "developers": [
    "daniel_cahall",
    "danielenricocahall@gmail.com"
  ],
  "kwds": "elephas badge elephas_app elephas_hyperparameter_optimization large_deep_networks_nips2012",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_elephas",
  "homepage": "https://danielenricocahall.github.io/elephas/",
  "release_count": 39,
  "dependency_ids": [
    "pypi_cython",
    "pypi_flask",
    "pypi_h5py",
    "pypi_numpy",
    "pypi_pyspark",
    "pypi_tensorflow"
  ],
  "documentation_summary": "Elephas is a distributed deep learning framework that extends Keras for scalable training with Apache Spark. It supports data-parallel training, distributed inference, and evaluation of deep learning models. Elephas simplifies the process of prototyping distributed models on large datasets, maintaining Keras's ease of use. It operates by initializing Keras models on a driver, serializing them, and distributing them to Spark workers for training with data and model parameters. Elephas supports integration with Spark MLlib and Spark ML for leveraging Spark's machine learning library and Hadoop for model saving and loading. Notably, features like distributed hyper-parameter optimization and training of ensemble models were removed in version 3.0.0 due to compatibility issues. Elephas is designed for users already within the Spark ecosystem or those needing to distribute data across workers for deep learning tasks.",
  "embedding": [
    -0.032141804695129395,
    -0.012853936292231083,
    -0.0024579844903200865,
    -0.02356322854757309,
    0.014859317801892757,
    0.023047957569360733,
    0.01052825152873993,
    0.004567812662571669,
    -0.014399751089513302,
    -0.0323367714881897,
    -0.011454347521066666,
    0.00937933474779129,
    -0.022295938804745674,
    0.0027069165371358395,
    0.0026616561226546764,
    -0.0009321889374405146,
    0.0141908572986722,
    -0.019065046682953835,
    -0.005636652931571007,
    0.003589492989704013,
    0.023911384865641594,
    -0.014566865749657154,
    -0.019998107105493546,
    -0.035428401082754135,
    -0.01623801700770855,
    0.021571774035692215,
    0.016725435853004456,
    0.00652793375775218,
    -0.005218865349888802,
    -0.030749177560210228,
    0.03673746809363365,
    -0.017728127539157867,
    0.007081502117216587,
    -0.015054285526275635,
    -0.006312076468020678,
    -0.00817471370100975,
    0.02264409512281418,
    0.018285177648067474,
    0.050997957587242126,
    0.003899352392181754,
    0.017379971221089363,
    -0.0015632224967703223,
    -0.012700747698545456,
    -0.02278335765004158,
    -0.020179148763418198,
    0.013139424845576286,
    0.007673368323594332,
    -0.054925162345170975,
    0.021613553166389465,
    0.028688091784715652,
    0.010166168212890625,
    0.02042982168495655,
    -0.014371898956596851,
    0.004519070964306593,
    0.014511161483824253,
    -0.013125498779118061,
    -0.012401333078742027,
    0.004821966867893934,
    -0.003093370236456394,
    0.0102288369089365,
    0.018145915120840073,
    0.01140560582280159,
    -0.04228011891245842,
    -0.015054285526275635,
    -0.0025171712040901184,
    -0.009428076446056366,
    -0.0030272204894572496,
    0.007805667817592621,
    0.0039898729883134365,
    0.010980854742228985,
    0.036988142877817154,
    0.02205919288098812,
    -0.01956639252603054,
    -0.004111727699637413,
    0.002325685229152441,
    -0.016474762931466103,
    0.007742999587208033,
    0.010939075611531734,
    -0.02292262203991413,
    -0.02533186413347721,
    -0.004122172482311726,
    -0.028228525072336197,
    -0.0062250373885035515,
    0.01866118609905243,
    0.02438487857580185,
    0.0005344201344996691,
    -0.03514987602829933,
    0.007944930344820023,
    -0.03670961782336235,
    0.01953854039311409,
    0.017352117225527763,
    0.005546132568269968,
    0.008766579441726208,
    0.01701788790524006,
    0.0004025559173896909,
    0.012338664382696152,
    -0.006848237477242947,
    -0.002379649318754673,
    0.008014561608433723,
    -0.016948256641626358,
    -0.015082137659192085,
    0.011168858967721462,
    -0.011182785034179688,
    -0.011217600665986538,
    -0.03899352252483368,
    0.0019949364941567183,
    -0.016070902347564697,
    0.012749489396810532,
    0.02286691591143608,
    0.005511316936463118,
    -0.02118183858692646,
    0.05052446573972702,
    0.0037322372663766146,
    -0.05954867973923683,
    -0.006869127042591572,
    -0.008035451173782349,
    0.011718946509063244,
    -0.011523978784680367,
    -0.006381707731634378,
    -0.009581265971064568,
    -0.002092420356348157,
    -0.0001616751542314887,
    0.0026181365828961134,
    -0.007513216231018305,
    -0.008592501282691956,
    -0.002898402512073517,
    -0.004919450730085373,
    -0.02374427020549774,
    -0.007429658900946379,
    -0.02360500767827034,
    0.010131352581083775,
    -0.01948283612728119,
    0.019343573600053787,
    -0.01699003577232361,
    -0.023437893018126488,
    -0.0068064588122069836,
    -0.008954583667218685,
    -0.024691255763173103,
    -0.019232163205742836,
    -0.025721799582242966,
    0.0057828789576888084,
    0.015444220043718815,
    0.005946512334048748,
    -0.016558321192860603,
    -0.03186327964067459,
    0.023187220096588135,
    0.014385825023055077,
    0.023772122338414192,
    -0.0010636179940775037,
    0.005048268474638462,
    0.013731290586292744,
    -0.026696637272834778,
    0.010312394239008427,
    0.007645515725016594,
    0.0006384319276548922,
    -0.016502616927027702,
    -0.007422695867717266,
    0.007729073520749807,
    -0.014316193759441376,
    -0.0019287867471575737,
    0.005396425258368254,
    0.008300050161778927,
    -0.011851245537400246,
    0.013438839465379715,
    -0.001675502979196608,
    0.03361798822879791,
    0.01100174430757761,
    -0.00012446593609638512,
    -0.00975534413009882,
    -0.006308595184236765,
    -0.014873243868350983,
    0.025693947449326515,
    -0.029022322967648506,
    -0.002668619155883789,
    -0.012665932066738605,
    0.0014230895321816206,
    -0.009072957560420036,
    0.030442800372838974,
    -0.023034030571579933,
    -0.006019625347107649,
    0.03682102635502815,
    0.030275685712695122,
    0.014399751089513302,
    0.0164190586656332,
    0.015583482570946217,
    0.007401806302368641,
    -0.00860642734915018,
    -0.019273942336440086,
    0.012338664382696152,
    0.010333283804357052,
    0.019329646602272987,
    0.01946890912950039,
    -0.031361933797597885,
    -0.01615445874631405,
    -0.5771041512489319,
    0.006037033163011074,
    -0.01722678169608116,
    -0.027963927015662193,
    -0.03008071705698967,
    -0.008989399299025536,
    -0.006980536971241236,
    -0.014455456286668777,
    -0.016920404508709908,
    0.029635077342391014,
    -0.016516542062163353,
    -0.010166168212890625,
    -0.028883060440421104,
    -0.013438839465379715,
    -0.038742851465940475,
    -0.010730181820690632,
    0.0243291724473238,
    -0.02675234153866768,
    0.004292768891900778,
    -0.009407187812030315,
    -0.03019212745130062,
    0.002974997041746974,
    -0.014413677155971527,
    0.009219182655215263,
    -0.0024423175491392612,
    0.02758791856467724,
    0.003387562232092023,
    0.013564175926148891,
    0.029746487736701965,
    0.008474128320813179,
    -0.0244127307087183,
    0.02513689547777176,
    0.008592501282691956,
    0.010465582832694054,
    0.060718487948179245,
    -0.019998107105493546,
    -0.0323089174926281,
    0.05278052017092705,
    0.02272765338420868,
    0.056484904140233994,
    -0.03838076815009117,
    0.01342491339892149,
    0.010904259979724884,
    0.008070266805589199,
    0.011238490231335163,
    0.027323318645358086,
    0.0036556427367031574,
    -0.004626999143511057,
    0.008320939727127552,
    0.01212977059185505,
    -0.017700273543596268,
    -0.005758507642894983,
    -0.0028775131795555353,
    0.006980536971241236,
    0.010375062003731728,
    0.016948256641626358,
    0.013689511455595493,
    -0.009247035719454288,
    -0.012749489396810532,
    0.004261435009539127,
    0.015722746029496193,
    -0.014065520837903023,
    -0.0023848717100918293,
    -0.024691255763173103,
    -0.021335028111934662,
    0.004014243837445974,
    0.011280269362032413,
    -0.022421276196837425,
    0.014044631272554398,
    -0.043477777391672134,
    0.045176781713962555,
    -0.018870079889893532,
    0.01297927275300026,
    0.003937649540603161,
    0.011941766366362572,
    0.02529008500277996,
    0.03584618866443634,
    0.001283826888538897,
    -0.016140533611178398,
    0.03356228396296501,
    0.01381484791636467,
    -0.009636971168220043,
    -0.012777341529726982,
    -0.01796487346291542,
    0.037795864045619965,
    -0.0008716967422515154,
    0.005229310132563114,
    -0.006785569246858358,
    -0.0059325858019292355,
    0.006399115547537804,
    0.02696123532950878,
    0.016683656722307205,
    -0.009741418063640594,
    -0.0405811183154583,
    0.026668785139918327,
    -0.0020454192999750376,
    -0.002759139984846115,
    0.002179459435865283,
    -0.011447384022176266,
    -0.0244962889701128,
    -0.0008629928342998028,
    -0.01339009776711464,
    -0.015889860689640045,
    -0.003439785912632942,
    0.02116791345179081,
    0.005424277391284704,
    -0.03682102635502815,
    -0.0017660235753282905,
    0.01800665259361267,
    -0.03331160917878151,
    -0.03183542564511299,
    -0.016502616927027702,
    -0.01267985813319683,
    0.00901028886437416,
    0.02275550551712513,
    -0.032949525862932205,
    0.024579845368862152,
    0.014357971958816051,
    0.013222982175648212,
    -0.018605481833219528,
    0.017421748489141464,
    0.00430321367457509,
    -0.012749489396810532,
    -0.011739836074411869,
    0.004494699649512768,
    0.0008451497997157276,
    -0.018494071438908577,
    -0.008348791860044003,
    -0.011106191202998161,
    0.020095590502023697,
    0.012965346686542034,
    -0.012018361128866673,
    0.00818167719990015,
    -0.0033248942345380783,
    0.03395221754908562,
    0.004957748111337423,
    0.0204437468200922,
    0.009532523341476917,
    0.0162101648747921,
    -0.02597247250378132,
    -0.005218865349888802,
    0.015304957516491413,
    0.0001281650911550969,
    -0.014455456286668777,
    -0.033757250756025314,
    -0.010855518281459808,
    -0.01562526263296604,
    0.0030655176378786564,
    -0.008125972002744675,
    -0.007958856411278248,
    -0.020847609266638756,
    -0.006990981753915548,
    -0.022142751142382622,
    0.01509606372565031,
    -0.01228296011686325,
    -0.00898243673145771,
    -0.0016293722437694669,
    -0.000750277191400528,
    -0.013125498779118061,
    -0.027852516621351242,
    -0.002898402512073517,
    0.0324760340154171,
    -0.01881437562406063,
    0.008710874244570732,
    -0.040302593261003494,
    -0.0163494274020195,
    0.006336447317153215,
    0.013745216652750969,
    0.008049377240240574,
    -0.023994943127036095,
    -0.004355437122285366,
    -0.02764362283051014,
    0.005601837299764156,
    0.031417638063430786,
    0.011273305863142014,
    0.014163004234433174,
    0.00015155685832723975,
    0.002304795663803816,
    -0.01466435007750988,
    4.8891502046899404e-06,
    0.0067159379832446575,
    0.015402441844344139,
    -0.025888914242386818,
    -6.789051258238032e-05,
    0.030442800372838974,
    0.012860899791121483,
    0.037127405405044556,
    0.028771650046110153,
    -0.033757250756025314,
    0.011043522506952286,
    -0.013466691598296165,
    0.022323792800307274,
    -0.0102288369089365,
    0.027406876906752586,
    -0.00511093670502305,
    0.012756452895700932,
    0.028144968673586845,
    0.0031804093159735203,
    -0.009567339904606342,
    0.02279728464782238,
    0.015416367910802364,
    0.0023883532267063856,
    0.022323792800307274,
    -0.019844917580485344,
    0.004915968980640173,
    -0.02207311987876892,
    0.013905368745326996,
    -0.014030705206096172,
    0.001946194563060999,
    0.004661814775317907,
    0.006207629572600126,
    -0.014016779139637947,
    -0.04584524407982826,
    -0.0003862360608763993,
    -0.01714322343468666,
    0.010305430740118027,
    -0.028353862464427948,
    0.014413677155971527,
    -0.023883532732725143,
    0.013146387413144112,
    0.0032587444875389338,
    0.008648206479847431,
    0.030777031555771828,
    0.02530401200056076,
    0.010291504673659801,
    0.009657859802246094,
    0.02765754982829094,
    0.027936074882745743,
    0.012895715422928333,
    -0.019817065447568893,
    -0.003634753404185176,
    0.034537121653556824,
    -0.007589810993522406,
    -0.015249253250658512,
    0.00548346433788538,
    -0.012923567555844784,
    0.006869127042591572,
    -0.005006489809602499,
    0.019371425732970238,
    -0.040358297526836395,
    0.022463055327534676,
    0.02764362283051014,
    0.031222671270370483,
    -0.001095822430215776,
    0.0074087693355977535,
    0.012909641489386559,
    -0.013188166543841362,
    0.015458147041499615,
    -0.012429185211658478,
    0.005793323274701834,
    -0.013640769757330418,
    0.01095996517688036,
    0.01722678169608116,
    0.025596462190151215,
    0.017366044223308563,
    -0.014803612604737282,
    -0.0033701544161885977,
    0.012192439287900925,
    0.02285299077630043,
    0.016850773245096207,
    0.00901028886437416,
    0.0042335824109613895,
    0.03974553942680359,
    0.004978637211024761,
    0.021808519959449768,
    -0.03180757537484169,
    -0.013619880191981792,
    -0.014803612604737282,
    -0.028688091784715652,
    -0.018856152892112732,
    -0.009052067995071411,
    -0.018257325515151024,
    -0.010319357737898827,
    -0.024733034893870354,
    0.02116791345179081,
    0.0008999844430945814,
    0.024719107896089554,
    0.045093223452568054,
    0.03359013423323631,
    0.010570029728114605,
    -0.023103661835193634,
    -0.04241938143968582,
    0.003707866184413433,
    -0.005142271053045988,
    -0.015221400186419487,
    -0.01960817165672779,
    -0.03801868483424187,
    -0.00010635091894073412,
    -0.005218865349888802,
    0.04386771470308304,
    -0.0019253052305430174,
    0.026418112218379974,
    -0.012833046726882458,
    -0.00810508243739605,
    -0.02127932198345661,
    -0.012477927841246128,
    0.0325874425470829,
    -0.016488689929246902,
    0.0141908572986722,
    -0.014803612604737282,
    -0.0002715620503295213,
    0.010166168212890625,
    -0.01788131520152092,
    -0.00978319626301527,
    0.06177688017487526,
    0.0026808048132807016,
    0.004755817353725433,
    -0.010249726474285126,
    0.011217600665986538,
    -0.003246559062972665,
    0.00672986451536417,
    -0.011530942283570766,
    -0.0041465433314442635,
    -0.004285805858671665,
    0.005030860658735037,
    0.006548822857439518,
    0.03180757537484169,
    0.006245926953852177,
    0.04225226864218712,
    0.007596774026751518,
    -0.0067194197326898575,
    -0.021404659375548363,
    -0.013216018676757812,
    0.014511161483824253,
    0.032169654965400696,
    0.02523438073694706,
    -0.009031178429722786,
    0.010416841134428978,
    -0.04383986070752144,
    0.00026895085466094315,
    -0.016001271083950996,
    -0.005755026359111071,
    0.006190221756696701,
    0.015291031450033188,
    -0.02126539684832096,
    -0.0032831153366714716,
    0.0012742526596412063,
    0.0032221879810094833,
    -0.0005879492382518947,
    -0.006576675456017256,
    -0.021488215774297714,
    0.019970254972577095,
    0.008724801242351532,
    -0.0072068385779857635,
    0.011899988166987896,
    -0.018382661044597626,
    0.03345087170600891,
    -0.0071197994984686375,
    0.04144454374909401,
    0.012032287195324898,
    0.025443274527788162,
    -0.0009017252014018595,
    -0.0030811845790594816,
    -0.0006419134442694485,
    -0.004125654231756926,
    0.021516069769859314,
    0.03579048439860344,
    0.00672290101647377,
    -0.012484890408813953,
    0.03567907214164734,
    0.005692358128726482,
    0.027323318645358086,
    0.008522870019078255,
    -0.002506726421415806,
    0.01135686319321394,
    0.031445492058992386,
    -0.0035825299564749002,
    0.009483781643211842,
    -0.005984809715300798,
    -0.011955692432820797,
    -0.00668808538466692,
    0.014344045892357826,
    -0.014552939683198929,
    -0.006308595184236765,
    0.059938617050647736,
    -0.006733345799148083,
    -0.04247508943080902,
    -0.0014248302904888988,
    0.022964399307966232,
    -0.0016067420365288854,
    0.01880044862627983,
    -0.02605602890253067,
    -0.012101918458938599,
    -0.015862008556723595,
    -0.004007280804216862,
    -0.007931004278361797,
    -0.011705020442605019,
    0.009922458790242672,
    0.019176457077264786,
    0.02126539684832096,
    -0.005365090910345316,
    0.02276943251490593,
    -0.03902137652039528,
    -0.0027486952021718025,
    -0.020959017798304558,
    -0.030721325427293777,
    -0.022212382405996323,
    -0.0041082464158535,
    0.03631968051195145,
    0.011656277813017368,
    0.008035451173782349,
    -0.002771325409412384,
    -0.0064722285605967045,
    0.005236273165792227,
    0.018118061125278473,
    -0.006420005112886429,
    -0.013160314410924911,
    -0.04283716902136803,
    0.009643933735787868,
    -0.012436148710548878,
    0.008801395073533058,
    0.000281353946775198,
    0.016043050214648247,
    0.004626999143511057,
    0.011078338138759136,
    0.012819120660424232,
    0.0005357257323339581,
    -0.0008307883399538696,
    -0.0038297211285680532,
    1.3803859474137425e-05,
    0.016669731587171555,
    0.00689349789172411,
    0.00608577486127615,
    -0.01951068826019764,
    0.011245453730225563,
    -0.028715943917632103,
    -0.011572720482945442,
    0.0014674795093014836,
    0.00022303772857412696,
    -0.00689001614227891,
    0.009177404455840588,
    -0.007276469841599464,
    -0.032197508960962296,
    0.015318884514272213,
    0.00777085218578577,
    0.004567812662571669,
    0.012331701815128326,
    0.0014030705206096172,
    0.017338192090392113,
    -0.020805830135941505,
    -0.006057922262698412,
    0.016098754480481148,
    -0.030609915032982826,
    -0.011050486005842686,
    0.003592974739149213,
    -0.020025959238409996,
    0.02597247250378132,
    0.01499858032912016,
    -0.02264409512281418,
    0.03916063904762268,
    0.002550245961174369,
    -0.010639660991728306,
    -0.019803138449788094,
    0.014239598996937275,
    0.012540595605969429,
    0.032225362956523895,
    -0.013585064560174942,
    -0.018048429861664772,
    -0.017268560826778412,
    0.015277105383574963,
    -0.030275685712695122,
    0.013877516612410545,
    0.001979269552975893,
    -0.013724327087402344,
    -0.014566865749657154,
    -0.004759298637509346,
    -0.0005727173993363976,
    -0.019078973680734634,
    0.0016711510252207518,
    -0.029885750263929367,
    -0.03665391355752945,
    0.021697109565138817,
    -0.018271250650286674,
    0.001369995647110045,
    -0.016530469059944153,
    0.010514325462281704,
    0.015708819031715393,
    -0.010033869184553623,
    -0.031445492058992386,
    0.005354646127671003,
    0.0004969933652319014,
    0.00817471370100975,
    0.04133313521742821,
    0.04659726098179817,
    0.05389462038874626,
    -0.012310812249779701,
    0.025777503848075867,
    0.021404659375548363,
    -0.013306539505720139,
    -0.02533186413347721,
    -0.011008706875145435,
    0.018104135990142822,
    -0.007067576050758362,
    0.007387880235910416,
    0.022532686591148376,
    0.010702329687774181,
    -0.004156988114118576,
    -0.022602317854762077,
    0.006256371736526489,
    0.013202092610299587,
    0.0018104135524481535,
    -0.019399277865886688,
    -0.018118061125278473,
    -0.015082137659192085,
    -0.008125972002744675,
    0.023967090994119644,
    -0.0008825766271911561,
    0.018215546384453773,
    -0.02127932198345661,
    -0.0006654140306636691,
    0.02360500767827034,
    -0.014817538671195507,
    0.014552939683198929,
    0.013571138493716717,
    0.003780979197472334,
    -0.005904733669012785,
    0.028270304203033447,
    0.03921634331345558,
    0.03489920496940613,
    -0.007325212005525827,
    0.01136382669210434,
    -0.01779775880277157,
    -0.02118183858692646,
    0.016697583720088005,
    0.013919294811785221,
    0.031361933797597885,
    -0.0016641878755763173,
    0.022964399307966232,
    -0.0058211758732795715,
    0.018466219305992126,
    -0.003351005958393216,
    -0.0032796338200569153,
    0.017338192090392113,
    -0.038603588938713074,
    -0.02026270516216755,
    -0.015708819031715393,
    -0.023465745151042938,
    -0.025067264214158058,
    -0.03799083083868027,
    -0.006308595184236765,
    0.006754235364496708,
    0.010368099436163902,
    -0.015109989792108536,
    -0.016488689929246902,
    -0.0004952525487169623,
    0.009219182655215263,
    0.034648530185222626,
    6.223296804819256e-05,
    0.02264409512281418,
    0.017366044223308563,
    -0.003610382555052638,
    0.0008490665350109339,
    -0.01639120653271675,
    0.012150660157203674,
    -0.0004526033881120384,
    0.014156041666865349,
    0.015304957516491413,
    -0.04481469839811325,
    -0.015360662713646889,
    0.021613553166389465,
    -0.007756925653666258,
    -0.02776895835995674,
    -0.029857898131012917,
    0.04378415644168854,
    0.012143697589635849,
    0.025763578712940216,
    -0.022504832595586777,
    -0.0004347603826317936,
    -0.012338664382696152,
    -0.024691255763173103,
    -0.020694419741630554,
    0.004891598131507635,
    -0.003044628305360675,
    -0.03631968051195145,
    -0.017742052674293518,
    0.028270304203033447,
    0.01719892956316471,
    0.019162531942129135,
    -0.012923567555844784,
    -0.0019392314134165645,
    0.009428076446056366,
    -0.010354173369705677,
    -0.02693338319659233,
    -0.0064269681461155415,
    0.015848081558942795,
    0.02924514189362526,
    0.0005296330200508237,
    -0.007067576050758362,
    0.03570692613720894,
    0.005368572659790516,
    0.014399751089513302,
    -0.014733981341123581,
    -0.011572720482945442,
    0.03183542564511299,
    0.0011367308907210827,
    0.0033666728995740414,
    0.011342937126755714,
    -0.01430226769298315,
    -0.005984809715300798,
    -0.02359108068048954,
    -0.014023741707205772,
    -0.005051750224083662,
    -0.014803612604737282,
    0.019023269414901733,
    0.006155406124889851,
    -0.02207311987876892,
    -0.007589810993522406,
    -0.009950311854481697,
    0.0009896347764879465,
    -0.001949676196090877,
    -0.004449439700692892,
    -0.007339138071984053,
    0.010284542106091976,
    -0.03579048439860344,
    0.010166168212890625,
    -0.020917240530252457,
    -0.01967780292034149,
    0.009302740916609764,
    0.011231527663767338,
    0.02186422608792782,
    -0.010423804633319378,
    0.023827828466892242,
    0.0019723062869161367,
    -0.00689001614227891,
    0.015458147041499615,
    -0.010667514055967331,
    -0.03512202203273773,
    0.008042413741350174,
    -0.022518759593367577,
    3.2476469641551375e-05,
    0.012331701815128326,
    0.003620827104896307,
    -0.018424440175294876,
    -0.02119576558470726,
    -0.0050830841064453125,
    0.02271372638642788,
    0.008898879401385784,
    -0.005260644014924765,
    -0.011454347521066666,
    0.005511316936463118,
    0.017254633828997612,
    -0.015639187768101692,
    -0.02430132031440735,
    0.024705182760953903,
    0.0037600896321237087,
    -0.02036019042134285,
    -0.010173131711781025,
    -0.012881789356470108,
    0.005121381487697363,
    -0.03579048439860344,
    0.007687294390052557,
    -0.01942712999880314,
    -0.03935560584068298,
    -0.005845546722412109,
    -0.01012439001351595,
    0.0022734617814421654,
    -0.027838589623570442,
    0.03492705523967743,
    -0.006033551413565874,
    -0.01637727953493595,
    -0.029579373076558113,
    0.015263179317116737,
    0.01302105188369751,
    -0.015402441844344139,
    0.003638234920799732,
    0.006413042079657316,
    0.013633807189762592,
    0.010681440122425556,
    0.01639120653271675,
    -0.016530469059944153,
    -0.013773069716989994,
    0.004895079880952835,
    -0.04322710633277893,
    -0.019134679809212685,
    -0.00426839804276824,
    0.015834156423807144,
    0.01722678169608116,
    -0.02437095157802105,
    0.010876407846808434,
    -0.015597409568727016,
    -0.05049661174416542,
    0.00568191334605217,
    -0.021613553166389465,
    0.016795067116618156,
    -0.002261276124045253,
    0.02290869504213333,
    0.026292774826288223,
    -0.004184840712696314,
    0.02602817676961422,
    0.008432349190115929,
    -0.006047477480024099,
    0.014636497013270855,
    -0.010764997452497482,
    0.00773603655397892,
    -0.030637769028544426,
    -0.030526358634233475,
    -0.0648406594991684,
    0.012798231095075607,
    0.038714997470378876,
    -0.007951893843710423,
    -0.012359553948044777,
    0.018104135990142822,
    -0.003290078602731228,
    -0.010256689041852951,
    0.008049377240240574,
    0.007172022946178913,
    -0.0027817701920866966,
    0.012958383187651634,
    0.014037668704986572,
    -0.044285502284765244,
    -0.01956639252603054,
    -0.00030115534900687635,
    -0.0021864224690943956,
    -0.00692831352353096,
    -0.00033205421641469,
    0.021711036562919617,
    -0.034759942442178726,
    0.008738727308809757,
    -0.01615445874631405,
    0.015304957516491413,
    -0.013800921849906445,
    -0.012658968567848206,
    0.011635389178991318,
    -0.0013882739003747702,
    0.007485363632440567,
    0.0406646728515625,
    0.012624152936041355,
    0.0035546773578971624,
    -0.01052128802984953,
    -0.000692831352353096,
    -0.027058720588684082,
    0.005260644014924765,
    0.028270304203033447,
    -0.029161585494875908,
    0.011503089219331741,
    -0.01632157526910305,
    0.019023269414901733,
    -0.0325038880109787,
    0.003349265083670616,
    -0.011684130877256393,
    -0.00047392796841450036,
    -0.028284231200814247,
    0.023103661835193634,
    0.013167276978492737,
    -0.04305998980998993,
    -0.03899352252483368,
    0.026334553956985474,
    -0.00039994472172111273,
    -0.013104609213769436,
    -0.006785569246858358,
    0.023117588832974434,
    -0.005629689898341894,
    0.011245453730225563,
    -0.02049945294857025,
    -0.015416367910802364,
    -0.020736198872327805,
    0.005048268474638462,
    -0.011976581998169422,
    -0.039411310106515884,
    0.015416367910802364,
    0.18861724436283112,
    0.0074087693355977535,
    0.02187815122306347,
    0.0036765323020517826,
    0.03322805091738701,
    0.0163494274020195,
    0.006566230673342943,
    0.013111571781337261,
    -0.030721325427293777,
    0.021766740828752518,
    0.00901028886437416,
    -0.018104135990142822,
    -0.02194778248667717,
    0.005215383600443602,
    0.02375819720327854,
    -0.0005648838705383241,
    -0.0050796028226614,
    -0.017366044223308563,
    4.370995520730503e-05,
    -0.027991779148578644,
    0.00047871514107100666,
    -0.002047159941866994,
    -0.020903313532471657,
    -0.006559267640113831,
    0.013947147876024246,
    -0.019775286316871643,
    -0.0002608997456263751,
    0.0059813279658555984,
    0.011593610048294067,
    0.0008212140528485179,
    -0.01783953607082367,
    0.019065046682953835,
    0.018076283857226372,
    0.0038053500466048717,
    -0.0404975600540638,
    -0.03726666793227196,
    0.008641242980957031,
    0.004285805858671665,
    0.03322805091738701,
    0.008355755358934402,
    0.01700396090745926,
    -0.021460363641381264,
    -0.019023269414901733,
    -0.004853301215916872,
    0.003293560119345784,
    0.011287231929600239,
    -0.012958383187651634,
    0.0039446125738322735,
    -0.007492327131330967,
    0.01543029397726059,
    -0.03732237219810486,
    -0.02122361771762371,
    0.014873243868350983,
    0.029050175100564957,
    -0.008968510664999485,
    -0.0065140072256326675,
    -0.014942875131964684,
    0.02208704501390457,
    0.020583009347319603,
    0.020666567608714104,
    -0.012965346686542034,
    0.020791903138160706,
    0.008836210705339909,
    0.013633807189762592,
    -0.014678276143968105,
    -0.01616838574409485,
    -0.022142751142382622,
    0.02451021410524845,
    -0.010716255754232407,
    0.027922147884964943,
    -0.023841753602027893,
    -0.018870079889893532,
    -0.026710564270615578,
    -0.020694419741630554,
    -0.014552939683198929,
    -0.03308878839015961,
    0.028688091784715652,
    0.005246717948466539,
    0.03008071705698967,
    0.03478779271245003,
    -0.003450230462476611,
    0.014873243868350983,
    -0.005225828383117914,
    0.00733217503875494,
    -0.005970883183181286,
    -0.028938764706254005,
    0.03592974692583084,
    -0.011412568390369415,
    -0.020819755271077156,
    -0.009330593049526215,
    -0.022128824144601822,
    -0.01342491339892149,
    0.004891598131507635,
    -0.015792377293109894,
    0.00020911147294100374,
    -0.005831620655953884,
    -0.0010636179940775037,
    0.036291830241680145,
    -0.036347534507513046,
    0.009247035719454288,
    -0.02698908932507038,
    0.054089587181806564,
    0.02517867460846901,
    0.005441685207188129,
    -0.01012439001351595,
    0.007645515725016594,
    -0.0070536499843001366,
    0.011677167378365993,
    0.02285299077630043,
    -0.004097801633179188,
    0.0025345790199935436,
    -0.01625194400548935,
    -0.003895870642736554,
    -0.010618772357702255,
    0.009511634707450867,
    0.00470707518979907,
    0.0020976427476853132,
    0.005768952425569296,
    0.010806776583194733,
    0.008397533558309078,
    -0.011649315245449543,
    -0.025861062109470367,
    0.020624788478016853,
    0.0032987825106829405,
    -0.015750598162412643,
    -0.012094954960048199,
    -0.0324481800198555,
    0.023006178438663483,
    -0.006218074355274439,
    0.015527778305113316,
    0.013773069716989994,
    -0.035372696816921234,
    0.01857762783765793,
    0.01711537130177021,
    -0.0016267610481008887,
    -0.03890996426343918,
    -0.010375062003731728,
    0.005949994083493948,
    0.018452292308211327,
    -0.0004064726526848972,
    -0.032225362956523895,
    0.015458147041499615,
    0.010904259979724884,
    0.004289287608116865,
    -0.02520652674138546,
    -0.035372696816921234,
    0.01055610366165638,
    0.004755817353725433,
    -5.099948248243891e-05,
    -0.014176931232213974,
    -0.03010857105255127,
    0.0028896986041218042,
    -0.004752335604280233,
    -0.044313352555036545,
    0.03406362608075142,
    -0.02679412066936493,
    0.0019253052305430174,
    -0.009567339904606342,
    0.0019026750233024359,
    0.00047827992239035666,
    -0.040441855788230896,
    -0.005636652931571007,
    -0.004198766779154539,
    -0.01144042145460844,
    -0.02034626342356205,
    0.003735718782991171,
    -0.17535944283008575,
    -0.005661023780703545,
    0.011677167378365993,
    -0.04988385736942291,
    0.029746487736701965,
    0.00937933474779129,
    0.03253173828125,
    -0.007784778252243996,
    -0.022323792800307274,
    2.7634918296826072e-05,
    0.014316193759441376,
    -0.014497234486043453,
    -0.030498506501317024,
    -0.02930084802210331,
    -0.003711347933858633,
    -0.004383289720863104,
    0.019886696711182594,
    0.0035111578181385994,
    0.05353253707289696,
    0.020736198872327805,
    0.011141006834805012,
    -0.05133218690752983,
    -0.0003364061703905463,
    0.02445450983941555,
    -0.00777085218578577,
    -0.003015034832060337,
    -0.004418105352669954,
    0.009595192037522793,
    0.0035686036571860313,
    -0.03395221754908562,
    -0.014197819866240025,
    0.0007855279836803675,
    0.029078027233481407,
    0.007269506808370352,
    -0.0003244382969569415,
    0.007833519950509071,
    0.009400224313139915,
    -0.022240234538912773,
    -0.023256851360201836,
    0.027337245643138885,
    0.019803138449788094,
    0.005748063325881958,
    -0.006190221756696701,
    -0.004212693311274052,
    -0.003693940117955208,
    0.023034030571579933,
    -0.015750598162412643,
    -0.016683656722307205,
    2.9810897103743628e-05,
    -0.02349359728395939,
    0.019260015338659286,
    -0.014580792747437954,
    0.02264409512281418,
    0.004658333491533995,
    0.03002501279115677,
    0.011280269362032413,
    0.012443112209439278,
    0.013543286360800266,
    0.028200672939419746,
    -0.0243291724473238,
    0.010326320305466652,
    -0.018090208992362022,
    0.01699003577232361,
    -0.023312555626034737,
    0.009581265971064568,
    -0.015778450295329094,
    -0.031417638063430786,
    0.03813009336590767,
    -0.03431430086493492,
    0.005591392517089844,
    0.01345276553183794,
    0.029467962682247162,
    -0.02034626342356205,
    0.009337556548416615,
    0.021502142772078514,
    0.010131352581083775,
    -0.023270778357982635,
    0.01785346306860447,
    0.030777031555771828,
    -0.003972465172410011,
    -0.023465745151042938,
    0.04643014445900917,
    0.004550404846668243,
    0.0055322060361504555,
    -0.00850894395262003,
    -0.018159840255975723,
    -0.0033544874750077724,
    -0.0036277903709560633,
    -0.024203836917877197,
    -0.0072068385779857635,
    0.009581265971064568,
    -0.025081191211938858,
    0.00531634921208024,
    -0.004564331378787756,
    0.0025415420532226562,
    0.019329646602272987,
    -0.010040832683444023,
    -0.007036242168396711,
    0.007798704784363508,
    0.0009574302821420133,
    0.0017225040355697274,
    0.01881437562406063,
    -0.024482361972332,
    0.01778383180499077,
    0.03604115545749664,
    0.028715943917632103,
    -0.028910912573337555,
    0.0032796338200569153,
    0.04559456929564476,
    -0.01385662704706192,
    -0.011064412072300911,
    -0.006816903594881296,
    0.02534578926861286,
    0.048574790358543396,
    0.0005274570430628955,
    0.004355437122285366,
    0.00809811893850565,
    0.0013343095779418945,
    0.042809318751096725,
    0.004515589214861393,
    0.048546936362981796,
    -0.024022795259952545,
    -0.02207311987876892,
    0.019761361181735992,
    -0.026668785139918327,
    -0.041277430951595306,
    -0.10177309811115265,
    -0.02696123532950878,
    0.013515433296561241,
    0.0243291724473238,
    -0.0012490112567320466,
    0.007596774026751518,
    -0.006653269752860069,
    0.021390732377767563,
    -0.02863238751888275,
    0.014239598996937275,
    -0.009483781643211842,
    -0.005201457533985376,
    0.007436621934175491,
    -0.005229310132563114,
    0.01637727953493595,
    -0.007527142763137817,
    -0.02295047417283058,
    -0.00608229311183095,
    0.012484890408813953,
    0.019942400977015495,
    -0.005466056521981955,
    -0.023939238861203194,
    -0.012032287195324898,
    -0.001140212407335639,
    0.0015536481514573097,
    0.008641242980957031,
    -0.025610389187932014,
    0.011245453730225563,
    0.0032152249477803707,
    0.0026198772247880697,
    -0.00014470252790488303,
    -0.0283817145973444,
    -0.0007733425591140985,
    -0.002498022513464093,
    -0.008418423123657703,
    -0.02782466448843479,
    -0.015402441844344139,
    -0.016934329643845558,
    0.026334553956985474,
    -0.032281067222356796,
    0.01880044862627983,
    0.018257325515151024,
    -0.0024196873418986797,
    0.027351170778274536,
    -0.01630764827132225,
    0.016614025458693504,
    -0.0030098126735538244,
    0.0328102633357048,
    0.03147334232926369,
    -0.0163633543998003,
    -0.021752815693616867,
    -0.011189748533070087,
    -0.00608229311183095,
    0.018382661044597626,
    0.024886224418878555,
    0.01349454466253519,
    0.016711510717868805,
    0.014072484336793423,
    -0.019051121547818184,
    -0.015973418951034546,
    0.017477454617619514,
    0.003680013818666339,
    0.018326956778764725,
    -0.0015815007500350475,
    0.00447381054982543,
    -0.016614025458693504,
    -0.028771650046110153,
    -0.0030951108783483505,
    0.008662132546305656,
    -0.019830992445349693,
    -0.011746798641979694,
    0.009943348355591297,
    -0.01864725910127163,
    0.005497390404343605,
    -0.03668176382780075,
    -0.009128662757575512,
    -0.01945498213171959,
    -0.02615351229906082,
    0.016029123216867447,
    0.006078811828047037,
    -0.01857762783765793,
    0.005211902316659689,
    0.016627952456474304,
    -0.016767214983701706,
    0.0018974527483806014,
    0.007729073520749807,
    0.016502616927027702,
    -0.006409560330212116,
    0.017505306750535965,
    -0.039411310106515884,
    0.0020401969086378813,
    -0.003693940117955208,
    0.016070902347564697,
    0.0013195129577070475,
    -0.013118535280227661,
    -0.029830045998096466,
    -0.007624626625329256,
    0.00025154303875751793,
    -0.009483781643211842,
    0.019218236207962036,
    -0.016822919249534607,
    0.0023030550219118595,
    -0.06729167699813843,
    0.009957274422049522,
    0.0018835264490917325,
    -0.02205919288098812,
    -0.01700396090745926,
    -0.03191898390650749,
    -0.008376643992960453,
    0.002280424814671278,
    0.0016763733001425862,
    0.0064687468111515045,
    -0.016460837796330452,
    0.009059030562639236,
    -0.006305113434791565,
    0.0018991935066878796,
    -0.027281539514660835,
    -0.02295047417283058,
    0.02516474947333336,
    -0.019956327974796295,
    0.054061733186244965,
    0.014413677155971527,
    -0.027963927015662193,
    0.013216018676757812,
    0.028660239651799202,
    0.00588036235421896,
    -0.033645838499069214,
    -0.022449128329753876,
    0.0022960917558521032,
    0.023911384865641594,
    -0.010006016120314598,
    -0.003495490876957774,
    0.010054758749902248,
    -0.015834156423807144,
    -0.01857762783765793,
    0.012965346686542034,
    0.017421748489141464,
    -0.005988290999084711,
    0.034592825919389725,
    0.013689511455595493,
    0.007471437565982342,
    0.028688091784715652,
    -0.03086058795452118,
    -0.032030392438173294,
    0.013069793581962585,
    0.005768952425569296,
    -0.002092420356348157,
    0.013000162318348885,
    0.018271250650286674,
    0.008146860636770725,
    -0.010458620265126228,
    0.013313503004610538,
    0.032893821597099304,
    0.007575884461402893,
    -0.02210097201168537,
    -0.039327751845121384,
    0.000821649213321507,
    -0.006280742585659027,
    0.0325874425470829,
    -0.012840010225772858,
    0.0163633543998003,
    0.002625099616125226,
    0.026654858142137527,
    0.016530469059944153,
    0.002059345366433263,
    -0.010145279578864574,
    -0.01958031952381134,
    -0.018354808911681175,
    -0.02774110622704029,
    -0.025526830926537514,
    -0.024008870124816895,
    -0.033729396760463715,
    -0.023187220096588135,
    -0.01945498213171959,
    0.008871026337146759,
    0.023215072229504585,
    0.0019235644722357392,
    -0.015653114765882492,
    -0.017324265092611313,
    -0.02047159895300865,
    -0.028117114678025246,
    0.03723881393671036,
    0.020972944796085358,
    -0.010604845359921455,
    -0.009804085828363895,
    0.023117588832974434,
    0.03849217668175697,
    -0.0012490112567320466,
    -0.0070536499843001366,
    -0.004076912067830563,
    -0.0019374906551092863,
    0.017366044223308563,
    -0.01389144267886877,
    0.031111260876059532,
    -0.013118535280227661,
    0.02275550551712513,
    0.02042982168495655,
    -0.0040351334027945995,
    -0.02116791345179081,
    -0.008898879401385784,
    0.01298623625189066,
    0.02375819720327854,
    0.00016472152492497116,
    0.003930686507374048,
    0.01267289463430643,
    -0.0001767982030287385,
    -0.02360500767827034,
    -0.012700747698545456,
    0.013975000008940697,
    -0.012352591380476952,
    0.004414624068886042,
    0.01386359054595232,
    0.007791741285473108,
    -0.030275685712695122,
    0.0010200984543189406,
    0.015123916789889336,
    -0.007575884461402893,
    0.0327267087996006,
    0.031361933797597885,
    -0.026390260085463524,
    -0.0161962378770113,
    0.008327902294695377,
    0.01052825152873993,
    0.016683656722307205,
    0.016878625378012657,
    -0.015667039901018143,
    0.035511959344148636,
    0.020791903138160706,
    0.00527805183082819,
    0.006447857711464167,
    0.01019402127712965,
    0.016056975349783897,
    0.004042096436023712,
    0.039327751845121384,
    -0.021362880244851112,
    -0.011196712031960487,
    -0.02194778248667717,
    0.01052128802984953,
    -0.0080633033066988,
    -0.0032134840730577707,
    0.019329646602272987,
    0.09263747185468674,
    0.0020175667013972998,
    -0.0489368699491024,
    0.015179621987044811,
    -0.017240706831216812,
    0.006402597296983004,
    -0.006970092188566923,
    0.016753287985920906,
    -0.001009653671644628,
    0.012143697589635849,
    -0.018563702702522278,
    -0.01059091929346323,
    -0.03400792181491852,
    -0.015277105383574963,
    -0.024162057787179947,
    -0.011628425680100918,
    -0.004254471976310015,
    0.034676384180784225,
    -0.0002702564524952322,
    0.007022315636277199,
    0.03411933407187462,
    0.007805667817592621,
    0.0025624316185712814,
    0.0011645833728834987,
    -0.031222671270370483,
    0.010347209870815277,
    0.05542650818824768,
    0.04659726098179817,
    0.01793702132999897,
    -0.05358824133872986,
    0.010869444347918034,
    -0.005347683094441891,
    -0.027546139433979988,
    -0.012122808024287224,
    -0.005528724752366543,
    0.05030164495110512,
    0.02690553106367588,
    -0.029690783470869064,
    0.024593772366642952,
    -0.006012661848217249,
    -0.02290869504213333,
    0.003979428205639124,
    -0.012763415463268757,
    -0.04464758560061455,
    0.00861339084804058,
    0.006830829661339521,
    -0.01260326337069273,
    -0.008125972002744675,
    -0.03821365162730217
  ]
}