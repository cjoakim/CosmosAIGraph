{
  "libtype": "pypi",
  "libname": "taming-transformers",
  "url": "https://github.com/compvis/taming-transformers",
  "html": "<!DOCTYPE html><html  lang=\"en\"    data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-theme=\"dark\"  data-a11y-animated-images=\"system\" data-a11y-link-underlines=\"true\"  >  <head>    <meta charset=\"utf-8\">  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">  <link rel=\"preconnect\" href=\"https://github.githubassets.com\" crossorigin>  <link rel=\"preconnect\" href=\"https://avatars.githubusercontent.com\">    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/light-0eace2597ca3.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/dark-a167e256da9c.css\" /><link data-color-theme=\"dark_dimmed\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_dimmed-d11f2cf8009b.css\" /><link data-color-theme=\"dark_high_contrast\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_high_contrast-ea7373db06c8.css\" /><link data-color-theme=\"dark_colorblind\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_colorblind-afa99dcf40f7.css\" /><link data-color-theme=\"light_colorblind\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_colorblind-af6c685139ba.css\" /><link data-color-theme=\"light_high_contrast\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_high_contrast-578cdbc8a5a9.css\" /><link data-color-theme=\"light_tritanopia\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_tritanopia-5cb699a7e247.css\" /><link data-color-theme=\"dark_tritanopia\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_tritanopia-9b32204967c6.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/primer-primitives-2ef2a46b27ee.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/primer-711f412bb361.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/global-4803cd254267.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/github-f4d857cbc96a.css\" />  <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/repository-6247ca238fd4.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/code-6d7b4ef0ea51.css\" />    <script type=\"application/json\" id=\"client-env\">{\"locale\":\"en\",\"featureFlags\":[\"code_vulnerability_scanning\",\"copilot_conversational_ux_history_refs\",\"copilot_chat_attach_knowledge\",\"copilot_chat_knowledge_base_copy\",\"copilot_smell_icebreaker_ux\",\"copilot_implicit_context\",\"docset_management_ui\",\"copilot_chat_settings\",\"failbot_handle_non_errors\",\"geojson_azure_maps\",\"image_metric_tracking\",\"marketing_forms_api_integration_contact_request\",\"marketing_pages_search_explore_provider\",\"turbo_experiment_risky\",\"sample_network_conn_type\",\"no_character_key_shortcuts_in_inputs\",\"custom_inp\",\"remove_child_patch\"]}</script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/wp-runtime-47578fb192fd.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_dompurify_dist_purify_js-6890e890956f.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_stacktrace-parser_dist_stack-trace-parser_esm_js-node_modules_github_bro-a4c183-79f9611c275b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_hydro-analytics-client_dist_analytics-client_js-node_modules_gith-6a10dd-e66ebda625fb.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_failbot_failbot_ts-479802999bcc.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/environment-fe7570f3bc38.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_selector-observer_dist_index_esm_js-9f960d9b217c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_focus-zone_js-086f7a27bac0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_relative-time-element_dist_index_js-c76945c5961a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_details-dialog-elemen-29dc30-a2a71f11a507.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_auto-complete-element_dist_index_js-12366198e7a5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_text-expander-element_dist_index_js-8a621df59e80.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-b7d8f4-654130b7cde5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_primer_view-co-5dccdf-e5e2b9fa3c0c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/github-elements-e4eda4896b4e.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/element-registry-b99c9d8fad1d.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_catalyst_lib_index_js-node_modules_github_hydro-analytics-client_-978abc0-add939c751ce.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_lit-html_lit-html_js-5b376145beff.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_alive-client_dist-bf5aa2-1b562c29ab8e.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_morphdom_dist_morphdom-esm_js-5bff297a06de.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_turbo_dist_turbo_es2017-esm_js-c91f4ad18b62.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_color-convert_index_js-72c9fbde5ad4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_scroll-anchoring_dist_scro-231ccf-aa129238d13b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_dimensions_js-node_modules_github_jtml_lib_index_js-95b84ee6bc34.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_session-resume_dist_index_js-node_modules_primer_behaviors_dist_e-da6ec6-3f39339c9d98.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_paste-markdown_dist_index_esm_js-node_modules_github_quote-select-67e0dc-1aa35af077a4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_updatable-content_ts-ee3fc84d7fb0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_task-list_ts-app_assets_modules_github_onfocus_ts-app_ass-421cec-9de4213015af.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_sticky-scroll-into-view_ts-94209c43e6af.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_ajax-error_ts-app_assets_modules_github_behaviors_include-467754-f9bd433e9591.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_commenting_edit_ts-app_assets_modules_github_behaviors_ht-83c235-9285faa0e011.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_blob-anchor_ts-app_assets_modules_github_filter-sort_ts-app_assets_-c96432-da3733f430b8.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/behaviors-1fb9e5061509.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_catalyst_lib_index_js-d0256ebff5cd.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/notifications-global-352d84c6cc82.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_virtualized-list_es_index_js-node_modules_github_template-parts_lib_index_js-878844713bc9.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-c537341-c7f6a41a084c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_ref-selector_ts-b593b93f23f5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/codespaces-1a8626dd714a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_mini-throt-08ab15-3e0517baca99.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_github_mini-th-55cf52-e14cb4b719b4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/repositories-69068e0899f9.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/code-menu-614feb194539.js\"></script>    <title>GitHub - CompVis/taming-transformers: Taming Transformers for High-Resolution Image Synthesis</title>  <meta name=\"route-pattern\" content=\"/:user_id/:repository\" data-turbo-transient>  <meta name=\"route-controller\" content=\"files\" data-turbo-transient>  <meta name=\"route-action\" content=\"disambiguate\" data-turbo-transient>      <meta name=\"current-catalog-service-hash\" content=\"82c569b93da5c18ed649ebd4c2c79437db4611a6a1373e805a3cb001c64130b7\">  <meta name=\"request-id\" content=\"F019:2A85FF:F2379:1669B4:65E78348\" data-pjax-transient=\"true\"/><meta name=\"html-safe-nonce\" content=\"3725cc8a4b86fd5aa33c3c65e9e8309cb28428048e37d2d8f241cbfac903ef04\" data-pjax-transient=\"true\"/><meta name=\"visitor-payload\" content=\"eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJGMDE5OjJBODVGRjpGMjM3OToxNjY5QjQ6NjVFNzgzNDgiLCJ2aXNpdG9yX2lkIjoiNTA1OTg3NDAzMDc5NzQyMzQzMiIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9\" data-pjax-transient=\"true\"/><meta name=\"visitor-hmac\" content=\"e6f0a2fa5ee98cc8b8bf852c5981ceb994716bc6e39ecf1413f28bfdfb754ea6\" data-pjax-transient=\"true\"/>    <meta name=\"hovercard-subject-tag\" content=\"repository:322324704\" data-turbo-transient>  <meta name=\"github-keyboard-shortcuts\" content=\"repository,copilot\" data-turbo-transient=\"true\" />    <meta name=\"selected-link\" value=\"repo_source\" data-turbo-transient>  <link rel=\"assets\" href=\"https://github.githubassets.com/\">    <meta name=\"google-site-verification\" content=\"c1kuD-K2HIVF635lypcsWPoD4kilo5-jA_wBFyT4uMY\">  <meta name=\"google-site-verification\" content=\"KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU\">  <meta name=\"google-site-verification\" content=\"ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA\">  <meta name=\"google-site-verification\" content=\"GXs5KoUUkNCoaAZn7wPN-t01Pywp9M3sEjnt_3_ZWPc\">  <meta name=\"google-site-verification\" content=\"Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I\"><meta name=\"octolytics-url\" content=\"https://collector.github.com/github/collect\" />  <meta name=\"analytics-location\" content=\"/&lt;user-name&gt;/&lt;repo-name&gt;\" data-turbo-transient=\"true\" />        <meta name=\"user-login\" content=\"\">      <meta name=\"viewport\" content=\"width=device-width\">          <meta name=\"description\" content=\"Taming Transformers for High-Resolution Image Synthesis - CompVis/taming-transformers\">      <link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/opensearch.xml\" title=\"GitHub\">    <link rel=\"fluid-icon\" href=\"https://github.com/fluidicon.png\" title=\"GitHub\">    <meta property=\"fb:app_id\" content=\"1401488693436528\">    <meta name=\"apple-itunes-app\" content=\"app-id=1477376905, app-argument=https://github.com/compvis/taming-transformers\" />      <meta name=\"twitter:image:src\" content=\"https://opengraph.githubassets.com/12ed3527bc9a80d5567e2a93d151b580d59ce480773b32a8ec6fae7f850e783c/CompVis/taming-transformers\" /><meta name=\"twitter:site\" content=\"@github\" /><meta name=\"twitter:card\" content=\"summary_large_image\" /><meta name=\"twitter:title\" content=\"GitHub - CompVis/taming-transformers: Taming Transformers for High-Resolution Image Synthesis\" /><meta name=\"twitter:description\" content=\"Taming Transformers for High-Resolution Image Synthesis - CompVis/taming-transformers\" />      <meta property=\"og:image\" content=\"https://opengraph.githubassets.com/12ed3527bc9a80d5567e2a93d151b580d59ce480773b32a8ec6fae7f850e783c/CompVis/taming-transformers\" /><meta property=\"og:image:alt\" content=\"Taming Transformers for High-Resolution Image Synthesis - CompVis/taming-transformers\" /><meta property=\"og:image:width\" content=\"1200\" /><meta property=\"og:image:height\" content=\"600\" /><meta property=\"og:site_name\" content=\"GitHub\" /><meta property=\"og:type\" content=\"object\" /><meta property=\"og:title\" content=\"GitHub - CompVis/taming-transformers: Taming Transformers for High-Resolution Image Synthesis\" /><meta property=\"og:url\" content=\"https://github.com/CompVis/taming-transformers\" /><meta property=\"og:description\" content=\"Taming Transformers for High-Resolution Image Synthesis - CompVis/taming-transformers\" />              <meta name=\"hostname\" content=\"github.com\">        <meta name=\"expected-hostname\" content=\"github.com\">  <meta http-equiv=\"x-pjax-version\" content=\"b9fa4cafade57d606c6dcfafff1d08bd597980af7b9837ed473fdf0cdea8a3bc\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-csp-version\" content=\"5dcfbec3488c5fd5a334e287ce6a17058b7d4beb91db2d4d184e4d55bbf1d7d7\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-css-version\" content=\"d33c7c2fcff40783f3002896023f41e2c17ec62b12ddbe7434e2001d743fb853\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-js-version\" content=\"4ba4a7cc07194c8d5f24291dea4fbc790ffd83ba40beacaf8d0117187b571b4d\" data-turbo-track=\"reload\">  <meta name=\"turbo-cache-control\" content=\"no-preview\" data-turbo-transient=\"\">      <meta data-hydrostats=\"publish\">  <meta name=\"go-import\" content=\"github.com/CompVis/taming-transformers git https://github.com/CompVis/taming-transformers.git\">  <meta name=\"octolytics-dimension-user_id\" content=\"30233788\" /><meta name=\"octolytics-dimension-user_login\" content=\"CompVis\" /><meta name=\"octolytics-dimension-repository_id\" content=\"322324704\" /><meta name=\"octolytics-dimension-repository_nwo\" content=\"CompVis/taming-transformers\" /><meta name=\"octolytics-dimension-repository_public\" content=\"true\" /><meta name=\"octolytics-dimension-repository_is_fork\" content=\"false\" /><meta name=\"octolytics-dimension-repository_network_root_id\" content=\"322324704\" /><meta name=\"octolytics-dimension-repository_network_root_nwo\" content=\"CompVis/taming-transformers\" />    <link rel=\"canonical\" href=\"https://github.com/CompVis/taming-transformers\" data-turbo-transient>  <meta name=\"turbo-body-classes\" content=\"logged-out env-production page-responsive\">  <meta name=\"browser-stats-url\" content=\"https://api.github.com/_private/browser/stats\">  <meta name=\"browser-errors-url\" content=\"https://api.github.com/_private/browser/errors\">  <link rel=\"mask-icon\" href=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" color=\"#000000\">  <link rel=\"alternate icon\" class=\"js-site-favicon\" type=\"image/png\" href=\"https://github.githubassets.com/favicons/favicon.png\">  <link rel=\"icon\" class=\"js-site-favicon\" type=\"image/svg+xml\" href=\"https://github.githubassets.com/favicons/favicon.svg\"><meta name=\"theme-color\" content=\"#1e2327\"><meta name=\"color-scheme\" content=\"light dark\" />  <link rel=\"manifest\" href=\"/manifest.json\" crossOrigin=\"use-credentials\">  </head>  <body class=\"logged-out env-production page-responsive\" style=\"word-wrap: break-word;\">    <div data-turbo-body class=\"logged-out env-production page-responsive\" style=\"word-wrap: break-word;\">          <div class=\"position-relative js-header-wrapper \">      <a href=\"#start-of-content\" class=\"px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content\">Skip to content</a>      <span data-view-component=\"true\" class=\"progress-pjax-loader Progress position-fixed width-full\">    <span style=\"width: 0%;\" data-view-component=\"true\" class=\"Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis\"></span></span>              <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Button_IconButton_js-node_modules_primer_react_lib--23bcad-a89698f38643.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/keyboard-shortcuts-dialog-a23eda2bcf8d.js\"></script><react-partial  partial-name=\"keyboard-shortcuts-dialog\"  data-ssr=\"false\">    <script type=\"application/json\" data-target=\"react-partial.embeddedData\">{\"props\":{}}</script>  <div data-target=\"react-partial.reactRoot\"></div></react-partial>                          <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-94fd67-99519581d0f8.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/sessions-585a7232e50a.js\"></script><header class=\"Header-old header-logged-out js-details-container Details position-relative f4 py-3\" role=\"banner\" data-color-mode=light data-light-theme=light data-dark-theme=dark>  <button type=\"button\" class=\"Header-backdrop d-lg-none border-0 position-fixed top-0 left-0 width-full height-full js-details-target\" aria-label=\"Toggle navigation\">    <span class=\"d-none\">Toggle navigation</span>  </button>  <div class=\" d-flex flex-column flex-lg-row flex-items-center p-responsive height-full position-relative z-1\">    <div class=\"d-flex flex-justify-between flex-items-center width-full width-lg-auto\">      <a class=\"mr-lg-3 color-fg-inherit flex-order-2\" href=\"https://github.com/\" aria-label=\"Homepage\" data-ga-click=\"(Logged out) Header, go to homepage, icon:logo-wordmark\">        <svg height=\"32\" aria-hidden=\"true\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"32\" data-view-component=\"true\" class=\"octicon octicon-mark-github\">    <path d=\"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z\"></path></svg>      </a>      <div class=\"flex-1\">        <a href=\"/login?return_to=https%3A%2F%2Fgithub.com%2Fcompvis%2Ftaming-transformers\"          class=\"d-inline-block d-lg-none flex-order-1 f5 no-underline border color-border-default rounded-2 px-2 py-1 color-fg-inherit\"          data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/compvis/taming-transformers&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"95f211127ed79dbc2817c23f0ec05630d594b9e46995cb24ef5e55498f01490e\"          data-ga-click=\"(Logged out) Header, clicked Sign in, text:sign-in\">          Sign in        </a>      </div>      <div class=\"flex-1 flex-order-2 text-right\">        <button aria-label=\"Toggle navigation\" aria-expanded=\"false\" type=\"button\" data-view-component=\"true\" class=\"js-details-target Button--link Button--medium Button d-lg-none color-fg-inherit p-1\">  <span class=\"Button-content\">    <span class=\"Button-label\"><div class=\"HeaderMenu-toggle-bar rounded my-1\"></div>            <div class=\"HeaderMenu-toggle-bar rounded my-1\"></div>            <div class=\"HeaderMenu-toggle-bar rounded my-1\"></div></span>  </span></button>      </div>    </div>    <div class=\"HeaderMenu--logged-out p-responsive height-fit position-lg-relative d-lg-flex flex-column flex-auto pt-7 pb-4 top-0\">      <div class=\"header-menu-wrapper d-flex flex-column flex-self-end flex-lg-row flex-justify-between flex-auto p-3 p-lg-0 rounded rounded-lg-0 mt-3 mt-lg-0\">          <nav class=\"mt-0 px-3 px-lg-0 mb-3 mb-lg-0\" aria-label=\"Global\">            <ul class=\"d-lg-flex list-style-none\">                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Product        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 d-lg-flex dropdown-menu-wide\">          <div class=\"px-lg-4 border-lg-right mb-4 mb-lg-0 pr-lg-7\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}\" href=\"/features/actions\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-workflow color-fg-subtle mr-3\">    <path d=\"M1 3a2 2 0 0 1 2-2h6.5a2 2 0 0 1 2 2v6.5a2 2 0 0 1-2 2H7v4.063C7 16.355 7.644 17 8.438 17H12.5v-2.5a2 2 0 0 1 2-2H21a2 2 0 0 1 2 2V21a2 2 0 0 1-2 2h-6.5a2 2 0 0 1-2-2v-2.5H8.437A2.939 2.939 0 0 1 5.5 15.562V11.5H3a2 2 0 0 1-2-2Zm2-.5a.5.5 0 0 0-.5.5v6.5a.5.5 0 0 0 .5.5h6.5a.5.5 0 0 0 .5-.5V3a.5.5 0 0 0-.5-.5ZM14.5 14a.5.5 0 0 0-.5.5V21a.5.5 0 0 0 .5.5H21a.5.5 0 0 0 .5-.5v-6.5a.5.5 0 0 0-.5-.5Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Actions</div>        Automate any workflow      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}\" href=\"/features/packages\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-package color-fg-subtle mr-3\">    <path d=\"M12.876.64V.639l8.25 4.763c.541.313.875.89.875 1.515v9.525a1.75 1.75 0 0 1-.875 1.516l-8.25 4.762a1.748 1.748 0 0 1-1.75 0l-8.25-4.763a1.75 1.75 0 0 1-.875-1.515V6.917c0-.625.334-1.202.875-1.515L11.126.64a1.748 1.748 0 0 1 1.75 0Zm-1 1.298L4.251 6.34l7.75 4.474 7.75-4.474-7.625-4.402a.248.248 0 0 0-.25 0Zm.875 19.123 7.625-4.402a.25.25 0 0 0 .125-.216V7.639l-7.75 4.474ZM3.501 7.64v8.803c0 .09.048.172.125.216l7.625 4.402v-8.947Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Packages</div>        Host and manage packages      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}\" href=\"/features/security\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-shield-check color-fg-subtle mr-3\">    <path d=\"M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z\"></path><path d=\"m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Security</div>        Find and fix vulnerabilities      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}\" href=\"/features/codespaces\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-codespaces color-fg-subtle mr-3\">    <path d=\"M3.5 3.75C3.5 2.784 4.284 2 5.25 2h13.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 18.75 13H5.25a1.75 1.75 0 0 1-1.75-1.75Zm-2 12c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v4a1.75 1.75 0 0 1-1.75 1.75H3.25a1.75 1.75 0 0 1-1.75-1.75ZM5.25 3.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h13.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Zm-2 12a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h17.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25Z\"></path><path d=\"M10 17.75a.75.75 0 0 1 .75-.75h6.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Codespaces</div>        Instant dev environments      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}\" href=\"/features/copilot\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-copilot color-fg-subtle mr-3\">    <path d=\"M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z\"></path><path d=\"M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Copilot</div>        Write better code with AI      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}\" href=\"/features/code-review\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-code-review color-fg-subtle mr-3\">    <path d=\"M10.3 6.74a.75.75 0 0 1-.04 1.06l-2.908 2.7 2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z\"></path><path d=\"M1.5 4.25c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v12.5a1.75 1.75 0 0 1-1.75 1.75h-9.69l-3.573 3.573A1.458 1.458 0 0 1 5 21.043V18.5H3.25a1.75 1.75 0 0 1-1.75-1.75ZM3.25 4a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h2.5a.75.75 0 0 1 .75.75v3.19l3.72-3.72a.749.749 0 0 1 .53-.22h10a.25.25 0 0 0 .25-.25V4.25a.25.25 0 0 0-.25-.25Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Code review</div>        Manage code changes      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}\" href=\"/features/issues\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-issue-opened color-fg-subtle mr-3\">    <path d=\"M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1ZM2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5 9.5 9.5 0 0 0 2.5 12Zm9.5 2a2 2 0 1 1-.001-3.999A2 2 0 0 1 12 14Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Issues</div>        Plan and track work      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}\" href=\"/features/discussions\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-comment-discussion color-fg-subtle mr-3\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z\"></path><path d=\"M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Discussions</div>        Collaborate outside of code      </div>    </a></li>            </ul>          </div>          <div class=\"px-lg-4\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"product-explore-heading\">Explore</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"product-explore-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to All features&quot;,&quot;label&quot;:&quot;ref_cta:All features;&quot;}\" href=\"/features\">      All features    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Documentation&quot;,&quot;label&quot;:&quot;ref_cta:Documentation;&quot;}\" href=\"https://docs.github.com\">      Documentation    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Skills&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Skills;&quot;}\" href=\"https://skills.github.com/\">      GitHub Skills    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Blog&quot;,&quot;label&quot;:&quot;ref_cta:Blog;&quot;}\" href=\"https://github.blog\">      Blog    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Solutions        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 px-lg-4\">          <div class=\"border-bottom pb-3 mb-3\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-for-heading\">For</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-for-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Enterprise&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise;&quot;}\" href=\"/enterprise\">      Enterprise    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Teams&quot;,&quot;label&quot;:&quot;ref_cta:Teams;&quot;}\" href=\"/team\">      Teams    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Startups&quot;,&quot;label&quot;:&quot;ref_cta:Startups;&quot;}\" href=\"/enterprise/startups\">      Startups    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Education&quot;,&quot;label&quot;:&quot;ref_cta:Education;&quot;}\" href=\"https://education.github.com\">      Education    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>          <div class=\"border-bottom pb-3 mb-3\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-by-solution-heading\">By Solution</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-by-solution-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to CI/CD &amp;amp; Automation&quot;,&quot;label&quot;:&quot;ref_cta:CI/CD &amp;amp; Automation;&quot;}\" href=\"/solutions/ci-cd/\">      CI/CD &amp; Automation    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevOps&quot;,&quot;label&quot;:&quot;ref_cta:DevOps;&quot;}\" href=\"/solutions/devops/\">      DevOps    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevSecOps&quot;,&quot;label&quot;:&quot;ref_cta:DevSecOps;&quot;}\" href=\"https://resources.github.com/devops/fundamentals/devsecops/\">      DevSecOps    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>          <div class=\"\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-resources-heading\">Resources</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-resources-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Learning Pathways&quot;,&quot;label&quot;:&quot;ref_cta:Learning Pathways;&quot;}\" href=\"https://resources.github.com/learn/pathways/\">      Learning Pathways    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}\" href=\"https://resources.github.com/\">      White papers, Ebooks, Webinars    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}\" href=\"/customer-stories\">      Customer Stories    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}\" href=\"https://partner.github.com/\">      Partners    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Open Source        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 px-lg-4\">          <div class=\"border-bottom pb-3 mb-3\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}\" href=\"/sponsors\">            <div>        <div class=\"color-fg-default h4\">GitHub Sponsors</div>        Fund open source developers      </div>    </a></li>            </ul>          </div>          <div class=\"border-bottom pb-3 mb-3\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}\" href=\"/readme\">            <div>        <div class=\"color-fg-default h4\">The ReadME Project</div>        GitHub community articles      </div>    </a></li>            </ul>          </div>          <div class=\"\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"open-source-repositories-heading\">Repositories</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"open-source-repositories-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Topics&quot;,&quot;label&quot;:&quot;ref_cta:Topics;&quot;}\" href=\"/topics\">      Topics    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Trending&quot;,&quot;label&quot;:&quot;ref_cta:Trending;&quot;}\" href=\"/trending\">      Trending    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Collections&quot;,&quot;label&quot;:&quot;ref_cta:Collections;&quot;}\" href=\"/collections\">      Collections    </a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">    <a class=\"HeaderMenu-link no-underline px-0 px-lg-2 py-3 py-lg-2 d-block d-lg-inline-block\" data-analytics-event=\"{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}\" href=\"/pricing\">Pricing</a></li>            </ul>          </nav>        <div class=\"d-lg-flex flex-items-center mb-3 mb-lg-0 text-center text-lg-left ml-3\" style=\"\">                <qbsearch-input class=\"search-input\" data-scope=\"repo:CompVis/taming-transformers\" data-custom-scopes-path=\"/search/custom_scopes\" data-delete-custom-scopes-csrf=\"yT2eTP2G82ppG6QSOYV2yMjXCoV6ztTECBQA_oU6YEkd3Qkc1kCZnWoM0XSWtffMjbR7VgFwab3RIos8Dg80eA\" data-max-custom-scopes=\"10\" data-header-redesign-enabled=\"false\" data-initial-value=\"\" data-blackbird-suggestions-path=\"/search/suggestions\" data-jump-to-suggestions-path=\"/_graphql/GetSuggestedNavigationDestinations\" data-current-repository=\"CompVis/taming-transformers\" data-current-org=\"CompVis\" data-current-owner=\"\" data-logged-in=\"false\" data-copilot-chat-enabled=\"false\" data-blackbird-indexed-repo-csrf=\"<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=Jz%2FezKuz3c7L10%2Bg9fuW5vpmh0MqAYcCcs6oYj5HQp4%2B3bv%2F1WdAxaRJW6X%2FcL%2Bd8lQAJKX3OXFDFbOjzibNXBqd97NTHbOsQt9MCO%2BiBSbi9w7fDuiAVMBzc6URkdlbqs2PoFlSWozWzAa16ImSJkbG3MEDBPSHOb51LFMQQroK7rYSYnLHKQ%2FBMIto57w%2F5sCZb0bG7IYwN023aIDIXL1ALZkpuZNJX3Qs2GvzfdZpYCsRogBJQW8e4aQ4d%2FSAOMLjt4VPA6JSM1Gpn1IFizYRKy%2FqC8Wnf0om%2FY5wEUxQcKeHvO0R%2BhTGX9fWtuapopjv6m%2ByNH5gEAkBkJkCwUnf%2BxWJNAmfukJ6p%2FQ7hHG7SfScjp9R%2B72T7InIvj%2FN%2FnsSxN6NTW7eV%2BC4lOIG%2BWNeE3QCowvIGy44seBQwUaqXsynF2%2FqbutKTdhP5XlTwC8salWf2h0IeBbCGIYFeSoyHChRIEPj%2FeRYLB%2B8Z1FGsknRLqUUh9U0l6jTcghuRKXULWTFkNzKE2JROFUdCZm2l2TYUXpxbGA%3D--cWbX1UlecxHBD0It--usvo99TOo3Xu3WlI10%2Ff2Q%3D%3D&quot; />\">  <div    class=\"search-input-container search-with-dialog position-relative d-flex flex-row flex-items-center mr-4 rounded\"    data-action=\"click:qbsearch-input#searchInputContainerClicked\"  >      <button        type=\"button\"        class=\"header-search-button placeholder  input-button form-control d-flex flex-1 flex-self-stretch flex-items-center no-wrap width-full py-0 pl-2 pr-0 text-left border-0 box-shadow-none\"        data-target=\"qbsearch-input.inputButton\"        placeholder=\"Search or jump to...\"        data-hotkey=s,/        autocapitalize=\"off\"        data-action=\"click:qbsearch-input#handleExpand\"      >        <div class=\"mr-2 color-fg-muted\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg>        </div>        <span class=\"flex-1\" data-target=\"qbsearch-input.inputButtonText\">Search or jump to...</span>          <div class=\"d-flex\" data-target=\"qbsearch-input.hotkeyIndicator\">            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"22\" height=\"20\" aria-hidden=\"true\" class=\"mr-1\"><path fill=\"none\" stroke=\"#979A9C\" opacity=\".4\" d=\"M3.5.5h12c1.7 0 3 1.3 3 3v13c0 1.7-1.3 3-3 3h-12c-1.7 0-3-1.3-3-3v-13c0-1.7 1.3-3 3-3z\"></path><path fill=\"#979A9C\" d=\"M11.8 6L8 15.1h-.9L10.8 6h1z\"></path></svg>          </div>      </button>    <input type=\"hidden\" name=\"type\" class=\"js-site-search-type-field\">    <div class=\"Overlay--hidden \" data-modal-dialog-overlay>  <modal-dialog data-action=\"close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose\" data-target=\"qbsearch-input.searchSuggestionsDialog\" role=\"dialog\" id=\"search-suggestions-dialog\" aria-modal=\"true\" aria-labelledby=\"search-suggestions-dialog-header\" data-view-component=\"true\" class=\"Overlay Overlay--width-large Overlay--height-auto\">      <h1 id=\"search-suggestions-dialog-header\" class=\"sr-only\">Search code, repositories, users, issues, pull requests...</h1>    <div class=\"Overlay-body Overlay-body--paddingNone\">                <div data-view-component=\"true\">        <div class=\"search-suggestions position-fixed width-full color-shadow-large border color-fg-default color-bg-default overflow-hidden d-flex flex-column query-builder-container\"          style=\"border-radius: 12px;\"          data-target=\"qbsearch-input.queryBuilderContainer\"          hidden        >          <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"query-builder-test-form\" action=\"\" accept-charset=\"UTF-8\" method=\"get\">  <query-builder data-target=\"qbsearch-input.queryBuilder\" id=\"query-builder-query-builder-test\" data-filter-key=\":\" data-view-component=\"true\" class=\"QueryBuilder search-query-builder\">    <div class=\"FormControl FormControl--fullWidth\">      <label id=\"query-builder-test-label\" for=\"query-builder-test\" class=\"FormControl-label sr-only\">        Search      </label>      <div        class=\"QueryBuilder-StyledInput width-fit \"        data-target=\"query-builder.styledInput\"      >          <span id=\"query-builder-test-leadingvisual-wrap\" class=\"FormControl-input-leadingVisualWrap QueryBuilder-leadingVisualWrap\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search FormControl-input-leadingVisual\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg>          </span>        <div data-target=\"query-builder.styledInputContainer\" class=\"QueryBuilder-StyledInputContainer\">          <div            aria-hidden=\"true\"            class=\"QueryBuilder-StyledInputContent\"            data-target=\"query-builder.styledInputContent\"          ></div>          <div class=\"QueryBuilder-InputWrapper\">            <div aria-hidden=\"true\" class=\"QueryBuilder-Sizer\" data-target=\"query-builder.sizer\"></div>            <input id=\"query-builder-test\" name=\"query-builder-test\" value=\"\" autocomplete=\"off\" type=\"text\" role=\"combobox\" spellcheck=\"false\" aria-expanded=\"false\" aria-describedby=\"validation-f515adda-5328-4312-9a26-cbe56795285d\" data-target=\"query-builder.input\" data-action=\"          input:query-builder#inputChange          blur:query-builder#inputBlur          keydown:query-builder#inputKeydown          focus:query-builder#inputFocus        \" data-view-component=\"true\" class=\"FormControl-input QueryBuilder-Input FormControl-medium\" />          </div>        </div>          <span class=\"sr-only\" id=\"query-builder-test-clear\">Clear</span>          <button role=\"button\" id=\"query-builder-test-clear-button\" aria-labelledby=\"query-builder-test-clear query-builder-test-label\" data-target=\"query-builder.clearButton\" data-action=\"                click:query-builder#clear                focus:query-builder#clearButtonFocus                blur:query-builder#clearButtonBlur              \" variant=\"small\" hidden=\"hidden\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--invisible Button--medium mr-1 px-2 py-0 d-flex flex-items-center rounded-1 color-fg-muted\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x-circle-fill Button-visual\">    <path d=\"M2.343 13.657A8 8 0 1 1 13.658 2.343 8 8 0 0 1 2.343 13.657ZM6.03 4.97a.751.751 0 0 0-1.042.018.751.751 0 0 0-.018 1.042L6.94 8 4.97 9.97a.749.749 0 0 0 .326 1.275.749.749 0 0 0 .734-.215L8 9.06l1.97 1.97a.749.749 0 0 0 1.275-.326.749.749 0 0 0-.215-.734L9.06 8l1.97-1.97a.749.749 0 0 0-.326-1.275.749.749 0 0 0-.734.215L8 6.94Z\"></path></svg></button>      </div>      <template id=\"search-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg></template><template id=\"code-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg></template><template id=\"file-code-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-file-code\">    <path d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg></template><template id=\"history-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-history\">    <path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></template><template id=\"repo-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo\">    <path d=\"M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z\"></path></svg></template><template id=\"bookmark-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bookmark\">    <path d=\"M3 2.75C3 1.784 3.784 1 4.75 1h6.5c.966 0 1.75.784 1.75 1.75v11.5a.75.75 0 0 1-1.227.579L8 11.722l-3.773 3.107A.751.751 0 0 1 3 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.91l3.023-2.489a.75.75 0 0 1 .954 0l3.023 2.49V2.75a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"plus-circle-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-plus-circle\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm7.25-3.25v2.5h2.5a.75.75 0 0 1 0 1.5h-2.5v2.5a.75.75 0 0 1-1.5 0v-2.5h-2.5a.75.75 0 0 1 0-1.5h2.5v-2.5a.75.75 0 0 1 1.5 0Z\"></path></svg></template><template id=\"circle-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg></template><template id=\"trash-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-trash\">    <path d=\"M11 1.75V3h2.25a.75.75 0 0 1 0 1.5H2.75a.75.75 0 0 1 0-1.5H5V1.75C5 .784 5.784 0 6.75 0h2.5C10.216 0 11 .784 11 1.75ZM4.496 6.675l.66 6.6a.25.25 0 0 0 .249.225h5.19a.25.25 0 0 0 .249-.225l.66-6.6a.75.75 0 0 1 1.492.149l-.66 6.6A1.748 1.748 0 0 1 10.595 15h-5.19a1.75 1.75 0 0 1-1.741-1.575l-.66-6.6a.75.75 0 1 1 1.492-.15ZM6.5 1.75V3h3V1.75a.25.25 0 0 0-.25-.25h-2.5a.25.25 0 0 0-.25.25Z\"></path></svg></template><template id=\"team-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-people\">    <path d=\"M2 5.5a3.5 3.5 0 1 1 5.898 2.549 5.508 5.508 0 0 1 3.034 4.084.75.75 0 1 1-1.482.235 4 4 0 0 0-7.9 0 .75.75 0 0 1-1.482-.236A5.507 5.507 0 0 1 3.102 8.05 3.493 3.493 0 0 1 2 5.5ZM11 4a3.001 3.001 0 0 1 2.22 5.018 5.01 5.01 0 0 1 2.56 3.012.749.749 0 0 1-.885.954.752.752 0 0 1-.549-.514 3.507 3.507 0 0 0-2.522-2.372.75.75 0 0 1-.574-.73v-.352a.75.75 0 0 1 .416-.672A1.5 1.5 0 0 0 11 5.5.75.75 0 0 1 11 4Zm-5.5-.5a2 2 0 1 0-.001 3.999A2 2 0 0 0 5.5 3.5Z\"></path></svg></template><template id=\"project-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-project\">    <path d=\"M1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0ZM1.5 1.75v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25ZM11.75 3a.75.75 0 0 1 .75.75v7.5a.75.75 0 0 1-1.5 0v-7.5a.75.75 0 0 1 .75-.75Zm-8.25.75a.75.75 0 0 1 1.5 0v5.5a.75.75 0 0 1-1.5 0ZM8 3a.75.75 0 0 1 .75.75v3.5a.75.75 0 0 1-1.5 0v-3.5A.75.75 0 0 1 8 3Z\"></path></svg></template><template id=\"pencil-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pencil\">    <path d=\"M11.013 1.427a1.75 1.75 0 0 1 2.474 0l1.086 1.086a1.75 1.75 0 0 1 0 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 0 1-.927-.928l.929-3.25c.081-.286.235-.547.445-.758l8.61-8.61Zm.176 4.823L9.75 4.81l-6.286 6.287a.253.253 0 0 0-.064.108l-.558 1.953 1.953-.558a.253.253 0 0 0 .108-.064Zm1.238-3.763a.25.25 0 0 0-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 0 0 0-.354Z\"></path></svg></template><template id=\"copilot-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copilot\">    <path d=\"M7.998 15.035c-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.201-.508-.254-1.084-.254-1.656 0-.87.128-1.769.693-2.484.579-.733 1.494-1.124 2.724-1.261 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095v1.872c0 .766-3.351 3.795-8.002 3.795Zm0-1.485c2.28 0 4.584-1.11 5.002-1.433V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-1.146 0-2.059-.327-2.71-.991A3.222 3.222 0 0 1 8 6.303a3.24 3.24 0 0 1-.544.743c-.65.664-1.563.991-2.71.991-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433ZM6.762 2.83c-.193-.206-.637-.413-1.682-.297-1.019.113-1.479.404-1.713.7-.247.312-.369.789-.369 1.554 0 .793.129 1.171.308 1.371.162.181.519.379 1.442.379.853 0 1.339-.235 1.638-.54.315-.322.527-.827.617-1.553.117-.935-.037-1.395-.241-1.614Zm4.155-.297c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Z\"></path><path d=\"M6.25 9.037a.75.75 0 0 1 .75.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 .75-.75Zm4.25.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 1.5 0Z\"></path></svg></template><template id=\"workflow-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-workflow\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h3.5C6.216 0 7 .784 7 1.75v3.5A1.75 1.75 0 0 1 5.25 7H4v4a1 1 0 0 0 1 1h4v-1.25C9 9.784 9.784 9 10.75 9h3.5c.966 0 1.75.784 1.75 1.75v3.5A1.75 1.75 0 0 1 14.25 16h-3.5A1.75 1.75 0 0 1 9 14.25v-.75H5A2.5 2.5 0 0 1 2.5 11V7h-.75A1.75 1.75 0 0 1 0 5.25Zm1.75-.25a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Zm9 9a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"book-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-book\">    <path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg></template><template id=\"code-review-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code-review\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 13H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25v-8.5C0 1.784.784 1 1.75 1ZM1.5 2.75v8.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm5.28 1.72a.75.75 0 0 1 0 1.06L5.31 7l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.75.75 0 0 1 1.06 0Zm2.44 0a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L10.69 7 9.22 5.53a.75.75 0 0 1 0-1.06Z\"></path></svg></template><template id=\"codespaces-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-codespaces\">    <path d=\"M0 11.25c0-.966.784-1.75 1.75-1.75h12.5c.966 0 1.75.784 1.75 1.75v3A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm2-9.5C2 .784 2.784 0 3.75 0h8.5C13.216 0 14 .784 14 1.75v5a1.75 1.75 0 0 1-1.75 1.75h-8.5A1.75 1.75 0 0 1 2 6.75Zm1.75-.25a.25.25 0 0 0-.25.25v5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-5a.25.25 0 0 0-.25-.25Zm-2 9.5a.25.25 0 0 0-.25.25v3c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-3a.25.25 0 0 0-.25-.25Z\"></path><path d=\"M7 12.75a.75.75 0 0 1 .75-.75h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z\"></path></svg></template><template id=\"comment-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-comment\">    <path d=\"M1 2.75C1 1.784 1.784 1 2.75 1h10.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 13.25 12H9.06l-2.573 2.573A1.458 1.458 0 0 1 4 13.543V12H2.75A1.75 1.75 0 0 1 1 10.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h4.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"comment-discussion-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-comment-discussion\">    <path d=\"M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z\"></path></svg></template><template id=\"organization-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-organization\">    <path d=\"M1.75 16A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0h8.5C11.216 0 12 .784 12 1.75v12.5c0 .085-.006.168-.018.25h2.268a.25.25 0 0 0 .25-.25V8.285a.25.25 0 0 0-.111-.208l-1.055-.703a.749.749 0 1 1 .832-1.248l1.055.703c.487.325.779.871.779 1.456v5.965A1.75 1.75 0 0 1 14.25 16h-3.5a.766.766 0 0 1-.197-.026c-.099.017-.2.026-.303.026h-3a.75.75 0 0 1-.75-.75V14h-1v1.25a.75.75 0 0 1-.75.75Zm-.25-1.75c0 .138.112.25.25.25H4v-1.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 .75.75v1.25h2.25a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM3.75 6h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 3.75A.75.75 0 0 1 3.75 3h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 3.75Zm4 3A.75.75 0 0 1 7.75 6h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 7 6.75ZM7.75 3h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 9.75A.75.75 0 0 1 3.75 9h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 9.75ZM7.75 9h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z\"></path></svg></template><template id=\"rocket-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-rocket\">    <path d=\"M14.064 0h.186C15.216 0 16 .784 16 1.75v.186a8.752 8.752 0 0 1-2.564 6.186l-.458.459c-.314.314-.641.616-.979.904v3.207c0 .608-.315 1.172-.833 1.49l-2.774 1.707a.749.749 0 0 1-1.11-.418l-.954-3.102a1.214 1.214 0 0 1-.145-.125L3.754 9.816a1.218 1.218 0 0 1-.124-.145L.528 8.717a.749.749 0 0 1-.418-1.11l1.71-2.774A1.748 1.748 0 0 1 3.31 4h3.204c.288-.338.59-.665.904-.979l.459-.458A8.749 8.749 0 0 1 14.064 0ZM8.938 3.623h-.002l-.458.458c-.76.76-1.437 1.598-2.02 2.5l-1.5 2.317 2.143 2.143 2.317-1.5c.902-.583 1.74-1.26 2.499-2.02l.459-.458a7.25 7.25 0 0 0 2.123-5.127V1.75a.25.25 0 0 0-.25-.25h-.186a7.249 7.249 0 0 0-5.125 2.123ZM3.56 14.56c-.732.732-2.334 1.045-3.005 1.148a.234.234 0 0 1-.201-.064.234.234 0 0 1-.064-.201c.103-.671.416-2.273 1.15-3.003a1.502 1.502 0 1 1 2.12 2.12Zm6.94-3.935c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 0 0 .119-.213ZM3.678 8.116 5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 0 0-.213.119l-1.2 1.95ZM12 5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg></template><template id=\"shield-check-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield-check\">    <path d=\"m8.533.133 5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667l5.25-1.68a1.748 1.748 0 0 1 1.066 0Zm-.61 1.429.001.001-5.25 1.68a.251.251 0 0 0-.174.237V7c0 1.36.275 2.666 1.057 3.859.784 1.194 2.121 2.342 4.366 3.298a.196.196 0 0 0 .154 0c2.245-.957 3.582-2.103 4.366-3.297C13.225 9.666 13.5 8.358 13.5 7V3.48a.25.25 0 0 0-.174-.238l-5.25-1.68a.25.25 0 0 0-.153 0ZM11.28 6.28l-3.5 3.5a.75.75 0 0 1-1.06 0l-1.5-1.5a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l.97.97 2.97-2.97a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg></template><template id=\"heart-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-heart\">    <path d=\"m8 14.25.345.666a.75.75 0 0 1-.69 0l-.008-.004-.018-.01a7.152 7.152 0 0 1-.31-.17 22.055 22.055 0 0 1-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.066 22.066 0 0 1-3.744 2.584l-.018.01-.006.003h-.002ZM4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.58 20.58 0 0 0 8 13.393a20.58 20.58 0 0 0 3.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.749.749 0 0 1-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5Z\"></path></svg></template><template id=\"server-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-server\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v4c0 .372-.116.717-.314 1 .198.283.314.628.314 1v4a1.75 1.75 0 0 1-1.75 1.75H1.75A1.75 1.75 0 0 1 0 12.75v-4c0-.358.109-.707.314-1a1.739 1.739 0 0 1-.314-1v-4C0 1.784.784 1 1.75 1ZM1.5 2.75v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm.25 5.75a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25ZM7 4.75A.75.75 0 0 1 7.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5A.75.75 0 0 1 7 4.75ZM7.75 10h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM3 4.75A.75.75 0 0 1 3.75 4h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 4.75ZM3.75 10h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z\"></path></svg></template><template id=\"globe-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-globe\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM5.78 8.75a9.64 9.64 0 0 0 1.363 4.177c.255.426.542.832.857 1.215.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a9.927 9.927 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.507 6.507 0 0 0 4.666 5.5c-.123-.181-.24-.365-.352-.552-.715-1.192-1.437-2.874-1.581-4.948Zm-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948.12-.197.237-.381.353-.552a6.507 6.507 0 0 0-4.666 5.5Zm10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948-.12.197-.237.381-.353.552a6.507 6.507 0 0 0 4.666-5.5Zm2.733-1.5a6.507 6.507 0 0 0-4.666-5.5c.123.181.24.365.353.552.714 1.192 1.436 2.874 1.58 4.948Z\"></path></svg></template><template id=\"issue-opened-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg></template><template id=\"device-mobile-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-device-mobile\">    <path d=\"M3.75 0h8.5C13.216 0 14 .784 14 1.75v12.5A1.75 1.75 0 0 1 12.25 16h-8.5A1.75 1.75 0 0 1 2 14.25V1.75C2 .784 2.784 0 3.75 0ZM3.5 1.75v12.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM8 13a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z\"></path></svg></template><template id=\"package-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-package\">    <path d=\"m8.878.392 5.25 3.045c.54.314.872.89.872 1.514v6.098a1.75 1.75 0 0 1-.872 1.514l-5.25 3.045a1.75 1.75 0 0 1-1.756 0l-5.25-3.045A1.75 1.75 0 0 1 1 11.049V4.951c0-.624.332-1.201.872-1.514L7.122.392a1.75 1.75 0 0 1 1.756 0ZM7.875 1.69l-4.63 2.685L8 7.133l4.755-2.758-4.63-2.685a.248.248 0 0 0-.25 0ZM2.5 5.677v5.372c0 .09.047.171.125.216l4.625 2.683V8.432Zm6.25 8.271 4.625-2.683a.25.25 0 0 0 .125-.216V5.677L8.75 8.432Z\"></path></svg></template><template id=\"credit-card-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-credit-card\">    <path d=\"M10.75 9a.75.75 0 0 0 0 1.5h1.5a.75.75 0 0 0 0-1.5h-1.5Z\"></path><path d=\"M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25ZM14.5 6.5h-13v5.75c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25Zm0-2.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25V5h13Z\"></path></svg></template><template id=\"play-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg></template><template id=\"gift-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-gift\">    <path d=\"M2 2.75A2.75 2.75 0 0 1 4.75 0c.983 0 1.873.42 2.57 1.232.268.318.497.668.68 1.042.183-.375.411-.725.68-1.044C9.376.42 10.266 0 11.25 0a2.75 2.75 0 0 1 2.45 4h.55c.966 0 1.75.784 1.75 1.75v2c0 .698-.409 1.301-1 1.582v4.918A1.75 1.75 0 0 1 13.25 16H2.75A1.75 1.75 0 0 1 1 14.25V9.332C.409 9.05 0 8.448 0 7.75v-2C0 4.784.784 4 1.75 4h.55c-.192-.375-.3-.8-.3-1.25ZM7.25 9.5H2.5v4.75c0 .138.112.25.25.25h4.5Zm1.5 0v5h4.5a.25.25 0 0 0 .25-.25V9.5Zm0-4V8h5.5a.25.25 0 0 0 .25-.25v-2a.25.25 0 0 0-.25-.25Zm-7 0a.25.25 0 0 0-.25.25v2c0 .138.112.25.25.25h5.5V5.5h-5.5Zm3-4a1.25 1.25 0 0 0 0 2.5h2.309c-.233-.818-.542-1.401-.878-1.793-.43-.502-.915-.707-1.431-.707ZM8.941 4h2.309a1.25 1.25 0 0 0 0-2.5c-.516 0-1 .205-1.43.707-.337.392-.646.975-.879 1.793Z\"></path></svg></template><template id=\"code-square-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code-square\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25Zm7.47 3.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L10.69 8 9.22 6.53a.75.75 0 0 1 0-1.06ZM6.78 6.53 5.31 8l1.47 1.47a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg></template><template id=\"device-desktop-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-device-desktop\">    <path d=\"M14.25 1c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 14.25 12h-3.727c.099 1.041.52 1.872 1.292 2.757A.752.752 0 0 1 11.25 16h-6.5a.75.75 0 0 1-.565-1.243c.772-.885 1.192-1.716 1.292-2.757H1.75A1.75 1.75 0 0 1 0 10.25v-7.5C0 1.784.784 1 1.75 1ZM1.75 2.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25ZM9.018 12H6.982a5.72 5.72 0 0 1-.765 2.5h3.566a5.72 5.72 0 0 1-.765-2.5Z\"></path></svg></template>        <div class=\"position-relative\">                <ul                  role=\"listbox\"                  class=\"ActionListWrap QueryBuilder-ListWrap\"                  aria-label=\"Suggestions\"                  data-action=\"                    combobox-commit:query-builder#comboboxCommit                    mousedown:query-builder#resultsMousedown                  \"                  data-target=\"query-builder.resultsList\"                  data-persist-list=false                  id=\"query-builder-test-results\"                ></ul>        </div>      <div class=\"FormControl-inlineValidation\" id=\"validation-f515adda-5328-4312-9a26-cbe56795285d\" hidden=\"hidden\">        <span class=\"FormControl-inlineValidation--visual\">          <svg aria-hidden=\"true\" height=\"12\" viewBox=\"0 0 12 12\" version=\"1.1\" width=\"12\" data-view-component=\"true\" class=\"octicon octicon-alert-fill\">    <path d=\"M4.855.708c.5-.896 1.79-.896 2.29 0l4.675 8.351a1.312 1.312 0 0 1-1.146 1.954H1.33A1.313 1.313 0 0 1 .183 9.058ZM7 7V3H5v4Zm-1 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z\"></path></svg>        </span>        <span></span></div>    </div>    <div data-target=\"query-builder.screenReaderFeedback\" aria-live=\"polite\" aria-atomic=\"true\" class=\"sr-only\"></div></query-builder></form>          <div class=\"d-flex flex-row color-fg-muted px-3 text-small color-bg-default search-feedback-prompt\">            <a target=\"_blank\" href=\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\" data-view-component=\"true\" class=\"Link color-fg-accent text-normal ml-2\">              Search syntax tips</a>            <div class=\"d-flex flex-1\"></div>          </div>        </div></div>    </div></modal-dialog></div>  </div>  <div data-action=\"click:qbsearch-input#retract\" class=\"dark-backdrop position-fixed\" hidden data-target=\"qbsearch-input.darkBackdrop\"></div>  <div class=\"color-fg-default\">    <dialog-helper>  <dialog data-target=\"qbsearch-input.feedbackDialog\" data-action=\"close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose\" id=\"feedback-dialog\" aria-modal=\"true\" aria-labelledby=\"feedback-dialog-title\" aria-describedby=\"feedback-dialog-description\" data-view-component=\"true\" class=\"Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade\">    <div data-view-component=\"true\" class=\"Overlay-header\">  <div class=\"Overlay-headerContentWrap\">    <div class=\"Overlay-titleWrap\">      <h1 class=\"Overlay-title \" id=\"feedback-dialog-title\">        Provide feedback      </h1>    </div>    <div class=\"Overlay-actionWrap\">      <button data-close-dialog-id=\"feedback-dialog\" aria-label=\"Close\" type=\"button\" data-view-component=\"true\" class=\"close-button Overlay-closeButton\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button>    </div>  </div></div>      <scrollable-region data-labelled-by=\"feedback-dialog-title\">        <div data-view-component=\"true\" class=\"Overlay-body\">        <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"code-search-feedback-form\" data-turbo=\"false\" action=\"/search/feedback\" accept-charset=\"UTF-8\" method=\"post\"><input type=\"hidden\" data-csrf=\"true\" name=\"authenticity_token\" value=\"RA1AQSAuAPyca5Kvp0qlaZFQER0dAUi4DP+sWh3eeN2rhkV30F+ZDPLttb80t2MRXowvcfsFM7iA6R1u/L725Q==\" />          <p>We read every piece of feedback, and take your input very seriously.</p>          <textarea name=\"feedback\" class=\"form-control width-full mb-2\" style=\"height: 120px\" id=\"feedback\"></textarea>          <input name=\"include_email\" id=\"include_email\" aria-label=\"Include my email address so I can be contacted\" class=\"form-control mr-2\" type=\"checkbox\">          <label for=\"include_email\" style=\"font-weight: normal\">Include my email address so I can be contacted</label></form></div>      </scrollable-region>      <div data-view-component=\"true\" class=\"Overlay-footer Overlay-footer--alignEnd\">          <button data-close-dialog-id=\"feedback-dialog\" type=\"button\" data-view-component=\"true\" class=\"btn\">    Cancel</button>          <button form=\"code-search-feedback-form\" data-action=\"click:qbsearch-input#submitFeedback\" type=\"submit\" data-view-component=\"true\" class=\"btn-primary btn\">    Submit feedback</button></div></dialog></dialog-helper>    <custom-scopes data-target=\"qbsearch-input.customScopesManager\">    <dialog-helper>  <dialog data-target=\"custom-scopes.customScopesModalDialog\" data-action=\"close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose\" id=\"custom-scopes-dialog\" aria-modal=\"true\" aria-labelledby=\"custom-scopes-dialog-title\" aria-describedby=\"custom-scopes-dialog-description\" data-view-component=\"true\" class=\"Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade\">    <div data-view-component=\"true\" class=\"Overlay-header Overlay-header--divided\">  <div class=\"Overlay-headerContentWrap\">    <div class=\"Overlay-titleWrap\">      <h1 class=\"Overlay-title \" id=\"custom-scopes-dialog-title\">        Saved searches      </h1>        <h2 id=\"custom-scopes-dialog-description\" class=\"Overlay-description\">Use saved searches to filter your results more quickly</h2>    </div>    <div class=\"Overlay-actionWrap\">      <button data-close-dialog-id=\"custom-scopes-dialog\" aria-label=\"Close\" type=\"button\" data-view-component=\"true\" class=\"close-button Overlay-closeButton\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button>    </div>  </div></div>      <scrollable-region data-labelled-by=\"custom-scopes-dialog-title\">        <div data-view-component=\"true\" class=\"Overlay-body\">        <div data-target=\"custom-scopes.customScopesModalDialogFlash\"></div>        <div hidden class=\"create-custom-scope-form\" data-target=\"custom-scopes.createCustomScopeForm\">        <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"custom-scopes-dialog-form\" data-turbo=\"false\" action=\"/search/custom_scopes\" accept-charset=\"UTF-8\" method=\"post\"><input type=\"hidden\" data-csrf=\"true\" name=\"authenticity_token\" value=\"j9mYmMvWvI5XFx/MK3uwYQA6TTERP+qiZk3zanujx+H+r6kKXLRJ6201ty6MxI2J+gGgj5ykc+vMZUhM5DB28A==\" />          <div data-target=\"custom-scopes.customScopesModalDialogFlash\"></div>          <input type=\"hidden\" id=\"custom_scope_id\" name=\"custom_scope_id\" data-target=\"custom-scopes.customScopesIdField\">          <div class=\"form-group\">            <label for=\"custom_scope_name\">Name</label>            <auto-check src=\"/search/custom_scopes/check_name\" required>              <input                type=\"text\"                name=\"custom_scope_name\"                id=\"custom_scope_name\"                data-target=\"custom-scopes.customScopesNameField\"                class=\"form-control\"                autocomplete=\"off\"                placeholder=\"github-ruby\"                required                maxlength=\"50\">              <input type=\"hidden\" data-csrf=\"true\" value=\"X6nPCjnQqdn8X0ciFL0YLgfnjVuz18OEIz/ktXoKE0VjQ8PeHYubx1Y42PPk7GgDAWTUU6CwWYXB+QnRAqYBjQ==\" />            </auto-check>          </div>          <div class=\"form-group\">            <label for=\"custom_scope_query\">Query</label>            <input              type=\"text\"              name=\"custom_scope_query\"              id=\"custom_scope_query\"              data-target=\"custom-scopes.customScopesQueryField\"              class=\"form-control\"              autocomplete=\"off\"              placeholder=\"(repo:mona/a OR repo:mona/b) AND lang:python\"              required              maxlength=\"500\">          </div>          <p class=\"text-small color-fg-muted\">            To see all available qualifiers, see our <a class=\"Link--inTextBlock\" href=\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\">documentation</a>.          </p></form>        </div>        <div data-target=\"custom-scopes.manageCustomScopesForm\">          <div data-target=\"custom-scopes.list\"></div>        </div></div>      </scrollable-region>      <div data-view-component=\"true\" class=\"Overlay-footer Overlay-footer--alignEnd Overlay-footer--divided\">          <button data-action=\"click:custom-scopes#customScopesCancel\" type=\"button\" data-view-component=\"true\" class=\"btn\">    Cancel</button>          <button form=\"custom-scopes-dialog-form\" data-action=\"click:custom-scopes#customScopesSubmit\" data-target=\"custom-scopes.customScopesSubmitButton\" type=\"submit\" data-view-component=\"true\" class=\"btn-primary btn\">    Create saved search</button></div></dialog></dialog-helper>    </custom-scopes>  </div></qbsearch-input><input type=\"hidden\" data-csrf=\"true\" class=\"js-data-jump-to-suggestions-path-csrf\" value=\"9PAHHSQr1sYBqljKB+tX8UrwOPIjVg2FCpSPE35cKaidymUxi9iFS+c9+G6CInPM8ajxY97tRF9/jwN2z2mMMQ==\" />          <div class=\"position-relative mr-lg-3 d-lg-inline-block\">            <a href=\"/login?return_to=https%3A%2F%2Fgithub.com%2Fcompvis%2Ftaming-transformers\"              class=\"HeaderMenu-link HeaderMenu-link--sign-in flex-shrink-0 no-underline d-block d-lg-inline-block border border-lg-0 rounded rounded-lg-0 p-2 p-lg-0\"              data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/compvis/taming-transformers&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"95f211127ed79dbc2817c23f0ec05630d594b9e46995cb24ef5e55498f01490e\"              data-ga-click=\"(Logged out) Header, clicked Sign in, text:sign-in\">              Sign in            </a>          </div>            <a href=\"/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=CompVis%2Ftaming-transformers\"              class=\"HeaderMenu-link HeaderMenu-link--sign-up flex-shrink-0 d-none d-lg-inline-block no-underline border color-border-default rounded px-2 py-1\"              data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/compvis/taming-transformers&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"95f211127ed79dbc2817c23f0ec05630d594b9e46995cb24ef5e55498f01490e\"              data-analytics-event=\"{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/&lt;user-name&gt;/&lt;repo-name&gt;;ref_cta:Sign up;ref_loc:header logged out&quot;}\"            >              Sign up            </a>        </div>      </div>    </div>  </div></header>      <div hidden=\"hidden\" data-view-component=\"true\" class=\"js-stale-session-flash stale-session-flash flash flash-warn flash-full mb-3\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        <span class=\"js-stale-session-flash-signed-in\" hidden>You signed in with another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>        <span class=\"js-stale-session-flash-signed-out\" hidden>You signed out in another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>        <span class=\"js-stale-session-flash-switched\" hidden>You switched accounts on another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>    <button id=\"icon-button-a8b4383d-e874-44a9-88a0-42a7336beeaf\" aria-labelledby=\"tooltip-32a9e3bb-7b95-467f-a17b-5999c6ad5e0f\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--invisible Button--medium flash-close js-flash-close\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x Button-visual\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button><tool-tip id=\"tooltip-32a9e3bb-7b95-467f-a17b-5999c6ad5e0f\" for=\"icon-button-a8b4383d-e874-44a9-88a0-42a7336beeaf\" popover=\"manual\" data-direction=\"s\" data-type=\"label\" data-view-component=\"true\" class=\"sr-only position-absolute\">Dismiss alert</tool-tip>  </div>    </div>  <div id=\"start-of-content\" class=\"show-on-focus\"></div>    <div id=\"js-flash-container\" data-turbo-replace>  <template class=\"js-flash-template\">    <div class=\"flash flash-full   {{ className }}\">  <div class=\"px-2\" >    <button autofocus class=\"flash-close js-flash-close\" type=\"button\" aria-label=\"Dismiss this message\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>    </button>    <div aria-atomic=\"true\" role=\"alert\" class=\"js-flash-alert\">            <div>{{ message }}</div>    </div>  </div></div>  </template></div>        <include-fragment class=\"js-notification-shelf-include-fragment\" data-base-src=\"https://github.com/notifications/beta/shelf\"></include-fragment>  <div    class=\"application-main \"    data-commit-hovercards-enabled    data-discussion-hovercards-enabled    data-issue-and-pr-hovercards-enabled  >        <div itemscope itemtype=\"http://schema.org/SoftwareSourceCode\" class=\"\">    <main id=\"js-repo-pjax-container\" >                        <div id=\"repository-container-header\"  class=\"pt-3 hide-full-screen\" style=\"background-color: var(--page-header-bgColor, var(--color-page-header-bg));\" data-turbo-replace>      <div class=\"d-flex flex-wrap flex-justify-end mb-3  px-3 px-md-4 px-lg-5\" style=\"gap: 1rem;\">        <div class=\"flex-auto min-width-0 width-fit mr-3\">              <div class=\" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo color-fg-muted mr-2\">    <path d=\"M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z\"></path></svg>        <span class=\"author flex-self-stretch\" itemprop=\"author\">      <a class=\"url fn\" rel=\"author\" data-hovercard-type=\"organization\" data-hovercard-url=\"/orgs/CompVis/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"/CompVis\">        CompVis</a>    </span>    <span class=\"mx-1 flex-self-stretch color-fg-muted\">/</span>    <strong itemprop=\"name\" class=\"mr-2 flex-self-stretch\">      <a data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" href=\"/CompVis/taming-transformers\">taming-transformers</a>    </strong>    <span></span><span class=\"Label Label--secondary v-align-middle mr-1\">Public</span>  </div>        </div>        <div id=\"repository-details-container\" data-turbo-replace>            <ul class=\"pagehead-actions flex-shrink-0 d-none d-md-inline\" style=\"padding: 2px 0;\">            <li>            <a href=\"/login?return_to=%2FCompVis%2Ftaming-transformers\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/compvis/taming-transformers&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"8925744b0d86a86bdf18127874defb5d3d5359694289f6b0ce70f50f40236cb0\" aria-label=\"You must be signed in to change notification settings\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bell mr-2\">    <path d=\"M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z\"></path></svg>Notifications</a>  </li>  <li>          <a icon=\"repo-forked\" id=\"fork-button\" href=\"/login?return_to=%2FCompVis%2Ftaming-transformers\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:322324704,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/compvis/taming-transformers&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"2e75d05e346e7d2f300bf760596ab95cd2b52cb56faf05d170508e96b1e8328a\" data-view-component=\"true\" class=\"btn-sm btn\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-2\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>Fork    <span id=\"repo-network-counter\" data-pjax-replace=\"true\" data-turbo-replace=\"true\" title=\"1,058\" data-view-component=\"true\" class=\"Counter\">1.1k</span></a>  </li>  <li>        <div data-view-component=\"true\" class=\"BtnGroup d-flex\">        <a href=\"/login?return_to=%2FCompVis%2Ftaming-transformers\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:322324704,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/compvis/taming-transformers&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"06989dfeedca5a37387877ef524f242e0310f8a39eaa38138f7b32018a12cd85\" aria-label=\"You must be signed in to star a repository\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn BtnGroup-item\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star v-align-text-bottom d-inline-block mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg><span data-view-component=\"true\" class=\"d-inline\">          Star</span>          <span id=\"repo-stars-counter-star\" aria-label=\"5179 users starred this repository\" data-singular-suffix=\"user starred this repository\" data-plural-suffix=\"users starred this repository\" data-turbo-replace=\"true\" title=\"5,179\" data-view-component=\"true\" class=\"Counter js-social-count\">5.2k</span></a>        <button aria-label=\"You must be signed in to add this repository to a list\" type=\"button\" disabled=\"disabled\" data-view-component=\"true\" class=\"btn-sm btn BtnGroup-item px-2\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-triangle-down\">    <path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></button></div>  </li>    <li>            </li></ul>        </div>      </div>        <div id=\"responsive-meta-container\" data-turbo-replace>      <div class=\"d-block d-md-none mb-2 px-3 px-md-4 px-lg-5\">      <p class=\"f4 mb-3 \">        Taming Transformers for High-Resolution Image Synthesis      </p>      <div class=\"mb-2 d-flex flex-items-center Link--secondary\">        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link flex-shrink-0 mr-2\">    <path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg>        <span class=\"flex-auto min-width-0 css-truncate css-truncate-target width-fit\">          <a title=\"https://arxiv.org/abs/2012.09841\" role=\"link\" target=\"_blank\" class=\"text-bold\" rel=\"noopener noreferrer\" href=\"https://arxiv.org/abs/2012.09841\">arxiv.org/abs/2012.09841</a>        </span>      </div>          <h3 class=\"sr-only\">License</h3>  <div class=\"mb-2\">    <a href=\"/CompVis/taming-transformers/blob/master/License.txt\"      class=\"Link--muted\"            data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}\"    >      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-law mr-2\">    <path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg>     MIT license    </a>  </div>    <div class=\"mb-3\">        <a class=\"Link--secondary no-underline mr-3\" href=\"/CompVis/taming-transformers/stargazers\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star mr-1\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg>          <span class=\"text-bold\">5.2k</span>          stars</a>        <a class=\"Link--secondary no-underline mr-3\" href=\"/CompVis/taming-transformers/forks\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-1\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>          <span class=\"text-bold\">1.1k</span>          forks</a>          <a class=\"Link--secondary no-underline mr-3 d-inline-block\" href=\"/CompVis/taming-transformers/branches\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-branch mr-1\">    <path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg>            <span>Branches</span></a>          <a class=\"Link--secondary no-underline d-inline-block\" href=\"/CompVis/taming-transformers/tags\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-tag mr-1\">    <path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg>            <span>Tags</span></a>        <a class=\"Link--secondary no-underline d-inline-block\" href=\"/CompVis/taming-transformers/activity\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pulse mr-1\">    <path d=\"M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z\"></path></svg>          <span>Activity</span></a>    </div>      <div class=\"d-flex flex-wrap gap-2\">        <div class=\"flex-1\">            <div data-view-component=\"true\" class=\"BtnGroup d-flex\">        <a href=\"/login?return_to=%2FCompVis%2Ftaming-transformers\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:322324704,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/compvis/taming-transformers&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"06989dfeedca5a37387877ef524f242e0310f8a39eaa38138f7b32018a12cd85\" aria-label=\"You must be signed in to star a repository\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn btn-block BtnGroup-item\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star v-align-text-bottom d-inline-block mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg><span data-view-component=\"true\" class=\"d-inline\">          Star</span></a>        <button aria-label=\"You must be signed in to add this repository to a list\" type=\"button\" disabled=\"disabled\" data-view-component=\"true\" class=\"btn-sm btn BtnGroup-item px-2\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-triangle-down\">    <path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></button></div>        </div>        <div class=\"flex-1\">                <a href=\"/login?return_to=%2FCompVis%2Ftaming-transformers\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/compvis/taming-transformers&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"8925744b0d86a86bdf18127874defb5d3d5359694289f6b0ce70f50f40236cb0\" aria-label=\"You must be signed in to change notification settings\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn btn-block\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bell mr-2\">    <path d=\"M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z\"></path></svg>Notifications</a>        </div>          <span>                      </span>      </div>  </div></div>          <nav data-pjax=\"#js-repo-pjax-container\" aria-label=\"Repository\" data-view-component=\"true\" class=\"js-repo-nav js-sidenav-container-pjax js-responsive-underlinenav overflow-hidden UnderlineNav px-3 px-md-4 px-lg-5\">  <ul data-view-component=\"true\" class=\"UnderlineNav-body list-style-none\">      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"code-tab\" href=\"/CompVis/taming-transformers\" data-tab-item=\"i0code-tab\" data-selected-links=\"repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments repo_attestations /CompVis/taming-transformers\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g c\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" aria-current=\"page\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item selected\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg>        <span data-content=\"Code\">Code</span>          <span id=\"code-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"issues-tab\" href=\"/CompVis/taming-transformers/issues\" data-tab-item=\"i1issues-tab\" data-selected-links=\"repo_issues repo_labels repo_milestones /CompVis/taming-transformers/issues\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g i\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg>        <span data-content=\"Issues\">Issues</span>          <span id=\"issues-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"133\" data-view-component=\"true\" class=\"Counter\">133</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"pull-requests-tab\" href=\"/CompVis/taming-transformers/pulls\" data-tab-item=\"i2pull-requests-tab\" data-selected-links=\"repo_pulls checks /CompVis/taming-transformers/pulls\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g p\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-pull-request UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z\"></path></svg>        <span data-content=\"Pull requests\">Pull requests</span>          <span id=\"pull-requests-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"17\" data-view-component=\"true\" class=\"Counter\">17</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"actions-tab\" href=\"/CompVis/taming-transformers/actions\" data-tab-item=\"i3actions-tab\" data-selected-links=\"repo_actions /CompVis/taming-transformers/actions\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g a\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg>        <span data-content=\"Actions\">Actions</span>          <span id=\"actions-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"projects-tab\" href=\"/CompVis/taming-transformers/projects\" data-tab-item=\"i4projects-tab\" data-selected-links=\"repo_projects new_repo_project repo_project /CompVis/taming-transformers/projects\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g b\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-table UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z\"></path></svg>        <span data-content=\"Projects\">Projects</span>          <span id=\"projects-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"0\" hidden=\"hidden\" data-view-component=\"true\" class=\"Counter\">0</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"security-tab\" href=\"/CompVis/taming-transformers/security\" data-tab-item=\"i5security-tab\" data-selected-links=\"security overview alerts policy token_scanning code_scanning /CompVis/taming-transformers/security\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g s\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        <span data-content=\"Security\">Security</span>          <include-fragment src=\"/CompVis/taming-transformers/security/overall-count\" accept=\"text/fragment+html\"></include-fragment>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"insights-tab\" href=\"/CompVis/taming-transformers/pulse\" data-tab-item=\"i6insights-tab\" data-selected-links=\"repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /CompVis/taming-transformers/pulse\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-graph UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg>        <span data-content=\"Insights\">Insights</span>          <span id=\"insights-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li></ul>    <div style=\"visibility:hidden;\" data-view-component=\"true\" class=\"UnderlineNav-actions js-responsive-underlinenav-overflow position-absolute pr-3 pr-md-4 pr-lg-5 right-0\">      <action-menu data-select-variant=\"none\" data-view-component=\"true\">  <focus-group direction=\"vertical\" mnemonics retain>    <button id=\"action-menu-5a27e99a-cb2c-4a30-9d43-dbaa0e848a38-button\" popovertarget=\"action-menu-5a27e99a-cb2c-4a30-9d43-dbaa0e848a38-overlay\" aria-controls=\"action-menu-5a27e99a-cb2c-4a30-9d43-dbaa0e848a38-list\" aria-haspopup=\"true\" aria-labelledby=\"tooltip-eed6e09d-1847-4ba8-b351-3e1093de6eb3\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--secondary Button--medium UnderlineNav-item\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-kebab-horizontal Button-visual\">    <path d=\"M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path></svg></button><tool-tip id=\"tooltip-eed6e09d-1847-4ba8-b351-3e1093de6eb3\" for=\"action-menu-5a27e99a-cb2c-4a30-9d43-dbaa0e848a38-button\" popover=\"manual\" data-direction=\"s\" data-type=\"label\" data-view-component=\"true\" class=\"sr-only position-absolute\">Additional navigation options</tool-tip><anchored-position id=\"action-menu-5a27e99a-cb2c-4a30-9d43-dbaa0e848a38-overlay\" anchor=\"action-menu-5a27e99a-cb2c-4a30-9d43-dbaa0e848a38-button\" align=\"start\" side=\"outside-bottom\" anchor-offset=\"normal\" popover=\"auto\" data-view-component=\"true\">  <div data-view-component=\"true\" class=\"Overlay Overlay--size-auto\">          <div data-view-component=\"true\" class=\"Overlay-body Overlay-body--paddingNone\">          <div data-view-component=\"true\">  <ul aria-labelledby=\"action-menu-5a27e99a-cb2c-4a30-9d43-dbaa0e848a38-button\" id=\"action-menu-5a27e99a-cb2c-4a30-9d43-dbaa0e848a38-list\" role=\"menu\" data-view-component=\"true\" class=\"ActionListWrap--inset ActionListWrap\">      <li hidden=\"hidden\" data-menu-item=\"i0code-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-f04bdfbc-1df1-4617-a2c3-c81915500c02\" href=\"/CompVis/taming-transformers\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Code</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i1issues-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-facead5a-7636-4850-9e02-0369a15e4625\" href=\"/CompVis/taming-transformers/issues\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Issues</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i2pull-requests-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-31195c7a-1174-41ad-b49c-acb8f676c017\" href=\"/CompVis/taming-transformers/pulls\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-pull-request\">    <path d=\"M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Pull requests</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i3actions-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-e881df4c-2621-45b1-b8d2-aa5fafd5942c\" href=\"/CompVis/taming-transformers/actions\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Actions</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i4projects-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-5782924b-3ab7-40af-8596-8e8d3cb62c55\" href=\"/CompVis/taming-transformers/projects\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-table\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Projects</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i5security-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-e4e1db06-a089-4fed-9f0f-1aa6c3934a90\" href=\"/CompVis/taming-transformers/security\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield\">    <path d=\"M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Security</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i6insights-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-c876fc0b-3233-4ab2-9664-5e3195f72ba8\" href=\"/CompVis/taming-transformers/pulse\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-graph\">    <path d=\"M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Insights</span></a>    </li></ul>  </div></div>      </div></anchored-position>  </focus-group></action-menu></div></nav>  </div>  <turbo-frame id=\"repo-content-turbo-frame\" target=\"_top\" data-turbo-action=\"advance\" class=\"\">    <div id=\"repo-content-pjax-container\" class=\"repository-content \" >                <h1 class='sr-only'>CompVis/taming-transformers</h1>  <div class=\"clearfix container-xl px-md-4 px-lg-5 px-3\">    <div>  <div id=\"spoof-warning\" class=\"mt-0 pb-3\" hidden aria-hidden>  <div data-view-component=\"true\" class=\"flash flash-warn mt-0 clearfix\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert float-left mt-1\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>      <div class=\"overflow-hidden\">This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.</div>  </div></div>  <include-fragment src=\"/CompVis/taming-transformers/spoofed_commit_check/3ba01b241669f5ade541ce990f7650a3b8f65318\" data-test-selector=\"spoofed-commit-check\"></include-fragment>  <div style=\"max-width: 100%\" data-view-component=\"true\" class=\"Layout Layout--flowRow-until-md react-repos-overview-margin Layout--sidebarPosition-end Layout--sidebarPosition-flowRow-end\">  <div data-view-component=\"true\" class=\"Layout-main\">        <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/react-lib-1fbfc5be2c18.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_octicons-react_dist_index_esm_js-node_modules_primer_react_lib-es-2e8e7c-adc8451a70cf.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Box_Box_js-8f8c5e2a2cbf.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Button_Button_js-67fe00b5266a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_ActionList_index_js-2dd4d13d3ae6.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Overlay_Overlay_js-node_modules_primer_react_lib-es-fa1130-829932cf63db.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Text_Text_js-node_modules_primer_react_lib-esm_Text-85a14b-236dc9716ad0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_ActionMenu_ActionMenu_js-eaf74522e470.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_react-router-dom_dist_index_js-3b41341d50fe.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Dialog_js-node_modules_primer_react_lib-esm_Label_L-857e1c-77794958a54a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_UnderlineNav_index_js-89fa5806aa3c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_AvatarStack_AvatarStack_js-node_modules_primer_reac-e445e7-175b51e43dcc.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_react-core_create-browser-history_ts-ui_packages_react-core_AppContextProvider_ts-809ab9-bf008735d0bb.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_paths_index_ts-7137b25aa38b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_ref-selector_RefSelector_tsx-dbbdef4348e2.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_commit-attribution_index_ts-ui_packages_commit-checks-status_index_ts-ui_packages-ffbe33-4c4ddf7d268d.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_react-code-view_components_directory_DirectoryContent_index_ts-app_assets_-1fd1f5-c96303590595.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/repos-overview-523b8f59ec33.js\"></script><react-partial  partial-name=\"repos-overview\"  data-ssr=\"true\">    <script type=\"application/json\" data-target=\"react-partial.embeddedData\">{\"props\":{\"initialPayload\":{\"allShortcutsEnabled\":false,\"path\":\"/\",\"repo\":{\"id\":322324704,\"defaultBranch\":\"master\",\"name\":\"taming-transformers\",\"ownerLogin\":\"CompVis\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2020-12-17T14:47:06.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/30233788?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":true},\"currentUser\":null,\"refInfo\":{\"name\":\"master\",\"listCacheKey\":\"v0:1687959985.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"3ba01b241669f5ade541ce990f7650a3b8f65318\"},\"tree\":{\"items\":[{\"name\":\"assets\",\"path\":\"assets\",\"contentType\":\"directory\"},{\"name\":\"configs\",\"path\":\"configs\",\"contentType\":\"directory\"},{\"name\":\"data\",\"path\":\"data\",\"contentType\":\"directory\"},{\"name\":\"scripts\",\"path\":\"scripts\",\"contentType\":\"directory\"},{\"name\":\"taming\",\"path\":\"taming\",\"contentType\":\"directory\"},{\"name\":\"License.txt\",\"path\":\"License.txt\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"environment.yaml\",\"path\":\"environment.yaml\",\"contentType\":\"file\"},{\"name\":\"main.py\",\"path\":\"main.py\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"}],\"templateDirectorySuggestionUrl\":null,\"readme\":null,\"totalCount\":10,\"showBranchInfobar\":false},\"fileTree\":null,\"fileTreeProcessingTime\":null,\"foldersToFetch\":[],\"treeExpanded\":false,\"symbolsExpanded\":false,\"isOverview\":true,\"overview\":{\"banners\":{\"shouldRecommendReadme\":false,\"isPersonalRepo\":false,\"showUseActionBanner\":false,\"actionSlug\":null,\"actionId\":null,\"showProtectBranchBanner\":false,\"recentlyTouchedDataChannel\":null,\"publishBannersInfo\":{\"dismissActionNoticePath\":\"/settings/dismiss-notice/publish_action_from_repo\",\"releasePath\":\"/CompVis/taming-transformers/releases/new?marketplace=true\",\"showPublishActionBanner\":false},\"interactionLimitBanner\":null,\"showInvitationBanner\":false,\"inviterName\":null},\"codeButton\":{\"contactPath\":\"/contact\",\"isEnterprise\":false,\"local\":{\"protocolInfo\":{\"httpAvailable\":true,\"sshAvailable\":null,\"httpUrl\":\"https://github.com/CompVis/taming-transformers.git\",\"showCloneWarning\":null,\"sshUrl\":null,\"sshCertificatesRequired\":null,\"sshCertificatesAvailable\":null,\"ghCliUrl\":\"gh repo clone CompVis/taming-transformers\",\"defaultProtocol\":\"http\",\"newSshKeyUrl\":\"/settings/ssh/new\",\"setProtocolPath\":\"/users/set_protocol\"},\"platformInfo\":{\"cloneUrl\":\"https://desktop.github.com\",\"showVisualStudioCloneButton\":false,\"visualStudioCloneUrl\":\"https://windows.github.com\",\"showXcodeCloneButton\":false,\"xcodeCloneUrl\":\"https://developer.apple.com\",\"zipballUrl\":\"/CompVis/taming-transformers/archive/refs/heads/master.zip\"}},\"newCodespacePath\":\"/codespaces/new?hide_repo_select=true\\u0026repo=322324704\"},\"popovers\":{\"rename\":null,\"renamedParentRepo\":null},\"commitCount\":\"96\",\"overviewFiles\":[{\"displayName\":\"README.md\",\"repoName\":\"taming-transformers\",\"refName\":\"master\",\"path\":\"README.md\",\"preferredFileType\":\"readme\",\"tabName\":\"README\",\"richText\":\"\\u003carticle class=\\\"markdown-body entry-content container-lg\\\" itemprop=\\\"text\\\"\\u003e\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch1 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eTaming Transformers for High-Resolution Image Synthesis\\u003c/h1\\u003e\\u003ca id=\\\"user-content-taming-transformers-for-high-resolution-image-synthesis\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Taming Transformers for High-Resolution Image Synthesis\\\" href=\\\"#taming-transformers-for-high-resolution-image-synthesis\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch5 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCVPR 2021 (Oral)\\u003c/h5\\u003e\\u003ca id=\\\"user-content-cvpr-2021-oral\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: CVPR 2021 (Oral)\\\" href=\\\"#cvpr-2021-oral\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/mountain.jpeg\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/mountain.jpeg\\\" alt=\\\"teaser\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca href=\\\"https://compvis.github.io/taming-transformers/\\\" rel=\\\"nofollow\\\"\\u003e\\u003cstrong\\u003eTaming Transformers for High-Resolution Image Synthesis\\u003c/strong\\u003e\\u003c/a\\u003e\\u003cbr\\u003e\\n\\u003ca href=\\\"https://github.com/pesser\\\"\\u003ePatrick Esser\\u003c/a\\u003e*,\\n\\u003ca href=\\\"https://github.com/rromb\\\"\\u003eRobin Rombach\\u003c/a\\u003e*,\\n\\u003ca href=\\\"https://hci.iwr.uni-heidelberg.de/Staff/bommer\\\" rel=\\\"nofollow\\\"\\u003eBj\u00f6rn Ommer\\u003c/a\\u003e\\u003cbr\\u003e\\n* equal contribution\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003cstrong\\u003etl;dr\\u003c/strong\\u003e We combine the efficiancy of convolutional approaches with the expressivity of transformers by introducing a convolutional VQGAN, which learns a codebook of context-rich visual parts, whose composition is modeled with an autoregressive transformer.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/teaser.png\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/teaser.png\\\" alt=\\\"teaser\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\n\\u003ca href=\\\"https://arxiv.org/abs/2012.09841\\\" rel=\\\"nofollow\\\"\\u003earXiv\\u003c/a\\u003e | \\u003ca href=\\\"#bibtex\\\"\\u003eBibTeX\\u003c/a\\u003e | \\u003ca href=\\\"https://compvis.github.io/taming-transformers/\\\" rel=\\\"nofollow\\\"\\u003eProject Page\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eNews\\u003c/h3\\u003e\\u003ca id=\\\"user-content-news\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: News\\\" href=\\\"#news\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e2022\\u003c/h4\\u003e\\u003ca id=\\\"user-content-2022\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: 2022\\\" href=\\\"#2022\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eMore pretrained VQGANs (e.g. a f8-model with only 256 codebook entries) are available in our new work on \\u003ca href=\\\"https://github.com/CompVis/latent-diffusion\\\"\\u003eLatent Diffusion Models\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eAdded scene synthesis models as proposed in the paper \\u003ca href=\\\"https://arxiv.org/abs/2105.06458\\\" rel=\\\"nofollow\\\"\\u003eHigh-Resolution Complex Scene Synthesis with Transformers\\u003c/a\\u003e, see \\u003ca href=\\\"#scene-image-synthesis\\\"\\u003ethis section\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e2021\\u003c/h4\\u003e\\u003ca id=\\\"user-content-2021\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: 2021\\\" href=\\\"#2021\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eThanks to \\u003ca href=\\\"https://github.com/rom1504\\\"\\u003erom1504\\u003c/a\\u003e it is now easy to \\u003ca href=\\\"#training-on-custom-data\\\"\\u003etrain a VQGAN on your own datasets\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eIncluded a bugfix for the quantizer. For backward compatibility it is\\ndisabled by default (which corresponds to always training with \\u003ccode\\u003ebeta=1.0\\u003c/code\\u003e).\\nUse \\u003ccode\\u003elegacy=False\\u003c/code\\u003e in the quantizer config to enable it.\\nThanks \\u003ca href=\\\"https://github.com/richcmwang\\\"\\u003erichcmwang\\u003c/a\\u003e and \\u003ca href=\\\"https://github.com/wcshin-git\\\"\\u003ewcshin-git\\u003c/a\\u003e!\\u003c/li\\u003e\\n\\u003cli\\u003eOur paper received an update: See \\u003ca href=\\\"https://arxiv.org/abs/2012.09841v3\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2012.09841v3\\u003c/a\\u003e and the corresponding changelog.\\u003c/li\\u003e\\n\\u003cli\\u003eAdded a pretrained, \\u003ca href=\\\"https://k00.fr/s511rwcv\\\" rel=\\\"nofollow\\\"\\u003e1.4B transformer model\\u003c/a\\u003e trained for class-conditional ImageNet synthesis, which obtains state-of-the-art FID scores among autoregressive approaches and outperforms BigGAN.\\u003c/li\\u003e\\n\\u003cli\\u003eAdded pretrained, unconditional models on \\u003ca href=\\\"https://k00.fr/yndvfu95\\\" rel=\\\"nofollow\\\"\\u003eFFHQ\\u003c/a\\u003e and \\u003ca href=\\\"https://k00.fr/2xkmielf\\\" rel=\\\"nofollow\\\"\\u003eCelebA-HQ\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eAdded accelerated sampling via caching of keys/values in the self-attention operation, used in \\u003ccode\\u003escripts/sample_fast.py\\u003c/code\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eAdded a checkpoint of a \\u003ca href=\\\"https://heibox.uni-heidelberg.de/d/2e5662443a6b4307b470/\\\" rel=\\\"nofollow\\\"\\u003eVQGAN\\u003c/a\\u003e trained with f8 compression and Gumbel-Quantization.\\nSee also our updated \\u003ca href=\\\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/reconstruction_usage.ipynb\\\" rel=\\\"nofollow\\\"\\u003ereconstruction notebook\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eWe added a \\u003ca href=\\\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/reconstruction_usage.ipynb\\\" rel=\\\"nofollow\\\"\\u003ecolab notebook\\u003c/a\\u003e which compares two VQGANs and OpenAI's \\u003ca href=\\\"https://github.com/openai/DALL-E\\\"\\u003eDALL-E\\u003c/a\\u003e. See also \\u003ca href=\\\"#more-resources\\\"\\u003ethis section\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eWe now include an overview of pretrained models in \\u003ca href=\\\"#overview-of-pretrained-models\\\"\\u003eTab.1\\u003c/a\\u003e. We added models for \\u003ca href=\\\"#coco\\\"\\u003eCOCO\\u003c/a\\u003e and \\u003ca href=\\\"#ade20k\\\"\\u003eADE20k\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eThe streamlit demo now supports image completions.\\u003c/li\\u003e\\n\\u003cli\\u003eWe now include a couple of examples from the D-RIN dataset so you can run the\\n\\u003ca href=\\\"#d-rin\\\"\\u003eD-RIN demo\\u003c/a\\u003e without preparing the dataset first.\\u003c/li\\u003e\\n\\u003cli\\u003eYou can now jump right into sampling with our \\u003ca href=\\\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb\\\" rel=\\\"nofollow\\\"\\u003eColab quickstart notebook\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eRequirements\\u003c/h2\\u003e\\u003ca id=\\\"user-content-requirements\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Requirements\\\" href=\\\"#requirements\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eA suitable \\u003ca href=\\\"https://conda.io/\\\" rel=\\\"nofollow\\\"\\u003econda\\u003c/a\\u003e environment named \\u003ccode\\u003etaming\\u003c/code\\u003e can be created\\nand activated with:\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"conda env create -f environment.yaml\\nconda activate taming\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003econda env create -f environment.yaml\\nconda activate taming\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eOverview of pretrained models\\u003c/h2\\u003e\\u003ca id=\\\"user-content-overview-of-pretrained-models\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Overview of pretrained models\\\" href=\\\"#overview-of-pretrained-models\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe following table provides an overview of all models that are currently available.\\nFID scores were evaluated using \\u003ca href=\\\"https://github.com/toshas/torch-fidelity\\\"\\u003etorch-fidelity\\u003c/a\\u003e.\\nFor reference, we also include a link to the recently released autoencoder of the \\u003ca href=\\\"https://github.com/openai/DALL-E\\\"\\u003eDALL-E\\u003c/a\\u003e model.\\nSee the corresponding \\u003ca href=\\\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/reconstruction_usage.ipynb\\\" rel=\\\"nofollow\\\"\\u003ecolab\\nnotebook\\u003c/a\\u003e\\nfor a comparison and discussion of reconstruction capabilities.\\u003c/p\\u003e\\n\\u003ctable\\u003e\\n\\u003cthead\\u003e\\n\\u003ctr\\u003e\\n\\u003cth\\u003eDataset\\u003c/th\\u003e\\n\\u003cth\\u003eFID vs train\\u003c/th\\u003e\\n\\u003cth\\u003eFID vs val\\u003c/th\\u003e\\n\\u003cth\\u003eLink\\u003c/th\\u003e\\n\\u003cth\\u003eSamples (256x256)\\u003c/th\\u003e\\n\\u003cth\\u003eComments\\u003c/th\\u003e\\n\\u003c/tr\\u003e\\n\\u003c/thead\\u003e\\n\\u003ctbody\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eFFHQ (f=16)\\u003c/td\\u003e\\n\\u003ctd\\u003e9.6\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/yndvfu95\\\" rel=\\\"nofollow\\\"\\u003effhq_transformer\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/j626x093\\\" rel=\\\"nofollow\\\"\\u003effhq_samples\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eCelebA-HQ (f=16)\\u003c/td\\u003e\\n\\u003ctd\\u003e10.2\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/2xkmielf\\\" rel=\\\"nofollow\\\"\\u003ecelebahq_transformer\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/j626x093\\\" rel=\\\"nofollow\\\"\\u003ecelebahq_samples\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eADE20K (f=16)\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e35.5\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/ot46cksa\\\" rel=\\\"nofollow\\\"\\u003eade20k_transformer\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://heibox.uni-heidelberg.de/f/70bb78cbaf844501b8fb/\\\" rel=\\\"nofollow\\\"\\u003eade20k_samples.zip\\u003c/a\\u003e [2k]\\u003c/td\\u003e\\n\\u003ctd\\u003eevaluated on val split (2k images)\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eCOCO-Stuff (f=16)\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e20.4\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/2zz6i2ce\\\" rel=\\\"nofollow\\\"\\u003ecoco_transformer\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://heibox.uni-heidelberg.de/f/a395a9be612f4a7a8054/\\\" rel=\\\"nofollow\\\"\\u003ecoco_samples.zip\\u003c/a\\u003e [5k]\\u003c/td\\u003e\\n\\u003ctd\\u003eevaluated on val split (5k images)\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eImageNet (cIN) (f=16)\\u003c/td\\u003e\\n\\u003ctd\\u003e15.98/15.78/6.59/5.88/5.20\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/s511rwcv\\\" rel=\\\"nofollow\\\"\\u003ecin_transformer\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/j626x093\\\" rel=\\\"nofollow\\\"\\u003ecin_samples\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003edifferent decoding hyperparameters\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eFacesHQ (f=16)\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/qqfl2do8\\\" rel=\\\"nofollow\\\"\\u003efaceshq_transformer\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eS-FLCKR (f=16)\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://heibox.uni-heidelberg.de/d/73487ab6e5314cb5adba/\\\" rel=\\\"nofollow\\\"\\u003esflckr\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eD-RIN (f=16)\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/39jcugc5\\\" rel=\\\"nofollow\\\"\\u003edrin_transformer\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eVQGAN ImageNet (f=16), 1024\\u003c/td\\u003e\\n\\u003ctd\\u003e10.54\\u003c/td\\u003e\\n\\u003ctd\\u003e7.94\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://heibox.uni-heidelberg.de/d/8088892a516d4e3baf92/\\\" rel=\\\"nofollow\\\"\\u003evqgan_imagenet_f16_1024\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/j626x093\\\" rel=\\\"nofollow\\\"\\u003ereconstructions\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eReconstruction-FIDs.\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eVQGAN ImageNet (f=16), 16384\\u003c/td\\u003e\\n\\u003ctd\\u003e7.41\\u003c/td\\u003e\\n\\u003ctd\\u003e4.98\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/\\\" rel=\\\"nofollow\\\"\\u003evqgan_imagenet_f16_16384\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/j626x093\\\" rel=\\\"nofollow\\\"\\u003ereconstructions\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eReconstruction-FIDs.\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eVQGAN OpenImages (f=8), 256\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e1.49\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip\\\" rel=\\\"nofollow\\\"\\u003ehttps://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e---\\u003c/td\\u003e\\n\\u003ctd\\u003eReconstruction-FIDs. Available via \\u003ca href=\\\"https://github.com/CompVis/latent-diffusion\\\"\\u003elatent diffusion\\u003c/a\\u003e.\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eVQGAN OpenImages (f=8), 16384\\u003c/td\\u003e\\n\\u003ctd\\u003e--\\u003c/td\\u003e\\n\\u003ctd\\u003e1.14\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://ommer-lab.com/files/latent-diffusion/vq-f8.zip\\\" rel=\\\"nofollow\\\"\\u003ehttps://ommer-lab.com/files/latent-diffusion/vq-f8.zip\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e---\\u003c/td\\u003e\\n\\u003ctd\\u003eReconstruction-FIDs. Available via \\u003ca href=\\\"https://github.com/CompVis/latent-diffusion\\\"\\u003elatent diffusion\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eVQGAN OpenImages (f=8), 8192, GumbelQuantization\\u003c/td\\u003e\\n\\u003ctd\\u003e3.24\\u003c/td\\u003e\\n\\u003ctd\\u003e1.49\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://heibox.uni-heidelberg.de/d/2e5662443a6b4307b470/\\\" rel=\\\"nofollow\\\"\\u003evqgan_gumbel_f8\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e---\\u003c/td\\u003e\\n\\u003ctd\\u003eReconstruction-FIDs.\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eDALL-E dVAE (f=8), 8192, GumbelQuantization\\u003c/td\\u003e\\n\\u003ctd\\u003e33.88\\u003c/td\\u003e\\n\\u003ctd\\u003e32.01\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/openai/DALL-E\\\"\\u003ehttps://github.com/openai/DALL-E\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://k00.fr/j626x093\\\" rel=\\\"nofollow\\\"\\u003ereconstructions\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eReconstruction-FIDs.\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003c/tbody\\u003e\\n\\u003c/table\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eRunning pretrained models\\u003c/h2\\u003e\\u003ca id=\\\"user-content-running-pretrained-models\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Running pretrained models\\\" href=\\\"#running-pretrained-models\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe commands below will start a streamlit demo which supports sampling at\\ndifferent resolutions and image completions. To run a non-interactive version\\nof the sampling process, replace \\u003ccode\\u003estreamlit run scripts/sample_conditional.py --\\u003c/code\\u003e\\nby \\u003ccode\\u003epython scripts/make_samples.py --outdir \\u0026lt;path_to_write_samples_to\\u0026gt;\\u003c/code\\u003e and\\nkeep the remaining command line arguments.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTo sample from unconditional or class-conditional models,\\nrun \\u003ccode\\u003epython scripts/sample_fast.py -r \\u0026lt;path/to/config_and_checkpoint\\u0026gt;\\u003c/code\\u003e.\\nWe describe below how to use this script to sample from the ImageNet, FFHQ, and CelebA-HQ models,\\nrespectively.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eS-FLCKR\\u003c/h3\\u003e\\u003ca id=\\\"user-content-s-flckr\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: S-FLCKR\\\" href=\\\"#s-flckr\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/sunset_and_ocean.jpg\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/sunset_and_ocean.jpg\\\" alt=\\\"teaser\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eYou can also \\u003ca href=\\\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb\\\" rel=\\\"nofollow\\\"\\u003erun this model in a Colab\\nnotebook\\u003c/a\\u003e,\\nwhich includes all necessary steps to start sampling.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDownload the\\n\\u003ca href=\\\"https://heibox.uni-heidelberg.de/d/73487ab6e5314cb5adba/\\\" rel=\\\"nofollow\\\"\\u003e2020-11-09T13-31-51_sflckr\\u003c/a\\u003e\\nfolder and place it into \\u003ccode\\u003elogs\\u003c/code\\u003e. Then, run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-09T13-31-51_sflckr/\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003estreamlit run scripts/sample_conditional.py -- -r logs/2020-11-09T13-31-51_sflckr/\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eImageNet\\u003c/h3\\u003e\\u003ca id=\\\"user-content-imagenet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: ImageNet\\\" href=\\\"#imagenet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/imagenet.png\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/imagenet.png\\\" alt=\\\"teaser\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDownload the \\u003ca href=\\\"https://k00.fr/s511rwcv\\\" rel=\\\"nofollow\\\"\\u003e2021-04-03T19-39-50_cin_transformer\\u003c/a\\u003e\\nfolder and place it into logs.  Sampling from the class-conditional ImageNet\\nmodel does not require any data preparation. To produce 50 samples for each of\\nthe 1000 classes of ImageNet, with k=600 for top-k sampling, p=0.92 for nucleus\\nsampling and temperature t=1.0, run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python scripts/sample_fast.py -r logs/2021-04-03T19-39-50_cin_transformer/ -n 50 -k 600 -t 1.0 -p 0.92 --batch_size 25   \\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython scripts/sample_fast.py -r logs/2021-04-03T19-39-50_cin_transformer/ -n 50 -k 600 -t 1.0 -p 0.92 --batch_size 25   \\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTo restrict the model to certain classes, provide them via the \\u003ccode\\u003e--classes\\u003c/code\\u003e argument, separated by\\ncommas. For example, to sample 50 \\u003cem\\u003eostriches\\u003c/em\\u003e, \\u003cem\\u003eborder collies\\u003c/em\\u003e and \\u003cem\\u003ewhiskey jugs\\u003c/em\\u003e, run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python scripts/sample_fast.py -r logs/2021-04-03T19-39-50_cin_transformer/ -n 50 -k 600 -t 1.0 -p 0.92 --batch_size 25 --classes 9,232,901   \\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython scripts/sample_fast.py -r logs/2021-04-03T19-39-50_cin_transformer/ -n 50 -k 600 -t 1.0 -p 0.92 --batch_size 25 --classes 9,232,901   \\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eWe recommended to experiment with the autoregressive decoding parameters (top-k, top-p and temperature) for best results.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFFHQ/CelebA-HQ\\u003c/h3\\u003e\\u003ca id=\\\"user-content-ffhqceleba-hq\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: FFHQ/CelebA-HQ\\\" href=\\\"#ffhqceleba-hq\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDownload the \\u003ca href=\\\"https://k00.fr/yndvfu95\\\" rel=\\\"nofollow\\\"\\u003e2021-04-23T18-19-01_ffhq_transformer\\u003c/a\\u003e and\\n\\u003ca href=\\\"https://k00.fr/2xkmielf\\\" rel=\\\"nofollow\\\"\\u003e2021-04-23T18-11-19_celebahq_transformer\\u003c/a\\u003e\\nfolders and place them into logs.\\nAgain, sampling from these unconditional models does not require any data preparation.\\nTo produce 50000 samples, with k=250 for top-k sampling,\\np=1.0 for nucleus sampling and temperature t=1.0, run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python scripts/sample_fast.py -r logs/2021-04-23T18-19-01_ffhq_transformer/   \\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython scripts/sample_fast.py -r logs/2021-04-23T18-19-01_ffhq_transformer/   \\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003efor FFHQ and\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python scripts/sample_fast.py -r logs/2021-04-23T18-11-19_celebahq_transformer/   \\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython scripts/sample_fast.py -r logs/2021-04-23T18-11-19_celebahq_transformer/   \\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eto sample from the CelebA-HQ model.\\nFor both models it can be advantageous to vary the top-k/top-p parameters for sampling.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFacesHQ\\u003c/h3\\u003e\\u003ca id=\\\"user-content-faceshq\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: FacesHQ\\\" href=\\\"#faceshq\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/faceshq.jpg\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/faceshq.jpg\\\" alt=\\\"teaser\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDownload \\u003ca href=\\\"https://k00.fr/qqfl2do8\\\" rel=\\\"nofollow\\\"\\u003e2020-11-13T21-41-45_faceshq_transformer\\u003c/a\\u003e and\\nplace it into \\u003ccode\\u003elogs\\u003c/code\\u003e. Follow the data preparation steps for\\n\\u003ca href=\\\"#celeba-hq\\\"\\u003eCelebA-HQ\\u003c/a\\u003e and \\u003ca href=\\\"#ffhq\\\"\\u003eFFHQ\\u003c/a\\u003e. Run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-13T21-41-45_faceshq_transformer/\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003estreamlit run scripts/sample_conditional.py -- -r logs/2020-11-13T21-41-45_faceshq_transformer/\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eD-RIN\\u003c/h3\\u003e\\u003ca id=\\\"user-content-d-rin\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: D-RIN\\\" href=\\\"#d-rin\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/drin.jpg\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/drin.jpg\\\" alt=\\\"teaser\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDownload \\u003ca href=\\\"https://k00.fr/39jcugc5\\\" rel=\\\"nofollow\\\"\\u003e2020-11-20T12-54-32_drin_transformer\\u003c/a\\u003e and\\nplace it into \\u003ccode\\u003elogs\\u003c/code\\u003e. To run the demo on a couple of example depth maps\\nincluded in the repository, run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T12-54-32_drin_transformer/ --ignore_base_data data=\\u0026quot;{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.imagenet.DRINExamples}}}\\u0026quot;\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003estreamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T12-54-32_drin_transformer/ --ignore_base_data data=\\\"{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.imagenet.DRINExamples}}}\\\"\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTo run the demo on the complete validation set, first follow the data preparation steps for\\n\\u003ca href=\\\"#imagenet\\\"\\u003eImageNet\\u003c/a\\u003e and then run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T12-54-32_drin_transformer/\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003estreamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T12-54-32_drin_transformer/\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCOCO\\u003c/h3\\u003e\\u003ca id=\\\"user-content-coco\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: COCO\\\" href=\\\"#coco\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDownload \\u003ca href=\\\"https://k00.fr/2zz6i2ce\\\" rel=\\\"nofollow\\\"\\u003e2021-01-20T16-04-20_coco_transformer\\u003c/a\\u003e and\\nplace it into \\u003ccode\\u003elogs\\u003c/code\\u003e. To run the demo on a couple of example segmentation maps\\nincluded in the repository, run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"streamlit run scripts/sample_conditional.py -- -r logs/2021-01-20T16-04-20_coco_transformer/ --ignore_base_data data=\\u0026quot;{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.coco.Examples}}}\\u0026quot;\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003estreamlit run scripts/sample_conditional.py -- -r logs/2021-01-20T16-04-20_coco_transformer/ --ignore_base_data data=\\\"{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.coco.Examples}}}\\\"\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eADE20k\\u003c/h3\\u003e\\u003ca id=\\\"user-content-ade20k\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: ADE20k\\\" href=\\\"#ade20k\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDownload \\u003ca href=\\\"https://k00.fr/ot46cksa\\\" rel=\\\"nofollow\\\"\\u003e2020-11-20T21-45-44_ade20k_transformer\\u003c/a\\u003e and\\nplace it into \\u003ccode\\u003elogs\\u003c/code\\u003e. To run the demo on a couple of example segmentation maps\\nincluded in the repository, run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T21-45-44_ade20k_transformer/ --ignore_base_data data=\\u0026quot;{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.ade20k.Examples}}}\\u0026quot;\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003estreamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T21-45-44_ade20k_transformer/ --ignore_base_data data=\\\"{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.ade20k.Examples}}}\\\"\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eScene Image Synthesis\\u003c/h2\\u003e\\u003ca id=\\\"user-content-scene-image-synthesis\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Scene Image Synthesis\\\" href=\\\"#scene-image-synthesis\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/scene_images_samples.svg\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/scene_images_samples.svg\\\" alt=\\\"teaser\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\nScene image generation based on bounding box conditionals as done in our CVPR2021 AI4CC workshop paper \\u003ca href=\\\"https://arxiv.org/abs/2105.06458\\\" rel=\\\"nofollow\\\"\\u003eHigh-Resolution Complex Scene Synthesis with Transformers\\u003c/a\\u003e (see talk on \\u003ca href=\\\"https://visual.cs.brown.edu/workshops/aicc2021/#awards\\\" rel=\\\"nofollow\\\"\\u003eworkshop page\\u003c/a\\u003e). Supporting the datasets COCO and Open Images.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eTraining\\u003c/h3\\u003e\\u003ca id=\\\"user-content-training\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Training\\\" href=\\\"#training\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDownload first-stage models \\u003ca href=\\\"https://heibox.uni-heidelberg.de/f/78dea9589974474c97c1/\\\" rel=\\\"nofollow\\\"\\u003eCOCO-8k-VQGAN\\u003c/a\\u003e for COCO or \\u003ca href=\\\"https://heibox.uni-heidelberg.de/f/461d9a9f4fcf48ab84f4/\\\" rel=\\\"nofollow\\\"\\u003eCOCO/Open-Images-8k-VQGAN\\u003c/a\\u003e for Open Images.\\nChange \\u003ccode\\u003eckpt_path\\u003c/code\\u003e in \\u003ccode\\u003edata/coco_scene_images_transformer.yaml\\u003c/code\\u003e and \\u003ccode\\u003edata/open_images_scene_images_transformer.yaml\\u003c/code\\u003e to point to the downloaded first-stage models.\\nDownload the full COCO/OI datasets and adapt \\u003ccode\\u003edata_path\\u003c/code\\u003e in the same files, unless working with the 100 files provided for training and validation suits your needs already.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eCode can be run with\\n\\u003ccode\\u003epython main.py --base configs/coco_scene_images_transformer.yaml -t True --gpus 0,\\u003c/code\\u003e\\nor\\n\\u003ccode\\u003epython main.py --base configs/open_images_scene_images_transformer.yaml -t True --gpus 0,\\u003c/code\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eSampling\\u003c/h3\\u003e\\u003ca id=\\\"user-content-sampling\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Sampling\\\" href=\\\"#sampling\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTrain a model as described above or download a pre-trained model:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://drive.google.com/file/d/1FEK-Z7hyWJBvFWQF50pzSK9y1W_CJEig/view?usp=sharing\\\" rel=\\\"nofollow\\\"\\u003eOpen Images 1 billion parameter model\\u003c/a\\u003e available that trained 100 epochs. On 256x256 pixels, FID 41.48\u00b10.21, SceneFID 14.60\u00b10.15, Inception Score 18.47\u00b10.27. The model was trained with 2d crops of images and is thus well-prepared for the task of generating high-resolution images, e.g. 512x512.\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://drive.google.com/file/d/1xf89g0mc78J3d8Bx5YhbK4tNRNlOoYaO\\\" rel=\\\"nofollow\\\"\\u003eOpen Images distilled version of the above model with 125 million parameters\\u003c/a\\u003e allows for sampling on smaller GPUs (4 GB is enough for sampling 256x256 px images). Model was trained for 60 epochs with 10% soft loss, 90% hard loss. On 256x256 pixels, FID 43.07\u00b10.40, SceneFID 15.93\u00b10.19, Inception Score 17.23\u00b10.11.\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://heibox.uni-heidelberg.de/f/0d0b2594e9074c7e9a33/\\\" rel=\\\"nofollow\\\"\\u003eCOCO 30 epochs\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://drive.google.com/file/d/1bInd49g2YulTJBjU32Awyt5qnzxxG5U9/\\\" rel=\\\"nofollow\\\"\\u003eCOCO 60 epochs\\u003c/a\\u003e (find model statistics for both COCO versions in \\u003ccode\\u003eassets/coco_scene_images_training.svg\\u003c/code\\u003e)\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eWhen downloading a pre-trained model, remember to change \\u003ccode\\u003eckpt_path\\u003c/code\\u003e in \\u003ccode\\u003econfigs/*project.yaml\\u003c/code\\u003e to point to your downloaded first-stage model (see -\\u0026gt;Training).\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eScene image generation can be run with\\n\\u003ccode\\u003epython scripts/make_scene_samples.py --outdir=/some/outdir -r /path/to/pretrained/model --resolution=512,512\\u003c/code\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eTraining on custom data\\u003c/h2\\u003e\\u003ca id=\\\"user-content-training-on-custom-data\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Training on custom data\\\" href=\\\"#training-on-custom-data\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTraining on your own dataset can be beneficial to get better tokens and hence better images for your domain.\\nThose are the steps to follow to make this work:\\u003c/p\\u003e\\n\\u003col dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003einstall the repo with \\u003ccode\\u003econda env create -f environment.yaml\\u003c/code\\u003e, \\u003ccode\\u003econda activate taming\\u003c/code\\u003e and \\u003ccode\\u003epip install -e .\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eput your .jpg files in a folder \\u003ccode\\u003eyour_folder\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003ecreate 2 text files a \\u003ccode\\u003exx_train.txt\\u003c/code\\u003e and \\u003ccode\\u003exx_test.txt\\u003c/code\\u003e that point to the files in your training and test set respectively (for example \\u003ccode\\u003efind $(pwd)/your_folder -name \\\"*.jpg\\\" \\u0026gt; train.txt\\u003c/code\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eadapt \\u003ccode\\u003econfigs/custom_vqgan.yaml\\u003c/code\\u003e to point to these 2 files\\u003c/li\\u003e\\n\\u003cli\\u003erun \\u003ccode\\u003epython main.py --base configs/custom_vqgan.yaml -t True --gpus 0,1\\u003c/code\\u003e to\\ntrain on two GPUs. Use \\u003ccode\\u003e--gpus 0,\\u003c/code\\u003e (with a trailing comma) to train on a single GPU.\\u003c/li\\u003e\\n\\u003c/ol\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eData Preparation\\u003c/h2\\u003e\\u003ca id=\\\"user-content-data-preparation\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Data Preparation\\\" href=\\\"#data-preparation\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eImageNet\\u003c/h3\\u003e\\u003ca id=\\\"user-content-imagenet-1\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: ImageNet\\\" href=\\\"#imagenet-1\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe code will try to download (through \\u003ca href=\\\"http://academictorrents.com/\\\" rel=\\\"nofollow\\\"\\u003eAcademic\\nTorrents\\u003c/a\\u003e) and prepare ImageNet the first time it\\nis used. However, since ImageNet is quite large, this requires a lot of disk\\nspace and time. If you already have ImageNet on your disk, you can speed things\\nup by putting the data into\\n\\u003ccode\\u003e${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/\\u003c/code\\u003e (which defaults to\\n\\u003ccode\\u003e~/.cache/autoencoders/data/ILSVRC2012_{split}/data/\\u003c/code\\u003e), where \\u003ccode\\u003e{split}\\u003c/code\\u003e is one\\nof \\u003ccode\\u003etrain\\u003c/code\\u003e/\\u003ccode\\u003evalidation\\u003c/code\\u003e. It should have the following structure:\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/\\n\u251c\u2500\u2500 n01440764\\n\u2502   \u251c\u2500\u2500 n01440764_10026.JPEG\\n\u2502   \u251c\u2500\u2500 n01440764_10027.JPEG\\n\u2502   \u251c\u2500\u2500 ...\\n\u251c\u2500\u2500 n01443537\\n\u2502   \u251c\u2500\u2500 n01443537_10007.JPEG\\n\u2502   \u251c\u2500\u2500 n01443537_10014.JPEG\\n\u2502   \u251c\u2500\u2500 ...\\n\u251c\u2500\u2500 ...\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003e${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/\\n\u251c\u2500\u2500 n01440764\\n\u2502   \u251c\u2500\u2500 n01440764_10026.JPEG\\n\u2502   \u251c\u2500\u2500 n01440764_10027.JPEG\\n\u2502   \u251c\u2500\u2500 ...\\n\u251c\u2500\u2500 n01443537\\n\u2502   \u251c\u2500\u2500 n01443537_10007.JPEG\\n\u2502   \u251c\u2500\u2500 n01443537_10014.JPEG\\n\u2502   \u251c\u2500\u2500 ...\\n\u251c\u2500\u2500 ...\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eIf you haven't extracted the data, you can also place\\n\\u003ccode\\u003eILSVRC2012_img_train.tar\\u003c/code\\u003e/\\u003ccode\\u003eILSVRC2012_img_val.tar\\u003c/code\\u003e (or symlinks to them) into\\n\\u003ccode\\u003e${XDG_CACHE}/autoencoders/data/ILSVRC2012_train/\\u003c/code\\u003e /\\n\\u003ccode\\u003e${XDG_CACHE}/autoencoders/data/ILSVRC2012_validation/\\u003c/code\\u003e, which will then be\\nextracted into above structure without downloading it again.  Note that this\\nwill only happen if neither a folder\\n\\u003ccode\\u003e${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/\\u003c/code\\u003e nor a file\\n\\u003ccode\\u003e${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/.ready\\u003c/code\\u003e exist. Remove them\\nif you want to force running the dataset preparation again.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eYou will then need to prepare the depth data using\\n\\u003ca href=\\\"https://github.com/intel-isl/MiDaS\\\"\\u003eMiDaS\\u003c/a\\u003e. Create a symlink\\n\\u003ccode\\u003edata/imagenet_depth\\u003c/code\\u003e pointing to a folder with two subfolders \\u003ccode\\u003etrain\\u003c/code\\u003e and\\n\\u003ccode\\u003eval\\u003c/code\\u003e, each mirroring the structure of the corresponding ImageNet folder\\ndescribed above and containing a \\u003ccode\\u003epng\\u003c/code\\u003e file for each of ImageNet's \\u003ccode\\u003eJPEG\\u003c/code\\u003e\\nfiles. The \\u003ccode\\u003epng\\u003c/code\\u003e encodes \\u003ccode\\u003efloat32\\u003c/code\\u003e depth values obtained from MiDaS as RGBA\\nimages. We provide the script \\u003ccode\\u003escripts/extract_depth.py\\u003c/code\\u003e to generate this data.\\n\\u003cstrong\\u003ePlease note\\u003c/strong\\u003e that this script uses \\u003ca href=\\\"https://pytorch.org/hub/intelisl_midas_v2/\\\" rel=\\\"nofollow\\\"\\u003eMiDaS via PyTorch\\nHub\\u003c/a\\u003e. When we prepared the data,\\nthe hub provided the \\u003ca href=\\\"https://github.com/intel-isl/MiDaS/releases/tag/v2\\\"\\u003eMiDaS\\nv2.0\\u003c/a\\u003e version, but now it\\nprovides a v2.1 version. We haven't tested our models with depth maps obtained\\nvia v2.1 and if you want to make sure that things work as expected, you must\\nadjust the script to make sure it explicitly uses\\n\\u003ca href=\\\"https://github.com/intel-isl/MiDaS/releases/tag/v2\\\"\\u003ev2.0\\u003c/a\\u003e!\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCelebA-HQ\\u003c/h3\\u003e\\u003ca id=\\\"user-content-celeba-hq\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: CelebA-HQ\\\" href=\\\"#celeba-hq\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eCreate a symlink \\u003ccode\\u003edata/celebahq\\u003c/code\\u003e pointing to a folder containing the \\u003ccode\\u003e.npy\\u003c/code\\u003e\\nfiles of CelebA-HQ (instructions to obtain them can be found in the \\u003ca href=\\\"https://github.com/tkarras/progressive_growing_of_gans\\\"\\u003ePGGAN\\nrepository\\u003c/a\\u003e).\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFFHQ\\u003c/h3\\u003e\\u003ca id=\\\"user-content-ffhq\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: FFHQ\\\" href=\\\"#ffhq\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eCreate a symlink \\u003ccode\\u003edata/ffhq\\u003c/code\\u003e pointing to the \\u003ccode\\u003eimages1024x1024\\u003c/code\\u003e folder obtained\\nfrom the \\u003ca href=\\\"https://github.com/NVlabs/ffhq-dataset\\\"\\u003eFFHQ repository\\u003c/a\\u003e.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eS-FLCKR\\u003c/h3\\u003e\\u003ca id=\\\"user-content-s-flckr-1\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: S-FLCKR\\\" href=\\\"#s-flckr-1\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eUnfortunately, we are not allowed to distribute the images we collected for the\\nS-FLCKR dataset and can therefore only give a description how it was produced.\\nThere are many resources on \\u003ca href=\\\"https://github.com/adrianmrit/flickrdatasets\\\"\\u003ecollecting images from the\\nweb\\u003c/a\\u003e to get started.\\nWe collected sufficiently large images from \\u003ca href=\\\"https://www.flickr.com\\\" rel=\\\"nofollow\\\"\\u003eflickr\\u003c/a\\u003e\\n(see \\u003ccode\\u003edata/flickr_tags.txt\\u003c/code\\u003e for a full list of tags used to find images)\\nand various \\u003ca href=\\\"https://www.reddit.com/r/sfwpornnetwork/wiki/network\\\" rel=\\\"nofollow\\\"\\u003esubreddits\\u003c/a\\u003e\\n(see \\u003ccode\\u003edata/subreddits.txt\\u003c/code\\u003e for all subreddits that were used).\\nOverall, we collected 107625 images, and split them randomly into 96861\\ntraining images and 10764 validation images. We then obtained segmentation\\nmasks for each image using \\u003ca href=\\\"https://arxiv.org/abs/1606.00915\\\" rel=\\\"nofollow\\\"\\u003eDeepLab v2\\u003c/a\\u003e\\ntrained on \\u003ca href=\\\"https://arxiv.org/abs/1612.03716\\\" rel=\\\"nofollow\\\"\\u003eCOCO-Stuff\\u003c/a\\u003e. We used a \\u003ca href=\\\"https://github.com/kazuto1011/deeplab-pytorch\\\"\\u003ePyTorch\\nreimplementation\\u003c/a\\u003e and include an\\nexample script for this process in \\u003ccode\\u003escripts/extract_segmentation.py\\u003c/code\\u003e.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCOCO\\u003c/h3\\u003e\\u003ca id=\\\"user-content-coco-1\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: COCO\\\" href=\\\"#coco-1\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eCreate a symlink \\u003ccode\\u003edata/coco\\u003c/code\\u003e containing the images from the 2017 split in\\n\\u003ccode\\u003etrain2017\\u003c/code\\u003e and \\u003ccode\\u003eval2017\\u003c/code\\u003e, and their annotations in \\u003ccode\\u003eannotations\\u003c/code\\u003e. Files can be\\nobtained from the \\u003ca href=\\\"https://cocodataset.org/\\\" rel=\\\"nofollow\\\"\\u003eCOCO webpage\\u003c/a\\u003e. In addition, we use\\nthe \\u003ca href=\\\"http://calvin.inf.ed.ac.uk/wp-content/uploads/data/cocostuffdataset/stuffthingmaps_trainval2017.zip\\\" rel=\\\"nofollow\\\"\\u003eStuff+thing PNG-style annotations on COCO 2017\\ntrainval\\u003c/a\\u003e\\nannotations from \\u003ca href=\\\"https://github.com/nightrome/cocostuff\\\"\\u003eCOCO-Stuff\\u003c/a\\u003e, which\\nshould be placed under \\u003ccode\\u003edata/cocostuffthings\\u003c/code\\u003e.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eADE20k\\u003c/h3\\u003e\\u003ca id=\\\"user-content-ade20k-1\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: ADE20k\\\" href=\\\"#ade20k-1\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eCreate a symlink \\u003ccode\\u003edata/ade20k_root\\u003c/code\\u003e containing the contents of\\n\\u003ca href=\\\"http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\\\" rel=\\\"nofollow\\\"\\u003eADEChallengeData2016.zip\\u003c/a\\u003e\\nfrom the \\u003ca href=\\\"http://sceneparsing.csail.mit.edu/\\\" rel=\\\"nofollow\\\"\\u003eMIT Scene Parsing Benchmark\\u003c/a\\u003e.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eTraining models\\u003c/h2\\u003e\\u003ca id=\\\"user-content-training-models\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Training models\\\" href=\\\"#training-models\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFacesHQ\\u003c/h3\\u003e\\u003ca id=\\\"user-content-faceshq-1\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: FacesHQ\\\" href=\\\"#faceshq-1\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTrain a VQGAN with\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python main.py --base configs/faceshq_vqgan.yaml -t True --gpus 0,\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython main.py --base configs/faceshq_vqgan.yaml -t True --gpus 0,\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThen, adjust the checkpoint path of the config key\\n\\u003ccode\\u003emodel.params.first_stage_config.params.ckpt_path\\u003c/code\\u003e in\\n\\u003ccode\\u003econfigs/faceshq_transformer.yaml\\u003c/code\\u003e (or download\\n\\u003ca href=\\\"https://k00.fr/uxy5usa9\\\" rel=\\\"nofollow\\\"\\u003e2020-11-09T13-33-36_faceshq_vqgan\\u003c/a\\u003e and place into \\u003ccode\\u003elogs\\u003c/code\\u003e, which\\ncorresponds to the preconfigured checkpoint path), then run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python main.py --base configs/faceshq_transformer.yaml -t True --gpus 0,\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython main.py --base configs/faceshq_transformer.yaml -t True --gpus 0,\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eD-RIN\\u003c/h3\\u003e\\u003ca id=\\\"user-content-d-rin-1\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: D-RIN\\\" href=\\\"#d-rin-1\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTrain a VQGAN on ImageNet with\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python main.py --base configs/imagenet_vqgan.yaml -t True --gpus 0,\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython main.py --base configs/imagenet_vqgan.yaml -t True --gpus 0,\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eor download a pretrained one from \\u003ca href=\\\"https://k00.fr/u0j2dtac\\\" rel=\\\"nofollow\\\"\\u003e2020-09-23T17-56-33_imagenet_vqgan\\u003c/a\\u003e\\nand place under \\u003ccode\\u003elogs\\u003c/code\\u003e. If you trained your own, adjust the path in the config\\nkey \\u003ccode\\u003emodel.params.first_stage_config.params.ckpt_path\\u003c/code\\u003e of\\n\\u003ccode\\u003econfigs/drin_transformer.yaml\\u003c/code\\u003e.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTrain a VQGAN on Depth Maps of ImageNet with\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python main.py --base configs/imagenetdepth_vqgan.yaml -t True --gpus 0,\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython main.py --base configs/imagenetdepth_vqgan.yaml -t True --gpus 0,\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eor download a pretrained one from \\u003ca href=\\\"https://k00.fr/55rlxs6i\\\" rel=\\\"nofollow\\\"\\u003e2020-11-03T15-34-24_imagenetdepth_vqgan\\u003c/a\\u003e\\nand place under \\u003ccode\\u003elogs\\u003c/code\\u003e. If you trained your own, adjust the path in the config\\nkey \\u003ccode\\u003emodel.params.cond_stage_config.params.ckpt_path\\u003c/code\\u003e of\\n\\u003ccode\\u003econfigs/drin_transformer.yaml\\u003c/code\\u003e.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eTo train the transformer, run\\u003c/p\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"python main.py --base configs/drin_transformer.yaml -t True --gpus 0,\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003epython main.py --base configs/drin_transformer.yaml -t True --gpus 0,\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eMore Resources\\u003c/h2\\u003e\\u003ca id=\\\"user-content-more-resources\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: More Resources\\\" href=\\\"#more-resources\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eComparing Different First Stage Models\\u003c/h3\\u003e\\u003ca id=\\\"user-content-comparing-different-first-stage-models\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Comparing Different First Stage Models\\\" href=\\\"#comparing-different-first-stage-models\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe reconstruction and compression capabilities of different fist stage models can be analyzed in this \\u003ca href=\\\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/reconstruction_usage.ipynb\\\" rel=\\\"nofollow\\\"\\u003ecolab notebook\\u003c/a\\u003e.\\nIn particular, the notebook compares two VQGANs with a downsampling factor of f=16 for each and codebook dimensionality of 1024 and 16384,\\na VQGAN with f=8 and 8192 codebook entries and the discrete autoencoder of OpenAI's \\u003ca href=\\\"https://github.com/openai/DALL-E\\\"\\u003eDALL-E\\u003c/a\\u003e (which has f=8 and 8192\\ncodebook entries).\\n\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/first_stage_squirrels.png\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/first_stage_squirrels.png\\\" alt=\\\"firststages1\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\n\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/first_stage_mushrooms.png\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/first_stage_mushrooms.png\\\" alt=\\\"firststages2\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eOther\\u003c/h3\\u003e\\u003ca id=\\\"user-content-other\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Other\\\" href=\\\"#other\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eA \\u003ca href=\\\"https://www.youtube.com/watch?v=o7dqGcLDf0A\\u0026amp;feature=emb_imp_woyt\\\" rel=\\\"nofollow\\\"\\u003evideo summary\\u003c/a\\u003e by \\u003ca href=\\\"https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg\\\" rel=\\\"nofollow\\\"\\u003eTwo Minute Papers\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eA \\u003ca href=\\\"https://www.youtube.com/watch?v=-wDSDtIAyWQ\\\" rel=\\\"nofollow\\\"\\u003evideo summary\\u003c/a\\u003e by \\u003ca href=\\\"https://www.youtube.com/c/GradientDude/about\\\" rel=\\\"nofollow\\\"\\u003eGradient Dude\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eA \\u003ca href=\\\"https://wandb.ai/ayush-thakur/taming-transformer/reports/-Overview-Taming-Transformers-for-High-Resolution-Image-Synthesis---Vmlldzo0NjEyMTY\\\" rel=\\\"nofollow\\\"\\u003eweights and biases report summarizing the paper\\u003c/a\\u003e\\nby \\u003ca href=\\\"https://github.com/ayulockin\\\"\\u003eayulockin\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eA \\u003ca href=\\\"https://www.youtube.com/watch?v=JfUTd8fjtX8\\u0026amp;feature=emb_imp_woyt\\\" rel=\\\"nofollow\\\"\\u003evideo summary\\u003c/a\\u003e by \\u003ca href=\\\"https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg\\\" rel=\\\"nofollow\\\"\\u003eWhat's AI\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eTake a look at \\u003ca href=\\\"https://github.com/ak9250/taming-transformers/blob/master/tamingtransformerscolab.ipynb\\\"\\u003eak9250's notebook\\u003c/a\\u003e if you want to run the streamlit demos on Colab.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eText-to-Image Optimization via CLIP\\u003c/h3\\u003e\\u003ca id=\\\"user-content-text-to-image-optimization-via-clip\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Text-to-Image Optimization via CLIP\\\" href=\\\"#text-to-image-optimization-via-clip\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eVQGAN has been successfully used as an image generator guided by the \\u003ca href=\\\"https://github.com/openai/CLIP\\\"\\u003eCLIP\\u003c/a\\u003e model, both for pure image generation\\nfrom scratch and image-to-image translation. We recommend the following notebooks/videos/resources:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://twitter.com/advadnoun/status/1389316507134357506\\\" rel=\\\"nofollow\\\"\\u003eAdvadnouns\\u003c/a\\u003e Patreon and corresponding LatentVision notebooks: \\u003ca href=\\\"https://www.patreon.com/patronizeme\\\" rel=\\\"nofollow\\\"\\u003ehttps://www.patreon.com/patronizeme\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eThe \\u003ca href=\\\"https://colab.research.google.com/drive/1L8oL-vLJXVcRzCFbPwOoMkPKJ8-aYdPN\\\" rel=\\\"nofollow\\\"\\u003enotebook\\u003c/a\\u003e of \\u003ca href=\\\"https://twitter.com/RiversHaveWings\\\" rel=\\\"nofollow\\\"\\u003eRivers Have Wings\\u003c/a\\u003e.\\u003c/li\\u003e\\n\\u003cli\\u003eA \\u003ca href=\\\"https://www.youtube.com/watch?v=90QDe6DQXF4\\u0026amp;t=12s\\\" rel=\\\"nofollow\\\"\\u003evideo\\u003c/a\\u003e explanation by \\u003ca href=\\\"https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg\\\" rel=\\\"nofollow\\\"\\u003eDot CSV\\u003c/a\\u003e (in Spanish, but English subtitles are available)\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"/CompVis/taming-transformers/blob/master/assets/birddrawnbyachild.png\\\"\\u003e\\u003cimg src=\\\"/CompVis/taming-transformers/raw/master/assets/birddrawnbyachild.png\\\" alt=\\\"txt2img\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eText prompt: \\u003cem\\u003e'A bird drawn by a child'\\u003c/em\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eShout-outs\\u003c/h2\\u003e\\u003ca id=\\\"user-content-shout-outs\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Shout-outs\\\" href=\\\"#shout-outs\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThanks to everyone who makes their code and models available. In particular,\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eThe architecture of our VQGAN is inspired by \\u003ca href=\\\"https://github.com/hojonathanho/diffusion\\\"\\u003eDenoising Diffusion Probabilistic Models\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eThe very hackable transformer implementation \\u003ca href=\\\"https://github.com/karpathy/minGPT\\\"\\u003eminGPT\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eThe good ol' \\u003ca href=\\\"https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\\\"\\u003ePatchGAN\\u003c/a\\u003e and \\u003ca href=\\\"https://github.com/richzhang/PerceptualSimilarity\\\"\\u003eLearned Perceptual Similarity (LPIPS)\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eBibTeX\\u003c/h2\\u003e\\u003ca id=\\\"user-content-bibtex\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: BibTeX\\\" href=\\\"#bibtex\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"@misc{esser2020taming,\\n      title={Taming Transformers for High-Resolution Image Synthesis}, \\n      author={Patrick Esser and Robin Rombach and Bj\u00f6rn Ommer},\\n      year={2020},\\n      eprint={2012.09841},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CV}\\n}\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003e@misc{esser2020taming,\\n      title={Taming Transformers for High-Resolution Image Synthesis}, \\n      author={Patrick Esser and Robin Rombach and Bj\u00f6rn Ommer},\\n      year={2020},\\n      eprint={2012.09841},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CV}\\n}\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003c/article\\u003e\",\"loaded\":true,\"timedOut\":false,\"errorMessage\":null,\"headerInfo\":{\"toc\":[{\"level\":1,\"text\":\"Taming Transformers for High-Resolution Image Synthesis\",\"anchor\":\"taming-transformers-for-high-resolution-image-synthesis\",\"htmlText\":\"Taming Transformers for High-Resolution Image Synthesis\"},{\"level\":5,\"text\":\"CVPR 2021 (Oral)\",\"anchor\":\"cvpr-2021-oral\",\"htmlText\":\"CVPR 2021 (Oral)\"},{\"level\":3,\"text\":\"News\",\"anchor\":\"news\",\"htmlText\":\"News\"},{\"level\":4,\"text\":\"2022\",\"anchor\":\"2022\",\"htmlText\":\"2022\"},{\"level\":4,\"text\":\"2021\",\"anchor\":\"2021\",\"htmlText\":\"2021\"},{\"level\":2,\"text\":\"Requirements\",\"anchor\":\"requirements\",\"htmlText\":\"Requirements\"},{\"level\":2,\"text\":\"Overview of pretrained models\",\"anchor\":\"overview-of-pretrained-models\",\"htmlText\":\"Overview of pretrained models\"},{\"level\":2,\"text\":\"Running pretrained models\",\"anchor\":\"running-pretrained-models\",\"htmlText\":\"Running pretrained models\"},{\"level\":3,\"text\":\"S-FLCKR\",\"anchor\":\"s-flckr\",\"htmlText\":\"S-FLCKR\"},{\"level\":3,\"text\":\"ImageNet\",\"anchor\":\"imagenet\",\"htmlText\":\"ImageNet\"},{\"level\":3,\"text\":\"FFHQ/CelebA-HQ\",\"anchor\":\"ffhqceleba-hq\",\"htmlText\":\"FFHQ/CelebA-HQ\"},{\"level\":3,\"text\":\"FacesHQ\",\"anchor\":\"faceshq\",\"htmlText\":\"FacesHQ\"},{\"level\":3,\"text\":\"D-RIN\",\"anchor\":\"d-rin\",\"htmlText\":\"D-RIN\"},{\"level\":3,\"text\":\"COCO\",\"anchor\":\"coco\",\"htmlText\":\"COCO\"},{\"level\":3,\"text\":\"ADE20k\",\"anchor\":\"ade20k\",\"htmlText\":\"ADE20k\"},{\"level\":2,\"text\":\"Scene Image Synthesis\",\"anchor\":\"scene-image-synthesis\",\"htmlText\":\"Scene Image Synthesis\"},{\"level\":3,\"text\":\"Training\",\"anchor\":\"training\",\"htmlText\":\"Training\"},{\"level\":3,\"text\":\"Sampling\",\"anchor\":\"sampling\",\"htmlText\":\"Sampling\"},{\"level\":2,\"text\":\"Training on custom data\",\"anchor\":\"training-on-custom-data\",\"htmlText\":\"Training on custom data\"},{\"level\":2,\"text\":\"Data Preparation\",\"anchor\":\"data-preparation\",\"htmlText\":\"Data Preparation\"},{\"level\":3,\"text\":\"ImageNet\",\"anchor\":\"imagenet-1\",\"htmlText\":\"ImageNet\"},{\"level\":3,\"text\":\"CelebA-HQ\",\"anchor\":\"celeba-hq\",\"htmlText\":\"CelebA-HQ\"},{\"level\":3,\"text\":\"FFHQ\",\"anchor\":\"ffhq\",\"htmlText\":\"FFHQ\"},{\"level\":3,\"text\":\"S-FLCKR\",\"anchor\":\"s-flckr-1\",\"htmlText\":\"S-FLCKR\"},{\"level\":3,\"text\":\"COCO\",\"anchor\":\"coco-1\",\"htmlText\":\"COCO\"},{\"level\":3,\"text\":\"ADE20k\",\"anchor\":\"ade20k-1\",\"htmlText\":\"ADE20k\"},{\"level\":2,\"text\":\"Training models\",\"anchor\":\"training-models\",\"htmlText\":\"Training models\"},{\"level\":3,\"text\":\"FacesHQ\",\"anchor\":\"faceshq-1\",\"htmlText\":\"FacesHQ\"},{\"level\":3,\"text\":\"D-RIN\",\"anchor\":\"d-rin-1\",\"htmlText\":\"D-RIN\"},{\"level\":2,\"text\":\"More Resources\",\"anchor\":\"more-resources\",\"htmlText\":\"More Resources\"},{\"level\":3,\"text\":\"Comparing Different First Stage Models\",\"anchor\":\"comparing-different-first-stage-models\",\"htmlText\":\"Comparing Different First Stage Models\"},{\"level\":3,\"text\":\"Other\",\"anchor\":\"other\",\"htmlText\":\"Other\"},{\"level\":3,\"text\":\"Text-to-Image Optimization via CLIP\",\"anchor\":\"text-to-image-optimization-via-clip\",\"htmlText\":\"Text-to-Image Optimization via CLIP\"},{\"level\":2,\"text\":\"Shout-outs\",\"anchor\":\"shout-outs\",\"htmlText\":\"Shout-outs\"},{\"level\":2,\"text\":\"BibTeX\",\"anchor\":\"bibtex\",\"htmlText\":\"BibTeX\"}],\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fcompvis%2Ftaming-transformers\"}},{\"displayName\":\"License.txt\",\"repoName\":\"taming-transformers\",\"refName\":\"master\",\"path\":\"License.txt\",\"preferredFileType\":\"license\",\"tabName\":\"MIT\",\"richText\":null,\"loaded\":false,\"timedOut\":false,\"errorMessage\":null,\"headerInfo\":{\"toc\":null,\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fcompvis%2Ftaming-transformers\"}}],\"overviewFilesProcessingTime\":17.165048}},\"appPayload\":{\"helpUrl\":\"https://docs.github.com\",\"findFileWorkerPath\":\"/assets-cdn/worker/find-file-worker-32bb159cc57c.js\",\"findInFileWorkerPath\":\"/assets-cdn/worker/find-in-file-worker-c6704d501c10.js\",\"githubDevUrl\":null,\"enabled_features\":{\"code_nav_ui_events\":false,\"copilot_conversational_ux\":false,\"copilot_conversational_ux_embedding_update\":false,\"copilot_popover_file_editor_header\":false,\"copilot_smell_icebreaker_ux\":true,\"copilot_workspace\":false,\"codeview_firefox_inert\":true}}}}</script>  <div data-target=\"react-partial.reactRoot\"><style data-styled=\"true\" data-styled-version=\"5.3.6\">.cgQnMS{font-weight:600;font-size:32px;margin:0;}/*!sc*/data-styled.g1[id=\"Heading__StyledHeading-sc-1c1dgg0-0\"]{content:\"cgQnMS,\"}/*!sc*/.izjvBm{margin-top:16px;margin-bottom:16px;}/*!sc*/.rPQgy{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/.eUMEDg{margin-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;row-gap:16px;}/*!sc*/.eLcVee{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;padding-bottom:16px;padding-top:8px;}/*!sc*/.hsfLlq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;gap:8px;}/*!sc*/@media screen and (max-width:320px){.hsfLlq{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}}/*!sc*/.gpKoUz{position:relative;}/*!sc*/@media screen and (max-width:380px){.gpKoUz .ref-selector-button-text-container{max-width:80px;}}/*!sc*/@media screen and (max-width:320px){.gpKoUz{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}.gpKoUz .overview-ref-selector{width:100%;}.gpKoUz .overview-ref-selector > span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}.gpKoUz .overview-ref-selector > span > span[data-component=\"text\"]{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}}/*!sc*/.kkrdEu{-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/.bKgizp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;}/*!sc*/.iPGYsi{margin-right:4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.dKmYfk{font-size:14px;min-width:0;max-width:125px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}/*!sc*/.trpoQ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;pointer-events:none;}/*!sc*/.laYubZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (max-width:1079px){.laYubZ{display:none;}}/*!sc*/.swnaL{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:1080px){.swnaL{display:none;}}/*!sc*/@media screen and (max-width:543px){.swnaL{display:none;}}/*!sc*/.bWpuBf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:8px;gap:8px;}/*!sc*/.grHjNb{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;}/*!sc*/@media screen and (max-width:543px){.grHjNb{display:none;}}/*!sc*/.dXTsqj{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (max-width:1011px){.dXTsqj{display:none;}}/*!sc*/.dCOrmu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:1012px){.dCOrmu{display:none;}}/*!sc*/@media screen and (max-width:544px){.bVvbgP{display:none;}}/*!sc*/.bNDvfp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:544px){.bNDvfp{display:none;}}/*!sc*/.yfPnm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;gap:16px;}/*!sc*/.cAQuiW{width:100%;border-collapse:separate;border-spacing:0;border:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));border-radius:6px;table-layout:fixed;overflow:unset;}/*!sc*/.iiUlLN{height:0px;line-height:0px;}/*!sc*/.iiUlLN tr{height:0px;font-size:0px;}/*!sc*/.jmggSN{padding:16px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));font-size:12px;text-align:left;height:40px;}/*!sc*/.jmggSN th{padding-left:16px;background-color:var(--bgColor-muted,var(--color-canvas-subtle,#f6f8fa));}/*!sc*/.kvYunM{width:100%;border-top-left-radius:6px;}/*!sc*/@media screen and (min-width:544px){.kvYunM{display:none;}}/*!sc*/.hrLuxA{width:40%;border-top-left-radius:6px;}/*!sc*/@media screen and (max-width:543px){.hrLuxA{display:none;}}/*!sc*/@media screen and (max-width:543px){.ePjhhA{display:none;}}/*!sc*/.cuEKae{text-align:right;padding-right:16px;width:136px;border-top-right-radius:6px;}/*!sc*/.jEbBOT{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));font-size:12px;height:40px;}/*!sc*/.bTxCvM{background-color:var(--bgColor-muted,var(--color-canvas-subtle,#f6f8fa));padding:4px;border-top-left-radius:6px;border-top-right-radius:6px;}/*!sc*/.eYedVD{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:8px;min-width:273px;padding-right:8px;padding-left:16px;padding-top:8px;padding-bottom:8px;}/*!sc*/.jGfYmh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;}/*!sc*/.lhFvfi{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/.bqgLjk{display:inherit;}/*!sc*/@media screen and (min-width:544px){.bqgLjk{display:none;}}/*!sc*/@media screen and (min-width:768px){.bqgLjk{display:none;}}/*!sc*/.epsqEd{text-align:center;vertical-align:center;height:40px;border-top:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));}/*!sc*/.ldpruc{border-top:1px solid var(--borderColor-default,var(--color-border-default));cursor:pointer;}/*!sc*/.ehcSsh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;gap:16px;}/*!sc*/.iGmlUb{border:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));border-radius:6px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}/*!sc*/@media screen and (max-width:543px){.iGmlUb{margin-left:-16px;margin-right:-16px;max-width:calc(100% + 32px);}}/*!sc*/@media screen and (min-width:544px){.iGmlUb{max-width:100%;}}/*!sc*/.iRQGXA{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-bottom:1px solid;border-bottom-color:var(--borderColor-default,var(--color-border-default,#d0d7de));-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-right:8px;position:-webkit-sticky;position:sticky;top:0;background-color:var(--bgColor-default,var(--color-canvas-default,#ffffff));z-index:1;border-top-left-radius:6px;border-top-right-radius:6px;}/*!sc*/.dvTdPK{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:8px;padding-right:8px;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;border-bottom:none;border-bottom-color:var(--borderColor-muted,var(--color-border-muted,hsla(210,18%,87%,1)));align:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-height:48px;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;max-width:100%;}/*!sc*/.gwuIGu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/.kOxwQs{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;margin-right:8px;}/*!sc*/.kOgeFj{font-weight:600;}/*!sc*/.bJMeLZ{padding:32px;overflow:auto;}/*!sc*/data-styled.g2[id=\"Box-sc-g0xbh4-0\"]{content:\"izjvBm,rPQgy,eUMEDg,eLcVee,hsfLlq,gpKoUz,kkrdEu,bKgizp,iPGYsi,dKmYfk,trpoQ,laYubZ,swnaL,bWpuBf,grHjNb,dXTsqj,dCOrmu,bVvbgP,bNDvfp,yfPnm,cAQuiW,iiUlLN,jmggSN,kvYunM,hrLuxA,ePjhhA,cuEKae,jEbBOT,bTxCvM,eYedVD,jGfYmh,lhFvfi,bqgLjk,epsqEd,ldpruc,ehcSsh,iGmlUb,iRQGXA,dvTdPK,gwuIGu,kOxwQs,kOgeFj,bJMeLZ,\"}/*!sc*/.bOMzPg{min-width:0;}/*!sc*/.eUGNHp{font-weight:600;}/*!sc*/.dALsKK{color:var(--fgColor-default,var(--color-fg-default,#1F2328));}/*!sc*/data-styled.g6[id=\"Text-sc-17v1xeu-0\"]{content:\"bOMzPg,eUGNHp,dALsKK,\"}/*!sc*/.dheQRw{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.dheQRw:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.dheQRw:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.vLMkZ{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;position:relative;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;color:var(--fgColor-default,var(--color-fg-default,#1F2328));text-align:center;-webkit-text-decoration:none;text-decoration:none;line-height:calc(20/14);border-radius:6px;font-size:14px;padding-left:8px;padding-right:8px;padding-top:calc((2rem - 1.25rem) / 2);padding-bottom:calc((2rem - 1.25rem) / 2);}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.vLMkZ:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.vLMkZ:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.vLMkZ span[data-component=\"icon\"]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/@media (hover:hover){.vLMkZ:hover{background-color:var(--bgColor-neutral-muted,var(--color-neutral-muted,rgba(175,184,193,0.2)));-webkit-transition:background .12s ease-out;transition:background .12s ease-out;-webkit-text-decoration:none;text-decoration:none;}}/*!sc*/.vLMkZ:focus{outline:2px solid transparent;}/*!sc*/.vLMkZ:focus{box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.vLMkZ:focus:not(:focus-visible){box-shadow:none;}/*!sc*/.vLMkZ:focus-visible{outline:2px solid transparent;box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.vLMkZ span[data-content]::before{content:attr(data-content);display:block;height:0;font-weight:600;visibility:hidden;white-space:nowrap;}/*!sc*/.vLMkZ::after{position:absolute;right:50%;bottom:calc(50% - 25px);width:100%;height:2px;content:\"\";background-color:var(--underlineNav-borderColor-active,var(--color-primer-border-active,#fd8c73));border-radius:0;-webkit-transform:translate(50%,-50%);-ms-transform:translate(50%,-50%);transform:translate(50%,-50%);}/*!sc*/@media (forced-colors:active){.vLMkZ::after{background-color:LinkText;}}/*!sc*/.bhqztV{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;position:relative;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;color:var(--fgColor-default,var(--color-fg-default,#1F2328));text-align:center;-webkit-text-decoration:none;text-decoration:none;line-height:calc(20/14);border-radius:6px;font-size:14px;padding-left:8px;padding-right:8px;padding-top:calc((2rem - 1.25rem) / 2);padding-bottom:calc((2rem - 1.25rem) / 2);}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.bhqztV:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.bhqztV:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.bhqztV span[data-component=\"icon\"]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/@media (hover:hover){.bhqztV:hover{background-color:var(--bgColor-neutral-muted,var(--color-neutral-muted,rgba(175,184,193,0.2)));-webkit-transition:background .12s ease-out;transition:background .12s ease-out;-webkit-text-decoration:none;text-decoration:none;}}/*!sc*/.bhqztV:focus{outline:2px solid transparent;}/*!sc*/.bhqztV:focus{box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.bhqztV:focus:not(:focus-visible){box-shadow:none;}/*!sc*/.bhqztV:focus-visible{outline:2px solid transparent;box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.bhqztV span[data-content]::before{content:attr(data-content);display:block;height:0;font-weight:600;visibility:hidden;white-space:nowrap;}/*!sc*/.bhqztV::after{position:absolute;right:50%;bottom:calc(50% - 25px);width:100%;height:2px;content:\"\";background-color:transparent;border-radius:0;-webkit-transform:translate(50%,-50%);-ms-transform:translate(50%,-50%);transform:translate(50%,-50%);}/*!sc*/@media (forced-colors:active){.bhqztV::after{background-color:transparent;}}/*!sc*/data-styled.g8[id=\"Link__StyledLink-sc-14289xe-0\"]{content:\"dheQRw,vLMkZ,bhqztV,\"}/*!sc*/.izDscS{border-radius:6px;border:1px solid;border-color:var(--button-default-borderColor-rest,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:var(--button-default-bgColor-rest,var(--color-btn-bg,#f6f8fa));box-shadow:var(--button-default-shadow-resting,var(--color-btn-shadow,0 1px 0 rgba(31,35,40,0.04))),var(--button-default-shadow-inset,var(--color-btn-inset-shadow,inset 0 1px 0 rgba(255,255,255,0.25)));}/*!sc*/.izDscS:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.izDscS:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.izDscS:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.izDscS[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.izDscS[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.izDscS:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.izDscS:active{-webkit-transition:none;transition:none;}/*!sc*/.izDscS[data-inactive]{cursor:auto;}/*!sc*/.izDscS:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));border-color:var(--button-default-borderColor-disabled,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.izDscS:focus{outline:solid 1px transparent;}}/*!sc*/.izDscS [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-default-bgColor-rest,var(--color-btn-counter-bg,rgba(31,35,40,0.08)));}/*!sc*/.izDscS[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.izDscS[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.izDscS[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.izDscS[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.izDscS[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.izDscS[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.izDscS[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.izDscS[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.izDscS[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.izDscS[data-block=\"block\"]{width:100%;}/*!sc*/.izDscS[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.izDscS[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.izDscS [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.izDscS [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.izDscS [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.izDscS [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.izDscS [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.izDscS [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.izDscS:hover:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-hover,var(--color-btn-hover-bg,#f3f4f6));border-color:var(--button-default-borderColor-hover,var(--button-default-borderColor-hover,var(--color-btn-hover-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS:active:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS[aria-expanded=true]{background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS [data-component=\"leadingVisual\"],.izDscS [data-component=\"trailingVisual\"],.izDscS [data-component=\"trailingAction\"]{color:var(--button-color,var(--fgColor-muted,var(--color-fg-muted,#656d76)));}/*!sc*/.izDscS{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/.izDscS svg{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.izDscS > span{width:inherit;}/*!sc*/.cuOWTR{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.cuOWTR:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.cuOWTR:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.cuOWTR:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.cuOWTR[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.cuOWTR[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.cuOWTR:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.cuOWTR:active{-webkit-transition:none;transition:none;}/*!sc*/.cuOWTR[data-inactive]{cursor:auto;}/*!sc*/.cuOWTR:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.cuOWTR:disabled [data-component=ButtonCounter],.cuOWTR:disabled [data-component=\"leadingVisual\"],.cuOWTR:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.cuOWTR:focus{outline:solid 1px transparent;}}/*!sc*/.cuOWTR [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.cuOWTR[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.cuOWTR[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.cuOWTR[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.cuOWTR[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.cuOWTR[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.cuOWTR[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.cuOWTR[data-block=\"block\"]{width:100%;}/*!sc*/.cuOWTR[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.cuOWTR[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.cuOWTR [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.cuOWTR [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.cuOWTR [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.cuOWTR [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.cuOWTR:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.cuOWTR:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.cuOWTR[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.cuOWTR[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.cuOWTR:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.cuOWTR:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.cuOWTR:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.cuOWTR{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));padding-left:4px;padding-right:4px;}/*!sc*/.cuOWTR span[data-component=\"leadingVisual\"]{margin-right:4px !important;}/*!sc*/.tDSzd{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.tDSzd:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.tDSzd:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.tDSzd:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.tDSzd[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.tDSzd[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.tDSzd:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.tDSzd:active{-webkit-transition:none;transition:none;}/*!sc*/.tDSzd[data-inactive]{cursor:auto;}/*!sc*/.tDSzd:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.tDSzd:disabled [data-component=ButtonCounter],.tDSzd:disabled [data-component=\"leadingVisual\"],.tDSzd:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.tDSzd:focus{outline:solid 1px transparent;}}/*!sc*/.tDSzd [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.tDSzd[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.tDSzd[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.tDSzd[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.tDSzd[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.tDSzd[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.tDSzd[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.tDSzd[data-block=\"block\"]{width:100%;}/*!sc*/.tDSzd[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.tDSzd[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.tDSzd [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.tDSzd [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.tDSzd [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.tDSzd [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.tDSzd:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.tDSzd:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.tDSzd[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.tDSzd[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd[data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.tDSzd:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.tDSzd:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.ftZGca{border-radius:6px;border:1px solid;border-color:var(--button-default-borderColor-rest,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:var(--button-default-bgColor-rest,var(--color-btn-bg,#f6f8fa));box-shadow:var(--button-default-shadow-resting,var(--color-btn-shadow,0 1px 0 rgba(31,35,40,0.04))),var(--button-default-shadow-inset,var(--color-btn-inset-shadow,inset 0 1px 0 rgba(255,255,255,0.25)));}/*!sc*/.ftZGca:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.ftZGca:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.ftZGca:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.ftZGca[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.ftZGca[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.ftZGca:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.ftZGca:active{-webkit-transition:none;transition:none;}/*!sc*/.ftZGca[data-inactive]{cursor:auto;}/*!sc*/.ftZGca:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));border-color:var(--button-default-borderColor-disabled,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.ftZGca:focus{outline:solid 1px transparent;}}/*!sc*/.ftZGca [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-default-bgColor-rest,var(--color-btn-counter-bg,rgba(31,35,40,0.08)));}/*!sc*/.ftZGca[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.ftZGca[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.ftZGca[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.ftZGca[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.ftZGca[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.ftZGca[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.ftZGca[data-block=\"block\"]{width:100%;}/*!sc*/.ftZGca[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.ftZGca[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.ftZGca [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.ftZGca [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.ftZGca [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.ftZGca [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.ftZGca [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.ftZGca [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.ftZGca:hover:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-hover,var(--color-btn-hover-bg,#f3f4f6));border-color:var(--button-default-borderColor-hover,var(--button-default-borderColor-hover,var(--color-btn-hover-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca:active:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca[aria-expanded=true]{background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca [data-component=\"leadingVisual\"],.ftZGca [data-component=\"trailingVisual\"],.ftZGca [data-component=\"trailingAction\"]{color:var(--button-color,var(--fgColor-muted,var(--color-fg-muted,#656d76)));}/*!sc*/.gYvpXq{border-radius:6px;border:1px solid;border-color:var(--button-primary-borderColor-rest,var(--color-btn-primary-border,rgba(31,35,40,0.15)));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-primary-fgColor-rest,var(--color-btn-primary-text,#ffffff));background-color:var(--button-primary-bgColor-rest,var(--color-btn-primary-bg,#1f883d));box-shadow:var(--shadow-resting-small,var(--color-btn-primary-shadow,0 1px 0 rgba(31,35,40,0.1)));}/*!sc*/.gYvpXq:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.gYvpXq:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.gYvpXq:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.gYvpXq[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.gYvpXq[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.gYvpXq:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.gYvpXq:active{-webkit-transition:none;transition:none;}/*!sc*/.gYvpXq[data-inactive]{cursor:auto;}/*!sc*/.gYvpXq:disabled{cursor:not-allowed;box-shadow:none;color:var(--button-primary-fgColor-disabled,var(--color-btn-primary-disabled-text,rgba(255,255,255,0.8)));background-color:var(--button-primary-bgColor-disabled,var(--color-btn-primary-disabled-bg,#94d3a2));border-color:var(--button-primary-borderColor-disabled,var(--color-btn-primary-disabled-border,rgba(31,35,40,0.15)));}/*!sc*/.gYvpXq:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.gYvpXq:focus{outline:solid 1px transparent;}}/*!sc*/.gYvpXq [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-primary-bgColor-rest,var(--color-btn-primary-counter-bg,rgba(0,45,17,0.2)));color:var(--button-primary-fgColor-rest,var(--color-btn-primary-text,#ffffff));}/*!sc*/.gYvpXq[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.gYvpXq[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.gYvpXq[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.gYvpXq[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.gYvpXq[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.gYvpXq[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.gYvpXq[data-block=\"block\"]{width:100%;}/*!sc*/.gYvpXq[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.gYvpXq[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.gYvpXq [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.gYvpXq [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.gYvpXq [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.gYvpXq [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.gYvpXq [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.gYvpXq [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.gYvpXq:hover:not([disabled]):not([data-inactive]){color:btn.primary.hoverText;background-color:var(--button-primary-bgColor-hover,var(--color-btn-primary-hover-bg,#1a7f37));}/*!sc*/.gYvpXq:focus:not([disabled]){box-shadow:inset 0 0 0 3px;}/*!sc*/.gYvpXq:focus-visible:not([disabled]){box-shadow:inset 0 0 0 3px;}/*!sc*/.gYvpXq:active:not([disabled]):not([data-inactive]){background-color:var(--button-primary-bgColor-active,var(--color-btn-primary-selected-bg,hsla(137,66%,28%,1)));box-shadow:var(--button-primary-shadow-selected,var(--color-btn-primary-selected-shadow,inset 0 1px 0 rgba(0,45,17,0.2)));}/*!sc*/.gYvpXq[aria-expanded=true]{background-color:var(--button-primary-bgColor-active,var(--color-btn-primary-selected-bg,hsla(137,66%,28%,1)));box-shadow:var(--button-primary-shadow-selected,var(--color-btn-primary-selected-shadow,inset 0 1px 0 rgba(0,45,17,0.2)));}/*!sc*/.gYvpXq svg{color:fg.primary;}/*!sc*/.fAkXQN{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--fgColor-default,var(--color-fg-default,#1F2328));background-color:transparent;box-shadow:none;}/*!sc*/.fAkXQN:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.fAkXQN:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.fAkXQN:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.fAkXQN[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.fAkXQN[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.fAkXQN:active{-webkit-transition:none;transition:none;}/*!sc*/.fAkXQN[data-inactive]{cursor:auto;}/*!sc*/.fAkXQN:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.fAkXQN:disabled [data-component=ButtonCounter],.fAkXQN:disabled [data-component=\"leadingVisual\"],.fAkXQN:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.fAkXQN:focus{outline:solid 1px transparent;}}/*!sc*/.fAkXQN [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.fAkXQN[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.fAkXQN[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.fAkXQN[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.fAkXQN[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.fAkXQN[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.fAkXQN[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.fAkXQN[data-block=\"block\"]{width:100%;}/*!sc*/.fAkXQN[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.fAkXQN[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.fAkXQN [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.fAkXQN [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.fAkXQN [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.fAkXQN [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.fAkXQN:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.fAkXQN[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.fAkXQN:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.fAkXQN:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.fAkXQN:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.fAkXQN:focus:not([disabled]){-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.jPraEl{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.jPraEl:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.jPraEl:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.jPraEl:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.jPraEl[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.jPraEl[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.jPraEl:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.jPraEl:active{-webkit-transition:none;transition:none;}/*!sc*/.jPraEl[data-inactive]{cursor:auto;}/*!sc*/.jPraEl:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.jPraEl:disabled [data-component=ButtonCounter],.jPraEl:disabled [data-component=\"leadingVisual\"],.jPraEl:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.jPraEl:focus{outline:solid 1px transparent;}}/*!sc*/.jPraEl [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.jPraEl[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.jPraEl[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.jPraEl[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.jPraEl[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.jPraEl[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.jPraEl[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.jPraEl[data-block=\"block\"]{width:100%;}/*!sc*/.jPraEl[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.jPraEl[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.jPraEl [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.jPraEl [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.jPraEl [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.jPraEl [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.jPraEl:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.jPraEl:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.jPraEl[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.jPraEl[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.jPraEl:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.jPraEl:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.jPraEl:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.jPraEl{color:var(--fgColor-muted,var(--color-fg-subtle,#6e7781));padding-left:8px;padding-right:8px;}/*!sc*/data-styled.g9[id=\"types__StyledButton-sc-ws60qy-0\"]{content:\"izDscS,cuOWTR,tDSzd,ftZGca,gYvpXq,fAkXQN,jPraEl,\"}/*!sc*/.rTZSs{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;-webkit-clip:rect(0,0,0,0);clip:rect(0,0,0,0);white-space:nowrap;border-width:0;}/*!sc*/data-styled.g10[id=\"_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0\"]{content:\"rTZSs,\"}/*!sc*/.fUpWeN{display:inline-block;overflow:hidden;text-overflow:ellipsis;vertical-align:top;white-space:nowrap;max-width:125px;max-width:100%;}/*!sc*/data-styled.g15[id=\"Truncate__StyledTruncate-sc-23o1d2-0\"]{content:\"fUpWeN,\"}/*!sc*/.dMjscx{position:relative;display:inline-block;}/*!sc*/.dMjscx::before{position:absolute;z-index:1000001;display:none;width:0px;height:0px;color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));pointer-events:none;content:'';border:6px solid transparent;opacity:0;}/*!sc*/.dMjscx::after{position:absolute;z-index:1000000;display:none;padding:0.5em 0.75em;font:normal normal 11px/1.5 -apple-system,BlinkMacSystemFont,\"Segoe UI\",\"Noto Sans\",Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\";-webkit-font-smoothing:subpixel-antialiased;color:var(--fgColor-onEmphasis,var(--color-fg-on-emphasis,#ffffff));text-align:center;-webkit-text-decoration:none;text-decoration:none;text-shadow:none;text-transform:none;-webkit-letter-spacing:normal;-moz-letter-spacing:normal;-ms-letter-spacing:normal;letter-spacing:normal;word-wrap:break-word;white-space:pre;pointer-events:none;content:attr(aria-label);background:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));border-radius:6px;opacity:0;}/*!sc*/@-webkit-keyframes tooltip-appear{from{opacity:0;}to{opacity:1;}}/*!sc*/@keyframes tooltip-appear{from{opacity:0;}to{opacity:1;}}/*!sc*/.dMjscx:hover::before,.dMjscx:active::before,.dMjscx:focus::before,.dMjscx:focus-within::before,.dMjscx:hover::after,.dMjscx:active::after,.dMjscx:focus::after,.dMjscx:focus-within::after{display:inline-block;-webkit-text-decoration:none;text-decoration:none;-webkit-animation-name:tooltip-appear;animation-name:tooltip-appear;-webkit-animation-duration:0.1s;animation-duration:0.1s;-webkit-animation-fill-mode:forwards;animation-fill-mode:forwards;-webkit-animation-timing-function:ease-in;animation-timing-function:ease-in;-webkit-animation-delay:0.4s;animation-delay:0.4s;}/*!sc*/.dMjscx.tooltipped-no-delay:hover::before,.dMjscx.tooltipped-no-delay:active::before,.dMjscx.tooltipped-no-delay:focus::before,.dMjscx.tooltipped-no-delay:focus-within::before,.dMjscx.tooltipped-no-delay:hover::after,.dMjscx.tooltipped-no-delay:active::after,.dMjscx.tooltipped-no-delay:focus::after,.dMjscx.tooltipped-no-delay:focus-within::after{-webkit-animation-delay:0s;animation-delay:0s;}/*!sc*/.dMjscx.tooltipped-multiline:hover::after,.dMjscx.tooltipped-multiline:active::after,.dMjscx.tooltipped-multiline:focus::after,.dMjscx.tooltipped-multiline:focus-within::after{display:table-cell;}/*!sc*/.dMjscx.tooltipped-s::after,.dMjscx.tooltipped-se::after,.dMjscx.tooltipped-sw::after{top:100%;right:50%;margin-top:6px;}/*!sc*/.dMjscx.tooltipped-s::before,.dMjscx.tooltipped-se::before,.dMjscx.tooltipped-sw::before{top:auto;right:50%;bottom:-7px;margin-right:-6px;border-bottom-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-se::after{right:auto;left:50%;margin-left:-16px;}/*!sc*/.dMjscx.tooltipped-sw::after{margin-right:-16px;}/*!sc*/.dMjscx.tooltipped-n::after,.dMjscx.tooltipped-ne::after,.dMjscx.tooltipped-nw::after{right:50%;bottom:100%;margin-bottom:6px;}/*!sc*/.dMjscx.tooltipped-n::before,.dMjscx.tooltipped-ne::before,.dMjscx.tooltipped-nw::before{top:-7px;right:50%;bottom:auto;margin-right:-6px;border-top-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-ne::after{right:auto;left:50%;margin-left:-16px;}/*!sc*/.dMjscx.tooltipped-nw::after{margin-right:-16px;}/*!sc*/.dMjscx.tooltipped-s::after,.dMjscx.tooltipped-n::after{-webkit-transform:translateX(50%);-ms-transform:translateX(50%);transform:translateX(50%);}/*!sc*/.dMjscx.tooltipped-w::after{right:100%;bottom:50%;margin-right:6px;-webkit-transform:translateY(50%);-ms-transform:translateY(50%);transform:translateY(50%);}/*!sc*/.dMjscx.tooltipped-w::before{top:50%;bottom:50%;left:-7px;margin-top:-6px;border-left-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-e::after{bottom:50%;left:100%;margin-left:6px;-webkit-transform:translateY(50%);-ms-transform:translateY(50%);transform:translateY(50%);}/*!sc*/.dMjscx.tooltipped-e::before{top:50%;right:-7px;bottom:50%;margin-top:-6px;border-right-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-multiline::after{width:-webkit-max-content;width:-moz-max-content;width:max-content;max-width:250px;word-wrap:break-word;white-space:pre-line;border-collapse:separate;}/*!sc*/.dMjscx.tooltipped-multiline.tooltipped-s::after,.dMjscx.tooltipped-multiline.tooltipped-n::after{right:auto;left:50%;-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%);transform:translateX(-50%);}/*!sc*/.dMjscx.tooltipped-multiline.tooltipped-w::after,.dMjscx.tooltipped-multiline.tooltipped-e::after{right:100%;}/*!sc*/.dMjscx.tooltipped-align-right-2::after{right:0;margin-right:0;}/*!sc*/.dMjscx.tooltipped-align-right-2::before{right:15px;}/*!sc*/.dMjscx.tooltipped-align-left-2::after{left:0;margin-left:0;}/*!sc*/.dMjscx.tooltipped-align-left-2::before{left:10px;}/*!sc*/data-styled.g18[id=\"Tooltip__TooltipBase-sc-17tf59c-0\"]{content:\"dMjscx,\"}/*!sc*/.bPgibo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;list-style:none;white-space:nowrap;padding-top:0;padding-bottom:0;padding-left:0;padding-right:0;margin:0;margin-bottom:-1px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:8px;position:relative;}/*!sc*/data-styled.g103[id=\"UnderlineNav__NavigationList-sc-1jfr31k-0\"]{content:\"bPgibo,\"}/*!sc*/</style> <!-- --> <!-- --> <div class=\"Box-sc-g0xbh4-0 izjvBm\"><div class=\"Box-sc-g0xbh4-0 rPQgy\"><div class=\"Box-sc-g0xbh4-0 eUMEDg\"></div></div><div class=\"Box-sc-g0xbh4-0 eLcVee\"><div class=\"Box-sc-g0xbh4-0 hsfLlq\"><div class=\"Box-sc-g0xbh4-0 gpKoUz\"><button type=\"button\" id=\"branch-picker-repos-header-ref-selector\" aria-haspopup=\"true\" tabindex=\"0\" aria-label=\"master branch\" data-testid=\"anchor-button\" class=\"types__StyledButton-sc-ws60qy-0 izDscS overview-ref-selector\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"text\"><div class=\"Box-sc-g0xbh4-0 bKgizp\"><div class=\"Box-sc-g0xbh4-0 iPGYsi\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></div><div class=\"Box-sc-g0xbh4-0 dKmYfk ref-selector-button-text-container\"><span class=\"Text-sc-17v1xeu-0 bOMzPg\">\u00a0<!-- -->master</span></div></div></span><span data-component=\"trailingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-triangle-down\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></span></span></button><button hidden=\"\" data-hotkey-scope=\"read-only-cursor-text-area\"></button></div><div class=\"Box-sc-g0xbh4-0 laYubZ\"><a style=\"--button-color:fg.muted\" type=\"button\" href=\"/CompVis/taming-transformers/branches\" class=\"types__StyledButton-sc-ws60qy-0 cuOWTR\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></span><span data-component=\"text\">Branches</span></span></a><a style=\"--button-color:fg.muted\" type=\"button\" href=\"/CompVis/taming-transformers/tags\" class=\"types__StyledButton-sc-ws60qy-0 cuOWTR\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-tag\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg></span><span data-component=\"text\">Tags</span></span></a></div><div class=\"Box-sc-g0xbh4-0 swnaL\"><a style=\"--button-color:fg.muted\" type=\"button\" aria-label=\"Go to Branches page\" href=\"/CompVis/taming-transformers/branches\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 tDSzd\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></a><a style=\"--button-color:fg.muted\" type=\"button\" aria-label=\"Go to Tags page\" href=\"/CompVis/taming-transformers/tags\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 tDSzd\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-tag\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg></a></div></div><div class=\"Box-sc-g0xbh4-0 bWpuBf\"><div class=\"Box-sc-g0xbh4-0 grHjNb\"><div class=\"Box-sc-g0xbh4-0 dXTsqj\"><!--$!--><template></template><!--/$--></div><div class=\"Box-sc-g0xbh4-0 dCOrmu\"><button type=\"button\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 ftZGca\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"text\">Go to file</span></span></button></div><div class=\"react-directory-add-file-icon\"></div><div class=\"react-directory-remove-file-icon\"></div></div><button type=\"button\" id=\":R2il5:\" aria-haspopup=\"true\" tabindex=\"0\" class=\"types__StyledButton-sc-ws60qy-0 gYvpXq\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><div class=\"Box-sc-g0xbh4-0 bVvbgP\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-code\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg></div></span><span data-component=\"text\">Code</span></span><span data-component=\"trailingAction\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-triangle-down\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></span></button><div class=\"Box-sc-g0xbh4-0 bNDvfp\"><button data-component=\"IconButton\" type=\"button\" aria-label=\"Open more actions menu\" id=\":R3il5:\" aria-haspopup=\"true\" tabindex=\"0\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 ftZGca\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-kebab-horizontal\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path></svg></button></div></div></div><div class=\"Box-sc-g0xbh4-0 yfPnm\"><div data-hpc=\"true\" class=\"Box-sc-g0xbh4-0\"><button hidden=\"\" data-testid=\"focus-next-element-button\" data-hotkey=\"j\" data-hotkey-scope=\"read-only-cursor-text-area\"></button><button hidden=\"\" data-hotkey=\"j\"></button><button hidden=\"\" data-testid=\"focus-previous-element-button\" data-hotkey=\"k\" data-hotkey-scope=\"read-only-cursor-text-area\"></button><button hidden=\"\" data-hotkey=\"k\"></button><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\" id=\"folders-and-files\">Folders and files</h2><table aria-labelledby=\"folders-and-files\" class=\"Box-sc-g0xbh4-0 cAQuiW\"><thead class=\"Box-sc-g0xbh4-0 iiUlLN\"><tr class=\"Box-sc-g0xbh4-0 jmggSN\"><th colSpan=\"2\" class=\"Box-sc-g0xbh4-0 kvYunM\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Name</span></th><th colSpan=\"1\" class=\"Box-sc-g0xbh4-0 hrLuxA\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Name</span></th><th class=\"Box-sc-g0xbh4-0 ePjhhA\"><div title=\"Last commit message\" class=\"Truncate__StyledTruncate-sc-23o1d2-0 fUpWeN\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Last commit message</span></div></th><th colSpan=\"1\" class=\"Box-sc-g0xbh4-0 cuEKae\"><div title=\"Last commit date\" class=\"Truncate__StyledTruncate-sc-23o1d2-0 fUpWeN\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Last commit date</span></div></th></tr></thead><tbody><tr class=\"Box-sc-g0xbh4-0 jEbBOT\"><td colSpan=\"3\" class=\"Box-sc-g0xbh4-0 bTxCvM\"><div class=\"Box-sc-g0xbh4-0 eYedVD\"><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\">Latest commit</h2><div style=\"width:120px\" class=\"Skeleton Skeleton--text\" data-testid=\"loading\">\u00a0</div><div class=\"Box-sc-g0xbh4-0 jGfYmh\"><div data-testid=\"latest-commit-details\" class=\"Box-sc-g0xbh4-0 lhFvfi\"></div><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\">History</h2><a class=\"types__StyledButton-sc-ws60qy-0 fAkXQN react-last-commit-history-group\" href=\"/CompVis/taming-transformers/commits/master/\" data-size=\"small\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-history\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></span><span data-component=\"text\"><span class=\"Text-sc-17v1xeu-0 dALsKK\">96 Commits</span></span></span></a><div class=\"Box-sc-g0xbh4-0 bqgLjk\"></div><span role=\"tooltip\" aria-label=\"Commit history\" class=\"Tooltip__TooltipBase-sc-17tf59c-0 dMjscx tooltipped-n\"><a class=\"types__StyledButton-sc-ws60qy-0 fAkXQN react-last-commit-history-icon\" href=\"/CompVis/taming-transformers/commits/master/\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-history\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></span></span></a></span></div></div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-0\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"assets\" aria-label=\"assets, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/assets\">assets</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"assets\" aria-label=\"assets, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/assets\">assets</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-1\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"configs\" aria-label=\"configs, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/configs\">configs</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"configs\" aria-label=\"configs, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/configs\">configs</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-2\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"data\" aria-label=\"data, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/data\">data</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"data\" aria-label=\"data, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/data\">data</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-3\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"scripts\" aria-label=\"scripts, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/scripts\">scripts</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"scripts\" aria-label=\"scripts, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/scripts\">scripts</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-4\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"taming\" aria-label=\"taming, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/taming\">taming</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"taming\" aria-label=\"taming, (Directory)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/tree/master/taming\">taming</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-5\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"License.txt\" aria-label=\"License.txt, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/License.txt\">License.txt</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"License.txt\" aria-label=\"License.txt, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/License.txt\">License.txt</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-6\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"README.md\" aria-label=\"README.md, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/README.md\">README.md</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"README.md\" aria-label=\"README.md, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/README.md\">README.md</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-7\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"environment.yaml\" aria-label=\"environment.yaml, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/environment.yaml\">environment.yaml</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"environment.yaml\" aria-label=\"environment.yaml, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/environment.yaml\">environment.yaml</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-8\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"main.py\" aria-label=\"main.py, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/main.py\">main.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"main.py\" aria-label=\"main.py, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/main.py\">main.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-9\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"setup.py\" aria-label=\"setup.py, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/setup.py\">setup.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"setup.py\" aria-label=\"setup.py, (File)\" class=\"Link--primary\" href=\"/CompVis/taming-transformers/blob/master/setup.py\">setup.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"Box-sc-g0xbh4-0 epsqEd d-none\" data-testid=\"view-all-files-row\"><td colSpan=\"3\" class=\"Box-sc-g0xbh4-0 ldpruc\"><div><button class=\"Link__StyledLink-sc-14289xe-0 dheQRw\">View all files</button></div></td></tr></tbody></table></div><div class=\"Box-sc-g0xbh4-0 ehcSsh\"><div class=\"Box-sc-g0xbh4-0 iGmlUb\"><div class=\"Box-sc-g0xbh4-0 iRQGXA\"><h2 class=\"_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0 rTZSs\">Repository files navigation</h2><nav aria-label=\"Repository files\" class=\"Box-sc-g0xbh4-0 dvTdPK\"><ul role=\"list\" class=\"UnderlineNav__NavigationList-sc-1jfr31k-0 bPgibo\"><li class=\"Box-sc-g0xbh4-0 gwuIGu\"><a href=\"#\" aria-current=\"page\" class=\"Link__StyledLink-sc-14289xe-0 vLMkZ\"><span data-component=\"icon\" class=\"Box-sc-g0xbh4-0 kOxwQs\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-book\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg></span><span data-component=\"text\" data-content=\"README\" class=\"Box-sc-g0xbh4-0 kOgeFj\">README</span></a></li><li class=\"Box-sc-g0xbh4-0 gwuIGu\"><a href=\"#\" class=\"Link__StyledLink-sc-14289xe-0 bhqztV\"><span data-component=\"icon\" class=\"Box-sc-g0xbh4-0 kOxwQs\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-law\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg></span><span data-component=\"text\" data-content=\"MIT license\" class=\"Box-sc-g0xbh4-0\">MIT license</span></a></li></ul></nav><button style=\"--button-color:fg.subtle\" type=\"button\" aria-label=\"Outline\" id=\":Rdkl5:\" aria-haspopup=\"true\" tabindex=\"0\" class=\"types__StyledButton-sc-ws60qy-0 jPraEl\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-list-unordered\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M5.75 2.5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2 14a1 1 0 1 1 0-2 1 1 0 0 1 0 2Zm1-6a1 1 0 1 1-2 0 1 1 0 0 1 2 0ZM2 4a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z\"></path></svg></button></div><div class=\"Box-sc-g0xbh4-0 bJMeLZ js-snippet-clipboard-copy-unpositioned\" data-hpc=\"true\"><article class=\"markdown-body entry-content container-lg\" itemprop=\"text\"><div class=\"markdown-heading\" dir=\"auto\"><h1 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Taming Transformers for High-Resolution Image Synthesis</h1><a id=\"user-content-taming-transformers-for-high-resolution-image-synthesis\" class=\"anchor-element\" aria-label=\"Permalink: Taming Transformers for High-Resolution Image Synthesis\" href=\"#taming-transformers-for-high-resolution-image-synthesis\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">CVPR 2021 (Oral)</h5><a id=\"user-content-cvpr-2021-oral\" class=\"anchor-element\" aria-label=\"Permalink: CVPR 2021 (Oral)\" href=\"#cvpr-2021-oral\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/mountain.jpeg\"><img src=\"/CompVis/taming-transformers/raw/master/assets/mountain.jpeg\" alt=\"teaser\" style=\"max-width: 100%;\"></a></p><p dir=\"auto\"><a href=\"https://compvis.github.io/taming-transformers/\" rel=\"nofollow\"><strong>Taming Transformers for High-Resolution Image Synthesis</strong></a><br><a href=\"https://github.com/pesser\">Patrick Esser</a>*,<a href=\"https://github.com/rromb\">Robin Rombach</a>*,<a href=\"https://hci.iwr.uni-heidelberg.de/Staff/bommer\" rel=\"nofollow\">Bj\u00f6rn Ommer</a><br>* equal contribution</p><p dir=\"auto\"><strong>tl;dr</strong> We combine the efficiancy of convolutional approaches with the expressivity of transformers by introducing a convolutional VQGAN, which learns a codebook of context-rich visual parts, whose composition is modeled with an autoregressive transformer.</p><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/teaser.png\"><img src=\"/CompVis/taming-transformers/raw/master/assets/teaser.png\" alt=\"teaser\" style=\"max-width: 100%;\"></a><a href=\"https://arxiv.org/abs/2012.09841\" rel=\"nofollow\">arXiv</a> | <a href=\"#bibtex\">BibTeX</a> | <a href=\"https://compvis.github.io/taming-transformers/\" rel=\"nofollow\">Project Page</a></p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">News</h3><a id=\"user-content-news\" class=\"anchor-element\" aria-label=\"Permalink: News\" href=\"#news\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">2022</h4><a id=\"user-content-2022\" class=\"anchor-element\" aria-label=\"Permalink: 2022\" href=\"#2022\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>More pretrained VQGANs (e.g. a f8-model with only 256 codebook entries) are available in our new work on <a href=\"https://github.com/CompVis/latent-diffusion\">Latent Diffusion Models</a>.</li><li>Added scene synthesis models as proposed in the paper <a href=\"https://arxiv.org/abs/2105.06458\" rel=\"nofollow\">High-Resolution Complex Scene Synthesis with Transformers</a>, see <a href=\"#scene-image-synthesis\">this section</a>.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">2021</h4><a id=\"user-content-2021\" class=\"anchor-element\" aria-label=\"Permalink: 2021\" href=\"#2021\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Thanks to <a href=\"https://github.com/rom1504\">rom1504</a> it is now easy to <a href=\"#training-on-custom-data\">train a VQGAN on your own datasets</a>.</li><li>Included a bugfix for the quantizer. For backward compatibility it isdisabled by default (which corresponds to always training with <code>beta=1.0</code>).Use <code>legacy=False</code> in the quantizer config to enable it.Thanks <a href=\"https://github.com/richcmwang\">richcmwang</a> and <a href=\"https://github.com/wcshin-git\">wcshin-git</a>!</li><li>Our paper received an update: See <a href=\"https://arxiv.org/abs/2012.09841v3\" rel=\"nofollow\">https://arxiv.org/abs/2012.09841v3</a> and the corresponding changelog.</li><li>Added a pretrained, <a href=\"https://k00.fr/s511rwcv\" rel=\"nofollow\">1.4B transformer model</a> trained for class-conditional ImageNet synthesis, which obtains state-of-the-art FID scores among autoregressive approaches and outperforms BigGAN.</li><li>Added pretrained, unconditional models on <a href=\"https://k00.fr/yndvfu95\" rel=\"nofollow\">FFHQ</a> and <a href=\"https://k00.fr/2xkmielf\" rel=\"nofollow\">CelebA-HQ</a>.</li><li>Added accelerated sampling via caching of keys/values in the self-attention operation, used in <code>scripts/sample_fast.py</code>.</li><li>Added a checkpoint of a <a href=\"https://heibox.uni-heidelberg.de/d/2e5662443a6b4307b470/\" rel=\"nofollow\">VQGAN</a> trained with f8 compression and Gumbel-Quantization.See also our updated <a href=\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/reconstruction_usage.ipynb\" rel=\"nofollow\">reconstruction notebook</a>.</li><li>We added a <a href=\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/reconstruction_usage.ipynb\" rel=\"nofollow\">colab notebook</a> which compares two VQGANs and OpenAI's <a href=\"https://github.com/openai/DALL-E\">DALL-E</a>. See also <a href=\"#more-resources\">this section</a>.</li><li>We now include an overview of pretrained models in <a href=\"#overview-of-pretrained-models\">Tab.1</a>. We added models for <a href=\"#coco\">COCO</a> and <a href=\"#ade20k\">ADE20k</a>.</li><li>The streamlit demo now supports image completions.</li><li>We now include a couple of examples from the D-RIN dataset so you can run the<a href=\"#d-rin\">D-RIN demo</a> without preparing the dataset first.</li><li>You can now jump right into sampling with our <a href=\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb\" rel=\"nofollow\">Colab quickstart notebook</a>.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Requirements</h2><a id=\"user-content-requirements\" class=\"anchor-element\" aria-label=\"Permalink: Requirements\" href=\"#requirements\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">A suitable <a href=\"https://conda.io/\" rel=\"nofollow\">conda</a> environment named <code>taming</code> can be createdand activated with:</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"conda env create -f environment.yamlconda activate taming\"><pre class=\"notranslate\"><code>conda env create -f environment.yamlconda activate taming</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Overview of pretrained models</h2><a id=\"user-content-overview-of-pretrained-models\" class=\"anchor-element\" aria-label=\"Permalink: Overview of pretrained models\" href=\"#overview-of-pretrained-models\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">The following table provides an overview of all models that are currently available.FID scores were evaluated using <a href=\"https://github.com/toshas/torch-fidelity\">torch-fidelity</a>.For reference, we also include a link to the recently released autoencoder of the <a href=\"https://github.com/openai/DALL-E\">DALL-E</a> model.See the corresponding <a href=\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/reconstruction_usage.ipynb\" rel=\"nofollow\">colabnotebook</a>for a comparison and discussion of reconstruction capabilities.</p><table><thead><tr><th>Dataset</th><th>FID vs train</th><th>FID vs val</th><th>Link</th><th>Samples (256x256)</th><th>Comments</th></tr></thead><tbody><tr><td>FFHQ (f=16)</td><td>9.6</td><td>--</td><td><a href=\"https://k00.fr/yndvfu95\" rel=\"nofollow\">ffhq_transformer</a></td><td><a href=\"https://k00.fr/j626x093\" rel=\"nofollow\">ffhq_samples</a></td><td></td></tr><tr><td>CelebA-HQ (f=16)</td><td>10.2</td><td>--</td><td><a href=\"https://k00.fr/2xkmielf\" rel=\"nofollow\">celebahq_transformer</a></td><td><a href=\"https://k00.fr/j626x093\" rel=\"nofollow\">celebahq_samples</a></td><td></td></tr><tr><td>ADE20K (f=16)</td><td>--</td><td>35.5</td><td><a href=\"https://k00.fr/ot46cksa\" rel=\"nofollow\">ade20k_transformer</a></td><td><a href=\"https://heibox.uni-heidelberg.de/f/70bb78cbaf844501b8fb/\" rel=\"nofollow\">ade20k_samples.zip</a> [2k]</td><td>evaluated on val split (2k images)</td></tr><tr><td>COCO-Stuff (f=16)</td><td>--</td><td>20.4</td><td><a href=\"https://k00.fr/2zz6i2ce\" rel=\"nofollow\">coco_transformer</a></td><td><a href=\"https://heibox.uni-heidelberg.de/f/a395a9be612f4a7a8054/\" rel=\"nofollow\">coco_samples.zip</a> [5k]</td><td>evaluated on val split (5k images)</td></tr><tr><td>ImageNet (cIN) (f=16)</td><td>15.98/15.78/6.59/5.88/5.20</td><td>--</td><td><a href=\"https://k00.fr/s511rwcv\" rel=\"nofollow\">cin_transformer</a></td><td><a href=\"https://k00.fr/j626x093\" rel=\"nofollow\">cin_samples</a></td><td>different decoding hyperparameters</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>FacesHQ (f=16)</td><td>--</td><td>--</td><td><a href=\"https://k00.fr/qqfl2do8\" rel=\"nofollow\">faceshq_transformer</a></td><td></td><td></td></tr><tr><td>S-FLCKR (f=16)</td><td>--</td><td>--</td><td><a href=\"https://heibox.uni-heidelberg.de/d/73487ab6e5314cb5adba/\" rel=\"nofollow\">sflckr</a></td><td></td><td></td></tr><tr><td>D-RIN (f=16)</td><td>--</td><td>--</td><td><a href=\"https://k00.fr/39jcugc5\" rel=\"nofollow\">drin_transformer</a></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>VQGAN ImageNet (f=16), 1024</td><td>10.54</td><td>7.94</td><td><a href=\"https://heibox.uni-heidelberg.de/d/8088892a516d4e3baf92/\" rel=\"nofollow\">vqgan_imagenet_f16_1024</a></td><td><a href=\"https://k00.fr/j626x093\" rel=\"nofollow\">reconstructions</a></td><td>Reconstruction-FIDs.</td></tr><tr><td>VQGAN ImageNet (f=16), 16384</td><td>7.41</td><td>4.98</td><td><a href=\"https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/\" rel=\"nofollow\">vqgan_imagenet_f16_16384</a></td><td><a href=\"https://k00.fr/j626x093\" rel=\"nofollow\">reconstructions</a></td><td>Reconstruction-FIDs.</td></tr><tr><td>VQGAN OpenImages (f=8), 256</td><td>--</td><td>1.49</td><td><a href=\"https://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip\" rel=\"nofollow\">https://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip</a></td><td>---</td><td>Reconstruction-FIDs. Available via <a href=\"https://github.com/CompVis/latent-diffusion\">latent diffusion</a>.</td></tr><tr><td>VQGAN OpenImages (f=8), 16384</td><td>--</td><td>1.14</td><td><a href=\"https://ommer-lab.com/files/latent-diffusion/vq-f8.zip\" rel=\"nofollow\">https://ommer-lab.com/files/latent-diffusion/vq-f8.zip</a></td><td>---</td><td>Reconstruction-FIDs. Available via <a href=\"https://github.com/CompVis/latent-diffusion\">latent diffusion</a></td></tr><tr><td>VQGAN OpenImages (f=8), 8192, GumbelQuantization</td><td>3.24</td><td>1.49</td><td><a href=\"https://heibox.uni-heidelberg.de/d/2e5662443a6b4307b470/\" rel=\"nofollow\">vqgan_gumbel_f8</a></td><td>---</td><td>Reconstruction-FIDs.</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>DALL-E dVAE (f=8), 8192, GumbelQuantization</td><td>33.88</td><td>32.01</td><td><a href=\"https://github.com/openai/DALL-E\">https://github.com/openai/DALL-E</a></td><td><a href=\"https://k00.fr/j626x093\" rel=\"nofollow\">reconstructions</a></td><td>Reconstruction-FIDs.</td></tr></tbody></table><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Running pretrained models</h2><a id=\"user-content-running-pretrained-models\" class=\"anchor-element\" aria-label=\"Permalink: Running pretrained models\" href=\"#running-pretrained-models\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">The commands below will start a streamlit demo which supports sampling atdifferent resolutions and image completions. To run a non-interactive versionof the sampling process, replace <code>streamlit run scripts/sample_conditional.py --</code>by <code>python scripts/make_samples.py --outdir &lt;path_to_write_samples_to&gt;</code> andkeep the remaining command line arguments.</p><p dir=\"auto\">To sample from unconditional or class-conditional models,run <code>python scripts/sample_fast.py -r &lt;path/to/config_and_checkpoint&gt;</code>.We describe below how to use this script to sample from the ImageNet, FFHQ, and CelebA-HQ models,respectively.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">S-FLCKR</h3><a id=\"user-content-s-flckr\" class=\"anchor-element\" aria-label=\"Permalink: S-FLCKR\" href=\"#s-flckr\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/sunset_and_ocean.jpg\"><img src=\"/CompVis/taming-transformers/raw/master/assets/sunset_and_ocean.jpg\" alt=\"teaser\" style=\"max-width: 100%;\"></a></p><p dir=\"auto\">You can also <a href=\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb\" rel=\"nofollow\">run this model in a Colabnotebook</a>,which includes all necessary steps to start sampling.</p><p dir=\"auto\">Download the<a href=\"https://heibox.uni-heidelberg.de/d/73487ab6e5314cb5adba/\" rel=\"nofollow\">2020-11-09T13-31-51_sflckr</a>folder and place it into <code>logs</code>. Then, run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-09T13-31-51_sflckr/\"><pre class=\"notranslate\"><code>streamlit run scripts/sample_conditional.py -- -r logs/2020-11-09T13-31-51_sflckr/</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">ImageNet</h3><a id=\"user-content-imagenet\" class=\"anchor-element\" aria-label=\"Permalink: ImageNet\" href=\"#imagenet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/imagenet.png\"><img src=\"/CompVis/taming-transformers/raw/master/assets/imagenet.png\" alt=\"teaser\" style=\"max-width: 100%;\"></a></p><p dir=\"auto\">Download the <a href=\"https://k00.fr/s511rwcv\" rel=\"nofollow\">2021-04-03T19-39-50_cin_transformer</a>folder and place it into logs.  Sampling from the class-conditional ImageNetmodel does not require any data preparation. To produce 50 samples for each ofthe 1000 classes of ImageNet, with k=600 for top-k sampling, p=0.92 for nucleussampling and temperature t=1.0, run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python scripts/sample_fast.py -r logs/2021-04-03T19-39-50_cin_transformer/ -n 50 -k 600 -t 1.0 -p 0.92 --batch_size 25   \"><pre class=\"notranslate\"><code>python scripts/sample_fast.py -r logs/2021-04-03T19-39-50_cin_transformer/ -n 50 -k 600 -t 1.0 -p 0.92 --batch_size 25   </code></pre></div><p dir=\"auto\">To restrict the model to certain classes, provide them via the <code>--classes</code> argument, separated bycommas. For example, to sample 50 <em>ostriches</em>, <em>border collies</em> and <em>whiskey jugs</em>, run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python scripts/sample_fast.py -r logs/2021-04-03T19-39-50_cin_transformer/ -n 50 -k 600 -t 1.0 -p 0.92 --batch_size 25 --classes 9,232,901   \"><pre class=\"notranslate\"><code>python scripts/sample_fast.py -r logs/2021-04-03T19-39-50_cin_transformer/ -n 50 -k 600 -t 1.0 -p 0.92 --batch_size 25 --classes 9,232,901   </code></pre></div><p dir=\"auto\">We recommended to experiment with the autoregressive decoding parameters (top-k, top-p and temperature) for best results.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">FFHQ/CelebA-HQ</h3><a id=\"user-content-ffhqceleba-hq\" class=\"anchor-element\" aria-label=\"Permalink: FFHQ/CelebA-HQ\" href=\"#ffhqceleba-hq\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Download the <a href=\"https://k00.fr/yndvfu95\" rel=\"nofollow\">2021-04-23T18-19-01_ffhq_transformer</a> and<a href=\"https://k00.fr/2xkmielf\" rel=\"nofollow\">2021-04-23T18-11-19_celebahq_transformer</a>folders and place them into logs.Again, sampling from these unconditional models does not require any data preparation.To produce 50000 samples, with k=250 for top-k sampling,p=1.0 for nucleus sampling and temperature t=1.0, run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python scripts/sample_fast.py -r logs/2021-04-23T18-19-01_ffhq_transformer/   \"><pre class=\"notranslate\"><code>python scripts/sample_fast.py -r logs/2021-04-23T18-19-01_ffhq_transformer/   </code></pre></div><p dir=\"auto\">for FFHQ and</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python scripts/sample_fast.py -r logs/2021-04-23T18-11-19_celebahq_transformer/   \"><pre class=\"notranslate\"><code>python scripts/sample_fast.py -r logs/2021-04-23T18-11-19_celebahq_transformer/   </code></pre></div><p dir=\"auto\">to sample from the CelebA-HQ model.For both models it can be advantageous to vary the top-k/top-p parameters for sampling.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">FacesHQ</h3><a id=\"user-content-faceshq\" class=\"anchor-element\" aria-label=\"Permalink: FacesHQ\" href=\"#faceshq\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/faceshq.jpg\"><img src=\"/CompVis/taming-transformers/raw/master/assets/faceshq.jpg\" alt=\"teaser\" style=\"max-width: 100%;\"></a></p><p dir=\"auto\">Download <a href=\"https://k00.fr/qqfl2do8\" rel=\"nofollow\">2020-11-13T21-41-45_faceshq_transformer</a> andplace it into <code>logs</code>. Follow the data preparation steps for<a href=\"#celeba-hq\">CelebA-HQ</a> and <a href=\"#ffhq\">FFHQ</a>. Run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-13T21-41-45_faceshq_transformer/\"><pre class=\"notranslate\"><code>streamlit run scripts/sample_conditional.py -- -r logs/2020-11-13T21-41-45_faceshq_transformer/</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">D-RIN</h3><a id=\"user-content-d-rin\" class=\"anchor-element\" aria-label=\"Permalink: D-RIN\" href=\"#d-rin\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/drin.jpg\"><img src=\"/CompVis/taming-transformers/raw/master/assets/drin.jpg\" alt=\"teaser\" style=\"max-width: 100%;\"></a></p><p dir=\"auto\">Download <a href=\"https://k00.fr/39jcugc5\" rel=\"nofollow\">2020-11-20T12-54-32_drin_transformer</a> andplace it into <code>logs</code>. To run the demo on a couple of example depth mapsincluded in the repository, run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T12-54-32_drin_transformer/ --ignore_base_data data=&quot;{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.imagenet.DRINExamples}}}&quot;\"><pre class=\"notranslate\"><code>streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T12-54-32_drin_transformer/ --ignore_base_data data=\"{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.imagenet.DRINExamples}}}\"</code></pre></div><p dir=\"auto\">To run the demo on the complete validation set, first follow the data preparation steps for<a href=\"#imagenet\">ImageNet</a> and then run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T12-54-32_drin_transformer/\"><pre class=\"notranslate\"><code>streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T12-54-32_drin_transformer/</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">COCO</h3><a id=\"user-content-coco\" class=\"anchor-element\" aria-label=\"Permalink: COCO\" href=\"#coco\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Download <a href=\"https://k00.fr/2zz6i2ce\" rel=\"nofollow\">2021-01-20T16-04-20_coco_transformer</a> andplace it into <code>logs</code>. To run the demo on a couple of example segmentation mapsincluded in the repository, run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"streamlit run scripts/sample_conditional.py -- -r logs/2021-01-20T16-04-20_coco_transformer/ --ignore_base_data data=&quot;{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.coco.Examples}}}&quot;\"><pre class=\"notranslate\"><code>streamlit run scripts/sample_conditional.py -- -r logs/2021-01-20T16-04-20_coco_transformer/ --ignore_base_data data=\"{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.coco.Examples}}}\"</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">ADE20k</h3><a id=\"user-content-ade20k\" class=\"anchor-element\" aria-label=\"Permalink: ADE20k\" href=\"#ade20k\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Download <a href=\"https://k00.fr/ot46cksa\" rel=\"nofollow\">2020-11-20T21-45-44_ade20k_transformer</a> andplace it into <code>logs</code>. To run the demo on a couple of example segmentation mapsincluded in the repository, run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T21-45-44_ade20k_transformer/ --ignore_base_data data=&quot;{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.ade20k.Examples}}}&quot;\"><pre class=\"notranslate\"><code>streamlit run scripts/sample_conditional.py -- -r logs/2020-11-20T21-45-44_ade20k_transformer/ --ignore_base_data data=\"{target: main.DataModuleFromConfig, params: {batch_size: 1, validation: {target: taming.data.ade20k.Examples}}}\"</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Scene Image Synthesis</h2><a id=\"user-content-scene-image-synthesis\" class=\"anchor-element\" aria-label=\"Permalink: Scene Image Synthesis\" href=\"#scene-image-synthesis\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/scene_images_samples.svg\"><img src=\"/CompVis/taming-transformers/raw/master/assets/scene_images_samples.svg\" alt=\"teaser\" style=\"max-width: 100%;\"></a>Scene image generation based on bounding box conditionals as done in our CVPR2021 AI4CC workshop paper <a href=\"https://arxiv.org/abs/2105.06458\" rel=\"nofollow\">High-Resolution Complex Scene Synthesis with Transformers</a> (see talk on <a href=\"https://visual.cs.brown.edu/workshops/aicc2021/#awards\" rel=\"nofollow\">workshop page</a>). Supporting the datasets COCO and Open Images.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Training</h3><a id=\"user-content-training\" class=\"anchor-element\" aria-label=\"Permalink: Training\" href=\"#training\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Download first-stage models <a href=\"https://heibox.uni-heidelberg.de/f/78dea9589974474c97c1/\" rel=\"nofollow\">COCO-8k-VQGAN</a> for COCO or <a href=\"https://heibox.uni-heidelberg.de/f/461d9a9f4fcf48ab84f4/\" rel=\"nofollow\">COCO/Open-Images-8k-VQGAN</a> for Open Images.Change <code>ckpt_path</code> in <code>data/coco_scene_images_transformer.yaml</code> and <code>data/open_images_scene_images_transformer.yaml</code> to point to the downloaded first-stage models.Download the full COCO/OI datasets and adapt <code>data_path</code> in the same files, unless working with the 100 files provided for training and validation suits your needs already.</p><p dir=\"auto\">Code can be run with<code>python main.py --base configs/coco_scene_images_transformer.yaml -t True --gpus 0,</code>or<code>python main.py --base configs/open_images_scene_images_transformer.yaml -t True --gpus 0,</code></p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Sampling</h3><a id=\"user-content-sampling\" class=\"anchor-element\" aria-label=\"Permalink: Sampling\" href=\"#sampling\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Train a model as described above or download a pre-trained model:</p><ul dir=\"auto\"><li><a href=\"https://drive.google.com/file/d/1FEK-Z7hyWJBvFWQF50pzSK9y1W_CJEig/view?usp=sharing\" rel=\"nofollow\">Open Images 1 billion parameter model</a> available that trained 100 epochs. On 256x256 pixels, FID 41.48\u00b10.21, SceneFID 14.60\u00b10.15, Inception Score 18.47\u00b10.27. The model was trained with 2d crops of images and is thus well-prepared for the task of generating high-resolution images, e.g. 512x512.</li><li><a href=\"https://drive.google.com/file/d/1xf89g0mc78J3d8Bx5YhbK4tNRNlOoYaO\" rel=\"nofollow\">Open Images distilled version of the above model with 125 million parameters</a> allows for sampling on smaller GPUs (4 GB is enough for sampling 256x256 px images). Model was trained for 60 epochs with 10% soft loss, 90% hard loss. On 256x256 pixels, FID 43.07\u00b10.40, SceneFID 15.93\u00b10.19, Inception Score 17.23\u00b10.11.</li><li><a href=\"https://heibox.uni-heidelberg.de/f/0d0b2594e9074c7e9a33/\" rel=\"nofollow\">COCO 30 epochs</a></li><li><a href=\"https://drive.google.com/file/d/1bInd49g2YulTJBjU32Awyt5qnzxxG5U9/\" rel=\"nofollow\">COCO 60 epochs</a> (find model statistics for both COCO versions in <code>assets/coco_scene_images_training.svg</code>)</li></ul><p dir=\"auto\">When downloading a pre-trained model, remember to change <code>ckpt_path</code> in <code>configs/*project.yaml</code> to point to your downloaded first-stage model (see -&gt;Training).</p><p dir=\"auto\">Scene image generation can be run with<code>python scripts/make_scene_samples.py --outdir=/some/outdir -r /path/to/pretrained/model --resolution=512,512</code></p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Training on custom data</h2><a id=\"user-content-training-on-custom-data\" class=\"anchor-element\" aria-label=\"Permalink: Training on custom data\" href=\"#training-on-custom-data\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Training on your own dataset can be beneficial to get better tokens and hence better images for your domain.Those are the steps to follow to make this work:</p><ol dir=\"auto\"><li>install the repo with <code>conda env create -f environment.yaml</code>, <code>conda activate taming</code> and <code>pip install -e .</code></li><li>put your .jpg files in a folder <code>your_folder</code></li><li>create 2 text files a <code>xx_train.txt</code> and <code>xx_test.txt</code> that point to the files in your training and test set respectively (for example <code>find $(pwd)/your_folder -name \"*.jpg\" &gt; train.txt</code>)</li><li>adapt <code>configs/custom_vqgan.yaml</code> to point to these 2 files</li><li>run <code>python main.py --base configs/custom_vqgan.yaml -t True --gpus 0,1</code> totrain on two GPUs. Use <code>--gpus 0,</code> (with a trailing comma) to train on a single GPU.</li></ol><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Data Preparation</h2><a id=\"user-content-data-preparation\" class=\"anchor-element\" aria-label=\"Permalink: Data Preparation\" href=\"#data-preparation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">ImageNet</h3><a id=\"user-content-imagenet-1\" class=\"anchor-element\" aria-label=\"Permalink: ImageNet\" href=\"#imagenet-1\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">The code will try to download (through <a href=\"http://academictorrents.com/\" rel=\"nofollow\">AcademicTorrents</a>) and prepare ImageNet the first time itis used. However, since ImageNet is quite large, this requires a lot of diskspace and time. If you already have ImageNet on your disk, you can speed thingsup by putting the data into<code>${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/</code> (which defaults to<code>~/.cache/autoencoders/data/ILSVRC2012_{split}/data/</code>), where <code>{split}</code> is oneof <code>train</code>/<code>validation</code>. It should have the following structure:</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/\u251c\u2500\u2500 n01440764\u2502   \u251c\u2500\u2500 n01440764_10026.JPEG\u2502   \u251c\u2500\u2500 n01440764_10027.JPEG\u2502   \u251c\u2500\u2500 ...\u251c\u2500\u2500 n01443537\u2502   \u251c\u2500\u2500 n01443537_10007.JPEG\u2502   \u251c\u2500\u2500 n01443537_10014.JPEG\u2502   \u251c\u2500\u2500 ...\u251c\u2500\u2500 ...\"><pre class=\"notranslate\"><code>${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/\u251c\u2500\u2500 n01440764\u2502   \u251c\u2500\u2500 n01440764_10026.JPEG\u2502   \u251c\u2500\u2500 n01440764_10027.JPEG\u2502   \u251c\u2500\u2500 ...\u251c\u2500\u2500 n01443537\u2502   \u251c\u2500\u2500 n01443537_10007.JPEG\u2502   \u251c\u2500\u2500 n01443537_10014.JPEG\u2502   \u251c\u2500\u2500 ...\u251c\u2500\u2500 ...</code></pre></div><p dir=\"auto\">If you haven't extracted the data, you can also place<code>ILSVRC2012_img_train.tar</code>/<code>ILSVRC2012_img_val.tar</code> (or symlinks to them) into<code>${XDG_CACHE}/autoencoders/data/ILSVRC2012_train/</code> /<code>${XDG_CACHE}/autoencoders/data/ILSVRC2012_validation/</code>, which will then beextracted into above structure without downloading it again.  Note that thiswill only happen if neither a folder<code>${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/</code> nor a file<code>${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/.ready</code> exist. Remove themif you want to force running the dataset preparation again.</p><p dir=\"auto\">You will then need to prepare the depth data using<a href=\"https://github.com/intel-isl/MiDaS\">MiDaS</a>. Create a symlink<code>data/imagenet_depth</code> pointing to a folder with two subfolders <code>train</code> and<code>val</code>, each mirroring the structure of the corresponding ImageNet folderdescribed above and containing a <code>png</code> file for each of ImageNet's <code>JPEG</code>files. The <code>png</code> encodes <code>float32</code> depth values obtained from MiDaS as RGBAimages. We provide the script <code>scripts/extract_depth.py</code> to generate this data.<strong>Please note</strong> that this script uses <a href=\"https://pytorch.org/hub/intelisl_midas_v2/\" rel=\"nofollow\">MiDaS via PyTorchHub</a>. When we prepared the data,the hub provided the <a href=\"https://github.com/intel-isl/MiDaS/releases/tag/v2\">MiDaSv2.0</a> version, but now itprovides a v2.1 version. We haven't tested our models with depth maps obtainedvia v2.1 and if you want to make sure that things work as expected, you mustadjust the script to make sure it explicitly uses<a href=\"https://github.com/intel-isl/MiDaS/releases/tag/v2\">v2.0</a>!</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">CelebA-HQ</h3><a id=\"user-content-celeba-hq\" class=\"anchor-element\" aria-label=\"Permalink: CelebA-HQ\" href=\"#celeba-hq\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Create a symlink <code>data/celebahq</code> pointing to a folder containing the <code>.npy</code>files of CelebA-HQ (instructions to obtain them can be found in the <a href=\"https://github.com/tkarras/progressive_growing_of_gans\">PGGANrepository</a>).</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">FFHQ</h3><a id=\"user-content-ffhq\" class=\"anchor-element\" aria-label=\"Permalink: FFHQ\" href=\"#ffhq\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Create a symlink <code>data/ffhq</code> pointing to the <code>images1024x1024</code> folder obtainedfrom the <a href=\"https://github.com/NVlabs/ffhq-dataset\">FFHQ repository</a>.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">S-FLCKR</h3><a id=\"user-content-s-flckr-1\" class=\"anchor-element\" aria-label=\"Permalink: S-FLCKR\" href=\"#s-flckr-1\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Unfortunately, we are not allowed to distribute the images we collected for theS-FLCKR dataset and can therefore only give a description how it was produced.There are many resources on <a href=\"https://github.com/adrianmrit/flickrdatasets\">collecting images from theweb</a> to get started.We collected sufficiently large images from <a href=\"https://www.flickr.com\" rel=\"nofollow\">flickr</a>(see <code>data/flickr_tags.txt</code> for a full list of tags used to find images)and various <a href=\"https://www.reddit.com/r/sfwpornnetwork/wiki/network\" rel=\"nofollow\">subreddits</a>(see <code>data/subreddits.txt</code> for all subreddits that were used).Overall, we collected 107625 images, and split them randomly into 96861training images and 10764 validation images. We then obtained segmentationmasks for each image using <a href=\"https://arxiv.org/abs/1606.00915\" rel=\"nofollow\">DeepLab v2</a>trained on <a href=\"https://arxiv.org/abs/1612.03716\" rel=\"nofollow\">COCO-Stuff</a>. We used a <a href=\"https://github.com/kazuto1011/deeplab-pytorch\">PyTorchreimplementation</a> and include anexample script for this process in <code>scripts/extract_segmentation.py</code>.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">COCO</h3><a id=\"user-content-coco-1\" class=\"anchor-element\" aria-label=\"Permalink: COCO\" href=\"#coco-1\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Create a symlink <code>data/coco</code> containing the images from the 2017 split in<code>train2017</code> and <code>val2017</code>, and their annotations in <code>annotations</code>. Files can beobtained from the <a href=\"https://cocodataset.org/\" rel=\"nofollow\">COCO webpage</a>. In addition, we usethe <a href=\"http://calvin.inf.ed.ac.uk/wp-content/uploads/data/cocostuffdataset/stuffthingmaps_trainval2017.zip\" rel=\"nofollow\">Stuff+thing PNG-style annotations on COCO 2017trainval</a>annotations from <a href=\"https://github.com/nightrome/cocostuff\">COCO-Stuff</a>, whichshould be placed under <code>data/cocostuffthings</code>.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">ADE20k</h3><a id=\"user-content-ade20k-1\" class=\"anchor-element\" aria-label=\"Permalink: ADE20k\" href=\"#ade20k-1\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Create a symlink <code>data/ade20k_root</code> containing the contents of<a href=\"http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\" rel=\"nofollow\">ADEChallengeData2016.zip</a>from the <a href=\"http://sceneparsing.csail.mit.edu/\" rel=\"nofollow\">MIT Scene Parsing Benchmark</a>.</p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Training models</h2><a id=\"user-content-training-models\" class=\"anchor-element\" aria-label=\"Permalink: Training models\" href=\"#training-models\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">FacesHQ</h3><a id=\"user-content-faceshq-1\" class=\"anchor-element\" aria-label=\"Permalink: FacesHQ\" href=\"#faceshq-1\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Train a VQGAN with</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python main.py --base configs/faceshq_vqgan.yaml -t True --gpus 0,\"><pre class=\"notranslate\"><code>python main.py --base configs/faceshq_vqgan.yaml -t True --gpus 0,</code></pre></div><p dir=\"auto\">Then, adjust the checkpoint path of the config key<code>model.params.first_stage_config.params.ckpt_path</code> in<code>configs/faceshq_transformer.yaml</code> (or download<a href=\"https://k00.fr/uxy5usa9\" rel=\"nofollow\">2020-11-09T13-33-36_faceshq_vqgan</a> and place into <code>logs</code>, whichcorresponds to the preconfigured checkpoint path), then run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python main.py --base configs/faceshq_transformer.yaml -t True --gpus 0,\"><pre class=\"notranslate\"><code>python main.py --base configs/faceshq_transformer.yaml -t True --gpus 0,</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">D-RIN</h3><a id=\"user-content-d-rin-1\" class=\"anchor-element\" aria-label=\"Permalink: D-RIN\" href=\"#d-rin-1\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Train a VQGAN on ImageNet with</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python main.py --base configs/imagenet_vqgan.yaml -t True --gpus 0,\"><pre class=\"notranslate\"><code>python main.py --base configs/imagenet_vqgan.yaml -t True --gpus 0,</code></pre></div><p dir=\"auto\">or download a pretrained one from <a href=\"https://k00.fr/u0j2dtac\" rel=\"nofollow\">2020-09-23T17-56-33_imagenet_vqgan</a>and place under <code>logs</code>. If you trained your own, adjust the path in the configkey <code>model.params.first_stage_config.params.ckpt_path</code> of<code>configs/drin_transformer.yaml</code>.</p><p dir=\"auto\">Train a VQGAN on Depth Maps of ImageNet with</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python main.py --base configs/imagenetdepth_vqgan.yaml -t True --gpus 0,\"><pre class=\"notranslate\"><code>python main.py --base configs/imagenetdepth_vqgan.yaml -t True --gpus 0,</code></pre></div><p dir=\"auto\">or download a pretrained one from <a href=\"https://k00.fr/55rlxs6i\" rel=\"nofollow\">2020-11-03T15-34-24_imagenetdepth_vqgan</a>and place under <code>logs</code>. If you trained your own, adjust the path in the configkey <code>model.params.cond_stage_config.params.ckpt_path</code> of<code>configs/drin_transformer.yaml</code>.</p><p dir=\"auto\">To train the transformer, run</p><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python main.py --base configs/drin_transformer.yaml -t True --gpus 0,\"><pre class=\"notranslate\"><code>python main.py --base configs/drin_transformer.yaml -t True --gpus 0,</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">More Resources</h2><a id=\"user-content-more-resources\" class=\"anchor-element\" aria-label=\"Permalink: More Resources\" href=\"#more-resources\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Comparing Different First Stage Models</h3><a id=\"user-content-comparing-different-first-stage-models\" class=\"anchor-element\" aria-label=\"Permalink: Comparing Different First Stage Models\" href=\"#comparing-different-first-stage-models\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">The reconstruction and compression capabilities of different fist stage models can be analyzed in this <a href=\"https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/reconstruction_usage.ipynb\" rel=\"nofollow\">colab notebook</a>.In particular, the notebook compares two VQGANs with a downsampling factor of f=16 for each and codebook dimensionality of 1024 and 16384,a VQGAN with f=8 and 8192 codebook entries and the discrete autoencoder of OpenAI's <a href=\"https://github.com/openai/DALL-E\">DALL-E</a> (which has f=8 and 8192codebook entries).<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/first_stage_squirrels.png\"><img src=\"/CompVis/taming-transformers/raw/master/assets/first_stage_squirrels.png\" alt=\"firststages1\" style=\"max-width: 100%;\"></a><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/first_stage_mushrooms.png\"><img src=\"/CompVis/taming-transformers/raw/master/assets/first_stage_mushrooms.png\" alt=\"firststages2\" style=\"max-width: 100%;\"></a></p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Other</h3><a id=\"user-content-other\" class=\"anchor-element\" aria-label=\"Permalink: Other\" href=\"#other\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>A <a href=\"https://www.youtube.com/watch?v=o7dqGcLDf0A&amp;feature=emb_imp_woyt\" rel=\"nofollow\">video summary</a> by <a href=\"https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg\" rel=\"nofollow\">Two Minute Papers</a>.</li><li>A <a href=\"https://www.youtube.com/watch?v=-wDSDtIAyWQ\" rel=\"nofollow\">video summary</a> by <a href=\"https://www.youtube.com/c/GradientDude/about\" rel=\"nofollow\">Gradient Dude</a>.</li><li>A <a href=\"https://wandb.ai/ayush-thakur/taming-transformer/reports/-Overview-Taming-Transformers-for-High-Resolution-Image-Synthesis---Vmlldzo0NjEyMTY\" rel=\"nofollow\">weights and biases report summarizing the paper</a>by <a href=\"https://github.com/ayulockin\">ayulockin</a>.</li><li>A <a href=\"https://www.youtube.com/watch?v=JfUTd8fjtX8&amp;feature=emb_imp_woyt\" rel=\"nofollow\">video summary</a> by <a href=\"https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg\" rel=\"nofollow\">What's AI</a>.</li><li>Take a look at <a href=\"https://github.com/ak9250/taming-transformers/blob/master/tamingtransformerscolab.ipynb\">ak9250's notebook</a> if you want to run the streamlit demos on Colab.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Text-to-Image Optimization via CLIP</h3><a id=\"user-content-text-to-image-optimization-via-clip\" class=\"anchor-element\" aria-label=\"Permalink: Text-to-Image Optimization via CLIP\" href=\"#text-to-image-optimization-via-clip\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">VQGAN has been successfully used as an image generator guided by the <a href=\"https://github.com/openai/CLIP\">CLIP</a> model, both for pure image generationfrom scratch and image-to-image translation. We recommend the following notebooks/videos/resources:</p><ul dir=\"auto\"><li><a href=\"https://twitter.com/advadnoun/status/1389316507134357506\" rel=\"nofollow\">Advadnouns</a> Patreon and corresponding LatentVision notebooks: <a href=\"https://www.patreon.com/patronizeme\" rel=\"nofollow\">https://www.patreon.com/patronizeme</a></li><li>The <a href=\"https://colab.research.google.com/drive/1L8oL-vLJXVcRzCFbPwOoMkPKJ8-aYdPN\" rel=\"nofollow\">notebook</a> of <a href=\"https://twitter.com/RiversHaveWings\" rel=\"nofollow\">Rivers Have Wings</a>.</li><li>A <a href=\"https://www.youtube.com/watch?v=90QDe6DQXF4&amp;t=12s\" rel=\"nofollow\">video</a> explanation by <a href=\"https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg\" rel=\"nofollow\">Dot CSV</a> (in Spanish, but English subtitles are available)</li></ul><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"/CompVis/taming-transformers/blob/master/assets/birddrawnbyachild.png\"><img src=\"/CompVis/taming-transformers/raw/master/assets/birddrawnbyachild.png\" alt=\"txt2img\" style=\"max-width: 100%;\"></a></p><p dir=\"auto\">Text prompt: <em>'A bird drawn by a child'</em></p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Shout-outs</h2><a id=\"user-content-shout-outs\" class=\"anchor-element\" aria-label=\"Permalink: Shout-outs\" href=\"#shout-outs\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Thanks to everyone who makes their code and models available. In particular,</p><ul dir=\"auto\"><li>The architecture of our VQGAN is inspired by <a href=\"https://github.com/hojonathanho/diffusion\">Denoising Diffusion Probabilistic Models</a></li><li>The very hackable transformer implementation <a href=\"https://github.com/karpathy/minGPT\">minGPT</a></li><li>The good ol' <a href=\"https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\">PatchGAN</a> and <a href=\"https://github.com/richzhang/PerceptualSimilarity\">Learned Perceptual Similarity (LPIPS)</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">BibTeX</h2><a id=\"user-content-bibtex\" class=\"anchor-element\" aria-label=\"Permalink: BibTeX\" href=\"#bibtex\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"@misc{esser2020taming,      title={Taming Transformers for High-Resolution Image Synthesis},       author={Patrick Esser and Robin Rombach and Bj\u00f6rn Ommer},      year={2020},      eprint={2012.09841},      archivePrefix={arXiv},      primaryClass={cs.CV}}\"><pre class=\"notranslate\"><code>@misc{esser2020taming,      title={Taming Transformers for High-Resolution Image Synthesis},       author={Patrick Esser and Robin Rombach and Bj\u00f6rn Ommer},      year={2020},      eprint={2012.09841},      archivePrefix={arXiv},      primaryClass={cs.CV}}</code></pre></div></article></div></div></div></div></div> <!-- --> <!-- --> <script type=\"application/json\" id=\"__PRIMER_DATA__\">{\"resolvedServerColorMode\":\"day\"}</script></div></react-partial>        <input type=\"hidden\" data-csrf=\"true\" value=\"/douMCEIZMP57wpkaeKrT06hRLCGRltj4a4JsmyOMd1u/1aTeK9aIzVyAV0xy1PLWMCSQ3NK/wYP1jeEDkFXhw==\" /></div>  <div data-view-component=\"true\" class=\"Layout-sidebar\">            <div class=\"BorderGrid about-margin\" data-pjax>        <div class=\"BorderGrid-row\">          <div class=\"BorderGrid-cell\">            <div class=\"hide-sm hide-md\">  <h2 class=\"mb-3 h4\">About</h2>      <p class=\"f4 my-3\">        Taming Transformers for High-Resolution Image Synthesis      </p>      <div class=\"my-3 d-flex flex-items-center\">        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link flex-shrink-0 mr-2\">    <path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg>        <span class=\"flex-auto min-width-0 css-truncate css-truncate-target width-fit\">          <a title=\"https://arxiv.org/abs/2012.09841\" role=\"link\" target=\"_blank\" rel=\"noopener noreferrer nofollow\" class=\"text-bold\" href=\"https://arxiv.org/abs/2012.09841\">arxiv.org/abs/2012.09841</a>        </span>      </div>    <h3 class=\"sr-only\">Resources</h3>    <div class=\"mt-2\">      <a class=\"Link--muted\" data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}\" href=\"#readme-ov-file\">        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-book mr-2\">    <path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg>        Readme</a>    </div>      <h3 class=\"sr-only\">License</h3>  <div class=\"mt-2\">    <a href=\"#MIT-1-ov-file\"      class=\"Link--muted\"            data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}\"    >      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-law mr-2\">    <path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg>     MIT license    </a>  </div>  <include-fragment  src=\"/compvis/taming-transformers/hovercards/citation/sidebar_partial?tree_name=master\">  </include-fragment>  <div class=\"mt-2\">    <a href=\"/CompVis/taming-transformers/activity\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg text=\"gray\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pulse mr-2\">    <path d=\"M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z\"></path></svg>      <span class=\"color-fg-muted\">Activity</span></a>  </div>    <div class=\"mt-2\">      <a href=\"/CompVis/taming-transformers/custom-properties\" data-view-component=\"true\" class=\"Link Link--muted\">        <svg text=\"gray\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-note mr-2\">    <path d=\"M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25Zm1.75-.25a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25ZM3.5 6.25a.75.75 0 0 1 .75-.75h7a.75.75 0 0 1 0 1.5h-7a.75.75 0 0 1-.75-.75Zm.75 2.25h4a.75.75 0 0 1 0 1.5h-4a.75.75 0 0 1 0-1.5Z\"></path></svg>        <span class=\"color-fg-muted\">Custom properties</span></a>    </div>  <h3 class=\"sr-only\">Stars</h3>  <div class=\"mt-2\">    <a href=\"/CompVis/taming-transformers/stargazers\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg>      <strong>5.2k</strong>      stars</a>  </div>  <h3 class=\"sr-only\">Watchers</h3>  <div class=\"mt-2\">    <a href=\"/CompVis/taming-transformers/watchers\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-eye mr-2\">    <path d=\"M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z\"></path></svg>      <strong>74</strong>      watching</a>  </div>  <h3 class=\"sr-only\">Forks</h3>  <div class=\"mt-2\">    <a href=\"/CompVis/taming-transformers/forks\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-2\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>      <strong>1.1k</strong>      forks</a>  </div>    <div class=\"mt-2\">      <a class=\"Link--muted\" href=\"/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FCompVis%2Ftaming-transformers&amp;report=CompVis+%28user%29\">          Report repository</a>    </div></div>          </div>        </div>                    <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\">  <a href=\"/CompVis/taming-transformers/releases\" data-view-component=\"true\" class=\"Link--primary no-underline Link\">    Releases</a></h2>    <div class=\"text-small color-fg-muted\">No releases published</div>              </div>            </div>                            <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">  <a href=\"/orgs/CompVis/packages?repo_name=taming-transformers\" data-view-component=\"true\" class=\"Link--primary no-underline Link d-flex flex-items-center\">    Packages      <span title=\"0\" hidden=\"hidden\" data-view-component=\"true\" class=\"Counter ml-1\">0</span></a></h2>      <div class=\"text-small color-fg-muted\">        No packages published <br>      </div>              </div>            </div>                    <div class=\"BorderGrid-row\" >              <div class=\"BorderGrid-cell\">                  <h2 class=\"h4 mb-3\">    <a href=\"/CompVis/taming-transformers/network/dependents\" data-view-component=\"true\" class=\"Link--primary no-underline Link\">      Used by <span title=\"397\" data-view-component=\"true\" class=\"Counter\">397</span></a>  </h2>  <a class=\"d-flex flex-items-center\" href=\"/CompVis/taming-transformers/network/dependents\">    <ul class=\"hx_flex-avatar-stack list-style-none min-width-0\">          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/161731248?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@bfriend0303\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/44968714?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@yuhaoliu7456\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/131300370?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@rexionmars\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/16623530?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@pangjh3\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/27672442?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@thxxx\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/82561851?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@viboognesh\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/74986481?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@code-x-0018\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar\" src=\"https://avatars.githubusercontent.com/u/45630465?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@ictnlp\" />          </li>    </ul>      <span class=\"px-2 text-bold text-small no-wrap\">        + 389      </span>  </a>              </div>            </div>                    <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">  <a href=\"/CompVis/taming-transformers/graphs/contributors\" data-view-component=\"true\" class=\"Link--primary no-underline Link d-flex flex-items-center\">    Contributors      <span title=\"8\" data-view-component=\"true\" class=\"Counter ml-1\">8</span></a></h2>      <ul class=\"list-style-none d-flex flex-wrap mb-n2\">    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/pesser\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/pesser/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/2175508?s=64&amp;v=4\" alt=\"@pesser\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/rromb\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/rromb/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/38811725?s=64&amp;v=4\" alt=\"@rromb\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/manolo-lolo\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/manolo-lolo/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/47297044?s=64&amp;v=4\" alt=\"@manolo-lolo\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/tgisaturday\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/tgisaturday/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/3591020?s=64&amp;v=4\" alt=\"@tgisaturday\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/rom1504\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/rom1504/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/2346494?s=64&amp;v=4\" alt=\"@rom1504\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/carmocca\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/carmocca/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/11067892?s=64&amp;v=4\" alt=\"@carmocca\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/olaviinha\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/olaviinha/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/50331907?s=64&amp;v=4\" alt=\"@olaviinha\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/wcshin-git\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/wcshin-git/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/76698585?s=64&amp;v=4\" alt=\"@wcshin-git\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li></ul>              </div>            </div>                            <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">Languages</h2><div class=\"mb-2\">  <span data-view-component=\"true\" class=\"Progress\">    <span style=\"background-color:#DA5B0B !important;;width: 98.3%;\" itemprop=\"keywords\" aria-label=\"Jupyter Notebook 98.3\" data-view-component=\"true\" class=\"Progress-item color-bg-success-emphasis\"></span>    <span style=\"background-color:#3572A5 !important;;width: 1.7%;\" itemprop=\"keywords\" aria-label=\"Python 1.7\" data-view-component=\"true\" class=\"Progress-item color-bg-success-emphasis\"></span></span></div><ul class=\"list-style-none\">    <li class=\"d-inline\">        <a class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3\" href=\"/CompVis/taming-transformers/search?l=jupyter-notebook\"  data-ga-click=\"Repository, language stats search click, location:repo overview\">          <svg style=\"color:#DA5B0B;\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill mr-2\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg>          <span class=\"color-fg-default text-bold mr-1\">Jupyter Notebook</span>          <span>98.3%</span>        </a>    </li>    <li class=\"d-inline\">        <a class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3\" href=\"/CompVis/taming-transformers/search?l=python\"  data-ga-click=\"Repository, language stats search click, location:repo overview\">          <svg style=\"color:#3572A5;\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill mr-2\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg>          <span class=\"color-fg-default text-bold mr-1\">Python</span>          <span>1.7%</span>        </a>    </li></ul>              </div>            </div>              </div></div>  </div></div>  </div>  </div></turbo-frame>    </main>  </div>  </div>          <footer class=\"footer pt-8 pb-6 f6 color-fg-muted p-responsive\" role=\"contentinfo\" >  <h2 class='sr-only'>Footer</h2>    <div class=\"d-flex flex-justify-center flex-items-center flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap\">    <div class=\"d-flex flex-items-center flex-shrink-0 mx-2\">      <a aria-label=\"Homepage\" title=\"GitHub\" class=\"footer-octicon mr-2\" href=\"https://github.com\">        <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-mark-github\">    <path d=\"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z\"></path></svg></a>      <span>        &copy; 2024 GitHub,&nbsp;Inc.      </span>    </div>    <nav aria-label=\"Footer\">      <h3 class=\"sr-only\" id=\"sr-footer-heading\">Footer navigation</h3>      <ul class=\"list-style-none d-flex flex-justify-center flex-wrap mb-2 mb-lg-0\" aria-labelledby=\"sr-footer-heading\">          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to Terms&quot;,&quot;label&quot;:&quot;text:terms&quot;}\" href=\"https://docs.github.com/site-policy/github-terms/github-terms-of-service\" data-view-component=\"true\" class=\"Link--secondary Link\">Terms</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to privacy&quot;,&quot;label&quot;:&quot;text:privacy&quot;}\" href=\"https://docs.github.com/site-policy/privacy-policies/github-privacy-statement\" data-view-component=\"true\" class=\"Link--secondary Link\">Privacy</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to security&quot;,&quot;label&quot;:&quot;text:security&quot;}\" href=\"/security\" data-view-component=\"true\" class=\"Link--secondary Link\">Security</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to status&quot;,&quot;label&quot;:&quot;text:status&quot;}\" href=\"https://www.githubstatus.com/\" data-view-component=\"true\" class=\"Link--secondary Link\">Status</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to docs&quot;,&quot;label&quot;:&quot;text:docs&quot;}\" href=\"https://docs.github.com\" data-view-component=\"true\" class=\"Link--secondary Link\">Docs</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to contact&quot;,&quot;label&quot;:&quot;text:contact&quot;}\" href=\"https://support.github.com?tags=dotcom-footer\" data-view-component=\"true\" class=\"Link--secondary Link\">Contact</a>          </li>          <li class=\"mx-2\" >  <cookie-consent-link>    <button type=\"button\" class=\"Link--secondary underline-on-hover border-0 p-0 color-bg-transparent\" data-action=\"click:cookie-consent-link#showConsentManagement\">      Manage cookies    </button>  </cookie-consent-link></li><li class=\"mx-2\">  <cookie-consent-link>    <button type=\"button\" class=\"Link--secondary underline-on-hover border-0 p-0 color-bg-transparent\" data-action=\"click:cookie-consent-link#showConsentManagement\">      Do not share my personal information    </button>  </cookie-consent-link></li>      </ul>    </nav>  </div></footer>    <cookie-consent id=\"cookie-consent-banner\" class=\"position-fixed bottom-0 left-0\" style=\"z-index: 999999\" data-initial-cookie-consent-allowed=\"\" data-cookie-consent-required=\"false\"></cookie-consent>  <div id=\"ajax-error-message\" class=\"ajax-error-message flash flash-error\" hidden>    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>    <button type=\"button\" class=\"flash-close js-ajax-error-dismiss\" aria-label=\"Dismiss error\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>    </button>    You can\u2019t perform that action at this time.  </div>    <template id=\"site-details-dialog\">  <details class=\"details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm\" open>    <summary role=\"button\" aria-label=\"Close dialog\"></summary>    <details-dialog class=\"Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal\">      <button class=\"Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0\" type=\"button\" aria-label=\"Close dialog\" data-close-dialog>        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>      </button>      <div class=\"octocat-spinner my-6 js-details-dialog-spinner\"></div>    </details-dialog>  </details></template>    <div class=\"Popover js-hovercard-content position-absolute\" style=\"display: none; outline: none;\" tabindex=\"0\">  <div class=\"Popover-message Popover-message--bottom-left Popover-message--large Box color-shadow-large\" style=\"width:360px;\">  </div></div>    <template id=\"snippet-clipboard-copy-button\">  <div class=\"zeroclipboard-container position-absolute right-0 top-0\">    <clipboard-copy aria-label=\"Copy\" class=\"ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copy js-clipboard-copy-icon m-2\">    <path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"></path><path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg>      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2\">    <path d=\"M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"></path></svg>    </clipboard-copy>  </div></template><template id=\"snippet-clipboard-copy-button-unpositioned\">  <div class=\"zeroclipboard-container\">    <clipboard-copy aria-label=\"Copy\" class=\"ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copy js-clipboard-copy-icon\">    <path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"></path><path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg>      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none\">    <path d=\"M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"></path></svg>    </clipboard-copy>  </div></template>    </div>    <div id=\"js-global-screen-reader-notice\" class=\"sr-only\" aria-live=\"polite\" aria-atomic=\"true\" ></div>    <div id=\"js-global-screen-reader-notice-assertive\" class=\"sr-only\" aria-live=\"assertive\" aria-atomic=\"true\"></div>  </body></html>",
  "embeddings": []
}