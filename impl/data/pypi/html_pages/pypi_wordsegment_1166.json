{
  "libtype": "pypi",
  "libname": "wordsegment",
  "url": "http://www.grantjenks.com/docs/wordsegment/",
  "html": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"  \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"><html xmlns=\"http://www.w3.org/1999/xhtml\">  <head>    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />    <title>Python Word Segmentation &#8212; Word Segment 1.3.1 documentation</title>    <link rel=\"stylesheet\" href=\"_static/alabaster.css\" type=\"text/css\" />    <link rel=\"stylesheet\" href=\"_static/pygments.css\" type=\"text/css\" />    <script type=\"text/javascript\" src=\"_static/documentation_options.js\"></script>    <script type=\"text/javascript\" src=\"_static/jquery.js\"></script>    <script type=\"text/javascript\" src=\"_static/underscore.js\"></script>    <script type=\"text/javascript\" src=\"_static/doctools.js\"></script>    <link rel=\"index\" title=\"Index\" href=\"genindex.html\" />    <link rel=\"search\" title=\"Search\" href=\"search.html\" />     <link rel=\"stylesheet\" href=\"_static/custom.css\" type=\"text/css\" />      <meta name=\"viewport\" content=\"width=device-width, initial-scale=0.9, maximum-scale=0.9\" />  </head><body>      <div class=\"document\">      <div class=\"documentwrapper\">        <div class=\"bodywrapper\">          <div class=\"body\" role=\"main\">              <div class=\"section\" id=\"python-word-segmentation\"><h1>Python Word Segmentation<a class=\"headerlink\" href=\"#python-word-segmentation\" title=\"Permalink to this headline\">\u00b6</a></h1><p><a class=\"reference external\" href=\"http://www.grantjenks.com/docs/wordsegment/\">WordSegment</a> is an Apache2 licensed module for English wordsegmentation, written in pure-Python, and based on a trillion-word corpus.</p><p>Based on code from the chapter \u201c<a class=\"reference external\" href=\"http://norvig.com/ngrams/\">Natural Language Corpus Data</a>\u201d by PeterNorvig from the book \u201c<a class=\"reference external\" href=\"http://oreilly.com/catalog/9780596157111/\">Beautiful Data</a>\u201d (Segaran and Hammerbacher, 2009).</p><p>Data files are derived from the <a class=\"reference external\" href=\"http://googleresearch.blogspot.com/2006/08/all-our-n-gram-are-belong-to-you.html\">Google Web Trillion Word Corpus</a>, asdescribed by Thorsten Brants and Alex Franz, and <a class=\"reference external\" href=\"https://catalog.ldc.upenn.edu/LDC2006T13\">distributed</a> by theLinguistic Data Consortium. This module contains only a subset of thatdata. The unigram data includes only the most common 333,000 words. Similarly,bigram data includes only the most common 250,000 phrases. Every word andphrase is lowercased with punctuation removed.</p><div class=\"section\" id=\"features\"><h2>Features<a class=\"headerlink\" href=\"#features\" title=\"Permalink to this headline\">\u00b6</a></h2><ul class=\"simple\"><li>Pure-Python</li><li>Fully documented</li><li>100% Test Coverage</li><li>Includes unigram and bigram data</li><li>Command line interface for batch processing</li><li>Easy to hack (e.g. different scoring, new data, different language)</li><li>Developed on Python 2.7</li><li>Tested on CPython 2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6 and PyPy, PyPy3</li><li>Tested on Windows, Mac OS X, and Linux</li><li>Tested using Travis CI and AppVeyor CI</li></ul><a class=\"reference external image-reference\" href=\"http://www.grantjenks.com/docs/wordsegment/\"><img alt=\"https://api.travis-ci.org/grantjenks/python-wordsegment.svg\" src=\"https://api.travis-ci.org/grantjenks/python-wordsegment.svg\" /></a><a class=\"reference external image-reference\" href=\"http://www.grantjenks.com/docs/wordsegment/\"><img alt=\"https://ci.appveyor.com/api/projects/status/github/grantjenks/python-wordsegment?branch=master&amp;svg=true\" src=\"https://ci.appveyor.com/api/projects/status/github/grantjenks/python-wordsegment?branch=master&amp;svg=true\" /></a></div><div class=\"section\" id=\"quickstart\"><h2>Quickstart<a class=\"headerlink\" href=\"#quickstart\" title=\"Permalink to this headline\">\u00b6</a></h2><p>Installing <a class=\"reference external\" href=\"http://www.grantjenks.com/docs/wordsegment/\">WordSegment</a> is simple with<a class=\"reference external\" href=\"http://www.pip-installer.org/\">pip</a>:</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span>$ pip install wordsegment</pre></div></div><p>You can access documentation in the interpreter with Python\u2019s built-in helpfunction:</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">wordsegment</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">help</span><span class=\"p\">(</span><span class=\"n\">wordsegment</span><span class=\"p\">)</span></pre></div></div></div><div class=\"section\" id=\"tutorial\"><h2>Tutorial<a class=\"headerlink\" href=\"#tutorial\" title=\"Permalink to this headline\">\u00b6</a></h2><p>In your own Python programs, you\u2019ll mostly want to use <cite>segment</cite> to divide aphrase into a list of its parts:</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">wordsegment</span> <span class=\"k\">import</span> <span class=\"n\">load</span><span class=\"p\">,</span> <span class=\"n\">segment</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">load</span><span class=\"p\">()</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">segment</span><span class=\"p\">(</span><span class=\"s1\">&#39;thisisatest&#39;</span><span class=\"p\">)</span><span class=\"go\">[&#39;this&#39;, &#39;is&#39;, &#39;a&#39;, &#39;test&#39;]</span></pre></div></div><p>The <cite>load</cite> function reads and parses the unigrams and bigrams data fromdisk. Loading the data only needs to be done once.</p><p><a class=\"reference external\" href=\"http://www.grantjenks.com/docs/wordsegment/\">WordSegment</a> also provides a command-line interface for batchprocessing. This interface accepts two arguments: in-file and out-file. Linesfrom in-file are iteratively segmented, joined by a space, and written toout-file. Input and output default to stdin and stdout respectively.</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span>$ echo thisisatest | python -m wordsegmentthis is a test</pre></div></div><p>If you want to run <a class=\"reference external\" href=\"http://www.grantjenks.com/docs/wordsegment/\">WordSegment</a> as a kind of server process then use Python\u2019s<code class=\"docutils literal notranslate\"><span class=\"pre\">-u</span></code> option for unbuffered output. You can also set <code class=\"docutils literal notranslate\"><span class=\"pre\">PYTHONUNBUFFERED=1</span></code> inthe environment.</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">subprocess</span> <span class=\"k\">as</span> <span class=\"nn\">sp</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">wordsegment</span> <span class=\"o\">=</span> <span class=\"n\">sp</span><span class=\"o\">.</span><span class=\"n\">Popen</span><span class=\"p\">(</span><span class=\"go\">        [&#39;python&#39;, &#39;-um&#39;, &#39;wordsegment&#39;],</span><span class=\"go\">        stdin=sp.PIPE, stdout=sp.PIPE, stderr=sp.STDOUT)</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">wordsegment</span><span class=\"o\">.</span><span class=\"n\">stdin</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"s1\">&#39;thisisatest</span><span class=\"se\">\\n</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">wordsegment</span><span class=\"o\">.</span><span class=\"n\">stdout</span><span class=\"o\">.</span><span class=\"n\">readline</span><span class=\"p\">()</span><span class=\"go\">&#39;this is a test\\n&#39;</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">wordsegment</span><span class=\"o\">.</span><span class=\"n\">stdin</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"s1\">&#39;workswithotherlanguages</span><span class=\"se\">\\n</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">wordsegment</span><span class=\"o\">.</span><span class=\"n\">stdout</span><span class=\"o\">.</span><span class=\"n\">readline</span><span class=\"p\">()</span><span class=\"go\">&#39;works with other languages\\n&#39;</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">wordsegment</span><span class=\"o\">.</span><span class=\"n\">stdin</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">wordsegment</span><span class=\"o\">.</span><span class=\"n\">wait</span><span class=\"p\">()</span>  <span class=\"c1\"># Process exit code.</span><span class=\"go\">0</span></pre></div></div><p>The maximum segmented word length is 24 characters. Neither the unigram norbigram data contain words exceeding that length. The corpus also excludespunctuation and all letters have been lowercased. Before segmenting text,<cite>clean</cite> is called to transform the input to a canonical form:</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">wordsegment</span> <span class=\"k\">import</span> <span class=\"n\">clean</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">clean</span><span class=\"p\">(</span><span class=\"s1\">&#39;She said, &quot;Python rocks!&quot;&#39;</span><span class=\"p\">)</span><span class=\"go\">&#39;shesaidpythonrocks&#39;</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">segment</span><span class=\"p\">(</span><span class=\"s1\">&#39;She said, &quot;Python rocks!&quot;&#39;</span><span class=\"p\">)</span><span class=\"go\">[&#39;she&#39;, &#39;said&#39;, &#39;python&#39;, &#39;rocks&#39;]</span></pre></div></div><p>Sometimes its interesting to explore the unigram and bigram countsthemselves. These are stored in Python dictionaries mapping word to count.</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">wordsegment</span> <span class=\"k\">as</span> <span class=\"nn\">ws</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">()</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">UNIGRAMS</span><span class=\"p\">[</span><span class=\"s1\">&#39;the&#39;</span><span class=\"p\">]</span><span class=\"go\">23135851162.0</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">UNIGRAMS</span><span class=\"p\">[</span><span class=\"s1\">&#39;gray&#39;</span><span class=\"p\">]</span><span class=\"go\">21424658.0</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">UNIGRAMS</span><span class=\"p\">[</span><span class=\"s1\">&#39;grey&#39;</span><span class=\"p\">]</span><span class=\"go\">18276942.0</span></pre></div></div><p>Above we see that the spelling <cite>gray</cite> is more common than the spelling <cite>grey</cite>.</p><p>Bigrams are joined by a space:</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">heapq</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pprint</span> <span class=\"k\">import</span> <span class=\"n\">pprint</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">operator</span> <span class=\"k\">import</span> <span class=\"n\">itemgetter</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pprint</span><span class=\"p\">(</span><span class=\"n\">heapq</span><span class=\"o\">.</span><span class=\"n\">nlargest</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">BIGRAMS</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">(),</span> <span class=\"n\">itemgetter</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)))</span><span class=\"go\">[(&#39;of the&#39;, 2766332391.0),</span><span class=\"go\"> (&#39;in the&#39;, 1628795324.0),</span><span class=\"go\"> (&#39;to the&#39;, 1139248999.0),</span><span class=\"go\"> (&#39;on the&#39;, 800328815.0),</span><span class=\"go\"> (&#39;for the&#39;, 692874802.0),</span><span class=\"go\"> (&#39;and the&#39;, 629726893.0),</span><span class=\"go\"> (&#39;to be&#39;, 505148997.0),</span><span class=\"go\"> (&#39;is a&#39;, 476718990.0),</span><span class=\"go\"> (&#39;with the&#39;, 461331348.0),</span><span class=\"go\"> (&#39;from the&#39;, 428303219.0)]</span></pre></div></div><p>Some bigrams begin with <cite>&lt;s&gt;</cite>. This is to indicate the start of a bigram:</p><div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">BIGRAMS</span><span class=\"p\">[</span><span class=\"s1\">&#39;&lt;s&gt; where&#39;</span><span class=\"p\">]</span><span class=\"go\">15419048.0</span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">BIGRAMS</span><span class=\"p\">[</span><span class=\"s1\">&#39;&lt;s&gt; what&#39;</span><span class=\"p\">]</span><span class=\"go\">11779290.0</span></pre></div></div><p>The unigrams and bigrams data is stored in the <cite>wordsegment</cite> directory inthe <cite>unigrams.txt</cite> and <cite>bigrams.txt</cite> files respectively.</p></div><div class=\"section\" id=\"user-guide\"><h2>User Guide<a class=\"headerlink\" href=\"#user-guide\" title=\"Permalink to this headline\">\u00b6</a></h2><ul class=\"simple\"><li><a class=\"reference external\" href=\"http://www.grantjenks.com/docs/wordsegment/api.html\">Word Segment API Reference</a></li><li><a class=\"reference external\" href=\"http://www.grantjenks.com/docs/wordsegment/using-a-different-corpus.html\">Using a Different Corpus</a></li><li><a class=\"reference external\" href=\"http://www.grantjenks.com/docs/wordsegment/python-load-dict-fast-from-file.html\">Python: Load dict Fast From File</a></li></ul></div><div class=\"section\" id=\"references\"><h2>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this headline\">\u00b6</a></h2><ul class=\"simple\"><li><a class=\"reference external\" href=\"http://www.grantjenks.com/docs/wordsegment/\">WordSegment Documentation</a></li><li><a class=\"reference external\" href=\"https://pypi.python.org/pypi/wordsegment\">WordSegment at PyPI</a></li><li><a class=\"reference external\" href=\"https://github.com/grantjenks/python-wordsegment\">WordSegment at Github</a></li><li><a class=\"reference external\" href=\"https://github.com/grantjenks/python-wordsegment/issues\">WordSegment Issue Tracker</a></li></ul></div><div class=\"section\" id=\"wordsegment-license\"><h2>WordSegment License<a class=\"headerlink\" href=\"#wordsegment-license\" title=\"Permalink to this headline\">\u00b6</a></h2><p>Copyright 2018 Grant Jenks</p><p>Licensed under the Apache License, Version 2.0 (the \u201cLicense\u201d);you may not use this file except in compliance with the License.You may obtain a copy of the License at</p><blockquote><div><a class=\"reference external\" href=\"http://www.apache.org/licenses/LICENSE-2.0\">http://www.apache.org/licenses/LICENSE-2.0</a></div></blockquote><p>Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an \u201cAS IS\u201d BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.</p></div></div>          </div>        </div>      </div>      <div class=\"sphinxsidebar\" role=\"navigation\" aria-label=\"main navigation\">        <div class=\"sphinxsidebarwrapper\"><p class=\"logo\">  <a href=\"#\">    <img class=\"logo\" src=\"_static/gj-logo.png\" alt=\"Logo\"/>        <h1 class=\"logo logo-name\">Word Segment</h1>      </a></p><p><iframe src=\"https://ghbtns.com/github-btn.html?user=grantjenks&repo=python-wordsegment&type=star&count=true&size=large&v=2\"  allowtransparency=\"true\" frameborder=\"0\" scrolling=\"0\" width=\"200px\" height=\"35px\"></iframe></p>    <p><a href=\"https://travis-ci.org/grantjenks/python-wordsegment\">    <img        alt=\"https://secure.travis-ci.org/grantjenks/python-wordsegment.svg?branch=master\"        src=\"https://secure.travis-ci.org/grantjenks/python-wordsegment.svg?branch=master\"    /></a></p><h3>Give Support</h3><p>If you or your organization uses WordSegment, consider financial support:</p><p>  <a href=\"http://gum.co/wordsegment\" target=\"_blank\">Give to Python WordSegment</a></p>   <h3><a href=\"#\">Table Of Contents</a></h3>  <ul><li><a class=\"reference internal\" href=\"#\">Python Word Segmentation</a><ul><li><a class=\"reference internal\" href=\"#features\">Features</a></li><li><a class=\"reference internal\" href=\"#quickstart\">Quickstart</a></li><li><a class=\"reference internal\" href=\"#tutorial\">Tutorial</a></li><li><a class=\"reference internal\" href=\"#user-guide\">User Guide</a></li><li><a class=\"reference internal\" href=\"#references\">References</a></li><li><a class=\"reference internal\" href=\"#wordsegment-license\">WordSegment License</a></li></ul></li></ul><div class=\"relations\"><h3>Related Topics</h3><ul>  <li><a href=\"#\">Documentation overview</a><ul>  </ul></li></ul></div><div id=\"searchbox\" style=\"display: none\" role=\"search\">  <h3>Quick search</h3>    <div class=\"searchformwrapper\">    <form class=\"search\" action=\"search.html\" method=\"get\">      <input type=\"text\" name=\"q\" />      <input type=\"submit\" value=\"Go\" />      <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />      <input type=\"hidden\" name=\"area\" value=\"default\" />    </form>    </div></div><script type=\"text/javascript\">$('#searchbox').show(0);</script>        </div>      </div>      <div class=\"clearer\"></div>    </div>    <div class=\"footer\">      &copy;2017, Grant Jenks.            |      <a href=\"_sources/index.rst.txt\"          rel=\"nofollow\">Page source</a>    </div>            <script type=\"text/javascript\">      var _gaq = _gaq || [];      _gaq.push(['_setAccount', 'UA-19364636-2']);      _gaq.push(['_setDomainName', 'none']);      _gaq.push(['_setAllowLinker', true]);      _gaq.push(['_trackPageview']);      (function() {        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);      })();    </script>      </body></html>",
  "embeddings": []
}