{
  "libtype": "pypi",
  "libname": "torch-model-archiver",
  "url": "https://github.com/pytorch/serve/blob/master/model-archiver",
  "html": "{\"payload\":{\"allShortcutsEnabled\":false,\"path\":\"model-archiver\",\"repo\":{\"id\":212488700,\"defaultBranch\":\"master\",\"name\":\"serve\",\"ownerLogin\":\"pytorch\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2019-10-03T03:17:43.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/21003710?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":true},\"currentUser\":null,\"refInfo\":{\"name\":\"master\",\"listCacheKey\":\"v0:1709672705.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"1ff1b3b87da8cfe36e238088234c72f7413f7f9e\"},\"tree\":{\"items\":[{\"name\":\"model_archiver\",\"path\":\"model-archiver/model_archiver\",\"contentType\":\"directory\"},{\"name\":\".coveragerc\",\"path\":\"model-archiver/.coveragerc\",\"contentType\":\"file\"},{\"name\":\"LICENSE\",\"path\":\"model-archiver/LICENSE\",\"contentType\":\"file\"},{\"name\":\"MANIFEST.in\",\"path\":\"model-archiver/MANIFEST.in\",\"contentType\":\"file\"},{\"name\":\"PyPiDescription.rst\",\"path\":\"model-archiver/PyPiDescription.rst\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"model-archiver/README.md\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"model-archiver/setup.py\",\"contentType\":\"file\"}],\"templateDirectorySuggestionUrl\":null,\"readme\":{\"displayName\":\"README.md\",\"richText\":\"<article class=\\\"markdown-body entry-content container-lg\\\" itemprop=\\\"text\\\"><div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h1 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Torch Model archiver for TorchServe</h1><a id=\\\"user-content-torch-model-archiver-for-torchserve\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Torch Model archiver for TorchServe\\\" href=\\\"#torch-model-archiver-for-torchserve\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Contents of this Document</h2><a id=\\\"user-content-contents-of-this-document\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Contents of this Document\\\" href=\\\"#contents-of-this-document\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<ul dir=\\\"auto\\\">\\n<li><a href=\\\"#overview\\\">Overview</a></li>\\n<li><a href=\\\"#installation\\\">Installation</a></li>\\n<li><a href=\\\"#torch-model-archiver-command-line-interface\\\">Torch Model Archiver CLI</a></li>\\n<li><a href=\\\"#artifact-details\\\">Artifact Details</a>\\n<ul dir=\\\"auto\\\">\\n<li><a href=\\\"#mar-inf\\\">MAR-INFO</a></li>\\n<li><a href=\\\"#model-name\\\">Model name</a></li>\\n<li><a href=\\\"#model-file\\\">Model File</a></li>\\n<li><a href=\\\"#serialized-file\\\">Serialized File</a></li>\\n<li><a href=\\\"#handler\\\">handler</a></li>\\n</ul>\\n</li>\\n<li><a href=\\\"#creating-a-model-archive\\\">Quick Start: Creating a Model Archive</a></li>\\n<li><a href=\\\"#model-specific-custom-python-requirements\\\">Model specific custom python requirements</a></li>\\n</ul>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Overview</h2><a id=\\\"user-content-overview\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Overview\\\" href=\\\"#overview\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">A key feature of TorchServe is the ability to package all model artifacts into a single model archive file. It is a separate command line interface (CLI), <code>torch-model-archiver</code>, that can take model checkpoints or model definition file with state_dict, and package them into a <code>.mar</code> file. This file can then be redistributed and served by anyone using TorchServe. It takes in the following model artifacts: a model checkpoint file in case of torchscript or a model definition file and a state_dict file in case of eager mode, and other optional assets that may be required to serve the model. The CLI creates a <code>.mar</code> file that TorchServe's server CLI uses to serve the models.</p>\\n<p dir=\\\"auto\\\"><strong>Important</strong>: Make sure you try the <a href=\\\"#creating-a-model-archive\\\">Quick Start: Creating a Model Archive</a> tutorial for a short example of using <code>torch-model-archiver</code>.</p>\\n<p dir=\\\"auto\\\">The following information is required to create a standalone model archive:</p>\\n<ol dir=\\\"auto\\\">\\n<li><a href=\\\"#model-name\\\">Model name</a></li>\\n<li><a href=\\\"#model-file\\\">Model file</a></li>\\n<li><a href=\\\"#serialized-file\\\">Serialized file</a></li>\\n</ol>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Installation</h2><a id=\\\"user-content-installation\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Installation\\\" href=\\\"#installation\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">Install torch-model-archiver as follows:</p>\\n<div class=\\\"highlight highlight-source-shell notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"pip install torch-model-archiver\\\"><pre>pip install torch-model-archiver</pre></div>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Installation from source</h2><a id=\\\"user-content-installation-from-source\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Installation from source\\\" href=\\\"#installation-from-source\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">Install torch-model-archiver as follows:</p>\\n<div class=\\\"highlight highlight-source-shell notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"git clone https://github.com/pytorch/serve.git\\ncd serve/model-archiver\\npip install .\\\"><pre>git clone https://github.com/pytorch/serve.git\\n<span class=\\\"pl-c1\\\">cd</span> serve/model-archiver\\npip install <span class=\\\"pl-c1\\\">.</span></pre></div>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Torch Model Archiver Command Line Interface</h2><a id=\\\"user-content-torch-model-archiver-command-line-interface\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Torch Model Archiver Command Line Interface\\\" href=\\\"#torch-model-archiver-command-line-interface\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">Now let's cover the details on using the CLI tool: <code>model-archiver</code>.</p>\\n<p dir=\\\"auto\\\">Here is an example usage with the densenet161 model archive following the example in the <a href=\\\"/pytorch/serve/blob/master/examples/README.md\\\">examples README</a>:</p>\\n<div class=\\\"highlight highlight-source-shell notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"torch-model-archiver --model-name densenet161 --version 1.0 --model-file examples/image_classifier/densenet_161/model.py --serialized-file densenet161-8d451a50.pth --extra-files examples/image_classifier/index_to_name.json --handler image_classifier\\\"><pre>torch-model-archiver --model-name densenet161 --version 1.0 --model-file examples/image_classifier/densenet_161/model.py --serialized-file densenet161-8d451a50.pth --extra-files examples/image_classifier/index_to_name.json --handler image_classifier</pre></div>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Arguments</h3><a id=\\\"user-content-arguments\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Arguments\\\" href=\\\"#arguments\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<div class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"$ torch-model-archiver -h\\nusage: torch-model-archiver [-h] --model-name MODEL_NAME  --version MODEL_VERSION_NUMBER\\n                      --model-file MODEL_FILE_PATH --serialized-file MODEL_SERIALIZED_PATH\\n                      --handler HANDLER [--runtime {python,python3}]\\n                      [--export-path EXPORT_PATH] [-f] [--requirements-file] [--config-file]\\n\\nModel Archiver Tool\\n\\noptional arguments:\\n  -h, --help            show this help message and exit\\n  --model-name MODEL_NAME\\n                        Exported model name. Exported file will be named as\\n                        model-name.mar and saved in current working directory\\n                        if no --export-path is specified, else it will be\\n                        saved under the export path\\n  --serialized-file SERIALIZED_FILE\\n                        Path to .pt or .pth file containing state_dict in\\n                        case of eager mode or an executable ScriptModule\\n                        in case of TorchScript.\\n  --model-file MODEL_FILE\\n                        Path to python file containing model architecture.\\n                        This parameter is mandatory for eager mode models.\\n                        The model architecture file must contain only one\\n                        class definition extended from torch.nn.Module.\\n  --handler HANDLER     TorchServe's default handler name  or handler python\\n                        file path to handle custom TorchServe inference logic.\\n  --extra-files EXTRA_FILES\\n                        Comma separated path to extra dependency files.\\n  --runtime {python,python3}\\n                        The runtime specifies which language to run your\\n                        inference code on. The default runtime is\\n                        RuntimeType.PYTHON. At the present moment we support\\n                        the following runtimes python, python3\\n  --export-path EXPORT_PATH\\n                        Path where the exported .mar file will be saved. This\\n                        is an optional parameter. If --export-path is not\\n                        specified, the file will be saved in the current\\n                        working directory.\\n  --archive-format {tgz, no-archive, zip-store, default}\\n                        The format in which the model artifacts are archived.\\n                        &quot;tgz&quot;: This creates the model-archive in &lt;model-name&gt;.tar.gz format.\\n                        If platform hosting requires model-artifacts to be in &quot;.tar.gz&quot;\\n                        use this option.\\n                        &quot;no-archive&quot;: This option creates an non-archived version of model artifacts\\n                        at &quot;export-path/{model-name}&quot; location. As a result of this choice,\\n                        MANIFEST file will be created at &quot;export-path/{model-name}&quot; location\\n                        without archiving these model files\\n                        &quot;zip-store&quot;: This creates the model-archive in &lt;model-name&gt;.mar format\\n                        but will skip deflating the files to speed up creation. Mainly used\\n                        for testing purposes\\n                        &quot;default&quot;: This creates the model-archive in &lt;model-name&gt;.mar format.\\n                        This is the default archiving format. Models archived in this format\\n                        will be readily hostable on TorchServe.\\n  -f, --force           When the -f or --force flag is specified, an existing\\n                        .mar file with same name as that provided in --model-\\n                        name in the path specified by --export-path will\\n                        overwritten\\n  -v, --version         Model's version.\\n  -r, --requirements-file\\n                        Path to requirements.txt file containing a list of model specific python\\n                        packages to be installed by TorchServe for seamless model serving.\\n  -c, --config-file         Path to a model config yaml file.\\\"><pre class=\\\"notranslate\\\"><code>$ torch-model-archiver -h\\nusage: torch-model-archiver [-h] --model-name MODEL_NAME  --version MODEL_VERSION_NUMBER\\n                      --model-file MODEL_FILE_PATH --serialized-file MODEL_SERIALIZED_PATH\\n                      --handler HANDLER [--runtime {python,python3}]\\n                      [--export-path EXPORT_PATH] [-f] [--requirements-file] [--config-file]\\n\\nModel Archiver Tool\\n\\noptional arguments:\\n  -h, --help            show this help message and exit\\n  --model-name MODEL_NAME\\n                        Exported model name. Exported file will be named as\\n                        model-name.mar and saved in current working directory\\n                        if no --export-path is specified, else it will be\\n                        saved under the export path\\n  --serialized-file SERIALIZED_FILE\\n                        Path to .pt or .pth file containing state_dict in\\n                        case of eager mode or an executable ScriptModule\\n                        in case of TorchScript.\\n  --model-file MODEL_FILE\\n                        Path to python file containing model architecture.\\n                        This parameter is mandatory for eager mode models.\\n                        The model architecture file must contain only one\\n                        class definition extended from torch.nn.Module.\\n  --handler HANDLER     TorchServe's default handler name  or handler python\\n                        file path to handle custom TorchServe inference logic.\\n  --extra-files EXTRA_FILES\\n                        Comma separated path to extra dependency files.\\n  --runtime {python,python3}\\n                        The runtime specifies which language to run your\\n                        inference code on. The default runtime is\\n                        RuntimeType.PYTHON. At the present moment we support\\n                        the following runtimes python, python3\\n  --export-path EXPORT_PATH\\n                        Path where the exported .mar file will be saved. This\\n                        is an optional parameter. If --export-path is not\\n                        specified, the file will be saved in the current\\n                        working directory.\\n  --archive-format {tgz, no-archive, zip-store, default}\\n                        The format in which the model artifacts are archived.\\n                        \\\"tgz\\\": This creates the model-archive in &lt;model-name&gt;.tar.gz format.\\n                        If platform hosting requires model-artifacts to be in \\\".tar.gz\\\"\\n                        use this option.\\n                        \\\"no-archive\\\": This option creates an non-archived version of model artifacts\\n                        at \\\"export-path/{model-name}\\\" location. As a result of this choice,\\n                        MANIFEST file will be created at \\\"export-path/{model-name}\\\" location\\n                        without archiving these model files\\n                        \\\"zip-store\\\": This creates the model-archive in &lt;model-name&gt;.mar format\\n                        but will skip deflating the files to speed up creation. Mainly used\\n                        for testing purposes\\n                        \\\"default\\\": This creates the model-archive in &lt;model-name&gt;.mar format.\\n                        This is the default archiving format. Models archived in this format\\n                        will be readily hostable on TorchServe.\\n  -f, --force           When the -f or --force flag is specified, an existing\\n                        .mar file with same name as that provided in --model-\\n                        name in the path specified by --export-path will\\n                        overwritten\\n  -v, --version         Model's version.\\n  -r, --requirements-file\\n                        Path to requirements.txt file containing a list of model specific python\\n                        packages to be installed by TorchServe for seamless model serving.\\n  -c, --config-file         Path to a model config yaml file.\\n</code></pre></div>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Artifact Details</h2><a id=\\\"user-content-artifact-details\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Artifact Details\\\" href=\\\"#artifact-details\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">MAR-INF</h3><a id=\\\"user-content-mar-inf\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: MAR-INF\\\" href=\\\"#mar-inf\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\"><strong>MAR-INF</strong> is a reserved folder name that will be used inside <code>.mar</code> file. This folder contains the model archive metadata files. Users should avoid using <strong>MAR-INF</strong> in their model path.</p>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Runtime</h3><a id=\\\"user-content-runtime\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Runtime\\\" href=\\\"#runtime\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Model name</h3><a id=\\\"user-content-model-name\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Model name\\\" href=\\\"#model-name\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">A valid model name must begin with a letter of the alphabet and can only contains letters, digits, underscores <code>_</code>, dashes <code>-</code> and periods <code>.</code>.</p>\\n<p dir=\\\"auto\\\"><strong>Note</strong>: The model name can be overridden when you register the model with <a href=\\\"/pytorch/serve/blob/master/docs/management_api.md#register-a-model\\\">Register Model API</a>.</p>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Model file</h3><a id=\\\"user-content-model-file\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Model file\\\" href=\\\"#model-file\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">A model file should contain the model architecture. This file is mandatory in case of eager mode models.</p>\\n<p dir=\\\"auto\\\">This file should contain a single class that inherits from\\n<a href=\\\"https://pytorch.org/docs/stable/generated/torch.nn.Module.html\\\" rel=\\\"nofollow\\\">torch.nn.Module</a>.</p>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Serialized file</h3><a id=\\\"user-content-serialized-file\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Serialized file\\\" href=\\\"#serialized-file\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">A serialized file (.pt or .pth) should be a checkpoint in case of torchscript and state_dict in case of eager mode.</p>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Handler</h3><a id=\\\"user-content-handler\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Handler\\\" href=\\\"#handler\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">Handler can be TorchServe's inbuilt handler name or path to a py file to handle custom TorchServe inference logic. TorchServe supports the following handlers out of box:</p>\\n<ol dir=\\\"auto\\\">\\n<li><code>image_classifier</code></li>\\n<li><code>object_detector</code></li>\\n<li><code>text_classifier</code></li>\\n<li><code>image_segmenter</code></li>\\n</ol>\\n<p dir=\\\"auto\\\">For a more comprehensive list of built in handlers, make sure to checkout the <a href=\\\"/pytorch/serve/blob/master/docs/default_handlers.md\\\">examples</a></p>\\n<p dir=\\\"auto\\\">In case of custom handler, if you plan to provide just <code>module_name</code> or <code>module_name:entry_point_function_name</code> then make sure that it is prefixed with absolute or relative path of python file.\\ne.g. if your custom handler custom_image_classifier.py is in /home/serve/examples then\\n<code>--handler /home/serve/examples/custom_image_classifier</code> or if it has my_entry_point module level function then <code>--handler /home/serve/examples/custom_image_classifier:my_entry_point_func</code></p>\\n<p dir=\\\"auto\\\">For more details refer <a href=\\\"/pytorch/serve/blob/master/docs/default_handlers.md\\\">default handler documentation</a> or <a href=\\\"/pytorch/serve/blob/master/docs/custom_service.md\\\">custom handler documentation</a></p>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Config file</h3><a id=\\\"user-content-config-file\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Config file\\\" href=\\\"#config-file\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">A model config yaml file. For example:</p>\\n<div class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"# TS frontend parameters\\n# See all supported parameters: https://github.com/pytorch/serve/blob/master/frontend/archive/src/main/java/org/pytorch/serve/archive/model/ModelConfig.java#L14\\nminWorkers: 1 # default: #CPU or #GPU\\nmaxWorkers: 1 # default: #CPU or #GPU\\nbatchSize: 1 # default: 1\\nmaxBatchDelay: 100 # default: 100 msec\\nresponseTimeout: 120 # default: 120 sec\\ndeviceType: cpu # cpu, gpu, neuron\\ndeviceIds: [0,1,2,3] # gpu device ids allocated to this model.\\nparallelType: pp # pp: pipeline parallel; pptp: tensor+pipeline parallel. Default: empty\\nuseVenv: Create python virtual environment when using python backend to install model dependencies\\n         (if enabled globally using install_py_dep_per_model=true) and run workers for model loading\\n         and inference. Note that, although creation of virtual environment adds a latency overhead\\n         (approx. 2 to 3 seconds) during model load and disk space overhead (approx. 25M), overall\\n         it can speed up load time and reduce disk utilization for models with custom dependencies\\n         since it enables reusing custom packages(specified in requirements.txt) and their\\n         supported dependencies that are already available in the base python environment.\\n\\n# See torchrun parameters: https://pytorch.org/docs/stable/elastic/run.html\\ntorchrun:\\n  nproc-per-node: 2\\n\\n# TS backend parameters\\npippy:\\n  rpc_timeout: 1800\\n  pp_group_size: 4 # pipeline parallel size, tp_group_size = world size / pp_group_size\\\"><pre class=\\\"notranslate\\\"><code># TS frontend parameters\\n# See all supported parameters: https://github.com/pytorch/serve/blob/master/frontend/archive/src/main/java/org/pytorch/serve/archive/model/ModelConfig.java#L14\\nminWorkers: 1 # default: #CPU or #GPU\\nmaxWorkers: 1 # default: #CPU or #GPU\\nbatchSize: 1 # default: 1\\nmaxBatchDelay: 100 # default: 100 msec\\nresponseTimeout: 120 # default: 120 sec\\ndeviceType: cpu # cpu, gpu, neuron\\ndeviceIds: [0,1,2,3] # gpu device ids allocated to this model.\\nparallelType: pp # pp: pipeline parallel; pptp: tensor+pipeline parallel. Default: empty\\nuseVenv: Create python virtual environment when using python backend to install model dependencies\\n         (if enabled globally using install_py_dep_per_model=true) and run workers for model loading\\n         and inference. Note that, although creation of virtual environment adds a latency overhead\\n         (approx. 2 to 3 seconds) during model load and disk space overhead (approx. 25M), overall\\n         it can speed up load time and reduce disk utilization for models with custom dependencies\\n         since it enables reusing custom packages(specified in requirements.txt) and their\\n         supported dependencies that are already available in the base python environment.\\n\\n# See torchrun parameters: https://pytorch.org/docs/stable/elastic/run.html\\ntorchrun:\\n  nproc-per-node: 2\\n\\n# TS backend parameters\\npippy:\\n  rpc_timeout: 1800\\n  pp_group_size: 4 # pipeline parallel size, tp_group_size = world size / pp_group_size\\n</code></pre></div>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Creating a Model Archive</h2><a id=\\\"user-content-creating-a-model-archive\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Creating a Model Archive\\\" href=\\\"#creating-a-model-archive\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\"><strong>1. Download the torch model archiver source</strong></p>\\n<div class=\\\"highlight highlight-source-shell notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"git clone https://github.com/pytorch/serve.git\\\"><pre>git clone https://github.com/pytorch/serve.git</pre></div>\\n<p dir=\\\"auto\\\"><strong>2. Package your model</strong></p>\\n<p dir=\\\"auto\\\">With the model artifacts available locally, you can use the <code>torch-model-archiver</code> CLI to generate a <code>.mar</code> file that can be used to serve an inference API with TorchServe.</p>\\n<p dir=\\\"auto\\\">In this next step we'll run <code>torch-model-archiver</code> and tell it our model's name is <code>densenet_161</code> and its version is <code>1.0</code> with the <code>model-name</code> and <code>version</code> parameter respectively and that it will use TorchServe's default <code>image_classifier</code> handler with the <code>handler</code> argument . Then we're giving it the <code>model-file</code> and <code>serialized-file</code> to the model's assets.</p>\\n<p dir=\\\"auto\\\">For torchscript:</p>\\n<div class=\\\"highlight highlight-source-shell notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"torch-model-archiver --model-name densenet_161 --version 1.0 --serialized-file model.pt --handler image_classifier\\\"><pre>torch-model-archiver --model-name densenet_161 --version 1.0 --serialized-file model.pt --handler image_classifier</pre></div>\\n<p dir=\\\"auto\\\">For eagermode:</p>\\n<div class=\\\"highlight highlight-source-shell notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"torch-model-archiver --model-name densenet_161 --version 1.0 --model-file model.py --serialized-file model.pt --handler image_classifier\\\"><pre>torch-model-archiver --model-name densenet_161 --version 1.0 --model-file model.py --serialized-file model.pt --handler image_classifier</pre></div>\\n<p dir=\\\"auto\\\">This will package all the model artifacts files and output <code>densenet_161.mar</code> in the current working directory. This <code>.mar</code> file is all you need to run TorchServe, serving inference requests for a simple image recognition API. Go back to the <a href=\\\"/pytorch/serve/blob/master/README.md#serve-a-model\\\">Serve a Model tutorial</a> and try to run this model archive that you just created!</p>\\n<div class=\\\"markdown-heading\\\" dir=\\\"auto\\\"><h3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\">Model specific custom python requirements</h3><a id=\\\"user-content-model-specific-custom-python-requirements\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Model specific custom python requirements\\\" href=\\\"#model-specific-custom-python-requirements\\\"><svg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"><path d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"></path></svg></a></div>\\n<p dir=\\\"auto\\\">Custom models/handlers may depend on different python packages which are not installed by-default as a part of <code>TorchServe</code> setup.\\nSupply a <a href=\\\"https://pip.pypa.io/en/stable/user_guide/#requirements-files\\\" rel=\\\"nofollow\\\">python requirements</a> file containing the list of required python packages to be installed by <code>TorchServe</code> for seamless model serving using <code>--requirements-file</code> parameter while creating the model-archiver.</p>\\n<p dir=\\\"auto\\\">Example:</p>\\n<div class=\\\"highlight highlight-source-shell notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"torch-model-archiver --model-name densenet_161 --version 1.0 --model-file model.py --serialized-file model.pt --handler image_classifier --requirements-file &lt;path_to_custom_requirements_file&gt;\\\"><pre>torch-model-archiver --model-name densenet_161 --version 1.0 --model-file model.py --serialized-file model.pt --handler image_classifier --requirements-file <span class=\\\"pl-k\\\">&lt;</span>path_to_custom_requirements_file<span class=\\\"pl-k\\\">&gt;</span></pre></div>\\n<p dir=\\\"auto\\\"><strong>Note</strong>: This feature is by-default disabled in TorchServe and needs to be enabled through configuration. For more details refer <a href=\\\"/pytorch/serve/blob/master/docs/configuration.md#allow-model-specific-custom-python-packages\\\">TorchServe's configuration documentation</a></p>\\n</article>\",\"errorMessage\":null,\"headerInfo\":{\"toc\":[{\"level\":1,\"text\":\"Torch Model archiver for TorchServe\",\"anchor\":\"torch-model-archiver-for-torchserve\",\"htmlText\":\"Torch Model archiver for TorchServe\"},{\"level\":2,\"text\":\"Contents of this Document\",\"anchor\":\"contents-of-this-document\",\"htmlText\":\"Contents of this Document\"},{\"level\":2,\"text\":\"Overview\",\"anchor\":\"overview\",\"htmlText\":\"Overview\"},{\"level\":2,\"text\":\"Installation\",\"anchor\":\"installation\",\"htmlText\":\"Installation\"},{\"level\":2,\"text\":\"Installation from source\",\"anchor\":\"installation-from-source\",\"htmlText\":\"Installation from source\"},{\"level\":2,\"text\":\"Torch Model Archiver Command Line Interface\",\"anchor\":\"torch-model-archiver-command-line-interface\",\"htmlText\":\"Torch Model Archiver Command Line Interface\"},{\"level\":3,\"text\":\"Arguments\",\"anchor\":\"arguments\",\"htmlText\":\"Arguments\"},{\"level\":2,\"text\":\"Artifact Details\",\"anchor\":\"artifact-details\",\"htmlText\":\"Artifact Details\"},{\"level\":3,\"text\":\"MAR-INF\",\"anchor\":\"mar-inf\",\"htmlText\":\"MAR-INF\"},{\"level\":3,\"text\":\"Runtime\",\"anchor\":\"runtime\",\"htmlText\":\"Runtime\"},{\"level\":3,\"text\":\"Model name\",\"anchor\":\"model-name\",\"htmlText\":\"Model name\"},{\"level\":3,\"text\":\"Model file\",\"anchor\":\"model-file\",\"htmlText\":\"Model file\"},{\"level\":3,\"text\":\"Serialized file\",\"anchor\":\"serialized-file\",\"htmlText\":\"Serialized file\"},{\"level\":3,\"text\":\"Handler\",\"anchor\":\"handler\",\"htmlText\":\"Handler\"},{\"level\":3,\"text\":\"Config file\",\"anchor\":\"config-file\",\"htmlText\":\"Config file\"},{\"level\":2,\"text\":\"Creating a Model Archive\",\"anchor\":\"creating-a-model-archive\",\"htmlText\":\"Creating a Model Archive\"},{\"level\":3,\"text\":\"Model specific custom python requirements\",\"anchor\":\"model-specific-custom-python-requirements\",\"htmlText\":\"Model specific custom python requirements\"}],\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fpytorch%2Fserve%2Ftree%2Fmaster%2Fmodel-archiver\"}},\"totalCount\":7,\"showBranchInfobar\":false},\"fileTree\":{\"\":{\"items\":[{\"name\":\".github\",\"path\":\".github\",\"contentType\":\"directory\"},{\"name\":\"benchmarks\",\"path\":\"benchmarks\",\"contentType\":\"directory\"},{\"name\":\"binaries\",\"path\":\"binaries\",\"contentType\":\"directory\"},{\"name\":\"ci\",\"path\":\"ci\",\"contentType\":\"directory\"},{\"name\":\"cpp\",\"path\":\"cpp\",\"contentType\":\"directory\"},{\"name\":\"docker\",\"path\":\"docker\",\"contentType\":\"directory\"},{\"name\":\"docs\",\"path\":\"docs\",\"contentType\":\"directory\"},{\"name\":\"examples\",\"path\":\"examples\",\"contentType\":\"directory\"},{\"name\":\"frontend\",\"path\":\"frontend\",\"contentType\":\"directory\"},{\"name\":\"kubernetes\",\"path\":\"kubernetes\",\"contentType\":\"directory\"},{\"name\":\"model-archiver\",\"path\":\"model-archiver\",\"contentType\":\"directory\"},{\"name\":\"plugins\",\"path\":\"plugins\",\"contentType\":\"directory\"},{\"name\":\"requirements\",\"path\":\"requirements\",\"contentType\":\"directory\"},{\"name\":\"serving-sdk\",\"path\":\"serving-sdk\",\"contentType\":\"directory\"},{\"name\":\"test\",\"path\":\"test\",\"contentType\":\"directory\"},{\"name\":\"third_party\",\"path\":\"third_party\",\"contentType\":\"directory\"},{\"name\":\"ts\",\"path\":\"ts\",\"contentType\":\"directory\"},{\"name\":\"ts_scripts\",\"path\":\"ts_scripts\",\"contentType\":\"directory\"},{\"name\":\"workflow-archiver\",\"path\":\"workflow-archiver\",\"contentType\":\"directory\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\".gitmodules\",\"path\":\".gitmodules\",\"contentType\":\"file\"},{\"name\":\".pre-commit-config.yaml\",\"path\":\".pre-commit-config.yaml\",\"contentType\":\"file\"},{\"name\":\"CODE_OF_CONDUCT.md\",\"path\":\"CODE_OF_CONDUCT.md\",\"contentType\":\"file\"},{\"name\":\"CONTRIBUTING.md\",\"path\":\"CONTRIBUTING.md\",\"contentType\":\"file\"},{\"name\":\"LICENSE\",\"path\":\"LICENSE\",\"contentType\":\"file\"},{\"name\":\"MANIFEST.in\",\"path\":\"MANIFEST.in\",\"contentType\":\"file\"},{\"name\":\"PyPiDescription.rst\",\"path\":\"PyPiDescription.rst\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"SECURITY.md\",\"path\":\"SECURITY.md\",\"contentType\":\"file\"},{\"name\":\"_config.yml\",\"path\":\"_config.yml\",\"contentType\":\"file\"},{\"name\":\"codecov.yml\",\"path\":\"codecov.yml\",\"contentType\":\"file\"},{\"name\":\"link_check_config.json\",\"path\":\"link_check_config.json\",\"contentType\":\"file\"},{\"name\":\"mypy.ini\",\"path\":\"mypy.ini\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"},{\"name\":\"torchserve_sanity.py\",\"path\":\"torchserve_sanity.py\",\"contentType\":\"file\"}],\"totalCount\":35}},\"fileTreeProcessingTime\":5.430751,\"foldersToFetch\":[],\"treeExpanded\":true,\"symbolsExpanded\":false,\"csrf_tokens\":{\"/pytorch/serve/branches\":{\"post\":\"SGzNbs7nmntCUV9p_xtw2HInFaVjr88Hr7F0xWLHZWaDqg5qpWL2GKWeDwDuHeby4mx02hDs4fdantpMpBFlfA\"},\"/pytorch/serve/branches/fetch_and_merge/master\":{\"post\":\"zIVkF-N-qzjXeLBR_NSQNsyzr-QexvbCQC0TW3St1l9GYe_VvT-dMaqJ2dMUFtn-5Os3blhYQW4_sNU57523rw\"},\"/pytorch/serve/branches/fetch_and_merge/master?discard_changes=true\":{\"post\":\"0dtv6nS7zUX8G65CiyTVKsUFxig3muVN9_a51f-Qud9bP-QoKvr7TIHqx8Bj5pzi7V1eonEEUuGIa3-3ZKDYLw\"}}},\"title\":\"serve/model-archiver at master \u00b7 pytorch/serve\"}",
  "embeddings": []
}