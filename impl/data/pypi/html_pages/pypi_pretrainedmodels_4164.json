{
  "libtype": "pypi",
  "libname": "pretrainedmodels",
  "url": "https://github.com/cadene/pretrained-models.pytorch",
  "html": "<!DOCTYPE html><html  lang=\"en\"    data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-theme=\"dark\"  data-a11y-animated-images=\"system\" data-a11y-link-underlines=\"true\"  >  <head>    <meta charset=\"utf-8\">  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">  <link rel=\"preconnect\" href=\"https://github.githubassets.com\" crossorigin>  <link rel=\"preconnect\" href=\"https://avatars.githubusercontent.com\">    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/light-0eace2597ca3.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/dark-a167e256da9c.css\" /><link data-color-theme=\"dark_dimmed\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_dimmed-d11f2cf8009b.css\" /><link data-color-theme=\"dark_high_contrast\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_high_contrast-ea7373db06c8.css\" /><link data-color-theme=\"dark_colorblind\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_colorblind-afa99dcf40f7.css\" /><link data-color-theme=\"light_colorblind\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_colorblind-af6c685139ba.css\" /><link data-color-theme=\"light_high_contrast\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_high_contrast-578cdbc8a5a9.css\" /><link data-color-theme=\"light_tritanopia\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_tritanopia-5cb699a7e247.css\" /><link data-color-theme=\"dark_tritanopia\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_tritanopia-9b32204967c6.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/primer-primitives-2ef2a46b27ee.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/primer-711f412bb361.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/global-4803cd254267.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/github-f4d857cbc96a.css\" />  <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/repository-6247ca238fd4.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/code-6d7b4ef0ea51.css\" />    <script type=\"application/json\" id=\"client-env\">{\"locale\":\"en\",\"featureFlags\":[\"code_vulnerability_scanning\",\"copilot_conversational_ux_history_refs\",\"copilot_chat_attach_knowledge\",\"copilot_chat_knowledge_base_copy\",\"copilot_smell_icebreaker_ux\",\"copilot_implicit_context\",\"docset_management_ui\",\"copilot_chat_settings\",\"failbot_handle_non_errors\",\"geojson_azure_maps\",\"image_metric_tracking\",\"marketing_forms_api_integration_contact_request\",\"marketing_pages_search_explore_provider\",\"turbo_experiment_risky\",\"sample_network_conn_type\",\"no_character_key_shortcuts_in_inputs\",\"report_hydro_web_vitals\",\"custom_inp\",\"remove_child_patch\"]}</script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/wp-runtime-47578fb192fd.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_dompurify_dist_purify_js-6890e890956f.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_stacktrace-parser_dist_stack-trace-parser_esm_js-node_modules_github_bro-a4c183-79f9611c275b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_hydro-analytics-client_dist_analytics-client_js-node_modules_gith-6a10dd-e66ebda625fb.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_failbot_failbot_ts-479802999bcc.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/environment-fe7570f3bc38.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_selector-observer_dist_index_esm_js-9f960d9b217c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_focus-zone_js-086f7a27bac0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_relative-time-element_dist_index_js-c76945c5961a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_details-dialog-elemen-29dc30-a2a71f11a507.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_auto-complete-element_dist_index_js-12366198e7a5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_text-expander-element_dist_index_js-8a621df59e80.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-b7d8f4-654130b7cde5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_primer_view-co-5dccdf-e5e2b9fa3c0c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/github-elements-e4eda4896b4e.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/element-registry-b99c9d8fad1d.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_catalyst_lib_index_js-node_modules_github_hydro-analytics-client_-978abc0-add939c751ce.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_lit-html_lit-html_js-5b376145beff.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_alive-client_dist-bf5aa2-1b562c29ab8e.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_morphdom_dist_morphdom-esm_js-5bff297a06de.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_turbo_dist_turbo_es2017-esm_js-c91f4ad18b62.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_color-convert_index_js-72c9fbde5ad4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_scroll-anchoring_dist_scro-231ccf-aa129238d13b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_dimensions_js-node_modules_github_jtml_lib_index_js-95b84ee6bc34.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_session-resume_dist_index_js-node_modules_primer_behaviors_dist_e-da6ec6-3f39339c9d98.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_paste-markdown_dist_index_esm_js-node_modules_github_quote-select-67e0dc-1aa35af077a4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_updatable-content_ts-ee3fc84d7fb0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_task-list_ts-app_assets_modules_github_onfocus_ts-app_ass-421cec-9de4213015af.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_sticky-scroll-into-view_ts-94209c43e6af.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_ajax-error_ts-app_assets_modules_github_behaviors_include-467754-f9bd433e9591.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_commenting_edit_ts-app_assets_modules_github_behaviors_ht-83c235-9285faa0e011.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_blob-anchor_ts-app_assets_modules_github_filter-sort_ts-app_assets_-c96432-da3733f430b8.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/behaviors-1fb9e5061509.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_catalyst_lib_index_js-d0256ebff5cd.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/notifications-global-352d84c6cc82.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_virtualized-list_es_index_js-node_modules_github_template-parts_lib_index_js-878844713bc9.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-c537341-c7f6a41a084c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_ref-selector_ts-b593b93f23f5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/codespaces-1a8626dd714a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_mini-throt-08ab15-3e0517baca99.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_github_mini-th-55cf52-e14cb4b719b4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/repositories-69068e0899f9.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/code-menu-614feb194539.js\"></script>    <title>GitHub - Cadene/pretrained-models.pytorch: Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc.</title>  <meta name=\"route-pattern\" content=\"/:user_id/:repository\" data-turbo-transient>  <meta name=\"route-controller\" content=\"files\" data-turbo-transient>  <meta name=\"route-action\" content=\"disambiguate\" data-turbo-transient>      <meta name=\"current-catalog-service-hash\" content=\"82c569b93da5c18ed649ebd4c2c79437db4611a6a1373e805a3cb001c64130b7\">  <meta name=\"request-id\" content=\"ED1D:51C1:8EC15:CC398:65E7817A\" data-pjax-transient=\"true\"/><meta name=\"html-safe-nonce\" content=\"a125e6effee94f5d9b7bfc68b866c18464447fb60d96b58ba0f92ba0c42cd47f\" data-pjax-transient=\"true\"/><meta name=\"visitor-payload\" content=\"eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJFRDFEOjUxQzE6OEVDMTU6Q0MzOTg6NjVFNzgxN0EiLCJ2aXNpdG9yX2lkIjoiNjQ4NTk4MjY2NDA0NzY5MDEwNiIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9\" data-pjax-transient=\"true\"/><meta name=\"visitor-hmac\" content=\"694b11478171453d5a5e524f8d3b0d1c0f904ad6848fbbd413fbf5359b736fa3\" data-pjax-transient=\"true\"/>    <meta name=\"hovercard-subject-tag\" content=\"repository:87720287\" data-turbo-transient>  <meta name=\"github-keyboard-shortcuts\" content=\"repository,copilot\" data-turbo-transient=\"true\" />    <meta name=\"selected-link\" value=\"repo_source\" data-turbo-transient>  <link rel=\"assets\" href=\"https://github.githubassets.com/\">    <meta name=\"google-site-verification\" content=\"c1kuD-K2HIVF635lypcsWPoD4kilo5-jA_wBFyT4uMY\">  <meta name=\"google-site-verification\" content=\"KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU\">  <meta name=\"google-site-verification\" content=\"ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA\">  <meta name=\"google-site-verification\" content=\"GXs5KoUUkNCoaAZn7wPN-t01Pywp9M3sEjnt_3_ZWPc\">  <meta name=\"google-site-verification\" content=\"Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I\"><meta name=\"octolytics-url\" content=\"https://collector.github.com/github/collect\" />  <meta name=\"analytics-location\" content=\"/&lt;user-name&gt;/&lt;repo-name&gt;\" data-turbo-transient=\"true\" />        <meta name=\"user-login\" content=\"\">      <meta name=\"viewport\" content=\"width=device-width\">          <meta name=\"description\" content=\"Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc. - Cadene/pretrained-models.pytorch\">      <link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/opensearch.xml\" title=\"GitHub\">    <link rel=\"fluid-icon\" href=\"https://github.com/fluidicon.png\" title=\"GitHub\">    <meta property=\"fb:app_id\" content=\"1401488693436528\">    <meta name=\"apple-itunes-app\" content=\"app-id=1477376905, app-argument=https://github.com/cadene/pretrained-models.pytorch\" />      <meta name=\"twitter:image:src\" content=\"https://opengraph.githubassets.com/16f625ca94f732036abdd911cb29cc0777cb6b417f8dce1b20c917f8040db2cc/Cadene/pretrained-models.pytorch\" /><meta name=\"twitter:site\" content=\"@github\" /><meta name=\"twitter:card\" content=\"summary_large_image\" /><meta name=\"twitter:title\" content=\"GitHub - Cadene/pretrained-models.pytorch: Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc.\" /><meta name=\"twitter:description\" content=\"Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc. - Cadene/pretrained-models.pytorch\" />      <meta property=\"og:image\" content=\"https://opengraph.githubassets.com/16f625ca94f732036abdd911cb29cc0777cb6b417f8dce1b20c917f8040db2cc/Cadene/pretrained-models.pytorch\" /><meta property=\"og:image:alt\" content=\"Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc. - Cadene/pretrained-models.pytorch\" /><meta property=\"og:image:width\" content=\"1200\" /><meta property=\"og:image:height\" content=\"600\" /><meta property=\"og:site_name\" content=\"GitHub\" /><meta property=\"og:type\" content=\"object\" /><meta property=\"og:title\" content=\"GitHub - Cadene/pretrained-models.pytorch: Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc.\" /><meta property=\"og:url\" content=\"https://github.com/Cadene/pretrained-models.pytorch\" /><meta property=\"og:description\" content=\"Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc. - Cadene/pretrained-models.pytorch\" />              <meta name=\"hostname\" content=\"github.com\">        <meta name=\"expected-hostname\" content=\"github.com\">  <meta http-equiv=\"x-pjax-version\" content=\"b9fa4cafade57d606c6dcfafff1d08bd597980af7b9837ed473fdf0cdea8a3bc\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-csp-version\" content=\"5dcfbec3488c5fd5a334e287ce6a17058b7d4beb91db2d4d184e4d55bbf1d7d7\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-css-version\" content=\"d33c7c2fcff40783f3002896023f41e2c17ec62b12ddbe7434e2001d743fb853\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-js-version\" content=\"4ba4a7cc07194c8d5f24291dea4fbc790ffd83ba40beacaf8d0117187b571b4d\" data-turbo-track=\"reload\">  <meta name=\"turbo-cache-control\" content=\"no-preview\" data-turbo-transient=\"\">      <meta data-hydrostats=\"publish\">  <meta name=\"go-import\" content=\"github.com/Cadene/pretrained-models.pytorch git https://github.com/Cadene/pretrained-models.pytorch.git\">  <meta name=\"octolytics-dimension-user_id\" content=\"4681518\" /><meta name=\"octolytics-dimension-user_login\" content=\"Cadene\" /><meta name=\"octolytics-dimension-repository_id\" content=\"87720287\" /><meta name=\"octolytics-dimension-repository_nwo\" content=\"Cadene/pretrained-models.pytorch\" /><meta name=\"octolytics-dimension-repository_public\" content=\"true\" /><meta name=\"octolytics-dimension-repository_is_fork\" content=\"false\" /><meta name=\"octolytics-dimension-repository_network_root_id\" content=\"87720287\" /><meta name=\"octolytics-dimension-repository_network_root_nwo\" content=\"Cadene/pretrained-models.pytorch\" />    <link rel=\"canonical\" href=\"https://github.com/Cadene/pretrained-models.pytorch\" data-turbo-transient>  <meta name=\"turbo-body-classes\" content=\"logged-out env-production page-responsive\">  <meta name=\"browser-stats-url\" content=\"https://api.github.com/_private/browser/stats\">  <meta name=\"browser-errors-url\" content=\"https://api.github.com/_private/browser/errors\">  <link rel=\"mask-icon\" href=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" color=\"#000000\">  <link rel=\"alternate icon\" class=\"js-site-favicon\" type=\"image/png\" href=\"https://github.githubassets.com/favicons/favicon.png\">  <link rel=\"icon\" class=\"js-site-favicon\" type=\"image/svg+xml\" href=\"https://github.githubassets.com/favicons/favicon.svg\"><meta name=\"theme-color\" content=\"#1e2327\"><meta name=\"color-scheme\" content=\"light dark\" />  <link rel=\"manifest\" href=\"/manifest.json\" crossOrigin=\"use-credentials\">  </head>  <body class=\"logged-out env-production page-responsive\" style=\"word-wrap: break-word;\">    <div data-turbo-body class=\"logged-out env-production page-responsive\" style=\"word-wrap: break-word;\">          <div class=\"position-relative js-header-wrapper \">      <a href=\"#start-of-content\" class=\"px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content\">Skip to content</a>      <span data-view-component=\"true\" class=\"progress-pjax-loader Progress position-fixed width-full\">    <span style=\"width: 0%;\" data-view-component=\"true\" class=\"Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis\"></span></span>              <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Button_IconButton_js-node_modules_primer_react_lib--23bcad-a89698f38643.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/keyboard-shortcuts-dialog-a23eda2bcf8d.js\"></script><react-partial  partial-name=\"keyboard-shortcuts-dialog\"  data-ssr=\"false\">    <script type=\"application/json\" data-target=\"react-partial.embeddedData\">{\"props\":{}}</script>  <div data-target=\"react-partial.reactRoot\"></div></react-partial>                          <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-94fd67-99519581d0f8.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/sessions-585a7232e50a.js\"></script><header class=\"Header-old header-logged-out js-details-container Details position-relative f4 py-3\" role=\"banner\" data-color-mode=light data-light-theme=light data-dark-theme=dark>  <button type=\"button\" class=\"Header-backdrop d-lg-none border-0 position-fixed top-0 left-0 width-full height-full js-details-target\" aria-label=\"Toggle navigation\">    <span class=\"d-none\">Toggle navigation</span>  </button>  <div class=\" d-flex flex-column flex-lg-row flex-items-center p-responsive height-full position-relative z-1\">    <div class=\"d-flex flex-justify-between flex-items-center width-full width-lg-auto\">      <a class=\"mr-lg-3 color-fg-inherit flex-order-2\" href=\"https://github.com/\" aria-label=\"Homepage\" data-ga-click=\"(Logged out) Header, go to homepage, icon:logo-wordmark\">        <svg height=\"32\" aria-hidden=\"true\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"32\" data-view-component=\"true\" class=\"octicon octicon-mark-github\">    <path d=\"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z\"></path></svg>      </a>      <div class=\"flex-1\">        <a href=\"/login?return_to=https%3A%2F%2Fgithub.com%2Fcadene%2Fpretrained-models.pytorch\"          class=\"d-inline-block d-lg-none flex-order-1 f5 no-underline border color-border-default rounded-2 px-2 py-1 color-fg-inherit\"          data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/cadene/pretrained-models.pytorch&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"62cf232eeadac2763aba8365546ec358699df70b29d9e04e80fce451e0abfa24\"          data-ga-click=\"(Logged out) Header, clicked Sign in, text:sign-in\">          Sign in        </a>      </div>      <div class=\"flex-1 flex-order-2 text-right\">        <button aria-label=\"Toggle navigation\" aria-expanded=\"false\" type=\"button\" data-view-component=\"true\" class=\"js-details-target Button--link Button--medium Button d-lg-none color-fg-inherit p-1\">  <span class=\"Button-content\">    <span class=\"Button-label\"><div class=\"HeaderMenu-toggle-bar rounded my-1\"></div>            <div class=\"HeaderMenu-toggle-bar rounded my-1\"></div>            <div class=\"HeaderMenu-toggle-bar rounded my-1\"></div></span>  </span></button>      </div>    </div>    <div class=\"HeaderMenu--logged-out p-responsive height-fit position-lg-relative d-lg-flex flex-column flex-auto pt-7 pb-4 top-0\">      <div class=\"header-menu-wrapper d-flex flex-column flex-self-end flex-lg-row flex-justify-between flex-auto p-3 p-lg-0 rounded rounded-lg-0 mt-3 mt-lg-0\">          <nav class=\"mt-0 px-3 px-lg-0 mb-3 mb-lg-0\" aria-label=\"Global\">            <ul class=\"d-lg-flex list-style-none\">                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Product        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 d-lg-flex dropdown-menu-wide\">          <div class=\"px-lg-4 border-lg-right mb-4 mb-lg-0 pr-lg-7\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}\" href=\"/features/actions\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-workflow color-fg-subtle mr-3\">    <path d=\"M1 3a2 2 0 0 1 2-2h6.5a2 2 0 0 1 2 2v6.5a2 2 0 0 1-2 2H7v4.063C7 16.355 7.644 17 8.438 17H12.5v-2.5a2 2 0 0 1 2-2H21a2 2 0 0 1 2 2V21a2 2 0 0 1-2 2h-6.5a2 2 0 0 1-2-2v-2.5H8.437A2.939 2.939 0 0 1 5.5 15.562V11.5H3a2 2 0 0 1-2-2Zm2-.5a.5.5 0 0 0-.5.5v6.5a.5.5 0 0 0 .5.5h6.5a.5.5 0 0 0 .5-.5V3a.5.5 0 0 0-.5-.5ZM14.5 14a.5.5 0 0 0-.5.5V21a.5.5 0 0 0 .5.5H21a.5.5 0 0 0 .5-.5v-6.5a.5.5 0 0 0-.5-.5Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Actions</div>        Automate any workflow      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}\" href=\"/features/packages\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-package color-fg-subtle mr-3\">    <path d=\"M12.876.64V.639l8.25 4.763c.541.313.875.89.875 1.515v9.525a1.75 1.75 0 0 1-.875 1.516l-8.25 4.762a1.748 1.748 0 0 1-1.75 0l-8.25-4.763a1.75 1.75 0 0 1-.875-1.515V6.917c0-.625.334-1.202.875-1.515L11.126.64a1.748 1.748 0 0 1 1.75 0Zm-1 1.298L4.251 6.34l7.75 4.474 7.75-4.474-7.625-4.402a.248.248 0 0 0-.25 0Zm.875 19.123 7.625-4.402a.25.25 0 0 0 .125-.216V7.639l-7.75 4.474ZM3.501 7.64v8.803c0 .09.048.172.125.216l7.625 4.402v-8.947Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Packages</div>        Host and manage packages      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}\" href=\"/features/security\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-shield-check color-fg-subtle mr-3\">    <path d=\"M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z\"></path><path d=\"m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Security</div>        Find and fix vulnerabilities      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}\" href=\"/features/codespaces\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-codespaces color-fg-subtle mr-3\">    <path d=\"M3.5 3.75C3.5 2.784 4.284 2 5.25 2h13.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 18.75 13H5.25a1.75 1.75 0 0 1-1.75-1.75Zm-2 12c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v4a1.75 1.75 0 0 1-1.75 1.75H3.25a1.75 1.75 0 0 1-1.75-1.75ZM5.25 3.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h13.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Zm-2 12a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h17.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25Z\"></path><path d=\"M10 17.75a.75.75 0 0 1 .75-.75h6.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Codespaces</div>        Instant dev environments      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}\" href=\"/features/copilot\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-copilot color-fg-subtle mr-3\">    <path d=\"M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z\"></path><path d=\"M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Copilot</div>        Write better code with AI      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}\" href=\"/features/code-review\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-code-review color-fg-subtle mr-3\">    <path d=\"M10.3 6.74a.75.75 0 0 1-.04 1.06l-2.908 2.7 2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z\"></path><path d=\"M1.5 4.25c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v12.5a1.75 1.75 0 0 1-1.75 1.75h-9.69l-3.573 3.573A1.458 1.458 0 0 1 5 21.043V18.5H3.25a1.75 1.75 0 0 1-1.75-1.75ZM3.25 4a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h2.5a.75.75 0 0 1 .75.75v3.19l3.72-3.72a.749.749 0 0 1 .53-.22h10a.25.25 0 0 0 .25-.25V4.25a.25.25 0 0 0-.25-.25Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Code review</div>        Manage code changes      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}\" href=\"/features/issues\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-issue-opened color-fg-subtle mr-3\">    <path d=\"M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1ZM2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5 9.5 9.5 0 0 0 2.5 12Zm9.5 2a2 2 0 1 1-.001-3.999A2 2 0 0 1 12 14Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Issues</div>        Plan and track work      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}\" href=\"/features/discussions\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-comment-discussion color-fg-subtle mr-3\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z\"></path><path d=\"M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Discussions</div>        Collaborate outside of code      </div>    </a></li>            </ul>          </div>          <div class=\"px-lg-4\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"product-explore-heading\">Explore</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"product-explore-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to All features&quot;,&quot;label&quot;:&quot;ref_cta:All features;&quot;}\" href=\"/features\">      All features    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Documentation&quot;,&quot;label&quot;:&quot;ref_cta:Documentation;&quot;}\" href=\"https://docs.github.com\">      Documentation    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Skills&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Skills;&quot;}\" href=\"https://skills.github.com/\">      GitHub Skills    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Blog&quot;,&quot;label&quot;:&quot;ref_cta:Blog;&quot;}\" href=\"https://github.blog\">      Blog    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Solutions        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 px-lg-4\">          <div class=\"border-bottom pb-3 mb-3\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-for-heading\">For</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-for-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Enterprise&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise;&quot;}\" href=\"/enterprise\">      Enterprise    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Teams&quot;,&quot;label&quot;:&quot;ref_cta:Teams;&quot;}\" href=\"/team\">      Teams    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Startups&quot;,&quot;label&quot;:&quot;ref_cta:Startups;&quot;}\" href=\"/enterprise/startups\">      Startups    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Education&quot;,&quot;label&quot;:&quot;ref_cta:Education;&quot;}\" href=\"https://education.github.com\">      Education    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>          <div class=\"border-bottom pb-3 mb-3\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-by-solution-heading\">By Solution</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-by-solution-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to CI/CD &amp;amp; Automation&quot;,&quot;label&quot;:&quot;ref_cta:CI/CD &amp;amp; Automation;&quot;}\" href=\"/solutions/ci-cd/\">      CI/CD &amp; Automation    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevOps&quot;,&quot;label&quot;:&quot;ref_cta:DevOps;&quot;}\" href=\"/solutions/devops/\">      DevOps    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevSecOps&quot;,&quot;label&quot;:&quot;ref_cta:DevSecOps;&quot;}\" href=\"https://resources.github.com/devops/fundamentals/devsecops/\">      DevSecOps    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>          <div class=\"\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-resources-heading\">Resources</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-resources-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Learning Pathways&quot;,&quot;label&quot;:&quot;ref_cta:Learning Pathways;&quot;}\" href=\"https://resources.github.com/learn/pathways/\">      Learning Pathways    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}\" href=\"https://resources.github.com/\">      White papers, Ebooks, Webinars    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}\" href=\"/customer-stories\">      Customer Stories    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}\" href=\"https://partner.github.com/\">      Partners    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Open Source        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 px-lg-4\">          <div class=\"border-bottom pb-3 mb-3\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}\" href=\"/sponsors\">            <div>        <div class=\"color-fg-default h4\">GitHub Sponsors</div>        Fund open source developers      </div>    </a></li>            </ul>          </div>          <div class=\"border-bottom pb-3 mb-3\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}\" href=\"/readme\">            <div>        <div class=\"color-fg-default h4\">The ReadME Project</div>        GitHub community articles      </div>    </a></li>            </ul>          </div>          <div class=\"\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"open-source-repositories-heading\">Repositories</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"open-source-repositories-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Topics&quot;,&quot;label&quot;:&quot;ref_cta:Topics;&quot;}\" href=\"/topics\">      Topics    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Trending&quot;,&quot;label&quot;:&quot;ref_cta:Trending;&quot;}\" href=\"/trending\">      Trending    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Collections&quot;,&quot;label&quot;:&quot;ref_cta:Collections;&quot;}\" href=\"/collections\">      Collections    </a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">    <a class=\"HeaderMenu-link no-underline px-0 px-lg-2 py-3 py-lg-2 d-block d-lg-inline-block\" data-analytics-event=\"{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}\" href=\"/pricing\">Pricing</a></li>            </ul>          </nav>        <div class=\"d-lg-flex flex-items-center mb-3 mb-lg-0 text-center text-lg-left ml-3\" style=\"\">                <qbsearch-input class=\"search-input\" data-scope=\"repo:Cadene/pretrained-models.pytorch\" data-custom-scopes-path=\"/search/custom_scopes\" data-delete-custom-scopes-csrf=\"dc9RVZl1_i7ZN1CVyMdUo4T1-jFbUm3GDvw-Nkuq10Y3FhSJdPDsVsGQR52DT1APGf7hdt1v1IhOJEX8Wbpqaw\" data-max-custom-scopes=\"10\" data-header-redesign-enabled=\"false\" data-initial-value=\"\" data-blackbird-suggestions-path=\"/search/suggestions\" data-jump-to-suggestions-path=\"/_graphql/GetSuggestedNavigationDestinations\" data-current-repository=\"Cadene/pretrained-models.pytorch\" data-current-org=\"\" data-current-owner=\"Cadene\" data-logged-in=\"false\" data-copilot-chat-enabled=\"false\" data-blackbird-indexed-repo-csrf=\"<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=yCkKzbK98b8Pqp7FWcp2AVwZfsfLOLkt1myFOd4n4b7eAv3oi%2F9%2BGDDuF9xQ6T1AEW4E%2F4%2FeHbo9etPJQczs9YszCXdAFQM992ATAuymPyUUsGkknSy5mvR6LuxHnSP%2BoUYRJkkFKO%2FUj4HoU7eZp6dW93r5cY3pbbtd5NGx3pHuQEcYlCfKHRVGgW1ZOSWBhljG7jRxTkM4%2FF9kM%2F5ObhNL%2FxUZAjaRtuVBi5TLlCI%2BQumKCWDw%2BjYZkRJhHbztkI7VxTPdvBcYtKhjim8Z06Qvbi5rxqJaqCZUCiQa0TR%2B738GQWAY9TeKJwCag41IryD1bkjxHxTgG%2FF1vKr1bnQqC%2B8pv6TtSnzo2%2Bw8l%2BvI5t3no%2FrORuMrM20LdR3slR9yP5aw31iq7vW3ZMmJBd2MnOfUa%2F9U3bZacFehym%2FrONIR%2F4sBTaGQ%2BAhyF%2BOpaibd2WYJpAe4FI83y7rsy3O7D3M0FWviA4gTjgqsOJ45vIS52ltSQv6L21Xjf40oOpLXEbhk0UeF1i%2BFtSX0oEwPipqZuteStIkZuCiat2U7EA%3D%3D--5ORjwwpbzozDugnH--PhSZikqhZIb%2F4f7jC01bug%3D%3D&quot; />\">  <div    class=\"search-input-container search-with-dialog position-relative d-flex flex-row flex-items-center mr-4 rounded\"    data-action=\"click:qbsearch-input#searchInputContainerClicked\"  >      <button        type=\"button\"        class=\"header-search-button placeholder  input-button form-control d-flex flex-1 flex-self-stretch flex-items-center no-wrap width-full py-0 pl-2 pr-0 text-left border-0 box-shadow-none\"        data-target=\"qbsearch-input.inputButton\"        placeholder=\"Search or jump to...\"        data-hotkey=s,/        autocapitalize=\"off\"        data-action=\"click:qbsearch-input#handleExpand\"      >        <div class=\"mr-2 color-fg-muted\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg>        </div>        <span class=\"flex-1\" data-target=\"qbsearch-input.inputButtonText\">Search or jump to...</span>          <div class=\"d-flex\" data-target=\"qbsearch-input.hotkeyIndicator\">            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"22\" height=\"20\" aria-hidden=\"true\" class=\"mr-1\"><path fill=\"none\" stroke=\"#979A9C\" opacity=\".4\" d=\"M3.5.5h12c1.7 0 3 1.3 3 3v13c0 1.7-1.3 3-3 3h-12c-1.7 0-3-1.3-3-3v-13c0-1.7 1.3-3 3-3z\"></path><path fill=\"#979A9C\" d=\"M11.8 6L8 15.1h-.9L10.8 6h1z\"></path></svg>          </div>      </button>    <input type=\"hidden\" name=\"type\" class=\"js-site-search-type-field\">    <div class=\"Overlay--hidden \" data-modal-dialog-overlay>  <modal-dialog data-action=\"close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose\" data-target=\"qbsearch-input.searchSuggestionsDialog\" role=\"dialog\" id=\"search-suggestions-dialog\" aria-modal=\"true\" aria-labelledby=\"search-suggestions-dialog-header\" data-view-component=\"true\" class=\"Overlay Overlay--width-large Overlay--height-auto\">      <h1 id=\"search-suggestions-dialog-header\" class=\"sr-only\">Search code, repositories, users, issues, pull requests...</h1>    <div class=\"Overlay-body Overlay-body--paddingNone\">                <div data-view-component=\"true\">        <div class=\"search-suggestions position-fixed width-full color-shadow-large border color-fg-default color-bg-default overflow-hidden d-flex flex-column query-builder-container\"          style=\"border-radius: 12px;\"          data-target=\"qbsearch-input.queryBuilderContainer\"          hidden        >          <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"query-builder-test-form\" action=\"\" accept-charset=\"UTF-8\" method=\"get\">  <query-builder data-target=\"qbsearch-input.queryBuilder\" id=\"query-builder-query-builder-test\" data-filter-key=\":\" data-view-component=\"true\" class=\"QueryBuilder search-query-builder\">    <div class=\"FormControl FormControl--fullWidth\">      <label id=\"query-builder-test-label\" for=\"query-builder-test\" class=\"FormControl-label sr-only\">        Search      </label>      <div        class=\"QueryBuilder-StyledInput width-fit \"        data-target=\"query-builder.styledInput\"      >          <span id=\"query-builder-test-leadingvisual-wrap\" class=\"FormControl-input-leadingVisualWrap QueryBuilder-leadingVisualWrap\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search FormControl-input-leadingVisual\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg>          </span>        <div data-target=\"query-builder.styledInputContainer\" class=\"QueryBuilder-StyledInputContainer\">          <div            aria-hidden=\"true\"            class=\"QueryBuilder-StyledInputContent\"            data-target=\"query-builder.styledInputContent\"          ></div>          <div class=\"QueryBuilder-InputWrapper\">            <div aria-hidden=\"true\" class=\"QueryBuilder-Sizer\" data-target=\"query-builder.sizer\"></div>            <input id=\"query-builder-test\" name=\"query-builder-test\" value=\"\" autocomplete=\"off\" type=\"text\" role=\"combobox\" spellcheck=\"false\" aria-expanded=\"false\" aria-describedby=\"validation-f8fcb9dd-1d8e-46f6-ad63-26e014ea0b9b\" data-target=\"query-builder.input\" data-action=\"          input:query-builder#inputChange          blur:query-builder#inputBlur          keydown:query-builder#inputKeydown          focus:query-builder#inputFocus        \" data-view-component=\"true\" class=\"FormControl-input QueryBuilder-Input FormControl-medium\" />          </div>        </div>          <span class=\"sr-only\" id=\"query-builder-test-clear\">Clear</span>          <button role=\"button\" id=\"query-builder-test-clear-button\" aria-labelledby=\"query-builder-test-clear query-builder-test-label\" data-target=\"query-builder.clearButton\" data-action=\"                click:query-builder#clear                focus:query-builder#clearButtonFocus                blur:query-builder#clearButtonBlur              \" variant=\"small\" hidden=\"hidden\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--invisible Button--medium mr-1 px-2 py-0 d-flex flex-items-center rounded-1 color-fg-muted\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x-circle-fill Button-visual\">    <path d=\"M2.343 13.657A8 8 0 1 1 13.658 2.343 8 8 0 0 1 2.343 13.657ZM6.03 4.97a.751.751 0 0 0-1.042.018.751.751 0 0 0-.018 1.042L6.94 8 4.97 9.97a.749.749 0 0 0 .326 1.275.749.749 0 0 0 .734-.215L8 9.06l1.97 1.97a.749.749 0 0 0 1.275-.326.749.749 0 0 0-.215-.734L9.06 8l1.97-1.97a.749.749 0 0 0-.326-1.275.749.749 0 0 0-.734.215L8 6.94Z\"></path></svg></button>      </div>      <template id=\"search-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg></template><template id=\"code-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg></template><template id=\"file-code-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-file-code\">    <path d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg></template><template id=\"history-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-history\">    <path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></template><template id=\"repo-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo\">    <path d=\"M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z\"></path></svg></template><template id=\"bookmark-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bookmark\">    <path d=\"M3 2.75C3 1.784 3.784 1 4.75 1h6.5c.966 0 1.75.784 1.75 1.75v11.5a.75.75 0 0 1-1.227.579L8 11.722l-3.773 3.107A.751.751 0 0 1 3 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.91l3.023-2.489a.75.75 0 0 1 .954 0l3.023 2.49V2.75a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"plus-circle-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-plus-circle\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm7.25-3.25v2.5h2.5a.75.75 0 0 1 0 1.5h-2.5v2.5a.75.75 0 0 1-1.5 0v-2.5h-2.5a.75.75 0 0 1 0-1.5h2.5v-2.5a.75.75 0 0 1 1.5 0Z\"></path></svg></template><template id=\"circle-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg></template><template id=\"trash-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-trash\">    <path d=\"M11 1.75V3h2.25a.75.75 0 0 1 0 1.5H2.75a.75.75 0 0 1 0-1.5H5V1.75C5 .784 5.784 0 6.75 0h2.5C10.216 0 11 .784 11 1.75ZM4.496 6.675l.66 6.6a.25.25 0 0 0 .249.225h5.19a.25.25 0 0 0 .249-.225l.66-6.6a.75.75 0 0 1 1.492.149l-.66 6.6A1.748 1.748 0 0 1 10.595 15h-5.19a1.75 1.75 0 0 1-1.741-1.575l-.66-6.6a.75.75 0 1 1 1.492-.15ZM6.5 1.75V3h3V1.75a.25.25 0 0 0-.25-.25h-2.5a.25.25 0 0 0-.25.25Z\"></path></svg></template><template id=\"team-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-people\">    <path d=\"M2 5.5a3.5 3.5 0 1 1 5.898 2.549 5.508 5.508 0 0 1 3.034 4.084.75.75 0 1 1-1.482.235 4 4 0 0 0-7.9 0 .75.75 0 0 1-1.482-.236A5.507 5.507 0 0 1 3.102 8.05 3.493 3.493 0 0 1 2 5.5ZM11 4a3.001 3.001 0 0 1 2.22 5.018 5.01 5.01 0 0 1 2.56 3.012.749.749 0 0 1-.885.954.752.752 0 0 1-.549-.514 3.507 3.507 0 0 0-2.522-2.372.75.75 0 0 1-.574-.73v-.352a.75.75 0 0 1 .416-.672A1.5 1.5 0 0 0 11 5.5.75.75 0 0 1 11 4Zm-5.5-.5a2 2 0 1 0-.001 3.999A2 2 0 0 0 5.5 3.5Z\"></path></svg></template><template id=\"project-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-project\">    <path d=\"M1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0ZM1.5 1.75v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25ZM11.75 3a.75.75 0 0 1 .75.75v7.5a.75.75 0 0 1-1.5 0v-7.5a.75.75 0 0 1 .75-.75Zm-8.25.75a.75.75 0 0 1 1.5 0v5.5a.75.75 0 0 1-1.5 0ZM8 3a.75.75 0 0 1 .75.75v3.5a.75.75 0 0 1-1.5 0v-3.5A.75.75 0 0 1 8 3Z\"></path></svg></template><template id=\"pencil-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pencil\">    <path d=\"M11.013 1.427a1.75 1.75 0 0 1 2.474 0l1.086 1.086a1.75 1.75 0 0 1 0 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 0 1-.927-.928l.929-3.25c.081-.286.235-.547.445-.758l8.61-8.61Zm.176 4.823L9.75 4.81l-6.286 6.287a.253.253 0 0 0-.064.108l-.558 1.953 1.953-.558a.253.253 0 0 0 .108-.064Zm1.238-3.763a.25.25 0 0 0-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 0 0 0-.354Z\"></path></svg></template><template id=\"copilot-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copilot\">    <path d=\"M7.998 15.035c-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.201-.508-.254-1.084-.254-1.656 0-.87.128-1.769.693-2.484.579-.733 1.494-1.124 2.724-1.261 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095v1.872c0 .766-3.351 3.795-8.002 3.795Zm0-1.485c2.28 0 4.584-1.11 5.002-1.433V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-1.146 0-2.059-.327-2.71-.991A3.222 3.222 0 0 1 8 6.303a3.24 3.24 0 0 1-.544.743c-.65.664-1.563.991-2.71.991-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433ZM6.762 2.83c-.193-.206-.637-.413-1.682-.297-1.019.113-1.479.404-1.713.7-.247.312-.369.789-.369 1.554 0 .793.129 1.171.308 1.371.162.181.519.379 1.442.379.853 0 1.339-.235 1.638-.54.315-.322.527-.827.617-1.553.117-.935-.037-1.395-.241-1.614Zm4.155-.297c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Z\"></path><path d=\"M6.25 9.037a.75.75 0 0 1 .75.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 .75-.75Zm4.25.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 1.5 0Z\"></path></svg></template><template id=\"workflow-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-workflow\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h3.5C6.216 0 7 .784 7 1.75v3.5A1.75 1.75 0 0 1 5.25 7H4v4a1 1 0 0 0 1 1h4v-1.25C9 9.784 9.784 9 10.75 9h3.5c.966 0 1.75.784 1.75 1.75v3.5A1.75 1.75 0 0 1 14.25 16h-3.5A1.75 1.75 0 0 1 9 14.25v-.75H5A2.5 2.5 0 0 1 2.5 11V7h-.75A1.75 1.75 0 0 1 0 5.25Zm1.75-.25a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Zm9 9a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"book-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-book\">    <path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg></template><template id=\"code-review-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code-review\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 13H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25v-8.5C0 1.784.784 1 1.75 1ZM1.5 2.75v8.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm5.28 1.72a.75.75 0 0 1 0 1.06L5.31 7l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.75.75 0 0 1 1.06 0Zm2.44 0a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L10.69 7 9.22 5.53a.75.75 0 0 1 0-1.06Z\"></path></svg></template><template id=\"codespaces-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-codespaces\">    <path d=\"M0 11.25c0-.966.784-1.75 1.75-1.75h12.5c.966 0 1.75.784 1.75 1.75v3A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm2-9.5C2 .784 2.784 0 3.75 0h8.5C13.216 0 14 .784 14 1.75v5a1.75 1.75 0 0 1-1.75 1.75h-8.5A1.75 1.75 0 0 1 2 6.75Zm1.75-.25a.25.25 0 0 0-.25.25v5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-5a.25.25 0 0 0-.25-.25Zm-2 9.5a.25.25 0 0 0-.25.25v3c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-3a.25.25 0 0 0-.25-.25Z\"></path><path d=\"M7 12.75a.75.75 0 0 1 .75-.75h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z\"></path></svg></template><template id=\"comment-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-comment\">    <path d=\"M1 2.75C1 1.784 1.784 1 2.75 1h10.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 13.25 12H9.06l-2.573 2.573A1.458 1.458 0 0 1 4 13.543V12H2.75A1.75 1.75 0 0 1 1 10.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h4.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"comment-discussion-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-comment-discussion\">    <path d=\"M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z\"></path></svg></template><template id=\"organization-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-organization\">    <path d=\"M1.75 16A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0h8.5C11.216 0 12 .784 12 1.75v12.5c0 .085-.006.168-.018.25h2.268a.25.25 0 0 0 .25-.25V8.285a.25.25 0 0 0-.111-.208l-1.055-.703a.749.749 0 1 1 .832-1.248l1.055.703c.487.325.779.871.779 1.456v5.965A1.75 1.75 0 0 1 14.25 16h-3.5a.766.766 0 0 1-.197-.026c-.099.017-.2.026-.303.026h-3a.75.75 0 0 1-.75-.75V14h-1v1.25a.75.75 0 0 1-.75.75Zm-.25-1.75c0 .138.112.25.25.25H4v-1.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 .75.75v1.25h2.25a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM3.75 6h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 3.75A.75.75 0 0 1 3.75 3h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 3.75Zm4 3A.75.75 0 0 1 7.75 6h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 7 6.75ZM7.75 3h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 9.75A.75.75 0 0 1 3.75 9h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 9.75ZM7.75 9h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z\"></path></svg></template><template id=\"rocket-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-rocket\">    <path d=\"M14.064 0h.186C15.216 0 16 .784 16 1.75v.186a8.752 8.752 0 0 1-2.564 6.186l-.458.459c-.314.314-.641.616-.979.904v3.207c0 .608-.315 1.172-.833 1.49l-2.774 1.707a.749.749 0 0 1-1.11-.418l-.954-3.102a1.214 1.214 0 0 1-.145-.125L3.754 9.816a1.218 1.218 0 0 1-.124-.145L.528 8.717a.749.749 0 0 1-.418-1.11l1.71-2.774A1.748 1.748 0 0 1 3.31 4h3.204c.288-.338.59-.665.904-.979l.459-.458A8.749 8.749 0 0 1 14.064 0ZM8.938 3.623h-.002l-.458.458c-.76.76-1.437 1.598-2.02 2.5l-1.5 2.317 2.143 2.143 2.317-1.5c.902-.583 1.74-1.26 2.499-2.02l.459-.458a7.25 7.25 0 0 0 2.123-5.127V1.75a.25.25 0 0 0-.25-.25h-.186a7.249 7.249 0 0 0-5.125 2.123ZM3.56 14.56c-.732.732-2.334 1.045-3.005 1.148a.234.234 0 0 1-.201-.064.234.234 0 0 1-.064-.201c.103-.671.416-2.273 1.15-3.003a1.502 1.502 0 1 1 2.12 2.12Zm6.94-3.935c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 0 0 .119-.213ZM3.678 8.116 5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 0 0-.213.119l-1.2 1.95ZM12 5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg></template><template id=\"shield-check-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield-check\">    <path d=\"m8.533.133 5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667l5.25-1.68a1.748 1.748 0 0 1 1.066 0Zm-.61 1.429.001.001-5.25 1.68a.251.251 0 0 0-.174.237V7c0 1.36.275 2.666 1.057 3.859.784 1.194 2.121 2.342 4.366 3.298a.196.196 0 0 0 .154 0c2.245-.957 3.582-2.103 4.366-3.297C13.225 9.666 13.5 8.358 13.5 7V3.48a.25.25 0 0 0-.174-.238l-5.25-1.68a.25.25 0 0 0-.153 0ZM11.28 6.28l-3.5 3.5a.75.75 0 0 1-1.06 0l-1.5-1.5a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l.97.97 2.97-2.97a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg></template><template id=\"heart-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-heart\">    <path d=\"m8 14.25.345.666a.75.75 0 0 1-.69 0l-.008-.004-.018-.01a7.152 7.152 0 0 1-.31-.17 22.055 22.055 0 0 1-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.066 22.066 0 0 1-3.744 2.584l-.018.01-.006.003h-.002ZM4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.58 20.58 0 0 0 8 13.393a20.58 20.58 0 0 0 3.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.749.749 0 0 1-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5Z\"></path></svg></template><template id=\"server-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-server\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v4c0 .372-.116.717-.314 1 .198.283.314.628.314 1v4a1.75 1.75 0 0 1-1.75 1.75H1.75A1.75 1.75 0 0 1 0 12.75v-4c0-.358.109-.707.314-1a1.739 1.739 0 0 1-.314-1v-4C0 1.784.784 1 1.75 1ZM1.5 2.75v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm.25 5.75a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25ZM7 4.75A.75.75 0 0 1 7.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5A.75.75 0 0 1 7 4.75ZM7.75 10h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM3 4.75A.75.75 0 0 1 3.75 4h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 4.75ZM3.75 10h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z\"></path></svg></template><template id=\"globe-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-globe\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM5.78 8.75a9.64 9.64 0 0 0 1.363 4.177c.255.426.542.832.857 1.215.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a9.927 9.927 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.507 6.507 0 0 0 4.666 5.5c-.123-.181-.24-.365-.352-.552-.715-1.192-1.437-2.874-1.581-4.948Zm-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948.12-.197.237-.381.353-.552a6.507 6.507 0 0 0-4.666 5.5Zm10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948-.12.197-.237.381-.353.552a6.507 6.507 0 0 0 4.666-5.5Zm2.733-1.5a6.507 6.507 0 0 0-4.666-5.5c.123.181.24.365.353.552.714 1.192 1.436 2.874 1.58 4.948Z\"></path></svg></template><template id=\"issue-opened-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg></template><template id=\"device-mobile-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-device-mobile\">    <path d=\"M3.75 0h8.5C13.216 0 14 .784 14 1.75v12.5A1.75 1.75 0 0 1 12.25 16h-8.5A1.75 1.75 0 0 1 2 14.25V1.75C2 .784 2.784 0 3.75 0ZM3.5 1.75v12.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM8 13a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z\"></path></svg></template><template id=\"package-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-package\">    <path d=\"m8.878.392 5.25 3.045c.54.314.872.89.872 1.514v6.098a1.75 1.75 0 0 1-.872 1.514l-5.25 3.045a1.75 1.75 0 0 1-1.756 0l-5.25-3.045A1.75 1.75 0 0 1 1 11.049V4.951c0-.624.332-1.201.872-1.514L7.122.392a1.75 1.75 0 0 1 1.756 0ZM7.875 1.69l-4.63 2.685L8 7.133l4.755-2.758-4.63-2.685a.248.248 0 0 0-.25 0ZM2.5 5.677v5.372c0 .09.047.171.125.216l4.625 2.683V8.432Zm6.25 8.271 4.625-2.683a.25.25 0 0 0 .125-.216V5.677L8.75 8.432Z\"></path></svg></template><template id=\"credit-card-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-credit-card\">    <path d=\"M10.75 9a.75.75 0 0 0 0 1.5h1.5a.75.75 0 0 0 0-1.5h-1.5Z\"></path><path d=\"M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25ZM14.5 6.5h-13v5.75c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25Zm0-2.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25V5h13Z\"></path></svg></template><template id=\"play-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg></template><template id=\"gift-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-gift\">    <path d=\"M2 2.75A2.75 2.75 0 0 1 4.75 0c.983 0 1.873.42 2.57 1.232.268.318.497.668.68 1.042.183-.375.411-.725.68-1.044C9.376.42 10.266 0 11.25 0a2.75 2.75 0 0 1 2.45 4h.55c.966 0 1.75.784 1.75 1.75v2c0 .698-.409 1.301-1 1.582v4.918A1.75 1.75 0 0 1 13.25 16H2.75A1.75 1.75 0 0 1 1 14.25V9.332C.409 9.05 0 8.448 0 7.75v-2C0 4.784.784 4 1.75 4h.55c-.192-.375-.3-.8-.3-1.25ZM7.25 9.5H2.5v4.75c0 .138.112.25.25.25h4.5Zm1.5 0v5h4.5a.25.25 0 0 0 .25-.25V9.5Zm0-4V8h5.5a.25.25 0 0 0 .25-.25v-2a.25.25 0 0 0-.25-.25Zm-7 0a.25.25 0 0 0-.25.25v2c0 .138.112.25.25.25h5.5V5.5h-5.5Zm3-4a1.25 1.25 0 0 0 0 2.5h2.309c-.233-.818-.542-1.401-.878-1.793-.43-.502-.915-.707-1.431-.707ZM8.941 4h2.309a1.25 1.25 0 0 0 0-2.5c-.516 0-1 .205-1.43.707-.337.392-.646.975-.879 1.793Z\"></path></svg></template><template id=\"code-square-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code-square\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25Zm7.47 3.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L10.69 8 9.22 6.53a.75.75 0 0 1 0-1.06ZM6.78 6.53 5.31 8l1.47 1.47a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg></template><template id=\"device-desktop-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-device-desktop\">    <path d=\"M14.25 1c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 14.25 12h-3.727c.099 1.041.52 1.872 1.292 2.757A.752.752 0 0 1 11.25 16h-6.5a.75.75 0 0 1-.565-1.243c.772-.885 1.192-1.716 1.292-2.757H1.75A1.75 1.75 0 0 1 0 10.25v-7.5C0 1.784.784 1 1.75 1ZM1.75 2.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25ZM9.018 12H6.982a5.72 5.72 0 0 1-.765 2.5h3.566a5.72 5.72 0 0 1-.765-2.5Z\"></path></svg></template>        <div class=\"position-relative\">                <ul                  role=\"listbox\"                  class=\"ActionListWrap QueryBuilder-ListWrap\"                  aria-label=\"Suggestions\"                  data-action=\"                    combobox-commit:query-builder#comboboxCommit                    mousedown:query-builder#resultsMousedown                  \"                  data-target=\"query-builder.resultsList\"                  data-persist-list=false                  id=\"query-builder-test-results\"                ></ul>        </div>      <div class=\"FormControl-inlineValidation\" id=\"validation-f8fcb9dd-1d8e-46f6-ad63-26e014ea0b9b\" hidden=\"hidden\">        <span class=\"FormControl-inlineValidation--visual\">          <svg aria-hidden=\"true\" height=\"12\" viewBox=\"0 0 12 12\" version=\"1.1\" width=\"12\" data-view-component=\"true\" class=\"octicon octicon-alert-fill\">    <path d=\"M4.855.708c.5-.896 1.79-.896 2.29 0l4.675 8.351a1.312 1.312 0 0 1-1.146 1.954H1.33A1.313 1.313 0 0 1 .183 9.058ZM7 7V3H5v4Zm-1 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z\"></path></svg>        </span>        <span></span></div>    </div>    <div data-target=\"query-builder.screenReaderFeedback\" aria-live=\"polite\" aria-atomic=\"true\" class=\"sr-only\"></div></query-builder></form>          <div class=\"d-flex flex-row color-fg-muted px-3 text-small color-bg-default search-feedback-prompt\">            <a target=\"_blank\" href=\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\" data-view-component=\"true\" class=\"Link color-fg-accent text-normal ml-2\">              Search syntax tips</a>            <div class=\"d-flex flex-1\"></div>          </div>        </div></div>    </div></modal-dialog></div>  </div>  <div data-action=\"click:qbsearch-input#retract\" class=\"dark-backdrop position-fixed\" hidden data-target=\"qbsearch-input.darkBackdrop\"></div>  <div class=\"color-fg-default\">    <dialog-helper>  <dialog data-target=\"qbsearch-input.feedbackDialog\" data-action=\"close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose\" id=\"feedback-dialog\" aria-modal=\"true\" aria-labelledby=\"feedback-dialog-title\" aria-describedby=\"feedback-dialog-description\" data-view-component=\"true\" class=\"Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade\">    <div data-view-component=\"true\" class=\"Overlay-header\">  <div class=\"Overlay-headerContentWrap\">    <div class=\"Overlay-titleWrap\">      <h1 class=\"Overlay-title \" id=\"feedback-dialog-title\">        Provide feedback      </h1>    </div>    <div class=\"Overlay-actionWrap\">      <button data-close-dialog-id=\"feedback-dialog\" aria-label=\"Close\" type=\"button\" data-view-component=\"true\" class=\"close-button Overlay-closeButton\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button>    </div>  </div></div>      <scrollable-region data-labelled-by=\"feedback-dialog-title\">        <div data-view-component=\"true\" class=\"Overlay-body\">        <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"code-search-feedback-form\" data-turbo=\"false\" action=\"/search/feedback\" accept-charset=\"UTF-8\" method=\"post\"><input type=\"hidden\" data-csrf=\"true\" name=\"authenticity_token\" value=\"t8MF9vWk9F++ijaM8RgD0lfh27dwFLrXQD5+87J0xUs94TF8hFX5EghAWNUMHaO1FXEE/1+rEHpPB6pY25qvSg==\" />          <p>We read every piece of feedback, and take your input very seriously.</p>          <textarea name=\"feedback\" class=\"form-control width-full mb-2\" style=\"height: 120px\" id=\"feedback\"></textarea>          <input name=\"include_email\" id=\"include_email\" aria-label=\"Include my email address so I can be contacted\" class=\"form-control mr-2\" type=\"checkbox\">          <label for=\"include_email\" style=\"font-weight: normal\">Include my email address so I can be contacted</label></form></div>      </scrollable-region>      <div data-view-component=\"true\" class=\"Overlay-footer Overlay-footer--alignEnd\">          <button data-close-dialog-id=\"feedback-dialog\" type=\"button\" data-view-component=\"true\" class=\"btn\">    Cancel</button>          <button form=\"code-search-feedback-form\" data-action=\"click:qbsearch-input#submitFeedback\" type=\"submit\" data-view-component=\"true\" class=\"btn-primary btn\">    Submit feedback</button></div></dialog></dialog-helper>    <custom-scopes data-target=\"qbsearch-input.customScopesManager\">    <dialog-helper>  <dialog data-target=\"custom-scopes.customScopesModalDialog\" data-action=\"close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose\" id=\"custom-scopes-dialog\" aria-modal=\"true\" aria-labelledby=\"custom-scopes-dialog-title\" aria-describedby=\"custom-scopes-dialog-description\" data-view-component=\"true\" class=\"Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade\">    <div data-view-component=\"true\" class=\"Overlay-header Overlay-header--divided\">  <div class=\"Overlay-headerContentWrap\">    <div class=\"Overlay-titleWrap\">      <h1 class=\"Overlay-title \" id=\"custom-scopes-dialog-title\">        Saved searches      </h1>        <h2 id=\"custom-scopes-dialog-description\" class=\"Overlay-description\">Use saved searches to filter your results more quickly</h2>    </div>    <div class=\"Overlay-actionWrap\">      <button data-close-dialog-id=\"custom-scopes-dialog\" aria-label=\"Close\" type=\"button\" data-view-component=\"true\" class=\"close-button Overlay-closeButton\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button>    </div>  </div></div>      <scrollable-region data-labelled-by=\"custom-scopes-dialog-title\">        <div data-view-component=\"true\" class=\"Overlay-body\">        <div data-target=\"custom-scopes.customScopesModalDialogFlash\"></div>        <div hidden class=\"create-custom-scope-form\" data-target=\"custom-scopes.createCustomScopeForm\">        <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"custom-scopes-dialog-form\" data-turbo=\"false\" action=\"/search/custom_scopes\" accept-charset=\"UTF-8\" method=\"post\"><input type=\"hidden\" data-csrf=\"true\" name=\"authenticity_token\" value=\"CnTCn1IQpX7QWQotEh8i/vOSf/bedEQclUZLD/l6+EFPWfg6hj1nDPRAgvB3vO5LWbJI7Oyh/dCo39Np67xO+g==\" />          <div data-target=\"custom-scopes.customScopesModalDialogFlash\"></div>          <input type=\"hidden\" id=\"custom_scope_id\" name=\"custom_scope_id\" data-target=\"custom-scopes.customScopesIdField\">          <div class=\"form-group\">            <label for=\"custom_scope_name\">Name</label>            <auto-check src=\"/search/custom_scopes/check_name\" required>              <input                type=\"text\"                name=\"custom_scope_name\"                id=\"custom_scope_name\"                data-target=\"custom-scopes.customScopesNameField\"                class=\"form-control\"                autocomplete=\"off\"                placeholder=\"github-ruby\"                required                maxlength=\"50\">              <input type=\"hidden\" data-csrf=\"true\" value=\"CvcAu4cDr1VxOfbASlehL7MhB/5EPeajvJr9iqLTr0s62pt96e6u/cj3IPGpDvpc6toI8cKYHyzgMl3bxeVvLA==\" />            </auto-check>          </div>          <div class=\"form-group\">            <label for=\"custom_scope_query\">Query</label>            <input              type=\"text\"              name=\"custom_scope_query\"              id=\"custom_scope_query\"              data-target=\"custom-scopes.customScopesQueryField\"              class=\"form-control\"              autocomplete=\"off\"              placeholder=\"(repo:mona/a OR repo:mona/b) AND lang:python\"              required              maxlength=\"500\">          </div>          <p class=\"text-small color-fg-muted\">            To see all available qualifiers, see our <a class=\"Link--inTextBlock\" href=\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\">documentation</a>.          </p></form>        </div>        <div data-target=\"custom-scopes.manageCustomScopesForm\">          <div data-target=\"custom-scopes.list\"></div>        </div></div>      </scrollable-region>      <div data-view-component=\"true\" class=\"Overlay-footer Overlay-footer--alignEnd Overlay-footer--divided\">          <button data-action=\"click:custom-scopes#customScopesCancel\" type=\"button\" data-view-component=\"true\" class=\"btn\">    Cancel</button>          <button form=\"custom-scopes-dialog-form\" data-action=\"click:custom-scopes#customScopesSubmit\" data-target=\"custom-scopes.customScopesSubmitButton\" type=\"submit\" data-view-component=\"true\" class=\"btn-primary btn\">    Create saved search</button></div></dialog></dialog-helper>    </custom-scopes>  </div></qbsearch-input><input type=\"hidden\" data-csrf=\"true\" class=\"js-data-jump-to-suggestions-path-csrf\" value=\"QhvOzIFKDytClFzkKc21zjsmh8WyL8C/fuAd/nafe+7sqp6pPdTcK6yZYScbS85MqxmDf9tLR4TLdVNN3zqhew==\" />          <div class=\"position-relative mr-lg-3 d-lg-inline-block\">            <a href=\"/login?return_to=https%3A%2F%2Fgithub.com%2Fcadene%2Fpretrained-models.pytorch\"              class=\"HeaderMenu-link HeaderMenu-link--sign-in flex-shrink-0 no-underline d-block d-lg-inline-block border border-lg-0 rounded rounded-lg-0 p-2 p-lg-0\"              data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/cadene/pretrained-models.pytorch&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"62cf232eeadac2763aba8365546ec358699df70b29d9e04e80fce451e0abfa24\"              data-ga-click=\"(Logged out) Header, clicked Sign in, text:sign-in\">              Sign in            </a>          </div>            <a href=\"/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=Cadene%2Fpretrained-models.pytorch\"              class=\"HeaderMenu-link HeaderMenu-link--sign-up flex-shrink-0 d-none d-lg-inline-block no-underline border color-border-default rounded px-2 py-1\"              data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/cadene/pretrained-models.pytorch&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"62cf232eeadac2763aba8365546ec358699df70b29d9e04e80fce451e0abfa24\"              data-analytics-event=\"{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/&lt;user-name&gt;/&lt;repo-name&gt;;ref_cta:Sign up;ref_loc:header logged out&quot;}\"            >              Sign up            </a>        </div>      </div>    </div>  </div></header>      <div hidden=\"hidden\" data-view-component=\"true\" class=\"js-stale-session-flash stale-session-flash flash flash-warn flash-full mb-3\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        <span class=\"js-stale-session-flash-signed-in\" hidden>You signed in with another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>        <span class=\"js-stale-session-flash-signed-out\" hidden>You signed out in another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>        <span class=\"js-stale-session-flash-switched\" hidden>You switched accounts on another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>    <button id=\"icon-button-f33003d5-f43d-46be-9b2c-61265488f60e\" aria-labelledby=\"tooltip-cdcf9244-5ebc-4841-8a16-762b97e915be\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--invisible Button--medium flash-close js-flash-close\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x Button-visual\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button><tool-tip id=\"tooltip-cdcf9244-5ebc-4841-8a16-762b97e915be\" for=\"icon-button-f33003d5-f43d-46be-9b2c-61265488f60e\" popover=\"manual\" data-direction=\"s\" data-type=\"label\" data-view-component=\"true\" class=\"sr-only position-absolute\">Dismiss alert</tool-tip>  </div>    </div>  <div id=\"start-of-content\" class=\"show-on-focus\"></div>    <div id=\"js-flash-container\" data-turbo-replace>  <template class=\"js-flash-template\">    <div class=\"flash flash-full   {{ className }}\">  <div class=\"px-2\" >    <button autofocus class=\"flash-close js-flash-close\" type=\"button\" aria-label=\"Dismiss this message\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>    </button>    <div aria-atomic=\"true\" role=\"alert\" class=\"js-flash-alert\">            <div>{{ message }}</div>    </div>  </div></div>  </template></div>        <include-fragment class=\"js-notification-shelf-include-fragment\" data-base-src=\"https://github.com/notifications/beta/shelf\"></include-fragment>  <div    class=\"application-main \"    data-commit-hovercards-enabled    data-discussion-hovercards-enabled    data-issue-and-pr-hovercards-enabled  >        <div itemscope itemtype=\"http://schema.org/SoftwareSourceCode\" class=\"\">    <main id=\"js-repo-pjax-container\" >                <div id=\"repository-container-header\"  class=\"pt-3 hide-full-screen\" style=\"background-color: var(--page-header-bgColor, var(--color-page-header-bg));\" data-turbo-replace>      <div class=\"d-flex flex-wrap flex-justify-end mb-3  px-3 px-md-4 px-lg-5\" style=\"gap: 1rem;\">        <div class=\"flex-auto min-width-0 width-fit mr-3\">              <div class=\" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo color-fg-muted mr-2\">    <path d=\"M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z\"></path></svg>        <span class=\"author flex-self-stretch\" itemprop=\"author\">      <a class=\"url fn\" rel=\"author\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/Cadene/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"/Cadene\">        Cadene</a>    </span>    <span class=\"mx-1 flex-self-stretch color-fg-muted\">/</span>    <strong itemprop=\"name\" class=\"mr-2 flex-self-stretch\">      <a data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" href=\"/Cadene/pretrained-models.pytorch\">pretrained-models.pytorch</a>    </strong>    <span></span><span class=\"Label Label--secondary v-align-middle mr-1\">Public</span>  </div>        </div>        <div id=\"repository-details-container\" data-turbo-replace>            <ul class=\"pagehead-actions flex-shrink-0 d-none d-md-inline\" style=\"padding: 2px 0;\">            <li>            <a href=\"/login?return_to=%2FCadene%2Fpretrained-models.pytorch\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/cadene/pretrained-models.pytorch&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"4a9faf51792ae704fe90df84ab22f4ba99c8291860b5d0fedb23967bf5ab951c\" aria-label=\"You must be signed in to change notification settings\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bell mr-2\">    <path d=\"M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z\"></path></svg>Notifications</a>  </li>  <li>          <a icon=\"repo-forked\" id=\"fork-button\" href=\"/login?return_to=%2FCadene%2Fpretrained-models.pytorch\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:87720287,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/cadene/pretrained-models.pytorch&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"7044f224b869d387dd2d5d7ab2e47ee65c803f7d1314aa4379ec9b006b9f5d12\" data-view-component=\"true\" class=\"btn-sm btn\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-2\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>Fork    <span id=\"repo-network-counter\" data-pjax-replace=\"true\" data-turbo-replace=\"true\" title=\"1,841\" data-view-component=\"true\" class=\"Counter\">1.8k</span></a>  </li>  <li>        <div data-view-component=\"true\" class=\"BtnGroup d-flex\">        <a href=\"/login?return_to=%2FCadene%2Fpretrained-models.pytorch\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:87720287,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/cadene/pretrained-models.pytorch&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"1a9a7cab150dcf08eb2879827cb2b1de9fb09f94232673d993a8103f81ca9c9d\" aria-label=\"You must be signed in to star a repository\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn BtnGroup-item\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star v-align-text-bottom d-inline-block mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg><span data-view-component=\"true\" class=\"d-inline\">          Star</span>          <span id=\"repo-stars-counter-star\" aria-label=\"8913 users starred this repository\" data-singular-suffix=\"user starred this repository\" data-plural-suffix=\"users starred this repository\" data-turbo-replace=\"true\" title=\"8,913\" data-view-component=\"true\" class=\"Counter js-social-count\">8.9k</span></a>        <button aria-label=\"You must be signed in to add this repository to a list\" type=\"button\" disabled=\"disabled\" data-view-component=\"true\" class=\"btn-sm btn BtnGroup-item px-2\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-triangle-down\">    <path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></button></div>  </li>    <li>            </li></ul>        </div>      </div>        <div id=\"responsive-meta-container\" data-turbo-replace>      <div class=\"d-block d-md-none mb-2 px-3 px-md-4 px-lg-5\">      <p class=\"f4 mb-3 \">        Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc.      </p>          <h3 class=\"sr-only\">License</h3>  <div class=\"mb-2\">    <a href=\"/Cadene/pretrained-models.pytorch/blob/master/LICENSE.txt\"      class=\"Link--muted\"            data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}\"    >      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-law mr-2\">    <path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg>     BSD-3-Clause license    </a>  </div>    <div class=\"mb-3\">        <a class=\"Link--secondary no-underline mr-3\" href=\"/Cadene/pretrained-models.pytorch/stargazers\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star mr-1\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg>          <span class=\"text-bold\">8.9k</span>          stars</a>        <a class=\"Link--secondary no-underline mr-3\" href=\"/Cadene/pretrained-models.pytorch/forks\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-1\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>          <span class=\"text-bold\">1.8k</span>          forks</a>          <a class=\"Link--secondary no-underline mr-3 d-inline-block\" href=\"/Cadene/pretrained-models.pytorch/branches\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-branch mr-1\">    <path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg>            <span>Branches</span></a>          <a class=\"Link--secondary no-underline d-inline-block\" href=\"/Cadene/pretrained-models.pytorch/tags\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-tag mr-1\">    <path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg>            <span>Tags</span></a>        <a class=\"Link--secondary no-underline d-inline-block\" href=\"/Cadene/pretrained-models.pytorch/activity\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pulse mr-1\">    <path d=\"M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z\"></path></svg>          <span>Activity</span></a>    </div>      <div class=\"d-flex flex-wrap gap-2\">        <div class=\"flex-1\">            <div data-view-component=\"true\" class=\"BtnGroup d-flex\">        <a href=\"/login?return_to=%2FCadene%2Fpretrained-models.pytorch\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:87720287,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/cadene/pretrained-models.pytorch&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"1a9a7cab150dcf08eb2879827cb2b1de9fb09f94232673d993a8103f81ca9c9d\" aria-label=\"You must be signed in to star a repository\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn btn-block BtnGroup-item\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star v-align-text-bottom d-inline-block mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg><span data-view-component=\"true\" class=\"d-inline\">          Star</span></a>        <button aria-label=\"You must be signed in to add this repository to a list\" type=\"button\" disabled=\"disabled\" data-view-component=\"true\" class=\"btn-sm btn BtnGroup-item px-2\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-triangle-down\">    <path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></button></div>        </div>        <div class=\"flex-1\">                <a href=\"/login?return_to=%2FCadene%2Fpretrained-models.pytorch\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/cadene/pretrained-models.pytorch&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"4a9faf51792ae704fe90df84ab22f4ba99c8291860b5d0fedb23967bf5ab951c\" aria-label=\"You must be signed in to change notification settings\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn btn-block\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bell mr-2\">    <path d=\"M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z\"></path></svg>Notifications</a>        </div>          <span>                      </span>      </div>  </div></div>          <nav data-pjax=\"#js-repo-pjax-container\" aria-label=\"Repository\" data-view-component=\"true\" class=\"js-repo-nav js-sidenav-container-pjax js-responsive-underlinenav overflow-hidden UnderlineNav px-3 px-md-4 px-lg-5\">  <ul data-view-component=\"true\" class=\"UnderlineNav-body list-style-none\">      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"code-tab\" href=\"/Cadene/pretrained-models.pytorch\" data-tab-item=\"i0code-tab\" data-selected-links=\"repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments repo_attestations /Cadene/pretrained-models.pytorch\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g c\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" aria-current=\"page\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item selected\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg>        <span data-content=\"Code\">Code</span>          <span id=\"code-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"issues-tab\" href=\"/Cadene/pretrained-models.pytorch/issues\" data-tab-item=\"i1issues-tab\" data-selected-links=\"repo_issues repo_labels repo_milestones /Cadene/pretrained-models.pytorch/issues\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g i\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg>        <span data-content=\"Issues\">Issues</span>          <span id=\"issues-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"84\" data-view-component=\"true\" class=\"Counter\">84</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"pull-requests-tab\" href=\"/Cadene/pretrained-models.pytorch/pulls\" data-tab-item=\"i2pull-requests-tab\" data-selected-links=\"repo_pulls checks /Cadene/pretrained-models.pytorch/pulls\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g p\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-pull-request UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z\"></path></svg>        <span data-content=\"Pull requests\">Pull requests</span>          <span id=\"pull-requests-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"14\" data-view-component=\"true\" class=\"Counter\">14</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"actions-tab\" href=\"/Cadene/pretrained-models.pytorch/actions\" data-tab-item=\"i3actions-tab\" data-selected-links=\"repo_actions /Cadene/pretrained-models.pytorch/actions\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g a\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg>        <span data-content=\"Actions\">Actions</span>          <span id=\"actions-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"projects-tab\" href=\"/Cadene/pretrained-models.pytorch/projects\" data-tab-item=\"i4projects-tab\" data-selected-links=\"repo_projects new_repo_project repo_project /Cadene/pretrained-models.pytorch/projects\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g b\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-table UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z\"></path></svg>        <span data-content=\"Projects\">Projects</span>          <span id=\"projects-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"0\" hidden=\"hidden\" data-view-component=\"true\" class=\"Counter\">0</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"security-tab\" href=\"/Cadene/pretrained-models.pytorch/security\" data-tab-item=\"i5security-tab\" data-selected-links=\"security overview alerts policy token_scanning code_scanning /Cadene/pretrained-models.pytorch/security\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g s\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        <span data-content=\"Security\">Security</span>          <include-fragment src=\"/Cadene/pretrained-models.pytorch/security/overall-count\" accept=\"text/fragment+html\"></include-fragment>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"insights-tab\" href=\"/Cadene/pretrained-models.pytorch/pulse\" data-tab-item=\"i6insights-tab\" data-selected-links=\"repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /Cadene/pretrained-models.pytorch/pulse\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-graph UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg>        <span data-content=\"Insights\">Insights</span>          <span id=\"insights-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li></ul>    <div style=\"visibility:hidden;\" data-view-component=\"true\" class=\"UnderlineNav-actions js-responsive-underlinenav-overflow position-absolute pr-3 pr-md-4 pr-lg-5 right-0\">      <action-menu data-select-variant=\"none\" data-view-component=\"true\">  <focus-group direction=\"vertical\" mnemonics retain>    <button id=\"action-menu-44079cd7-cf81-4f86-aafe-f5540a7b4737-button\" popovertarget=\"action-menu-44079cd7-cf81-4f86-aafe-f5540a7b4737-overlay\" aria-controls=\"action-menu-44079cd7-cf81-4f86-aafe-f5540a7b4737-list\" aria-haspopup=\"true\" aria-labelledby=\"tooltip-40c99ce6-bbbf-4cc2-9b0d-922793105e3e\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--secondary Button--medium UnderlineNav-item\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-kebab-horizontal Button-visual\">    <path d=\"M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path></svg></button><tool-tip id=\"tooltip-40c99ce6-bbbf-4cc2-9b0d-922793105e3e\" for=\"action-menu-44079cd7-cf81-4f86-aafe-f5540a7b4737-button\" popover=\"manual\" data-direction=\"s\" data-type=\"label\" data-view-component=\"true\" class=\"sr-only position-absolute\">Additional navigation options</tool-tip><anchored-position id=\"action-menu-44079cd7-cf81-4f86-aafe-f5540a7b4737-overlay\" anchor=\"action-menu-44079cd7-cf81-4f86-aafe-f5540a7b4737-button\" align=\"start\" side=\"outside-bottom\" anchor-offset=\"normal\" popover=\"auto\" data-view-component=\"true\">  <div data-view-component=\"true\" class=\"Overlay Overlay--size-auto\">          <div data-view-component=\"true\" class=\"Overlay-body Overlay-body--paddingNone\">          <div data-view-component=\"true\">  <ul aria-labelledby=\"action-menu-44079cd7-cf81-4f86-aafe-f5540a7b4737-button\" id=\"action-menu-44079cd7-cf81-4f86-aafe-f5540a7b4737-list\" role=\"menu\" data-view-component=\"true\" class=\"ActionListWrap--inset ActionListWrap\">      <li hidden=\"hidden\" data-menu-item=\"i0code-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-c737ef59-03cd-43a2-bd52-7e9cc977eb1f\" href=\"/Cadene/pretrained-models.pytorch\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Code</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i1issues-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-ea72e9f8-86f1-4c6a-b76a-ccc62999cb0e\" href=\"/Cadene/pretrained-models.pytorch/issues\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Issues</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i2pull-requests-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-484bfaa3-3073-420b-9847-fa6f188dfda4\" href=\"/Cadene/pretrained-models.pytorch/pulls\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-pull-request\">    <path d=\"M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Pull requests</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i3actions-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-810f6105-eda1-4863-ac4d-eec1136eaeb2\" href=\"/Cadene/pretrained-models.pytorch/actions\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Actions</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i4projects-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-78b7435a-929d-425b-a882-9a1de4e50017\" href=\"/Cadene/pretrained-models.pytorch/projects\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-table\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Projects</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i5security-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-86e4ff21-629b-41d8-8e39-012a1cb2b11e\" href=\"/Cadene/pretrained-models.pytorch/security\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield\">    <path d=\"M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Security</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i6insights-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-7dd7d32d-816d-402f-8e38-676d8f85be8b\" href=\"/Cadene/pretrained-models.pytorch/pulse\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-graph\">    <path d=\"M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Insights</span></a>    </li></ul>  </div></div>      </div></anchored-position>  </focus-group></action-menu></div></nav>  </div>  <turbo-frame id=\"repo-content-turbo-frame\" target=\"_top\" data-turbo-action=\"advance\" class=\"\">    <div id=\"repo-content-pjax-container\" class=\"repository-content \" >                <h1 class='sr-only'>Cadene/pretrained-models.pytorch</h1>  <div class=\"clearfix container-xl px-md-4 px-lg-5 px-3\">    <div>  <div id=\"spoof-warning\" class=\"mt-0 pb-3\" hidden aria-hidden>  <div data-view-component=\"true\" class=\"flash flash-warn mt-0 clearfix\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert float-left mt-1\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>      <div class=\"overflow-hidden\">This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.</div>  </div></div>  <include-fragment src=\"/Cadene/pretrained-models.pytorch/spoofed_commit_check/8aae3d8f1135b6b13fed79c1d431e3449fdbf6e0\" data-test-selector=\"spoofed-commit-check\"></include-fragment>  <div style=\"max-width: 100%\" data-view-component=\"true\" class=\"Layout Layout--flowRow-until-md react-repos-overview-margin Layout--sidebarPosition-end Layout--sidebarPosition-flowRow-end\">  <div data-view-component=\"true\" class=\"Layout-main\">        <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/react-lib-1fbfc5be2c18.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_octicons-react_dist_index_esm_js-node_modules_primer_react_lib-es-2e8e7c-adc8451a70cf.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Box_Box_js-8f8c5e2a2cbf.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Button_Button_js-67fe00b5266a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_ActionList_index_js-2dd4d13d3ae6.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Overlay_Overlay_js-node_modules_primer_react_lib-es-fa1130-829932cf63db.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Text_Text_js-node_modules_primer_react_lib-esm_Text-85a14b-236dc9716ad0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_ActionMenu_ActionMenu_js-eaf74522e470.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_react-router-dom_dist_index_js-3b41341d50fe.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Dialog_js-node_modules_primer_react_lib-esm_Label_L-857e1c-77794958a54a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_UnderlineNav_index_js-89fa5806aa3c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_AvatarStack_AvatarStack_js-node_modules_primer_reac-e445e7-175b51e43dcc.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_react-core_create-browser-history_ts-ui_packages_react-core_AppContextProvider_ts-809ab9-bf008735d0bb.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_paths_index_ts-7137b25aa38b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_ref-selector_RefSelector_tsx-dbbdef4348e2.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_commit-attribution_index_ts-ui_packages_commit-checks-status_index_ts-ui_packages-ffbe33-4c4ddf7d268d.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_react-code-view_components_directory_DirectoryContent_index_ts-app_assets_-1fd1f5-c96303590595.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/repos-overview-523b8f59ec33.js\"></script><react-partial  partial-name=\"repos-overview\"  data-ssr=\"true\">    <script type=\"application/json\" data-target=\"react-partial.embeddedData\">{\"props\":{\"initialPayload\":{\"allShortcutsEnabled\":false,\"path\":\"/\",\"repo\":{\"id\":87720287,\"defaultBranch\":\"master\",\"name\":\"pretrained-models.pytorch\",\"ownerLogin\":\"Cadene\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2017-04-09T15:54:23.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/4681518?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":false},\"currentUser\":null,\"refInfo\":{\"name\":\"master\",\"listCacheKey\":\"v0:1512033190.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"8aae3d8f1135b6b13fed79c1d431e3449fdbf6e0\"},\"tree\":{\"items\":[{\"name\":\"data\",\"path\":\"data\",\"contentType\":\"directory\"},{\"name\":\"examples\",\"path\":\"examples\",\"contentType\":\"directory\"},{\"name\":\"pretrainedmodels\",\"path\":\"pretrainedmodels\",\"contentType\":\"directory\"},{\"name\":\"tests\",\"path\":\"tests\",\"contentType\":\"directory\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\".travis.yml\",\"path\":\".travis.yml\",\"contentType\":\"file\"},{\"name\":\"LICENSE.txt\",\"path\":\"LICENSE.txt\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"requirements.txt\",\"path\":\"requirements.txt\",\"contentType\":\"file\"},{\"name\":\"setup.cfg\",\"path\":\"setup.cfg\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"}],\"templateDirectorySuggestionUrl\":null,\"readme\":null,\"totalCount\":11,\"showBranchInfobar\":false},\"fileTree\":null,\"fileTreeProcessingTime\":null,\"foldersToFetch\":[],\"treeExpanded\":false,\"symbolsExpanded\":false,\"isOverview\":true,\"overview\":{\"banners\":{\"shouldRecommendReadme\":false,\"isPersonalRepo\":false,\"showUseActionBanner\":false,\"actionSlug\":null,\"actionId\":null,\"showProtectBranchBanner\":false,\"recentlyTouchedDataChannel\":null,\"publishBannersInfo\":{\"dismissActionNoticePath\":\"/settings/dismiss-notice/publish_action_from_repo\",\"releasePath\":\"/Cadene/pretrained-models.pytorch/releases/new?marketplace=true\",\"showPublishActionBanner\":false},\"interactionLimitBanner\":null,\"showInvitationBanner\":false,\"inviterName\":null},\"codeButton\":{\"contactPath\":\"/contact\",\"isEnterprise\":false,\"local\":{\"protocolInfo\":{\"httpAvailable\":true,\"sshAvailable\":null,\"httpUrl\":\"https://github.com/Cadene/pretrained-models.pytorch.git\",\"showCloneWarning\":null,\"sshUrl\":null,\"sshCertificatesRequired\":null,\"sshCertificatesAvailable\":null,\"ghCliUrl\":\"gh repo clone Cadene/pretrained-models.pytorch\",\"defaultProtocol\":\"http\",\"newSshKeyUrl\":\"/settings/ssh/new\",\"setProtocolPath\":\"/users/set_protocol\"},\"platformInfo\":{\"cloneUrl\":\"https://desktop.github.com\",\"showVisualStudioCloneButton\":false,\"visualStudioCloneUrl\":\"https://windows.github.com\",\"showXcodeCloneButton\":false,\"xcodeCloneUrl\":\"https://developer.apple.com\",\"zipballUrl\":\"/Cadene/pretrained-models.pytorch/archive/refs/heads/master.zip\"}},\"newCodespacePath\":\"/codespaces/new?hide_repo_select=true\\u0026repo=87720287\"},\"popovers\":{\"rename\":null,\"renamedParentRepo\":null},\"commitCount\":\"154\",\"overviewFiles\":[{\"displayName\":\"README.md\",\"repoName\":\"pretrained-models.pytorch\",\"refName\":\"master\",\"path\":\"README.md\",\"preferredFileType\":\"readme\",\"tabName\":\"README\",\"richText\":\"\\u003carticle class=\\\"markdown-body entry-content container-lg\\\" itemprop=\\\"text\\\"\\u003e\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch1 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003ePretrained models for Pytorch (Work in progress)\\u003c/h1\\u003e\\u003ca id=\\\"user-content-pretrained-models-for-pytorch-work-in-progress\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Pretrained models for Pytorch (Work in progress)\\\" href=\\\"#pretrained-models-for-pytorch-work-in-progress\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe goal of this repo is:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eto help to reproduce research papers results (transfer learning setups for instance),\\u003c/li\\u003e\\n\\u003cli\\u003eto access pretrained ConvNets with a unique interface/API inspired by torchvision.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca href=\\\"https://travis-ci.org/Cadene/pretrained-models.pytorch\\\" rel=\\\"nofollow\\\"\\u003e\\u003cimg src=\\\"https://camo.githubusercontent.com/b744495d00a078e34957dc310b0cb746223f5f7c562acc4806a80d285b62b2a0/68747470733a2f2f6170692e7472617669732d63692e6f72672f436164656e652f707265747261696e65642d6d6f64656c732e7079746f7263682e7376673f6272616e63683d6d6173746572\\\" data-canonical-src=\\\"https://api.travis-ci.org/Cadene/pretrained-models.pytorch.svg?branch=master\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eNews:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e27/10/2018: Fix compatibility issues, Add tests, Add travis\\u003c/li\\u003e\\n\\u003cli\\u003e04/06/2018: \\u003ca href=\\\"https://github.com/CUHK-MMLAB/polynet\\\"\\u003ePolyNet\\u003c/a\\u003e and \\u003ca href=\\\"https://arxiv.org/abs/1712.00559\\\" rel=\\\"nofollow\\\"\\u003ePNASNet-5-Large\\u003c/a\\u003e thanks to \\u003ca href=\\\"https://github.com/creafz\\\"\\u003eAlex Parinov\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e16/04/2018: \\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eSE-ResNet* and SE-ResNeXt*\\u003c/a\\u003e thanks to \\u003ca href=\\\"https://github.com/creafz\\\"\\u003eAlex Parinov\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e09/04/2018: \\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eSENet154\\u003c/a\\u003e thanks to \\u003ca href=\\\"https://github.com/creafz\\\"\\u003eAlex Parinov\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e22/03/2018: CaffeResNet101 (good for localization with FasterRCNN)\\u003c/li\\u003e\\n\\u003cli\\u003e21/03/2018: NASNet Mobile thanks to \\u003ca href=\\\"https://github.com/veronikayurchuk\\\"\\u003eVeronika Yurchuk\\u003c/a\\u003e and \\u003ca href=\\\"https://github.com/DagnyT\\\"\\u003eAnastasiia\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e25/01/2018: DualPathNetworks thanks to \\u003ca href=\\\"https://github.com/rwightman/pytorch-dpn-pretrained\\\"\\u003eRoss Wightman\\u003c/a\\u003e, Xception thanks to \\u003ca href=\\\"https://github.com/tstandley/Xception-PyTorch\\\"\\u003eT Standley\\u003c/a\\u003e, improved TransformImage API\\u003c/li\\u003e\\n\\u003cli\\u003e13/01/2018: \\u003ccode\\u003epip install pretrainedmodels\\u003c/code\\u003e, \\u003ccode\\u003epretrainedmodels.model_names\\u003c/code\\u003e, \\u003ccode\\u003epretrainedmodels.pretrained_settings\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e12/01/2018: \\u003ccode\\u003epython setup.py install\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e08/12/2017: update data url (/!\\\\ \\u003ccode\\u003egit pull\\u003c/code\\u003e is needed)\\u003c/li\\u003e\\n\\u003cli\\u003e30/11/2017: improve API (\\u003ccode\\u003emodel.features(input)\\u003c/code\\u003e, \\u003ccode\\u003emodel.logits(features)\\u003c/code\\u003e, \\u003ccode\\u003emodel.forward(input)\\u003c/code\\u003e, \\u003ccode\\u003emodel.last_linear\\u003c/code\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003e16/11/2017: nasnet-a-large pretrained model ported by T. Durand and R. Cadene\\u003c/li\\u003e\\n\\u003cli\\u003e22/07/2017: torchvision pretrained models\\u003c/li\\u003e\\n\\u003cli\\u003e22/07/2017: momentum in inceptionv4 and inceptionresnetv2 to 0.1\\u003c/li\\u003e\\n\\u003cli\\u003e17/07/2017: model.input_range attribut\\u003c/li\\u003e\\n\\u003cli\\u003e17/07/2017: BNInception pretrained on Imagenet\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eSummary\\u003c/h2\\u003e\\u003ca id=\\\"user-content-summary\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Summary\\\" href=\\\"#summary\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#installation\\\"\\u003eInstallation\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#quick-examples\\\"\\u003eQuick examples\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#few-use-cases\\\"\\u003eFew use cases\\u003c/a\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#compute-imagenet-logits\\\"\\u003eCompute imagenet logits\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#compute-imagenet-validation-metrics\\\"\\u003eCompute imagenet validation metrics\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#evaluation-on-imagenet\\\"\\u003eEvaluation on ImageNet\\u003c/a\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#accuracy-on-validation-set\\\"\\u003eAccuracy on valset\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#reproducing-results\\\"\\u003eReproducing results\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#documentation\\\"\\u003eDocumentation\\u003c/a\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#available-models\\\"\\u003eAvailable models\\u003c/a\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eAlexNet\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#bninception\\\"\\u003eBNInception\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#caffe-resnet\\\"\\u003eCaffeResNet101\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet121\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet161\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet169\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet201\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet201\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet68\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet92\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet98\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet107\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet113\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet\\\"\\u003eFBResNet152\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#inception\\\"\\u003eInceptionResNetV2\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#inception\\\"\\u003eInceptionV3\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#inception\\\"\\u003eInceptionV4\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#nasnet\\\"\\u003eNASNet-A-Large\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#nasnet\\\"\\u003eNASNet-A-Mobile\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#pnasnet\\\"\\u003ePNASNet-5-Large\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#polynet\\\"\\u003ePolyNet\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#resnext\\\"\\u003eResNeXt101_32x4d\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#resnext\\\"\\u003eResNeXt101_64x4d\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet101\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet152\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet18\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet34\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet50\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSENet154\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNet50\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNet101\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNet152\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNeXt50_32x4d\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNeXt101_32x4d\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eSqueezeNet1_0\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eSqueezeNet1_1\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG11\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG13\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG16\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG19\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG11_BN\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG13_BN\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG16_BN\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG19_BN\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#xception\\\"\\u003eXception\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#model-api\\\"\\u003eModel API\\u003c/a\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#modelinput_size\\\"\\u003emodel.input_size\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#modelinput_space\\\"\\u003emodel.input_space\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#modelinput_range\\\"\\u003emodel.input_range\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#modelmean\\\"\\u003emodel.mean\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#modelstd\\\"\\u003emodel.std\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#modelfeatures\\\"\\u003emodel.features\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#modellogits\\\"\\u003emodel.logits\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#modelforward\\\"\\u003emodel.forward\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#reproducing\\\"\\u003eReproducing porting\\u003c/a\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#hand-porting-of-resnet152\\\"\\u003eResNet*\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#automatic-porting-of-resnext\\\"\\u003eResNeXt*\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#hand-porting-of-inceptionv4-and-inceptionresnetv2\\\"\\u003eInception*\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eInstallation\\u003c/h2\\u003e\\u003ca id=\\\"user-content-installation\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Installation\\\" href=\\\"#installation\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003col dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://www.continuum.io/downloads\\\" rel=\\\"nofollow\\\"\\u003epython3 with anaconda\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"http://pytorch.org\\\" rel=\\\"nofollow\\\"\\u003epytorch with/out CUDA\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ol\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eInstall from pip\\u003c/h3\\u003e\\u003ca id=\\\"user-content-install-from-pip\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Install from pip\\\" href=\\\"#install-from-pip\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003col start=\\\"3\\\" dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003epip install pretrainedmodels\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ol\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eInstall from repo\\u003c/h3\\u003e\\u003ca id=\\\"user-content-install-from-repo\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Install from repo\\\" href=\\\"#install-from-repo\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003col start=\\\"3\\\" dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003egit clone https://github.com/Cadene/pretrained-models.pytorch.git\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ecd pretrained-models.pytorch\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003epython setup.py install\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ol\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eQuick examples\\u003c/h2\\u003e\\u003ca id=\\\"user-content-quick-examples\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Quick examples\\\" href=\\\"#quick-examples\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eTo import \\u003ccode\\u003epretrainedmodels\\u003c/code\\u003e:\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"import pretrainedmodels\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-k\\\"\\u003eimport\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003epretrainedmodels\\u003c/span\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eTo print the available pretrained models:\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"print(pretrainedmodels.model_names)\\n\\u0026gt; ['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetalarge', 'nasnetamobile', 'cafferesnet101', 'senet154',  'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'polynet', 'pnasnet5large']\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003epretrainedmodels\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003emodel_names\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-c1\\\"\\u003e\\u0026gt;\\u003c/span\\u003e [\\u003cspan class=\\\"pl-s\\\"\\u003e'fbresnet152'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'bninception'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'resnext101_32x4d'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'resnext101_64x4d'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'inceptionv4'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'inceptionresnetv2'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'alexnet'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'densenet121'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'densenet169'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'densenet201'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'densenet161'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'resnet18'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'resnet34'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'resnet50'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'resnet101'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'resnet152'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'inceptionv3'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'squeezenet1_0'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'squeezenet1_1'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'vgg11'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'vgg11_bn'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'vgg13'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'vgg13_bn'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'vgg16'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'vgg16_bn'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'vgg19_bn'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'vgg19'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'nasnetalarge'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'nasnetamobile'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'cafferesnet101'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'senet154'\\u003c/span\\u003e,  \\u003cspan class=\\\"pl-s\\\"\\u003e'se_resnet50'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'se_resnet101'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'se_resnet152'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'se_resnext50_32x4d'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'se_resnext101_32x4d'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'cafferesnet101'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'polynet'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'pnasnet5large'\\u003c/span\\u003e]\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eTo print the available pretrained settings for a chosen model:\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"print(pretrainedmodels.pretrained_settings['nasnetalarge'])\\n\\u0026gt; {'imagenet': {'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth', 'input_space': 'RGB', 'input_size': [3, 331, 331], 'input_range': [0, 1], 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'num_classes': 1000}, 'imagenet+background': {'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth', 'input_space': 'RGB', 'input_size': [3, 331, 331], 'input_range': [0, 1], 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'num_classes': 1001}}\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003epretrainedmodels\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003epretrained_settings\\u003c/span\\u003e[\\u003cspan class=\\\"pl-s\\\"\\u003e'nasnetalarge'\\u003c/span\\u003e])\\n\\u003cspan class=\\\"pl-c1\\\"\\u003e\\u0026gt;\\u003c/span\\u003e {\\u003cspan class=\\\"pl-s\\\"\\u003e'imagenet'\\u003c/span\\u003e: {\\u003cspan class=\\\"pl-s\\\"\\u003e'url'\\u003c/span\\u003e: \\u003cspan class=\\\"pl-s\\\"\\u003e'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'input_space'\\u003c/span\\u003e: \\u003cspan class=\\\"pl-s\\\"\\u003e'RGB'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'input_size'\\u003c/span\\u003e: [\\u003cspan class=\\\"pl-c1\\\"\\u003e3\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e331\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e331\\u003c/span\\u003e], \\u003cspan class=\\\"pl-s\\\"\\u003e'input_range'\\u003c/span\\u003e: [\\u003cspan class=\\\"pl-c1\\\"\\u003e0\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e1\\u003c/span\\u003e], \\u003cspan class=\\\"pl-s\\\"\\u003e'mean'\\u003c/span\\u003e: [\\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e], \\u003cspan class=\\\"pl-s\\\"\\u003e'std'\\u003c/span\\u003e: [\\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e], \\u003cspan class=\\\"pl-s\\\"\\u003e'num_classes'\\u003c/span\\u003e: \\u003cspan class=\\\"pl-c1\\\"\\u003e1000\\u003c/span\\u003e}, \\u003cspan class=\\\"pl-s\\\"\\u003e'imagenet+background'\\u003c/span\\u003e: {\\u003cspan class=\\\"pl-s\\\"\\u003e'url'\\u003c/span\\u003e: \\u003cspan class=\\\"pl-s\\\"\\u003e'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'input_space'\\u003c/span\\u003e: \\u003cspan class=\\\"pl-s\\\"\\u003e'RGB'\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s\\\"\\u003e'input_size'\\u003c/span\\u003e: [\\u003cspan class=\\\"pl-c1\\\"\\u003e3\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e331\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e331\\u003c/span\\u003e], \\u003cspan class=\\\"pl-s\\\"\\u003e'input_range'\\u003c/span\\u003e: [\\u003cspan class=\\\"pl-c1\\\"\\u003e0\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e1\\u003c/span\\u003e], \\u003cspan class=\\\"pl-s\\\"\\u003e'mean'\\u003c/span\\u003e: [\\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e], \\u003cspan class=\\\"pl-s\\\"\\u003e'std'\\u003c/span\\u003e: [\\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e, \\u003cspan class=\\\"pl-c1\\\"\\u003e0.5\\u003c/span\\u003e], \\u003cspan class=\\\"pl-s\\\"\\u003e'num_classes'\\u003c/span\\u003e: \\u003cspan class=\\\"pl-c1\\\"\\u003e1001\\u003c/span\\u003e}}\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eTo load a pretrained models from imagenet:\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"model_name = 'nasnetalarge' # could be fbresnet152 or inceptionresnetv2\\nmodel = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\\nmodel.eval()\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-s1\\\"\\u003emodel_name\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s\\\"\\u003e'nasnetalarge'\\u003c/span\\u003e \\u003cspan class=\\\"pl-c\\\"\\u003e# could be fbresnet152 or inceptionresnetv2\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003epretrainedmodels\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003e__dict__\\u003c/span\\u003e[\\u003cspan class=\\\"pl-s1\\\"\\u003emodel_name\\u003c/span\\u003e](\\u003cspan class=\\\"pl-s1\\\"\\u003enum_classes\\u003c/span\\u003e\\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e\\u003cspan class=\\\"pl-c1\\\"\\u003e1000\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s1\\\"\\u003epretrained\\u003c/span\\u003e\\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e\\u003cspan class=\\\"pl-s\\\"\\u003e'imagenet'\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003eeval\\u003c/span\\u003e()\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003cstrong\\u003eNote\\u003c/strong\\u003e: By default, models will be downloaded to your \\u003ccode\\u003e$HOME/.torch\\u003c/code\\u003e folder. You can modify this behavior using the \\u003ccode\\u003e$TORCH_HOME\\u003c/code\\u003e variable as follow: \\u003ccode\\u003eexport TORCH_HOME=\\\"/local/pretrainedmodels\\\"\\u003c/code\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eTo load an image and do a complete forward pass:\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"import torch\\nimport pretrainedmodels.utils as utils\\n\\nload_img = utils.LoadImage()\\n\\n# transformations depending on the model\\n#\u00a0rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)\\ntf_img = utils.TransformImage(model) \\n\\npath_img = 'data/cat.jpg'\\n\\ninput_img = load_img(path_img)\\ninput_tensor = tf_img(input_img)         # 3x400x225 -\\u0026gt; 3x299x299 size may differ\\ninput_tensor = input_tensor.unsqueeze(0) # 3x299x299 -\\u0026gt; 1x3x299x299\\ninput = torch.autograd.Variable(input_tensor,\\n    requires_grad=False)\\n\\noutput_logits = model(input) # 1x1000\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-k\\\"\\u003eimport\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003etorch\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-k\\\"\\u003eimport\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003epretrainedmodels\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003eutils\\u003c/span\\u003e \\u003cspan class=\\\"pl-k\\\"\\u003eas\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003eutils\\u003c/span\\u003e\\n\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eload_img\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003eutils\\u003c/span\\u003e.\\u003cspan class=\\\"pl-v\\\"\\u003eLoadImage\\u003c/span\\u003e()\\n\\n\\u003cspan class=\\\"pl-c\\\"\\u003e# transformations depending on the model\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-c\\\"\\u003e#\u00a0rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003etf_img\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003eutils\\u003c/span\\u003e.\\u003cspan class=\\\"pl-v\\\"\\u003eTransformImage\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e) \\n\\n\\u003cspan class=\\\"pl-s1\\\"\\u003epath_img\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s\\\"\\u003e'data/cat.jpg'\\u003c/span\\u003e\\n\\n\\u003cspan class=\\\"pl-s1\\\"\\u003einput_img\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-en\\\"\\u003eload_img\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003epath_img\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-s1\\\"\\u003einput_tensor\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-en\\\"\\u003etf_img\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_img\\u003c/span\\u003e)         \\u003cspan class=\\\"pl-c\\\"\\u003e# 3x400x225 -\\u0026gt; 3x299x299 size may differ\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003einput_tensor\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003einput_tensor\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003eunsqueeze\\u003c/span\\u003e(\\u003cspan class=\\\"pl-c1\\\"\\u003e0\\u003c/span\\u003e) \\u003cspan class=\\\"pl-c\\\"\\u003e# 3x299x299 -\\u0026gt; 1x3x299x299\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003einput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003etorch\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003eautograd\\u003c/span\\u003e.\\u003cspan class=\\\"pl-v\\\"\\u003eVariable\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_tensor\\u003c/span\\u003e,\\n    \\u003cspan class=\\\"pl-s1\\\"\\u003erequires_grad\\u003c/span\\u003e\\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e\\u003cspan class=\\\"pl-c1\\\"\\u003eFalse\\u003c/span\\u003e)\\n\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput_logits\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-en\\\"\\u003emodel\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput\\u003c/span\\u003e) \\u003cspan class=\\\"pl-c\\\"\\u003e# 1x1000\\u003c/span\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eTo extract features (beware this API is not available for all networks):\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"output_features = model.features(input) # 1x14x14x2048 size may differ\\noutput_logits = model.logits(output_features) # 1x1000\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput_features\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003efeatures\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput\\u003c/span\\u003e) \\u003cspan class=\\\"pl-c\\\"\\u003e# 1x14x14x2048 size may differ\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput_logits\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003elogits\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput_features\\u003c/span\\u003e) \\u003cspan class=\\\"pl-c\\\"\\u003e# 1x1000\\u003c/span\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFew use cases\\u003c/h2\\u003e\\u003ca id=\\\"user-content-few-use-cases\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Few use cases\\\" href=\\\"#few-use-cases\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCompute imagenet logits\\u003c/h3\\u003e\\u003ca id=\\\"user-content-compute-imagenet-logits\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Compute imagenet logits\\\" href=\\\"#compute-imagenet-logits\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eSee \\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch/blob/master/examples/imagenet_logits.py\\\"\\u003eexamples/imagenet_logits.py\\u003c/a\\u003e to compute logits of classes appearance over a single image with a pretrained model on imagenet.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"$ python examples/imagenet_logits.py -h\\n\\u0026gt; nasnetalarge, resnet152, inceptionresnetv2, inceptionv4, ...\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003e$ python examples/imagenet_logits.py -h\\n\\u0026gt; nasnetalarge, resnet152, inceptionresnetv2, inceptionv4, ...\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"$ python examples/imagenet_logits.py -a nasnetalarge --path_img data/cat.jpg\\n\\u0026gt; 'nasnetalarge': data/cat.jpg' is a 'tiger cat' \\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003e$ python examples/imagenet_logits.py -a nasnetalarge --path_img data/cat.jpg\\n\\u0026gt; 'nasnetalarge': data/cat.jpg' is a 'tiger cat' \\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCompute imagenet evaluation metrics\\u003c/h3\\u003e\\u003ca id=\\\"user-content-compute-imagenet-evaluation-metrics\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Compute imagenet evaluation metrics\\\" href=\\\"#compute-imagenet-evaluation-metrics\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eSee \\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch/blob/master/examples/imagenet_eval.py\\\"\\u003eexamples/imagenet_eval.py\\u003c/a\\u003e to evaluate pretrained models on imagenet valset.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"$ python examples/imagenet_eval.py /local/common-data/imagenet_2012/images -a nasnetalarge -b 20 -e\\n\\u0026gt; * Acc@1 82.693, Acc@5 96.13\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003e$ python examples/imagenet_eval.py /local/common-data/imagenet_2012/images -a nasnetalarge -b 20 -e\\n\\u0026gt; * Acc@1 82.693, Acc@5 96.13\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eEvaluation on imagenet\\u003c/h2\\u003e\\u003ca id=\\\"user-content-evaluation-on-imagenet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Evaluation on imagenet\\\" href=\\\"#evaluation-on-imagenet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAccuracy on validation set (single model)\\u003c/h3\\u003e\\u003ca id=\\\"user-content-accuracy-on-validation-set-single-model\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Accuracy on validation set (single model)\\\" href=\\\"#accuracy-on-validation-set-single-model\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eResults were obtained using (center cropped) images of the same size than during the training process.\\u003c/p\\u003e\\n\\u003ctable\\u003e\\n\\u003cthead\\u003e\\n\\u003ctr\\u003e\\n\\u003cth\\u003eModel\\u003c/th\\u003e\\n\\u003cth\\u003eVersion\\u003c/th\\u003e\\n\\u003cth\\u003eAcc@1\\u003c/th\\u003e\\n\\u003cth\\u003eAcc@5\\u003c/th\\u003e\\n\\u003c/tr\\u003e\\n\\u003c/thead\\u003e\\n\\u003ctbody\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003ePNASNet-5-Large\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/tensorflow/models/tree/master/research/slim\\\"\\u003eTensorflow\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e82.858\\u003c/td\\u003e\\n\\u003ctd\\u003e96.182\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#pnasnet\\\"\\u003ePNASNet-5-Large\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e82.736\\u003c/td\\u003e\\n\\u003ctd\\u003e95.992\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eNASNet-A-Large\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/tensorflow/models/tree/master/research/slim\\\"\\u003eTensorflow\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e82.693\\u003c/td\\u003e\\n\\u003ctd\\u003e96.163\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#nasnet\\\"\\u003eNASNet-A-Large\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e82.566\\u003c/td\\u003e\\n\\u003ctd\\u003e96.086\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eSENet154\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eCaffe\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e81.32\\u003c/td\\u003e\\n\\u003ctd\\u003e95.53\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSENet154\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e81.304\\u003c/td\\u003e\\n\\u003ctd\\u003e95.498\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003ePolyNet\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/CUHK-MMLAB/polynet\\\"\\u003eCaffe\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e81.29\\u003c/td\\u003e\\n\\u003ctd\\u003e95.75\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#polynet\\\"\\u003ePolyNet\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e81.002\\u003c/td\\u003e\\n\\u003ctd\\u003e95.624\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eInceptionResNetV2\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/tensorflow/models/tree/master/slim\\\"\\u003eTensorflow\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e80.4\\u003c/td\\u003e\\n\\u003ctd\\u003e95.3\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eInceptionV4\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/tensorflow/models/tree/master/slim\\\"\\u003eTensorflow\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e80.2\\u003c/td\\u003e\\n\\u003ctd\\u003e95.3\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNeXt101_32x4d\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e80.236\\u003c/td\\u003e\\n\\u003ctd\\u003e95.028\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eSE-ResNeXt101_32x4d\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eCaffe\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e80.19\\u003c/td\\u003e\\n\\u003ctd\\u003e95.04\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#inception\\\"\\u003eInceptionResNetV2\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e80.170\\u003c/td\\u003e\\n\\u003ctd\\u003e95.234\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#inception\\\"\\u003eInceptionV4\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e80.062\\u003c/td\\u003e\\n\\u003ctd\\u003e94.926\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet107_5k\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e79.746\\u003c/td\\u003e\\n\\u003ctd\\u003e94.684\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eResNeXt101_64x4d\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/facebookresearch/ResNeXt\\\"\\u003eTorch7\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e79.6\\u003c/td\\u003e\\n\\u003ctd\\u003e94.7\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet131\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e79.432\\u003c/td\\u003e\\n\\u003ctd\\u003e94.574\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet92_5k\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e79.400\\u003c/td\\u003e\\n\\u003ctd\\u003e94.620\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet98\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e79.224\\u003c/td\\u003e\\n\\u003ctd\\u003e94.488\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNeXt50_32x4d\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e79.076\\u003c/td\\u003e\\n\\u003ctd\\u003e94.434\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eSE-ResNeXt50_32x4d\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eCaffe\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e79.03\\u003c/td\\u003e\\n\\u003ctd\\u003e94.46\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#xception\\\"\\u003eXception\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/keras-team/keras/blob/master/keras/applications/xception.py\\\"\\u003eKeras\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e79.000\\u003c/td\\u003e\\n\\u003ctd\\u003e94.500\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#resnext\\\"\\u003eResNeXt101_64x4d\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e78.956\\u003c/td\\u003e\\n\\u003ctd\\u003e94.252\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#xception\\\"\\u003eXception\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e78.888\\u003c/td\\u003e\\n\\u003ctd\\u003e94.292\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eResNeXt101_32x4d\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/facebookresearch/ResNeXt\\\"\\u003eTorch7\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e78.8\\u003c/td\\u003e\\n\\u003ctd\\u003e94.4\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eSE-ResNet152\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eCaffe\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e78.66\\u003c/td\\u003e\\n\\u003ctd\\u003e94.46\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNet152\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e78.658\\u003c/td\\u003e\\n\\u003ctd\\u003e94.374\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eResNet152\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e78.428\\u003c/td\\u003e\\n\\u003ctd\\u003e94.110\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNet101\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e78.396\\u003c/td\\u003e\\n\\u003ctd\\u003e94.258\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eSE-ResNet101\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eCaffe\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e78.25\\u003c/td\\u003e\\n\\u003ctd\\u003e94.28\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#resnext\\\"\\u003eResNeXt101_32x4d\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e78.188\\u003c/td\\u003e\\n\\u003ctd\\u003e93.886\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eFBResNet152\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/facebook/fb.resnet.torch\\\"\\u003eTorch7\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e77.84\\u003c/td\\u003e\\n\\u003ctd\\u003e93.84\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eSE-ResNet50\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eCaffe\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e77.63\\u003c/td\\u003e\\n\\u003ctd\\u003e93.64\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#senet\\\"\\u003eSE-ResNet50\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e77.636\\u003c/td\\u003e\\n\\u003ctd\\u003e93.752\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet161\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e77.560\\u003c/td\\u003e\\n\\u003ctd\\u003e93.798\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet101\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e77.438\\u003c/td\\u003e\\n\\u003ctd\\u003e93.672\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet\\\"\\u003eFBResNet152\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e77.386\\u003c/td\\u003e\\n\\u003ctd\\u003e93.594\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#inception\\\"\\u003eInceptionV3\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e77.294\\u003c/td\\u003e\\n\\u003ctd\\u003e93.454\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet201\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e77.152\\u003c/td\\u003e\\n\\u003ctd\\u003e93.548\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet68b_5k\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e77.034\\u003c/td\\u003e\\n\\u003ctd\\u003e93.590\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#caffe-resnet\\\"\\u003eCaffeResnet101\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/KaimingHe/deep-residual-networks\\\"\\u003eCaffe\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e76.400\\u003c/td\\u003e\\n\\u003ctd\\u003e92.900\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#caffe-resnet\\\"\\u003eCaffeResnet101\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e76.200\\u003c/td\\u003e\\n\\u003ctd\\u003e92.766\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet169\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e76.026\\u003c/td\\u003e\\n\\u003ctd\\u003e92.992\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet50\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e76.002\\u003c/td\\u003e\\n\\u003ctd\\u003e92.980\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\\\"\\u003eDualPathNet68\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e75.868\\u003c/td\\u003e\\n\\u003ctd\\u003e92.774\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eDenseNet121\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e74.646\\u003c/td\\u003e\\n\\u003ctd\\u003e92.136\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG19_BN\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e74.266\\u003c/td\\u003e\\n\\u003ctd\\u003e92.066\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eNASNet-A-Mobile\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/tensorflow/models/tree/master/research/slim\\\"\\u003eTensorflow\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e74.0\\u003c/td\\u003e\\n\\u003ctd\\u003e91.6\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/veronikayurchuk/pretrained-models.pytorch/blob/master/pretrainedmodels/models/nasnet_mobile.py\\\"\\u003eNASNet-A-Mobile\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e74.080\\u003c/td\\u003e\\n\\u003ctd\\u003e91.740\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet34\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e73.554\\u003c/td\\u003e\\n\\u003ctd\\u003e91.456\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#bninception\\\"\\u003eBNInception\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003eOur porting\\u003c/td\\u003e\\n\\u003ctd\\u003e73.524\\u003c/td\\u003e\\n\\u003ctd\\u003e91.562\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG16_BN\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e73.518\\u003c/td\\u003e\\n\\u003ctd\\u003e91.608\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG19\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e72.080\\u003c/td\\u003e\\n\\u003ctd\\u003e90.822\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG16\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e71.636\\u003c/td\\u003e\\n\\u003ctd\\u003e90.354\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG13_BN\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e71.508\\u003c/td\\u003e\\n\\u003ctd\\u003e90.494\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG11_BN\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e70.452\\u003c/td\\u003e\\n\\u003ctd\\u003e89.818\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eResNet18\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e70.142\\u003c/td\\u003e\\n\\u003ctd\\u003e89.274\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG13\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e69.662\\u003c/td\\u003e\\n\\u003ctd\\u003e89.264\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eVGG11\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e68.970\\u003c/td\\u003e\\n\\u003ctd\\u003e88.746\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eSqueezeNet1_1\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e58.250\\u003c/td\\u003e\\n\\u003ctd\\u003e80.800\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eSqueezeNet1_0\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e58.108\\u003c/td\\u003e\\n\\u003ctd\\u003e80.428\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\\\"\\u003eAlexnet\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://github.com/pytorch/vision#models\\\"\\u003ePytorch\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e56.432\\u003c/td\\u003e\\n\\u003ctd\\u003e79.194\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003c/tbody\\u003e\\n\\u003c/table\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eNotes:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003ethe Pytorch version of ResNet152 is not a porting of the Torch7 but has been retrained by facebook.\\u003c/li\\u003e\\n\\u003cli\\u003eFor the PolyNet evaluation each image was resized to 378x378 without preserving the aspect ratio and then the central 331\u00d7331 patch from the resulting image was used.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eBeware, the accuracy reported here is not always representative of the transferable capacity of the network on other tasks and datasets. You must try them all! :P\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eReproducing results\\u003c/h3\\u003e\\u003ca id=\\\"user-content-reproducing-results\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Reproducing results\\\" href=\\\"#reproducing-results\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003ePlease see \\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#compute-imagenet-validation-metrics\\\"\\u003eCompute imagenet validation metrics\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eDocumentation\\u003c/h2\\u003e\\u003ca id=\\\"user-content-documentation\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Documentation\\\" href=\\\"#documentation\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAvailable models\\u003c/h3\\u003e\\u003ca id=\\\"user-content-available-models\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Available models\\\" href=\\\"#available-models\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eNASNet*\\u003c/h4\\u003e\\u003ca id=\\\"user-content-nasnet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: NASNet*\\\" href=\\\"#nasnet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/tensorflow/models/tree/master/research/slim\\\"\\u003eTensorFlow Slim repo\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003enasnetalarge(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003enasnetalarge(num_classes=1001, pretrained='imagenet+background')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003enasnetamobile(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFaceBook ResNet*\\u003c/h4\\u003e\\u003ca id=\\\"user-content-facebook-resnet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: FaceBook ResNet*\\\" href=\\\"#facebook-resnet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/facebook/fb.resnet.torch\\\"\\u003eTorch7 repo of FaceBook\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThere are a bit different from the ResNet* of torchvision. ResNet152 is currently the only one available.\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003efbresnet152(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCaffe ResNet*\\u003c/h4\\u003e\\u003ca id=\\\"user-content-caffe-resnet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Caffe ResNet*\\\" href=\\\"#caffe-resnet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/KaimingHe/deep-residual-networks\\\"\\u003eCaffe repo of KaimingHe\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ecafferesnet101(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eInception*\\u003c/h4\\u003e\\u003ca id=\\\"user-content-inception\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Inception*\\\" href=\\\"#inception\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/tensorflow/models/tree/master/slim\\\"\\u003eTensorFlow Slim repo\\u003c/a\\u003e and \\u003ca href=\\\"https://github.com/pytorch/vision/tree/master/torchvision\\\"\\u003ePytorch/Vision repo\\u003c/a\\u003e for \\u003ccode\\u003einceptionv3\\u003c/code\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003einceptionresnetv2(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003einceptionresnetv2(num_classes=1001, pretrained='imagenet+background')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003einceptionv4(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003einceptionv4(num_classes=1001, pretrained='imagenet+background')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003einceptionv3(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eBNInception\\u003c/h4\\u003e\\u003ca id=\\\"user-content-bninception\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: BNInception\\\" href=\\\"#bninception\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/Cadene/tensorflow-model-zoo.torch/pull/2\\\" data-hovercard-type=\\\"pull_request\\\" data-hovercard-url=\\\"/Cadene/tensorflow-model-zoo.torch/pull/2/hovercard\\\"\\u003eTrained with Caffe\\u003c/a\\u003e by \\u003ca href=\\\"http://yjxiong.me\\\" rel=\\\"nofollow\\\"\\u003eXiong Yuanjun\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ebninception(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eResNeXt*\\u003c/h4\\u003e\\u003ca id=\\\"user-content-resnext\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: ResNeXt*\\\" href=\\\"#resnext\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/facebookresearch/ResNeXt\\\"\\u003eResNeXt repo of FaceBook\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnext101_32x4d(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnext101_62x4d(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eDualPathNetworks\\u003c/h4\\u003e\\u003ca id=\\\"user-content-dualpathnetworks\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: DualPathNetworks\\\" href=\\\"#dualpathnetworks\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/cypw/DPNs\\\"\\u003eMXNET repo of Chen Yunpeng\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe porting has been made possible by \\u003ca href=\\\"http://rwightman.com\\\" rel=\\\"nofollow\\\"\\u003eRoss Wightman\\u003c/a\\u003e in his \\u003ca href=\\\"https://github.com/rwightman/pytorch-dpn-pretrained\\\"\\u003ePyTorch repo\\u003c/a\\u003e.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eAs you can see \\u003ca href=\\\"https://github.com/rwightman/pytorch-dpn-pretrained\\\"\\u003ehere\\u003c/a\\u003e DualPathNetworks allows you to try different scales. The default one in this repo is 0.875 meaning that the original input size is 256 before croping to 224.\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edpn68(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edpn98(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edpn131(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edpn68b(num_classes=1000, pretrained='imagenet+5k')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edpn92(num_classes=1000, pretrained='imagenet+5k')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edpn107(num_classes=1000, pretrained='imagenet+5k')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ccode\\u003e'imagenet+5k'\\u003c/code\\u003e means that the network has been pretrained on imagenet5k before being finetuned on imagenet1k.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eXception\\u003c/h4\\u003e\\u003ca id=\\\"user-content-xception\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Xception\\\" href=\\\"#xception\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/keras-team/keras/blob/master/keras/applications/xception.py\\\"\\u003eKeras repo\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe porting has been made possible by \\u003ca href=\\\"https://github.com/tstandley/Xception-PyTorch\\\"\\u003eT Standley\\u003c/a\\u003e.\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003exception(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eSENet*\\u003c/h4\\u003e\\u003ca id=\\\"user-content-senet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: SENet*\\\" href=\\\"#senet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/hujie-frank/SENet\\\"\\u003eCaffe repo of Jie Hu\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003esenet154(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ese_resnet50(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ese_resnet101(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ese_resnet152(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ese_resnext50_32x4d(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ese_resnext101_32x4d(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003ePNASNet*\\u003c/h4\\u003e\\u003ca id=\\\"user-content-pnasnet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: PNASNet*\\\" href=\\\"#pnasnet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/tensorflow/models/tree/master/research/slim\\\"\\u003eTensorFlow Slim repo\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003epnasnet5large(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003epnasnet5large(num_classes=1001, pretrained='imagenet+background')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003ePolyNet\\u003c/h4\\u003e\\u003ca id=\\\"user-content-polynet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: PolyNet\\\" href=\\\"#polynet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/CUHK-MMLAB/polynet\\\"\\u003eCaffe repo of the CUHK Multimedia Lab\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003epolynet(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eTorchVision\\u003c/h4\\u003e\\u003ca id=\\\"user-content-torchvision\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: TorchVision\\\" href=\\\"#torchvision\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSource: \\u003ca href=\\\"https://github.com/pytorch/vision/tree/master/torchvision\\\"\\u003ePytorch/Vision repo\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e(\\u003ccode\\u003einceptionv3\\u003c/code\\u003e included in \\u003ca href=\\\"https://github.com/Cadene/pretrained-models.pytorch#inception\\\"\\u003eInception*\\u003c/a\\u003e)\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnet18(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnet34(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnet50(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnet101(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnet152(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edensenet121(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edensenet161(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edensenet169(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003edensenet201(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003esqueezenet1_0(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003esqueezenet1_1(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ealexnet(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evgg11(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evgg13(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evgg16(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evgg19(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evgg11_bn(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evgg13_bn(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evgg16_bn(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evgg19_bn(num_classes=1000, pretrained='imagenet')\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eModel API\\u003c/h3\\u003e\\u003ca id=\\\"user-content-model-api\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Model API\\\" href=\\\"#model-api\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eOnce a pretrained model has been loaded, you can use it that way.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003cstrong\\u003eImportant note\\u003c/strong\\u003e: All image must be loaded using \\u003ccode\\u003ePIL\\u003c/code\\u003e which scales the pixel values between 0 and 1.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.input_size\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modelinput_size\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.input_size\\\" href=\\\"#modelinput_size\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eAttribut of type \\u003ccode\\u003elist\\u003c/code\\u003e composed of 3 numbers:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003enumber of color channels,\\u003c/li\\u003e\\n\\u003cli\\u003eheight of the input image,\\u003c/li\\u003e\\n\\u003cli\\u003ewidth of the input image.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eExample:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003e[3, 299, 299]\\u003c/code\\u003e for inception* networks,\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003e[3, 224, 224]\\u003c/code\\u003e for resnet* networks.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.input_space\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modelinput_space\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.input_space\\\" href=\\\"#modelinput_space\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eAttribut of type \\u003ccode\\u003estr\\u003c/code\\u003e representating the color space of the image. Can be \\u003ccode\\u003eRGB\\u003c/code\\u003e or \\u003ccode\\u003eBGR\\u003c/code\\u003e.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.input_range\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modelinput_range\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.input_range\\\" href=\\\"#modelinput_range\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eAttribut of type \\u003ccode\\u003elist\\u003c/code\\u003e composed of 2 numbers:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003emin pixel value,\\u003c/li\\u003e\\n\\u003cli\\u003emax pixel value.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eExample:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003e[0, 1]\\u003c/code\\u003e for resnet* and inception* networks,\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003e[0, 255]\\u003c/code\\u003e for bninception network.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.mean\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modelmean\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.mean\\\" href=\\\"#modelmean\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eAttribut of type \\u003ccode\\u003elist\\u003c/code\\u003e composed of 3 numbers which are used to normalize the input image (substract \\\"color-channel-wise\\\").\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eExample:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003e[0.5, 0.5, 0.5]\\u003c/code\\u003e for inception* networks,\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003e[0.485, 0.456, 0.406]\\u003c/code\\u003e for resnet* networks.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.std\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modelstd\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.std\\\" href=\\\"#modelstd\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eAttribut of type \\u003ccode\\u003elist\\u003c/code\\u003e composed of 3 numbers which are used to normalize the input image (divide \\\"color-channel-wise\\\").\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eExample:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003e[0.5, 0.5, 0.5]\\u003c/code\\u003e for inception* networks,\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003e[0.229, 0.224, 0.225]\\u003c/code\\u003e for resnet* networks.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.features\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modelfeatures\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.features\\\" href=\\\"#modelfeatures\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e/!\\\\ work in progress (may not be available)\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eMethod which is used to extract the features from the image.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eExample when the model is loaded using \\u003ccode\\u003efbresnet152\\u003c/code\\u003e:\\u003c/p\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"print(input_224.size())            # (1,3,224,224)\\noutput = model.features(input_224) \\nprint(output.size())               # (1,2048,1,1)\\n\\n# print(input_448.size())          # (1,3,448,448)\\noutput = model.features(input_448)\\n# print(output.size())             # (1,2048,7,7)\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())            \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,3,224,224)\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003efeatures\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e) \\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())               \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,2048,1,1)\\u003c/span\\u003e\\n\\n\\u003cspan class=\\\"pl-c\\\"\\u003e# print(input_448.size())          # (1,3,448,448)\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003efeatures\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_448\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-c\\\"\\u003e# print(output.size())             # (1,2048,7,7)\\u003c/span\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.logits\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modellogits\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.logits\\\" href=\\\"#modellogits\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e/!\\\\ work in progress (may not be available)\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eMethod which is used to classify the features from the image.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eExample when the model is loaded using \\u003ccode\\u003efbresnet152\\u003c/code\\u003e:\\u003c/p\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"output = model.features(input_224) \\nprint(output.size())               # (1,2048, 1, 1)\\noutput = model.logits(output)\\nprint(output.size())               # (1,1000)\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003efeatures\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e) \\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())               \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,2048, 1, 1)\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003elogits\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())               \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,1000)\\u003c/span\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.forward\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modelforward\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.forward\\\" href=\\\"#modelforward\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eMethod used to call \\u003ccode\\u003emodel.features\\u003c/code\\u003e and \\u003ccode\\u003emodel.logits\\u003c/code\\u003e. It can be overwritten as desired.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003cstrong\\u003eNote\\u003c/strong\\u003e: A good practice is to use \\u003ccode\\u003emodel.__call__\\u003c/code\\u003e as your function of choice to forward an input to your model. See the example bellow.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"# Without model.__call__\\noutput = model.forward(input_224)\\nprint(output.size())      # (1,1000)\\n\\n# With model.__call__\\noutput = model(input_224)\\nprint(output.size())      # (1,1000)\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-c\\\"\\u003e# Without model.__call__\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003eforward\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())      \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,1000)\\u003c/span\\u003e\\n\\n\\u003cspan class=\\\"pl-c\\\"\\u003e# With model.__call__\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-en\\\"\\u003emodel\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())      \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,1000)\\u003c/span\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003e\\u003ccode\\u003emodel.last_linear\\u003c/code\\u003e\\u003c/h4\\u003e\\u003ca id=\\\"user-content-modellast_linear\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: model.last_linear\\\" href=\\\"#modellast_linear\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eAttribut of type \\u003ccode\\u003enn.Linear\\u003c/code\\u003e. This module is the last one to be called during the forward pass.\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eCan be replaced by an adapted \\u003ccode\\u003enn.Linear\\u003c/code\\u003e for fine tuning.\\u003c/li\\u003e\\n\\u003cli\\u003eCan be replaced by \\u003ccode\\u003epretrained.utils.Identity\\u003c/code\\u003e for features extraction.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eExample when the model is loaded using \\u003ccode\\u003efbresnet152\\u003c/code\\u003e:\\u003c/p\\u003e\\n\\u003cdiv class=\\\"highlight highlight-source-python notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"print(input_224.size())            # (1,3,224,224)\\noutput = model.features(input_224) \\nprint(output.size())               # (1,2048,1,1)\\noutput = model.logits(output)\\nprint(output.size())               # (1,1000)\\n\\n# fine tuning\\ndim_feats = model.last_linear.in_features # =2048\\nnb_classes = 4\\nmodel.last_linear = nn.Linear(dim_feats, nb_classes)\\noutput = model(input_224)\\nprint(output.size())               # (1,4)\\n\\n# features extraction\\nmodel.last_linear = pretrained.utils.Identity()\\noutput = model(input_224)\\nprint(output.size())               # (1,2048)\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())            \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,3,224,224)\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003efeatures\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e) \\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())               \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,2048,1,1)\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003elogits\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())               \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,1000)\\u003c/span\\u003e\\n\\n\\u003cspan class=\\\"pl-c\\\"\\u003e# fine tuning\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003edim_feats\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003elast_linear\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003ein_features\\u003c/span\\u003e \\u003cspan class=\\\"pl-c\\\"\\u003e# =2048\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003enb_classes\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e4\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003elast_linear\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003enn\\u003c/span\\u003e.\\u003cspan class=\\\"pl-v\\\"\\u003eLinear\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003edim_feats\\u003c/span\\u003e, \\u003cspan class=\\\"pl-s1\\\"\\u003enb_classes\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-en\\\"\\u003emodel\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())               \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,4)\\u003c/span\\u003e\\n\\n\\u003cspan class=\\\"pl-c\\\"\\u003e# features extraction\\u003c/span\\u003e\\n\\u003cspan class=\\\"pl-s1\\\"\\u003emodel\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003elast_linear\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-s1\\\"\\u003epretrained\\u003c/span\\u003e.\\u003cspan class=\\\"pl-s1\\\"\\u003eutils\\u003c/span\\u003e.\\u003cspan class=\\\"pl-v\\\"\\u003eIdentity\\u003c/span\\u003e()\\n\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e \\u003cspan class=\\\"pl-c1\\\"\\u003e=\\u003c/span\\u003e \\u003cspan class=\\\"pl-en\\\"\\u003emodel\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003einput_224\\u003c/span\\u003e)\\n\\u003cspan class=\\\"pl-en\\\"\\u003eprint\\u003c/span\\u003e(\\u003cspan class=\\\"pl-s1\\\"\\u003eoutput\\u003c/span\\u003e.\\u003cspan class=\\\"pl-en\\\"\\u003esize\\u003c/span\\u003e())               \\u003cspan class=\\\"pl-c\\\"\\u003e# (1,2048)\\u003c/span\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eReproducing\\u003c/h2\\u003e\\u003ca id=\\\"user-content-reproducing\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Reproducing\\\" href=\\\"#reproducing\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eHand porting of ResNet152\\u003c/h3\\u003e\\u003ca id=\\\"user-content-hand-porting-of-resnet152\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Hand porting of ResNet152\\\" href=\\\"#hand-porting-of-resnet152\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"snippet-clipboard-content notranslate position-relative overflow-auto\\\" data-snippet-clipboard-copy-content=\\\"th pretrainedmodels/fbresnet/resnet152_dump.lua\\npython pretrainedmodels/fbresnet/resnet152_load.py\\\"\\u003e\\u003cpre class=\\\"notranslate\\\"\\u003e\\u003ccode\\u003eth pretrainedmodels/fbresnet/resnet152_dump.lua\\npython pretrainedmodels/fbresnet/resnet152_load.py\\n\\u003c/code\\u003e\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAutomatic porting of ResNeXt\\u003c/h3\\u003e\\u003ca id=\\\"user-content-automatic-porting-of-resnext\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Automatic porting of ResNeXt\\\" href=\\\"#automatic-porting-of-resnext\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca href=\\\"https://github.com/clcarwin/convert_torch_to_pytorch\\\"\\u003ehttps://github.com/clcarwin/convert_torch_to_pytorch\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eHand porting of NASNet, InceptionV4 and InceptionResNetV2\\u003c/h3\\u003e\\u003ca id=\\\"user-content-hand-porting-of-nasnet-inceptionv4-and-inceptionresnetv2\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Hand porting of NASNet, InceptionV4 and InceptionResNetV2\\\" href=\\\"#hand-porting-of-nasnet-inceptionv4-and-inceptionresnetv2\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca href=\\\"https://github.com/Cadene/tensorflow-model-zoo.torch\\\"\\u003ehttps://github.com/Cadene/tensorflow-model-zoo.torch\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAcknowledgement\\u003c/h2\\u003e\\u003ca id=\\\"user-content-acknowledgement\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Acknowledgement\\\" href=\\\"#acknowledgement\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThanks to the deep learning community and especially to the contributers of the pytorch ecosystem.\\u003c/p\\u003e\\n\\u003c/article\\u003e\",\"loaded\":true,\"timedOut\":false,\"errorMessage\":null,\"headerInfo\":{\"toc\":[{\"level\":1,\"text\":\"Pretrained models for Pytorch (Work in progress)\",\"anchor\":\"pretrained-models-for-pytorch-work-in-progress\",\"htmlText\":\"Pretrained models for Pytorch (Work in progress)\"},{\"level\":2,\"text\":\"Summary\",\"anchor\":\"summary\",\"htmlText\":\"Summary\"},{\"level\":2,\"text\":\"Installation\",\"anchor\":\"installation\",\"htmlText\":\"Installation\"},{\"level\":3,\"text\":\"Install from pip\",\"anchor\":\"install-from-pip\",\"htmlText\":\"Install from pip\"},{\"level\":3,\"text\":\"Install from repo\",\"anchor\":\"install-from-repo\",\"htmlText\":\"Install from repo\"},{\"level\":2,\"text\":\"Quick examples\",\"anchor\":\"quick-examples\",\"htmlText\":\"Quick examples\"},{\"level\":2,\"text\":\"Few use cases\",\"anchor\":\"few-use-cases\",\"htmlText\":\"Few use cases\"},{\"level\":3,\"text\":\"Compute imagenet logits\",\"anchor\":\"compute-imagenet-logits\",\"htmlText\":\"Compute imagenet logits\"},{\"level\":3,\"text\":\"Compute imagenet evaluation metrics\",\"anchor\":\"compute-imagenet-evaluation-metrics\",\"htmlText\":\"Compute imagenet evaluation metrics\"},{\"level\":2,\"text\":\"Evaluation on imagenet\",\"anchor\":\"evaluation-on-imagenet\",\"htmlText\":\"Evaluation on imagenet\"},{\"level\":3,\"text\":\"Accuracy on validation set (single model)\",\"anchor\":\"accuracy-on-validation-set-single-model\",\"htmlText\":\"Accuracy on validation set (single model)\"},{\"level\":3,\"text\":\"Reproducing results\",\"anchor\":\"reproducing-results\",\"htmlText\":\"Reproducing results\"},{\"level\":2,\"text\":\"Documentation\",\"anchor\":\"documentation\",\"htmlText\":\"Documentation\"},{\"level\":3,\"text\":\"Available models\",\"anchor\":\"available-models\",\"htmlText\":\"Available models\"},{\"level\":4,\"text\":\"NASNet*\",\"anchor\":\"nasnet\",\"htmlText\":\"NASNet*\"},{\"level\":4,\"text\":\"FaceBook ResNet*\",\"anchor\":\"facebook-resnet\",\"htmlText\":\"FaceBook ResNet*\"},{\"level\":4,\"text\":\"Caffe ResNet*\",\"anchor\":\"caffe-resnet\",\"htmlText\":\"Caffe ResNet*\"},{\"level\":4,\"text\":\"Inception*\",\"anchor\":\"inception\",\"htmlText\":\"Inception*\"},{\"level\":4,\"text\":\"BNInception\",\"anchor\":\"bninception\",\"htmlText\":\"BNInception\"},{\"level\":4,\"text\":\"ResNeXt*\",\"anchor\":\"resnext\",\"htmlText\":\"ResNeXt*\"},{\"level\":4,\"text\":\"DualPathNetworks\",\"anchor\":\"dualpathnetworks\",\"htmlText\":\"DualPathNetworks\"},{\"level\":4,\"text\":\"Xception\",\"anchor\":\"xception\",\"htmlText\":\"Xception\"},{\"level\":4,\"text\":\"SENet*\",\"anchor\":\"senet\",\"htmlText\":\"SENet*\"},{\"level\":4,\"text\":\"PNASNet*\",\"anchor\":\"pnasnet\",\"htmlText\":\"PNASNet*\"},{\"level\":4,\"text\":\"PolyNet\",\"anchor\":\"polynet\",\"htmlText\":\"PolyNet\"},{\"level\":4,\"text\":\"TorchVision\",\"anchor\":\"torchvision\",\"htmlText\":\"TorchVision\"},{\"level\":3,\"text\":\"Model API\",\"anchor\":\"model-api\",\"htmlText\":\"Model API\"},{\"level\":4,\"text\":\"model.input_size\",\"anchor\":\"modelinput_size\",\"htmlText\":\"model.input_size\"},{\"level\":4,\"text\":\"model.input_space\",\"anchor\":\"modelinput_space\",\"htmlText\":\"model.input_space\"},{\"level\":4,\"text\":\"model.input_range\",\"anchor\":\"modelinput_range\",\"htmlText\":\"model.input_range\"},{\"level\":4,\"text\":\"model.mean\",\"anchor\":\"modelmean\",\"htmlText\":\"model.mean\"},{\"level\":4,\"text\":\"model.std\",\"anchor\":\"modelstd\",\"htmlText\":\"model.std\"},{\"level\":4,\"text\":\"model.features\",\"anchor\":\"modelfeatures\",\"htmlText\":\"model.features\"},{\"level\":4,\"text\":\"model.logits\",\"anchor\":\"modellogits\",\"htmlText\":\"model.logits\"},{\"level\":4,\"text\":\"model.forward\",\"anchor\":\"modelforward\",\"htmlText\":\"model.forward\"},{\"level\":4,\"text\":\"model.last_linear\",\"anchor\":\"modellast_linear\",\"htmlText\":\"model.last_linear\"},{\"level\":2,\"text\":\"Reproducing\",\"anchor\":\"reproducing\",\"htmlText\":\"Reproducing\"},{\"level\":3,\"text\":\"Hand porting of ResNet152\",\"anchor\":\"hand-porting-of-resnet152\",\"htmlText\":\"Hand porting of ResNet152\"},{\"level\":3,\"text\":\"Automatic porting of ResNeXt\",\"anchor\":\"automatic-porting-of-resnext\",\"htmlText\":\"Automatic porting of ResNeXt\"},{\"level\":3,\"text\":\"Hand porting of NASNet, InceptionV4 and InceptionResNetV2\",\"anchor\":\"hand-porting-of-nasnet-inceptionv4-and-inceptionresnetv2\",\"htmlText\":\"Hand porting of NASNet, InceptionV4 and InceptionResNetV2\"},{\"level\":2,\"text\":\"Acknowledgement\",\"anchor\":\"acknowledgement\",\"htmlText\":\"Acknowledgement\"}],\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fcadene%2Fpretrained-models.pytorch\"}},{\"displayName\":\"LICENSE.txt\",\"repoName\":\"pretrained-models.pytorch\",\"refName\":\"master\",\"path\":\"LICENSE.txt\",\"preferredFileType\":\"license\",\"tabName\":\"BSD-3-Clause\",\"richText\":null,\"loaded\":false,\"timedOut\":false,\"errorMessage\":null,\"headerInfo\":{\"toc\":null,\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fcadene%2Fpretrained-models.pytorch\"}}],\"overviewFilesProcessingTime\":36.034877}},\"appPayload\":{\"helpUrl\":\"https://docs.github.com\",\"findFileWorkerPath\":\"/assets-cdn/worker/find-file-worker-32bb159cc57c.js\",\"findInFileWorkerPath\":\"/assets-cdn/worker/find-in-file-worker-c6704d501c10.js\",\"githubDevUrl\":null,\"enabled_features\":{\"code_nav_ui_events\":false,\"copilot_conversational_ux\":false,\"copilot_conversational_ux_embedding_update\":false,\"copilot_popover_file_editor_header\":false,\"copilot_smell_icebreaker_ux\":true,\"copilot_workspace\":false,\"codeview_firefox_inert\":true}}}}</script>  <div data-target=\"react-partial.reactRoot\"><style data-styled=\"true\" data-styled-version=\"5.3.6\">.cgQnMS{font-weight:600;font-size:32px;margin:0;}/*!sc*/data-styled.g1[id=\"Heading__StyledHeading-sc-1c1dgg0-0\"]{content:\"cgQnMS,\"}/*!sc*/.izjvBm{margin-top:16px;margin-bottom:16px;}/*!sc*/.rPQgy{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/.eUMEDg{margin-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;row-gap:16px;}/*!sc*/.eLcVee{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;padding-bottom:16px;padding-top:8px;}/*!sc*/.hsfLlq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;gap:8px;}/*!sc*/@media screen and (max-width:320px){.hsfLlq{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}}/*!sc*/.gpKoUz{position:relative;}/*!sc*/@media screen and (max-width:380px){.gpKoUz .ref-selector-button-text-container{max-width:80px;}}/*!sc*/@media screen and (max-width:320px){.gpKoUz{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}.gpKoUz .overview-ref-selector{width:100%;}.gpKoUz .overview-ref-selector > span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}.gpKoUz .overview-ref-selector > span > span[data-component=\"text\"]{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}}/*!sc*/.kkrdEu{-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/.bKgizp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;}/*!sc*/.iPGYsi{margin-right:4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.dKmYfk{font-size:14px;min-width:0;max-width:125px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}/*!sc*/.trpoQ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;pointer-events:none;}/*!sc*/.laYubZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (max-width:1079px){.laYubZ{display:none;}}/*!sc*/.swnaL{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:1080px){.swnaL{display:none;}}/*!sc*/@media screen and (max-width:543px){.swnaL{display:none;}}/*!sc*/.bWpuBf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:8px;gap:8px;}/*!sc*/.grHjNb{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;}/*!sc*/@media screen and (max-width:543px){.grHjNb{display:none;}}/*!sc*/.dXTsqj{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (max-width:1011px){.dXTsqj{display:none;}}/*!sc*/.dCOrmu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:1012px){.dCOrmu{display:none;}}/*!sc*/@media screen and (max-width:544px){.bVvbgP{display:none;}}/*!sc*/.bNDvfp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:544px){.bNDvfp{display:none;}}/*!sc*/.yfPnm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;gap:16px;}/*!sc*/.cAQuiW{width:100%;border-collapse:separate;border-spacing:0;border:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));border-radius:6px;table-layout:fixed;overflow:unset;}/*!sc*/.iiUlLN{height:0px;line-height:0px;}/*!sc*/.iiUlLN tr{height:0px;font-size:0px;}/*!sc*/.jmggSN{padding:16px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));font-size:12px;text-align:left;height:40px;}/*!sc*/.jmggSN th{padding-left:16px;background-color:var(--bgColor-muted,var(--color-canvas-subtle,#f6f8fa));}/*!sc*/.kvYunM{width:100%;border-top-left-radius:6px;}/*!sc*/@media screen and (min-width:544px){.kvYunM{display:none;}}/*!sc*/.hrLuxA{width:40%;border-top-left-radius:6px;}/*!sc*/@media screen and (max-width:543px){.hrLuxA{display:none;}}/*!sc*/@media screen and (max-width:543px){.ePjhhA{display:none;}}/*!sc*/.cuEKae{text-align:right;padding-right:16px;width:136px;border-top-right-radius:6px;}/*!sc*/.jEbBOT{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));font-size:12px;height:40px;}/*!sc*/.bTxCvM{background-color:var(--bgColor-muted,var(--color-canvas-subtle,#f6f8fa));padding:4px;border-top-left-radius:6px;border-top-right-radius:6px;}/*!sc*/.eYedVD{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:8px;min-width:273px;padding-right:8px;padding-left:16px;padding-top:8px;padding-bottom:8px;}/*!sc*/.jGfYmh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;}/*!sc*/.lhFvfi{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/.bqgLjk{display:inherit;}/*!sc*/@media screen and (min-width:544px){.bqgLjk{display:none;}}/*!sc*/@media screen and (min-width:768px){.bqgLjk{display:none;}}/*!sc*/.epsqEd{text-align:center;vertical-align:center;height:40px;border-top:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));}/*!sc*/.ldpruc{border-top:1px solid var(--borderColor-default,var(--color-border-default));cursor:pointer;}/*!sc*/.ehcSsh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;gap:16px;}/*!sc*/.iGmlUb{border:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));border-radius:6px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}/*!sc*/@media screen and (max-width:543px){.iGmlUb{margin-left:-16px;margin-right:-16px;max-width:calc(100% + 32px);}}/*!sc*/@media screen and (min-width:544px){.iGmlUb{max-width:100%;}}/*!sc*/.iRQGXA{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-bottom:1px solid;border-bottom-color:var(--borderColor-default,var(--color-border-default,#d0d7de));-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-right:8px;position:-webkit-sticky;position:sticky;top:0;background-color:var(--bgColor-default,var(--color-canvas-default,#ffffff));z-index:1;border-top-left-radius:6px;border-top-right-radius:6px;}/*!sc*/.dvTdPK{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:8px;padding-right:8px;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;border-bottom:none;border-bottom-color:var(--borderColor-muted,var(--color-border-muted,hsla(210,18%,87%,1)));align:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-height:48px;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;max-width:100%;}/*!sc*/.gwuIGu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/.kOxwQs{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;margin-right:8px;}/*!sc*/.kOgeFj{font-weight:600;}/*!sc*/.bJMeLZ{padding:32px;overflow:auto;}/*!sc*/data-styled.g2[id=\"Box-sc-g0xbh4-0\"]{content:\"izjvBm,rPQgy,eUMEDg,eLcVee,hsfLlq,gpKoUz,kkrdEu,bKgizp,iPGYsi,dKmYfk,trpoQ,laYubZ,swnaL,bWpuBf,grHjNb,dXTsqj,dCOrmu,bVvbgP,bNDvfp,yfPnm,cAQuiW,iiUlLN,jmggSN,kvYunM,hrLuxA,ePjhhA,cuEKae,jEbBOT,bTxCvM,eYedVD,jGfYmh,lhFvfi,bqgLjk,epsqEd,ldpruc,ehcSsh,iGmlUb,iRQGXA,dvTdPK,gwuIGu,kOxwQs,kOgeFj,bJMeLZ,\"}/*!sc*/.bOMzPg{min-width:0;}/*!sc*/.eUGNHp{font-weight:600;}/*!sc*/.dALsKK{color:var(--fgColor-default,var(--color-fg-default,#1F2328));}/*!sc*/data-styled.g6[id=\"Text-sc-17v1xeu-0\"]{content:\"bOMzPg,eUGNHp,dALsKK,\"}/*!sc*/.dheQRw{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.dheQRw:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.dheQRw:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.vLMkZ{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;position:relative;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;color:var(--fgColor-default,var(--color-fg-default,#1F2328));text-align:center;-webkit-text-decoration:none;text-decoration:none;line-height:calc(20/14);border-radius:6px;font-size:14px;padding-left:8px;padding-right:8px;padding-top:calc((2rem - 1.25rem) / 2);padding-bottom:calc((2rem - 1.25rem) / 2);}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.vLMkZ:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.vLMkZ:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.vLMkZ span[data-component=\"icon\"]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/@media (hover:hover){.vLMkZ:hover{background-color:var(--bgColor-neutral-muted,var(--color-neutral-muted,rgba(175,184,193,0.2)));-webkit-transition:background .12s ease-out;transition:background .12s ease-out;-webkit-text-decoration:none;text-decoration:none;}}/*!sc*/.vLMkZ:focus{outline:2px solid transparent;}/*!sc*/.vLMkZ:focus{box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.vLMkZ:focus:not(:focus-visible){box-shadow:none;}/*!sc*/.vLMkZ:focus-visible{outline:2px solid transparent;box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.vLMkZ span[data-content]::before{content:attr(data-content);display:block;height:0;font-weight:600;visibility:hidden;white-space:nowrap;}/*!sc*/.vLMkZ::after{position:absolute;right:50%;bottom:calc(50% - 25px);width:100%;height:2px;content:\"\";background-color:var(--underlineNav-borderColor-active,var(--color-primer-border-active,#fd8c73));border-radius:0;-webkit-transform:translate(50%,-50%);-ms-transform:translate(50%,-50%);transform:translate(50%,-50%);}/*!sc*/@media (forced-colors:active){.vLMkZ::after{background-color:LinkText;}}/*!sc*/.bhqztV{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;position:relative;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;color:var(--fgColor-default,var(--color-fg-default,#1F2328));text-align:center;-webkit-text-decoration:none;text-decoration:none;line-height:calc(20/14);border-radius:6px;font-size:14px;padding-left:8px;padding-right:8px;padding-top:calc((2rem - 1.25rem) / 2);padding-bottom:calc((2rem - 1.25rem) / 2);}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.bhqztV:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.bhqztV:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.bhqztV span[data-component=\"icon\"]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/@media (hover:hover){.bhqztV:hover{background-color:var(--bgColor-neutral-muted,var(--color-neutral-muted,rgba(175,184,193,0.2)));-webkit-transition:background .12s ease-out;transition:background .12s ease-out;-webkit-text-decoration:none;text-decoration:none;}}/*!sc*/.bhqztV:focus{outline:2px solid transparent;}/*!sc*/.bhqztV:focus{box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.bhqztV:focus:not(:focus-visible){box-shadow:none;}/*!sc*/.bhqztV:focus-visible{outline:2px solid transparent;box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.bhqztV span[data-content]::before{content:attr(data-content);display:block;height:0;font-weight:600;visibility:hidden;white-space:nowrap;}/*!sc*/.bhqztV::after{position:absolute;right:50%;bottom:calc(50% - 25px);width:100%;height:2px;content:\"\";background-color:transparent;border-radius:0;-webkit-transform:translate(50%,-50%);-ms-transform:translate(50%,-50%);transform:translate(50%,-50%);}/*!sc*/@media (forced-colors:active){.bhqztV::after{background-color:transparent;}}/*!sc*/data-styled.g8[id=\"Link__StyledLink-sc-14289xe-0\"]{content:\"dheQRw,vLMkZ,bhqztV,\"}/*!sc*/.izDscS{border-radius:6px;border:1px solid;border-color:var(--button-default-borderColor-rest,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:var(--button-default-bgColor-rest,var(--color-btn-bg,#f6f8fa));box-shadow:var(--button-default-shadow-resting,var(--color-btn-shadow,0 1px 0 rgba(31,35,40,0.04))),var(--button-default-shadow-inset,var(--color-btn-inset-shadow,inset 0 1px 0 rgba(255,255,255,0.25)));}/*!sc*/.izDscS:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.izDscS:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.izDscS:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.izDscS[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.izDscS[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.izDscS:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.izDscS:active{-webkit-transition:none;transition:none;}/*!sc*/.izDscS[data-inactive]{cursor:auto;}/*!sc*/.izDscS:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));border-color:var(--button-default-borderColor-disabled,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.izDscS:focus{outline:solid 1px transparent;}}/*!sc*/.izDscS [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-default-bgColor-rest,var(--color-btn-counter-bg,rgba(31,35,40,0.08)));}/*!sc*/.izDscS[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.izDscS[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.izDscS[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.izDscS[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.izDscS[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.izDscS[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.izDscS[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.izDscS[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.izDscS[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.izDscS[data-block=\"block\"]{width:100%;}/*!sc*/.izDscS[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.izDscS[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.izDscS [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.izDscS [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.izDscS [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.izDscS [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.izDscS [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.izDscS [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.izDscS:hover:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-hover,var(--color-btn-hover-bg,#f3f4f6));border-color:var(--button-default-borderColor-hover,var(--button-default-borderColor-hover,var(--color-btn-hover-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS:active:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS[aria-expanded=true]{background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS [data-component=\"leadingVisual\"],.izDscS [data-component=\"trailingVisual\"],.izDscS [data-component=\"trailingAction\"]{color:var(--button-color,var(--fgColor-muted,var(--color-fg-muted,#656d76)));}/*!sc*/.izDscS{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/.izDscS svg{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.izDscS > span{width:inherit;}/*!sc*/.cuOWTR{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.cuOWTR:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.cuOWTR:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.cuOWTR:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.cuOWTR[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.cuOWTR[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.cuOWTR:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.cuOWTR:active{-webkit-transition:none;transition:none;}/*!sc*/.cuOWTR[data-inactive]{cursor:auto;}/*!sc*/.cuOWTR:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.cuOWTR:disabled [data-component=ButtonCounter],.cuOWTR:disabled [data-component=\"leadingVisual\"],.cuOWTR:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.cuOWTR:focus{outline:solid 1px transparent;}}/*!sc*/.cuOWTR [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.cuOWTR[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.cuOWTR[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.cuOWTR[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.cuOWTR[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.cuOWTR[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.cuOWTR[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.cuOWTR[data-block=\"block\"]{width:100%;}/*!sc*/.cuOWTR[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.cuOWTR[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.cuOWTR [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.cuOWTR [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.cuOWTR [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.cuOWTR [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.cuOWTR:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.cuOWTR:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.cuOWTR[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.cuOWTR[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.cuOWTR:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.cuOWTR:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.cuOWTR:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.cuOWTR{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));padding-left:4px;padding-right:4px;}/*!sc*/.cuOWTR span[data-component=\"leadingVisual\"]{margin-right:4px !important;}/*!sc*/.tDSzd{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.tDSzd:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.tDSzd:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.tDSzd:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.tDSzd[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.tDSzd[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.tDSzd:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.tDSzd:active{-webkit-transition:none;transition:none;}/*!sc*/.tDSzd[data-inactive]{cursor:auto;}/*!sc*/.tDSzd:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.tDSzd:disabled [data-component=ButtonCounter],.tDSzd:disabled [data-component=\"leadingVisual\"],.tDSzd:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.tDSzd:focus{outline:solid 1px transparent;}}/*!sc*/.tDSzd [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.tDSzd[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.tDSzd[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.tDSzd[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.tDSzd[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.tDSzd[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.tDSzd[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.tDSzd[data-block=\"block\"]{width:100%;}/*!sc*/.tDSzd[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.tDSzd[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.tDSzd [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.tDSzd [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.tDSzd [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.tDSzd [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.tDSzd:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.tDSzd:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.tDSzd[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.tDSzd[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd[data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.tDSzd:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.tDSzd:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.ftZGca{border-radius:6px;border:1px solid;border-color:var(--button-default-borderColor-rest,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:var(--button-default-bgColor-rest,var(--color-btn-bg,#f6f8fa));box-shadow:var(--button-default-shadow-resting,var(--color-btn-shadow,0 1px 0 rgba(31,35,40,0.04))),var(--button-default-shadow-inset,var(--color-btn-inset-shadow,inset 0 1px 0 rgba(255,255,255,0.25)));}/*!sc*/.ftZGca:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.ftZGca:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.ftZGca:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.ftZGca[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.ftZGca[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.ftZGca:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.ftZGca:active{-webkit-transition:none;transition:none;}/*!sc*/.ftZGca[data-inactive]{cursor:auto;}/*!sc*/.ftZGca:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));border-color:var(--button-default-borderColor-disabled,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.ftZGca:focus{outline:solid 1px transparent;}}/*!sc*/.ftZGca [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-default-bgColor-rest,var(--color-btn-counter-bg,rgba(31,35,40,0.08)));}/*!sc*/.ftZGca[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.ftZGca[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.ftZGca[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.ftZGca[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.ftZGca[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.ftZGca[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.ftZGca[data-block=\"block\"]{width:100%;}/*!sc*/.ftZGca[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.ftZGca[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.ftZGca [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.ftZGca [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.ftZGca [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.ftZGca [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.ftZGca [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.ftZGca [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.ftZGca:hover:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-hover,var(--color-btn-hover-bg,#f3f4f6));border-color:var(--button-default-borderColor-hover,var(--button-default-borderColor-hover,var(--color-btn-hover-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca:active:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca[aria-expanded=true]{background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca [data-component=\"leadingVisual\"],.ftZGca [data-component=\"trailingVisual\"],.ftZGca [data-component=\"trailingAction\"]{color:var(--button-color,var(--fgColor-muted,var(--color-fg-muted,#656d76)));}/*!sc*/.gYvpXq{border-radius:6px;border:1px solid;border-color:var(--button-primary-borderColor-rest,var(--color-btn-primary-border,rgba(31,35,40,0.15)));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-primary-fgColor-rest,var(--color-btn-primary-text,#ffffff));background-color:var(--button-primary-bgColor-rest,var(--color-btn-primary-bg,#1f883d));box-shadow:var(--shadow-resting-small,var(--color-btn-primary-shadow,0 1px 0 rgba(31,35,40,0.1)));}/*!sc*/.gYvpXq:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.gYvpXq:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.gYvpXq:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.gYvpXq[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.gYvpXq[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.gYvpXq:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.gYvpXq:active{-webkit-transition:none;transition:none;}/*!sc*/.gYvpXq[data-inactive]{cursor:auto;}/*!sc*/.gYvpXq:disabled{cursor:not-allowed;box-shadow:none;color:var(--button-primary-fgColor-disabled,var(--color-btn-primary-disabled-text,rgba(255,255,255,0.8)));background-color:var(--button-primary-bgColor-disabled,var(--color-btn-primary-disabled-bg,#94d3a2));border-color:var(--button-primary-borderColor-disabled,var(--color-btn-primary-disabled-border,rgba(31,35,40,0.15)));}/*!sc*/.gYvpXq:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.gYvpXq:focus{outline:solid 1px transparent;}}/*!sc*/.gYvpXq [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-primary-bgColor-rest,var(--color-btn-primary-counter-bg,rgba(0,45,17,0.2)));color:var(--button-primary-fgColor-rest,var(--color-btn-primary-text,#ffffff));}/*!sc*/.gYvpXq[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.gYvpXq[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.gYvpXq[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.gYvpXq[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.gYvpXq[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.gYvpXq[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.gYvpXq[data-block=\"block\"]{width:100%;}/*!sc*/.gYvpXq[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.gYvpXq[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.gYvpXq [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.gYvpXq [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.gYvpXq [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.gYvpXq [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.gYvpXq [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.gYvpXq [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.gYvpXq:hover:not([disabled]):not([data-inactive]){color:btn.primary.hoverText;background-color:var(--button-primary-bgColor-hover,var(--color-btn-primary-hover-bg,#1a7f37));}/*!sc*/.gYvpXq:focus:not([disabled]){box-shadow:inset 0 0 0 3px;}/*!sc*/.gYvpXq:focus-visible:not([disabled]){box-shadow:inset 0 0 0 3px;}/*!sc*/.gYvpXq:active:not([disabled]):not([data-inactive]){background-color:var(--button-primary-bgColor-active,var(--color-btn-primary-selected-bg,hsla(137,66%,28%,1)));box-shadow:var(--button-primary-shadow-selected,var(--color-btn-primary-selected-shadow,inset 0 1px 0 rgba(0,45,17,0.2)));}/*!sc*/.gYvpXq[aria-expanded=true]{background-color:var(--button-primary-bgColor-active,var(--color-btn-primary-selected-bg,hsla(137,66%,28%,1)));box-shadow:var(--button-primary-shadow-selected,var(--color-btn-primary-selected-shadow,inset 0 1px 0 rgba(0,45,17,0.2)));}/*!sc*/.gYvpXq svg{color:fg.primary;}/*!sc*/.fAkXQN{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--fgColor-default,var(--color-fg-default,#1F2328));background-color:transparent;box-shadow:none;}/*!sc*/.fAkXQN:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.fAkXQN:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.fAkXQN:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.fAkXQN[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.fAkXQN[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.fAkXQN:active{-webkit-transition:none;transition:none;}/*!sc*/.fAkXQN[data-inactive]{cursor:auto;}/*!sc*/.fAkXQN:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.fAkXQN:disabled [data-component=ButtonCounter],.fAkXQN:disabled [data-component=\"leadingVisual\"],.fAkXQN:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.fAkXQN:focus{outline:solid 1px transparent;}}/*!sc*/.fAkXQN [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.fAkXQN[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.fAkXQN[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.fAkXQN[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.fAkXQN[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.fAkXQN[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.fAkXQN[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.fAkXQN[data-block=\"block\"]{width:100%;}/*!sc*/.fAkXQN[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.fAkXQN[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.fAkXQN [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.fAkXQN [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.fAkXQN [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.fAkXQN [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.fAkXQN:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.fAkXQN[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.fAkXQN:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.fAkXQN:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.fAkXQN:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.fAkXQN:focus:not([disabled]){-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.jPraEl{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.jPraEl:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.jPraEl:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.jPraEl:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.jPraEl[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.jPraEl[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.jPraEl:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.jPraEl:active{-webkit-transition:none;transition:none;}/*!sc*/.jPraEl[data-inactive]{cursor:auto;}/*!sc*/.jPraEl:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.jPraEl:disabled [data-component=ButtonCounter],.jPraEl:disabled [data-component=\"leadingVisual\"],.jPraEl:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.jPraEl:focus{outline:solid 1px transparent;}}/*!sc*/.jPraEl [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.jPraEl[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.jPraEl[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.jPraEl[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.jPraEl[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.jPraEl[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.jPraEl[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.jPraEl[data-block=\"block\"]{width:100%;}/*!sc*/.jPraEl[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.jPraEl[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.jPraEl [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.jPraEl [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.jPraEl [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.jPraEl [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.jPraEl:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.jPraEl:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.jPraEl[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.jPraEl[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.jPraEl:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.jPraEl:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.jPraEl:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.jPraEl{color:var(--fgColor-muted,var(--color-fg-subtle,#6e7781));padding-left:8px;padding-right:8px;}/*!sc*/data-styled.g9[id=\"types__StyledButton-sc-ws60qy-0\"]{content:\"izDscS,cuOWTR,tDSzd,ftZGca,gYvpXq,fAkXQN,jPraEl,\"}/*!sc*/.rTZSs{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;-webkit-clip:rect(0,0,0,0);clip:rect(0,0,0,0);white-space:nowrap;border-width:0;}/*!sc*/data-styled.g10[id=\"_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0\"]{content:\"rTZSs,\"}/*!sc*/.fUpWeN{display:inline-block;overflow:hidden;text-overflow:ellipsis;vertical-align:top;white-space:nowrap;max-width:125px;max-width:100%;}/*!sc*/data-styled.g15[id=\"Truncate__StyledTruncate-sc-23o1d2-0\"]{content:\"fUpWeN,\"}/*!sc*/.dMjscx{position:relative;display:inline-block;}/*!sc*/.dMjscx::before{position:absolute;z-index:1000001;display:none;width:0px;height:0px;color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));pointer-events:none;content:'';border:6px solid transparent;opacity:0;}/*!sc*/.dMjscx::after{position:absolute;z-index:1000000;display:none;padding:0.5em 0.75em;font:normal normal 11px/1.5 -apple-system,BlinkMacSystemFont,\"Segoe UI\",\"Noto Sans\",Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\";-webkit-font-smoothing:subpixel-antialiased;color:var(--fgColor-onEmphasis,var(--color-fg-on-emphasis,#ffffff));text-align:center;-webkit-text-decoration:none;text-decoration:none;text-shadow:none;text-transform:none;-webkit-letter-spacing:normal;-moz-letter-spacing:normal;-ms-letter-spacing:normal;letter-spacing:normal;word-wrap:break-word;white-space:pre;pointer-events:none;content:attr(aria-label);background:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));border-radius:6px;opacity:0;}/*!sc*/@-webkit-keyframes tooltip-appear{from{opacity:0;}to{opacity:1;}}/*!sc*/@keyframes tooltip-appear{from{opacity:0;}to{opacity:1;}}/*!sc*/.dMjscx:hover::before,.dMjscx:active::before,.dMjscx:focus::before,.dMjscx:focus-within::before,.dMjscx:hover::after,.dMjscx:active::after,.dMjscx:focus::after,.dMjscx:focus-within::after{display:inline-block;-webkit-text-decoration:none;text-decoration:none;-webkit-animation-name:tooltip-appear;animation-name:tooltip-appear;-webkit-animation-duration:0.1s;animation-duration:0.1s;-webkit-animation-fill-mode:forwards;animation-fill-mode:forwards;-webkit-animation-timing-function:ease-in;animation-timing-function:ease-in;-webkit-animation-delay:0.4s;animation-delay:0.4s;}/*!sc*/.dMjscx.tooltipped-no-delay:hover::before,.dMjscx.tooltipped-no-delay:active::before,.dMjscx.tooltipped-no-delay:focus::before,.dMjscx.tooltipped-no-delay:focus-within::before,.dMjscx.tooltipped-no-delay:hover::after,.dMjscx.tooltipped-no-delay:active::after,.dMjscx.tooltipped-no-delay:focus::after,.dMjscx.tooltipped-no-delay:focus-within::after{-webkit-animation-delay:0s;animation-delay:0s;}/*!sc*/.dMjscx.tooltipped-multiline:hover::after,.dMjscx.tooltipped-multiline:active::after,.dMjscx.tooltipped-multiline:focus::after,.dMjscx.tooltipped-multiline:focus-within::after{display:table-cell;}/*!sc*/.dMjscx.tooltipped-s::after,.dMjscx.tooltipped-se::after,.dMjscx.tooltipped-sw::after{top:100%;right:50%;margin-top:6px;}/*!sc*/.dMjscx.tooltipped-s::before,.dMjscx.tooltipped-se::before,.dMjscx.tooltipped-sw::before{top:auto;right:50%;bottom:-7px;margin-right:-6px;border-bottom-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-se::after{right:auto;left:50%;margin-left:-16px;}/*!sc*/.dMjscx.tooltipped-sw::after{margin-right:-16px;}/*!sc*/.dMjscx.tooltipped-n::after,.dMjscx.tooltipped-ne::after,.dMjscx.tooltipped-nw::after{right:50%;bottom:100%;margin-bottom:6px;}/*!sc*/.dMjscx.tooltipped-n::before,.dMjscx.tooltipped-ne::before,.dMjscx.tooltipped-nw::before{top:-7px;right:50%;bottom:auto;margin-right:-6px;border-top-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-ne::after{right:auto;left:50%;margin-left:-16px;}/*!sc*/.dMjscx.tooltipped-nw::after{margin-right:-16px;}/*!sc*/.dMjscx.tooltipped-s::after,.dMjscx.tooltipped-n::after{-webkit-transform:translateX(50%);-ms-transform:translateX(50%);transform:translateX(50%);}/*!sc*/.dMjscx.tooltipped-w::after{right:100%;bottom:50%;margin-right:6px;-webkit-transform:translateY(50%);-ms-transform:translateY(50%);transform:translateY(50%);}/*!sc*/.dMjscx.tooltipped-w::before{top:50%;bottom:50%;left:-7px;margin-top:-6px;border-left-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-e::after{bottom:50%;left:100%;margin-left:6px;-webkit-transform:translateY(50%);-ms-transform:translateY(50%);transform:translateY(50%);}/*!sc*/.dMjscx.tooltipped-e::before{top:50%;right:-7px;bottom:50%;margin-top:-6px;border-right-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-multiline::after{width:-webkit-max-content;width:-moz-max-content;width:max-content;max-width:250px;word-wrap:break-word;white-space:pre-line;border-collapse:separate;}/*!sc*/.dMjscx.tooltipped-multiline.tooltipped-s::after,.dMjscx.tooltipped-multiline.tooltipped-n::after{right:auto;left:50%;-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%);transform:translateX(-50%);}/*!sc*/.dMjscx.tooltipped-multiline.tooltipped-w::after,.dMjscx.tooltipped-multiline.tooltipped-e::after{right:100%;}/*!sc*/.dMjscx.tooltipped-align-right-2::after{right:0;margin-right:0;}/*!sc*/.dMjscx.tooltipped-align-right-2::before{right:15px;}/*!sc*/.dMjscx.tooltipped-align-left-2::after{left:0;margin-left:0;}/*!sc*/.dMjscx.tooltipped-align-left-2::before{left:10px;}/*!sc*/data-styled.g18[id=\"Tooltip__TooltipBase-sc-17tf59c-0\"]{content:\"dMjscx,\"}/*!sc*/.bPgibo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;list-style:none;white-space:nowrap;padding-top:0;padding-bottom:0;padding-left:0;padding-right:0;margin:0;margin-bottom:-1px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:8px;position:relative;}/*!sc*/data-styled.g103[id=\"UnderlineNav__NavigationList-sc-1jfr31k-0\"]{content:\"bPgibo,\"}/*!sc*/</style> <!-- --> <!-- --> <div class=\"Box-sc-g0xbh4-0 izjvBm\"><div class=\"Box-sc-g0xbh4-0 rPQgy\"><div class=\"Box-sc-g0xbh4-0 eUMEDg\"></div></div><div class=\"Box-sc-g0xbh4-0 eLcVee\"><div class=\"Box-sc-g0xbh4-0 hsfLlq\"><div class=\"Box-sc-g0xbh4-0 gpKoUz\"><button type=\"button\" id=\"branch-picker-repos-header-ref-selector\" aria-haspopup=\"true\" tabindex=\"0\" aria-label=\"master branch\" data-testid=\"anchor-button\" class=\"types__StyledButton-sc-ws60qy-0 izDscS overview-ref-selector\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"text\"><div class=\"Box-sc-g0xbh4-0 bKgizp\"><div class=\"Box-sc-g0xbh4-0 iPGYsi\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></div><div class=\"Box-sc-g0xbh4-0 dKmYfk ref-selector-button-text-container\"><span class=\"Text-sc-17v1xeu-0 bOMzPg\">\u00a0<!-- -->master</span></div></div></span><span data-component=\"trailingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-triangle-down\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></span></span></button><button hidden=\"\" data-hotkey-scope=\"read-only-cursor-text-area\"></button></div><div class=\"Box-sc-g0xbh4-0 laYubZ\"><a style=\"--button-color:fg.muted\" type=\"button\" href=\"/Cadene/pretrained-models.pytorch/branches\" class=\"types__StyledButton-sc-ws60qy-0 cuOWTR\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></span><span data-component=\"text\">Branches</span></span></a><a style=\"--button-color:fg.muted\" type=\"button\" href=\"/Cadene/pretrained-models.pytorch/tags\" class=\"types__StyledButton-sc-ws60qy-0 cuOWTR\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-tag\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg></span><span data-component=\"text\">Tags</span></span></a></div><div class=\"Box-sc-g0xbh4-0 swnaL\"><a style=\"--button-color:fg.muted\" type=\"button\" aria-label=\"Go to Branches page\" href=\"/Cadene/pretrained-models.pytorch/branches\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 tDSzd\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></a><a style=\"--button-color:fg.muted\" type=\"button\" aria-label=\"Go to Tags page\" href=\"/Cadene/pretrained-models.pytorch/tags\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 tDSzd\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-tag\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg></a></div></div><div class=\"Box-sc-g0xbh4-0 bWpuBf\"><div class=\"Box-sc-g0xbh4-0 grHjNb\"><div class=\"Box-sc-g0xbh4-0 dXTsqj\"><!--$!--><template></template><!--/$--></div><div class=\"Box-sc-g0xbh4-0 dCOrmu\"><button type=\"button\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 ftZGca\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"text\">Go to file</span></span></button></div><div class=\"react-directory-add-file-icon\"></div><div class=\"react-directory-remove-file-icon\"></div></div><button type=\"button\" id=\":R2il5:\" aria-haspopup=\"true\" tabindex=\"0\" class=\"types__StyledButton-sc-ws60qy-0 gYvpXq\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><div class=\"Box-sc-g0xbh4-0 bVvbgP\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-code\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg></div></span><span data-component=\"text\">Code</span></span><span data-component=\"trailingAction\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-triangle-down\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></span></button><div class=\"Box-sc-g0xbh4-0 bNDvfp\"><button data-component=\"IconButton\" type=\"button\" aria-label=\"Open more actions menu\" id=\":R3il5:\" aria-haspopup=\"true\" tabindex=\"0\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 ftZGca\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-kebab-horizontal\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path></svg></button></div></div></div><div class=\"Box-sc-g0xbh4-0 yfPnm\"><div data-hpc=\"true\" class=\"Box-sc-g0xbh4-0\"><button hidden=\"\" data-testid=\"focus-next-element-button\" data-hotkey=\"j\" data-hotkey-scope=\"read-only-cursor-text-area\"></button><button hidden=\"\" data-hotkey=\"j\"></button><button hidden=\"\" data-testid=\"focus-previous-element-button\" data-hotkey=\"k\" data-hotkey-scope=\"read-only-cursor-text-area\"></button><button hidden=\"\" data-hotkey=\"k\"></button><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\" id=\"folders-and-files\">Folders and files</h2><table aria-labelledby=\"folders-and-files\" class=\"Box-sc-g0xbh4-0 cAQuiW\"><thead class=\"Box-sc-g0xbh4-0 iiUlLN\"><tr class=\"Box-sc-g0xbh4-0 jmggSN\"><th colSpan=\"2\" class=\"Box-sc-g0xbh4-0 kvYunM\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Name</span></th><th colSpan=\"1\" class=\"Box-sc-g0xbh4-0 hrLuxA\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Name</span></th><th class=\"Box-sc-g0xbh4-0 ePjhhA\"><div title=\"Last commit message\" class=\"Truncate__StyledTruncate-sc-23o1d2-0 fUpWeN\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Last commit message</span></div></th><th colSpan=\"1\" class=\"Box-sc-g0xbh4-0 cuEKae\"><div title=\"Last commit date\" class=\"Truncate__StyledTruncate-sc-23o1d2-0 fUpWeN\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Last commit date</span></div></th></tr></thead><tbody><tr class=\"Box-sc-g0xbh4-0 jEbBOT\"><td colSpan=\"3\" class=\"Box-sc-g0xbh4-0 bTxCvM\"><div class=\"Box-sc-g0xbh4-0 eYedVD\"><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\">Latest commit</h2><div style=\"width:120px\" class=\"Skeleton Skeleton--text\" data-testid=\"loading\">\u00a0</div><div class=\"Box-sc-g0xbh4-0 jGfYmh\"><div data-testid=\"latest-commit-details\" class=\"Box-sc-g0xbh4-0 lhFvfi\"></div><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\">History</h2><a class=\"types__StyledButton-sc-ws60qy-0 fAkXQN react-last-commit-history-group\" href=\"/Cadene/pretrained-models.pytorch/commits/master/\" data-size=\"small\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-history\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></span><span data-component=\"text\"><span class=\"Text-sc-17v1xeu-0 dALsKK\">154 Commits</span></span></span></a><div class=\"Box-sc-g0xbh4-0 bqgLjk\"></div><span role=\"tooltip\" aria-label=\"Commit history\" class=\"Tooltip__TooltipBase-sc-17tf59c-0 dMjscx tooltipped-n\"><a class=\"types__StyledButton-sc-ws60qy-0 fAkXQN react-last-commit-history-icon\" href=\"/Cadene/pretrained-models.pytorch/commits/master/\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-history\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></span></span></a></span></div></div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-0\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"data\" aria-label=\"data, (Directory)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/tree/master/data\">data</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"data\" aria-label=\"data, (Directory)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/tree/master/data\">data</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-1\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"examples\" aria-label=\"examples, (Directory)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/tree/master/examples\">examples</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"examples\" aria-label=\"examples, (Directory)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/tree/master/examples\">examples</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-2\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"pretrainedmodels\" aria-label=\"pretrainedmodels, (Directory)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/tree/master/pretrainedmodels\">pretrainedmodels</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"pretrainedmodels\" aria-label=\"pretrainedmodels, (Directory)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/tree/master/pretrainedmodels\">pretrainedmodels</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-3\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"tests\" aria-label=\"tests, (Directory)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/tree/master/tests\">tests</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"tests\" aria-label=\"tests, (Directory)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/tree/master/tests\">tests</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-4\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".gitignore\" aria-label=\".gitignore, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/.gitignore\">.gitignore</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".gitignore\" aria-label=\".gitignore, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/.gitignore\">.gitignore</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-5\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".travis.yml\" aria-label=\".travis.yml, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/.travis.yml\">.travis.yml</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".travis.yml\" aria-label=\".travis.yml, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/.travis.yml\">.travis.yml</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-6\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"LICENSE.txt\" aria-label=\"LICENSE.txt, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/LICENSE.txt\">LICENSE.txt</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"LICENSE.txt\" aria-label=\"LICENSE.txt, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/LICENSE.txt\">LICENSE.txt</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-7\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"README.md\" aria-label=\"README.md, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/README.md\">README.md</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"README.md\" aria-label=\"README.md, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/README.md\">README.md</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-8\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"requirements.txt\" aria-label=\"requirements.txt, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/requirements.txt\">requirements.txt</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"requirements.txt\" aria-label=\"requirements.txt, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/requirements.txt\">requirements.txt</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-9\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"setup.cfg\" aria-label=\"setup.cfg, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/setup.cfg\">setup.cfg</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"setup.cfg\" aria-label=\"setup.cfg, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/setup.cfg\">setup.cfg</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-10\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"setup.py\" aria-label=\"setup.py, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/setup.py\">setup.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"setup.py\" aria-label=\"setup.py, (File)\" class=\"Link--primary\" href=\"/Cadene/pretrained-models.pytorch/blob/master/setup.py\">setup.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"Box-sc-g0xbh4-0 epsqEd show-for-mobile\" data-testid=\"view-all-files-row\"><td colSpan=\"3\" class=\"Box-sc-g0xbh4-0 ldpruc\"><div><button class=\"Link__StyledLink-sc-14289xe-0 dheQRw\">View all files</button></div></td></tr></tbody></table></div><div class=\"Box-sc-g0xbh4-0 ehcSsh\"><div class=\"Box-sc-g0xbh4-0 iGmlUb\"><div class=\"Box-sc-g0xbh4-0 iRQGXA\"><h2 class=\"_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0 rTZSs\">Repository files navigation</h2><nav aria-label=\"Repository files\" class=\"Box-sc-g0xbh4-0 dvTdPK\"><ul role=\"list\" class=\"UnderlineNav__NavigationList-sc-1jfr31k-0 bPgibo\"><li class=\"Box-sc-g0xbh4-0 gwuIGu\"><a href=\"#\" aria-current=\"page\" class=\"Link__StyledLink-sc-14289xe-0 vLMkZ\"><span data-component=\"icon\" class=\"Box-sc-g0xbh4-0 kOxwQs\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-book\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg></span><span data-component=\"text\" data-content=\"README\" class=\"Box-sc-g0xbh4-0 kOgeFj\">README</span></a></li><li class=\"Box-sc-g0xbh4-0 gwuIGu\"><a href=\"#\" class=\"Link__StyledLink-sc-14289xe-0 bhqztV\"><span data-component=\"icon\" class=\"Box-sc-g0xbh4-0 kOxwQs\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-law\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg></span><span data-component=\"text\" data-content=\"BSD-3-Clause license\" class=\"Box-sc-g0xbh4-0\">BSD-3-Clause license</span></a></li></ul></nav><button style=\"--button-color:fg.subtle\" type=\"button\" aria-label=\"Outline\" id=\":Rdkl5:\" aria-haspopup=\"true\" tabindex=\"0\" class=\"types__StyledButton-sc-ws60qy-0 jPraEl\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-list-unordered\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M5.75 2.5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2 14a1 1 0 1 1 0-2 1 1 0 0 1 0 2Zm1-6a1 1 0 1 1-2 0 1 1 0 0 1 2 0ZM2 4a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z\"></path></svg></button></div><div class=\"Box-sc-g0xbh4-0 bJMeLZ js-snippet-clipboard-copy-unpositioned\" data-hpc=\"true\"><article class=\"markdown-body entry-content container-lg\" itemprop=\"text\"><div class=\"markdown-heading\" dir=\"auto\"><h1 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Pretrained models for Pytorch (Work in progress)</h1><a id=\"user-content-pretrained-models-for-pytorch-work-in-progress\" class=\"anchor-element\" aria-label=\"Permalink: Pretrained models for Pytorch (Work in progress)\" href=\"#pretrained-models-for-pytorch-work-in-progress\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">The goal of this repo is:</p><ul dir=\"auto\"><li>to help to reproduce research papers results (transfer learning setups for instance),</li><li>to access pretrained ConvNets with a unique interface/API inspired by torchvision.</li></ul><p dir=\"auto\"><a href=\"https://travis-ci.org/Cadene/pretrained-models.pytorch\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b744495d00a078e34957dc310b0cb746223f5f7c562acc4806a80d285b62b2a0/68747470733a2f2f6170692e7472617669732d63692e6f72672f436164656e652f707265747261696e65642d6d6f64656c732e7079746f7263682e7376673f6272616e63683d6d6173746572\" data-canonical-src=\"https://api.travis-ci.org/Cadene/pretrained-models.pytorch.svg?branch=master\" style=\"max-width: 100%;\"></a></p><p dir=\"auto\">News:</p><ul dir=\"auto\"><li>27/10/2018: Fix compatibility issues, Add tests, Add travis</li><li>04/06/2018: <a href=\"https://github.com/CUHK-MMLAB/polynet\">PolyNet</a> and <a href=\"https://arxiv.org/abs/1712.00559\" rel=\"nofollow\">PNASNet-5-Large</a> thanks to <a href=\"https://github.com/creafz\">Alex Parinov</a></li><li>16/04/2018: <a href=\"https://github.com/hujie-frank/SENet\">SE-ResNet* and SE-ResNeXt*</a> thanks to <a href=\"https://github.com/creafz\">Alex Parinov</a></li><li>09/04/2018: <a href=\"https://github.com/hujie-frank/SENet\">SENet154</a> thanks to <a href=\"https://github.com/creafz\">Alex Parinov</a></li><li>22/03/2018: CaffeResNet101 (good for localization with FasterRCNN)</li><li>21/03/2018: NASNet Mobile thanks to <a href=\"https://github.com/veronikayurchuk\">Veronika Yurchuk</a> and <a href=\"https://github.com/DagnyT\">Anastasiia</a></li><li>25/01/2018: DualPathNetworks thanks to <a href=\"https://github.com/rwightman/pytorch-dpn-pretrained\">Ross Wightman</a>, Xception thanks to <a href=\"https://github.com/tstandley/Xception-PyTorch\">T Standley</a>, improved TransformImage API</li><li>13/01/2018: <code>pip install pretrainedmodels</code>, <code>pretrainedmodels.model_names</code>, <code>pretrainedmodels.pretrained_settings</code></li><li>12/01/2018: <code>python setup.py install</code></li><li>08/12/2017: update data url (/!\\ <code>git pull</code> is needed)</li><li>30/11/2017: improve API (<code>model.features(input)</code>, <code>model.logits(features)</code>, <code>model.forward(input)</code>, <code>model.last_linear</code>)</li><li>16/11/2017: nasnet-a-large pretrained model ported by T. Durand and R. Cadene</li><li>22/07/2017: torchvision pretrained models</li><li>22/07/2017: momentum in inceptionv4 and inceptionresnetv2 to 0.1</li><li>17/07/2017: model.input_range attribut</li><li>17/07/2017: BNInception pretrained on Imagenet</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Summary</h2><a id=\"user-content-summary\" class=\"anchor-element\" aria-label=\"Permalink: Summary\" href=\"#summary\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#installation\">Installation</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#quick-examples\">Quick examples</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#few-use-cases\">Few use cases</a><ul dir=\"auto\"><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#compute-imagenet-logits\">Compute imagenet logits</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#compute-imagenet-validation-metrics\">Compute imagenet validation metrics</a></li></ul></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#evaluation-on-imagenet\">Evaluation on ImageNet</a><ul dir=\"auto\"><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#accuracy-on-validation-set\">Accuracy on valset</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#reproducing-results\">Reproducing results</a></li></ul></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#documentation\">Documentation</a><ul dir=\"auto\"><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#available-models\">Available models</a><ul dir=\"auto\"><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">AlexNet</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#bninception\">BNInception</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#caffe-resnet\">CaffeResNet101</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet121</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet161</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet169</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet201</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet201</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet68</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet92</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet98</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet107</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet113</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet\">FBResNet152</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#inception\">InceptionResNetV2</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#inception\">InceptionV3</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#inception\">InceptionV4</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#nasnet\">NASNet-A-Large</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#nasnet\">NASNet-A-Mobile</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#pnasnet\">PNASNet-5-Large</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#polynet\">PolyNet</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#resnext\">ResNeXt101_32x4d</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#resnext\">ResNeXt101_64x4d</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet101</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet152</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet18</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet34</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet50</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SENet154</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNet50</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNet101</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNet152</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNeXt50_32x4d</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNeXt101_32x4d</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">SqueezeNet1_0</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">SqueezeNet1_1</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG11</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG13</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG16</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG19</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG11_BN</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG13_BN</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG16_BN</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG19_BN</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#xception\">Xception</a></li></ul></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#model-api\">Model API</a><ul dir=\"auto\"><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#modelinput_size\">model.input_size</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#modelinput_space\">model.input_space</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#modelinput_range\">model.input_range</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#modelmean\">model.mean</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#modelstd\">model.std</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#modelfeatures\">model.features</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#modellogits\">model.logits</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#modelforward\">model.forward</a></li></ul></li></ul></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#reproducing\">Reproducing porting</a><ul dir=\"auto\"><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#hand-porting-of-resnet152\">ResNet*</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#automatic-porting-of-resnext\">ResNeXt*</a></li><li><a href=\"https://github.com/Cadene/pretrained-models.pytorch#hand-porting-of-inceptionv4-and-inceptionresnetv2\">Inception*</a></li></ul></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Installation</h2><a id=\"user-content-installation\" class=\"anchor-element\" aria-label=\"Permalink: Installation\" href=\"#installation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ol dir=\"auto\"><li><a href=\"https://www.continuum.io/downloads\" rel=\"nofollow\">python3 with anaconda</a></li><li><a href=\"http://pytorch.org\" rel=\"nofollow\">pytorch with/out CUDA</a></li></ol><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Install from pip</h3><a id=\"user-content-install-from-pip\" class=\"anchor-element\" aria-label=\"Permalink: Install from pip\" href=\"#install-from-pip\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ol start=\"3\" dir=\"auto\"><li><code>pip install pretrainedmodels</code></li></ol><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Install from repo</h3><a id=\"user-content-install-from-repo\" class=\"anchor-element\" aria-label=\"Permalink: Install from repo\" href=\"#install-from-repo\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ol start=\"3\" dir=\"auto\"><li><code>git clone https://github.com/Cadene/pretrained-models.pytorch.git</code></li><li><code>cd pretrained-models.pytorch</code></li><li><code>python setup.py install</code></li></ol><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Quick examples</h2><a id=\"user-content-quick-examples\" class=\"anchor-element\" aria-label=\"Permalink: Quick examples\" href=\"#quick-examples\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>To import <code>pretrainedmodels</code>:</li></ul><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"import pretrainedmodels\"><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">pretrainedmodels</span></pre></div><ul dir=\"auto\"><li>To print the available pretrained models:</li></ul><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"print(pretrainedmodels.model_names)&gt; ['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetalarge', 'nasnetamobile', 'cafferesnet101', 'senet154',  'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'polynet', 'pnasnet5large']\"><pre><span class=\"pl-en\">print</span>(<span class=\"pl-s1\">pretrainedmodels</span>.<span class=\"pl-s1\">model_names</span>)<span class=\"pl-c1\">&gt;</span> [<span class=\"pl-s\">'fbresnet152'</span>, <span class=\"pl-s\">'bninception'</span>, <span class=\"pl-s\">'resnext101_32x4d'</span>, <span class=\"pl-s\">'resnext101_64x4d'</span>, <span class=\"pl-s\">'inceptionv4'</span>, <span class=\"pl-s\">'inceptionresnetv2'</span>, <span class=\"pl-s\">'alexnet'</span>, <span class=\"pl-s\">'densenet121'</span>, <span class=\"pl-s\">'densenet169'</span>, <span class=\"pl-s\">'densenet201'</span>, <span class=\"pl-s\">'densenet161'</span>, <span class=\"pl-s\">'resnet18'</span>, <span class=\"pl-s\">'resnet34'</span>, <span class=\"pl-s\">'resnet50'</span>, <span class=\"pl-s\">'resnet101'</span>, <span class=\"pl-s\">'resnet152'</span>, <span class=\"pl-s\">'inceptionv3'</span>, <span class=\"pl-s\">'squeezenet1_0'</span>, <span class=\"pl-s\">'squeezenet1_1'</span>, <span class=\"pl-s\">'vgg11'</span>, <span class=\"pl-s\">'vgg11_bn'</span>, <span class=\"pl-s\">'vgg13'</span>, <span class=\"pl-s\">'vgg13_bn'</span>, <span class=\"pl-s\">'vgg16'</span>, <span class=\"pl-s\">'vgg16_bn'</span>, <span class=\"pl-s\">'vgg19_bn'</span>, <span class=\"pl-s\">'vgg19'</span>, <span class=\"pl-s\">'nasnetalarge'</span>, <span class=\"pl-s\">'nasnetamobile'</span>, <span class=\"pl-s\">'cafferesnet101'</span>, <span class=\"pl-s\">'senet154'</span>,  <span class=\"pl-s\">'se_resnet50'</span>, <span class=\"pl-s\">'se_resnet101'</span>, <span class=\"pl-s\">'se_resnet152'</span>, <span class=\"pl-s\">'se_resnext50_32x4d'</span>, <span class=\"pl-s\">'se_resnext101_32x4d'</span>, <span class=\"pl-s\">'cafferesnet101'</span>, <span class=\"pl-s\">'polynet'</span>, <span class=\"pl-s\">'pnasnet5large'</span>]</pre></div><ul dir=\"auto\"><li>To print the available pretrained settings for a chosen model:</li></ul><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"print(pretrainedmodels.pretrained_settings['nasnetalarge'])&gt; {'imagenet': {'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth', 'input_space': 'RGB', 'input_size': [3, 331, 331], 'input_range': [0, 1], 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'num_classes': 1000}, 'imagenet+background': {'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth', 'input_space': 'RGB', 'input_size': [3, 331, 331], 'input_range': [0, 1], 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'num_classes': 1001}}\"><pre><span class=\"pl-en\">print</span>(<span class=\"pl-s1\">pretrainedmodels</span>.<span class=\"pl-s1\">pretrained_settings</span>[<span class=\"pl-s\">'nasnetalarge'</span>])<span class=\"pl-c1\">&gt;</span> {<span class=\"pl-s\">'imagenet'</span>: {<span class=\"pl-s\">'url'</span>: <span class=\"pl-s\">'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth'</span>, <span class=\"pl-s\">'input_space'</span>: <span class=\"pl-s\">'RGB'</span>, <span class=\"pl-s\">'input_size'</span>: [<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">331</span>, <span class=\"pl-c1\">331</span>], <span class=\"pl-s\">'input_range'</span>: [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-s\">'mean'</span>: [<span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>], <span class=\"pl-s\">'std'</span>: [<span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>], <span class=\"pl-s\">'num_classes'</span>: <span class=\"pl-c1\">1000</span>}, <span class=\"pl-s\">'imagenet+background'</span>: {<span class=\"pl-s\">'url'</span>: <span class=\"pl-s\">'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth'</span>, <span class=\"pl-s\">'input_space'</span>: <span class=\"pl-s\">'RGB'</span>, <span class=\"pl-s\">'input_size'</span>: [<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">331</span>, <span class=\"pl-c1\">331</span>], <span class=\"pl-s\">'input_range'</span>: [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-s\">'mean'</span>: [<span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>], <span class=\"pl-s\">'std'</span>: [<span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>], <span class=\"pl-s\">'num_classes'</span>: <span class=\"pl-c1\">1001</span>}}</pre></div><ul dir=\"auto\"><li>To load a pretrained models from imagenet:</li></ul><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"model_name = 'nasnetalarge' # could be fbresnet152 or inceptionresnetv2model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')model.eval()\"><pre><span class=\"pl-s1\">model_name</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\">'nasnetalarge'</span> <span class=\"pl-c\"># could be fbresnet152 or inceptionresnetv2</span><span class=\"pl-s1\">model</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">pretrainedmodels</span>.<span class=\"pl-s1\">__dict__</span>[<span class=\"pl-s1\">model_name</span>](<span class=\"pl-s1\">num_classes</span><span class=\"pl-c1\">=</span><span class=\"pl-c1\">1000</span>, <span class=\"pl-s1\">pretrained</span><span class=\"pl-c1\">=</span><span class=\"pl-s\">'imagenet'</span>)<span class=\"pl-s1\">model</span>.<span class=\"pl-en\">eval</span>()</pre></div><p dir=\"auto\"><strong>Note</strong>: By default, models will be downloaded to your <code>$HOME/.torch</code> folder. You can modify this behavior using the <code>$TORCH_HOME</code> variable as follow: <code>export TORCH_HOME=\"/local/pretrainedmodels\"</code></p><ul dir=\"auto\"><li>To load an image and do a complete forward pass:</li></ul><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"import torchimport pretrainedmodels.utils as utilsload_img = utils.LoadImage()# transformations depending on the model#\u00a0rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)tf_img = utils.TransformImage(model) path_img = 'data/cat.jpg'input_img = load_img(path_img)input_tensor = tf_img(input_img)         # 3x400x225 -&gt; 3x299x299 size may differinput_tensor = input_tensor.unsqueeze(0) # 3x299x299 -&gt; 1x3x299x299input = torch.autograd.Variable(input_tensor,    requires_grad=False)output_logits = model(input) # 1x1000\"><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">torch</span><span class=\"pl-k\">import</span> <span class=\"pl-s1\">pretrainedmodels</span>.<span class=\"pl-s1\">utils</span> <span class=\"pl-k\">as</span> <span class=\"pl-s1\">utils</span><span class=\"pl-s1\">load_img</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">utils</span>.<span class=\"pl-v\">LoadImage</span>()<span class=\"pl-c\"># transformations depending on the model</span><span class=\"pl-c\">#\u00a0rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)</span><span class=\"pl-s1\">tf_img</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">utils</span>.<span class=\"pl-v\">TransformImage</span>(<span class=\"pl-s1\">model</span>) <span class=\"pl-s1\">path_img</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\">'data/cat.jpg'</span><span class=\"pl-s1\">input_img</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">load_img</span>(<span class=\"pl-s1\">path_img</span>)<span class=\"pl-s1\">input_tensor</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">tf_img</span>(<span class=\"pl-s1\">input_img</span>)         <span class=\"pl-c\"># 3x400x225 -&gt; 3x299x299 size may differ</span><span class=\"pl-s1\">input_tensor</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">input_tensor</span>.<span class=\"pl-en\">unsqueeze</span>(<span class=\"pl-c1\">0</span>) <span class=\"pl-c\"># 3x299x299 -&gt; 1x3x299x299</span><span class=\"pl-s1\">input</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">torch</span>.<span class=\"pl-s1\">autograd</span>.<span class=\"pl-v\">Variable</span>(<span class=\"pl-s1\">input_tensor</span>,    <span class=\"pl-s1\">requires_grad</span><span class=\"pl-c1\">=</span><span class=\"pl-c1\">False</span>)<span class=\"pl-s1\">output_logits</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">model</span>(<span class=\"pl-s1\">input</span>) <span class=\"pl-c\"># 1x1000</span></pre></div><ul dir=\"auto\"><li>To extract features (beware this API is not available for all networks):</li></ul><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"output_features = model.features(input) # 1x14x14x2048 size may differoutput_logits = model.logits(output_features) # 1x1000\"><pre><span class=\"pl-s1\">output_features</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">features</span>(<span class=\"pl-s1\">input</span>) <span class=\"pl-c\"># 1x14x14x2048 size may differ</span><span class=\"pl-s1\">output_logits</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">logits</span>(<span class=\"pl-s1\">output_features</span>) <span class=\"pl-c\"># 1x1000</span></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Few use cases</h2><a id=\"user-content-few-use-cases\" class=\"anchor-element\" aria-label=\"Permalink: Few use cases\" href=\"#few-use-cases\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Compute imagenet logits</h3><a id=\"user-content-compute-imagenet-logits\" class=\"anchor-element\" aria-label=\"Permalink: Compute imagenet logits\" href=\"#compute-imagenet-logits\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>See <a href=\"https://github.com/Cadene/pretrained-models.pytorch/blob/master/examples/imagenet_logits.py\">examples/imagenet_logits.py</a> to compute logits of classes appearance over a single image with a pretrained model on imagenet.</li></ul><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"$ python examples/imagenet_logits.py -h&gt; nasnetalarge, resnet152, inceptionresnetv2, inceptionv4, ...\"><pre class=\"notranslate\"><code>$ python examples/imagenet_logits.py -h&gt; nasnetalarge, resnet152, inceptionresnetv2, inceptionv4, ...</code></pre></div><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"$ python examples/imagenet_logits.py -a nasnetalarge --path_img data/cat.jpg&gt; 'nasnetalarge': data/cat.jpg' is a 'tiger cat' \"><pre class=\"notranslate\"><code>$ python examples/imagenet_logits.py -a nasnetalarge --path_img data/cat.jpg&gt; 'nasnetalarge': data/cat.jpg' is a 'tiger cat' </code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Compute imagenet evaluation metrics</h3><a id=\"user-content-compute-imagenet-evaluation-metrics\" class=\"anchor-element\" aria-label=\"Permalink: Compute imagenet evaluation metrics\" href=\"#compute-imagenet-evaluation-metrics\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>See <a href=\"https://github.com/Cadene/pretrained-models.pytorch/blob/master/examples/imagenet_eval.py\">examples/imagenet_eval.py</a> to evaluate pretrained models on imagenet valset.</li></ul><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"$ python examples/imagenet_eval.py /local/common-data/imagenet_2012/images -a nasnetalarge -b 20 -e&gt; * Acc@1 82.693, Acc@5 96.13\"><pre class=\"notranslate\"><code>$ python examples/imagenet_eval.py /local/common-data/imagenet_2012/images -a nasnetalarge -b 20 -e&gt; * Acc@1 82.693, Acc@5 96.13</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Evaluation on imagenet</h2><a id=\"user-content-evaluation-on-imagenet\" class=\"anchor-element\" aria-label=\"Permalink: Evaluation on imagenet\" href=\"#evaluation-on-imagenet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Accuracy on validation set (single model)</h3><a id=\"user-content-accuracy-on-validation-set-single-model\" class=\"anchor-element\" aria-label=\"Permalink: Accuracy on validation set (single model)\" href=\"#accuracy-on-validation-set-single-model\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Results were obtained using (center cropped) images of the same size than during the training process.</p><table><thead><tr><th>Model</th><th>Version</th><th>Acc@1</th><th>Acc@5</th></tr></thead><tbody><tr><td>PNASNet-5-Large</td><td><a href=\"https://github.com/tensorflow/models/tree/master/research/slim\">Tensorflow</a></td><td>82.858</td><td>96.182</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#pnasnet\">PNASNet-5-Large</a></td><td>Our porting</td><td>82.736</td><td>95.992</td></tr><tr><td>NASNet-A-Large</td><td><a href=\"https://github.com/tensorflow/models/tree/master/research/slim\">Tensorflow</a></td><td>82.693</td><td>96.163</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#nasnet\">NASNet-A-Large</a></td><td>Our porting</td><td>82.566</td><td>96.086</td></tr><tr><td>SENet154</td><td><a href=\"https://github.com/hujie-frank/SENet\">Caffe</a></td><td>81.32</td><td>95.53</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SENet154</a></td><td>Our porting</td><td>81.304</td><td>95.498</td></tr><tr><td>PolyNet</td><td><a href=\"https://github.com/CUHK-MMLAB/polynet\">Caffe</a></td><td>81.29</td><td>95.75</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#polynet\">PolyNet</a></td><td>Our porting</td><td>81.002</td><td>95.624</td></tr><tr><td>InceptionResNetV2</td><td><a href=\"https://github.com/tensorflow/models/tree/master/slim\">Tensorflow</a></td><td>80.4</td><td>95.3</td></tr><tr><td>InceptionV4</td><td><a href=\"https://github.com/tensorflow/models/tree/master/slim\">Tensorflow</a></td><td>80.2</td><td>95.3</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNeXt101_32x4d</a></td><td>Our porting</td><td>80.236</td><td>95.028</td></tr><tr><td>SE-ResNeXt101_32x4d</td><td><a href=\"https://github.com/hujie-frank/SENet\">Caffe</a></td><td>80.19</td><td>95.04</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#inception\">InceptionResNetV2</a></td><td>Our porting</td><td>80.170</td><td>95.234</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#inception\">InceptionV4</a></td><td>Our porting</td><td>80.062</td><td>94.926</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet107_5k</a></td><td>Our porting</td><td>79.746</td><td>94.684</td></tr><tr><td>ResNeXt101_64x4d</td><td><a href=\"https://github.com/facebookresearch/ResNeXt\">Torch7</a></td><td>79.6</td><td>94.7</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet131</a></td><td>Our porting</td><td>79.432</td><td>94.574</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet92_5k</a></td><td>Our porting</td><td>79.400</td><td>94.620</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet98</a></td><td>Our porting</td><td>79.224</td><td>94.488</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNeXt50_32x4d</a></td><td>Our porting</td><td>79.076</td><td>94.434</td></tr><tr><td>SE-ResNeXt50_32x4d</td><td><a href=\"https://github.com/hujie-frank/SENet\">Caffe</a></td><td>79.03</td><td>94.46</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#xception\">Xception</a></td><td><a href=\"https://github.com/keras-team/keras/blob/master/keras/applications/xception.py\">Keras</a></td><td>79.000</td><td>94.500</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#resnext\">ResNeXt101_64x4d</a></td><td>Our porting</td><td>78.956</td><td>94.252</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#xception\">Xception</a></td><td>Our porting</td><td>78.888</td><td>94.292</td></tr><tr><td>ResNeXt101_32x4d</td><td><a href=\"https://github.com/facebookresearch/ResNeXt\">Torch7</a></td><td>78.8</td><td>94.4</td></tr><tr><td>SE-ResNet152</td><td><a href=\"https://github.com/hujie-frank/SENet\">Caffe</a></td><td>78.66</td><td>94.46</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNet152</a></td><td>Our porting</td><td>78.658</td><td>94.374</td></tr><tr><td>ResNet152</td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>78.428</td><td>94.110</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNet101</a></td><td>Our porting</td><td>78.396</td><td>94.258</td></tr><tr><td>SE-ResNet101</td><td><a href=\"https://github.com/hujie-frank/SENet\">Caffe</a></td><td>78.25</td><td>94.28</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#resnext\">ResNeXt101_32x4d</a></td><td>Our porting</td><td>78.188</td><td>93.886</td></tr><tr><td>FBResNet152</td><td><a href=\"https://github.com/facebook/fb.resnet.torch\">Torch7</a></td><td>77.84</td><td>93.84</td></tr><tr><td>SE-ResNet50</td><td><a href=\"https://github.com/hujie-frank/SENet\">Caffe</a></td><td>77.63</td><td>93.64</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#senet\">SE-ResNet50</a></td><td>Our porting</td><td>77.636</td><td>93.752</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet161</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>77.560</td><td>93.798</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet101</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>77.438</td><td>93.672</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet\">FBResNet152</a></td><td>Our porting</td><td>77.386</td><td>93.594</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#inception\">InceptionV3</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>77.294</td><td>93.454</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet201</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>77.152</td><td>93.548</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet68b_5k</a></td><td>Our porting</td><td>77.034</td><td>93.590</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#caffe-resnet\">CaffeResnet101</a></td><td><a href=\"https://github.com/KaimingHe/deep-residual-networks\">Caffe</a></td><td>76.400</td><td>92.900</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#caffe-resnet\">CaffeResnet101</a></td><td>Our porting</td><td>76.200</td><td>92.766</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet169</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>76.026</td><td>92.992</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet50</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>76.002</td><td>92.980</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks\">DualPathNet68</a></td><td>Our porting</td><td>75.868</td><td>92.774</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">DenseNet121</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>74.646</td><td>92.136</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG19_BN</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>74.266</td><td>92.066</td></tr><tr><td>NASNet-A-Mobile</td><td><a href=\"https://github.com/tensorflow/models/tree/master/research/slim\">Tensorflow</a></td><td>74.0</td><td>91.6</td></tr><tr><td><a href=\"https://github.com/veronikayurchuk/pretrained-models.pytorch/blob/master/pretrainedmodels/models/nasnet_mobile.py\">NASNet-A-Mobile</a></td><td>Our porting</td><td>74.080</td><td>91.740</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet34</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>73.554</td><td>91.456</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#bninception\">BNInception</a></td><td>Our porting</td><td>73.524</td><td>91.562</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG16_BN</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>73.518</td><td>91.608</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG19</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>72.080</td><td>90.822</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG16</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>71.636</td><td>90.354</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG13_BN</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>71.508</td><td>90.494</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG11_BN</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>70.452</td><td>89.818</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">ResNet18</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>70.142</td><td>89.274</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG13</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>69.662</td><td>89.264</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">VGG11</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>68.970</td><td>88.746</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">SqueezeNet1_1</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>58.250</td><td>80.800</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">SqueezeNet1_0</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>58.108</td><td>80.428</td></tr><tr><td><a href=\"https://github.com/Cadene/pretrained-models.pytorch#torchvision\">Alexnet</a></td><td><a href=\"https://github.com/pytorch/vision#models\">Pytorch</a></td><td>56.432</td><td>79.194</td></tr></tbody></table><p dir=\"auto\">Notes:</p><ul dir=\"auto\"><li>the Pytorch version of ResNet152 is not a porting of the Torch7 but has been retrained by facebook.</li><li>For the PolyNet evaluation each image was resized to 378x378 without preserving the aspect ratio and then the central 331\u00d7331 patch from the resulting image was used.</li></ul><p dir=\"auto\">Beware, the accuracy reported here is not always representative of the transferable capacity of the network on other tasks and datasets. You must try them all! :P</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Reproducing results</h3><a id=\"user-content-reproducing-results\" class=\"anchor-element\" aria-label=\"Permalink: Reproducing results\" href=\"#reproducing-results\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Please see <a href=\"https://github.com/Cadene/pretrained-models.pytorch#compute-imagenet-validation-metrics\">Compute imagenet validation metrics</a></p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Documentation</h2><a id=\"user-content-documentation\" class=\"anchor-element\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Available models</h3><a id=\"user-content-available-models\" class=\"anchor-element\" aria-label=\"Permalink: Available models\" href=\"#available-models\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">NASNet*</h4><a id=\"user-content-nasnet\" class=\"anchor-element\" aria-label=\"Permalink: NASNet*\" href=\"#nasnet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/tensorflow/models/tree/master/research/slim\">TensorFlow Slim repo</a></p><ul dir=\"auto\"><li><code>nasnetalarge(num_classes=1000, pretrained='imagenet')</code></li><li><code>nasnetalarge(num_classes=1001, pretrained='imagenet+background')</code></li><li><code>nasnetamobile(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">FaceBook ResNet*</h4><a id=\"user-content-facebook-resnet\" class=\"anchor-element\" aria-label=\"Permalink: FaceBook ResNet*\" href=\"#facebook-resnet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/facebook/fb.resnet.torch\">Torch7 repo of FaceBook</a></p><p dir=\"auto\">There are a bit different from the ResNet* of torchvision. ResNet152 is currently the only one available.</p><ul dir=\"auto\"><li><code>fbresnet152(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Caffe ResNet*</h4><a id=\"user-content-caffe-resnet\" class=\"anchor-element\" aria-label=\"Permalink: Caffe ResNet*\" href=\"#caffe-resnet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/KaimingHe/deep-residual-networks\">Caffe repo of KaimingHe</a></p><ul dir=\"auto\"><li><code>cafferesnet101(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Inception*</h4><a id=\"user-content-inception\" class=\"anchor-element\" aria-label=\"Permalink: Inception*\" href=\"#inception\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/tensorflow/models/tree/master/slim\">TensorFlow Slim repo</a> and <a href=\"https://github.com/pytorch/vision/tree/master/torchvision\">Pytorch/Vision repo</a> for <code>inceptionv3</code></p><ul dir=\"auto\"><li><code>inceptionresnetv2(num_classes=1000, pretrained='imagenet')</code></li><li><code>inceptionresnetv2(num_classes=1001, pretrained='imagenet+background')</code></li><li><code>inceptionv4(num_classes=1000, pretrained='imagenet')</code></li><li><code>inceptionv4(num_classes=1001, pretrained='imagenet+background')</code></li><li><code>inceptionv3(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">BNInception</h4><a id=\"user-content-bninception\" class=\"anchor-element\" aria-label=\"Permalink: BNInception\" href=\"#bninception\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/Cadene/tensorflow-model-zoo.torch/pull/2\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/Cadene/tensorflow-model-zoo.torch/pull/2/hovercard\">Trained with Caffe</a> by <a href=\"http://yjxiong.me\" rel=\"nofollow\">Xiong Yuanjun</a></p><ul dir=\"auto\"><li><code>bninception(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">ResNeXt*</h4><a id=\"user-content-resnext\" class=\"anchor-element\" aria-label=\"Permalink: ResNeXt*\" href=\"#resnext\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/facebookresearch/ResNeXt\">ResNeXt repo of FaceBook</a></p><ul dir=\"auto\"><li><code>resnext101_32x4d(num_classes=1000, pretrained='imagenet')</code></li><li><code>resnext101_62x4d(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">DualPathNetworks</h4><a id=\"user-content-dualpathnetworks\" class=\"anchor-element\" aria-label=\"Permalink: DualPathNetworks\" href=\"#dualpathnetworks\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/cypw/DPNs\">MXNET repo of Chen Yunpeng</a></p><p dir=\"auto\">The porting has been made possible by <a href=\"http://rwightman.com\" rel=\"nofollow\">Ross Wightman</a> in his <a href=\"https://github.com/rwightman/pytorch-dpn-pretrained\">PyTorch repo</a>.</p><p dir=\"auto\">As you can see <a href=\"https://github.com/rwightman/pytorch-dpn-pretrained\">here</a> DualPathNetworks allows you to try different scales. The default one in this repo is 0.875 meaning that the original input size is 256 before croping to 224.</p><ul dir=\"auto\"><li><code>dpn68(num_classes=1000, pretrained='imagenet')</code></li><li><code>dpn98(num_classes=1000, pretrained='imagenet')</code></li><li><code>dpn131(num_classes=1000, pretrained='imagenet')</code></li><li><code>dpn68b(num_classes=1000, pretrained='imagenet+5k')</code></li><li><code>dpn92(num_classes=1000, pretrained='imagenet+5k')</code></li><li><code>dpn107(num_classes=1000, pretrained='imagenet+5k')</code></li></ul><p dir=\"auto\"><code>'imagenet+5k'</code> means that the network has been pretrained on imagenet5k before being finetuned on imagenet1k.</p><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Xception</h4><a id=\"user-content-xception\" class=\"anchor-element\" aria-label=\"Permalink: Xception\" href=\"#xception\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/keras-team/keras/blob/master/keras/applications/xception.py\">Keras repo</a></p><p dir=\"auto\">The porting has been made possible by <a href=\"https://github.com/tstandley/Xception-PyTorch\">T Standley</a>.</p><ul dir=\"auto\"><li><code>xception(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">SENet*</h4><a id=\"user-content-senet\" class=\"anchor-element\" aria-label=\"Permalink: SENet*\" href=\"#senet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/hujie-frank/SENet\">Caffe repo of Jie Hu</a></p><ul dir=\"auto\"><li><code>senet154(num_classes=1000, pretrained='imagenet')</code></li><li><code>se_resnet50(num_classes=1000, pretrained='imagenet')</code></li><li><code>se_resnet101(num_classes=1000, pretrained='imagenet')</code></li><li><code>se_resnet152(num_classes=1000, pretrained='imagenet')</code></li><li><code>se_resnext50_32x4d(num_classes=1000, pretrained='imagenet')</code></li><li><code>se_resnext101_32x4d(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">PNASNet*</h4><a id=\"user-content-pnasnet\" class=\"anchor-element\" aria-label=\"Permalink: PNASNet*\" href=\"#pnasnet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/tensorflow/models/tree/master/research/slim\">TensorFlow Slim repo</a></p><ul dir=\"auto\"><li><code>pnasnet5large(num_classes=1000, pretrained='imagenet')</code></li><li><code>pnasnet5large(num_classes=1001, pretrained='imagenet+background')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">PolyNet</h4><a id=\"user-content-polynet\" class=\"anchor-element\" aria-label=\"Permalink: PolyNet\" href=\"#polynet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/CUHK-MMLAB/polynet\">Caffe repo of the CUHK Multimedia Lab</a></p><ul dir=\"auto\"><li><code>polynet(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">TorchVision</h4><a id=\"user-content-torchvision\" class=\"anchor-element\" aria-label=\"Permalink: TorchVision\" href=\"#torchvision\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Source: <a href=\"https://github.com/pytorch/vision/tree/master/torchvision\">Pytorch/Vision repo</a></p><p dir=\"auto\">(<code>inceptionv3</code> included in <a href=\"https://github.com/Cadene/pretrained-models.pytorch#inception\">Inception*</a>)</p><ul dir=\"auto\"><li><code>resnet18(num_classes=1000, pretrained='imagenet')</code></li><li><code>resnet34(num_classes=1000, pretrained='imagenet')</code></li><li><code>resnet50(num_classes=1000, pretrained='imagenet')</code></li><li><code>resnet101(num_classes=1000, pretrained='imagenet')</code></li><li><code>resnet152(num_classes=1000, pretrained='imagenet')</code></li><li><code>densenet121(num_classes=1000, pretrained='imagenet')</code></li><li><code>densenet161(num_classes=1000, pretrained='imagenet')</code></li><li><code>densenet169(num_classes=1000, pretrained='imagenet')</code></li><li><code>densenet201(num_classes=1000, pretrained='imagenet')</code></li><li><code>squeezenet1_0(num_classes=1000, pretrained='imagenet')</code></li><li><code>squeezenet1_1(num_classes=1000, pretrained='imagenet')</code></li><li><code>alexnet(num_classes=1000, pretrained='imagenet')</code></li><li><code>vgg11(num_classes=1000, pretrained='imagenet')</code></li><li><code>vgg13(num_classes=1000, pretrained='imagenet')</code></li><li><code>vgg16(num_classes=1000, pretrained='imagenet')</code></li><li><code>vgg19(num_classes=1000, pretrained='imagenet')</code></li><li><code>vgg11_bn(num_classes=1000, pretrained='imagenet')</code></li><li><code>vgg13_bn(num_classes=1000, pretrained='imagenet')</code></li><li><code>vgg16_bn(num_classes=1000, pretrained='imagenet')</code></li><li><code>vgg19_bn(num_classes=1000, pretrained='imagenet')</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Model API</h3><a id=\"user-content-model-api\" class=\"anchor-element\" aria-label=\"Permalink: Model API\" href=\"#model-api\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Once a pretrained model has been loaded, you can use it that way.</p><p dir=\"auto\"><strong>Important note</strong>: All image must be loaded using <code>PIL</code> which scales the pixel values between 0 and 1.</p><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.input_size</code></h4><a id=\"user-content-modelinput_size\" class=\"anchor-element\" aria-label=\"Permalink: model.input_size\" href=\"#modelinput_size\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Attribut of type <code>list</code> composed of 3 numbers:</p><ul dir=\"auto\"><li>number of color channels,</li><li>height of the input image,</li><li>width of the input image.</li></ul><p dir=\"auto\">Example:</p><ul dir=\"auto\"><li><code>[3, 299, 299]</code> for inception* networks,</li><li><code>[3, 224, 224]</code> for resnet* networks.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.input_space</code></h4><a id=\"user-content-modelinput_space\" class=\"anchor-element\" aria-label=\"Permalink: model.input_space\" href=\"#modelinput_space\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Attribut of type <code>str</code> representating the color space of the image. Can be <code>RGB</code> or <code>BGR</code>.</p><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.input_range</code></h4><a id=\"user-content-modelinput_range\" class=\"anchor-element\" aria-label=\"Permalink: model.input_range\" href=\"#modelinput_range\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Attribut of type <code>list</code> composed of 2 numbers:</p><ul dir=\"auto\"><li>min pixel value,</li><li>max pixel value.</li></ul><p dir=\"auto\">Example:</p><ul dir=\"auto\"><li><code>[0, 1]</code> for resnet* and inception* networks,</li><li><code>[0, 255]</code> for bninception network.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.mean</code></h4><a id=\"user-content-modelmean\" class=\"anchor-element\" aria-label=\"Permalink: model.mean\" href=\"#modelmean\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Attribut of type <code>list</code> composed of 3 numbers which are used to normalize the input image (substract \"color-channel-wise\").</p><p dir=\"auto\">Example:</p><ul dir=\"auto\"><li><code>[0.5, 0.5, 0.5]</code> for inception* networks,</li><li><code>[0.485, 0.456, 0.406]</code> for resnet* networks.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.std</code></h4><a id=\"user-content-modelstd\" class=\"anchor-element\" aria-label=\"Permalink: model.std\" href=\"#modelstd\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Attribut of type <code>list</code> composed of 3 numbers which are used to normalize the input image (divide \"color-channel-wise\").</p><p dir=\"auto\">Example:</p><ul dir=\"auto\"><li><code>[0.5, 0.5, 0.5]</code> for inception* networks,</li><li><code>[0.229, 0.224, 0.225]</code> for resnet* networks.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.features</code></h4><a id=\"user-content-modelfeatures\" class=\"anchor-element\" aria-label=\"Permalink: model.features\" href=\"#modelfeatures\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">/!\\ work in progress (may not be available)</p><p dir=\"auto\">Method which is used to extract the features from the image.</p><p dir=\"auto\">Example when the model is loaded using <code>fbresnet152</code>:</p><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"print(input_224.size())            # (1,3,224,224)output = model.features(input_224) print(output.size())               # (1,2048,1,1)# print(input_448.size())          # (1,3,448,448)output = model.features(input_448)# print(output.size())             # (1,2048,7,7)\"><pre><span class=\"pl-en\">print</span>(<span class=\"pl-s1\">input_224</span>.<span class=\"pl-en\">size</span>())            <span class=\"pl-c\"># (1,3,224,224)</span><span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">features</span>(<span class=\"pl-s1\">input_224</span>) <span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())               <span class=\"pl-c\"># (1,2048,1,1)</span><span class=\"pl-c\"># print(input_448.size())          # (1,3,448,448)</span><span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">features</span>(<span class=\"pl-s1\">input_448</span>)<span class=\"pl-c\"># print(output.size())             # (1,2048,7,7)</span></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.logits</code></h4><a id=\"user-content-modellogits\" class=\"anchor-element\" aria-label=\"Permalink: model.logits\" href=\"#modellogits\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">/!\\ work in progress (may not be available)</p><p dir=\"auto\">Method which is used to classify the features from the image.</p><p dir=\"auto\">Example when the model is loaded using <code>fbresnet152</code>:</p><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"output = model.features(input_224) print(output.size())               # (1,2048, 1, 1)output = model.logits(output)print(output.size())               # (1,1000)\"><pre><span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">features</span>(<span class=\"pl-s1\">input_224</span>) <span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())               <span class=\"pl-c\"># (1,2048, 1, 1)</span><span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">logits</span>(<span class=\"pl-s1\">output</span>)<span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())               <span class=\"pl-c\"># (1,1000)</span></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.forward</code></h4><a id=\"user-content-modelforward\" class=\"anchor-element\" aria-label=\"Permalink: model.forward\" href=\"#modelforward\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Method used to call <code>model.features</code> and <code>model.logits</code>. It can be overwritten as desired.</p><p dir=\"auto\"><strong>Note</strong>: A good practice is to use <code>model.__call__</code> as your function of choice to forward an input to your model. See the example bellow.</p><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"# Without model.__call__output = model.forward(input_224)print(output.size())      # (1,1000)# With model.__call__output = model(input_224)print(output.size())      # (1,1000)\"><pre><span class=\"pl-c\"># Without model.__call__</span><span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">forward</span>(<span class=\"pl-s1\">input_224</span>)<span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())      <span class=\"pl-c\"># (1,1000)</span><span class=\"pl-c\"># With model.__call__</span><span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">model</span>(<span class=\"pl-s1\">input_224</span>)<span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())      <span class=\"pl-c\"># (1,1000)</span></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"><code>model.last_linear</code></h4><a id=\"user-content-modellast_linear\" class=\"anchor-element\" aria-label=\"Permalink: model.last_linear\" href=\"#modellast_linear\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Attribut of type <code>nn.Linear</code>. This module is the last one to be called during the forward pass.</p><ul dir=\"auto\"><li>Can be replaced by an adapted <code>nn.Linear</code> for fine tuning.</li><li>Can be replaced by <code>pretrained.utils.Identity</code> for features extraction.</li></ul><p dir=\"auto\">Example when the model is loaded using <code>fbresnet152</code>:</p><div class=\"highlight highlight-source-python notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"print(input_224.size())            # (1,3,224,224)output = model.features(input_224) print(output.size())               # (1,2048,1,1)output = model.logits(output)print(output.size())               # (1,1000)# fine tuningdim_feats = model.last_linear.in_features # =2048nb_classes = 4model.last_linear = nn.Linear(dim_feats, nb_classes)output = model(input_224)print(output.size())               # (1,4)# features extractionmodel.last_linear = pretrained.utils.Identity()output = model(input_224)print(output.size())               # (1,2048)\"><pre><span class=\"pl-en\">print</span>(<span class=\"pl-s1\">input_224</span>.<span class=\"pl-en\">size</span>())            <span class=\"pl-c\"># (1,3,224,224)</span><span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">features</span>(<span class=\"pl-s1\">input_224</span>) <span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())               <span class=\"pl-c\"># (1,2048,1,1)</span><span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-en\">logits</span>(<span class=\"pl-s1\">output</span>)<span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())               <span class=\"pl-c\"># (1,1000)</span><span class=\"pl-c\"># fine tuning</span><span class=\"pl-s1\">dim_feats</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">model</span>.<span class=\"pl-s1\">last_linear</span>.<span class=\"pl-s1\">in_features</span> <span class=\"pl-c\"># =2048</span><span class=\"pl-s1\">nb_classes</span> <span class=\"pl-c1\">=</span> <span class=\"pl-c1\">4</span><span class=\"pl-s1\">model</span>.<span class=\"pl-s1\">last_linear</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">nn</span>.<span class=\"pl-v\">Linear</span>(<span class=\"pl-s1\">dim_feats</span>, <span class=\"pl-s1\">nb_classes</span>)<span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">model</span>(<span class=\"pl-s1\">input_224</span>)<span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())               <span class=\"pl-c\"># (1,4)</span><span class=\"pl-c\"># features extraction</span><span class=\"pl-s1\">model</span>.<span class=\"pl-s1\">last_linear</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">pretrained</span>.<span class=\"pl-s1\">utils</span>.<span class=\"pl-v\">Identity</span>()<span class=\"pl-s1\">output</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">model</span>(<span class=\"pl-s1\">input_224</span>)<span class=\"pl-en\">print</span>(<span class=\"pl-s1\">output</span>.<span class=\"pl-en\">size</span>())               <span class=\"pl-c\"># (1,2048)</span></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Reproducing</h2><a id=\"user-content-reproducing\" class=\"anchor-element\" aria-label=\"Permalink: Reproducing\" href=\"#reproducing\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Hand porting of ResNet152</h3><a id=\"user-content-hand-porting-of-resnet152\" class=\"anchor-element\" aria-label=\"Permalink: Hand porting of ResNet152\" href=\"#hand-porting-of-resnet152\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"th pretrainedmodels/fbresnet/resnet152_dump.luapython pretrainedmodels/fbresnet/resnet152_load.py\"><pre class=\"notranslate\"><code>th pretrainedmodels/fbresnet/resnet152_dump.luapython pretrainedmodels/fbresnet/resnet152_load.py</code></pre></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Automatic porting of ResNeXt</h3><a id=\"user-content-automatic-porting-of-resnext\" class=\"anchor-element\" aria-label=\"Permalink: Automatic porting of ResNeXt\" href=\"#automatic-porting-of-resnext\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a href=\"https://github.com/clcarwin/convert_torch_to_pytorch\">https://github.com/clcarwin/convert_torch_to_pytorch</a></p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Hand porting of NASNet, InceptionV4 and InceptionResNetV2</h3><a id=\"user-content-hand-porting-of-nasnet-inceptionv4-and-inceptionresnetv2\" class=\"anchor-element\" aria-label=\"Permalink: Hand porting of NASNet, InceptionV4 and InceptionResNetV2\" href=\"#hand-porting-of-nasnet-inceptionv4-and-inceptionresnetv2\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a href=\"https://github.com/Cadene/tensorflow-model-zoo.torch\">https://github.com/Cadene/tensorflow-model-zoo.torch</a></p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Acknowledgement</h2><a id=\"user-content-acknowledgement\" class=\"anchor-element\" aria-label=\"Permalink: Acknowledgement\" href=\"#acknowledgement\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Thanks to the deep learning community and especially to the contributers of the pytorch ecosystem.</p></article></div></div></div></div></div> <!-- --> <!-- --> <script type=\"application/json\" id=\"__PRIMER_DATA__\">{\"resolvedServerColorMode\":\"day\"}</script></div></react-partial>        <input type=\"hidden\" data-csrf=\"true\" value=\"O1sg6m4UMlKltNTg+vyb8tVAupL58KtPGTUl4R0f5kT1XdoDPxTl4rWZ4EfcviZaD2NPwtNcVLsma4sjWRI7pQ==\" /></div>  <div data-view-component=\"true\" class=\"Layout-sidebar\">            <div class=\"BorderGrid about-margin\" data-pjax>        <div class=\"BorderGrid-row\">          <div class=\"BorderGrid-cell\">            <div class=\"hide-sm hide-md\">  <h2 class=\"mb-3 h4\">About</h2>      <p class=\"f4 my-3\">        Pretrained ConvNets for pytorch: NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN, etc.      </p>    <h3 class=\"sr-only\">Topics</h3>    <div class=\"my-3\">        <div class=\"f6\">      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:pytorch\" href=\"/topics/pytorch\" title=\"Topic: pytorch\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  pytorch</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:imagenet\" href=\"/topics/imagenet\" title=\"Topic: imagenet\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  imagenet</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:resnet\" href=\"/topics/resnet\" title=\"Topic: resnet\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  resnet</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:inception\" href=\"/topics/inception\" title=\"Topic: inception\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  inception</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:resnext\" href=\"/topics/resnext\" title=\"Topic: resnext\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  resnext</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:pretrained\" href=\"/topics/pretrained\" title=\"Topic: pretrained\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  pretrained</a>  </div>    </div>    <h3 class=\"sr-only\">Resources</h3>    <div class=\"mt-2\">      <a class=\"Link--muted\" data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}\" href=\"#readme-ov-file\">        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-book mr-2\">    <path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg>        Readme</a>    </div>      <h3 class=\"sr-only\">License</h3>  <div class=\"mt-2\">    <a href=\"#BSD-3-Clause-1-ov-file\"      class=\"Link--muted\"            data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}\"    >      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-law mr-2\">    <path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg>     BSD-3-Clause license    </a>  </div>  <include-fragment  src=\"/cadene/pretrained-models.pytorch/hovercards/citation/sidebar_partial?tree_name=master\">  </include-fragment>  <div class=\"mt-2\">    <a href=\"/Cadene/pretrained-models.pytorch/activity\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg text=\"gray\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pulse mr-2\">    <path d=\"M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z\"></path></svg>      <span class=\"color-fg-muted\">Activity</span></a>  </div>  <h3 class=\"sr-only\">Stars</h3>  <div class=\"mt-2\">    <a href=\"/Cadene/pretrained-models.pytorch/stargazers\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg>      <strong>8.9k</strong>      stars</a>  </div>  <h3 class=\"sr-only\">Watchers</h3>  <div class=\"mt-2\">    <a href=\"/Cadene/pretrained-models.pytorch/watchers\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-eye mr-2\">    <path d=\"M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z\"></path></svg>      <strong>217</strong>      watching</a>  </div>  <h3 class=\"sr-only\">Forks</h3>  <div class=\"mt-2\">    <a href=\"/Cadene/pretrained-models.pytorch/forks\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-2\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>      <strong>1.8k</strong>      forks</a>  </div>    <div class=\"mt-2\">      <a class=\"Link--muted\" href=\"/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FCadene%2Fpretrained-models.pytorch&amp;report=Cadene+%28user%29\">          Report repository</a>    </div></div>          </div>        </div>                    <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\">  <a href=\"/Cadene/pretrained-models.pytorch/releases\" data-view-component=\"true\" class=\"Link--primary no-underline Link\">    Releases</a></h2>    <div class=\"text-small color-fg-muted\">No releases published</div>              </div>            </div>                            <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">  <a href=\"/users/Cadene/packages?repo_name=pretrained-models.pytorch\" data-view-component=\"true\" class=\"Link--primary no-underline Link d-flex flex-items-center\">    Packages      <span title=\"0\" hidden=\"hidden\" data-view-component=\"true\" class=\"Counter ml-1\">0</span></a></h2>      <div class=\"text-small color-fg-muted\">        No packages published <br>      </div>              </div>            </div>                    <div class=\"BorderGrid-row\" hidden>              <div class=\"BorderGrid-cell\">                <include-fragment src=\"/Cadene/pretrained-models.pytorch/used_by_list\" accept=\"text/fragment+html\"></include-fragment>              </div>            </div>                    <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">  <a href=\"/Cadene/pretrained-models.pytorch/graphs/contributors\" data-view-component=\"true\" class=\"Link--primary no-underline Link d-flex flex-items-center\">    Contributors      <span title=\"20\" data-view-component=\"true\" class=\"Counter ml-1\">20</span></a></h2>    <include-fragment src=\"/cadene/pretrained-models.pytorch/contributors_list?count=20&amp;current_repository=pretrained-models.pytorch&amp;items_to_show=14\" aria-busy=\"true\" aria-label=\"Loading contributors\">      <ul class=\"list-style-none d-flex flex-wrap mb-n2\">          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>          <li class=\"mb-2 \">            <div class=\"Skeleton avatar avatar-user mr-2\" style=\"width:32px;height:32px;\"></div>          </li>      </ul></include-fragment>  <div data-view-component=\"true\" class=\"mt-3\">    <a text=\"small\" href=\"/Cadene/pretrained-models.pytorch/graphs/contributors\" data-view-component=\"true\" class=\"Link\">      + 6 contributors</a></div>              </div>            </div>                            <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">Languages</h2><div class=\"mb-2\">  <span data-view-component=\"true\" class=\"Progress\">    <span style=\"background-color:#3572A5 !important;;width: 99.7%;\" itemprop=\"keywords\" aria-label=\"Python 99.7\" data-view-component=\"true\" class=\"Progress-item color-bg-success-emphasis\"></span>    <span style=\"background-color:#000080 !important;;width: 0.3%;\" itemprop=\"keywords\" aria-label=\"Lua 0.3\" data-view-component=\"true\" class=\"Progress-item color-bg-success-emphasis\"></span></span></div><ul class=\"list-style-none\">    <li class=\"d-inline\">        <a class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3\" href=\"/Cadene/pretrained-models.pytorch/search?l=python\"  data-ga-click=\"Repository, language stats search click, location:repo overview\">          <svg style=\"color:#3572A5;\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill mr-2\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg>          <span class=\"color-fg-default text-bold mr-1\">Python</span>          <span>99.7%</span>        </a>    </li>    <li class=\"d-inline\">        <a class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3\" href=\"/Cadene/pretrained-models.pytorch/search?l=lua\"  data-ga-click=\"Repository, language stats search click, location:repo overview\">          <svg style=\"color:#000080;\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill mr-2\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg>          <span class=\"color-fg-default text-bold mr-1\">Lua</span>          <span>0.3%</span>        </a>    </li></ul>              </div>            </div>              </div></div>  </div></div>  </div>  </div></turbo-frame>    </main>  </div>  </div>          <footer class=\"footer pt-8 pb-6 f6 color-fg-muted p-responsive\" role=\"contentinfo\" >  <h2 class='sr-only'>Footer</h2>    <div class=\"d-flex flex-justify-center flex-items-center flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap\">    <div class=\"d-flex flex-items-center flex-shrink-0 mx-2\">      <a aria-label=\"Homepage\" title=\"GitHub\" class=\"footer-octicon mr-2\" href=\"https://github.com\">        <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-mark-github\">    <path d=\"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z\"></path></svg></a>      <span>        &copy; 2024 GitHub,&nbsp;Inc.      </span>    </div>    <nav aria-label=\"Footer\">      <h3 class=\"sr-only\" id=\"sr-footer-heading\">Footer navigation</h3>      <ul class=\"list-style-none d-flex flex-justify-center flex-wrap mb-2 mb-lg-0\" aria-labelledby=\"sr-footer-heading\">          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to Terms&quot;,&quot;label&quot;:&quot;text:terms&quot;}\" href=\"https://docs.github.com/site-policy/github-terms/github-terms-of-service\" data-view-component=\"true\" class=\"Link--secondary Link\">Terms</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to privacy&quot;,&quot;label&quot;:&quot;text:privacy&quot;}\" href=\"https://docs.github.com/site-policy/privacy-policies/github-privacy-statement\" data-view-component=\"true\" class=\"Link--secondary Link\">Privacy</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to security&quot;,&quot;label&quot;:&quot;text:security&quot;}\" href=\"/security\" data-view-component=\"true\" class=\"Link--secondary Link\">Security</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to status&quot;,&quot;label&quot;:&quot;text:status&quot;}\" href=\"https://www.githubstatus.com/\" data-view-component=\"true\" class=\"Link--secondary Link\">Status</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to docs&quot;,&quot;label&quot;:&quot;text:docs&quot;}\" href=\"https://docs.github.com\" data-view-component=\"true\" class=\"Link--secondary Link\">Docs</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to contact&quot;,&quot;label&quot;:&quot;text:contact&quot;}\" href=\"https://support.github.com?tags=dotcom-footer\" data-view-component=\"true\" class=\"Link--secondary Link\">Contact</a>          </li>          <li class=\"mx-2\" >  <cookie-consent-link>    <button type=\"button\" class=\"Link--secondary underline-on-hover border-0 p-0 color-bg-transparent\" data-action=\"click:cookie-consent-link#showConsentManagement\">      Manage cookies    </button>  </cookie-consent-link></li><li class=\"mx-2\">  <cookie-consent-link>    <button type=\"button\" class=\"Link--secondary underline-on-hover border-0 p-0 color-bg-transparent\" data-action=\"click:cookie-consent-link#showConsentManagement\">      Do not share my personal information    </button>  </cookie-consent-link></li>      </ul>    </nav>  </div></footer>    <cookie-consent id=\"cookie-consent-banner\" class=\"position-fixed bottom-0 left-0\" style=\"z-index: 999999\" data-initial-cookie-consent-allowed=\"\" data-cookie-consent-required=\"false\"></cookie-consent>  <div id=\"ajax-error-message\" class=\"ajax-error-message flash flash-error\" hidden>    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>    <button type=\"button\" class=\"flash-close js-ajax-error-dismiss\" aria-label=\"Dismiss error\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>    </button>    You can\u2019t perform that action at this time.  </div>    <template id=\"site-details-dialog\">  <details class=\"details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm\" open>    <summary role=\"button\" aria-label=\"Close dialog\"></summary>    <details-dialog class=\"Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal\">      <button class=\"Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0\" type=\"button\" aria-label=\"Close dialog\" data-close-dialog>        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>      </button>      <div class=\"octocat-spinner my-6 js-details-dialog-spinner\"></div>    </details-dialog>  </details></template>    <div class=\"Popover js-hovercard-content position-absolute\" style=\"display: none; outline: none;\" tabindex=\"0\">  <div class=\"Popover-message Popover-message--bottom-left Popover-message--large Box color-shadow-large\" style=\"width:360px;\">  </div></div>    <template id=\"snippet-clipboard-copy-button\">  <div class=\"zeroclipboard-container position-absolute right-0 top-0\">    <clipboard-copy aria-label=\"Copy\" class=\"ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copy js-clipboard-copy-icon m-2\">    <path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"></path><path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg>      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2\">    <path d=\"M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"></path></svg>    </clipboard-copy>  </div></template><template id=\"snippet-clipboard-copy-button-unpositioned\">  <div class=\"zeroclipboard-container\">    <clipboard-copy aria-label=\"Copy\" class=\"ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copy js-clipboard-copy-icon\">    <path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"></path><path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg>      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none\">    <path d=\"M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"></path></svg>    </clipboard-copy>  </div></template>    </div>    <div id=\"js-global-screen-reader-notice\" class=\"sr-only\" aria-live=\"polite\" aria-atomic=\"true\" ></div>    <div id=\"js-global-screen-reader-notice-assertive\" class=\"sr-only\" aria-live=\"assertive\" aria-atomic=\"true\"></div>  </body></html>",
  "embeddings": []
}