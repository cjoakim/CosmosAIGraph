{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "license :: osi approved :: apache software license",
    "programming language :: python",
    "programming language :: python :: 2",
    "programming language :: python :: 2.7",
    "programming language :: python :: 3",
    "programming language :: python :: 3.4",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: implementation :: cpython",
    "programming language :: python :: implementation :: pypy",
    "topic :: database",
    "topic :: database :: front-ends",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": ".. image:: https://travis-ci.org/parsely/pykafka.svg?branch=master\n    :target: https://travis-ci.org/parsely/pykafka\n.. image:: https://codecov.io/github/parsely/pykafka/coverage.svg?branch=master\n    :target: https://codecov.io/github/parsely/pykafka?branch=master\n\npykafka\n=======\n\n.. image:: http://i.imgur.com/ztyl4lg.jpg\n\npykafka is a programmer-friendly kafka client for python. it includes python\nimplementations of kafka producers and consumers, which are optionally backed\nby a c extension built on `librdkafka`_. it runs under python 2.7+, python 3.4+,\nand pypy, and supports versions of kafka 0.8.2 and newer.\n\n.. _librdkafka: https://github.com/edenhill/librdkafka\n\npykafka's primary goal is to provide a similar level of abstraction to the\n`jvm kafka client`_ using idioms familiar to python programmers and exposing\nthe most pythonic api possible.\n\nyou can install pykafka from pypi with\n\n::\n\n    $ pip install pykafka\n\nor from conda-forge with\n\n::\n\n    $ conda install -c conda-forge pykafka\n\nfull documentation and usage examples for pykafka can be found on `readthedocs`_.\n\nyou can install pykafka for local development and testing by cloning this repository and\nrunning\n\n::\n\n    $ python setup.py develop\n\n.. _jvm kafka client: https://github.com/apache/kafka/tree/0.8.2/clients/src/main/java/org/apache/kafka\n.. _readthedocs: http://pykafka.readthedocs.org/en/latest/\n\ngetting started\n---------------\n\nassuming you have at least one kafka instance running on localhost, you can use pykafka\nto connect to it.\n\n.. sourcecode:: python\n\n    >>> from pykafka import kafkaclient\n    >>> client = kafkaclient(hosts=\"127.0.0.1:9092,127.0.0.1:9093,...\")\n\nor, for a tls connection, you might write (and also see ``sslconfig`` docs\nfor further details):\n\n.. sourcecode:: python\n\n    >>> from pykafka import kafkaclient, sslconfig\n    >>> config = sslconfig(cafile='/your/ca.cert',\n    ...                    certfile='/your/client.cert',  # optional\n    ...                    keyfile='/your/client.key',  # optional\n    ...                    password='unlock my client key please')  # optional\n    >>> client = kafkaclient(hosts=\"127.0.0.1:<ssl-port>,...\",\n    ...                      ssl_config=config)\n\nif the cluster you've connected to has any topics defined on it, you can list\nthem with:\n\n.. sourcecode:: python\n\n    >>> client.topics\n    >>> topic = client.topics['my.test']\n\nonce you've got a `topic`, you can create a `producer` for it and start\nproducing messages.\n\n.. sourcecode:: python\n\n    >>> with topic.get_sync_producer() as producer:\n    ...     for i in range(4):\n    ...         producer.produce('test message ' + str(i ** 2))\n\nthe example above would produce to kafka synchronously - the call only\nreturns after we have confirmation that the message made it to the cluster.\n\nto achieve higher throughput, we recommend using the ``producer`` in\nasynchronous mode, so that ``produce()`` calls will return immediately and the\nproducer may opt to send messages in larger batches. the ``producer`` collects\nproduced messages in an internal queue for ``linger_ms`` before sending each batch.\nthis delay can be removed or changed at the expense of efficiency with ``linger_ms``,\n``min_queued_messages``, and other keyword arguments (see `readthedocs`_). you can still obtain\ndelivery confirmation for messages, through a queue interface which can be\nenabled by setting ``delivery_reports=true``.  here's a rough usage example:\n\n.. sourcecode:: python\n\n    >>> with topic.get_producer(delivery_reports=true) as producer:\n    ...     count = 0\n    ...     while true:\n    ...         count += 1\n    ...         producer.produce('test msg', partition_key='{}'.format(count))\n    ...         if count % 10 ** 5 == 0:  # adjust this or bring lots of ram ;)\n    ...             while true:\n    ...                 try:\n    ...                     msg, exc = producer.get_delivery_report(block=false)\n    ...                     if exc is not none:\n    ...                         print 'failed to deliver msg {}: {}'.format(\n    ...                             msg.partition_key, repr(exc))\n    ...                     else:\n    ...                         print 'successfully delivered msg {}'.format(\n    ...                         msg.partition_key)\n    ...                 except queue.empty:\n    ...                     break\n\nnote that the delivery report queue is thread-local: it will only serve reports\nfor messages which were produced from the current thread. also, if you're using\n`delivery_reports=true`, failing to consume the delivery report queue will cause\npykafka's memory usage to grow unbounded.\n\nyou can also consume messages from this topic using a `consumer` instance.\n\n.. sourcecode:: python\n\n    >>> consumer = topic.get_simple_consumer()\n    >>> for message in consumer:\n    ...     if message is not none:\n    ...         print message.offset, message.value\n    0 test message 0\n    1 test message 1\n    2 test message 4\n    3 test message 9\n\nthis `simpleconsumer` doesn't scale - if you have two `simpleconsumers`\nconsuming the same topic, they will receive duplicate messages. to get around\nthis, you can use the `balancedconsumer`.\n\n.. sourcecode:: python\n\n    >>> balanced_consumer = topic.get_balanced_consumer(\n    ...     consumer_group='testgroup',\n    ...     auto_commit_enable=true,\n    ...     zookeeper_connect='myzkclusternode1.com:2181,myzkclusternode2.com:2181/myzkchroot'\n    ... )\n\nyou can have as many `balancedconsumer` instances consuming a topic as that\ntopic has partitions. if they are all connected to the same zookeeper instance,\nthey will communicate with it to automatically balance the partitions between\nthemselves. the partition assignment strategy used by the `balancedconsumer` is\nthe \"range\" strategy by default. the strategy is switchable via the `membership_protocol`\nkeyword argument, and can be either an object exposed by `pykafka.membershipprotocol` or\na custom instance of `pykafka.membershipprotocol.groupmembershipprotocol`.\n\nyou can also use the kafka 0.9 group membership api with the ``managed``\nkeyword argument on ``get_balanced_consumer``.\n\nusing the librdkafka extension\n------------------------------\n\npykafka includes a c extension that makes use of librdkafka to speed up producer\nand consumer operation. to use the librdkafka extension, you need to make sure the header\nfiles and shared library are somewhere where python can find them, both when you build\nthe extension (which is taken care of by ``setup.py develop``) and at run time.\ntypically, this means that you need to either install librdkafka in a place\nconventional for your system, or declare ``c_include_path``, ``library_path``,\nand ``ld_library_path`` in your shell environment to point to the installation location\nof the librdkafka shared objects. you can find this location with `locate librdkafka.so`.\n\nafter that, all that's needed is that you pass an extra parameter\n``use_rdkafka=true`` to ``topic.get_producer()``,\n``topic.get_simple_consumer()``, or ``topic.get_balanced_consumer()``.  note\nthat some configuration options may have different optimal values; it may be\nworthwhile to consult librdkafka's `configuration notes`_ for this.\n\n.. _0.9.1: https://github.com/edenhill/librdkafka/releases/tag/0.9.1\n.. _configuration notes: https://github.com/edenhill/librdkafka/blob/0.9.1/configuration.md\n\noperational tools\n-----------------\n\npykafka includes a small collection of `cli tools`_ that can help with common tasks\nrelated to the administration of a kafka cluster, including offset and lag monitoring and\ntopic inspection. the full, up-to-date interface for these tools can be fould by running\n\n.. sourcecode:: sh\n\n    $ python cli/kafka_tools.py --help\n\nor after installing pykafka via setuptools or pip:\n\n.. sourcecode:: sh\n\n    $ kafka-tools --help\n\n.. _cli tools: https://github.com/parsely/pykafka/blob/master/pykafka/cli/kafka_tools.py\n\npykafka or kafka-python?\n------------------------\n\nthese are two different projects.\nsee `the discussion here <https://github.com/parsely/pykafka/issues/334>`_ for comparisons\nbetween the two projects.\n\ncontributing\n------------\n\nif you're interested in contributing code to pykafka, a good place to start is the\n`\"help wanted\"`_ issue tag. we also recommend taking a look at the `contribution guide`_.\n\n.. _\"help wanted\": https://github.com/parsely/pykafka/issues?q=is%3aopen+is%3aissue+label%3a%22help+wanted%22\n\nsupport\n-------\n\nif you need help using pykafka, there are a bunch of resources available.\nfor usage questions or common recipes, check out the `stackoverflow tag`_.\nthe `google group`_ can be useful for more in-depth questions or inquries\nyou'd like to send directly to the pykafka maintainers. if you believe you've\nfound a bug in pykafka, please open a `github issue`_ after reading the\n`contribution guide`_.\n\n.. _stackoverflow tag: https://stackoverflow.com/questions/tagged/pykafka\n.. _github issue: https://github.com/parsely/pykafka/issues\n.. _google group: https://groups.google.com/forum/#!forum/pykafka-user\n.. _contribution guide: https://github.com/parsely/pykafka/blob/master/contributing.rst",
  "docs_url": null,
  "keywords": "apache kafka client driver",
  "license": "apache license 2.0",
  "name": "pykafka",
  "package_url": "https://pypi.org/project/pykafka/",
  "project_url": "https://pypi.org/project/pykafka/",
  "project_urls": {
    "Homepage": "https://github.com/Parsely/pykafka"
  },
  "release_url": "https://pypi.org/project/pykafka/2.8.0/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "full-featured pure-python kafka client",
  "version": "2.8.0",
  "releases": [],
  "developers": [
    "keith_bourgoin_and_emmett_butler",
    "pykafka-user@googlegroups.com"
  ],
  "kwds": "kafka_tools kafkaclient kafka use_rdkafka librdkafka",
  "license_kwds": "apache license 2.0",
  "libtype": "pypi",
  "id": "pypi_pykafka",
  "homepage": "https://github.com/parsely/pykafka",
  "release_count": 38,
  "dependency_ids": []
}