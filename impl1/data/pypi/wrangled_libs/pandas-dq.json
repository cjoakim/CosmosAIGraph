{
  "classifiers": [
    "operating system :: os independent",
    "programming language :: python :: 3"
  ],
  "description": "# pandas_dq\n`pandas-dq` is the ultimate data quality toolkit for pandas dataframes.\n\n![pandas_dq](./images/pandas_dq_logo.png)\n\n# table of contents\n<ul>\n<li><a href=\"#introduction\">what is pandas_dq</a></li>\n<li><a href=\"#components\">what are its main components</a></li>\n<li><a href=\"#uses\">how to use pandas_dq</a></li>\n<li><a href=\"#install\">how to install pandas_dq</a></li>\n<li><a href=\"#usage\">usage</a></li>\n<li><a href=\"#api\">api</a></li>\n<li><a href=\"#maintainers\">maintainers</a></li>\n<li><a href=\"#contributing\">contributing</a></li>\n<li><a href=\"#license\">license</a></li>\n</ul>\n<p>\n\n## introduction\n`pandas_dq` is a new python library for data quality analysis and improvement. it is fast, efficient and scalable. `pandas-dq` is:\n- a smart and simple way to clean and improve your pandas dataframes.\n- a powerful way to boost your data analysis with high-quality pandas dataframes.\n- a powerful and flexible library for data quality management in pandas.\n\n### data quality made easy with pandas and scikit-learn transformers\nthe new `pandas_dq` library in python is a great addition to the `pandas` ecosystem. it provides a set of tools for data quality assessment, which can be used to identify and address potential problems with data sets. this can help to improve the quality of data analysis and ensure that results are reliable.\n\nthe `pandas_dq` library is still under development, but it already includes a number of useful features. these include:\n- <b>data profiling</b>: pandas_dq displays a report either in-line or in html to give you a quick overview of your data, including its features, feature types, their null and unique value percentages, their maximum and minimum values.\n- <b>train test comparison</b>: pandas_dq displays a comparison report either in-line or in html to give you a quick comparison of your train and test dataasets, including their distributional differences (using the ks test), and comparing their null and unique value percentages.\n- <b>data cleaning</b>: pandas_dq allows you to quickly identify and remove data quality issues and inconsistencies in your data set.\n- <b>data imputation</b>: pandas_dq allows you to fill missing values with your own choice of values for each feature in your data. for example, you can have one default for `age` feature and another for `income` feature.\n- <b>data transformation</b>: pandas_dq allows you to transform skewed features into a more normal-like distribution.\n\nthe `pandas_dq` library is a valuable tool for anyone who works with data. it can help you to improve the quality of your data analysis and ensure that your results are reliable.\n\nhere are some of the benefits of using the pandas_dq library:\n- it can help you to identify and address potential problems with data sets before modeling.\n- it can fix data quality issues and improve the quality of your data.\n- it is easy to use and can be integrated with other `scikit-learn` pipelines.\n\n<b>alert!</b>: if you are using `pandas version 2.0` (\"the new pandas\"), beware that weird errors are popping up in all kinds of libraries that use pandas underneath. our `pandas_dq` library is no exception. so if you plan to use `pandas_dq` with `pandas version 2.0`, beware that you may see weird errors and we can't and won't fix them!\n\n## components\n\n`pandas_dq` has the following main modules:\n<li><b>dq_report</b>: the data quality report displays a data quality report either inline or in html after it analyzes your dataset for various issues, such as missing values, outliers, duplicates, correlations, etc. it also checks the relationship between the features and the target variable (if provided) to detect data leakage.</li>\n<li><b>dc_report</b>: the data comparison report displays a comparison report between train and test datasets either inline or in html after it analyzes both datasets for various issues, such as missing values, unique values, min and max, etc. it also checks provides a statistical test (ks test) to compare the distribitional differences of numeric features to detect data drift. you can exclude target column(s) from comparison between train and test.</li>\n<li><b>fix_dq</b>: this class is a scikit-learn compatible transformer that can detect and fix data quality issues in one line of code. it can remove id columns, zero-variance columns, rare categories, infinite values, mixed data types, outliers, high cardinality features, highly correlated features, duplicate rows and columns, skewed distributions and imbalanced classes.</li>\n<li><b>dataschemachecker</b>: this class can check your dataset data types against a specific schema and report any mismatches or errors.</li>\n\n`pandas_dq` is designed to provide you the cleanest features with the fewest steps.\n\n## uses\n`pandas_dq` has multiple important modules: `dq_report`, `fix_dq` and now `dataschemachecker`. <br>\n\n### 1.  dq_report function\n\n![dq_report_code](./images/find_dq_screenshot.png)\n\n<p>`dq_report` displays a data quality report (inline or html) after it analyzes your dataset looking for these issues:\n<ol>\n<li>it detects id columns</li>\n<li>it detects zero-variance columns </li>\n<li>it identifies rare categories (less than 5% of categories in a column)</li>\n<li>it finds infinite values in a column</li>\n<li>it detects mixed data types (i.e. a column that has more than a single data type)</li>\n<li>it detects outliers (i.e. a float column that is beyond the inter quartile range)</li>\n<li>it detects high cardinality features (i.e. a feature that has more than 100 categories)</li>\n<li>it detects highly correlated features (i.e. two features that have an absolute correlation higher than 0.8)</li>\n<li>it detects duplicate rows (i.e. the same row occurs more than once in the dataset)</li>\n<li>it detects duplicate columns (i.e. the same column occurs twice or more in the dataset)</li>\n<li>it detects skewed distributions (i.e. a feature that has a skew more than 1.0) </li>\n<li>it detects imbalanced classes (i.e. target variable has one class more than other in a significant way) </li>\n<li>it detects feature leakage (i.e. a feature that is highly correlated to target with correlation > 0.8)</li>\n</ol>\nnotice that for large datasets, this report generation may take time, hence we read a 100k sample from your csv file. if you want us to read the whole data, then send it in as a dataframe.\n\n### 2.  dc_report function\n\n![dc_report_code](./images/dc_report.png)\n\n`dc_report` is a data comparison tool that accepts two pandas dataframes as input and returns a report highlighting any differences between them. for example:\n<ol>\n<li>the function uses our function `dqr = dq_report(df)` to generate a data quality report for each dataframe and compares the results using the column names from the report.</li>\n<li>it also computes the kolmogorov-smirnov test statistic to measure the distribution difference for numeric columns with low cardinality.</li>\n<li>it also compares the missing values% and unique values% between the two dataframes and adds a comment in the \"distribution difference\" column if the two percentages are different.</li>\n<li>you can exclude target column(s) from comparison between train and test.</li>\n- notice that for large datasets, this report generation may take time. so make sure you take a sample of your train and test data before calling this report!\n</ol>\n\n### 3.  fix_dq class: a scikit_learn transformer which can detect data quality issues and fix them all in one line of code\n\n![fix_dq](./images/fix_dq_screenshot.png)\n\n<p>`fix_dq` is a great way to clean an entire train data set and apply the same steps in an mlops pipeline to a test dataset.  `fix_dq` can be used to detect most issues in your data (similar to dq_report but without the `target` related issues) in one step. then it fixes those issues it finds during the `fit` method by the `transform` method. this transformer can then be saved (or \"pickled\") for applying the same steps on test data either at the same time or later.<br>\n<p>fix_dq will perform following data quality cleaning steps:\n<ol>\n<li>it removes id columns from further processing</li>\n<li>it removes zero-variance columns from further processing</li>\n<li>it identifies rare categories and groups them into a single category called \"rare\"</li>\n<li>it finds infinite values and replaces them with an upper bound based on inter quartile range</li>\n<li>it detects mixed data types and drops those mixed-type columns from further processing</li>\n<li>it detects outliers and suggests to remove them or use robust statistics.</li>\n<li>it detects high cardinality features but leaves them as it is.</li>\n<li>it detects highly correlated features and drops one of them (whichever comes first in the column sequence)</li>\n<li>it detects duplicate rows and drops one of them or keeps only one copy of duplicate rows</li>\n<li>it detects duplicate columns and drops one of them or keeps only one copy</li>\n<li>it detects skewed distributions and applies log or box-cox transformations on them </li>\n<li>it detects imbalanced classes and leaves them as it is </li>\n<li>it detects feature leakage and drops one of those features if they are highly correlated to target </li>\n</ol>\n\n<b>how can we use fix_dq in gridsearchcv to find the best model pipeline?</b>\n<p>this is another way to find the best data cleaning steps for your train data and then use the cleaned data in hyper parameter tuning using gridsearchcv or randomizedsearchcv along with a lightgbm or an xgboost or a scikit-learn model.<br>\n\n### 4.  dataschemachecker class: a scikit_learn transformer that can check whether a pandas dataframe conforms to a given schema and coerces the data to conform to it.\nthe dataschemachecker class has two methods: fit and transform. you need to initialize the class with a schema that you want to compare your data's dtypes against. a schema is a dictionary that maps column names to data types. \n\nthe fit method takes a dataframe as an argument and checks if it matches the schema. the fit method first checks if the number of columns in the dataframe and the schema are equal. if not, it creates an exception. finally, the fit method displays a table of exceptions it found in your data against the given schema. \n\nthe transform method takes a dataframe as an argument and based on the given schema and the exceptions, converts all the exception data columns to the given schema. if it is not able to transform the column, it skips the column and displays out an error message.\n\n![dq_ds](./images/data_schema_checker.png)\n\n## install\n<p>\n\n**prerequsites:**\n<ol>\n<li><b>pandas_dq is built using pandas, numpy and scikit-learn - that's all.</b> it should run on almost all python3 anaconda installations without additional installs. you won't have to import any special libraries.</li>\n</ol>\nthe best method to install pandas_dq is to use pip:<p>\n\n```\npip install pandas_dq \n```\n\nto install from source:\n\n```\ncd <pandas_dq_destination>\ngit clone git@github.com:autoviml/pandas_dq.git\n```\nor download and unzip https://github.com/autoviml/pandas_dq/archive/master.zip\n```\nconda create -n <your_env_name> python=3.7 anaconda\nconda activate <your_env_name> # on windows: `source activate <your_env_name>`\ncd pandas_dq\npip install -r requirements.txt\n```\n\n## usage\n\n### to get a quick profile of your data, can simply call dq_report\n\n```\nfrom pandas_dq import dq_report\ndqr = dq_report(data, target=target, html=false, csv_engine=\"pandas\", verbose=1)\n```\n\nit displays a data quality report like this inline or in html format (and it saves the html to your machine):\n\n![dq_report](./images/dq_report_screenshot.png)\n\n### to get a quick comparison of two sets of data frames,  simply call dc_report\n`dc_report` is data comparison tool that accepts two pandas dataframes as input and returns a report highlighting any differences between them. it can also provide a report in html format as below.\n\n```\nfrom pandas_dq import dc_report\ndc_report = dc_report(train, test, exclude=[], html=true, verbose=1)\n```\n\n![dc_report_screenshot](./images/dc_report_screenshot.png)\n\n### to fix your data quality issues, use `fix_dq` as a scikit-learn compatible transformer<p>\n\n```\nfrom pandas_dq import fix_dq\n\n# create an instance of the fix_data_quality transformer with default parameters\nfdq = fix_dq()\n\n# fit the transformer on x_train and transform it\nx_train_transformed = fdq.fit_transform(x_train)\n\n# transform x_test using the fitted transformer\nx_test_transformed = fdq.transform(x_test)\n\n```\n\n### to validate that your data conforms to a given schema, use dataschemachecker:\n\nonce you define the schema as below, you can use it as follows:\n\n```\nschema = {'name': 'string',\n        'age': 'float32',\n        'gender': 'object',\n        'income': 'float64',\n        'date': 'date',\n        'target': 'integer'}\n```\n\n```\nfrom pandas_dq import dataschemachecker\n\nds = dataschemachecker(schema=schema)\nds.fit_transform(x_train)\ndf.transform(x_test)\n```\n\n## api\n\n<p>\npandas_dq has a very simple api with one major goal: find data quality issues in your data and fix them.\n\n**arguments**\n\n### `dq_report` has the following arguments:<br>\n<b>caution:</b> for very large data sets, we randomly sample 100k rows from your csv file to speed up reporting. if you want a larger sample, simply read in your file offline into a pandas dataframe and send it in as input, and we will load it as it is. this is one way to go around our speed limitations:\n\n#### inputs:\n- `data`: you can provide any kind of file format (string) or even a pandas dataframe (df). it reads parquet, csv, feather, arrow, all kinds of file formats straight from disk. you just have to tell it the path to the file and the name of the file. \n- `target`: default: `none`. otherwise, it should be a string name representing the name of a column in df. you can leave it as `none` if you don't want any target related issues.\n- `html`: default is `false`. if you want to display your report in html in a browser, set it to `true`. otherwise, it defaults to inline in a notebook or prints on the terminal. it also saves the html file in your working directory in your machine.\n- `csv_engine`: default is `pandas`. if you want to load your csv file using any other backend engine such as `arrow` or `parquet` please specify it here. this option only impacts csv files.\n- `verbose`: this has 2 possible states:\n  - `0` summary report. displays only the summary level data quality issues in the dataset. great for managers.\n  - `1` detailed report. displays all the gory details behind each dq issue in your dataset and what to do about them. great for engineers.\n#### outputs:\n- `dataframe`: if verbose=1, it returns a dataframe with detailed data quality issues with your data. if verbose=0, it returns with a dataframe containing only the highlights of the data quality issues.\n\n`dc_report` returns a dataframe highlighting differences between two dataframes, typically train and test. it has the following inputs and outputs:\n#### inputs:\n- `train`: a dataframe\n- `test`: a dataframe \n- `exclude`: an empty list or a list of columns that you want to exclude from comparison in both dataframes\n- `html`: return a html file containing the differences between the two dataframes\n- `verbose`: 0 will return just the highlights of differences. 1 will return a detailed description of differences between the two dataframes.\n\n#### outputs:\n- `dataframe`: if verbose=1, it returns a dataframe with the following column names: column name, data type train, data type test, missing values% train, missing values% test, unique values% train, unique values% test, minimum value train, minimum value test, maximum value train, maximum value test, dq issue train, dq issue test, distribution difference. if verbose=0, it will return only the following columns: column name, dq issue train, dq issue test, distribution difference.\n\n### `fix_dq` is a scikit-learn transformer. it finds and fixes data quality issues in your data<br>\n<b>caution:</b> x_train and x_test in fix_dq must be pandas dataframes or pandas series. i have not tested it on numpy arrays. you can try your luck.\n\n#### inputs:\n- `x_train` : a pandas dataframe\n- `x_test` : a pandas dataframe\n- `quantile`: float (0.75): define a threshold for iqr for outlier detection. could be any float between 0 and 1. if quantile is set to `none`, then no outlier detection will take place.\n- `cat_fill_value`: string (\"missing\") or a dictionary: define a fill value for missing categories in your object or categorical variables. this is a global default for your entire dataset. you can also give a dictionary where you specify different fill values for different columns.\n- `num_fill_value`: integer (99) or float value (999.0) or a dictionary: define a fill value for missing numbers in your integer or float variables.  this is a global default for your entire dataset. you can also give a dictionary where you specify different fill values for different columns.\n- `rare_threshold`: float (0.05):  define a threshold for rare categories. if a certain category in a column is less than say 5% (0.05) of samples, then it will be considered rare. all rare categories in that column will be merged under a new category named \"rare\". \n- `correlation_threshold`: float (0.8): define a correlation limit. anything above this limit, if two variables are correlated, one of them will be dropped. the program will tell you which variable is being dropped. you can switch the sequence of variables in your dataset if you want the one or other dropped.<br>\n\n### `dataschemachecker` is a scikit-learn transformer. it checks you data against a given schema<br>\n#### inputs:\n- `schema`: dictionary. a schema (dict) is a dictionary that maps column names to data types. this schema will determine the data types of whatever dataframe you want to comply with.\n\ndataschemachecker has two methods:\n- `fit` method: checks if the given dataframe matches the schema and displays a table of errors if any.\n- `transform` method: transforms the given dataframe's dtypes to the given schema and displays errors if any.\n\n## maintainers\n\n* [@autoviml](https://github.com/autoviml)\n\n## contributing\n\nsee [the contributing file](contributing.md)!\n\nprs accepted.\n\n## license\n\napache license 2.0 \u00a9 2020 ram seshadri\n\n## note of gratitude\n\nthis libray would not have been possible without the help of chatgpt and bard. this library is dedicated to the thousands of people who worked to create llm's. \n\n## disclaimer\nthis project is not an official google project. it is not supported by google and google specifically disclaims all warranties as to its quality, merchantability, or fitness for a particular purpose.\n\n\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache license 2.0",
  "name": "pandas-dq",
  "package_url": "https://pypi.org/project/pandas-dq/",
  "project_url": "https://pypi.org/project/pandas-dq/",
  "project_urls": {
    "Homepage": "https://github.com/AutoViML/pandas_dq"
  },
  "release_url": "https://pypi.org/project/pandas-dq/1.29/",
  "requires_dist": [
    "numpy (>=1.21.5)",
    "pandas (>=1.3.5)",
    "scikit-learn (>=0.24.2)"
  ],
  "requires_python": "",
  "summary": "clean your data using a scikit-learn transformer in a single line of code",
  "version": "1.29",
  "releases": [],
  "developers": [
    "ram_seshadri"
  ],
  "kwds": "pandas_dq pandas_dq_logo pandas_dq_destination pandas dataframe",
  "license_kwds": "apache license 2.0",
  "libtype": "pypi",
  "id": "pypi_pandas_dq",
  "homepage": "https://github.com/autoviml/pandas_dq",
  "release_count": 19,
  "dependency_ids": [
    "pypi_numpy",
    "pypi_pandas",
    "pypi_scikit_learn"
  ]
}