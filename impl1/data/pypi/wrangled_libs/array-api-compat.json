{
  "classifiers": [
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# array api compatibility library\n\nthis is a small wrapper around common array libraries that is compatible with\nthe [array api standard](https://data-apis.org/array-api/latest/). currently,\nnumpy, cupy, and pytorch are supported. if you want support for other array\nlibraries, or if you encounter any issues, please [open an\nissue](https://github.com/data-apis/array-api-compat/issues).\n\nnote that some of the functionality in this library is backwards incompatible\nwith the corresponding wrapped libraries. the end-goal is to eventually make\neach array library itself fully compatible with the array api, but this\nrequires making backwards incompatible changes in many cases, so this will\ntake some time.\n\ncurrently all libraries here are implemented against the [2022.12\nversion](https://data-apis.org/array-api/2022.12/) of the standard.\n\n## install\n\n`array-api-compat` is available on both [pypi](https://pypi.org/project/array-api-compat/)\n\n```\npython -m pip install array-api-compat\n```\n\nand [conda-forge](https://anaconda.org/conda-forge/array-api-compat)\n\n```\nconda install --channel conda-forge array-api-compat\n```\n\n## usage\n\nthe typical usage of this library will be to get the corresponding array api\ncompliant namespace from the input arrays using `array_namespace()`, like\n\n```py\ndef your_function(x, y):\n    xp = array_api_compat.array_namespace(x, y)\n    # now use xp as the array library namespace\n    return xp.mean(x, axis=0) + 2*xp.std(y, axis=0)\n```\n\nif you wish to have library-specific code-paths, you can import the\ncorresponding wrapped namespace for each library, like\n\n```py\nimport array_api_compat.numpy as np\n```\n\n```py\nimport array_api_compat.cupy as cp\n```\n\n```py\nimport array_api_compat.torch as torch\n```\n\neach will include all the functions from the normal numpy/cupy/pytorch\nnamespace, except that functions that are part of the array api are wrapped so\nthat they have the correct array api behavior. in each case, the array object\nused will be the same array object from the wrapped library.\n\n## difference between `array_api_compat` and `numpy.array_api`\n\n`numpy.array_api` is a strict minimal implementation of the array api (see\n[nep 47](https://numpy.org/neps/nep-0047-array-api-standard.html)). for\nexample, `numpy.array_api` does not include any functions that are not part of\nthe array api specification, and will explicitly disallow behaviors that are\nnot required by the spec (e.g., [cross-kind type\npromotions](https://data-apis.org/array-api/latest/api_specification/type_promotion.html)).\n(`cupy.array_api` is similar to `numpy.array_api`)\n\n`array_api_compat`, on the other hand, is just an extension of the\ncorresponding array library namespaces with changes needed to be compliant\nwith the array api. it includes all additional library functions not mentioned\nin the spec, and allows any library behaviors not explicitly disallowed by it,\nsuch as cross-kind casting.\n\nin particular, unlike `numpy.array_api`, this package does not use a separate\n`array` object, but rather just uses the corresponding array library array\nobjects (`numpy.ndarray`, `cupy.ndarray`, `torch.tensor`, etc.) directly. this\nis because those are the objects that are going to be passed as inputs to\nfunctions by end users. this does mean that a few behaviors cannot be wrapped\n(see below), but most of the array api functional, so this does not affect\nmost things.\n\narray consuming library authors coding against the array api may wish to test\nagainst `numpy.array_api` to ensure they are not using functionality outside\nof the standard, but prefer this implementation for the default behavior for\nend-users.\n\n## helper functions\n\nin addition to the wrapped library namespaces and functions in the array api\nspecification, there are several helper functions included here that aren't\npart of the specification but which are useful for using the array api:\n\n- `is_array_api_obj(x)`: return `true` if `x` is an array api compatible array\n  object.\n\n- `array_namespace(*xs)`: get the corresponding array api namespace for the\n  arrays `xs`. for example, if the arrays are numpy arrays, the returned\n  namespace will be `array_api_compat.numpy`. note that this function will\n  also work for namespaces that aren't supported by this compat library but\n  which do support the array api (i.e., arrays that have the\n  `__array_namespace__` attribute).\n\n- `device(x)`: equivalent to\n  [`x.device`](https://data-apis.org/array-api/latest/api_specification/generated/signatures.array_object.array.device.html)\n  in the array api specification. included because `numpy.ndarray` does not\n  include the `device` attribute and this library does not wrap or extend the\n  array object. note that for numpy, `device(x)` is always `\"cpu\"`.\n\n- `to_device(x, device, /, *, stream=none)`: equivalent to\n  [`x.to_device`](https://data-apis.org/array-api/latest/api_specification/generated/signatures.array_object.array.to_device.html).\n  included because neither numpy's, cupy's, nor pytorch's array objects\n  include this method. for numpy, this function effectively does nothing since\n  the only supported device is the cpu, but for cupy, this method supports\n  cupy cuda\n  [device](https://docs.cupy.dev/en/stable/reference/generated/cupy.cuda.device.html)\n  and\n  [stream](https://docs.cupy.dev/en/stable/reference/generated/cupy.cuda.stream.html)\n  objects. for pytorch, this is the same as\n  [`x.to(device)`](https://pytorch.org/docs/stable/generated/torch.tensor.to.html)\n  (the `stream` argument is not supported in pytorch).\n\n- `size(x)`: equivalent to\n  [`x.size`](https://data-apis.org/array-api/latest/api_specification/generated/array_api.array.size.html#array_api.array.size),\n  i.e., the number of elements in the array. included because pytorch's\n  `tensor` defines `size` as a method which returns the shape, and this cannot\n  be wrapped because this compat library doesn't wrap or extend the array\n  objects.\n\n## known differences from the array api specification\n\nthere are some known differences between this library and the array api\nspecification:\n\n### numpy and cupy\n\n- the array methods `__array_namespace__`, `device` (for numpy), `to_device`,\n  and `mt` are not defined. this reuses `np.ndarray` and `cp.ndarray` and we\n  don't want to monkeypatch or wrap it. the helper functions `device()` and\n  `to_device()` are provided to work around these missing methods (see above).\n  `x.mt` can be replaced with `xp.linalg.matrix_transpose(x)`.\n  `array_namespace(x)` should be used instead of `x.__array_namespace__`.\n\n- value-based casting for scalars will be in effect unless explicitly disabled\n  with the environment variable `npy_promotion_state=weak` or\n  `np._set_promotion_state('weak')` (requires numpy 1.24 or newer, see [nep\n  50](https://numpy.org/neps/nep-0050-scalar-promotion.html) and\n  https://github.com/numpy/numpy/issues/22341)\n\n- `asarray()` does not support `copy=false`.\n\n- functions which are not wrapped may not have the same type annotations\n  as the spec.\n\n- functions which are not wrapped may not use positional-only arguments.\n\nthe minimum supported numpy version is 1.21. however, this older version of\nnumpy has a few issues:\n\n- `unique_*` will not compare nans as unequal.\n- `finfo()` has no `smallest_normal`.\n- no `from_dlpack` or `__dlpack__`.\n- `argmax()` and `argmin()` do not have `keepdims`.\n- `qr()` doesn't support matrix stacks.\n- `asarray()` doesn't support `copy=true` (as noted above, `copy=false` is not\n  supported even in the latest numpy).\n- type promotion behavior will be value based for 0-d arrays (and there is no\n  `npy_promotion_state=weak` to disable this).\n\nif any of these are an issue, it is recommended to bump your minimum numpy\nversion.\n\n### pytorch\n\n- like numpy/cupy, we do not wrap the `torch.tensor` object. it is missing the\n  `__array_namespace__` and `to_device` methods, so the corresponding helper\n  functions `array_namespace()` and `to_device()` in this library should be\n  used instead (see above).\n\n- the `x.size` attribute on `torch.tensor` is a function that behaves\n  differently from\n  [`x.size`](https://data-apis.org/array-api/draft/api_specification/generated/array_api.array.size.html)\n  in the spec. use the `size(x)` helper function as a portable workaround (see\n  above).\n\n- pytorch does not have unsigned integer types other than `uint8`, and no\n  attempt is made to implement them here.\n\n- pytorch has type promotion semantics that differ from the array api\n  specification for 0-d tensor objects. the array functions in this wrapper\n  library do work around this, but the operators on the tensor object do not,\n  as no operators or methods on the tensor object are modified. if this is a\n  concern, use the functional form instead of the operator form, e.g., `add(x,\n  y)` instead of `x + y`.\n\n- [`unique_all()`](https://data-apis.org/array-api/latest/api_specification/generated/array_api.unique_all.html#array_api.unique_all)\n  is not implemented, due to the fact that `torch.unique` does not support\n  returning the `indices` array. the other\n  [`unique_*`](https://data-apis.org/array-api/latest/api_specification/set_functions.html)\n  functions are implemented.\n\n- slices do not support negative steps.\n\n- [`std()`](https://data-apis.org/array-api/latest/api_specification/generated/array_api.std.html#array_api.std)\n  and\n  [`var()`](https://data-apis.org/array-api/latest/api_specification/generated/array_api.var.html#array_api.var)\n  do not support floating-point `correction`.\n\n- the `stream` argument of the `to_device()` helper (see above) is not\n  supported.\n\n- as with numpy, type annotations and positional-only arguments may not\n  exactly match the spec for functions that are not wrapped at all.\n\nthe minimum supported pytorch version is 1.13.\n\n## vendoring\n\nthis library supports vendoring as an installation method. to vendor the\nlibrary, simply copy `array_api_compat` into the appropriate place in the\nlibrary, like\n\n```\ncp -r array_api_compat/ mylib/vendored/array_api_compat\n```\n\nyou may also rename it to something else if you like (nowhere in the code\nreferences the name \"array_api_compat\").\n\nalternatively, the library may be installed as dependency on pypi.\n\n## implementation notes\n\nas noted before, the goal of this library is to reuse the numpy and cupy array\nobjects, rather than wrapping or extending them. this means that the functions\nneed to accept and return `np.ndarray` for numpy and `cp.ndarray` for cupy.\n\neach namespace (`array_api_compat.numpy`, `array_api_compat.cupy`, and\n`array_api_compat.torch`) is populated with the normal library namespace (like\n`from numpy import *`). then specific functions are replaced with wrapped\nvariants.\n\nsince numpy and cupy are nearly identical in behavior, most wrapping logic can\nbe shared between them. wrapped functions that have the same logic between\nnumpy and cupy are in `array_api_compat/common/`.\nthese functions are defined like\n\n```py\n# in array_api_compat/common/_aliases.py\n\ndef acos(x, /, xp):\n    return xp.arccos(x)\n```\n\nthe `xp` argument refers to the original array namespace (either `numpy` or\n`cupy`). then in the specific `array_api_compat/numpy/` and\n`array_api_compat/cupy/` namespaces, the `@get_xp` decorator is applied to\nthese functions, which automatically removes the `xp` argument from the\nfunction signature and replaces it with the corresponding array library, like\n\n```py\n# in array_api_compat/numpy/_aliases.py\n\nfrom ..common import _aliases\n\nimport numpy as np\n\nacos = get_xp(np)(_aliases.acos)\n```\n\nthis `acos` now has the signature `acos(x, /)` and calls `numpy.arccos`.\n\nsimilarly, for cupy:\n\n```py\n# in array_api_compat/cupy/_aliases.py\n\nfrom ..common import _aliases\n\nimport cupy as cp\n\nacos = get_xp(cp)(_aliases.acos)\n```\n\nsince numpy and cupy are nearly identical in their behaviors, this allows\nwriting the wrapping logic for both libraries only once.\n\npytorch uses a similar layout in `array_api_compat/torch/`, but it differs\nenough from numpy/cupy that very few common wrappers for those libraries are\nreused.\n\nsee https://numpy.org/doc/stable/reference/array_api.html for a full list of\nchanges from the base numpy (the differences for cupy are nearly identical). a\ncorresponding document does not yet exist for pytorch, but you can examine the\nvarious comments in the\n[implementation](https://github.com/data-apis/array-api-compat/blob/main/array_api_compat/torch/_aliases.py)\nto see what functions and behaviors have been wrapped.\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "array-api-compat",
  "package_url": "https://pypi.org/project/array-api-compat/",
  "project_url": "https://pypi.org/project/array-api-compat/",
  "project_urls": {
    "Homepage": "https://data-apis.org/array-api-compat/"
  },
  "release_url": "https://pypi.org/project/array-api-compat/1.4/",
  "requires_dist": [
    "cupy ; extra == 'cupy'",
    "numpy ; extra == 'numpy'"
  ],
  "requires_python": ">=3.8",
  "summary": "a wrapper around numpy and other array libraries to make them compatible with the array api standard",
  "version": "1.4",
  "releases": [],
  "developers": [
    "consortium_for_python_data_api_standards"
  ],
  "kwds": "array_api_compat array_api is_array_api_obj array_namespace __array_namespace__",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_array_api_compat",
  "homepage": "https://data-apis.org/array-api-compat/",
  "release_count": 6,
  "dependency_ids": [
    "pypi_cupy",
    "pypi_numpy"
  ]
}