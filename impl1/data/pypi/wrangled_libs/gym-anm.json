{
  "classifiers": [
    "license :: osi approved :: mit license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# gym-anm\n[![downloads](https://pepy.tech/badge/gym-anm)](https://pepy.tech/project/gym-anm)\n[![documentation status](https://readthedocs.org/projects/ansicolortags/badge/?version=latest)](https://gym-anm.readthedocs.io/en/latest/)\n[![codecov](https://codecov.io/gh/robinhenry/gym-anm/branch/master/graph/badge.svg?token=7jsmjppiq7)](https://codecov.io/gh/robinhenry/gym-anm)\n[![checks](https://github.com/robinhenry/gym-anm/actions/workflows/ci_checks.yml/badge.svg)](https://github.com/robinhenry/gym-anm/actions/workflows/ci_checks.yml)\n[![license: mit](https://img.shields.io/badge/license-mit-yellow.svg)](https://opensource.org/licenses/mit)\n\n`gym-anm` is a framework for designing reinforcement learning (rl) environments that model active network\nmanagement (anm) tasks in electricity distribution networks. it is built on top of the\n[openai gym](https://github.com/openai/gym) toolkit.\n\nthe `gym-anm` framework was designed with one goal in mind: **bridge the gap between research in rl and in\nthe management of power systems**. we attempt to do this by providing rl researchers with an easy-to-work-with\nlibrary of environments that model decision-making tasks in power grids.\n\n**papers:**\n*  [gym-anm: reinforcement learning environments for active network management tasks in electricity distribution systems](https://doi.org/10.1016/j.egyai.2021.100092)\n*  [gym-anm: open-source software to leverage reinforcement learning for power system management in research and education](https://doi.org/10.1016/j.simpa.2021.100092)\n\n## key features\n*  very little background in electricity systems modelling it required. this makes `gym-anm` an ideal starting point\n   for rl students and researchers looking to enter the field.\n*  the environments (tasks) generated by `gym-anm` follow the [openai gym](https://github.com/openai/gym)\n   framework, with which a large part of the rl community is already familiar.\n*  the flexibility of `gym-anm`, with its different customizable components, makes it a suitable framework\n   to model a wide range of anm tasks, from simple ones that can be used for educational purposes, to complex ones\n   designed to conduct advanced research.\n\n## documentation\ndocumentation is provided online at [https://gym-anm.readthedocs.io/en/latest/](https://gym-anm.readthedocs.io/en/latest/).\n\n## installation\n\n### requirements\n`gym-anm` requires python 3.8+ and can run on linux, maxos, and windows. some rendering features may not work properly\non windows (not tested).\n\nwe recommend installing `gym-anm` in a python environment (e.g., [virtualenv](https://virtualenv.pypa.io/en/latest/)\nor [conda](https://conda.io/en/latest/#)).\n\n### using pip\nusing pip (preferably after activating your virtual environment):\n```\npip install gym-anm\n```\n\n### building from source\nalternatively, you can build `gym-anm` directly from source:\n```\ngit clone https://github.com/robinhenry/gym-anm.git\ncd gym-anm\npip install -e .\n```\n\n## example\nthe following code snippet illustrates how `gym-anm` environments can be used. in this example,\nactions are randomly sampled from the action space of the environment `anm6easy-v0`. for more information\nabout the agent-environment interface, see the official [openai gym documentation](https://github.com/openai/gym).\n```\nimport gym\nimport time\n\ndef run():\n   env = gym.make('gym_anm:anm6easy-v0')\n   o = env.reset()\n\n   for i in range(100):\n       a = env.action_space.sample()\n       o, r, done, info = env.step(a)\n       env.render()\n       time.sleep(0.5)  # otherwise the rendering is too fast for the human eye.\n\n   env.close()\n\nif __name__ == '__main__':\n    run()\n```\nthe above code would render the environment in your default web browser as shown in the image below:\n![alt text](https://github.com/robinhenry/gym-anm/blob/master/docs/source/images/anm6-easy-example.png?raw=true)\n\nadditional example scripts can be found in [examples/](examples).\n\n## testing the installation\nall unit tests in `gym-anm` can be ran from the project root directory with:\n```\npython -m pytest tests\n```\n\n## contributing\ncontributions are always welcome! please read the [contribution guidelines](contributing.md) first.\n\n## citing the project\nall publications derived from the use of `gym-anm` should cite the following two 2021 papers:\n```\n@article{henry2021100092,\n    title = {gym-anm: reinforcement learning environments for active network management tasks in electricity distribution systems},\n    journal = {energy and ai},\n    volume = {5},\n    pages = {100092},\n    year = {2021},\n    issn = {2666-5468},\n    doi = {https://doi.org/10.1016/j.egyai.2021.100092},\n    author = {robin henry and damien ernst},\n}\n```\n```\n@article{henry2021100092,\n    title = {gym-anm: open-source software to leverage reinforcement learning for power system management in research and education},\n    journal = {software impacts},\n    volume = {9},\n    pages = {100092},\n    year = {2021},\n    issn = {2665-9638},\n    doi = {https://doi.org/10.1016/j.simpa.2021.100092},\n    author = {robin henry and damien ernst}\n}\n```\n\n## maintainers\n`gym-anm` is currently maintained by [robin henry](https://www.robinxhenry.com/).\n\n## license\nthis project is licensed under the mit license - see the [license.md](license.md) file for details.\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "gym-anm",
  "package_url": "https://pypi.org/project/gym-anm/",
  "project_url": "https://pypi.org/project/gym-anm/",
  "project_urls": {
    "Documentation": "https://gym-anm.readthedocs.io/en/latest/",
    "Homepage": "https://github.com/robinhenry/gym-anm",
    "Repository": "https://github.com/robinhenry/gym-anm"
  },
  "release_url": "https://pypi.org/project/gym-anm/1.1.6/",
  "requires_dist": [
    "cvxpy (>=1.2.2,<2.0.0)",
    "gym (>=0.26.2,<0.27.0)",
    "numpy (>=1.23.5,<2.0.0)",
    "pandas (>=1.5.2,<2.0.0)",
    "requests (>=2.28.1,<3.0.0)",
    "websocket-client (==0.56.0)",
    "websocket-server (==0.4)"
  ],
  "requires_python": ">=3.8,<4.0",
  "summary": "a framework to build reinforcement learning environments for active network management tasks in electricity networks.",
  "version": "1.1.6",
  "releases": [],
  "developers": [
    "robin@robinxhenry.com",
    "robin_henry"
  ],
  "kwds": "gym_anm badge gym anm ci_checks",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_gym_anm",
  "homepage": "https://github.com/robinhenry/gym-anm",
  "release_count": 9,
  "dependency_ids": [
    "pypi_cvxpy",
    "pypi_gym",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_requests",
    "pypi_websocket_client",
    "pypi_websocket_server"
  ]
}