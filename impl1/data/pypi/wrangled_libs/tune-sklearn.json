{
  "classifiers": [],
  "description": "# tune-sklearn\n[![pytest](https://github.com/ray-project/tune-sklearn/workflows/development/badge.svg)](https://github.com/ray-project/tune-sklearn/actions?query=workflow%3a%22development%22)\n\ntune-sklearn is a drop-in replacement for scikit-learn\u2019s model selection module (gridsearchcv, randomizedsearchcv) with cutting edge hyperparameter tuning techniques.\n\n## \u26a0\ufe0f `tune-sklearn` is no longer being maintained\n\nthe latest release `0.5.0` is the last version of the library that will be released by the ray team, and it is compatible\nwith `ray>=2.7.x, ray<=2.9.x`. the library will not be guaranteed to work with future ray versions.\n\nthe recommended alternative to keep up with the latest version of ray is to migrate `tune-sklearn` usage\nto the [ray tune apis](https://docs.ray.io/en/latest/tune/getting-started.html) to accomplish the same thing.\n\nfeel free to post an issue on the [ray github](https://github.com/ray-project/ray) if you run into any issues in migrating.\n\n## features\nhere\u2019s what tune-sklearn has to offer:\n\n * **consistency with scikit-learn api**: change less than 5 lines in a standard scikit-learn script to use the api [[example](https://github.com/ray-project/tune-sklearn/blob/master/examples/random_forest.py)].\n * **modern tuning techniques**: tune-sklearn allows you to easily leverage bayesian optimization, hyperband, bohb, and other optimization techniques by simply toggling a few parameters.\n * **framework support**: tune-sklearn is used primarily for tuning scikit-learn models, but it also supports and provides examples for many other frameworks with scikit-learn wrappers such as skorch (pytorch) [[example](https://github.com/ray-project/tune-sklearn/blob/master/examples/torch_nn.py)], kerasclassifier (keras) [[example](https://github.com/ray-project/tune-sklearn/blob/master/examples/keras_example.py)], and xgboostclassifier (xgboost) [[example](https://github.com/ray-project/tune-sklearn/blob/master/examples/xgbclassifier.py)].\n * **scale up**: tune-sklearn leverages [ray tune](http://tune.io/), a library for distributed hyperparameter tuning, to parallelize cross validation on multiple cores and even multiple machines without changing your code.\n\ncheck out our [api documentation](docs) and [walkthrough](https://docs.ray.io/en/master/tune/examples/tune-sklearn.html) (for `master` branch).\n\n## installation\n\n### dependencies\n- numpy (>=1.16)\n- [ray](http://docs.ray.io/) (>=2.7.0)\n- scikit-learn (>=0.23)\n\n### user installation\n\n`pip install tune-sklearn ray[tune]`\n\nor\n\n`pip install -u git+https://github.com/ray-project/tune-sklearn.git && pip install 'ray[tune]'`\n\n\n### tune-sklearn early stopping\n\nfor certain estimators, tune-sklearn can also immediately enable **incremental training and early stopping**. such estimators include:\n * estimators that implement 'warm_start' (except for ensemble classifiers and decision trees)\n * estimators that implement partial fit\n * [xgboost](https://github.com/dmlc/xgboost/issues/1686), lightgbm and [catboost](https://catboost.ai/docs/concepts/python-reference_train.html?lang=en) models (via incremental learning)\n\nto read more about compatible scikit-learn models, see [scikit-learn's documentation at section 8.1.1.3](https://scikit-learn.org/stable/modules/computing.html#strategies-to-scale-computationally-bigger-data).\n\nearly stopping algorithms that can be enabled include hyperband and median stopping (see below for examples).\n\nif the estimator does not support `partial_fit`, a warning will be shown saying early stopping cannot be done and it will simply run the cross-validation on ray's parallel back-end.\n\napart from early stopping scheduling algorithms, tune-sklearn also supports passing custom stoppers to ray tune. these\ncan be passed via the `stopper` argument when instantiating `tunesearchcv` or `tunegridsearchcv`.\nsee [the ray documentation for an overview of available stoppers](https://docs.ray.io/en/master/tune/api_docs/stoppers.html).\n\n## examples\n\n#### [tunegridsearchcv](docs/tune_gridsearch.md)\nto start out, it\u2019s as easy as changing our import statement to get tune\u2019s grid search cross validation interface, and the rest is almost identical!\n\n`tunegridsearchcv` accepts dictionaries in the format `{ param_name: str : distribution: list }` or a list of such dictionaries, just like scikit-learn's `gridsearchcv`. the distribution can also be the output of ray tune's [`tune.grid_search`](https://docs.ray.io/en/master/tune/api/search_space.html).\n\n```python\n# from sklearn.model_selection import gridsearchcv\nfrom tune_sklearn import tunegridsearchcv\n\n# other imports\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import sgdclassifier\n\n# set training and validation sets\nx, y = make_classification(n_samples=11000, n_features=1000, n_informative=50, n_redundant=0, n_classes=10, class_sep=2.5)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1000)\n\n# example parameters to tune from sgdclassifier\nparameters = {\n    'alpha': [1e-4, 1e-1, 1],\n    'epsilon':[0.01, 0.1]\n}\n\ntune_search = tunegridsearchcv(\n    sgdclassifier(),\n    parameters,\n    early_stopping=\"medianstoppingrule\",\n    max_iters=10\n)\n\nimport time # just to compare fit times\nstart = time.time()\ntune_search.fit(x_train, y_train)\nend = time.time()\nprint(\"tune fit time:\", end - start)\npred = tune_search.predict(x_test)\naccuracy = np.count_nonzero(np.array(pred) == np.array(y_test)) / len(pred)\nprint(\"tune accuracy:\", accuracy)\n```\n\nif you'd like to compare fit times with sklearn's `gridsearchcv`, run the following block of code:\n\n```python\nfrom sklearn.model_selection import gridsearchcv\n# n_jobs=-1 enables use of all cores like tune does\nsklearn_search = gridsearchcv(\n    sgdclassifier(),\n    parameters,\n    n_jobs=-1\n)\n\nstart = time.time()\nsklearn_search.fit(x_train, y_train)\nend = time.time()\nprint(\"sklearn fit time:\", end - start)\npred = sklearn_search.predict(x_test)\naccuracy = np.count_nonzero(np.array(pred) == np.array(y_test)) / len(pred)\nprint(\"sklearn accuracy:\", accuracy)\n```\n\n#### [tunesearchcv](docs/tune_search.md)\n\n`tunesearchcv` is an upgraded version of scikit-learn's `randomizedsearchcv`.\n\nit also provides a wrapper for several search optimization algorithms from ray tune's [searchers](https://docs.ray.io/en/master/tune/api/suggestion.html), which in turn are wrappers for other libraries. the selection of the search algorithm is controlled by the `search_optimization` parameter. in order to use other algorithms, you need to install the libraries they depend on (`pip install` column). the search algorithms are as follows:\n\n| algorithm          | `search_optimization` value | summary                | website                                                 | `pip install`              |\n|--------------------|-----------------------------|------------------------|---------------------------------------------------------|--------------------------|\n| (random search)    | `\"random\"`                  | randomized search      |                                                         | built-in                 |\n| skoptsearch        | `\"bayesian\"`                | bayesian optimization  | [[scikit-optimize](https://scikit-optimize.github.io/)] | `scikit-optimize`        |\n| hyperoptsearch     | `\"hyperopt\"`                | tree-parzen estimators | [[hyperopt](http://hyperopt.github.io/hyperopt)]        | `hyperopt`               |\n| tunebohb           | `\"bohb\"`                    | bayesian opt/hyperband | [[bohb](https://github.com/automl/hpbandster)]          | `hpbandster configspace` |\n| optuna             | `\"optuna\"`                  | tree-parzen estimators | [[optuna](https://optuna.readthedocs.io/en/stable/)]    | `optuna`                 |\n\nall algorithms other than randomlistsearcher accept parameter distributions in the form of dictionaries in the format `{ param_name: str : distribution: tuple or list }`.\n\ntuples represent real distributions and should be two-element or three-element, in the format `(lower_bound: float, upper_bound: float, optional: \"uniform\" (default) or \"log-uniform\")`. lists represent categorical distributions. [ray tune search spaces](https://docs.ray.io/en/master/tune/api/search_space.html) are also supported and provide a rich set of potential distributions. search spaces allow for users to specify complex, potentially nested search spaces and parameter distributions. furthermore, each algorithm also accepts parameters in their own specific format. more information in [tune documentation](https://docs.ray.io/en/master/tune/api/suggestion.html).\n\nrandom search (default) accepts dictionaries in the format `{ param_name: str : distribution: list }` or a list of such dictionaries, just like scikit-learn's `randomizedsearchcv`.\n\n```python\nfrom tune_sklearn import tunesearchcv\n\n# other imports\nimport scipy\nfrom ray import tune\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import sgdclassifier\n\n# set training and validation sets\nx, y = make_classification(n_samples=11000, n_features=1000, n_informative=50, n_redundant=0, n_classes=10, class_sep=2.5)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1000)\n\n# example parameter distributions to tune from sgdclassifier\n# note the use of tuples instead if non-random optimization is desired\nparam_dists = {\n    'loss': ['squared_hinge', 'hinge'], \n    'alpha': (1e-4, 1e-1, 'log-uniform'),\n    'epsilon': (1e-2, 1e-1)\n}\n\nbohb_tune_search = tunesearchcv(sgdclassifier(),\n    param_distributions=param_dists,\n    n_trials=2,\n    max_iters=10,\n    search_optimization=\"bohb\"\n)\n\nbohb_tune_search.fit(x_train, y_train)\n\n# define the `param_dists using the searchspace api\n# this allows the specification of sampling from discrete and \n# categorical distributions (below for the `learning_rate` scheduler parameter)\nparam_dists = {\n    'loss': tune.choice(['squared_hinge', 'hinge']),\n    'alpha': tune.loguniform(1e-4, 1e-1),\n    'epsilon': tune.uniform(1e-2, 1e-1),\n}\n\n\nhyperopt_tune_search = tunesearchcv(sgdclassifier(),\n    param_distributions=param_dists,\n    n_trials=2,\n    early_stopping=true, # uses async hyperband if set to true\n    max_iters=10,\n    search_optimization=\"hyperopt\"\n)\n\nhyperopt_tune_search.fit(x_train, y_train)\n```\n\n### other machine learning libraries and examples\ntune-sklearn also supports the use of other machine learning libraries such as pytorch (using skorch) and keras. you can find these examples here:\n* [keras](https://github.com/ray-project/tune-sklearn/blob/master/examples/keras_example.py)\n* [lightgbm](https://github.com/ray-project/tune-sklearn/blob/master/examples/lgbm.py)\n* [sklearn random forest](https://github.com/ray-project/tune-sklearn/blob/master/examples/random_forest.py)\n* [sklearn pipeline](https://github.com/ray-project/tune-sklearn/blob/master/examples/sklearn_pipeline.py)\n* [pytorch (skorch)](https://github.com/ray-project/tune-sklearn/blob/master/examples/torch_nn.py)\n* [xgboost](https://github.com/ray-project/tune-sklearn/blob/master/examples/xgbclassifier.py)\n\n## [documentation](docs)\n\nsee the auto-generated docs [here](docs).\n\nthese are generated by `lazydocs` and should be updated on every release:\n\n```bash\npip install lazydocs\nlazydocs /path/to/tune-sklearn/tune-sklearn --src-base-url=\"https://github.com/ray-project/tune-sklearn/blob/master\" --overview-file=\"readme.md\"\n```\n\n## more information\n[ray tune](https://docs.ray.io/en/latest/tune/index.html)\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache 2.0",
  "name": "tune-sklearn",
  "package_url": "https://pypi.org/project/tune-sklearn/",
  "project_url": "https://pypi.org/project/tune-sklearn/",
  "project_urls": {
    "Homepage": "https://github.com/ray-project/tune-sklearn"
  },
  "release_url": "https://pypi.org/project/tune-sklearn/0.5.0/",
  "requires_dist": [
    "scikit-learn",
    "scipy",
    "ray[tune] (>=2.7.1)",
    "numpy (>=1.16)"
  ],
  "requires_python": "",
  "summary": "a drop-in replacement for scikit-learn's gridsearchcv / randomizedsearchcv with cutting edge hyperparameter tuning techniques.",
  "version": "0.5.0",
  "releases": [],
  "developers": [
    "michael_chau",
    "ray-dev@googlegroups.com"
  ],
  "kwds": "tune_sklearn tunegridsearchcv tune_gridsearch ray sklearn_search",
  "license_kwds": "apache 2.0",
  "libtype": "pypi",
  "id": "pypi_tune_sklearn",
  "homepage": "https://github.com/ray-project/tune-sklearn",
  "release_count": 23,
  "dependency_ids": [
    "pypi_numpy",
    "pypi_ray",
    "pypi_scikit_learn",
    "pypi_scipy"
  ]
}