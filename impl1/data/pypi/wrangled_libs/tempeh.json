{
  "classifiers": [
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3"
  ],
  "description": "[![build status](https://img.shields.io/azure-devops/build/responsibleai/tempeh/19/master?failed_label=bad&passed_label=good&label=gatedcheckin%3adev)](https://dev.azure.com/responsibleai/tempeh/_build/latest?definitionid=19&branchname=master) ![mit license](https://img.shields.io/badge/license-mit-blue.svg) ![pypi badge](https://img.shields.io/pypi/v/tempeh?color=blue)\n\n\n# tempeh\n\ntempeh is a framework to\n\n**te**st\n\n**m**achine learning\n\n**pe**rformance\n\nex**h**austively\n\nwhich includes tracking memory usage and run time. this is particularly useful as a pluggable tool for your repository's performance tests. typically, people want to run them periodically over various datasets and/or with a number of models to catch regressions with respect to run time or memory consumption. this should be as easy as\n\n```python\nimport pytest\nfrom time import time\nfrom tempeh.configurations import datasets, models\n\n@pytest.mark.parametrize('dataset', datasets.values())\n@pytest.mark.parametrize('model', models.values())\ndef test_fit_predict_regression(dataset, model):\n    dataset = dataset()\n    x_train, x_test = dataset.get_x()\n    y_train, y_test = dataset.get_y()\n    model = model()\n    max_execution_time = get_max_execution_time(dataset, model)\n    if model.compatible_with_dataset(dataset):\n        start_time = time()\n        model.fit(x_train, y_train)\n        model.predict(x_test)\n        duration = time() - start_time\n\n        assert duration < max_execution_time\n```\n\n## installation\n\ntempeh depends on various packages to provide models, including `tensorflow`, `torch`, `xgboost`, `lightgbm`. to install a release version of `tempeh` just run\n\n```python\npip install tempeh\n```\n\n<details>\n<summary>\n<strong>\n<em>\ncommon issues\n</em>\n</strong>\n</summary>\n\n- if you're using a 32-bit python version you might need to switch to a 64-bit python version first to successfully install tensorflow.\n- if the installation of `torch` fails try using the recommendation from the [pytorch website](https://pytorch.org/get-started/locally/) for stable versions without cuda for your python version on your operating system.\n- if the installation of `lightgbm` or `xgboost` fails try to use a pip version less than 20.0 until their bug is resolved.\n</details>\n\n## structure\n\n### datasets\n\ndatasets (located in the `datasets/` directory) encapsulate different datasets used for testing.\n\n#### to add a new one\n\n+ create a python file in the `datasets/` directory with naming convention `[name]_datasets.py`\n+ subclass `baseperformancedatasetwrapper`. the naming convention is `[dataset_name]performancedatasetwrapper`\n+ in `__init__` load the dataset and call `super().__init__(data, targets, size)`\n+ add the class to `__init__.py`\n+ make sure the class contains class variables `task`, `data_type`, `size`\n+ add an entry to the `datasets` dictionary in `configurations.py`.\n\n### models\n\nmodels (`models/` directory) wrap different machine learning models.\n\n#### to add a new one\n\n+ create a python file in the `models/` directory with naming convention `[name]_model.py`\n+ subclass `basemodelwrapper` and name the class `[name]modelwrapper`\n+ in `__init__` train the model; we expect format `__init__(self, ...)`\n+ models must contain `tasks` and `algorithm`\n+ add an entry to the `models` dictionary in `configurations.py`.\n\n\n## maintainers\n\nin alphabetical order:\n\n- [eduardo de leon](https://github.com/eedeleon)\n- [ilya matiach](https://github.com/imatiach-msft)\n- [roman lutz](https://github.com/romanlutz)\n\n\n# contributing\n\nto contribute please check our [contributing guide](contributing.md).\n\n# issues\n\n## regular (non-security) issues\nplease submit a report through [github issues](https://github.com/microsoft/tempeh/issues). a maintainer will respond within a reasonable period of time to handle the issue as follows:\n- bug: triage as `bug` and provide estimated timeline based on severity\n- feature request: triage as `feature request` and provide estimated timeline\n- question or discussion: triage as `question` and respond or notify/identify a suitable expert to respond\n\nmaintainers are supposed to link duplicate issues when possible.\n\n\n## reporting security issues\n\nplease take a look at our guidelines for reporting [security issues](security.md).\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "tempeh",
  "package_url": "https://pypi.org/project/tempeh/",
  "project_url": "https://pypi.org/project/tempeh/",
  "project_urls": {
    "Homepage": "https://github.com/microsoft/tempeh"
  },
  "release_url": "https://pypi.org/project/tempeh/0.1.12/",
  "requires_dist": [
    "memory-profiler",
    "numpy",
    "pandas",
    "pytest",
    "requests",
    "scipy",
    "shap",
    "scikit-learn"
  ],
  "requires_python": "",
  "summary": "machine learning performance testing framework",
  "version": "0.1.12",
  "releases": [],
  "developers": [
    "rolutz@microsoft.com",
    "roman_lutz"
  ],
  "kwds": "azure tempeh performancedatasetwrapper pypi io",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_tempeh",
  "homepage": "https://github.com/microsoft/tempeh",
  "release_count": 16,
  "dependency_ids": [
    "pypi_memory_profiler",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_pytest",
    "pypi_requests",
    "pypi_scikit_learn",
    "pypi_scipy",
    "pypi_shap"
  ]
}