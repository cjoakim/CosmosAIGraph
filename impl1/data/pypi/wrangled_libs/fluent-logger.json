{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "programming language :: python :: 3",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "programming language :: python :: implementation :: cpython",
    "programming language :: python :: implementation :: pypy",
    "topic :: system :: logging"
  ],
  "description": "a python structured logger for fluentd\n======================================\n\n.. image:: https://travis-ci.org/fluent/fluent-logger-python.svg?branch=master\n   :target: https://travis-ci.org/fluent/fluent-logger-python\n   :alt: build status\n\n.. image:: https://coveralls.io/repos/fluent/fluent-logger-python/badge.svg\n   :target: https://coveralls.io/r/fluent/fluent-logger-python\n   :alt: coverage status\n\nmany web/mobile applications generate huge amount of event logs (c,f.\nlogin, logout, purchase, follow, etc). to analyze these event logs could\nbe really valuable for improving the service. however, the challenge is\ncollecting these logs easily and reliably.\n\n`fluentd <https://github.com/fluent/fluentd>`__ solves that problem by\nhaving: easy installation, small footprint, plugins, reliable buffering,\nlog forwarding, etc.\n\n**fluent-logger-python** is a python library, to record the events from\npython application.\n\nrequirements\n------------\n\n-  python 3.5+\n- ``msgpack``\n- **important**: version 0.8.0 is the last version supporting python 2.6, 3.2 and 3.3\n- **important**: version 0.9.6 is the last version supporting python 2.7 and 3.4\n\ninstallation\n------------\n\nthis library is distributed as 'fluent-logger' python package. please\nexecute the following command to install it.\n\n.. code:: sh\n\n    $ pip install fluent-logger\n\nconfiguration\n-------------\n\nfluentd daemon must be launched with a tcp source configuration:\n\n::\n\n    <source>\n      type forward\n      port 24224\n    </source>\n\nto quickly test your setup, add a matcher that logs to the stdout:\n\n::\n\n    <match app.**>\n      type stdout\n    </match>\n\nusage\n-----\n\nfluentsender interface\n~~~~~~~~~~~~~~~~~~~~~~\n\n`sender.fluentsender` is a structured event logger for fluentd.\n\nby default, the logger assumes fluentd daemon is launched locally. you\ncan also specify remote logger by passing the options.\n\n.. code:: python\n\n    from fluent import sender\n\n    # for local fluent\n    logger = sender.fluentsender('app')\n\n    # for remote fluent\n    logger = sender.fluentsender('app', host='host', port=24224)\n\nfor sending event, call `emit` method with your event. following example will send the event to\nfluentd, with tag 'app.follow' and the attributes 'from' and 'to'.\n\n.. code:: python\n\n    # use current time\n    logger.emit('follow', {'from': 'usera', 'to': 'userb'})\n\n    # specify optional time\n    cur_time = int(time.time())\n    logger.emit_with_time('follow', cur_time, {'from': 'usera', 'to':'userb'})\n\nto send events with nanosecond-precision timestamps (fluent 0.14 and up),\nspecify `nanosecond_precision` on `fluentsender`.\n\n.. code:: python\n\n    # use nanosecond\n    logger = sender.fluentsender('app', nanosecond_precision=true)\n    logger.emit('follow', {'from': 'usera', 'to': 'userb'})\n    logger.emit_with_time('follow', time.time(), {'from': 'usera', 'to': 'userb'})\n\nyou can detect an error via return value of `emit`. if an error happens in `emit`, `emit` returns `false` and get an error object using `last_error` method.\n\n.. code:: python\n\n    if not logger.emit('follow', {'from': 'usera', 'to': 'userb'}):\n        print(logger.last_error)\n        logger.clear_last_error() # clear stored error after handled errors\n\nif you want to shutdown the client, call `close()` method.\n\n.. code:: python\n\n    logger.close()\n\nevent-based interface\n~~~~~~~~~~~~~~~~~~~~~\n\nthis api is a wrapper for `sender.fluentsender`.\n\nfirst, you need to call ``sender.setup()`` to create global `sender.fluentsender` logger\ninstance. this call needs to be called only once, at the beginning of\nthe application for example.\n\ninitialization code of event-based api is below:\n\n.. code:: python\n\n    from fluent import sender\n\n    # for local fluent\n    sender.setup('app')\n\n    # for remote fluent\n    sender.setup('app', host='host', port=24224)\n\nthen, please create the events like this. this will send the event to\nfluentd, with tag 'app.follow' and the attributes 'from' and 'to'.\n\n.. code:: python\n\n    from fluent import event\n\n    # send event to fluentd, with 'app.follow' tag\n    event.event('follow', {\n      'from': 'usera',\n      'to':   'userb'\n    })\n\n`event.event` has one limitation which can't return success/failure result.\n\nother methods for event-based interface.\n\n.. code:: python\n\n    sender.get_global_sender # get instance of global sender\n    sender.close # call fluentsender#close\n\nhandler for buffer overflow\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nyou can inject your own custom proc to handle buffer overflow in the event of connection failure. this will mitigate the loss of data instead of simply throwing data away.\n\n.. code:: python\n\n    import msgpack\n    from io import bytesio\n\n    def overflow_handler(pendings):\n        unpacker = msgpack.unpacker(bytesio(pendings))\n        for unpacked in unpacker:\n            print(unpacked)\n\n    logger = sender.fluentsender('app', host='host', port=24224, buffer_overflow_handler=overflow_handler)\n\nyou should handle any exception in handler. fluent-logger ignores exceptions from ``buffer_overflow_handler``.\n\nthis handler is also called when pending events exist during `close()`.\n\npython logging.handler interface\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nthis client-library also has ``fluenthandler`` class for python logging\nmodule.\n\n.. code:: python\n\n    import logging\n    from fluent import handler\n\n    custom_format = {\n      'host': '%(hostname)s',\n      'where': '%(module)s.%(funcname)s',\n      'type': '%(levelname)s',\n      'stack_trace': '%(exc_text)s'\n    }\n\n    logging.basicconfig(level=logging.info)\n    l = logging.getlogger('fluent.test')\n    h = handler.fluenthandler('app.follow', host='host', port=24224, buffer_overflow_handler=overflow_handler)\n    formatter = handler.fluentrecordformatter(custom_format)\n    h.setformatter(formatter)\n    l.addhandler(h)\n    l.info({\n      'from': 'usera',\n      'to': 'userb'\n    })\n    l.info('{\"from\": \"userc\", \"to\": \"userd\"}')\n    l.info(\"this log entry will be logged with the additional key: 'message'.\")\n\nyou can also customize formatter via logging.config.dictconfig\n\n.. code:: python\n\n    import logging.config\n    import yaml\n\n    with open('logging.yaml') as fd:\n        conf = yaml.load(fd)\n\n    logging.config.dictconfig(conf['logging'])\n\nyou can inject your own custom proc to handle buffer overflow in the event of connection failure. this will mitigate the loss of data instead of simply throwing data away.\n\n.. code:: python\n\n    import msgpack\n    from io import bytesio\n\n    def overflow_handler(pendings):\n        unpacker = msgpack.unpacker(bytesio(pendings))\n        for unpacked in unpacker:\n            print(unpacked)\n\na sample configuration ``logging.yaml`` would be:\n\n.. code:: python\n\n    logging:\n        version: 1\n\n        formatters:\n          brief:\n            format: '%(message)s'\n          default:\n            format: '%(asctime)s %(levelname)-8s %(name)-15s %(message)s'\n            datefmt: '%y-%m-%d %h:%m:%s'\n          fluent_fmt:\n            '()': fluent.handler.fluentrecordformatter\n            format:\n              level: '%(levelname)s'\n              hostname: '%(hostname)s'\n              where: '%(module)s.%(funcname)s'\n\n        handlers:\n            console:\n                class : logging.streamhandler\n                level: debug\n                formatter: default\n                stream: ext://sys.stdout\n            fluent:\n                class: fluent.handler.fluenthandler\n                host: localhost\n                port: 24224\n                tag: test.logging\n                buffer_overflow_handler: overflow_handler\n                formatter: fluent_fmt\n                level: debug\n            none:\n                class: logging.nullhandler\n\n        loggers:\n            amqp:\n                handlers: [none]\n                propagate: false\n            conf:\n                handlers: [none]\n                propagate: false\n            '': # root logger\n                handlers: [console, fluent]\n                level: debug\n                propagate: false\n\nasynchronous communication\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nbesides the regular interfaces - the event-based one provided by ``sender.fluentsender`` and the python logging one\nprovided by ``handler.fluenthandler`` - there are also corresponding asynchronous versions in ``asyncsender`` and\n``asynchandler`` respectively. these versions use a separate thread to handle the communication with the remote fluentd\nserver. in this way the client of the library won't be blocked during the logging of the events, and won't risk going\ninto timeout if the fluentd server becomes unreachable. also it won't be slowed down by the network overhead.\n\nthe interfaces in ``asyncsender`` and ``asynchandler`` are exactly the same as those in ``sender`` and ``handler``, so it's\njust a matter of importing from a different module.\n\nfor instance, for the event-based interface:\n\n.. code:: python\n\n    from fluent import asyncsender as sender\n\n    # for local fluent\n    sender.setup('app')\n\n    # for remote fluent\n    sender.setup('app', host='host', port=24224)\n\n    # do your work\n    ...\n\n    # important: before program termination, close the sender\n    sender.close()\n\nor for the python logging interface:\n\n.. code:: python\n\n    import logging\n    from fluent import asynchandler as handler\n\n    custom_format = {\n      'host': '%(hostname)s',\n      'where': '%(module)s.%(funcname)s',\n      'type': '%(levelname)s',\n      'stack_trace': '%(exc_text)s'\n    }\n\n    logging.basicconfig(level=logging.info)\n    l = logging.getlogger('fluent.test')\n    h = handler.fluenthandler('app.follow', host='host', port=24224, buffer_overflow_handler=overflow_handler)\n    formatter = handler.fluentrecordformatter(custom_format)\n    h.setformatter(formatter)\n    l.addhandler(h)\n    l.info({\n      'from': 'usera',\n      'to': 'userb'\n    })\n    l.info('{\"from\": \"userc\", \"to\": \"userd\"}')\n    l.info(\"this log entry will be logged with the additional key: 'message'.\")\n\n    ...\n\n    # important: before program termination, close the handler\n    h.close()\n\n**note**: please note that it's important to close the sender or the handler at program termination. this will make\nsure the communication thread terminates and it's joined correctly. otherwise the program won't exit, waiting for\nthe thread, unless forcibly killed.\n\ncircular queue mode\n+++++++++++++++++++\n\nin some applications it can be especially important to guarantee that the logging process won't block under *any*\ncircumstance, even when it's logging faster than the sending thread could handle (*backpressure*). in this case it's\npossible to enable the `circular queue` mode, by passing `true` in the `queue_circular` parameter of\n``asyncsender.fluentsender`` or ``asynchandler.fluenthandler``. by doing so the thread doing the logging won't block\neven when the queue is full, the new event will be added to the queue by discarding the oldest one.\n\n**warning**: setting `queue_circular` to `true` will cause loss of events if the queue fills up completely! make sure\nthat this doesn't happen, or it's acceptable for your application.\n\n\ntesting\n-------\n\ntesting can be done using\n`nose <https://nose.readthedocs.org/en/latest/>`__.\n\nrelease\n-------\n\nneed wheel package.\n\n.. code:: sh\n\n    $ pip install wheel\n\nafter that, type following command:\n\n.. code:: sh\n\n    $ python setup.py clean sdist bdist_wheel upload\n\ncontributors\n------------\n\npatches contributed by `those\npeople <https://github.com/fluent/fluent-logger-python/contributors>`__.\n\nlicense\n-------\n\napache license, version 2.0\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache license, version 2.0",
  "name": "fluent-logger",
  "package_url": "https://pypi.org/project/fluent-logger/",
  "project_url": "https://pypi.org/project/fluent-logger/",
  "project_urls": {
    "Download": "https://pypi.org/project/fluent-logger/",
    "Homepage": "https://github.com/fluent/fluent-logger-python"
  },
  "release_url": "https://pypi.org/project/fluent-logger/0.10.0/",
  "requires_dist": [
    "msgpack (>1.0)"
  ],
  "requires_python": ">=3.5",
  "summary": "a python logging handler for fluentd event collector",
  "version": "0.10.0",
  "releases": [],
  "developers": [
    "arcadiy@ivanov.biz",
    "arcadiy_ivanov",
    "kazuki.ohta@gmail.com",
    "kazuki_ohta"
  ],
  "kwds": "logging logs logger loggers log",
  "license_kwds": "apache license, version 2.0",
  "libtype": "pypi",
  "id": "pypi_fluent_logger",
  "homepage": "https://github.com/fluent/fluent-logger-python",
  "release_count": 33,
  "dependency_ids": [
    "pypi_msgpack"
  ]
}