{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "intended audience :: science/research",
    "license :: osi approved :: bsd license",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering",
    "topic :: software development :: libraries"
  ],
  "description": "[![github workflow ci status](https://img.shields.io/github/actions/workflow/status/ml31415/numpy-groupies/ci.yaml?branch=master&logo=github&style=flat)](https://github.com/ml31415/numpy-groupies/actions)\n[![pypi](https://img.shields.io/pypi/v/numpy-groupies.svg?style=flat)](https://pypi.org/project/numpy-groupies/)\n[![conda-forge](https://img.shields.io/conda/vn/conda-forge/numpy_groupies.svg?style=flat)](https://anaconda.org/conda-forge/numpy_groupies)\n[![code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n# numpy-groupies\n\nthis package consists of a small library of optimised tools for doing things that can roughly \nbe considered \"group-indexing operations\". the most prominent tool is `aggregate`, which is \ndescribed in detail further down the page.\n\n\n## installation\nif you have `pip`, then simply:\n```\npip install numpy_groupies\n```\nnote that `numpy_groupies` doesn't have any compulsory dependencies (even `numpy` is optional) \nso you should be able to install it fairly easily even without a package manager.  if you just \nwant one particular implementation of `aggregate` (e.g. `aggregate_numpy.py`), you can download \nthat one file, and copy-paste the contents of `utils.py` into the top of that file (replacing \nthe `from .utils import (...)` line).\n\n\n## aggregate\n\n![aggregate_diagram](/diagrams/aggregate.png)\n```python\nimport numpy as np\nimport numpy_groupies as npg\ngroup_idx = np.array([   3,   0,   0,   1,   0,   3,   5,   5,   0,   4])\na =         np.array([13.2, 3.5, 3.5,-8.2, 3.0,13.4,99.2,-7.1, 0.0,53.7])\nnpg.aggregate(group_idx, a, func='sum', fill_value=0)\n# >>>          array([10.0, -8.2, 0.0, 26.6, 53.7, 92.1])\n```\n`aggregate` takes an array of values, and an array giving the group number for each of those values. \nit then returns the sum (or mean, or std, or any, ...etc.) of the values in each group. you have \nprobably come across this idea before - see [matlab's `accumarray` function](http://uk.mathworks.com/help/matlab/ref/accumarray.html?refresh=true), or\n [`pandas` groupby concept](http://pandas.pydata.org/pandas-docs/dev/groupby.html), or\n [mapreduce paradigm](http://en.wikipedia.org/wiki/mapreduce), or simply the [basic histogram](https://en.wikipedia.org/wiki/histogram).\n\na couple of implemented functions do not reduce the data, instead it calculates values cumulatively\nwhile iterating over the data or permutates them. the output size matches the input size.\n\n```python\ngroup_idx = np.array([4, 3, 3, 4, 4, 1, 1, 1, 7, 8, 7, 4, 3, 3, 1, 1])\na =         np.array([3, 4, 1, 3, 9, 9, 6, 7, 7, 0, 8, 2, 1, 8, 9, 8])\nnpg.aggregate(group_idx, a, func='cumsum')\n# >>>          array([3, 4, 5, 6,15, 9,15,22, 7, 0,15,17, 6,14,31,39])\n```\n\n\n### inputs\nthe function accepts various different combinations of inputs, producing various different shapes of output. \nwe give a brief description of the general meaning of the inputs and then go over the different combinations \nin more detail:\n\n* `group_idx` - array of non-negative integers to be used as the \"labels\" with which to group the values in `a`.\n* `a` - array of values to be aggregated.\n* `func='sum'` - the function to use for aggregation. see the section below for more details.\n* `size=none` - the shape of the output array. if `none`, the maximum value in `group_idx` will set the size of the output.\n* `fill_value=0` - value to use for output groups that do not appear anywhere in the `group_idx` input array.\n* `order='c'` - for multidimensional output, this controls the layout in memory, can be `'f'` for fortran-style.\n* `dtype=none` - the`dtype` of the output. `none` means choose a sensible type for the given `a`, `func`, and `fill_value`.\n* `axis=none` - explained below.\n* `ddof=0` - passed through into calculations of variance and standard deviation (see section on functions).\n\n![aggregate_dims_diagram](/diagrams/aggregate_dims.png)\n\n* form 1 is the simplest, taking `group_idx` and `a` of matching 1d lengths, and producing a 1d output.\n* form 2 is similar to form 1, but takes a scalar `a`, which is broadcast out to the length of `group_idx`. note that this is generally not that useful.\n* form 3 is more complicated. `group_idx` is the same length as the `a.shape[axis]`. the groups are broadcast out along the other axis/axes of `a`, thus the output is of shape `n_groups x a.shape[0] x ... x a.shape[axis-1] x a.shape[axis+1] x ... a.shape[-1]`, i.e. the output has two or more dimensions.\n* form 4 also produces output with two or more dimensions, but for very different reasons to form 3.  here `a` is 1d and `group_idx` is exactly `2d`, whereas in form 3 `a` is `nd`, `group_idx` is `1d`, and we provide a value for `axis`.  the length of `a` must match `group_idx.shape[1]`, the value of `group_idx.shape[0]` determines the number of dimensions in the output, i.e. `group_idx[:,99]` gives the `(x,y,z)` group indices for the `a[99]`.\n* form 5 is the same as form 4 but with scalar `a`. as with form 2, this is rarely that helpful.\n\n**note on performance.** the `order` of the output is unlikely to affect performance of `aggregate` (although it may affect your downstream usage of that output), however the order of multidimensional `a` or `group_idx` can affect performance:  in form 4 it is best if columns are contiguous in memory within `group_idx`, i.e. `group_idx[:, 99]` corresponds to a contiguous chunk of memory; in form 3 it's best if all the data in `a` for `group_idx[i]` is contiguous, e.g. if `axis=1` then we want `a[:, 55]` to be contiguous.\n\n\n### available functions\nby default, `aggregate` assumes you want to sum the values within each group, however you can specify another \nfunction using the `func` kwarg.  this `func` can be any custom callable, however you will likely want one of\nthe following optimized functions. note that not all functions might be provided by all implementations.\n\n* `'sum'` - sum of items within each group (see example above).\n* `'prod'` - product of items within each group\n* `'mean'` - mean of items within each group\n* `'var'`- variance of items within each group. use `ddof` kwarg for degrees of freedom. the divisor used in calculations is `n - ddof`, where `n` represents the number of elements. by default `ddof` is zero.\n* `'std'` - standard deviation of items within each group. use `ddof` kwarg for degrees of freedom (see `var` above).\n* `'min'` - minimum value of items within each group.\n* `'max'` - maximum value of items within each group.\n* `'first'` - first item in `a` from each group.\n* `'last'` - last item in `a` from each group.\n* `'argmax'` - the index in `a` of the maximum value in each group.\n* `'argmin'` - the index in `a` of the minimum value in each group.\n\nthe above functions also have a `nan`-form, which skip the `nan` values instead of propagating them to the result of the calculation:\n* `'nansum'`, `'nanprod'`, `'nanmean'`, `'nanvar'`, `'nanstd'`, `'nanmin'`, `'nanmax'`, `'nanfirst'`, `'nanlast'`, `'nanargmax'`, `'nanargmin'`\n\nthe following functions are slightly different in that they always return boolean values. their treatment of nans is also different from above:\n* `'all'` - `true` if all items within a group are truethy. note that `np.all(nan)` is `true`, i.e. `nan` is actually truethy.\n* `'any'` - `true` if any items within a group are truethy.\n* `'allnan'` - `true` if all items within a group are `nan`.\n* `'anynan'` - `true` if any items within a group are `nan`.\n\nthe following functions don't reduce the data, but instead produce an output matching the size of the input:\n* `'cumsum'` - cumulative sum of items within each group.\n* `'cumprod'` - cumulative product of items within each group. (numba only)\n* `'cummin'` - cumulative minimum of items within each group. (numba only)\n* `'cummax'` - cumulative maximum of items within each group. (numba only)\n* `'sort'` - sort the items within each group in ascending order, use reverse=true to invert the order.\n\nfinally, there are three functions which don't reduce each group to a single value, instead they return the full \nset of items within the group:\n* `'array'` - simply returns the grouped items, using the same order as appeared in `a`. (numpy only)\n\n\n### examples\ncompute sums of consecutive integers, and then compute products of those consecutive integers.\n```python\ngroup_idx = np.arange(5).repeat(3)\n# group_idx: array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4])\na = np.arange(group_idx.size)\n# a: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\nx = npg.aggregate(group_idx, a) # sum is default\n# x: array([ 3, 12, 21, 30, 39])\nx = npg.aggregate(group_idx, a, 'prod')\n# x: array([ 0, 60, 336, 990, 2184])\n```\n\nget variance ignoring nans, setting all-nan groups to `nan`.\n```python\nx = npg.aggregate(group_idx, a, func='nanvar', fill_value=nan)\n```\n\ncount the number of elements in each group. note that this is equivalent to doing `np.bincount(group_idx)`, \nindeed that is how the numpy implementation does it.\n```python\nx = npg.aggregate(group_idx, 1)\n```\n\nsum 1000 values into a three-dimensional cube of size 15x15x15. note that in this example all three dimensions \nhave the same size, but that doesn't have to be the case.\n```python\ngroup_idx = np.random.randint(0, 15, size=(3, 1000))\na = np.random.random(group_idx.shape[1])\nx = npg.aggregate(group_idx, a, func=\"sum\", size=(15,15,15), order=\"f\")\n# x.shape: (15, 15, 15)\n# np.isfortran(x): true\n```\n\nuse a custom function to generate some strings.\n```python\ngroup_idx = np.array([1, 0,  1,  4,  1])\na = np.array([12.0, 3.2, -15, 88, 12.9])\nx = npg.aggregate(group_idx, a,\n              func=lambda g: ' or maybe '.join(str(gg) for gg in g), fill_value='')\n# x: ['3.2', '12.0 or maybe -15.0 or maybe 12.9', '', '', '88.0']\n```\n\nuse the `axis` arg in order to do a sum-aggregation on three rows simultaneously.\n```python\na = np.array([[99, 2,  11, 14,  20],\n\t   \t   [33, 76, 12, 100, 71],\n\t\t   [67, 10, -8, 1,   9]])\ngroup_idx = np.array([[3, 3, 7, 0, 0]])\nx = npg.aggregate(group_idx, a, axis=1)\n# x : [[ 34, 0, 0, 101, 0, 0, 0, 11],\n#      [171, 0, 0, 109, 0, 0, 0, 12],\n#      [ 10, 0, 0,  77, 0, 0, 0, -8]]\n```\n\n\n### multiple implementations\nthere are multiple implementations of `aggregate` provided. if you use `from numpy_groupies import aggregate`, \nthe best available implementation will automatically be selected. otherwise you can pick a specific version directly \nlike `from numpy_groupies import aggregate_nb as aggregate` or by importing aggregate from the implementing module \n`from numpy_groupies.aggregate_weave import aggregate`.\n\ncurrently the following implementations exist:\n* **numpy** - this is the default implementation. it uses plain `numpy`, mainly relying on `np.bincount` and basic indexing magic. it comes without other dependencies except `numpy` and shows reasonable performance for the occasional usage.\n* **numba** - this is the most performant implementation, based on jit compilation provided by numba and llvm.\n* **pure python** - this implementation has no dependencies and uses only the standard library. it's horribly slow and should only be used, if there is no numpy available.\n* **numpy ufunc** - *only for benchmarking.*  this implementation uses the `.at` method of numpy's `ufunc`s (e.g. `add.at`), which would appear to be designed for performing exactly the same calculation that `aggregate` executes, however the numpy implementation is rather incomplete.\n* **pandas** - *only for reference.*  the pandas' `groupby` concept is the same as the task performed by `aggregate`. however, `pandas` is not actually faster than the default `numpy` implementation. also, note that there may be room for improvement in the way that `pandas` is utilized here. most notably, when computing multiple aggregations of the same data (e.g. `'min'` and `'max'`) pandas could potentially be used more efficiently.\n\nall implementations have the same calling syntax and produce the same outputs, to within some floating-point error. \nhowever some implementations only support a subset of the valid inputs and will sometimes throw `notimplementederror`.\n\n\n### benchmarks\nscripts for testing and benchmarking are included in this repository. for benchmarking, run \n`python -m numpy_groupies.benchmarks.generic` from the root of this repository.\n\nbelow we are using `500,000` indices uniformly picked from `[0, 1000)`. the values of `a` are uniformly picked from \nthe interval `[0,1)`, with anything less than `0.2` then set to 0 (in order to serve as falsy values in boolean operations). \nfor `nan-` operations another 20% of the values are set to nan, leaving the remainder on the interval `[0.2,0.8)`.\n\nthe benchmarking results are given in ms for an i7-7560u running at 2.40ghz:\n\n| function  | ufunc   | numpy   | numba   | pandas  |\n|-----------|---------|---------|---------|---------|\n| sum       | 1.950   | 1.728   | 0.708   | 11.832  |\n| prod      | 2.279   | 2.349   | 0.709   | 11.649  |\n| min       | 2.472   | 2.489   | 0.716   | 11.686  |\n| max       | 2.457   | 2.480   | 0.745   | 11.598  |\n| len       | 1.481   | 1.270   | 0.635   | 10.932  |\n| all       | 37.186  | 3.054   | 0.892   | 12.587  |\n| any       | 35.278  | 5.157   | 0.890   | 12.845  |\n| anynan    | 5.783   | 2.126   | 0.762   | 144.740 |\n| allnan    | 7.971   | 4.367   | 0.774   | 144.507 |\n| mean      | ----    | 2.500   | 0.825   | 13.284  |\n| std       | ----    | 4.528   | 0.965   | 12.193  |\n| var       | ----    | 4.269   | 0.969   | 12.657  |\n| first     | ----    | 1.847   | 0.811   | 11.584  |\n| last      | ----    | 1.309   | 0.581   | 11.842  |\n| argmax    | ----    | 3.504   | 1.411   | 293.640 |\n| argmin    | ----    | 6.996   | 1.347   | 290.977 |\n| nansum    | ----    | 5.388   | 1.569   | 15.239  |\n| nanprod   | ----    | 5.707   | 1.546   | 15.004  |\n| nanmin    | ----    | 5.831   | 1.700   | 14.292  |\n| nanmax    | ----    | 5.847   | 1.731   | 14.927  |\n| nanlen    | ----    | 3.170   | 1.529   | 14.529  |\n| nanall    | ----    | 6.499   | 1.640   | 15.931  |\n| nanany    | ----    | 8.041   | 1.656   | 15.839  |\n| nanmean   | ----    | 5.636   | 1.583   | 15.185  |\n| nanvar    | ----    | 7.514   | 1.682   | 15.643  |\n| nanstd    | ----    | 7.292   | 1.666   | 15.104  |\n| nanfirst  | ----    | 5.318   | 2.096   | 14.432  |\n| nanlast   | ----    | 4.943   | 1.473   | 14.637  |\n| nanargmin | ----    | 7.977   | 1.779   | 298.911 |\n| nanargmax | ----    | 5.869   | 1.802   | 301.022 |\n| cumsum    | ----    | 71.713  | 1.119   | 8.864   |\n| cumprod   | ----    | ----    | 1.123   | 12.100  |\n| cummax    | ----    | ----    | 1.062   | 12.133  |\n| cummin    | ----    | ----    | 0.973   | 11.908  |\n| arbitrary | ----    | 147.853 | 46.690  | 129.779 |\n| sort      | ----    | 167.699 | ----    | ----    |\n\n_linux(x86_64), python 3.10.12, numpy 1.25.2, numba 0.58.0, pandas 2.0.2_\n\n## development\nthis project was started by @ml31415 and the `numba` and `weave` implementations are by him. the pure \npython and `numpy` implementations were written by @d1manson.\n\nthe authors hope that `numpy`'s `ufunc.at` methods or some other implementation of `aggregate` within\n`numpy` or `scipy` will eventually be fast enough, to make this package redundant. numpy 1.25 actually\ncontained major [improvements on ufunc speed](https://numpy.org/doc/stable/release/1.25.0-notes.html), \nwhich reduced the speed gap between numpy and the numba implementation a lot.\n",
  "docs_url": null,
  "keywords": "accumarray,aggregate,groupby,grouping,indexing",
  "license": "copyright (c) 2016, numpy-groupies developers all rights reserved.  redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:  1. redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.  this software is provided by the copyright holders and contributors \"as is\" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall the copyright owner or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. ",
  "name": "numpy-groupies",
  "package_url": "https://pypi.org/project/numpy-groupies/",
  "project_url": "https://pypi.org/project/numpy-groupies/",
  "project_urls": {
    "source": "https://github.com/ml31415/numpy-groupies",
    "tracker": "https://github.com/ml31415/numpy-groupies/issues"
  },
  "release_url": "https://pypi.org/project/numpy-groupies/0.10.2/",
  "requires_dist": [
    "numpy",
    "pytest ; extra == 'dev'",
    "numba ; extra == 'dev'",
    "pandas ; extra == 'dev'",
    "numba ; extra == 'fast'"
  ],
  "requires_python": ">=3.9",
  "summary": "optimised tools for group-indexing operations: aggregated sum and more.",
  "version": "0.10.2",
  "releases": [],
  "developers": [
    "danielmanson.uk@gmail.com",
    "dcherian@ucar.edu",
    "ml@occam.com.ua"
  ],
  "kwds": "numpy_groupies n_groups aggregate_weave groupby grouped",
  "license_kwds": "liability liable copyright negligence damages",
  "libtype": "pypi",
  "id": "pypi_numpy_groupies",
  "homepage": "",
  "release_count": 19,
  "dependency_ids": [
    "pypi_numba",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_pytest"
  ]
}