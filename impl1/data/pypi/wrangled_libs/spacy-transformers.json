{
  "classifiers": [
    "development status :: 5 - production/stable",
    "environment :: console",
    "intended audience :: developers",
    "intended audience :: science/research",
    "license :: osi approved :: mit license",
    "operating system :: macos :: macos x",
    "operating system :: microsoft :: windows",
    "operating system :: posix :: linux",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering",
    "topic :: scientific/engineering :: artificial intelligence"
  ],
  "description": "<a href=\"https://explosion.ai\"><img src=\"https://explosion.ai/assets/img/logo.svg\" width=\"125\" height=\"125\" align=\"right\" /></a>\n\n# spacy-transformers: use pretrained transformers like bert, xlnet and gpt-2 in spacy\n\nthis package provides [spacy](https://github.com/explosion/spacy) components and\narchitectures to use transformer models via\n[hugging face's `transformers`](https://github.com/huggingface/transformers) in\nspacy. the result is convenient access to state-of-the-art transformer\narchitectures, such as bert, gpt-2, xlnet, etc.\n\n> **this release requires [spacy v3](https://spacy.io/usage/v3).** for the\n> previous version of this library, see the\n> [`v0.6.x` branch](https://github.com/explosion/spacy-transformers/tree/v0.6.x).\n\n[![tests](https://github.com/explosion/spacy-transformers/actions/workflows/tests.yml/badge.svg)](https://github.com/explosion/spacy-transformers/actions/workflows/tests.yml)\n[![pypi](https://img.shields.io/pypi/v/spacy-transformers.svg?style=flat-square&logo=pypi&logocolor=white)](https://pypi.python.org/pypi/spacy-transformers)\n[![github](https://img.shields.io/github/release/explosion/spacy-transformers/all.svg?style=flat-square&logo=github)](https://github.com/explosion/spacy-transformers/releases)\n[![code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/ambv/black)\n\n## features\n\n- use pretrained transformer models like **bert**, **roberta** and **xlnet** to\n  power your spacy pipeline.\n- easy **multi-task learning**: backprop to one transformer model from several\n  pipeline components.\n- train using spacy v3's powerful and extensible config system.\n- automatic alignment of transformer output to spacy's tokenization.\n- easily customize what transformer data is saved in the `doc` object.\n- easily customize how long documents are processed.\n- out-of-the-box serialization and model packaging.\n\n## \ud83d\ude80 installation\n\ninstalling the package from pip will automatically install all dependencies,\nincluding pytorch and spacy. make sure you install this package **before** you\ninstall the models. also note that this package requires **python 3.6+**,\n**pytorch v1.5+** and **spacy v3.0+**.\n\n```bash\npip install 'spacy[transformers]'\n```\n\nfor gpu installation, find your cuda version using `nvcc --version` and add the\n[version in brackets](https://spacy.io/usage/#gpu), e.g.\n`spacy[transformers,cuda92]` for cuda9.2 or `spacy[transformers,cuda100]` for\ncuda10.0.\n\nif you are having trouble installing pytorch, follow the\n[instructions](https://pytorch.org/get-started/locally/) on the official website\nfor your specific operating system and requirements.\n\n## \ud83d\udcd6 documentation\n\n> \u26a0\ufe0f **important note:** this package has been extensively refactored to take\n> advantage of [spacy v3.0](https://spacy.io). previous versions that were built\n> for [spacy v2.x](https://v2.spacy.io) worked considerably differently. please\n> see previous tagged versions of this readme for documentation on prior\n> versions.\n\n- \ud83d\udcd8\n  [embeddings, transformers and transfer learning](https://spacy.io/usage/embeddings-transformers):\n  how to use transformers in spacy\n- \ud83d\udcd8 [training pipelines and models](https://spacy.io/usage/training): train and\n  update components on your own data and integrate custom models\n- \ud83d\udcd8\n  [layers and model architectures](https://spacy.io/usage/layers-architectures):\n  power spacy components with custom neural networks\n- \ud83d\udcd7 [`transformer`](https://spacy.io/api/transformer): pipeline component api\n  reference\n- \ud83d\udcd7\n  [transformer architectures](https://spacy.io/api/architectures#transformers):\n  architectures and registered functions\n\n## applying pretrained text and token classification models\n\nnote that the `transformer` component from `spacy-transformers` does not support\ntask-specific heads like token or text classification. a task-specific\ntransformer model can be used as a source of features to train spacy components\nlike `ner` or `textcat`, but the `transformer` component does not provide access\nto task-specific heads for training or inference.\n\nalternatively, if you only want use to the **predictions** from an existing\nhugging face text or token classification model, you can use the wrappers from\n[`spacy-huggingface-pipelines`](https://github.com/explosion/spacy-huggingface-pipelines)\nto incorporate task-specific transformer models into your spacy pipelines.\n\n## bug reports and other issues\n\nplease use [spacy's issue tracker](https://github.com/explosion/spacy/issues) to\nreport a bug, or open a new thread on the\n[discussion board](https://github.com/explosion/spacy/discussions) for any other\nissue.\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "spacy-transformers",
  "package_url": "https://pypi.org/project/spacy-transformers/",
  "project_url": "https://pypi.org/project/spacy-transformers/",
  "project_urls": {
    "Homepage": "https://spacy.io"
  },
  "release_url": "https://pypi.org/project/spacy-transformers/1.3.4/",
  "requires_dist": [
    "spacy <4.0.0,>=3.5.0",
    "transformers <4.37.0,>=3.4.0",
    "torch >=1.8.0",
    "srsly <3.0.0,>=2.4.0",
    "spacy-alignments <1.0.0,>=0.7.2",
    "dataclasses <1.0,>=0.6 ; python_version < \"3.7\"",
    "numpy >=1.15.0 ; python_version < \"3.9\"",
    "numpy >=1.19.0 ; python_version >= \"3.9\"",
    "cupy >=5.0.0b4 ; extra == 'cuda'",
    "cupy-cuda100 >=5.0.0b4 ; extra == 'cuda100'",
    "cupy-cuda101 >=5.0.0b4 ; extra == 'cuda101'",
    "cupy-cuda102 >=5.0.0b4 ; extra == 'cuda102'",
    "cupy-cuda110 >=5.0.0b4 ; extra == 'cuda110'",
    "cupy-cuda111 >=5.0.0b4 ; extra == 'cuda111'",
    "cupy-cuda112 >=5.0.0b4 ; extra == 'cuda112'",
    "cupy-cuda80 >=5.0.0b4 ; extra == 'cuda80'",
    "cupy-cuda90 >=5.0.0b4 ; extra == 'cuda90'",
    "cupy-cuda91 >=5.0.0b4 ; extra == 'cuda91'",
    "cupy-cuda92 >=5.0.0b4 ; extra == 'cuda92'"
  ],
  "requires_python": ">=3.7",
  "summary": "spacy pipelines for pre-trained bert and other transformers",
  "version": "1.3.4",
  "releases": [],
  "developers": [
    "contact@explosion.ai",
    "explosion"
  ],
  "kwds": "transformers spacy transformer xlnet explosion",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_spacy_transformers",
  "homepage": "https://spacy.io",
  "release_count": 75,
  "dependency_ids": [
    "pypi_cupy",
    "pypi_cupy_cuda100",
    "pypi_cupy_cuda101",
    "pypi_cupy_cuda102",
    "pypi_cupy_cuda110",
    "pypi_cupy_cuda111",
    "pypi_cupy_cuda112",
    "pypi_cupy_cuda80",
    "pypi_cupy_cuda90",
    "pypi_cupy_cuda91",
    "pypi_cupy_cuda92",
    "pypi_dataclasses",
    "pypi_numpy",
    "pypi_spacy",
    "pypi_spacy_alignments",
    "pypi_srsly",
    "pypi_torch",
    "pypi_transformers"
  ]
}