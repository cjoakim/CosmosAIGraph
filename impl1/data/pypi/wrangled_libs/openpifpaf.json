{
  "classifiers": [],
  "description": "# openpifpaf\n\ncontinuously tested on linux, macos and windows:\n[![tests](https://github.com/openpifpaf/openpifpaf/workflows/tests/badge.svg?branch=main)](https://github.com/openpifpaf/openpifpaf/actions?query=workflow%3atests)\n[![deploy-guide](https://github.com/openpifpaf/openpifpaf/workflows/deploy-guide/badge.svg)](https://github.com/openpifpaf/openpifpaf/actions?query=workflow%3adeploy-guide)\n[![downloads](https://pepy.tech/badge/openpifpaf)](https://pepy.tech/project/openpifpaf)\n<br />\n[__new__ 2021 paper](https://arxiv.org/abs/2103.02440):\n\n> __openpifpaf: composite fields for semantic keypoint detection and spatio-temporal association__<br />\n> _[sven kreiss](https://www.svenkreiss.com), [lorenzo bertoni](https://scholar.google.com/citations?user=f-4yhemaaaaj&hl=en), [alexandre alahi](https://scholar.google.com/citations?user=uihxq64aaaaj&hl=en)_, 2021.\n>\n> many image-based perception tasks can be formulated as detecting, associating\n> and tracking semantic keypoints, e.g., human body pose estimation and tracking.\n> in this work, we present a general framework that jointly detects and forms\n> spatio-temporal keypoint associations in a single stage, making this the first\n> real-time pose detection and tracking algorithm. we present a generic neural\n> network architecture that uses composite fields to detect and construct a\n> spatio-temporal pose which is a single, connected graph whose nodes are the\n> semantic keypoints (e.g., a person's body joints) in multiple frames. for the\n> temporal associations, we introduce the temporal composite association field\n> (tcaf) which requires an extended network architecture and training method\n> beyond previous composite fields. our experiments show competitive accuracy\n> while being an order of magnitude faster on multiple publicly available datasets\n> such as coco, crowdpose and the posetrack 2017 and 2018 datasets. we also show\n> that our method generalizes to any class of semantic keypoints such as car and\n> animal parts to provide a holistic perception framework that is well suited for\n> urban mobility such as self-driving cars and delivery robots.\n\nprevious [cvpr 2019 paper](http://openaccess.thecvf.com/content_cvpr_2019/html/kreiss_pifpaf_composite_fields_for_human_pose_estimation_cvpr_2019_paper.html).\n\n\n# [guide](https://openpifpaf.github.io/intro.html)\n\ndetailed documentation is in our __[openpifpaf guide](https://openpifpaf.github.io/intro.html)__.\nfor developers, there is also the\n__[dev guide](https://openpifpaf.github.io/dev/intro.html)__\nwhich is the same guide but based on the latest code in the `main` branch.\n\n\n# examples\n\n![example image with overlaid pose predictions](https://github.com/openpifpaf/openpifpaf/raw/main/docs/coco/000000081988.jpg.predictions.jpeg)\n\nimage credit: \"[learning to surf](https://www.flickr.com/photos/fotologic/6038911779/in/photostream/)\" by fotologic which is licensed under [cc-by-2.0].<br />\ncreated with:\n```sh\npip3 install matplotlib openpifpaf\npython3 -m openpifpaf.predict docs/coco/000000081988.jpg --image-output\n```\n\n---\n\nhere is the [tutorial for body, foot, face and hand keypoints](https://openpifpaf.github.io/plugins_wholebody.html). example:\n![example image with overlaid wholebody pose predictions](https://raw.githubusercontent.com/openpifpaf/openpifpaf/main/docs/soccer.jpeg.predictions.jpeg)\n\nimage credit: [photo](https://de.wikipedia.org/wiki/kamil_vacek#/media/datei:kamil_vacek_20200627.jpg) by [lokomotive74](https://commons.wikimedia.org/wiki/user:lokomotive74) which is licensed under [cc-by-4.0](https://creativecommons.org/licenses/by/4.0/).<br />\ncreated with:\n```sh\npython -m openpifpaf.predict guide/wholebody/soccer.jpeg \\\n  --checkpoint=shufflenetv2k30-wholebody --line-width=2 --image-output\n```\n\n---\n\nhere is the [tutorial for car keypoints](https://openpifpaf.github.io/plugins_apollocar3d.html). example:\n![example image cars](https://raw.githubusercontent.com/openpifpaf/openpifpaf/main/docs/peterbourg.jpg.predictions.jpeg)\n\nimage credit: [photo](https://commons.wikimedia.org/wiki/file:streets_of_saint_petersburg,_russia.jpg) by [ninaras](https://commons.wikimedia.org/wiki/user:ninaras) which is licensed under [cc-by-sa 4.0](https://creativecommons.org/licenses/by-sa/4.0/).\n\ncreated with:\n```sh\npython -m openpifpaf.predict guide/images/peterbourg.jpg \\\n  --checkpoint shufflenetv2k16-apollo-24 -o images \\\n  --instance-threshold 0.05 --seed-threshold 0.05 \\\n  --line-width 4 --font-size 0\n```\n\n---\n\nhere is the [tutorial for animal keypoints (dogs, cats, sheep, horses and cows)](https://openpifpaf.github.io/plugins_animalpose.html). example:\n![example image cars](https://raw.githubusercontent.com/openpifpaf/openpifpaf/main/docs/tappo_loomo.jpg.predictions.jpeg)\n\n\n```sh\npython -m openpifpaf.predict guide/images tappo_loomo.jpg \\\n  --checkpoint=shufflenetv2k30-animalpose \\\n  --line-width=6 --font-size=6 --white-overlay=0.3 \\\n  --long-edge=500\n```\n\n\n# commercial license\n\nthe open source license is in the [license](https://github.com/openpifpaf/openpifpaf/blob/main/license) file.\nthis software is also available for licensing via the epfl technology transfer\noffice (https://tto.epfl.ch/, info.tto@epfl.ch).\n\n\n[cc-by-2.0]: https://creativecommons.org/licenses/by/2.0/",
  "docs_url": null,
  "keywords": "",
  "license": "gnu agplv3",
  "name": "openpifpaf",
  "package_url": "https://pypi.org/project/openpifpaf/",
  "project_url": "https://pypi.org/project/openpifpaf/",
  "project_urls": {
    "Homepage": "https://github.com/openpifpaf/openpifpaf"
  },
  "release_url": "https://pypi.org/project/openpifpaf/0.13.11/",
  "requires_dist": [],
  "requires_python": ">=3.7",
  "summary": "pifpaf: composite fields for human pose estimation",
  "version": "0.13.11",
  "releases": [],
  "developers": [
    "research@svenkreiss.com",
    "sven_kreiss"
  ],
  "kwds": "openpifpaf __openpifpaf kreiss_pifpaf_composite_fields_for_human_pose_estimation_cvpr_2019_paper pifpaf workflows",
  "license_kwds": "gnu agplv3",
  "libtype": "pypi",
  "id": "pypi_openpifpaf",
  "homepage": "https://github.com/openpifpaf/openpifpaf",
  "release_count": 64,
  "dependency_ids": []
}