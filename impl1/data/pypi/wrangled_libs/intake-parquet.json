{
  "classifiers": [],
  "description": "# intake-parquet\n\n[![build status](https://travis-ci.org/continuumio/intake-parquet.svg?branch=master)](https://travis-ci.org/continuumio/intake-parquet)\n[![documentation status](https://readthedocs.org/projects/intake-parquet/badge/?version=latest)](http://intake-parquet.readthedocs.io/en/latest/?badge=latest)\n\n[intake data loader](https://github.com/continuumio/intake/) interface to the parquet binary tabular data format.\n\nparquet is very popular in the big-data ecosystem, because it provides columnar\nand chunk-wise access to the data, with efficient encodings and compression. this makes\nthe format particularly effective for streaming through large subsections of even\nlarger data-sets, hence it's common use with hadoop and spark.\n\nparquet data may be single files, directories of files, or nested directories, where\nthe directory names are meaningful in the partitioning of the data.\n\n### features\n\nthe parquet plugin allows for:\n\n- efficient metadata parsing, so you know the data types and number of records without\n  loading any data\n- random access of partitions\n- column and index selection, load only the data you need\n- passing of value-based filters, that you only load those partitions containing some\n  valid data (nb: does not filter the values within a partition)\n\n### installation\n\nthe conda install instructions are:\n\n```\nconda install -c conda-forge intake-parquet\n```\n\n### examples\n\nsee the notebook in the examples/ directory.\n",
  "docs_url": null,
  "keywords": "",
  "license": "bsd",
  "name": "intake-parquet",
  "package_url": "https://pypi.org/project/intake-parquet/",
  "project_url": "https://pypi.org/project/intake-parquet/",
  "project_urls": {
    "Homepage": "https://github.com/ContinuumIO/intake-parquet"
  },
  "release_url": "https://pypi.org/project/intake-parquet/0.3.0/",
  "requires_dist": [
    "intake",
    "pandas",
    "fastparquet",
    "pyarrow"
  ],
  "requires_python": "",
  "summary": "intake parquet plugin",
  "version": "0.3.0",
  "releases": [],
  "developers": [
    "martin.durant@utoronto.ca",
    "martin_durant"
  ],
  "kwds": "parquet intake chunk data streaming",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_intake_parquet",
  "homepage": "https://github.com/continuumio/intake-parquet",
  "release_count": 4,
  "dependency_ids": [
    "pypi_fastparquet",
    "pypi_intake",
    "pypi_pandas",
    "pypi_pyarrow"
  ]
}