{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "programming language :: python",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# hdfscli [![ci](https://github.com/mtth/hdfs/actions/workflows/ci.yml/badge.svg)](https://github.com/mtth/hdfs/actions/workflows/ci.yml) [![pypi badge](https://badge.fury.io/py/hdfs.svg)](https://pypi.python.org/pypi/hdfs/) [![downloads badge](https://img.shields.io/pypi/dm/hdfs.svg)](https://pypistats.org/packages/hdfs)\n\napi and command line interface for hdfs.\n\n```\n$ hdfscli --alias=dev\n\nwelcome to the interactive hdfs python shell.\nthe hdfs client is available as `client`.\n\nin [1]: client.list('models/')\nout[1]: ['1.json', '2.json']\n\nin [2]: client.status('models/2.json')\nout[2]: {\n  'accesstime': 1439743128690,\n  'blocksize': 134217728,\n  'childrennum': 0,\n  'fileid': 16389,\n  'group': 'supergroup',\n  'length': 48,\n  'modificationtime': 1439743129392,\n  'owner': 'drwho',\n  'pathsuffix': '',\n  'permission': '755',\n  'replication': 1,\n  'storagepolicy': 0,\n  'type': 'file'\n}\n\nin [3]: with client.read('models/2.json', encoding='utf-8') as reader:\n  ...:     from json import load\n  ...:     model = load(reader)\n  ...:\n```\n\n## features\n\n* python 3 bindings for the [webhdfs][] (and [httpfs][]) api,\n  supporting both secure and insecure clusters.\n* command line interface to transfer files and start an interactive client\n  shell, with aliases for convenient namenode url caching.\n* additional functionality through optional extensions:\n\n  + `avro`, to [read and write avro files directly from hdfs][].\n  + `dataframe`, to [load and save pandas dataframes][].\n  + `kerberos`, to [support kerberos authenticated clusters][].\n\nsee the [documentation][] to learn more.\n\n## getting started\n\n```sh\n$ pip install hdfs\n```\n\nthen hop on over to the [quickstart][] guide. a [conda\nfeedstock](https://github.com/conda-forge/python-hdfs-feedstock) is also\navailable.\n\n## testing\n\nhdfscli is tested against both [webhdfs][] and [httpfs][]. there are two ways\nof running tests (see `scripts/` for helpers to set up a test hdfs cluster):\n\n```sh\n$ hdfscli_test_url=http://localhost:50070 pytest # using a namenode's url.\n$ hdfscli_test_alias=dev pytest # using an alias.\n```\n\n## contributing\n\nwe'd love to hear what you think on the [issues][] page. pull requests are also\nmost welcome!\n\n[httpfs]: http://hadoop.apache.org/docs/current/hadoop-hdfs-httpfs/\n[webhdfs]: http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/webhdfs.html\n[read and write avro files directly from hdfs]: https://hdfscli.readthedocs.io/en/latest/api.html#module-hdfs.ext.avro\n[load and save pandas dataframes]: https://hdfscli.readthedocs.io/en/latest/api.html#module-hdfs.ext.dataframe\n[support kerberos authenticated clusters]: https://hdfscli.readthedocs.io/en/latest/api.html#module-hdfs.ext.kerberos\n[documentation]: https://hdfscli.readthedocs.io/\n[quickstart]: https://hdfscli.readthedocs.io/en/latest/quickstart.html\n[issues]: https://github.com/mtth/hdfs/issues\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "hdfs",
  "package_url": "https://pypi.org/project/hdfs/",
  "project_url": "https://pypi.org/project/hdfs/",
  "project_urls": {
    "Homepage": "https://hdfscli.readthedocs.io"
  },
  "release_url": "https://pypi.org/project/hdfs/2.7.3/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "hdfscli: api and command line interface for hdfs.",
  "version": "2.7.3",
  "releases": [],
  "developers": [
    "matthieu_monsch",
    "mtth@apache.org"
  ],
  "kwds": "hdfscli hdfscli_test_url hdfscli_test_alias hdfs webhdfs",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_hdfs",
  "homepage": "https://hdfscli.readthedocs.io",
  "release_count": 81,
  "dependency_ids": []
}