{
  "classifiers": [
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3"
  ],
  "description": "![logo](logo/opennsfw2_logo.png)\n\n[![ci](https://github.com/bhky/opennsfw2/actions/workflows/ci.yml/badge.svg)](https://github.com/bhky/opennsfw2/actions)\n[![license mit 1.0](https://img.shields.io/badge/license-mit%201.0-blue.svg)](license)\n\n# introduction\n\ndetecting not-suitable-for-work (nsfw) content is a high demand task in \ncomputer vision. while there are many types of nsfw content, here we focus on\nthe pornographic images and videos.\n\nthe [yahoo open-nsfw model](https://github.com/yahoo/open_nsfw) originally\ndeveloped with the caffe framework has been a favourite choice, but the work \nis now discontinued and caffe is also becoming less popular.\nplease see the description on the yahoo project page for\nthe context, definitions, and model training details.\n\nthis **open-nsfw 2** project provides a keras implementation of the\nyahoo model, with references to its previous third-party \n[tensorflow 1 implementation](https://github.com/mdietrichstein/tensorflow-open_nsfw).\nnote that **keras 3** is compatible with \ntensorflow, jax, and pytorch. however, currently this model is\nonly guaranteed to work with tensorflow and jax.\n\na simple api is provided for making predictions on images and videos.\n\n# installation\n\ntested with tensorflow and jax, for python 3.9, 3.10, and 3.11.\n\na note on pytorch:\n\nthe opennsfw 2 model can in fact be run on pytorch, but the biggest issue is \nthat the inference output on pytorch is quite different from \nthat on tensorflow and jax. the reason is still unknown. in addition, \ninference is much slower on pytorch probably because of the issues \ndiscussed [here](https://keras.io/keras_core/announcement/),\ni.e., pytorch uses `channels_first` for its image data format, but this model\nuses `channels_last` (as in tensorflow and jax), hence keras has to \nconvert the channel order back and forth at each layer.\ntherefore, at the moment it is not recommended to use pytorch for this model.\n\nthe best way to install open-nsfw 2 with its dependencies is from pypi:\n```shell\npython3 -m pip install --upgrade opennsfw2\n```\nalternatively, to obtain the latest version from this repository:\n```shell\ngit clone git@github.com:bhky/opennsfw2.git\ncd opennsfw2\npython3 -m pip install .\n```\n\n# usage\n\nquick examples for getting started are given below.\nfor more details, please refer to the [api](#api) section.\n\n## images\n\n```python\nimport opennsfw2 as n2\n\n# to get the nsfw probability of a single image.\nimage_path = \"path/to/your/image.jpg\"\n\nnsfw_probability = n2.predict_image(image_path)\n\n# to get the nsfw probabilities of a list of images.\n# this is better than looping with `predict_image` as the model will only be instantiated once\n# and batching is used during inference.\nimage_paths = [\n  \"path/to/your/image1.jpg\",\n  \"path/to/your/image2.jpg\",\n  # ...\n]\n\nnsfw_probabilities = n2.predict_images(image_paths)\n```\n\n## video\n\n```python\nimport opennsfw2 as n2\n\n# the video can be in any format supported by opencv.\nvideo_path = \"path/to/your/video.mp4\"\n\n# return two lists giving the elapsed time in seconds and the nsfw probability of each frame.\nelapsed_seconds, nsfw_probabilities = n2.predict_video_frames(video_path)\n```\n\n## lower level with keras\n\n```python\nimport numpy as np\nimport opennsfw2 as n2\nfrom pil import image\n\n# load and preprocess image.\nimage_path = \"path/to/your/image.jpg\"\npil_image = image.open(image_path)\nimage = n2.preprocess_image(pil_image, n2.preprocessing.yahoo)\n# the preprocessed image is a numpy array of shape (224, 224, 3).\n\n# create the model.\n# by default, this call will search for the pre-trained weights file from path:\n# $home/.opennsfw2/weights/open_nsfw_weights.h5\n# if not exists, the file will be downloaded from this repository.\n# the model is a `keras_core.model` object.\nmodel = n2.make_open_nsfw_model()\n\n# make predictions.\ninputs = np.expand_dims(image, axis=0)  # add batch axis (for single image).\npredictions = model.predict(inputs)\n\n# the shape of predictions is (num_images, 2).\n# each row gives [sfw_probability, nsfw_probability] of an input image, e.g.:\nsfw_probability, nsfw_probability = predictions[0]\n```\n\n# api\n\n### `preprocess_image`\napply necessary preprocessing to the input image.\n- parameters:\n  - `pil_image` (`pil.image`): input as a pillow image.\n  - `preprocessing` (`preprocessing` enum, default `preprocessing.yahoo`): \n    see [preprocessing details](#preprocessing-details).\n- return:\n  - numpy array of shape `(224, 224, 3)`.\n\n### `preprocessing`\nenum class for preprocessing options.\n- `preprocessing.yahoo`\n- `preprocessing.simple`\n\n### `make_open_nsfw_model`\ncreate an instance of the nsfw model, optionally with pre-trained weights from yahoo.\n- parameters:\n  - `input_shape` (`tuple[int, int, int]`, default `(224, 224, 3)`):\n    input shape of the model, this should not be changed.\n  - `weights_path` (`optional[str]`, default `$home/.opennsfw/weights/open_nsfw_weights.h5`): \n    path to the weights in hdf5 format to be loaded by the model. \n    the weights file will be downloaded if not exists.\n    if `none`, no weights will be downloaded nor loaded to the model.\n    users can provide path if the default is not preferred. \n    the environment variable `opennsfw2_home` can also be used to indicate\n    where the `.opennsfw2/` directory should be located.\n- return:\n  - `tf.keras.model` object.\n\n### `predict_image`\nend-to-end pipeline function from the input image to the predicted nsfw probability.\n- parameters:\n  - `image_path` (`str`): path to the input image file. \n    the image format must be supported by pillow.\n  - `preprocessing`: same as that in `preprocess_image`.\n  - `weights_path`: same as that in `make_open_nsfw_model`.\n  - `grad_cam_path` (`optional[str]`, default `none`): if not `none`, e.g., `cam.jpg`,\n    a [gradient-weighted class activation mapping (grad-cam)](https://keras.io/examples/vision/grad_cam/) \n    overlay plot will be saved, which highlights the important region(s) of the \n    (preprocessed) input image that lead to the prediction.\n    note that this feature is currently only supported by the tensorflow backend.\n  - `alpha` (`float`, default `0.8`): opacity of the grad-cam layer of the plot,\n    only valid if `grad_cam_path` is not `none`.\n- return:\n  - `nsfw_probability` (`float`): the predicted nsfw probability of the image.\n\n### `predict_images`\nend-to-end pipeline function from the input images to the predicted nsfw probabilities.\n- parameters:\n  - `image_paths` (`sequence[str]`): list of paths to the input image files. \n    the image format must be supported by pillow.\n  - `batch_size` (`int`, default `8`): batch size to be used for model inference. \n    choose a value that works the best with your device resources.\n  - `preprocessing`: same as that in `preprocess_image`.\n  - `weights_path`: same as that in `make_open_nsfw_model`.\n  - `grad_cam_paths` (`optional[sequence[str]]`, default `none`): if not `none`,\n    the corresponding grad-cam plots for the input images will be saved.\n    see the description in `predict_image`.\n    note that this feature is currently only supported by the tensorflow backend.\n  - `alpha`: same as that in `predict_image`.\n- return:\n  - `nsfw_probabilities` (`list[float]`): predicted nsfw probabilities of the images.\n\n### `aggregation`\nenum class for aggregation options in video frames prediction.\n- `aggregation.mean`\n- `aggregation.median`\n- `aggregation.max`\n- `aggregation.min`\n\n### `predict_video_frames`\nend-to-end pipeline function from the input video to predictions.\n- parameters:\n  - `video_path` (`str`): path to the input video source. \n    the video format must be supported by opencv.\n  - `frame_interval` (`int`, default `8`): prediction will be done on every this \n    number of frames, starting from frame 1, i.e., if this is 8, then \n    prediction will only be done on frame 1, 9, 17, etc.\n  - `aggregation_size` (`int`, default `8`):\n    number of frames for which their predicted nsfw probabilities will be aggregated.\n    for instance, if a prediction will be done \"on\" frame 9 (decided by `frame_interval`),\n    then it actually means prediction will be done on `aggregation_size` frames \n    starting from frame 9, e.g., frames 9 to 16 if the size is 8. \n    the predicted probabilities will be aggregated. after aggregation, \n    each of these frames in that interval will be assumed the same aggregated probability.\n  - `aggregation` (`aggregation` enum, default `aggregation.mean`): \n    the aggregation method.\n  - `batch_size` (`int`, default `8`, upper-bounded by `aggregation_size`): \n    batch size to be used for model inference. choose a value that works the best \n    with your device resources.\n  - `output_video_path` (`optional[str]`, default `none`): \n    if not `none`, e.g., `out.mp4`,\n    an output mp4 video with the same frame size and frame rate as\n    the input video will be saved via opencv. the predicted nsfw probability \n    is printed on the top-left corner of each frame. be aware that the output \n    file size could be much larger than the input file size.\n    this output video is for reference only.\n  - `preprocessing`: same as that in `preprocess_image`.\n  - `weights_path`: same as that in `make_open_nsfw_model`.\n  - `progress_bar` (`bool`, default `true`): whether to show the progress bar.\n- return:\n  - tuple of `list[float]`, each with length equals to the number of video frames.\n    - `elapsed_seconds`: video elapsed time in seconds at each frame.\n    - `nsfw_probabilities`: nsfw probability of each frame. \n      for any `frame_interval > 1`, all frames without a prediction \n      will be assumed to have the nsfw probability of the previous predicted frame.\n\n# preprocessing details\n\n## options\n\nthis implementation provides the following preprocessing options.\n- `yahoo`: the default option which was used in the original \n  [yahoo's caffe](https://github.com/yahoo/open_nsfw/blob/master/classify_nsfw.py#l19-l80) \n  and the later \n  [tensorflow 1](https://github.com/mdietrichstein/tensorflow-open_nsfw/blob/master/image_utils.py#l4-l53) \n  implementations. the key steps are:\n  - resize the input pillow image to `(256, 256)`.\n  - store the image as jpeg in memory and reload it again to a numpy image \n    (this step is mysterious, but somehow it really makes a difference).\n  - crop the centre part of the numpy image with size `(224, 224)`.\n  - swap the colour channels to bgr.\n  - subtract the training dataset mean value of each channel: `[104, 117, 123]`.\n- `simple`: a simpler and probably more intuitive preprocessing option is also provided,\n  but note that the model output probabilities will be different.\n  the key steps are:\n  - resize the input pillow image to `(224, 224)`.\n  - convert to a numpy image.\n  - swap the colour channels to bgr.\n  - subtract the training dataset mean value of each channel: `[104, 117, 123]`.\n\n## comparison\n\nusing 521 private test images, the nsfw probabilities given by \nthree different settings are compared:\n- [tensorflow 1 implementation](https://github.com/mdietrichstein/tensorflow-open_nsfw) with `yahoo` preprocessing.\n- keras implementation with `yahoo` preprocessing.\n- keras implementation with `simple` preprocessing.\n\nthe following figure shows the result:\n\n![nsfw probabilities comparison](docs/nsfw_probabilities_comparison.png)\n\nthe current keras implementation with `yahoo` preprocessing\ncan totally reproduce the well-tested tensorflow 1 result, \nwith small floating point errors only.\n\nwith `simple` preprocessing the result is different, where the model tends \nto give lower probabilities over the current test images.\n\nnote that this comparison does not conclude which preprocessing method is \n\"better\", it only shows their discrepancies. however, users that prefer the\noriginal yahoo result should go for the default `yahoo` preprocessing.\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "opennsfw2",
  "package_url": "https://pypi.org/project/opennsfw2/",
  "project_url": "https://pypi.org/project/opennsfw2/",
  "project_urls": {
    "Homepage": "https://github.com/bhky/opennsfw2"
  },
  "release_url": "https://pypi.org/project/opennsfw2/0.13.4/",
  "requires_dist": [
    "gdown >=4.2.0",
    "keras >=3.0.0",
    "matplotlib >=3.0.0",
    "numpy >=1.22.0",
    "opencv-python >=4.0.0.0",
    "Pillow >=8.0.0",
    "scikit-image >=0.18.0",
    "tqdm >=4.62"
  ],
  "requires_python": ">=3.9",
  "summary": "tensorflow 2 implementation of the yahoo open-nsfw model",
  "version": "0.13.4",
  "releases": [],
  "developers": [
    "attr",
    "xtorch501@gmail.com"
  ],
  "kwds": "classify_nsfw open_nsfw caffe nsfw_probability open_nsfw_weights",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_opennsfw2",
  "homepage": "https://github.com/bhky/opennsfw2",
  "release_count": 28,
  "dependency_ids": [
    "pypi_gdown",
    "pypi_keras",
    "pypi_matplotlib",
    "pypi_numpy",
    "pypi_opencv_python",
    "pypi_pillow",
    "pypi_scikit_image",
    "pypi_tqdm"
  ]
}