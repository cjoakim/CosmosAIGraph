{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "programming language :: python :: 2",
    "programming language :: python :: 2.7",
    "programming language :: python :: 3",
    "programming language :: python :: 3.2",
    "programming language :: python :: 3.3",
    "programming language :: python :: 3.4",
    "programming language :: python :: 3.5",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: scientific/engineering :: human machine interfaces",
    "topic :: scientific/engineering :: information analysis"
  ],
  "description": ".. image:: https://travis-ci.org/wiseman/py-webrtcvad.svg?branch=master\n    :target: https://travis-ci.org/wiseman/py-webrtcvad\n\npy-webrtcvad\n============\n\nthis is a python interface to the webrtc voice activity detector\n(vad).  it is compatible with python 2 and python 3.\n\na `vad <https://en.wikipedia.org/wiki/voice_activity_detection>`_\nclassifies a piece of audio data as being voiced or unvoiced. it can\nbe useful for telephony and speech recognition.\n\nthe vad that google developed for the `webrtc <https://webrtc.org/>`_\nproject is reportedly one of the best available, being fast, modern\nand free.\n\nhow to use it\n-------------\n\n0. install the webrtcvad module::\n\n    pip install webrtcvad\n\n1. create a ``vad`` object::\n\n    import webrtcvad\n    vad = webrtcvad.vad()\n\n2. optionally, set its aggressiveness mode, which is an integer\n   between 0 and 3. 0 is the least aggressive about filtering out\n   non-speech, 3 is the most aggressive. (you can also set the mode\n   when you create the vad, e.g. ``vad = webrtcvad.vad(3)``)::\n\n    vad.set_mode(1)\n\n3. give it a short segment (\"frame\") of audio. the webrtc vad only\n   accepts 16-bit mono pcm audio, sampled at 8000, 16000, or 32000 hz.\n   a frame must be either 10, 20, or 30 ms in duration::\n\n    # run the vad on 10 ms of silence. the result should be false.\n    sample_rate = 16000\n    frame_duration = 10  # ms\n    frame = b'\\x00\\x00' * (sample_rate * frame_duration / 1000)\n    print 'contains speech: %s' % (vad.is_speech(frame, sample_rate)\n\n\nsee `example.py\n<https://github.com/wiseman/py-webrtcvad/blob/master/example.py>`_ for\na more detailed example that will process a .wav file, find the voiced\nsegments, and write each one as a separate .wav.\n\n\nhow to run unit tests\n---------------------\n\nto run unit tests::\n\n    pip install -e \".[dev]\"\n    python setup.py test",
  "docs_url": null,
  "keywords": "speechrecognition asr voiceactivitydetection vad webrtc",
  "license": "mit",
  "name": "webrtcvad",
  "package_url": "https://pypi.org/project/webrtcvad/",
  "project_url": "https://pypi.org/project/webrtcvad/",
  "project_urls": {
    "Homepage": "https://github.com/wiseman/py-webrtcvad"
  },
  "release_url": "https://pypi.org/project/webrtcvad/2.0.10/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "python interface to the google webrtc voice activity detector (vad)",
  "version": "2.0.10",
  "releases": [],
  "developers": [
    "jjwiseman@gmail.com",
    "john_wiseman"
  ],
  "kwds": "voice_activity_detection voiceactivitydetection speechrecognition webrtc voiced",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_webrtcvad",
  "homepage": "https://github.com/wiseman/py-webrtcvad",
  "release_count": 12,
  "dependency_ids": []
}