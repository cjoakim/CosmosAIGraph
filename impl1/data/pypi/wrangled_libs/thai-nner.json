{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "programming language :: python :: 3",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: text processing",
    "topic :: text processing :: general",
    "topic :: text processing :: linguistic"
  ],
  "description": "# thai-nner (thai nested named entity recognition corpus)\ncode associated with the paper [thai nested named entity recognition corpus](https://github.com/vistec-ai/thai-nner/files/8497522/thai_nested_named_entity_recognition_corpus.pdf) at acl 2022.\n\n## abstract / motivation\nthis work presents the first thai nested named entity recognition (n-ner) dataset. thai n-ner consists of 264,798 mentions, 104 classes, and a maximum depth of 8 layers obtained from news articles and restaurant reviews, a total of 4894 documents. our work, to the best of our knowledge, presents the largest non-english n-ner dataset and the first non-english one with fine-grained classes.\n\n# how to use?\n\n## install\n\n> pip install thai_nner\n\n## usage\n\nyou needs to download model from \"data/[checkpoints]\": \n[download](https://drive.google.com/drive/folders/1t71ljtpo1w7xmvquyfhdvynhixllwq-j?usp=sharing)\n\nexample: 0906_214036/checkpoint.pth\n\nand use ```convert_model2use.py``` script by\n\n> python convert_model2use.py -i 0906_214036/checkpoint.pth -o model.pth\n\n### usage example\n\n```python\nimport os\nos.environ['cuda_visible_devices'] = \"0\" # for non-gpu: os.environ['cuda_visible_devices'] = \"\"\nfrom thai_nner import nner\nnner = nner(\"model.pth\")\nnner.get_tag(\"\u0e27\u0e31\u0e19\u0e19\u0e35\u0e49\u0e27\u0e31\u0e19\u0e17\u0e35\u0e48 5 \u0e40\u0e21\u0e29\u0e32\u0e22\u0e19 2565 \u0e40\u0e1b\u0e47\u0e19\u0e27\u0e31\u0e19\u0e17\u0e35\u0e48\u0e2d\u0e32\u0e01\u0e32\u0e28\u0e14\u0e35\u0e21\u0e32\u0e01\")\n# output: (['<s>', '\u0e27\u0e31\u0e19\u0e19\u0e35\u0e49', '\u0e27\u0e31\u0e19\u0e17\u0e35\u0e48', '', '', '5', '', '', '\u0e40\u0e21\u0e29\u0e32\u0e22\u0e19', '', '', '25', '65', '', '', '\u0e40\u0e1b\u0e47\u0e19', '\u0e27\u0e31\u0e19\u0e17\u0e35\u0e48', '', '\u0e2d\u0e32\u0e01\u0e32\u0e28', '', '\u0e14\u0e35\u0e21\u0e32\u0e01', '</s>'], [{'text': ['\u0e27\u0e31\u0e19\u0e19\u0e35\u0e49'], 'span': [1, 2], 'entity_type': 'rel'}, {'text': ['\u0e27\u0e31\u0e19\u0e17\u0e35\u0e48', '', '', '5'], 'span': [2, 6], 'entity_type': 'day'}, {'text': ['\u0e27\u0e31\u0e19\u0e17\u0e35\u0e48', '', '', '5', '', '', '\u0e40\u0e21\u0e29\u0e32\u0e22\u0e19', '', '', '25', '65'], 'span': [2, 13], 'entity_type': 'date'}, {'text': ['', '5'], 'span': [4, 6], 'entity_type': 'cardinal'}, {'text': ['', '\u0e40\u0e21\u0e29\u0e32\u0e22\u0e19'], 'span': [7, 9], 'entity_type': 'month'}, {'text': ['', '25', '65'], 'span': [10, 13], 'entity_type': 'year'}])\n```\n\n\n## example\n### python library\n\n[colabs](https://colab.research.google.com/drive/1seazogm9tzseltxihdyi7dwnmdo-ytjy?usp=sharing)\n\n### test\n\n[colabs](https://colab.research.google.com/drive/16m7vx0ezlppy2pqllimlbfmi9kbo5o7a?usp=sharing)\n\n# dataset and models\n## model's checkpoint\ndownload and save  models' checkpoints at the following path \"data/[checkpoints]\": \n[download](https://drive.google.com/drive/folders/1t71ljtpo1w7xmvquyfhdvynhixllwq-j?usp=sharing)\n\n## dataset \ndownload and save the dataset at the following path \"data/[scb-nner-th-2022]\": \n[download](https://drive.google.com/drive/folders/1lp3zk4i2q2sc77aovtepy9chb8lagfek?usp=sharing)\n\n## pre-trained language model\ndownload and save the pre-trained language model at the following path \"data/[lm]\": \n[download](https://drive.google.com/drive/folders/1tkkttmx0ifm1da8sfsgqixzy1tudbtv_?usp=sharing)\n\n# training/testing\n## train\n```\npython train.py --device 0,1 -c config.json\n```\n## test\n```\npython test_nne.py --resume [path]/checkpoint.pth\n```\n## tensorboard\n```\ntensorboard --logdir [path]/save/log/\n```\n\n# results\n![experimental results](/img/results.png)\n\n\n# citation\n```\n@inproceedings{buaphet-etal-2022-thai-nner,\n    title = \"thai nested named entity recognition corpus\",\n    author = \"buaphet, weerayut  and\n      udomcharoenchaikit, can  and\n      limkonchotiwat, peerat and\n      rutherford, attapol  and \n      nutanong, sarana\",\n    booktitle = \"findings of the association for computational linguistics: acl 2022\"\n    year = \"2022\",\n    publisher = \"association for computational linguistics\",\n}\n```\n\n## license\ncc-by-sa 3.0\n\n## acknowledgements\n- dataset information: the thai n-ner corpus is supported in part by the digital economy promotion agency (depa) digital infrastructure fund mp-62-003 and siam commercial bank. this dataset is released as scb-nner-th-2022.\n- training code: [tensorflow-project-template](https://github.com/mrgemy95/tensorflow-project-template) by [mahmoud gemy](https://github.com/mrgemy95)\n\n\n",
  "docs_url": null,
  "keywords": "thai,nlp,natural language processing,text analytics,text processing,localization,computational linguistics,thai language",
  "license": "mit license",
  "name": "thai-nner",
  "package_url": "https://pypi.org/project/thai-nner/",
  "project_url": "https://pypi.org/project/thai-nner/",
  "project_urls": {
    "Bug Reports": "https://github.com/vistec-AI/Thai-NNER/issues",
    "Homepage": "https://github.com/vistec-AI/Thai-NNER",
    "Source": "https://github.com/vistec-AI/Thai-NNER"
  },
  "release_url": "https://pypi.org/project/thai-nner/0.3/",
  "requires_dist": [
    "torch (>=1.1)",
    "torchvision",
    "numpy",
    "tqdm",
    "tensorboard (>=1.14)",
    "transformers",
    "pythainlp",
    "sentencepiece"
  ],
  "requires_python": ">=3.6",
  "summary": "thai nested named entity recognition",
  "version": "0.3",
  "releases": [],
  "developers": [
    "weerayut.fame@gmail.com",
    "weerayut_buaphet"
  ],
  "kwds": "thai_nested_named_entity_recognition_corpus thai_nner thai ner corpus",
  "license_kwds": "mit license",
  "libtype": "pypi",
  "id": "pypi_thai_nner",
  "homepage": "https://github.com/vistec-ai/thai-nner",
  "release_count": 1,
  "dependency_ids": [
    "pypi_numpy",
    "pypi_pythainlp",
    "pypi_sentencepiece",
    "pypi_tensorboard",
    "pypi_torch",
    "pypi_torchvision",
    "pypi_tqdm",
    "pypi_transformers"
  ]
}