{
  "classifiers": [],
  "description": "# mim: mim installs openmmlab packages\n\nmim provides a unified interface for launching and installing openmmlab projects and their extensions, and managing the openmmlab model zoo.\n\n## major features\n\n- **package management**\n\n  you can use mim to manage openmmlab codebases, install or uninstall them conveniently.\n\n- **model management**\n\n  you can use mim to manage openmmlab model zoo, e.g., download checkpoints by name, search checkpoints that meet specific criteria.\n\n- **unified entrypoint for scripts**\n\n  you can execute any script provided by all openmmlab codebases with unified commands. train, test and inference become easier than ever. besides, you can use `gridsearch` command for vanilla hyper-parameter search.\n\n## license\n\nthis project is released under the [apache 2.0 license](license).\n\n## changelog\n\nv0.1.1 was released in 13/6/2021.\n\n## customization\n\nyou can use `.mimrc` for customization. now we support customize default values of each sub-command. please refer to [customization.md](docs/en/customization.md) for details.\n\n## build custom projects with mim\n\nwe provide some examples of how to build custom projects based on openmmlab codebases and mim in [mim-example](https://github.com/open-mmlab/mim-example).\nwithout worrying about copying codes and scripts from existing codebases, users can focus on developing new components and mim helps integrate and run the new project.\n\n## installation\n\nplease refer to [installation.md](docs/en/installation.md) for installation.\n\n## command\n\n<details>\n<summary>1. install</summary>\n\n- command\n\n  ```bash\n  # install latest version of mmcv-full\n  > mim install mmcv-full  # wheel\n  # install 1.5.0\n  > mim install mmcv-full==1.5.0\n\n  # install latest version of mmcls\n  > mim install mmcls\n  # install master branch\n  > mim install git+https://github.com/open-mmlab/mmclassification.git\n  # install local repo\n  > git clone https://github.com/open-mmlab/mmclassification.git\n  > cd mmclassification\n  > mim install .\n\n  # install extension based on openmmlab\n  mim install git+https://github.com/xxx/mmcls-project.git\n  ```\n\n- api\n\n  ```python\n  from mim import install\n\n  # install mmcv\n  install('mmcv-full')\n\n  # install mmcls will automatically install mmcv if it is not installed\n  install('mmcls')\n\n  # install extension based on openmmlab\n  install('git+https://github.com/xxx/mmcls-project.git')\n  ```\n\n</details>\n\n<details>\n<summary>2. uninstall</summary>\n\n- command\n\n  ```bash\n  # uninstall mmcv\n  > mim uninstall mmcv-full\n\n  # uninstall mmcls\n  > mim uninstall mmcls\n  ```\n\n- api\n\n  ```python\n  from mim import uninstall\n\n  # uninstall mmcv\n  uninstall('mmcv-full')\n\n  # uninstall mmcls\n  uninstall('mmcls')\n  ```\n\n</details>\n\n<details>\n<summary>3. list</summary>\n\n- command\n\n  ```bash\n  > mim list\n  > mim list --all\n  ```\n\n- api\n\n  ```python\n  from mim import list_package\n\n  list_package()\n  list_package(true)\n  ```\n\n</details>\n\n<details>\n<summary>4. search</summary>\n\n- command\n\n  ```bash\n  > mim search mmcls\n  > mim search mmcls==0.23.0 --remote\n  > mim search mmcls --config resnet18_8xb16_cifar10\n  > mim search mmcls --model resnet\n  > mim search mmcls --dataset cifar-10\n  > mim search mmcls --valid-field\n  > mim search mmcls --condition 'batch_size>45,epochs>100'\n  > mim search mmcls --condition 'batch_size>45 epochs>100'\n  > mim search mmcls --condition '128<batch_size<=256'\n  > mim search mmcls --sort batch_size epochs\n  > mim search mmcls --field epochs batch_size weight\n  > mim search mmcls --exclude-field weight paper\n  ```\n\n- api\n\n  ```python\n  from mim import get_model_info\n\n  get_model_info('mmcls')\n  get_model_info('mmcls==0.23.0', local=false)\n  get_model_info('mmcls', models=['resnet'])\n  get_model_info('mmcls', training_datasets=['cifar-10'])\n  get_model_info('mmcls', filter_conditions='batch_size>45,epochs>100')\n  get_model_info('mmcls', filter_conditions='batch_size>45 epochs>100')\n  get_model_info('mmcls', filter_conditions='128<batch_size<=256')\n  get_model_info('mmcls', sorted_fields=['batch_size', 'epochs'])\n  get_model_info('mmcls', shown_fields=['epochs', 'batch_size', 'weight'])\n  ```\n\n</details>\n\n<details>\n<summary>5. download</summary>\n\n- command\n\n  ```bash\n  > mim download mmcls --config resnet18_8xb16_cifar10\n  > mim download mmcls --config resnet18_8xb16_cifar10 --dest .\n  ```\n\n- api\n\n  ```python\n  from mim import download\n\n  download('mmcls', ['resnet18_8xb16_cifar10'])\n  download('mmcls', ['resnet18_8xb16_cifar10'], dest_root='.')\n  ```\n\n</details>\n\n<details>\n<summary>6. train</summary>\n\n- command\n\n  ```bash\n  # train models on a single server with cpu by setting `gpus` to 0 and\n  # 'launcher' to 'none' (if applicable). the training script of the\n  # corresponding codebase will fail if it doesn't support cpu training.\n  > mim train mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 0\n  # train models on a single server with one gpu\n  > mim train mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 1\n  # train models on a single server with 4 gpus and pytorch distributed\n  > mim train mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 4 \\\n      --launcher pytorch\n  # train models on a slurm hpc with one 8-gpu node\n  > mim train mmcls resnet101_b16x8_cifar10.py --launcher slurm --gpus 8 \\\n      --gpus-per-node 8 --partition partition_name --work-dir tmp\n  # print help messages of sub-command train\n  > mim train -h\n  # print help messages of sub-command train and the training script of mmcls\n  > mim train mmcls -h\n  ```\n\n- api\n\n  ```python\n  from mim import train\n\n  train(repo='mmcls', config='resnet18_8xb16_cifar10.py', gpus=0,\n        other_args='--work-dir tmp')\n  train(repo='mmcls', config='resnet18_8xb16_cifar10.py', gpus=1,\n        other_args='--work-dir tmp')\n  train(repo='mmcls', config='resnet18_8xb16_cifar10.py', gpus=4,\n        launcher='pytorch', other_args='--work-dir tmp')\n  train(repo='mmcls', config='resnet18_8xb16_cifar10.py', gpus=8,\n        launcher='slurm', gpus_per_node=8, partition='partition_name',\n        other_args='--work-dir tmp')\n  ```\n\n</details>\n\n<details>\n<summary>7. test</summary>\n\n- command\n\n  ```bash\n  # test models on a single server with 1 gpu, report accuracy\n  > mim test mmcls resnet101_b16x8_cifar10.py --checkpoint \\\n      tmp/epoch_3.pth --gpus 1 --metrics accuracy\n  # test models on a single server with 1 gpu, save predictions\n  > mim test mmcls resnet101_b16x8_cifar10.py --checkpoint \\\n      tmp/epoch_3.pth --gpus 1 --out tmp.pkl\n  # test models on a single server with 4 gpus, pytorch distributed,\n  # report accuracy\n  > mim test mmcls resnet101_b16x8_cifar10.py --checkpoint \\\n      tmp/epoch_3.pth --gpus 4 --launcher pytorch --metrics accuracy\n  # test models on a slurm hpc with one 8-gpu node, report accuracy\n  > mim test mmcls resnet101_b16x8_cifar10.py --checkpoint \\\n      tmp/epoch_3.pth --gpus 8 --metrics accuracy --partition \\\n      partition_name --gpus-per-node 8 --launcher slurm\n  # print help messages of sub-command test\n  > mim test -h\n  # print help messages of sub-command test and the testing script of mmcls\n  > mim test mmcls -h\n  ```\n\n- api\n\n  ```python\n  from mim import test\n  test(repo='mmcls', config='resnet101_b16x8_cifar10.py',\n       checkpoint='tmp/epoch_3.pth', gpus=1, other_args='--metrics accuracy')\n  test(repo='mmcls', config='resnet101_b16x8_cifar10.py',\n       checkpoint='tmp/epoch_3.pth', gpus=1, other_args='--out tmp.pkl')\n  test(repo='mmcls', config='resnet101_b16x8_cifar10.py',\n       checkpoint='tmp/epoch_3.pth', gpus=4, launcher='pytorch',\n       other_args='--metrics accuracy')\n  test(repo='mmcls', config='resnet101_b16x8_cifar10.py',\n       checkpoint='tmp/epoch_3.pth', gpus=8, partition='partition_name',\n       launcher='slurm', gpus_per_node=8, other_args='--metrics accuracy')\n  ```\n\n</details>\n\n<details>\n<summary>8. run</summary>\n\n- command\n\n  ```bash\n  # get the flops of a model\n  > mim run mmcls get_flops resnet101_b16x8_cifar10.py\n  # publish a model\n  > mim run mmcls publish_model input.pth output.pth\n  # train models on a slurm hpc with one gpu\n  > srun -p partition --gres=gpu:1 mim run mmcls train \\\n      resnet101_b16x8_cifar10.py --work-dir tmp\n  # test models on a slurm hpc with one gpu, report accuracy\n  > srun -p partition --gres=gpu:1 mim run mmcls test \\\n      resnet101_b16x8_cifar10.py tmp/epoch_3.pth --metrics accuracy\n  # print help messages of sub-command run\n  > mim run -h\n  # print help messages of sub-command run, list all available scripts in\n  # codebase mmcls\n  > mim run mmcls -h\n  # print help messages of sub-command run, print the help message of\n  # training script in mmcls\n  > mim run mmcls train -h\n  ```\n\n- api\n\n  ```python\n  from mim import run\n\n  run(repo='mmcls', command='get_flops',\n      other_args='resnet101_b16x8_cifar10.py')\n  run(repo='mmcls', command='publish_model',\n      other_args='input.pth output.pth')\n  run(repo='mmcls', command='train',\n      other_args='resnet101_b16x8_cifar10.py --work-dir tmp')\n  run(repo='mmcls', command='test',\n      other_args='resnet101_b16x8_cifar10.py tmp/epoch_3.pth --metrics accuracy')\n  ```\n\n</details>\n\n<details>\n<summary>9. gridsearch</summary>\n\n- command\n\n  ```bash\n  # parameter search on a single server with cpu by setting `gpus` to 0 and\n  # 'launcher' to 'none' (if applicable). the training script of the\n  # corresponding codebase will fail if it doesn't support cpu training.\n  > mim gridsearch mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 0 \\\n      --search-args '--optimizer.lr 1e-2 1e-3'\n  # parameter search with on a single server with one gpu, search learning\n  # rate\n  > mim gridsearch mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 1 \\\n      --search-args '--optimizer.lr 1e-2 1e-3'\n  # parameter search with on a single server with one gpu, search\n  # weight_decay\n  > mim gridsearch mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 1 \\\n      --search-args '--optimizer.weight_decay 1e-3 1e-4'\n  # parameter search with on a single server with one gpu, search learning\n  # rate and weight_decay\n  > mim gridsearch mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 1 \\\n      --search-args '--optimizer.lr 1e-2 1e-3 --optimizer.weight_decay 1e-3 \\\n      1e-4'\n  # parameter search on a slurm hpc with one 8-gpu node, search learning\n  # rate and weight_decay\n  > mim gridsearch mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 8 \\\n      --partition partition_name --gpus-per-node 8 --launcher slurm \\\n      --search-args '--optimizer.lr 1e-2 1e-3 --optimizer.weight_decay 1e-3 \\\n      1e-4'\n  # parameter search on a slurm hpc with one 8-gpu node, search learning\n  # rate and weight_decay, max parallel jobs is 2\n  > mim gridsearch mmcls resnet101_b16x8_cifar10.py --work-dir tmp --gpus 8 \\\n      --partition partition_name --gpus-per-node 8 --launcher slurm \\\n      --max-jobs 2 --search-args '--optimizer.lr 1e-2 1e-3 \\\n      --optimizer.weight_decay 1e-3 1e-4'\n  # print the help message of sub-command search\n  > mim gridsearch -h\n  # print the help message of sub-command search and the help message of the\n  # training script of codebase mmcls\n  > mim gridsearch mmcls -h\n  ```\n\n- api\n\n  ```python\n  from mim import gridsearch\n\n  gridsearch(repo='mmcls', config='resnet101_b16x8_cifar10.py', gpus=0,\n             search_args='--optimizer.lr 1e-2 1e-3',\n             other_args='--work-dir tmp')\n  gridsearch(repo='mmcls', config='resnet101_b16x8_cifar10.py', gpus=1,\n             search_args='--optimizer.lr 1e-2 1e-3',\n             other_args='--work-dir tmp')\n  gridsearch(repo='mmcls', config='resnet101_b16x8_cifar10.py', gpus=1,\n             search_args='--optimizer.weight_decay 1e-3 1e-4',\n             other_args='--work-dir tmp')\n  gridsearch(repo='mmcls', config='resnet101_b16x8_cifar10.py', gpus=1,\n             search_args='--optimizer.lr 1e-2 1e-3 --optimizer.weight_decay'\n                         '1e-3 1e-4',\n             other_args='--work-dir tmp')\n  gridsearch(repo='mmcls', config='resnet101_b16x8_cifar10.py', gpus=8,\n             partition='partition_name', gpus_per_node=8, launcher='slurm',\n             search_args='--optimizer.lr 1e-2 1e-3 --optimizer.weight_decay'\n                         ' 1e-3 1e-4',\n             other_args='--work-dir tmp')\n  gridsearch(repo='mmcls', config='resnet101_b16x8_cifar10.py', gpus=8,\n             partition='partition_name', gpus_per_node=8, launcher='slurm',\n             max_workers=2,\n             search_args='--optimizer.lr 1e-2 1e-3 --optimizer.weight_decay'\n                         ' 1e-3 1e-4',\n             other_args='--work-dir tmp')\n  ```\n\n</details>\n\n## contributing\n\nwe appreciate all contributions to improve mim. please refer to [contributing.md](https://github.com/open-mmlab/mmcv/blob/master/contributing.md) for the contributing guideline.\n\n## license\n\nthis project is released under the [apache 2.0 license](license).\n\n## projects in openmmlab\n\n- [mmengine](https://github.com/open-mmlab/mmengine): openmmlab foundational library for training deep learning models.\n- [mmcv](https://github.com/open-mmlab/mmcv): openmmlab foundational library for computer vision.\n- [mmeval](https://github.com/open-mmlab/mmeval): a unified evaluation library for multiple machine learning libraries.\n- [mmpretrain](https://github.com/open-mmlab/mmpretrain): openmmlab pre-training toolbox and benchmark.\n- [mmagic](https://github.com/open-mmlab/mmagic): open**mm**lab **a**dvanced, **g**enerative and **i**ntelligent **c**reation toolbox.\n- [mmdetection](https://github.com/open-mmlab/mmdetection): openmmlab detection toolbox and benchmark.\n- [mmyolo](https://github.com/open-mmlab/mmyolo): openmmlab yolo series toolbox and benchmark.\n- [mmdetection3d](https://github.com/open-mmlab/mmdetection3d): openmmlab's next-generation platform for general 3d object detection.\n- [mmrotate](https://github.com/open-mmlab/mmrotate): openmmlab rotated object detection toolbox and benchmark.\n- [mmtracking](https://github.com/open-mmlab/mmtracking): openmmlab video perception toolbox and benchmark.\n- [mmpose](https://github.com/open-mmlab/mmpose): openmmlab pose estimation toolbox and benchmark.\n- [mmsegmentation](https://github.com/open-mmlab/mmsegmentation): openmmlab semantic segmentation toolbox and benchmark.\n- [mmocr](https://github.com/open-mmlab/mmocr): openmmlab text detection, recognition, and understanding toolbox.\n- [mmhuman3d](https://github.com/open-mmlab/mmhuman3d): openmmlab 3d human parametric model toolbox and benchmark.\n- [mmselfsup](https://github.com/open-mmlab/mmselfsup): openmmlab self-supervised learning toolbox and benchmark.\n- [mmfewshot](https://github.com/open-mmlab/mmfewshot): openmmlab fewshot learning toolbox and benchmark.\n- [mmaction2](https://github.com/open-mmlab/mmaction2): openmmlab's next-generation action understanding toolbox and benchmark.\n- [mmflow](https://github.com/open-mmlab/mmflow): openmmlab optical flow toolbox and benchmark.\n- [mmdeploy](https://github.com/open-mmlab/mmdeploy): openmmlab model deployment framework.\n- [mmrazor](https://github.com/open-mmlab/mmrazor): openmmlab model compression toolbox and benchmark.\n- [playground](https://github.com/open-mmlab/playground): a central hub for gathering and showcasing amazing projects built upon openmmlab.\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "openmim",
  "package_url": "https://pypi.org/project/openmim/",
  "project_url": "https://pypi.org/project/openmim/",
  "project_urls": {
    "Homepage": "https://github.com/open-mmlab/mim"
  },
  "release_url": "https://pypi.org/project/openmim/0.3.9/",
  "requires_dist": [
    "Click",
    "colorama",
    "model-index",
    "opendatalab",
    "pandas",
    "pip (>=19.3)",
    "requests",
    "rich",
    "tabulate",
    "Click ; extra == 'all'",
    "colorama ; extra == 'all'",
    "model-index ; extra == 'all'",
    "opendatalab ; extra == 'all'",
    "pandas ; extra == 'all'",
    "pip (>=19.3) ; extra == 'all'",
    "requests ; extra == 'all'",
    "rich ; extra == 'all'",
    "tabulate ; extra == 'all'",
    "docutils (==0.16.0) ; extra == 'all'",
    "myst-parser ; extra == 'all'",
    "pytorch-sphinx-theme ; extra == 'all'",
    "sphinx (==4.0.2) ; extra == 'all'",
    "sphinx-copybutton ; extra == 'all'",
    "sphinx-markdown-tables ; extra == 'all'",
    "coverage ; extra == 'all'",
    "flake8 ; extra == 'all'",
    "interrogate ; extra == 'all'",
    "pytest ; extra == 'all'",
    "coverage ; extra == 'tests'",
    "flake8 ; extra == 'tests'",
    "interrogate ; extra == 'tests'",
    "pytest ; extra == 'tests'"
  ],
  "requires_python": ">=3.6",
  "summary": "mim installs openmmlab packages",
  "version": "0.3.9",
  "releases": [],
  "developers": [
    "mim_authors",
    "openmmlab@gmail.com"
  ],
  "kwds": "openmmlab mmlab commands changelog gridsearch",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_openmim",
  "homepage": "https://github.com/open-mmlab/mim",
  "release_count": 19,
  "dependency_ids": [
    "pypi_click",
    "pypi_colorama",
    "pypi_coverage",
    "pypi_docutils",
    "pypi_flake8",
    "pypi_interrogate",
    "pypi_model_index",
    "pypi_myst_parser",
    "pypi_opendatalab",
    "pypi_pandas",
    "pypi_pip",
    "pypi_pytest",
    "pypi_pytorch_sphinx_theme",
    "pypi_requests",
    "pypi_rich",
    "pypi_sphinx",
    "pypi_sphinx_copybutton",
    "pypi_sphinx_markdown_tables",
    "pypi_tabulate"
  ]
}