{
  "classifiers": [],
  "description": "project description\n===================\n\nmulti model server (mms) is a flexible and easy to use tool for\nserving deep learning models exported from `mxnet <http://mxnet.io/>`__\nor the open neural network exchange (`onnx <http://onnx.ai/>`__).\n\nuse the mms server cli, or the pre-configured docker images, to start a\nservice that sets up http endpoints to handle model inference requests.\n\ndetailed documentation and examples are provided in the `docs\nfolder <https://github.com/awslabs/multi-model-server/blob/master/docs/readme.md>`__.\n\nprerequisites\n-------------\n\n* **java 8**: required. mms use java to serve http requests. you must install java 8 (or later) and make sure java is on available in $path environment variable *before* installing mms. if you have multiple java installed, you can use $java_home environment vairable to control which java to use.\n* **mxnet**: `mxnet` will not be installed by default with mms 1.0 any more. you have to install it manually if you use mxnet.\n\nfor ubuntu:\n::\n\n    sudo apt-get install openjdk-8-jre-headless\n\n\nfor centos\n::\n\n    sudo yum install java-1.8.0-openjdk\n\n\nfor mac:\n::\n\n    brew tap caskroom/versions\n    brew update\n    brew cask install java8\n\n\ninstall mxnet:\n::\n\n    pip install mxnet\n\nmxnet offers mkl pip packages that will be much faster when running on intel hardware.\nto install mkl package for cpu:\n::\n\n    pip install mxnet-mkl\n\nor for gpu instance:\n\n::\n\n    pip install mxnet-cu92mkl\n\n\ninstallation\n------------\n\n::\n\n    pip install multi-model-server\n\ndevelopment\n-----------\n\nwe welcome new contributors of all experience levels. for information on\nhow to install mms for development, refer to the `mms\ndocs <https://github.com/awslabs/multi-model-server/blob/master/docs/install.md>`__.\n\nimportant links\n---------------\n\n-  `official source code\n   repo <https://github.com/awslabs/multi-model-server>`__\n-  `download\n   releases <https://pypi.org/project/multi-model-server/#files>`__\n-  `issue\n   tracker <https://github.com/awslabs/multi-model-server/issues>`__\n\nsource code\n-----------\n\nyou can check the latest source code as follows:\n\n::\n\n    git clone https://github.com/awslabs/multi-model-server.git\n\ntesting\n-------\n\nafter installation, try out the mms quickstart for\n\n- `serving a model <https://github.com/awslabs/multi-model-server/blob/master/readme.md#serve-a-model>`__\n- `create a model archive <https://github.com/awslabs/multi-model-server/blob/master/readme.md#model-archive>`__.\n\nhelp and support\n----------------\n\n-  `documentation <https://github.com/awslabs/multi-model-server/blob/master/docs/readme.md>`__\n-  `forum <https://discuss.mxnet.io/latest>`__\n\ncitation\n--------\n\nif you use mms in a publication or project, please cite mms:\nhttps://github.com/awslabs/multi-model-server\n",
  "docs_url": null,
  "keywords": "multi model server serving deep learning inference ai",
  "license": "apache license version 2.0",
  "name": "multi-model-server",
  "package_url": "https://pypi.org/project/multi-model-server/",
  "project_url": "https://pypi.org/project/multi-model-server/",
  "project_urls": {
    "Homepage": "https://github.com/awslabs/multi-model-server"
  },
  "release_url": "https://pypi.org/project/multi-model-server/1.1.11/",
  "requires_dist": [
    "Pillow",
    "psutil",
    "future",
    "model-archiver",
    "mxnet ; extra == 'mxnet'",
    "mxnet-cu90mkl ; extra == 'mxnet-cu90mkl'",
    "mxnet-mkl ; extra == 'mxnet-mkl'"
  ],
  "requires_python": "",
  "summary": "multi model server is a tool for serving neural net models for inference",
  "version": "1.1.11",
  "releases": [],
  "developers": [
    "noreply@amazon.com",
    "trinity_team"
  ],
  "kwds": "awslabs mxnet server models http",
  "license_kwds": "apache license version 2.0",
  "libtype": "pypi",
  "id": "pypi_multi_model_server",
  "homepage": "https://github.com/awslabs/multi-model-server",
  "release_count": 1113,
  "dependency_ids": [
    "pypi_future",
    "pypi_model_archiver",
    "pypi_mxnet",
    "pypi_mxnet_cu90mkl",
    "pypi_mxnet_mkl",
    "pypi_pillow",
    "pypi_psutil"
  ]
}