{
  "classifiers": [
    "development status :: 4 - beta",
    "license :: osi approved :: apache software license",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "<div align=\"center\">\n  <img src=\"resources/mmtrack-logo.png\" width=\"600\"/>\n  <div>&nbsp;</div>\n  <div align=\"center\">\n    <b><font size=\"5\">openmmlab website</font></b>\n    <sup>\n      <a href=\"https://openmmlab.com\">\n        <i><font size=\"4\">hot</font></i>\n      </a>\n    </sup>\n    &nbsp;&nbsp;&nbsp;&nbsp;\n    <b><font size=\"5\">openmmlab platform</font></b>\n    <sup>\n      <a href=\"https://platform.openmmlab.com\">\n        <i><font size=\"4\">try it out</font></i>\n      </a>\n    </sup>\n  </div>\n  <div>&nbsp;</div>\n\n[![pypi - python version](https://img.shields.io/pypi/pyversions/mmtrack)](https://pypi.org/project/mmtrack/)\n[![pypi](https://img.shields.io/pypi/v/mmtrack)](https://pypi.org/project/mmtrack)\n[![docs](https://img.shields.io/badge/docs-latest-blue)](https://mmtracking.readthedocs.io/en/latest/)\n[![badge](https://github.com/open-mmlab/mmtracking/workflows/build/badge.svg)](https://github.com/open-mmlab/mmtracking/actions)\n[![codecov](https://codecov.io/gh/open-mmlab/mmtracking/branch/master/graph/badge.svg)](https://codecov.io/gh/open-mmlab/mmtracking)\n[![license](https://img.shields.io/github/license/open-mmlab/mmtracking.svg)](https://github.com/open-mmlab/mmtracking/blob/master/license)\n\n[\ud83d\udcd8documentation](https://mmtracking.readthedocs.io/) |\n[\ud83d\udee0\ufe0finstallation](https://mmtracking.readthedocs.io/en/latest/install.html) |\n[\ud83d\udc40model zoo](https://mmtracking.readthedocs.io/en/latest/model_zoo.html) |\n[\ud83c\udd95update news](https://mmtracking.readthedocs.io/en/latest/changelog.html) |\n[\ud83e\udd14reporting issues](https://github.com/open-mmlab/mmtracking/issues/new/choose)\n\n</div>\n\n<div align=\"center\">\n\nenglish | [\u7b80\u4f53\u4e2d\u6587](readme_zh-cn.md)\n\n</div>\n\n## introduction\n\nmmtracking is an open source video perception toolbox by pytorch. it is a part of [openmmlab](https://openmmlab.com) project.\n\nthe master branch works with **pytorch1.5+**.\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/24663779/103343312-c724f480-4ac6-11eb-9c22-b56f1902584e.gif\" width=\"800\"/>\n</div>\n\n### major features\n\n- **the first unified video perception platform**\n\n  we are the first open source toolbox that unifies versatile video perception tasks include video object detection, multiple object tracking, single object tracking and video instance segmentation.\n\n- **modular design**\n\n  we decompose the video perception framework into different components and one can easily construct a customized method by combining different modules.\n\n- **simple, fast and strong**\n\n  **simple**: mmtracking interacts with other openmmlab projects. it is built upon [mmdetection](https://github.com/open-mmlab/mmdetection) that we can capitalize any detector only through modifying the configs.\n\n  **fast**: all operations run on gpus. the training and inference speeds are faster than or comparable to other implementations.\n\n  **strong**: we reproduce state-of-the-art models and some of them even outperform the official implementations.\n\n## what's new\n\nwe release mmtracking 1.0.0rc0, the first version of mmtracking 1.x.\n\nbuilt upon the new [training engine](https://github.com/open-mmlab/mmengine), mmtracking 1.x unifies the interfaces of datasets, models, evaluation, and visualization.\n\nwe also support more methods in mmtracking 1.x, such as [strongsort](https://github.com/open-mmlab/mmtracking/tree/dev-1.x/configs/mot/strongsort) for mot, [mask2former](https://github.com/open-mmlab/mmtracking/tree/dev-1.x/configs/vis/mask2former) for vis, [prdimp](https://github.com/open-mmlab/mmtracking/tree/dev-1.x/configs/sot/prdimp) for sot.\n\nplease refer to [dev-1.x](https://github.com/open-mmlab/mmtracking/tree/dev-1.x) branch for the using of mmtracking 1.x.\n\n## installation\n\nplease refer to [install.md](docs/en/install.md) for install instructions.\n\n## getting started\n\nplease see [dataset.md](docs/en/dataset.md) and [quick_run.md](docs/en/quick_run.md) for the basic usage of mmtracking.\n\na colab tutorial is provided. you may preview the notebook [here](./demo/mmtracking_tutorial.ipynb) or directly run it on [colab](https://colab.research.google.com/github/open-mmlab/mmtracking/blob/master/demo/mmtracking_tutorial.ipynb).\n\nthere are also usage [tutorials](docs/en/tutorials/), such as [learning about configs](docs/en/tutorials/config.md), [an example about detailed description of vid config](docs/en/tutorials/config_vid.md), [an example about detailed description of mot config](docs/en/tutorials/config_mot.md), [an example about detailed description of sot config](docs/en/tutorials/config_sot.md), [customizing dataset](docs/en/tutorials/customize_dataset.md), [customizing data pipeline](docs/en/tutorials/customize_data_pipeline.md), [customizing vid model](docs/en/tutorials/customize_vid_model.md), [customizing mot model](docs/en/tutorials/customize_mot_model.md), [customizing sot model](docs/en/tutorials/customize_sot_model.md), [customizing runtime settings](docs/en/tutorials/customize_runtime.md) and [useful tools](docs/en/useful_tools_scripts.md).\n\n## benchmark and model zoo\n\nresults and models are available in the [model zoo](docs/en/model_zoo.md).\n\n### video object detection\n\nsupported methods\n\n- [x] [dff](configs/vid/dff) (cvpr 2017)\n- [x] [fgfa](configs/vid/fgfa) (iccv 2017)\n- [x] [selsa](configs/vid/selsa) (iccv 2019)\n- [x] [temporal roi align](configs/vid/temporal_roi_align) (aaai 2021)\n\nsupported datasets\n\n- [x] [ilsvrc](http://image-net.org/challenges/lsvrc/2017/)\n\n### single object tracking\n\nsupported methods\n\n- [x] [siameserpn++](configs/sot/siamese_rpn) (cvpr 2019)\n- [x] [stark](configs/sot/stark) (iccv 2021)\n- [ ] [prdimp](https://arxiv.org/abs/2003.12565) (cvpr2020) (wip)\n\nsupported datasets\n\n- [x] [lasot](http://vision.cs.stonybrook.edu/~lasot/)\n- [x] [uav123](https://cemse.kaust.edu.sa/ivul/uav123/)\n- [x] [trackingnet](https://tracking-net.org/)\n- [x] [otb100](http://www.visual-tracking.net/)\n- [x] [got10k](http://got-10k.aitestunion.com/)\n- [x] [vot2018](https://www.votchallenge.net/vot2018/)\n\n### multi-object tracking\n\nsupported methods\n\n- [x] [sort/deepsort](configs/mot/deepsort) (icip 2016/2017)\n- [x] [tracktor](configs/mot/tracktor) (iccv 2019)\n- [x] [qdtrack](configs/mot/qdtrack) (cvpr 2021)\n- [x] [bytetrack](configs/mot/bytetrack) (eccv 2022)\n- [x] [oc-sort](configs/mot/ocsort) (arxiv 2022)\n\nsupported datasets\n\n- [x] [mot challenge](https://motchallenge.net/)\n- [x] [crowdhuman](https://www.crowdhuman.org/)\n- [x] [lvis](https://www.lvisdataset.org/)\n- [x] [tao](https://taodataset.org/)\n- [x] [dancetrack](https://arxiv.org/abs/2111.14690)\n\n### video instance segmentation\n\nsupported methods\n\n- [x] [masktrack r-cnn](configs/vis/masktrack_rcnn) (iccv 2019)\n\nsupported datasets\n\n- [x] [youtube-vis](https://youtube-vos.org/dataset/vis/)\n\n## contributing\n\nwe appreciate all contributions to improve mmtracking. please refer to [contributing.md](https://github.com/open-mmlab/mmcv/blob/master/contributing.md) for the contributing guideline and [this discussion](https://github.com/open-mmlab/mmtracking/issues/73) for development roadmap.\n\n## acknowledgement\n\nmmtracking is an open source project that welcome any contribution and feedback.\nwe wish that the toolbox and benchmark could serve the growing research\ncommunity by providing a flexible as well as standardized toolkit to reimplement existing methods\nand develop their own new video perception methods.\n\n## citation\n\nif you find this project useful in your research, please consider cite:\n\n```latex\n@misc{mmtrack2020,\n    title={{mmtracking: openmmlab} video perception toolbox and benchmark},\n    author={mmtracking contributors},\n    howpublished = {\\url{https://github.com/open-mmlab/mmtracking}},\n    year={2020}\n}\n```\n\n## license\n\nthis project is released under the [apache 2.0 license](license).\n\n## projects in openmmlab\n\n- [mmcv](https://github.com/open-mmlab/mmcv): openmmlab foundational library for computer vision.\n- [mim](https://github.com/open-mmlab/mim): mim installs openmmlab packages.\n- [mmclassification](https://github.com/open-mmlab/mmclassification): openmmlab image classification toolbox and benchmark.\n- [mmdetection](https://github.com/open-mmlab/mmdetection): openmmlab detection toolbox and benchmark.\n- [mmdetection3d](https://github.com/open-mmlab/mmdetection3d): openmmlab's next-generation platform for general 3d object detection.\n- [mmrotate](https://github.com/open-mmlab/mmrotate): openmmlab rotated object detection toolbox and benchmark.\n- [mmsegmentation](https://github.com/open-mmlab/mmsegmentation): openmmlab semantic segmentation toolbox and benchmark.\n- [mmocr](https://github.com/open-mmlab/mmocr): openmmlab text detection, recognition and understanding toolbox.\n- [mmpose](https://github.com/open-mmlab/mmpose): openmmlab pose estimation toolbox and benchmark.\n- [mmhuman3d](https://github.com/open-mmlab/mmhuman3d): openmmlab 3d human parametric model toolbox and benchmark.\n- [mmselfsup](https://github.com/open-mmlab/mmselfsup): openmmlab self-supervised learning toolbox and benchmark.\n- [mmrazor](https://github.com/open-mmlab/mmrazor): openmmlab model compression toolbox and benchmark.\n- [mmfewshot](https://github.com/open-mmlab/mmfewshot): openmmlab fewshot learning toolbox and benchmark.\n- [mmaction2](https://github.com/open-mmlab/mmaction2): openmmlab's next-generation action understanding toolbox and benchmark.\n- [mmtracking](https://github.com/open-mmlab/mmtracking): openmmlab video perception toolbox and benchmark.\n- [mmflow](https://github.com/open-mmlab/mmflow): openmmlab optical flow toolbox and benchmark.\n- [mmediting](https://github.com/open-mmlab/mmediting): openmmlab image and video editing toolbox.\n- [mmgeneration](https://github.com/open-mmlab/mmgeneration):  openmmlab generative model toolbox and benchmark.\n- [mmdeploy](https://github.com/open-mmlab/mmdeploy): openmmlab deep learning model deployment toolset.\n\n\n",
  "docs_url": null,
  "keywords": "computer vision,object tracking,video object detection",
  "license": "apache license 2.0",
  "name": "mmtrack",
  "package_url": "https://pypi.org/project/mmtrack/",
  "project_url": "https://pypi.org/project/mmtrack/",
  "project_urls": {
    "Homepage": "https://github.com/open-mmlab/mmtracking"
  },
  "release_url": "https://pypi.org/project/mmtrack/0.14.0/",
  "requires_dist": [
    "attributee",
    "dotty-dict",
    "lap",
    "matplotlib",
    "mmcls (<1.0.0,>=0.16.0)",
    "motmetrics",
    "packaging",
    "pandas (<=1.3.5)",
    "pycocotools",
    "scipy (<=1.7.3)",
    "seaborn",
    "terminaltables",
    "tqdm",
    "cython ; extra == 'all'",
    "numpy ; extra == 'all'",
    "attributee ; extra == 'all'",
    "dotty-dict ; extra == 'all'",
    "lap ; extra == 'all'",
    "matplotlib ; extra == 'all'",
    "mmcls (<1.0.0,>=0.16.0) ; extra == 'all'",
    "motmetrics ; extra == 'all'",
    "packaging ; extra == 'all'",
    "pandas (<=1.3.5) ; extra == 'all'",
    "pycocotools ; extra == 'all'",
    "scipy (<=1.7.3) ; extra == 'all'",
    "seaborn ; extra == 'all'",
    "terminaltables ; extra == 'all'",
    "tqdm ; extra == 'all'",
    "asynctest ; extra == 'all'",
    "codecov ; extra == 'all'",
    "flake8 ; extra == 'all'",
    "interrogate ; extra == 'all'",
    "isort (==4.3.21) ; extra == 'all'",
    "kwarray ; extra == 'all'",
    "pytest ; extra == 'all'",
    "ubelt ; extra == 'all'",
    "xdoctest (>=0.10.0) ; extra == 'all'",
    "yapf ; extra == 'all'",
    "cython ; extra == 'build'",
    "numpy ; extra == 'build'",
    "mmcls (<1.0.0,>=0.16.0) ; extra == 'mim'",
    "mmcv-full (<1.7.0,>=1.3.17) ; extra == 'mim'",
    "mmdet (<3.0.0,>=2.19.1) ; extra == 'mim'",
    "asynctest ; extra == 'tests'",
    "codecov ; extra == 'tests'",
    "flake8 ; extra == 'tests'",
    "interrogate ; extra == 'tests'",
    "isort (==4.3.21) ; extra == 'tests'",
    "kwarray ; extra == 'tests'",
    "pytest ; extra == 'tests'",
    "ubelt ; extra == 'tests'",
    "xdoctest (>=0.10.0) ; extra == 'tests'",
    "yapf ; extra == 'tests'"
  ],
  "requires_python": "",
  "summary": "openmmlab unified video perception platform",
  "version": "0.14.0",
  "releases": [],
  "developers": [
    "mmtracking_contributors",
    "openmmlab@gmail.com"
  ],
  "kwds": "openmmlab tracking detection trackingnet mmcv",
  "license_kwds": "apache license 2.0",
  "libtype": "pypi",
  "id": "pypi_mmtrack",
  "homepage": "https://github.com/open-mmlab/mmtracking",
  "release_count": 13,
  "dependency_ids": [
    "pypi_asynctest",
    "pypi_attributee",
    "pypi_codecov",
    "pypi_cython",
    "pypi_dotty_dict",
    "pypi_flake8",
    "pypi_interrogate",
    "pypi_isort",
    "pypi_kwarray",
    "pypi_lap",
    "pypi_matplotlib",
    "pypi_mmcls",
    "pypi_mmcv_full",
    "pypi_mmdet",
    "pypi_motmetrics",
    "pypi_numpy",
    "pypi_packaging",
    "pypi_pandas",
    "pypi_pycocotools",
    "pypi_pytest",
    "pypi_scipy",
    "pypi_seaborn",
    "pypi_terminaltables",
    "pypi_tqdm",
    "pypi_ubelt",
    "pypi_xdoctest",
    "pypi_yapf"
  ]
}