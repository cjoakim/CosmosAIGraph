{
  "classifiers": [
    "development status :: 5 - production/stable",
    "environment :: console",
    "intended audience :: science/research",
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "programming language :: rust",
    "topic :: scientific/engineering"
  ],
  "description": "<h1 align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg\">\n  <br>\n</h1>\n\n<div align=\"center\">\n  <a href=\"https://crates.io/crates/polars\">\n    <img src=\"https://img.shields.io/crates/v/polars.svg\"/>\n  </a>\n  <a href=\"https://pypi.org/project/polars/\">\n    <img src=\"https://img.shields.io/pypi/v/polars.svg\" alt=\"pypi latest release\"/>\n  </a>\n  <a href=\"https://www.npmjs.com/package/nodejs-polars\">\n    <img src=\"https://img.shields.io/npm/v/nodejs-polars.svg\" alt=\"npm latest release\"/>\n  </a>\n  <a href=\"https://rpolars.r-universe.dev\">\n    <img src=\"https://rpolars.r-universe.dev/badges/polars\" alt=\"r-universe latest release\"/>\n  </a>\n  <a href=\"https://doi.org/10.5281/zenodo.7697217\">\n    <img src=\"https://zenodo.org/badge/doi/10.5281/zenodo.7697217.svg\" alt=\"doi latest release\"/>\n  </a>\n</div>\n\n<p align=\"center\">\n  <b>documentation</b>:\n  <a href=\"https://pola-rs.github.io/polars/py-polars/html/reference/index.html\">python</a>\n  -\n  <a href=\"https://docs.rs/polars/latest/polars/\">rust</a>\n  -\n  <a href=\"https://pola-rs.github.io/nodejs-polars/index.html\">node.js</a>\n  -\n  <a href=\"https://rpolars.github.io/index.html\">r</a>\n  |\n  <b>stackoverflow</b>:\n  <a href=\"https://stackoverflow.com/questions/tagged/python-polars\">python</a>\n  -\n  <a href=\"https://stackoverflow.com/questions/tagged/rust-polars\">rust</a>\n  -\n  <a href=\"https://stackoverflow.com/questions/tagged/nodejs-polars\">node.js</a>\n  -\n  <a href=\"https://stackoverflow.com/questions/tagged/r-polars\">r</a>\n  |\n  <a href=\"https://pola-rs.github.io/polars/\">user guide</a>\n  |\n  <a href=\"https://discord.gg/4ufp5cfbe7\">discord</a>\n</p>\n\n## polars: blazingly fast dataframes in rust, python, node.js, r and sql\n\npolars is a dataframe interface on top of an olap query engine implemented in rust using\n[apache arrow columnar format](https://arrow.apache.org/docs/format/columnar.html) as the memory model.\n\n- lazy | eager execution\n- multi-threaded\n- simd\n- query optimization\n- powerful expression api\n- hybrid streaming (larger than ram datasets)\n- rust | python | nodejs | r | ...\n\nto learn more, read the [user guide](https://pola-rs.github.io/polars/).\n\n## python\n\n```python\n>>> import polars as pl\n>>> df = pl.dataframe(\n...     {\n...         \"a\": [1, 2, 3, 4, 5],\n...         \"fruits\": [\"banana\", \"banana\", \"apple\", \"apple\", \"banana\"],\n...         \"b\": [5, 4, 3, 2, 1],\n...         \"cars\": [\"beetle\", \"audi\", \"beetle\", \"beetle\", \"beetle\"],\n...     }\n... )\n\n# embarrassingly parallel execution & very expressive query language\n>>> df.sort(\"fruits\").select(\n...     \"fruits\",\n...     \"cars\",\n...     pl.lit(\"fruits\").alias(\"literal_string_fruits\"),\n...     pl.col(\"b\").filter(pl.col(\"cars\") == \"beetle\").sum(),\n...     pl.col(\"a\").filter(pl.col(\"b\") > 2).sum().over(\"cars\").alias(\"sum_a_by_cars\"),\n...     pl.col(\"a\").sum().over(\"fruits\").alias(\"sum_a_by_fruits\"),\n...     pl.col(\"a\").reverse().over(\"fruits\").alias(\"rev_a_by_fruits\"),\n...     pl.col(\"a\").sort_by(\"b\").over(\"fruits\").alias(\"sort_a_by_b_by_fruits\"),\n... )\nshape: (5, 8)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 fruits   \u2506 cars     \u2506 literal_stri \u2506 b   \u2506 sum_a_by_ca \u2506 sum_a_by_fr \u2506 rev_a_by_fr \u2506 sort_a_by_b \u2502\n\u2502 ---      \u2506 ---      \u2506 ng_fruits    \u2506 --- \u2506 rs          \u2506 uits        \u2506 uits        \u2506 _by_fruits  \u2502\n\u2502 str      \u2506 str      \u2506 ---          \u2506 i64 \u2506 ---         \u2506 ---         \u2506 ---         \u2506 ---         \u2502\n\u2502          \u2506          \u2506 str          \u2506     \u2506 i64         \u2506 i64         \u2506 i64         \u2506 i64         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 \"apple\"  \u2506 \"beetle\" \u2506 \"fruits\"     \u2506 11  \u2506 4           \u2506 7           \u2506 4           \u2506 4           \u2502\n\u2502 \"apple\"  \u2506 \"beetle\" \u2506 \"fruits\"     \u2506 11  \u2506 4           \u2506 7           \u2506 3           \u2506 3           \u2502\n\u2502 \"banana\" \u2506 \"beetle\" \u2506 \"fruits\"     \u2506 11  \u2506 4           \u2506 8           \u2506 5           \u2506 5           \u2502\n\u2502 \"banana\" \u2506 \"audi\"   \u2506 \"fruits\"     \u2506 11  \u2506 2           \u2506 8           \u2506 2           \u2506 2           \u2502\n\u2502 \"banana\" \u2506 \"beetle\" \u2506 \"fruits\"     \u2506 11  \u2506 4           \u2506 8           \u2506 1           \u2506 1           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## sql\n\n```python\n>>> # create a sql context\n>>> context = pl.sqlcontext()\n>>> # register a table\n>>> table = pl.scan_ipc(\"file.arrow\")\n>>> context.register(\"my_table\", table)\n>>> # the query we want to run\n>>> query = \"\"\"\n... select sum(v1) as sum_v1, min(v2) as min_v2 from my_table\n... where id1 = 'id016'\n... limit 10\n... \"\"\"\n>>> ## option 1\n>>> # run query to materialization\n>>> context.query(query)\n shape: (1, 2)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 sum_v1 \u2506 min_v2 \u2502\n \u2502 ---    \u2506 ---    \u2502\n \u2502 i64    \u2506 i64    \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 298268 \u2506 1      \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n>>> ## option 2\n>>> # don't materialize the query, but return as lazyframe\n>>> # and continue in python\n>>> lf = context.execute(query)\n>>> (lf.join(other_table)\n...      .group_by(\"foo\")\n...      .agg(\n...     pl.col(\"sum_v1\").count()\n... ).collect())\n```\n\nsql commands can also be ran directly from your terminal using the polars cli:\n\n```bash\n# run an inline sql query\n> polars -c \"select sum(v1) as sum_v1, min(v2) as min_v2 from read_ipc('file.arrow') where id1 = 'id016' limit 10\"\n\n# run interactively\n> polars\npolars cli v0.3.0\ntype .help for help.\n\n> select sum(v1) as sum_v1, min(v2) as min_v2 from read_ipc('file.arrow') where id1 = 'id016' limit 10;\n```\n\nrefer to the [polars cli repository](https://github.com/pola-rs/polars-cli) for more information.\n\n## performance \ud83d\ude80\ud83d\ude80\n\n### blazingly fast\n\npolars is very fast. in fact, it is one of the best performing solutions available.\nsee the results in [duckdb's db-benchmark](https://duckdblabs.github.io/db-benchmark/).\n\nin the [tpch benchmarks](https://www.pola.rs/benchmarks.html) polars is orders of magnitudes faster than pandas, dask, modin and vaex\non full queries (including io).\n\n### lightweight\n\npolars is also very lightweight. it comes with zero required dependencies, and this shows in the import times:\n\n- polars: 70ms\n- numpy: 104ms\n- pandas: 520ms\n\n### handles larger than ram data\n\nif you have data that does not fit into memory, polars lazy is able to process your query (or parts of your query) in a\nstreaming fashion, this drastically reduces memory requirements so you might be able to process your 250gb dataset on your\nlaptop. collect with `collect(streaming=true)` to run the query streaming. (this might be a little slower, but\nit is still very fast!)\n\n## setup\n\n### python\n\ninstall the latest polars version with:\n\n```sh\npip install polars\n```\n\nwe also have a conda package (`conda install -c conda-forge polars`), however pip is the preferred way to install polars.\n\ninstall polars with all optional dependencies.\n\n```sh\npip install 'polars[all]'\npip install 'polars[numpy,pandas,pyarrow]'  # install a subset of all optional dependencies\n```\n\nyou can also install the dependencies directly.\n\n| tag        | description                                                                  |\n| ---------- | ---------------------------------------------------------------------------- |\n| **all**    | install all optional dependencies (all of the following)                     |\n| pandas     | install with pandas for converting data to and from pandas dataframes/series |\n| numpy      | install with numpy for converting data to and from numpy arrays              |\n| pyarrow    | reading data formats using pyarrow                                           |\n| fsspec     | support for reading from remote file systems                                 |\n| connectorx | support for reading from sql databases                                       |\n| xlsx2csv   | support for reading from excel files                                         |\n| openpyxl   | support for reading from excel files with native types                       |\n| deltalake  | support for reading from delta lake tables                                   |\n| pyiceberg  | support for reading from apache iceberg tables                               |\n| timezone   | timezone support, only needed if are on python<3.9 or you are on windows     |\n\nreleases happen quite often (weekly / every few days) at the moment, so updating polars regularly to get the latest bugfixes / features might not be a bad idea.\n\n### rust\n\nyou can take latest release from `crates.io`, or if you want to use the latest features / performance improvements\npoint to the `main` branch of this repo.\n\n```toml\npolars = { git = \"https://github.com/pola-rs/polars\", rev = \"<optional git tag>\" }\n```\n\nrequired rust version `>=1.71`.\n\n## contributing\n\nwant to contribute? read our [contribution guideline](/contributing.md).\n\n## python: compile polars from source\n\nif you want a bleeding edge release or maximal performance you should compile **polars** from source.\n\nthis can be done by going through the following steps in sequence:\n\n1. install the latest [rust compiler](https://www.rust-lang.org/tools/install)\n2. install [maturin](https://maturin.rs/): `pip install maturin`\n3. `cd py-polars` and choose one of the following:\n   - `make build-release`, fastest binary, very long compile times\n   - `make build-opt`, fast binary with debug symbols, long compile times\n   - `make build-debug-opt`, medium-speed binary with debug assertions and symbols, medium compile times\n   - `make build`, slow binary with debug assertions and symbols, fast compile times\n\n   append `-native` (e.g. `make build-release-native`) to enable further optimizations specific to\n   your cpu. this produces a non-portable binary/wheel however.\n\nnote that the rust crate implementing the python bindings is called `py-polars` to distinguish from the wrapped\nrust crate `polars` itself. however, both the python package and the python module are named `polars`, so you\ncan `pip install polars` and `import polars`.\n\n## use custom rust function in python?\n\nextending polars with udfs compiled in rust is easy. we expose pyo3 extensions for `dataframe` and `series`\ndata structures. see more in https://github.com/pola-rs/pyo3-polars.\n\n## going big...\n\ndo you expect more than `2^32` ~4,2 billion rows? compile polars with the `bigidx` feature flag.\n\nor for python users install `pip install polars-u64-idx`.\n\ndon't use this unless you hit the row boundary as the default polars is faster and consumes less memory.\n\n## legacy\n\ndo you want polars to run on an old cpu (e.g. dating from before 2011), or on an `x86-64` build\nof python on apple silicon under rosetta? install `pip install polars-lts-cpu`. this version of\npolars is compiled without [avx](https://en.wikipedia.org/wiki/advanced_vector_extensions) target\nfeatures.\n\n## sponsors\n\n[<img src=\"https://www.jetbrains.com/company/brand/img/jetbrains_logo.png\" height=\"50\" />](https://www.jetbrains.com)\n\n",
  "docs_url": null,
  "keywords": "dataframe,arrow,out-of-core",
  "license": "",
  "name": "polars",
  "package_url": "https://pypi.org/project/polars/",
  "project_url": "https://pypi.org/project/polars/",
  "project_urls": {
    "Changelog": "https://github.com/pola-rs/polars/releases",
    "Documentation": "https://pola-rs.github.io/polars/py-polars/html/reference/index.html",
    "Homepage": "https://www.pola.rs/",
    "Repository": "https://github.com/pola-rs/polars"
  },
  "release_url": "https://pypi.org/project/polars/0.20.2/",
  "requires_dist": [
    "adbc_driver_sqlite ; extra == 'adbc'",
    "cloudpickle ; extra == 'cloudpickle'",
    "connectorx >=0.3.2 ; extra == 'connectorx'",
    "deltalake >=0.14.0 ; extra == 'deltalake'",
    "fsspec ; extra == 'fsspec'",
    "gevent ; extra == 'gevent'",
    "matplotlib ; extra == 'matplotlib'",
    "numpy >=1.16.0 ; extra == 'numpy'",
    "openpyxl >=3.0.0 ; extra == 'openpyxl'",
    "pyarrow >=7.0.0 ; extra == 'pandas'",
    "pandas ; extra == 'pandas'",
    "pyarrow >=7.0.0 ; extra == 'pyarrow'",
    "pydantic ; extra == 'pydantic'",
    "pyiceberg >=0.5.0 ; extra == 'pyiceberg'",
    "pyxlsb >=1.0 ; extra == 'pyxlsb'",
    "sqlalchemy ; extra == 'sqlalchemy'",
    "pandas ; extra == 'sqlalchemy'",
    "backports.zoneinfo ; python_version < '3.9' and extra == 'timezone'",
    "tzdata ; platform_system == 'Windows' and extra == 'timezone'",
    "xlsx2csv >=0.8.0 ; extra == 'xlsx2csv'",
    "xlsxwriter ; extra == 'xlsxwriter'",
    "polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,pydantic,pyiceberg,sqlalchemy,xlsxwriter,adbc,cloudpickle,gevent] ; extra == 'all'"
  ],
  "requires_python": ">=3.8",
  "summary": "blazingly fast dataframe library",
  "version": "0.20.2",
  "releases": [],
  "developers": [
    "ritchie46@gmail.com"
  ],
  "kwds": "polars_github_logo_rect_dark_name polars pandas svg dataframe",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_polars",
  "homepage": "",
  "release_count": 309,
  "dependency_ids": [
    "pypi_adbc_driver_sqlite",
    "pypi_backports.zoneinfo",
    "pypi_cloudpickle",
    "pypi_connectorx",
    "pypi_deltalake",
    "pypi_fsspec",
    "pypi_gevent",
    "pypi_matplotlib",
    "pypi_numpy",
    "pypi_openpyxl",
    "pypi_pandas",
    "pypi_polars",
    "pypi_pyarrow",
    "pypi_pydantic",
    "pypi_pyiceberg",
    "pypi_pyxlsb",
    "pypi_sqlalchemy",
    "pypi_tzdata",
    "pypi_xlsx2csv",
    "pypi_xlsxwriter"
  ]
}