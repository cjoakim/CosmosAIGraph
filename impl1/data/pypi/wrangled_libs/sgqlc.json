{
  "classifiers": [
    "development status :: 4 - beta",
    "environment :: console",
    "environment :: web environment",
    "intended audience :: developers",
    "license :: osi approved :: isc license (iscl)",
    "license :: other/proprietary license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: utilities"
  ],
  "description": "`sgqlc` - simple graphql client\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. image:: https://github.com/profusion/sgqlc/actions/workflows/ci.yml/badge.svg\n    :target: https://github.com/profusion/sgqlc/actions/workflows/ci.yml\n\n.. image:: https://coveralls.io/repos/github/profusion/sgqlc/badge.svg?branch=master\n    :target: https://coveralls.io/github/profusion/sgqlc?branch=master\n\nintroduction\n------------\n\nthis package offers an easy to use `graphql <http://graphql.org>`_\nclient. it's composed of the following modules:\n\n- ``sgqlc.types``: declare graphql in python, base to generate and\n  interpret queries. submodule ``sgqlc.types.datetime`` will\n  provide bindings for ``datetime`` and iso 8601, while\n  ``sgqlc.types.relay`` will expose ``node``, ``pageinfo`` and\n  ``connection``.\n\n- ``sgqlc.operation``: use declared types to generate and\n  interpret queries.\n\n- ``sgqlc.endpoint``: provide access to graphql endpoints, notably\n  ``sgqlc.endpoint.http`` provides ``httpendpoint`` using\n  ``urllib.request.urlopen()``.\n\n\nwhat's graphql?\n===============\n\nstraight from http://graphql.org:\n\n   **a query language for your api**\n\n   graphql is a query language for apis and a runtime for fulfilling\n   those queries with your existing data. graphql provides a complete\n   and understandable description of the data in your api, gives\n   clients the power to ask for exactly what they need and nothing\n   more, makes it easier to evolve apis over time, and enables\n   powerful developer tools.\n\nit was created by facebook based on their problems and solutions using\n`rest <https://en.wikipedia.org/wiki/representational_state_transfer>`_\nto develop applications to consume their apis. it was publicly\nannounced at\n`react.js conf 2015 <https://reactjs.org/blog/2015/02/20/introducing-relay-and-graphql.html>`_\nand started to gain traction since then. right now there are big names\ntransitioning from rest to graphql:\n`yelp <https://www.yelp.com/developers/graphql/guides/intro>`_\n`shopify <https://help.shopify.com/api/storefront-api/graphql>`_\nand `github <https://developer.github.com/v4/>`_, that did an\nexcellent\n`post <https://githubengineering.com/the-github-graphql-api/>`_\nto explain why they changed.\n\na short list of advantages over rest:\n\n- built-in schema, with documentation, strong typing and\n  introspection. there is no need to use\n  `swagger <https://swagger.io>`_ or any other external tools to play\n  with it. actually graphql provides a standard in-browser ide for\n  exploring graphql endpoints: https://github.com/graphql/graphiql;\n\n- only the fields that you want. the queries must explicitly select which\n  fields are required, and that's all you're getting. if more fields\n  are added to the type, they **won't break** the api, since the new\n  fields won't be returned to old clients, as they didn't ask for such\n  fields. this makes much easier to keep apis stable and **avoids\n  versioning**. standard rest usually delivers all available fields in\n  the results, and when new fields are to be included, a new api\n  version is added (reflected in the url path, or in an http header);\n\n- all data in one request. instead of navigating hypermedia-driven\n  restful services, like  discovering new ``\"_links\": {\"href\"...`` and\n  executing a new http request, with graphql you specify nested\n  queries and let the whole navigation be done by the server. this\n  reduces latency **a lot**;\n\n- the resulting json object matches the given query exactly; if\n  you requested ``{ parent { child { info } } }``, you're going to\n  receive the json object ``{\"parent\": {\"child\": {\"info\": value }}}``.\n\nfrom github's\n`migrating from rest to graphql <https://developer.github.com/v4/guides/migrating-from-rest/>`_\none can see these in real life::\n\n   $ curl -v https://api.github.com/orgs/github/members\n   [\n     {\n       \"login\": \"...\",\n       \"id\": 1234,\n       \"avatar_url\": \"https://avatars3.githubusercontent.com/u/...\",\n       \"gravatar_id\": \"\",\n       \"url\": \"https://api.github.com/users/...\",\n       \"html_url\": \"https://github.com/...\",\n       \"followers_url\": \"https://api.github.com/users/.../followers\",\n       \"following_url\": \"https://api.github.com/users/.../following{/other_user}\",\n       \"gists_url\": \"https://api.github.com/users/.../gists{/gist_id}\",\n       \"starred_url\": \"https://api.github.com/users/.../starred{/owner}{/repo}\",\n       \"subscriptions_url\": \"https://api.github.com/users/.../subscriptions\",\n       \"organizations_url\": \"https://api.github.com/users/.../orgs\",\n       \"repos_url\": \"https://api.github.com/users/.../repos\",\n       \"events_url\": \"https://api.github.com/users/.../events{/privacy}\",\n       \"received_events_url\": \"https://api.github.com/users/.../received_events\",\n       \"type\": \"user\",\n       \"site_admin\": true\n     },\n     ...\n   ]\n\nbrings the whole set of member information, however you just want name\nand avatar url::\n\n   query {\n     organization(login:\"github\") { # select the organization\n       members(first: 100) {        # then select the organization's members\n         edges {  # edges + node: convention for paginated queries\n           node {\n             name\n             avatarurl\n           }\n         }\n       }\n     }\n   }\n\nlikewise, instead of 4 http requests::\n\n   curl -v https://api.github.com/repos/profusion/sgqlc/pulls/9\n   curl -v https://api.github.com/repos/profusion/sgqlc/pulls/9/commits\n   curl -v https://api.github.com/repos/profusion/sgqlc/issues/9/comments\n   curl -v https://api.github.com/repos/profusion/sgqlc/pulls/9/reviews\n\na single graphql query brings all the needed information, and just the\nneeded information::\n\n   query {\n     repository(owner: \"profusion\", name: \"sgqlc\") {\n       pullrequest(number: 9) {\n         commits(first: 10) { # commits of profusion/sgqlc pr #9\n           edges {\n             node { commit { oid, message } }\n           }\n         }\n         comments(first: 10) { # comments of profusion/sgqlc pr #9\n           edges {\n             node {\n               body\n               author { login }\n             }\n           }\n         }\n         reviews(first: 10) { # reviews of profusion/sgqlc/ pr #9\n           edges { node { state } }\n         }\n       }\n     }\n   }\n\n\nmotivation to create `sgqlc`\n============================\n\nas seen above, writing graphql queries is very easy, and it is equally easy to\ninterpret the results. so **what was the rationale to create sgqlc?**\n\n- graphql has its domain-specific language (dsl), and mixing two\n  languages is always painful, as seen with sql + python, html +\n  python... being able to write just python in python is much\n  better. not to say that graphql naming convention is closer to\n  java/javascript, using ``anameformat`` instead of python's\n  ``a_name_format``.\n\n- navigating dict-of-stuff is a bit painful:\n  ``d[\"repository\"][\"pullrequest\"][\"commits\"][\"edges\"][\"node\"]``,\n  since these are valid python identifiers, we better write:\n  ``repository.pull_request.commits.edges.node``.\n\n- handling new ``scalar`` types. graphql allows one to define new scalar\n  types, such as ``date``, ``time`` and ``datetime``. often these are\n  serialized as iso 8601 strings and the user must parse them in their\n  application. we offer ``sgqlc.types.datetime`` to automatically\n  generate ``datetime.date``, ``datetime.time`` and\n  ``datetime.datetime``.\n\n- make it easy to write dynamic queries, including nested. as seen,\n  graphql can be used to fetch lots of information in one go; however\n  if what you need (arguments and fields) changes based on some\n  variable, such as user input or cached data, then you need to\n  concatenate strings to compose the final query. this can be error\n  prone and servers may block you due to invalid queries. some tools\n  \"solve\" this by parsing the query locally before sending it to\n  server. however usually the indentation is screwed and reviewing it\n  is painful. we change that approach: use\n  ``sgqlc.operation.operation`` and it will always generate valid\n  queries, which can be printed out and properly indented. bonus point\n  is that it can be used to later interpret the json results into native\n  python objects.\n\n- usability improvements whenever needed. for instance\n  `relay <https://facebook.github.io/relay/>`_ published their\n  `cursor connections specification <https://facebook.github.io/relay/graphql/connections.htm>`_\n  and its widely used. to load more data, you need to extend the\n  previous data with newly fetched information, updating not only the\n  nodes and edges, but also page information. this is done\n  automatically by ``sgqlc.types.relay.connection``.\n\nit also helps with code-generation, ``sgqlc-codegen`` can generate both\nthe classes matching a graphql schema or functions to return\n``sgqlc.operation.operation`` based on executable documents\ngraphql domain specific language (dsl).\n\n\ninstallation\n------------\n\nautomatic::\n\n    pip install sgqlc\n\nfrom source using ``pip``::\n\n    pip install .\n\n\nusage\n-----\n\nto reach a graphql endpoint using synchronous `httpendpoint` with a\nhand-written query (see more at ``examples/basic/01_http_endpoint.py``):\n\n.. code-block:: python\n\n   from sgqlc.endpoint.http import httpendpoint\n\n   url = 'http://server.com/graphql'\n   headers = {'authorization': 'bearer token'}\n\n   query = 'query { ... }'\n   variables = {'varname': 'value'}\n\n   endpoint = httpendpoint(url, headers)\n   data = endpoint(query, variables)\n\n\nhowever, writing graphql queries and later interpreting the results\nmay be cumbersome. that's solved by our ``sgqlc.types``, which is\nusually paired with ``sgqlc.operation`` to generate queries and then\ninterpret results (see more at ``examples/basic/02_schema_types.py``). the\nexample below matches a subset of\n`github api v4 <https://developer.github.com/v4/query/>`_.\nin graphql syntax it would be::\n\n   query {\n     repository(owner: \"profusion\", name: \"sgqlc\") {\n       issues(first: 100) {\n         nodes {\n           number\n           title\n         }\n         pageinfo {\n           hasnextpage\n           endcursor\n         }\n       }\n     }\n   }\n\nthe output json object is:\n\n.. code-block:: json\n\n   {\n     \"data\": {\n       \"repository\": {\n         \"issues\": {\n           \"nodes\": [\n             {\"number\": 1, \"title\": \"...\"},\n             {\"number\": 2, \"title\": \"...\"}\n           ]\n         },\n         \"pageinfo\": {\n            \"hasnextpage\": false,\n            \"endcursor\": \"...\"\n         }\n       }\n     }\n   }\n\n.. code-block:: python\n\n   from sgqlc.endpoint.http import httpendpoint\n   from sgqlc.types import type, field, list_of\n   from sgqlc.types.relay import connection, connection_args\n   from sgqlc.operation import operation\n\n   # declare types matching github graphql schema:\n   class issue(type):\n       number = int\n       title = str\n\n   class issueconnection(connection):  # connection provides page_info!\n       nodes = list_of(issue)\n\n   class repository(type):\n       issues = field(issueconnection, args=connection_args())\n\n   class query(type):  # graphql's root\n       repository = field(repository, args={'owner': str, 'name': str})\n\n   # generate an operation on query, selecting fields:\n   op = operation(query)\n   # select a field, here with selection arguments, then another field:\n   issues = op.repository(owner=owner, name=name).issues(first=100)\n   # select sub-fields explicitly: { nodes { number title } }\n   issues.nodes.number()\n   issues.nodes.title()\n   # here uses __fields__() to select by name (*args)\n   issues.page_info.__fields__('has_next_page')\n   # here uses __fields__() to select by name (**kwargs)\n   issues.page_info.__fields__(end_cursor=true)\n\n   # you can print the resulting graphql\n   print(op)\n\n   # call the endpoint:\n   data = endpoint(op)\n\n   # interpret results into native objects\n   repo = (op + data).repository\n   for issue in repo.issues.nodes:\n       print(issue)\n\n\nwhy double-underscore and overloaded arithmetic methods?\n========================================================\n\nsince we don't want to clobber graphql fields, we cannot provide\nnicely named methods. therefore we use overloaded methods such as\n``__iadd__``, ``__add__``, ``__bytes__`` (compressed graphql\nrepresentation) and ``__str__`` (indented graphql representation).\n\nto select fields by name, use ``__fields__(*names, **names_and_args)``.\nthis helps with repetitive situations and can be used to \"include all\nfields\", or \"include all except...\":\n\n.. code-block:: python\n\n  # just 'a' and 'b'\n  type_selection.__fields__('a', 'b')\n  type_selection.__fields__(a=true, b=true) # equivalent\n\n  # a(arg1: value1), b(arg2: value2):\n  type_selection.__fields__(\n      a={'arg1': value1},\n      b={'arg2': value2})\n\n  # selects all possible fields\n  type_selection.__fields__()\n\n  # all but 'a' and 'b'\n  type_selection.__fields__(__exclude__=('a', 'b'))\n  type_selection.__fields__(a=false, b=false)\n\n\ncode generator\n--------------\n\nmanually converting an existing graphql schema to ``sgqlc.types``\nsubclasses is boring and error prone. to aid such task we offer a code\ngenerator that outputs a python module straight from json of an\nintrospection call:\n\n.. code-block:: console\n\n   user@host$ python3 -m sgqlc.introspection \\\n        --exclude-deprecated \\\n        --exclude-description \\\n        -h \"authorization: bearer ${gh_token}\" \\\n        https://api.github.com/graphql \\\n        github_schema.json\n   user@host$ sgqlc-codegen schema github_schema.json github_schema.py\n\nthis generates ``github_schema`` that provides the\n``sgqlc.types.schema`` instance of the same name ``github_schema``.\nthen it's a matter of using that in your python code, as in the example below\nfrom ``examples/github/github_agile_dashboard.py``:\n\n.. code-block:: python\n\n   from sgqlc.operation import operation\n   from github_schema import github_schema as schema\n\n   op = operation(schema.query)  # note 'schema.'\n\n   # -- code below follows as the original usage example:\n\n   # select a field, here with selection arguments, then another field:\n   issues = op.repository(owner=owner, name=name).issues(first=100)\n   # select sub-fields explicitly: { nodes { number title } }\n   issues.nodes.number()\n   issues.nodes.title()\n   # here uses __fields__() to select by name (*args)\n   issues.page_info.__fields__('has_next_page')\n   # here uses __fields__() to select by name (**kwargs)\n   issues.page_info.__fields__(end_cursor=true)\n\n   # you can print the resulting graphql\n   print(op)\n\n   # call the endpoint:\n   data = endpoint(op)\n\n   # interpret results into native objects\n   repo = (op + data).repository\n   for issue in repo.issues.nodes:\n       print(issue)\n\n\nyou can also generate these operations given a graphql domain specific\nlanguage (dsl) operation:\n\n.. code-block::\n\n   # sample_operations.gql\n\n   query listissues($owner: string!, $name: string!) {\n       repository(owner: $owner, name: $name) {\n           issues(first: 100) {\n               nodes {\n                   number\n                   title\n               }\n               pageinfo {\n                   hasnextpage\n                   endcursor\n               }\n           }\n       }\n   }\n\n.. code-block:: console\n\n   user@host$ sgqlc-codegen operation \\\n      --schema github_schema.json \\\n      github_schema \\\n      sample_operations.py \\\n      sample_operations.gql\n\nthis generates ``sample_operations.py`` that provides the ``operation``.\nthen it's a matter of using that in your python code, as in the example below\nfrom ``examples/github/github-agile-dashboard.py``:\n\n.. code-block:: python\n\n   from sample_operations import operations\n\n   op = operations.query.list_issues\n\n   # you can print the resulting graphql\n   print(op)\n\n   # call the endpoint:\n   data = endpoint(op, {'owner': owner, 'name': name})\n\n   # interpret results into native objects\n   repo = (op + data).repository\n   for issue in repo.issues.nodes:\n       print(issue)\n\nauthors\n-------\n\n- `gustavo sverzut barbieri <barbieri@profusion.mobi>`_\n\n\nlicense\n-------\n`sgqlc` is licensed under the `isc <https://opensource.org/licenses/isc>`_.\n\n\ngetting started developing\n--------------------------\n\nyou need to use `poetry <https://python-poetry.org/docs/#installation>`_.\n\n::\n\n    poetry install --all-extras --with dev\n    poetry shell\n\ninstall the `pre-commit <https://pre-commit.com/index.html#install>`_:\n\n::\n\n   pre-commit install -f\n\nrun the tests (one of the below):\n\n::\n\n    pre-commit run -a            # run all tests: flake8, pytest, ...\n    pre-commit run -a flake8     # run only flake8\n    pre-commit run -a tests      # run only pytest (unit tests)\n\nkeep 100% coverage. you can look at the coverage report at\n``cover/index.html``.  to do that, prefer\n`doctest <https://docs.python.org/3.7/library/doctest.html>`_\nso it serves as\nboth documentation and test. however we use\n`pytest <https://docs.pytest.org/>`_ to write explicit tests that would be\nhard to express using ``doctest``.\n\nbuild and review the generated sphinx documentation, and validate if your\nchanges look right:\n\n::\n\n    sphinx-build doc/source doc/build\n    open doc/build/html/index.html\n\n\nto integrate changes from another branch, please **rebase** instead of\ncreating merge commits (\n`read more <https://git-scm.com/book/en/v2/git-branching-rebasing>`_).\n\npublic schemas\n--------------\n\nthe following repositories provides public schemas generated using ``sgqlc-codegen``:\n\n- `mogost/sgqlc-schemas <https://github.com/mogost/sgqlc-schemas>`_ github, monday.com\n",
  "docs_url": null,
  "keywords": "graphql,client,http,endpoint",
  "license": "iscl",
  "name": "sgqlc",
  "package_url": "https://pypi.org/project/sgqlc/",
  "project_url": "https://pypi.org/project/sgqlc/",
  "project_urls": {
    "Documentation": "https://sgqlc.readthedocs.io/",
    "Homepage": "http://github.com/profusion/sgqlc",
    "Repository": "http://github.com/profusion/sgqlc"
  },
  "release_url": "https://pypi.org/project/sgqlc/16.3/",
  "requires_dist": [
    "graphql-core (>=3.1.7,<4.0.0)",
    "websocket-client ; extra == \"websocket\"",
    "requests ; extra == \"requests\""
  ],
  "requires_python": ">=3.7,<4.0",
  "summary": "simple graphql client",
  "version": "16.3",
  "releases": [],
  "developers": [
    "barbieri@profusion.mobi",
    "gustavo_sverzut_barbieri"
  ],
  "kwds": "graphql graphiql sgqlc gql nodes",
  "license_kwds": "iscl",
  "libtype": "pypi",
  "id": "pypi_sgqlc",
  "homepage": "http://github.com/profusion/sgqlc",
  "release_count": 24,
  "dependency_ids": [
    "pypi_graphql_core",
    "pypi_requests",
    "pypi_websocket_client"
  ]
}