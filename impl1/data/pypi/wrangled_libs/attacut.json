{
  "classifiers": [
    "license :: osi approved :: mit license",
    "natural language :: thai",
    "operating system :: os independent",
    "programming language :: python :: 3"
  ],
  "description": "# attacut: fast and reasonably accurate word tokenizer for thai\n\n[![build status](https://travis-ci.org/pythainlp/attacut.svg?branch=master)](https://travis-ci.org/pythainlp/attacut)\n[![build status](https://ci.appveyor.com/api/projects/status/ittfnb2pyg95kpxk/branch/master?svg=true)](https://ci.appveyor.com/project/wannaphongcom/attacut/branch/master)\n[![](https://img.shields.io/badge/-presentation-informational)](https://drive.google.com/file/d/16aunzv1hxvmergryfbf4jpco1qrqyhhe/view?usp=sharing)\n[![](http://img.shields.io/badge/arxiv-1911.07056-yellow.svg?style=flat)](https://arxiv.org/abs/1911.07056)\n\n## how does attacut look like?\n\n<div align=\"center\">\n    <img src=\"https://i.imgur.com/8ymq7ib.png\" width=\"700px\"/>\n    <br/>\n    <b>tl;dr:</b> \n3-layer dilated cnn on syllable and character features. it\u2019s <b>6x faster</b> than deepcut (sota) while its wl-f1 on best is <b>91%</b>, only 2% lower.\n</div>\n\n## installation\n\n```\n$ pip install attacut\n```\n\n**remarks:** windows users need to install **pytorch** before the command above.\nplease consult [pytorch.org](https://pytorch.org) for more details.\n\n## usage\n\n### command-line interface\n\n```\n$ attacut-cli -h\nattacut: fast and reasonably accurate word tokenizer for thai\n\nusage:\n  attacut-cli <src> [--dest=<dest>] [--model=<model>]\n  attacut-cli [-v | --version]\n  attacut-cli [-h | --help]\n\narguments:\n  <src>             path to input text file to be tokenized\n\noptions:\n  -h --help         show this screen.\n  --model=<model>   model to be used [default: attacut-sc].\n  --dest=<dest>     if not specified, it'll be <src>-tokenized-by-<model>.txt\n  -v --version      show version\n```\n\n### high-level api \n```\nfrom attacut import tokenize, tokenizer\n\n# tokenize `txt` using our best model `attacut-sc`\nwords = tokenize(txt)\n\n# alternatively, an attacut tokenizer might be instantiated directly, allowing\n# one to specify whether to use `attacut-sc` or `attacut-c`.\natta = tokenizer(model=\"attacut-sc\")\nwords = atta.tokenize(txt)\n```\n\n## benchmark results\n\nbelows are brief summaries. more details can be found on [our benchmarking page](https://pythainlp.github.io/attacut/benchmark.html).\n\n\n### tokenization quality\n![](https://pythainlp.github.io/attacut/_images/quality-benchmark-in-of-domain.png)\n\n### speed\n![](https://pythainlp.github.io/attacut/_images/speed-benchmark-ec2.png)\n\n\n## retraining on custom dataset\nplease refer to [our retraining page](https://pythainlp.github.io/attacut/)\n\n## related resources\n- [tokenization visualization][tovis]\n- [thai tokenizer dockers][docker]\n\n## acknowledgements\nthis repository was initially done by [pattarawat chormai][pat], while interning at [dr. attapol thamrongrattanarit's nlp lab][ate], chulalongkorn university, bangkok, thailand.\nmany people have involed in this project. complete list of names can be found on [acknowledgement](https://pythainlp.github.io/attacut/acknowledgement.html).\n\n\n[pat]: http://pat.chormai.org\n[ate]: https://attapol.github.io/lab.html\n[noom]: https://github.com/ekkalak-t\n[can]: https://github.com/c4n\n[ake]: https://github.com/ekapolc\n[tovis]: https://pythainlp.github.io/tokenization-benchmark-visualization/\n[docker]: https://github.com/pythainlp/docker-thai-tokenizers\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "attacut",
  "package_url": "https://pypi.org/project/attacut/",
  "project_url": "https://pypi.org/project/attacut/",
  "project_urls": {
    "Homepage": "https://github.com/PyThaiNLP/attacut"
  },
  "release_url": "https://pypi.org/project/attacut/1.0.6/",
  "requires_dist": [
    "docopt (>=0.6.2)",
    "fire (>=0.1.3)",
    "nptyping (>=0.2.0)",
    "numpy (>=1.17.0)",
    "pyyaml (>=5.1.2)",
    "six (>=1.12.0)",
    "ssg (>=0.0.4)",
    "torch (>=1.2.0)"
  ],
  "requires_python": "",
  "summary": "fast and reasonably accurate word tokenizer for thai",
  "version": "1.0.6",
  "releases": [],
  "developers": [
    "foomail@foo.com",
    "pattarawat_chormai_et_al"
  ],
  "kwds": "tokenizer attacut tokenizers tokenize badge",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_attacut",
  "homepage": "https://github.com/pythainlp/attacut",
  "release_count": 17,
  "dependency_ids": [
    "pypi_docopt",
    "pypi_fire",
    "pypi_nptyping",
    "pypi_numpy",
    "pypi_pyyaml",
    "pypi_six",
    "pypi_ssg",
    "pypi_torch"
  ]
}