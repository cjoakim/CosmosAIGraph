{
  "classifiers": [
    "intended audience :: science/research",
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering :: artificial intelligence"
  ],
  "description": "# jaxopt\n\n[**installation**](#installation)\n| [**documentation**](https://jaxopt.github.io)\n| [**examples**](https://github.com/google/jaxopt/tree/main/examples)\n| [**cite us**](#citeus)\n\nhardware accelerated, batchable and differentiable optimizers in\n[jax](https://github.com/google/jax).\n\n- **hardware accelerated:** our implementations run on gpu and tpu, in addition\n  to cpu.\n- **batchable:** multiple instances of the same optimization problem can be\n  automatically vectorized using jax's vmap.\n- **differentiable:** optimization problem solutions can be differentiated with\n  respect to their inputs either implicitly or via autodiff of unrolled\n  algorithm iterations.\n\n## installation<a id=\"installation\"></a>\n\nto install the latest release of jaxopt, use the following command:\n\n```bash\n$ pip install jaxopt\n```\n\nto install the **development** version, use the following command instead:\n\n```bash\n$ pip install git+https://github.com/google/jaxopt\n```\n\nalternatively, it can be installed from sources with the following command:\n\n```bash\n$ python setup.py install\n```\n\n## cite us<a id=\"citeus\"></a>\n\nour implicit differentiation framework is described in this\n[paper](https://arxiv.org/abs/2105.15183). to cite it:\n\n```\n@article{jaxopt_implicit_diff,\n  title={efficient and modular implicit differentiation},\n  author={blondel, mathieu and berthet, quentin and cuturi, marco and frostig, roy \n    and hoyer, stephan and llinares-l{\\'o}pez, felipe and pedregosa, fabian \n    and vert, jean-philippe},\n  journal={arxiv preprint arxiv:2105.15183},\n  year={2021}\n}\n```\n\n## disclaimer\n\njaxopt is an open source project maintained by a dedicated team in google research, but is not an official google product.\n",
  "docs_url": null,
  "keywords": "optimization,root finding,implicit differentiation,jax",
  "license": "apache 2.0",
  "name": "jaxopt",
  "package_url": "https://pypi.org/project/jaxopt/",
  "project_url": "https://pypi.org/project/jaxopt/",
  "project_urls": {
    "Homepage": "https://github.com/google/jaxopt"
  },
  "release_url": "https://pypi.org/project/jaxopt/0.8.2/",
  "requires_dist": [
    "jax >=0.2.18",
    "jaxlib >=0.1.69",
    "numpy >=1.18.4",
    "scipy >=1.0.0"
  ],
  "requires_python": "",
  "summary": "hardware accelerated, batchable and differentiable optimizers in jax.",
  "version": "0.8.2",
  "releases": [],
  "developers": [
    "google_llc",
    "no-reply@google.com"
  ],
  "kwds": "jaxopt_implicit_diff jaxopt jax optimizers implementations",
  "license_kwds": "apache 2.0",
  "libtype": "pypi",
  "id": "pypi_jaxopt",
  "homepage": "https://github.com/google/jaxopt",
  "release_count": 16,
  "dependency_ids": [
    "pypi_jax",
    "pypi_jaxlib",
    "pypi_numpy",
    "pypi_scipy"
  ]
}