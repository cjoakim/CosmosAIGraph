{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "# linkify-it-py\n\n[![ci](https://github.com/tsutsu3/linkify-it-py/workflows/ci/badge.svg?branch=main)](https://github.com/tsutsu3/linkify-it-py/actions)\n[![pypi](https://img.shields.io/pypi/v/linkify-it-py)](https://pypi.org/project/linkify-it-py/)\n[![anaconda-server badge](https://anaconda.org/conda-forge/linkify-it-py/badges/version.svg)](https://anaconda.org/conda-forge/linkify-it-py)\n[![documentation status](https://readthedocs.org/projects/linkify-it-py/badge/?version=latest)](https://linkify-it-py.readthedocs.io/en/latest/?badge=latest)\n[![codecov](https://codecov.io/gh/tsutsu3/linkify-it-py/branch/main/graph/badge.svg)](https://codecov.io/gh/tsutsu3/linkify-it-py)\n[![maintainability](https://api.codeclimate.com/v1/badges/6341fd3ec5f05fde392f/maintainability)](https://codeclimate.com/github/tsutsu3/linkify-it-py/maintainability)\n\nthis is python port of [linkify-it](https://github.com/markdown-it/linkify-it).\n\n> links recognition library with full unicode support.\n> focused on high quality link patterns detection in plain text.\n\n__[javascript demo](http://markdown-it.github.io/linkify-it/)__\n\nwhy it's awesome:\n\n- full unicode support, _with astral characters_!\n- international domains support.\n- allows rules extension & custom normalizers.\n\n\n## install\n\n```bash\npip install linkify-it-py\n```\n\nor\n\n```bash\nconda install -c conda-forge linkify-it-py\n```\n\n## usage examples\n\n### example 1. simple use\n\n```python\nfrom linkify_it import linkifyit\n\n\nlinkify = linkifyit()\n\nprint(linkify.test(\"site github.com!\"))\n# => true\n\nprint(linkify.match(\"site github.com!\"))\n# => [linkify_it.main.match({\n#         'schema': '',\n#         'index': 5,\n#         'last_index': 15,\n#         'raw': 'github.com',\n#         'text': 'github.com',\n#         'url': 'http://github.com'\n#     }]\n```\n\n### example 2. with options\n\n```python\nfrom linkify_it import linkifyit\nfrom linkify_it.tlds import tlds\n\n\n# reload full tlds list & add unofficial `.onion` domain.\nlinkify = (\n    linkifyit()\n    .tlds(tlds)               # reload with full tlds list\n    .tlds(\"onion\", true)      # add unofficial `.onion` domain\n    .add(\"git:\", \"http:\")     # add `git:` protocol as \"alias\"\n    .add(\"ftp:\", none)        # disable `ftp:` protocol\n    .set({\"fuzzy_ip\": true})  # enable ips in fuzzy links (without schema)\n)\nprint(linkify.test(\"site tamanegi.onion!\"))\n# => true\n\nprint(linkify.match(\"site tamanegi.onion!\"))\n# => [linkify_it.main.match({\n#         'schema': '',\n#         'index': 5,\n#         'last_index': 19,\n#         'raw': 'tamanegi.onion',\n#         'text': 'tamanegi.onion',\n#         'url': 'http://tamanegi.onion'\n#     }]\n```\n\n### example 3. add twitter mentions handler\n\n```python\nfrom linkify_it import linkifyit\n\n\nlinkify = linkifyit()\n\ndef validate(obj, text, pos):\n    tail = text[pos:]\n\n    if not obj.re.get(\"twitter\"):\n        obj.re[\"twitter\"] = re.compile(\n            \"^([a-za-z0-9_]){1,15}(?!_)(?=$|\" + obj.re[\"src_zpcc\"] + \")\"\n        )\n    if obj.re[\"twitter\"].search(tail):\n        if pos > 2 and tail[pos - 2] == \"@\":\n            return false\n        return len(obj.re[\"twitter\"].search(tail).group())\n    return 0\n\ndef normalize(obj, match):\n    match.url = \"https://twitter.com/\" + re.sub(r\"^@\", \"\", match.url)\n\nlinkify.add(\"@\", {\"validate\": validate, \"normalize\": normalize})\n```\n\n\n## api\n\n[api documentation](https://linkify-it-py.readthedocs.io/en/latest/)\n\n### linkifyit(schemas, options)\n\ncreates new linkifier instance with optional additional schemas.\n\nby default understands:\n\n- `http(s)://...` , `ftp://...`, `mailto:...` & `//...` links\n- \"fuzzy\" links and emails (google.com, foo@bar.com).\n\n`schemas` is an dict, where each key/value describes protocol/rule:\n\n- __key__ - link prefix (usually, protocol name with `:` at the end, `skype:`\n  for example). `linkify-it-py` makes sure that prefix is not preceded with\n  alphanumeric char.\n- __value__ - rule to check tail after link prefix\n  - _str_\n    - just alias to existing rule\n  - _dict_\n    - _validate_ - either a `re.pattern` (start with `^`, and don't include the\n      link prefix itself), or a validator `function` which, given arguments\n      _self_, _text_ and _pos_, returns the length of a match in _text_\n      starting at index _pos_.  _pos_ is the index right after the link prefix.\n      _self_ can be used to access the linkify object to cache data.\n    - _normalize_ - optional function to normalize text & url of matched result\n      (for example, for twitter mentions).\n\n`options`:\n\n- __fuzzy_link__ - recognize url-s without `http(s)://` head. default `true`.\n- __fuzzy_ip__ - allow ips in fuzzy links above. can conflict with some texts\n  like version numbers. default `false`.\n- __fuzzy_email__ - recognize emails without `mailto:` prefix. default `true`.\n- __---__ - set `true` to terminate link with `---` (if it's considered as long dash).\n\n\n### .test(text)\n\nsearches linkifiable pattern and returns `true` on success or `false` on fail.\n\n\n### .pretest(text)\n\nquick check if link may be can exist. can be used to optimize more expensive\n`.test()` calls. return `false` if link can not be found, `true` - if `.test()`\ncall needed to know exactly.\n\n\n### .test_schema_at(text, name, position)\n\nsimilar to `.test()` but checks only specific protocol tail exactly at given\nposition. returns length of found pattern (0 on fail).\n\n\n### .match(text)\n\nreturns `list` of found link matches or null if nothing found.\n\neach match has:\n\n- __schema__ - link schema, can be empty for fuzzy links, or `//` for\n  protocol-neutral links.\n- __index__ - offset of matched text\n- __last_index__ - index of next char after mathch end\n- __raw__ - matched text\n- __text__ - normalized text\n- __url__ - link, generated from matched text\n\n### .matchatstart(text)\n\nchecks if a match exists at the start of the string. returns `match`\n(see docs for `match(text)`) or null if no url is at the start.\ndoesn't work with fuzzy links.\n\n### .tlds(list_tlds, keep_old=false)\n\nload (or merge) new tlds list. those are needed for fuzzy links (without schema)\nto avoid false positives. by default:\n\n- 2-letter root zones are ok.\n- biz|com|edu|gov|net|org|pro|web|xxx|aero|asia|coop|info|museum|name|shop|\u0440\u0444 are ok.\n- encoded (`xn--...`) root zones are ok.\n\nif that's not enough, you can reload defaults with more detailed zones list.\n\n### .add(key, value)\n\nadd a new schema to the schemas object. as described in the constructor\ndefinition, `key` is a link prefix (`skype:`, for example), and `value`\nis a `str` to alias to another schema, or an `dict` with `validate` and\noptionally `normalize` definitions.  to disable an existing rule, use\n`.add(key, none)`.\n\n\n### .set(options)\n\noverride default options. missed properties will not be changed.\n\n\n## license\n\n[mit](https://github.com/tsutsu3/linkify-it-py/blob/master/license)\n",
  "docs_url": null,
  "keywords": "linkify,linkifier,autolink,autolinker",
  "license": "mit",
  "name": "linkify-it-py",
  "package_url": "https://pypi.org/project/linkify-it-py/",
  "project_url": "https://pypi.org/project/linkify-it-py/",
  "project_urls": {
    "Homepage": "https://github.com/tsutsu3/linkify-it-py"
  },
  "release_url": "https://pypi.org/project/linkify-it-py/2.0.2/",
  "requires_dist": [
    "uc-micro-py",
    "pytest ; extra == 'benchmark'",
    "pytest-benchmark ; extra == 'benchmark'",
    "pre-commit ; extra == 'dev'",
    "isort ; extra == 'dev'",
    "flake8 ; extra == 'dev'",
    "black ; extra == 'dev'",
    "pyproject-flake8 ; extra == 'dev'",
    "sphinx ; extra == 'doc'",
    "sphinx-book-theme ; extra == 'doc'",
    "myst-parser ; extra == 'doc'",
    "pytest ; extra == 'test'",
    "coverage ; extra == 'test'",
    "pytest-cov ; extra == 'test'"
  ],
  "requires_python": ">=3.7",
  "summary": "links recognition library with full unicode support.",
  "version": "2.0.2",
  "releases": [],
  "developers": [
    "tsutsu3"
  ],
  "kwds": "linkifyit linkify linkify_it autolinker autolink",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_linkify_it_py",
  "homepage": "",
  "release_count": 8,
  "dependency_ids": [
    "pypi_black",
    "pypi_coverage",
    "pypi_flake8",
    "pypi_isort",
    "pypi_myst_parser",
    "pypi_pre_commit",
    "pypi_pyproject_flake8",
    "pypi_pytest",
    "pypi_pytest_benchmark",
    "pypi_pytest_cov",
    "pypi_sphinx",
    "pypi_sphinx_book_theme",
    "pypi_uc_micro_py"
  ]
}