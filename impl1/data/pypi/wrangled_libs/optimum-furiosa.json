{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "intended audience :: education",
    "intended audience :: science/research",
    "license :: osi approved :: apache software license",
    "operating system :: os independent",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering :: artificial intelligence"
  ],
  "description": "[![test](https://github.com/huggingface/optimum-furiosa/actions/workflows/test.yml/badge.svg)](https://github.com/huggingface/optimum-furiosa/actions/workflows/test.yml)\n\n\n# optimum-furiosa\naccelerated inference of \ud83e\udd17 models using furiosaai npu chips.\n\n## furiosa sdk setup\na furiosa sdk environment needs to be enabled to use this library. please refer to furiosa's [installation](https://furiosa-ai.github.io/docs/latest/en/software/installation.html) guide.\n\n## install\nto install the latest release of this package:\n\n```bash\npip install optimum[furiosa]\n```\n\noptimum furiosa is a fast-moving project, and you may want to install from source.\n\n`pip install git+https://github.com/huggingface/optimum-furiosa.git`\n\n### installing in developer mode\n\nif you are working on the `optimum-furiosa` code then you should use an editable install\nby cloning and installing `optimum` and `optimum-furiosa`:\n\n```\ngit clone https://github.com/huggingface/optimum\ngit clone https://github.com/huggingface/optimum-furiosa\npip install -e optimum -e optimum-furiosa\n```\n\nnow whenever you change the code, you'll be able to run with those changes instantly.\n\n\n## how to use it?\nto load a model and run inference with furiosa npu, you can just replace your `automodelforxxx` class with the corresponding `furiosaaimodelforxxx` class. \n\n```diff\nimport requests\nfrom pil import image\n\n- from transformers import automodelforimageclassification\n+ from optimum.furiosa import furiosaaimodelforimageclassification\nfrom transformers import autofeatureextractor, pipeline\n\nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\nimage = image.open(requests.get(url, stream=true).raw)\n\nmodel_id = \"microsoft/resnet-50\"\n- model = automodelforimageclassification.from_pretrained(model_id)\n+ model = furiosaaimodelforimageclassification.from_pretrained(model_id, export=true, input_shape_dict={\"pixel_values\": [1, 3, 224, 224]}, output_shape_dict={\"logits\": [1, 1000]},)\nfeature_extractor = autofeatureextractor.from_pretrained(model_id)\ncls_pipe = pipeline(\"image-classification\", model=model, feature_extractor=feature_extractor)\noutputs = cls_pipe(image)\n```\n\nif you find any issue while using those, please open an issue or a pull request.\n",
  "docs_url": null,
  "keywords": "transformers,quantization,pruning,knowledge distillation,optimization,training",
  "license": "apache",
  "name": "optimum-furiosa",
  "package_url": "https://pypi.org/project/optimum-furiosa/",
  "project_url": "https://pypi.org/project/optimum-furiosa/",
  "project_urls": {
    "Homepage": "https://huggingface.co/hardware"
  },
  "release_url": "https://pypi.org/project/optimum-furiosa/0.1.0/",
  "requires_dist": [
    "optimum (>=1.8.0)",
    "transformers (>=4.20.0)",
    "datasets (>=1.4.0)",
    "furiosa-optimizer",
    "furiosa-quantizer (==0.9.0)",
    "furiosa-quantizer-impl (==0.9.1)",
    "furiosa-sdk",
    "onnx (>=1.12.0)",
    "sentencepiece",
    "scipy",
    "black (~=23.1) ; extra == 'quality'",
    "ruff (>=0.0.241) ; extra == 'quality'",
    "filelock ; extra == 'testing'",
    "GitPython ; extra == 'testing'",
    "parameterized ; extra == 'testing'",
    "psutil ; extra == 'testing'",
    "pytest ; extra == 'testing'",
    "pytest-pythonpath ; extra == 'testing'",
    "pytest-xdist ; extra == 'testing'",
    "Pillow ; extra == 'testing'",
    "librosa ; extra == 'testing'",
    "soundfile ; extra == 'testing'"
  ],
  "requires_python": "",
  "summary": "optimum furiosa is the interface between the \ud83e\udd17 transformers library and furiosa npus such as furiosa warboy. it provides a set of tools enabling easy model loading and inference for different downstream tasks for furiosa npu.",
  "version": "0.1.0",
  "releases": [],
  "developers": [
    "hardware@huggingface.co",
    "huggingface_inc"
  ],
  "kwds": "furiosa furiosaai furiosaaimodelforimageclassification furiosaaimodelforxxx optimum",
  "license_kwds": "apache",
  "libtype": "pypi",
  "id": "pypi_optimum_furiosa",
  "homepage": "https://huggingface.co/hardware",
  "release_count": 1,
  "dependency_ids": [
    "pypi_black",
    "pypi_datasets",
    "pypi_filelock",
    "pypi_furiosa_optimizer",
    "pypi_furiosa_quantizer",
    "pypi_furiosa_quantizer_impl",
    "pypi_furiosa_sdk",
    "pypi_gitpython",
    "pypi_librosa",
    "pypi_onnx",
    "pypi_optimum",
    "pypi_parameterized",
    "pypi_pillow",
    "pypi_psutil",
    "pypi_pytest",
    "pypi_pytest_pythonpath",
    "pypi_pytest_xdist",
    "pypi_ruff",
    "pypi_scipy",
    "pypi_sentencepiece",
    "pypi_soundfile",
    "pypi_transformers"
  ]
}