{
  "classifiers": [
    "development status :: 5 - production/stable",
    "license :: osi approved :: mit license",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# azure ml package client library for python\n\nwe are excited to introduce the ga of azure machine learning python sdk v2. the python sdk v2 introduces new sdk capabilities like standalone local jobs, reusable components for pipelines and managed online/batch inferencing. python sdk v2 allows you to move from simple to complex tasks easily and incrementally. this is enabled by using a common object model which brings concept reuse and consistency of actions across various tasks. the sdk v2 shares its foundation with the cli v2 which is also ga.\n\n[source code][source_code]\n| [package (pypi)][ml_pypi]\n| [package (conda)][ml_conda]\n| [api reference documentation][ml_ref_docs]\n| [product documentation][product_documentation]\n| [samples][ml_samples]\n\n\nthis package has been tested with python 3.7, 3.8, 3.9 and 3.10.\n\nfor a more complete set of azure libraries, see https://aka.ms/azsdk/python/all\n\n## getting started\n\n### prerequisites\n\n- python 3.7 or later is required to use this package.\n- you must have an [azure subscription][azure_subscription].\n- an [azure machine learning workspace][workspace].\n\n### install the package\n\ninstall the azure ml client library for python with [pip][pip_link]:\n\n```bash\npip install azure-ai-ml\npip install azure-identity\n```\n\n### authenticate the client\n\n```python\nfrom azure.ai.ml import mlclient\nfrom azure.identity import defaultazurecredential\n\nml_client = mlclient(\n    defaultazurecredential(), subscription_id, resource_group, workspace\n)\n```\n\n## key concepts\n\nazure machine learning python sdk v2 comes with many new features like standalone local jobs, reusable components for pipelines and managed online/batch inferencing. the sdk v2 brings consistency and ease of use across all assets of the platform. the python sdk v2 offers the following capabilities:\n* run **standalone jobs** - run a discrete ml activity as job. this job can be run locally or on the cloud. we currently support the following types of jobs:\n  * command - run a command (python, r, windows command, linux shell etc.)\n  * sweep - run a hyperparameter sweep on your command\n* run multiple jobs using our **improved pipelines**\n  * run a series of commands stitched into a pipeline (**new**)\n  * **components** - run pipelines using reusable components (**new**)\n* use your models for **managed online inferencing** (**new**)\n* use your models for managed **batch inferencing**\n* manage aml resources \u2013 workspace, compute, datastores\n* manage aml assets - datasets, environments, models\n* **automl** - run standalone automl training for various ml-tasks:\n  - classification (tabular data)\n  - regression (tabular data)\n  - time series forecasting (tabular data)\n  - image classification (multi-class) (**new**)\n  - image classification (multi-label) (**new**)\n  - image object detection (**new**)\n  - image instance segmentation (**new**)\n  - nlp text classification (multi-class) (**new**)\n  - nlp text classification (multi-label) (**new**)\n  - nlp text named entity recognition (ner) (**new**)\n\n## examples\n\n- view our [samples][ml_samples].\n\n## troubleshooting\n\n### general\n\nazure ml clients raise exceptions defined in [azure core][azure_core_readme].\n\n```python\nfrom azure.core.exceptions import httpresponseerror\n\ntry:\n    ml_client.compute.get(\"cpu-cluster\")\nexcept httpresponseerror as error:\n    print(\"request failed: {}\".format(error.message))\n```\n\n### logging\n\nthis library uses the standard\n[logging][python_logging] library for logging.\nbasic information about http sessions (urls, headers, etc.) is logged at info\nlevel.\n\ndetailed debug level logging, including request/response bodies and unredacted\nheaders, can be enabled on a client with the `logging_enable` argument.\n\nsee full sdk logging documentation with examples [here][sdk_logging_docs].\n\n### telemetry\n\nthe azure ml python sdk includes a telemetry feature that collects usage and failure data about the sdk and sends it to microsoft when you use the sdk in a jupyter notebook only.\n<u>telemetry will **not** be collected for any use of the python sdk outside of a jupyter notebook.</u>\n\ntelemetry data helps the sdk team understand how the sdk is used so it can be improved and the information about failures helps the team resolve problems and fix bugs.\nthe sdk telemetry feature is enabled by default for jupyter notebook usage and cannot be enabled for non-jupyter scenarios. to opt out of the telemetry feature in a jupyter scenario, pass in `enable_telemetry=false` when constructing your mlclient object.\n\n## next steps\n\n- view our [samples][ml_samples].\n\n## contributing\n\nthis project welcomes contributions and suggestions. most contributions require you to agree to a contributor license agreement (cla) declaring that you have the right to, and actually do, grant us the rights to use your contribution. for details, visit [cla.microsoft.com][cla].\n\nwhen you submit a pull request, a cla-bot will automatically determine whether you need to provide a cla and decorate the pr appropriately (e.g., label, comment). simply follow the instructions provided by the bot. you will only need to do this once across all repos using our cla.\n\nthis project has adopted the [microsoft open source code of conduct][code_of_conduct]. for more information see the [code of conduct faq][coc_faq] or contact [opencode@microsoft.com][coc_contact] with any additional questions or comments.\n\n<!-- links -->\n\n[source_code]: https://github.com/azure/azure-sdk-for-python/tree/main/sdk/ml/azure-ai-ml\n[ml_pypi]: https://pypi.org/project/azure-ai-ml/\n[ml_conda]: https://anaconda.org/microsoft/azure-ai-ml/\n[ml_ref_docs]: https://learn.microsoft.com/python/api/overview/azure/ai-ml-readme?view=azure-python\n[ml_samples]: https://github.com/azure/azureml-examples/tree/main/sdk/python\n[product_documentation]: https://docs.microsoft.com/azure/machine-learning/\n[azure_subscription]: https://azure.microsoft.com/free/\n[workspace]: https://docs.microsoft.com/azure/machine-learning/concept-workspace\n[python_logging]: https://docs.python.org/3/library/logging.html\n[sdk_logging_docs]: https://docs.microsoft.com/azure/developer/python/azure-sdk-logging\n[azure_core_readme]: https://github.com/azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/readme.md\n[pip_link]: https://pypi.org/project/pip/\n[azure_core_ref_docs]: https://aka.ms/azsdk-python-core-policies\n[azure_core]: https://github.com/azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/readme.md\n[azure_identity]: https://github.com/azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity\n[python_logging]: https://docs.python.org/3/library/logging.html\n[cla]: https://cla.microsoft.com\n[code_of_conduct]: https://opensource.microsoft.com/codeofconduct/\n[coc_faq]: https://opensource.microsoft.com/codeofconduct/faq/\n[coc_contact]: mailto:opencode@microsoft.com\n\n\n# release history\n\n## 1.12.1 (2023-11-17)\n\n### bugs fixed\n- addressed null value issue with workspace connection kinds\n- re-added workspace connection metadata legacy value to address holdover issues.\n- added support for developer-role users to create lean workspaces.\n- fix an issue with pipeline deployments\n\n## 1.12.0 (2023-11-13)\n\n### features added\n- workspace connections had 3 child classes added for open ai, cog search, and cog service connections.\n- workspace connections replaced metadata with tags, and surfaced api_version, api_type, and kind for certain connection types.\n\n\n### bugs fixed\n- workspace hubs now properly create various endpoints, and surface a variable to select the resource they connect to via the\n  'endpoint_resource_id' kwarg.\n\n## 1.11.1 (2023-10-13)\n\n### bugs fixed\n - pydash dependency version was upgraded to >=6.0.0 to patch [security vulnerability in versions below 6.0.0](https://github.com/advisories/ghsa-8mjr-6c96-39w8)\n - workspace hub deletion no longer fails if delete_dependent_resources is true.\n\n## 1.11.0 (2023-10-04)\n\n### features added\n- now, when you specify `delete_dependent_resources` as true when deleting a workspace, the log analytics resource\n  associated with the workspace application insights resource will also be deleted.\n- now, when creating or updating a workspace, you can provide a `serverless_compute` configuration object. this allows configuring a custom subnet in which all serverless computes will be created. you can also specify whether or not these serverless computes will have public ip addresses or not.\n\n### breaking changes\n - [python 3.7 reached end-of-life on june 27th 2023](https://devguide.python.org/versions/). consequently, 3.7 will be deprecated in azure-ai-ml starting in october 2023 and azure-ai-ml will end support for 3.7 in february 2024.\n\n## 1.10.1 (2023-09-17)\n\n### bugs fixed\n- feature sets can now be registers after being dumped and reloaded.\n- sdk feature store create/update can now assign materialization identities to cross rg offline stores and online stores.\n\n## 1.10.0 (2023-09-07)\n\n### features added\n- added support of features that are known into the future/at forecast time for dnn in automl forecasting jobs.\n- added support for new workspace connection types: azure_open_ai, cognitive_search, and cognitive_service.\n- added support for new credential type: apikeyconfiguration.\n- added support of `download` for component operations.\n\n### bugs fixed\n- local job runs will no longer fail if docker registry has no username/password\n- fixed an issue that code asset doesn't work with relative symbol links.\n- fixed [issue 31319](https://github.com/azure/azure-sdk-for-python/issues/31319): can't accept `pathlike` for `commandcomponent.code`.\n\n### other changes\n\n- `azure-ai-ml` now performs all file i/o on `utf-8` encoded files per azure sdk guidance. \n  (instead of the default behavior for python < 3.15, which uses locale specific encodings)\n- removed references to deprecated \"feature_store\" workspace connection type.\n\n## 1.9.0 (2023-07-25)\n\n### features added\n- added support to enable gpu access (local_enable_gpu) for local deployment.\n\n### other changes\n\n- improved the output when printing a workspace object to be more clean and readable.\n- log level of unknown field notifications for pipeline nodes raised from info to warning.\n## 1.8.0 (2023-06-12)\n\n### features added\n- added support to enable set workspace connection secret expiry time.\n- added support for `stage` on model version\n\n### bugs fixed\n\n- fixed an issue affecting authentication to registry-related services in sovereign regions.\n- made job_tier and priority values case insensitive\n\n## 1.7.2 (2023-05-18)\n\n### features added\n- public preview support for new schedule type `monitorschedule`\n\n\n## 1.7.1 (2023-05-17)\n\n### bugs fixed\n- fixed an issue where `onlinedeployment.provisioning_state` was incorrectly deserialized and set as `none`\n\n\n## 1.7.0 (2023-05-15)\n\n### features added\n- added data import schedule. the class added is `importdataschedule`.\n- added support to enable data isolation feature at workspace creation stage.\n- added auto_delete_setting support for asset version in data import job.\n\n### bugs fixed\n\n### breaking changes\n\n### other changes\n\n\n## 1.6.0 (2023-05-01)\n\n### features added\n- added experimental scatter gather node to dsl package. this node has a unique mldesigner dependency.\n- added support to make jobservice and serviceinstance objects serializable when printed\n- support singularity compute in pipeline job\n- added purge operation support for workspace resource\n- added feature store, its dedicated classes and updated the docstrings, now available in public interface. the classes added are `featurestoreoperations, featuresetoperations, featurestoreentityoperations` with properties classes specific to the new features.\n- support additional_includes in command component\n- added experimental `distribution: ray` support in command job.\n\n### bugs fixed\n\n- fixed issue where show_progress=false was not being respected for uploads when set via mlclient\n- fixed issue of spark input/output mode validation doesn't take effect because of wrong type assertion\n- fixed the bug when setting `node.limits.timeout` to a pipeline input.\n- removed experimental tag from idle shutdown, custom applications, setup scripts, and image metadata on compute instances.\n- removed experimental tag from jobservice classes\n\n### breaking changes\n\n- renamed `jobservicebase.job_service_type` to `type`\n\n### other changes\n\n- remove the default placeholder for commandcomponent.code\n\n## 1.5.0 (2023-03-20)\n\n### features added\n- added support for `tags` on compute resources.\n- added support for promoting data asset from a workspace to a registry\n- added support for registering named asset from job output or node output by specifying name and version settings.\n- added support for data binding on outputs inside dynamic arguments for dsl pipeline\n- added support for serverless compute in pipeline, command, automl and sweep job\n- added support for `job_tier` and `priority` in standalone job\n- added support for passing `locations` via command function and set it to `jobresourceconfiguration.locations`\n- added support for modifying ssh key values after creation on compute resources.\n- added workspaceconnection types `s3`, `snowflake`, `azure_sql_db`, `azure_synapse_analytics`, `azure_my_sql_db`, `azure_postgres_db`\n- added workspaceconnection auth type `access_key` for `s3`\n- added dataimport class and dataoperations.import_data.\n- added dataoperations.list_materialization_status - list status of data import jobs that create asset versions via asset name.\n\n### bugs fixed\n\n- fix experiment name wrongly set to 'default' when schedule existing job.\n- error message improvement when a local path fails to match with data asset type.\n- error message improvement when an asset does not exist in a registry\n- fix an issue when submit spark pipeline job with referring a registered component\n- fix an issue that prevented job.download from downloading the output of a batchjob\n\n### other changes\n\n- added dependency on `azure-mgmt-resource`\n- added dependency on `azure-mgmt-resourcegraph`\n- added dependency on `opencensus-ext-azure<2.0.0`\n- update job types to use mfe dec preview rest objects.\n- added classifiers for python version 3.11.\n- added warning for reserved keywords in io names in pipeline job nodes.\n- added telemetry logging for sdk jupyter notebook scenarios with opt-out option (see readme.md)\n\n## 1.4.0 (2023-02-07)\n\n### features added\n- added dedicated classes for each type of job service and updated the docstrings. the classes added are `jupyterlabjobservice, sshjobservice, tensorboardjobservice, vscodejobservice` with a few properties specific to the type.\n- added custom applications support to compute instances.\n- update data asset list, show and create operations to support data assets in registry.\n- added managed network features to workspace to include `managednetwork`, `fqdndestination`, `privateendpointdestination`, `servicetagdestination` as well as relevant schema.\n\n### bugs fixed\n- fixed an issue where the ordering of `.amlignore` and `.gitignore` files are not respected.\n- fixed an issue that attributes with a value of `false` in `pipelinejobsettings` are not respected.\n- fixed an issue where ignore files weren't considered during upload directory size calculations.\n- fixed an issue where symlinks crashed upload directory size calculations.\n- fixes a bug where enable_node_public_ip returned an improper value when fetching a compute.\n\n### other changes\n- update workspace creation to use log analytics-based application insights when the user does not specify/bring their own app insights.\n- upgraded minimum azure-core version to 1.23.0.\n\n## 1.3.0 (2023-01-13)\n\n### features added\n- change print behavior of entity classes to show object yaml in notebooks, can be configured on in other contexts.\n- added property to enable/disable public ip addresses to compute instances and aml computes.\n- `deployment` and `scheduleoperations` added to public interface.\n\n### bugs fixed\n- fixed issue with date-time format for utc_time_created field when creating models.\n- added stricter behavior for armstr schemas when parsing 'azureml:' prefix.\n- fixed issue where amlcomputes could only be created in a workspace's default region.\n- improved intellisense with vs code for fields supporting local paths and datastores.\n- added validation for token generation with aml scope when user_identity is used in job definition aka obo flow.\n- fixed duplicate node name error in pipeline when two node names assigned to the same node and get renamed by node.name='xx'.\n- resolve the cross references for mlclient, resource and onlinedeployment.\n- explicit use of optional (or a union with none), as per pep 484.\n- fixed print on command objects when job id is empty\n- fixed issue where `sastokenconfiguration` cannot be used as credential for `workspaceconnection`\n\n### other changes\n- removed dependency on api version 2021-10-01 and 2022-06-01-preview to reduce side of azure-ai-ml package.\n\n## 1.2.0 (2022-12-05)\n\n### breaking changes\n- removed description from registry.\n- disable sdk telemetry logging\n\n### features added\n- enable updating the cmk encryption key (workspace.encryption.keyvaultproperties.keyidentifier) for a workspace.\n- mark jobservice class and services param to command() as experimental.\n- added a replication_count value to the schema of systemcreatedstorageaccount in registry.\n- added support for fairfax and mooncake cloud for the registry discovery baseurl.\n- added support for variable args as pipeline input in dsl pipeline.\n- added os patching parameters to compute instance.\n\n### bugs fixed\n- update the upper bound dependencies version for tqdm, strictyaml, colorama and opencensus-ext-azure.\n- added missing \"properties\" to batch deployment.\n- retain the cases for the names of system job services (tracking and studio).\n- update registry begin_delete method return type.\n- fixed sweep job optional input cannot be empty.\n- fixed bool test for output in download operation.\n- fixed compute instance schedule not being created\n- removed erroneous experimental warning from compute schedules\n\n## 1.1.2 (2022-11-21)\n\n### features added\n- restored idle_time_before_shutdown property for compute instances.\n- deprecated idle_time_before_shutdown property in favor of idle_time_before_shutdown_minutes.\n\n### bugs fixed\n- fixed idle_time_before_shutdown appearing as none for compute instances returned by `show` or `list`.\n- fixed idle_time_before_shutdown_minutes preventing creation of compute instances when set to none.\n\n## 1.1.1 (2022-11-15)\n\n### breaking changes\n- renamed idle_time_before_shutdown to idle_time_before_shutdown_minutes and changed input type to int.\n\n### bugs fixed\n- fixed idle_time_before_shutdown_minutes not appearing in get calls for compute instances.\n\n## 1.1.0 (2022-11-07)\n\n### features added\n- registry list operation now accepts scope value to allow subscription-only based requests.\n- most configuration classes from the entity package now implement the standard mapping protocol.\n- add registry delete operation.\n- the values of jobservice.job_service_type are now using the snake case. e.g jupyter_lab, ssh, tensor_board, vs_code.\n- command function now accepts services param of type dict[str, jobservice] instead of dict.\n\n### bugs fixed\n- mlclient.from_config can now find the default config.json on compute instance when running sample notebooks.\n- fixed job inputs not accepting datastores or job inputs.\n- registries now assign managed tags to match registry's tags.\n- adjust registry experimental tags and imports to avoid warning printouts for unrelated operations.\n- make registry delete operation return an lropoller, and change name to begin_delete.\n- prevent registering an already existing environment that references conda file.\n- fix arm id logic for registry environments (ex: creating a registry component that references a registry environment).\n- fix arm id logic for passing models and environments with id (ex: creating endpoint deployment for a registry model should return said model's id immediately)\n\n### other changes\n- switched compute operations to go through 2022-10-01-preview api version.\n\n## 1.0.0 (2022-10-10)\n- ga release\n- dropped support for python 3.6. the python versions supported for this release are 3.7-3.10.\n\n### features added\n\n### breaking changes\n- onlinedeploymentoperations.delete has been renamed to begin_delete.\n- datastore credentials are switched to use unified credential configuration classes.\n- userassignedidentity is replaced by managedidentityconfiguration\n- endpoint and job use unified identity classes.\n- workspace managedserviceidentity has been replaced by identityconfiguration.\n\n\n### other changes\n - switched compute operations to use oct preview api version.\n - updated batch deployment/endpoint invoke and list-jobs function signatures with curated batchjob class.\n\n## 0.1.0b8 (2022-10-07)\n\n### features added\n - support passing jobservice as argument to command()\n - added support for custom setup scripts on compute instances.\n - added a `show_progress` parameter to mlclient for enable/disable progress bars of long running operations.\n - support `month_days` in `recurrencepattern` when using `recurrenceschedule`.\n - support `ml_client.schedules.list` with `list_view_type`, default to `enabled_only`.\n - add support for model sweeping and hyperparameter tuning in automl nlp jobs.\n - added `ml_client.jobs.show_services()` operation.\n\n### breaking changes\n- computeoperations.attach has been renamed to begin_attach.\n- deprecated parameter path has been removed from load and dump methods.\n- joboperations.cancel() is renamed to joboperations.begin_cancel() and it returns lropoller\n- workspace.list_keys renamed to workspace.get_keys.\n\n### bugs fixed\n- fix identity passthrough job with single file code\n- mlclient.from_config can now find the default config.json on compute instance when running sample notebooks.\n\n### other changes\n - removed declaration on python 3.6 support\n - added support for custom setup scripts on compute instances.\n - updated dependencies upper bounds to be major versions.\n\n## 0.1.0b7 (2022-09-22)\n\n### features added\n - spark job submission.\n - command and sweep job docker config (shmsize and dockerargs) spec support.\n - entity load and dump now also accept a file pointer as input.\n - load and dump input names changed from path to 'source' and 'dest', respectively.\n - load and dump 'path' input still works, but is deprecated and emits a warning.\n - managed identity support for compute instance (experimental).\n - enable using @dsl.pipeline without brackets when no additional parameters.\n - expose azure subscription id and resource group name from mlclient objects.\n - added idle shutdown support for compute instances, allowing instances to shutdown after a set period of inactivity.\n - online deployment data collection for eventhub and data storage will be supported.\n - syntax validation on scoring scripts of batch deployment and online deployment will prevent the user from submitting bad deployments.\n\n### breaking changes\n - change (begin_)create_or_update typehints to use generics.\n - remove invalid option from create_or_update typehints.\n - change error returned by (begin_)create_or_update invalid input to typeerror.\n - rename set_image_model apis for all vision tasks to set_training_parameters\n - joboperations.download defaults to \".\" instead of path.cwd()\n\n### bugs fixed\n\n### other changes\n - show 'properties' on data assets\n\n\n## 0.1.0b6 (2022-08-09)\n\n### features added\n\n- support for automl component\n- added skip_validation for job/component create_or_update\n\n### breaking changes\n\n- dataset removed from public interface.\n\n### bugs fixed\n\n- fixed mismatch errors when updating scale_settings for kubernetesonlinedeployment.\n- removed az cli command that was printed when deleting onlineendpoint\n\n## 0.1.0b5 (2022-07-15)\n\n### features added\n\n- allow input/output objects to be used by commandcomponent.\n- added mooncake cloud support.\n- unified inputs/outputs building and validation logic in basenode.\n- allow git repo urls to be used as code for jobs and components.\n- updated automl yaml schema to use inputschema.\n- added end_time to job schedule.\n- mir and pipeline job now support registry assets.\n\n\n### bugs fixed\n\n- have mldesigner use argparser to parse incoming args.\n- bumped pyjwt version to <3.0.0.\n- reverted \"upload support for symlinks\".\n- error message improvement when a yaml unionfield fails to match.\n- reintroduced support for symlinks when uploading.\n- hard coded registry base url to eastus region to support preview.\n\n## 0.1.0b4 (2022-06-16)\n\n## 0.1.0b3 (2022-05-24)\n\n### features added\n\n- first preview.\n",
  "docs_url": null,
  "keywords": "azure,azure sdk",
  "license": "mit license",
  "name": "azure-ai-ml",
  "package_url": "https://pypi.org/project/azure-ai-ml/",
  "project_url": "https://pypi.org/project/azure-ai-ml/",
  "project_urls": {
    "Bug Reports": "https://github.com/Azure/azure-sdk-for-python/issues",
    "Homepage": "https://github.com/Azure/azure-sdk-for-python",
    "Source": "https://github.com/Azure/azure-sdk-python"
  },
  "release_url": "https://pypi.org/project/azure-ai-ml/1.12.1/",
  "requires_dist": [
    "pyyaml<7.0.0,>=5.1.0",
    "msrest>=0.6.18",
    "azure-core<2.0.0,>=1.23.0",
    "azure-mgmt-core<2.0.0,>=1.3.0",
    "marshmallow<4.0.0,>=3.5",
    "jsonschema<5.0.0,>=4.0.0",
    "tqdm<5.0.0",
    "strictyaml<2.0.0",
    "colorama<0.5.0",
    "pyjwt<3.0.0",
    "azure-storage-blob<13.0.0,>=12.10.0",
    "azure-storage-file-share<13.0.0",
    "azure-storage-file-datalake<13.0.0",
    "pydash<7.0.6,>=6.0.0",
    "isodate",
    "azure-common<2.0.0,>=1.1",
    "typing-extensions<5.0.0",
    "opencensus-ext-azure<2.0.0",
    "mldesigner; extra == \"designer\""
  ],
  "requires_python": "<4.0,>=3.7",
  "summary": "microsoft azure machine learning client library for python",
  "version": "1.12.1",
  "releases": [],
  "developers": [
    "azuresdkengsysadmins@microsoft.com",
    "microsoft_corporation"
  ],
  "kwds": "azure_open_ai azure azureml azure_core azure_core_ref_docs",
  "license_kwds": "mit license",
  "libtype": "pypi",
  "id": "pypi_azure_ai_ml",
  "homepage": "https://github.com/azure/azure-sdk-for-python",
  "release_count": 28,
  "dependency_ids": [
    "pypi_azure_common",
    "pypi_azure_core",
    "pypi_azure_mgmt_core",
    "pypi_azure_storage_blob",
    "pypi_azure_storage_file_datalake",
    "pypi_azure_storage_file_share",
    "pypi_colorama",
    "pypi_isodate",
    "pypi_jsonschema",
    "pypi_marshmallow",
    "pypi_mldesigner",
    "pypi_msrest",
    "pypi_opencensus_ext_azure",
    "pypi_pydash",
    "pypi_pyjwt",
    "pypi_pyyaml",
    "pypi_strictyaml",
    "pypi_tqdm",
    "pypi_typing_extensions"
  ]
}