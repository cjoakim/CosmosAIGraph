{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "license :: osi approved",
    "operating system :: os independent",
    "programming language :: javascript",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "typing :: typed"
  ],
  "description": "# aws cloud development kit library\n\nthe aws cdk construct library provides apis to define your cdk application and add\ncdk constructs to the application.\n\n## usage\n\n### upgrade from cdk 1.x\n\nwhen upgrading from cdk 1.x, remove all dependencies to individual cdk packages\nfrom your dependencies file and follow the rest of the sections.\n\n### installation\n\nto use this package, you need to declare this package and the `constructs` package as\ndependencies.\n\naccording to the kind of project you are developing:\n\nfor projects that are cdk libraries in npm, declare them both under the `devdependencies` **and** `peerdependencies` sections.\nto make sure your library is compatible with the widest range of cdk versions: pick the minimum `aws-cdk-lib` version\nthat your library requires; declare a range dependency with a caret on that version in peerdependencies, and declare a\npoint version dependency on that version in devdependencies.\n\nfor example, let's say the minimum version your library needs is `2.38.0`. your `package.json` should look like this:\n\n```javascript\n{\n  \"peerdependencies\": {\n    \"aws-cdk-lib\": \"^2.38.0\",\n    \"constructs\": \"^10.0.0\"\n  },\n  \"devdependencies\": {\n    /* install the oldest version for testing so we don't accidentally use features from a newer version than we declare */\n    \"aws-cdk-lib\": \"2.38.0\"\n  }\n}\n```\n\nfor cdk apps, declare them under the `dependencies` section. use a caret so you always get the latest version:\n\n```json\n{\n  \"dependencies\": {\n    \"aws-cdk-lib\": \"^2.38.0\",\n    \"constructs\": \"^10.0.0\"\n  }\n}\n```\n\n### use in your code\n\n#### classic import\n\nyou can use a classic import to get access to each service namespaces:\n\n```python\nfrom aws_cdk import stack, app, aws_s3 as s3\n\napp = app()\nstack = stack(app, \"teststack\")\n\ns3.bucket(stack, \"testbucket\")\n```\n\n#### barrel import\n\nalternatively, you can use \"barrel\" imports:\n\n```python\nfrom aws_cdk import app, stack\nfrom aws_cdk.aws_s3 import bucket\n\napp = app()\nstack = stack(app, \"teststack\")\n\nbucket(stack, \"testbucket\")\n```\n\n<!--begin core documentation-->\n\n## stacks and stages\n\na `stack` is the smallest physical unit of deployment, and maps directly onto\na cloudformation stack. you define a stack by defining a subclass of `stack`\n-- let's call it `mystack` -- and instantiating the constructs that make up\nyour application in `mystack`'s constructor. you then instantiate this stack\none or more times to define different instances of your application. for example,\nyou can instantiate it once using few and cheap ec2 instances for testing,\nand once again using more and bigger ec2 instances for production.\n\nwhen your application grows, you may decide that it makes more sense to split it\nout across multiple `stack` classes. this can happen for a number of reasons:\n\n* you could be starting to reach the maximum number of resources allowed in a single\n  stack (this is currently 500).\n* you could decide you want to separate out stateful resources and stateless resources\n  into separate stacks, so that it becomes easy to tear down and recreate the stacks\n  that don't have stateful resources.\n* there could be a single stack with resources (like a vpc) that are shared\n  between multiple instances of other stacks containing your applications.\n\nas soon as your conceptual application starts to encompass multiple stacks,\nit is convenient to wrap them in another construct that represents your\nlogical application. you can then treat that new unit the same way you used\nto be able to treat a single stack: by instantiating it multiple times\nfor different instances of your application.\n\nyou can define a custom subclass of `stage`, holding one or more\n`stack`s, to represent a single logical instance of your application.\n\nas a final note: `stack`s are not a unit of reuse. they describe physical\ndeployment layouts, and as such are best left to application builders to\norganize their deployments with. if you want to vend a reusable construct,\ndefine it as a subclasses of `construct`: the consumers of your construct\nwill decide where to place it in their own stacks.\n\n## stack synthesizers\n\neach stack has a *synthesizer*, an object that determines how and where\nthe stack should be synthesized and deployed. the synthesizer controls\naspects like:\n\n* how does the stack reference assets? (either through cloudformation\n  parameters the cli supplies, or because the stack knows a predefined\n  location where assets will be uploaded).\n* what roles are used to deploy the stack? these can be bootstrapped\n  roles, roles created in some other way, or just the cli's current\n  credentials.\n\nthe following synthesizers are available:\n\n* `defaultstacksynthesizer`: recommended. uses predefined asset locations and\n  roles created by the modern bootstrap template. access control is done by\n  controlling who can assume the deploy role. this is the default stack\n  synthesizer in cdkv2.\n* `legacystacksynthesizer`: uses cloudformation parameters to communicate\n  asset locations, and the cli's current permissions to deploy stacks. this\n  is the default stack synthesizer in cdkv1.\n* `clicredentialsstacksynthesizer`: uses predefined asset locations, and the\n  cli's current permissions.\n\neach of these synthesizers takes configuration arguments. to configure\na stack with a synthesizer, pass it as one of its properties:\n\n```python\nmystack(app, \"mystack\",\n    synthesizer=defaultstacksynthesizer(\n        file_assets_bucket_name=\"my-orgs-asset-bucket\"\n    )\n)\n```\n\nfor more information on bootstrapping accounts and customizing synthesis,\nsee [bootstrapping in the cdk developer guide](https://docs.aws.amazon.com/cdk/latest/guide/bootstrapping.html).\n\n## nested stacks\n\n[nested stacks](https://docs.aws.amazon.com/awscloudformation/latest/userguide/using-cfn-nested-stacks.html) are stacks created as part of other stacks. you create a nested stack within another stack by using the `nestedstack` construct.\n\nas your infrastructure grows, common patterns can emerge in which you declare the same components in multiple templates. you can separate out these common components and create dedicated templates for them. then use the resource in your template to reference other templates, creating nested stacks.\n\nfor example, assume that you have a load balancer configuration that you use for most of your stacks. instead of copying and pasting the same configurations into your templates, you can create a dedicated template for the load balancer. then, you just use the resource to reference that template from within other templates.\n\nthe following example will define a single top-level stack that contains two nested stacks: each one with a single amazon s3 bucket:\n\n```python\nclass mynestedstack(cfn.nestedstack):\n    def __init__(self, scope, id, *, parameters=none, timeout=none, notifications=none):\n        super().__init__(scope, id, parameters=parameters, timeout=timeout, notifications=notifications)\n\n        s3.bucket(self, \"nestedbucket\")\n\nclass myparentstack(stack):\n    def __init__(self, scope, id, *, description=none, env=none, stackname=none, tags=none, synthesizer=none, terminationprotection=none, analyticsreporting=none, crossregionreferences=none, permissionsboundary=none, suppresstemplateindentation=none):\n        super().__init__(scope, id, description=description, env=env, stackname=stackname, tags=tags, synthesizer=synthesizer, terminationprotection=terminationprotection, analyticsreporting=analyticsreporting, crossregionreferences=crossregionreferences, permissionsboundary=permissionsboundary, suppresstemplateindentation=suppresstemplateindentation)\n\n        mynestedstack(self, \"nested1\")\n        mynestedstack(self, \"nested2\")\n```\n\nresources references across nested/parent boundaries (even with multiple levels of nesting) will be wired by the aws cdk\nthrough cloudformation parameters and outputs. when a resource from a parent stack is referenced by a nested stack,\na cloudformation parameter will automatically be added to the nested stack and assigned from the parent; when a resource\nfrom a nested stack is referenced by a parent stack, a cloudformation output will be automatically be added to the\nnested stack and referenced using `fn::getatt \"outputs.xxx\"` from the parent.\n\nnested stacks also support the use of docker image and file assets.\n\n## accessing resources in a different stack\n\nyou can access resources in a different stack, as long as they are in the\nsame account and aws region (see [next section](#accessing-resources-in-a-different-stack-and-region) for an exception).\nthe following example defines the stack `stack1`,\nwhich defines an amazon s3 bucket. then it defines a second stack, `stack2`,\nwhich takes the bucket from stack1 as a constructor property.\n\n```python\nprod = {\"account\": \"123456789012\", \"region\": \"us-east-1\"}\n\nstack1 = stackthatprovidesabucket(app, \"stack1\", env=prod)\n\n# stack2 will take a property { bucket: ibucket }\nstack2 = stackthatexpectsabucket(app, \"stack2\",\n    bucket=stack1.bucket,\n    env=prod\n)\n```\n\nif the aws cdk determines that the resource is in the same account and\nregion, but in a different stack, it automatically synthesizes aws\ncloudformation\n[exports](https://docs.aws.amazon.com/awscloudformation/latest/userguide/using-cfn-stack-exports.html)\nin the producing stack and an\n[fn::importvalue](https://docs.aws.amazon.com/awscloudformation/latest/userguide/intrinsic-function-reference-importvalue.html)\nin the consuming stack to transfer that information from one stack to the\nother.\n\n## accessing resources in a different stack and region\n\n> **this feature is currently experimental**\n\nyou can enable the stack property `crossregionreferences`\nin order to access resources in a different stack *and* region. with this feature flag\nenabled it is possible to do something like creating a cloudfront distribution in `us-east-2` and\nan acm certificate in `us-east-1`.\n\n```python\nstack1 = stack(app, \"stack1\",\n    env=environment(\n        region=\"us-east-1\"\n    ),\n    cross_region_references=true\n)\ncert = acm.certificate(stack1, \"cert\",\n    domain_name=\"*.example.com\",\n    validation=acm.certificatevalidation.from_dns(route53.publichostedzone.from_hosted_zone_id(stack1, \"zone\", \"z0329774b51cgxtdqv3x\"))\n)\n\nstack2 = stack(app, \"stack2\",\n    env=environment(\n        region=\"us-east-2\"\n    ),\n    cross_region_references=true\n)\ncloudfront.distribution(stack2, \"distribution\",\n    default_behavior=cloudfront.behavioroptions(\n        origin=origins.httporigin(\"example.com\")\n    ),\n    domain_names=[\"dev.example.com\"],\n    certificate=cert\n)\n```\n\nwhen the aws cdk determines that the resource is in a different stack *and* is in a different\nregion, it will \"export\" the value by creating a custom resource in the producing stack which\ncreates ssm parameters in the consuming region for each exported value. the parameters will be\ncreated with the name '/cdk/exports/${consumingstackname}/${export-name}'.\nin order to \"import\" the exports into the consuming stack a [ssm dynamic reference](https://docs.aws.amazon.com/awscloudformation/latest/userguide/dynamic-references.html#dynamic-references-ssm)\nis used to reference the ssm parameter which was created.\n\nin order to mimic strong references, a custom resource is also created in the consuming\nstack which marks the ssm parameters as being \"imported\". when a parameter has been successfully\nimported, the producing stack cannot update the value.\n\nsee the [adr](https://github.com/aws/aws-cdk/blob/main/packages/@aws-cdk/core/adr/cross-region-stack-references)\nfor more details on this feature.\n\n### removing automatic cross-stack references\n\nthe automatic references created by cdk when you use resources across stacks\nare convenient, but may block your deployments if you want to remove the\nresources that are referenced in this way. you will see an error like:\n\n```text\nexport stack1:exportsoutputfngetatt-****** cannot be deleted as it is in use by stack1\n```\n\nlet's say there is a bucket in the `stack1`, and the `stack2` references its\n`bucket.bucketname`. you now want to remove the bucket and run into the error above.\n\nit's not safe to remove `stack1.bucket` while `stack2` is still using it, so\nunblocking yourself from this is a two-step process. this is how it works:\n\ndeployment 1: break the relationship\n\n* make sure `stack2` no longer references `bucket.bucketname` (maybe the consumer\n  stack now uses its own bucket, or it writes to an aws dynamodb table, or maybe you just\n  remove the lambda function altogether).\n* in the `stack1` class, call `this.exportvalue(this.bucket.bucketname)`. this\n  will make sure the cloudformation export continues to exist while the relationship\n  between the two stacks is being broken.\n* deploy (this will effectively only change the `stack2`, but it's safe to deploy both).\n\ndeployment 2: remove the resource\n\n* you are now free to remove the `bucket` resource from `stack1`.\n* don't forget to remove the `exportvalue()` call as well.\n* deploy again (this time only the `stack1` will be changed -- the bucket will be deleted).\n\n## durations\n\nto make specifications of time intervals unambiguous, a single class called\n`duration` is used throughout the aws construct library by all constructs\nthat that take a time interval as a parameter (be it for a timeout, a\nrate, or something else).\n\nan instance of duration is constructed by using one of the static factory\nmethods on it:\n\n```python\nduration.seconds(300) # 5 minutes\nduration.minutes(5) # 5 minutes\nduration.hours(1) # 1 hour\nduration.days(7) # 7 days\nduration.parse(\"pt5m\")\n```\n\ndurations can be added or subtracted together:\n\n```python\nduration.minutes(1).plus(duration.seconds(60)) # 2 minutes\nduration.minutes(5).minus(duration.seconds(10))\n```\n\n## size (digital information quantity)\n\nto make specification of digital storage quantities unambiguous, a class called\n`size` is available.\n\nan instance of `size` is initialized through one of its static factory methods:\n\n```python\nsize.kibibytes(200) # 200 kib\nsize.mebibytes(5) # 5 mib\nsize.gibibytes(40) # 40 gib\nsize.tebibytes(200) # 200 tib\nsize.pebibytes(3)\n```\n\ninstances of `size` created with one of the units can be converted into others.\nby default, conversion to a higher unit will fail if the conversion does not produce\na whole number. this can be overridden by unsetting `integral` property.\n\n```python\nsize.mebibytes(2).to_kibibytes() # yields 2048\nsize.kibibytes(2050).to_mebibytes(rounding=sizeroundingbehavior.floor)\n```\n\n## secrets\n\nto help avoid accidental storage of secrets as plain text, we use the `secretvalue` type to\nrepresent secrets. any construct that takes a value that should be a secret (such as\na password or an access key) will take a parameter of type `secretvalue`.\n\nthe best practice is to store secrets in aws secrets manager and reference them using `secretvalue.secretsmanager`:\n\n```python\nsecret = secretvalue.secrets_manager(\"secretid\",\n    json_field=\"password\",  # optional: key of a json field to retrieve (defaults to all content),\n    version_id=\"id\",  # optional: id of the version (default awscurrent)\n    version_stage=\"stage\"\n)\n```\n\nusing aws secrets manager is the recommended way to reference secrets in a cdk app.\n`secretvalue` also supports the following secret sources:\n\n* `secretvalue.unsafeplaintext(secret)`: stores the secret as plain text in your app and the resulting template (not recommended).\n* `secretvalue.secretsmanager(secret)`: refers to a secret stored in secrets manager\n* `secretvalue.ssmsecure(param, version)`: refers to a secret stored as a securestring in the ssm\n  parameter store. if you don't specify the exact version, aws cloudformation uses the latest\n  version of the parameter.\n* `secretvalue.cfnparameter(param)`: refers to a secret passed through a cloudformation parameter (must have `noecho: true`).\n* `secretvalue.cfndynamicreference(dynref)`: refers to a secret described by a cloudformation dynamic reference (used by `ssmsecure` and `secretsmanager`).\n* `secretvalue.resourceattribute(attr)`: refers to a secret returned from a cloudformation resource creation.\n\n`secretvalue`s should only be passed to constructs that accept properties of type\n`secretvalue`. these constructs are written to ensure your secrets will not be\nexposed where they shouldn't be. if you try to use a `secretvalue` in a\ndifferent location, an error about unsafe secret usage will be thrown at\nsynthesis time.\n\nif you rotate the secret's value in secrets manager, you must also change at\nleast one property on the resource where you are using the secret, to force\ncloudformation to re-read the secret.\n\n`secretvalue.ssmsecure()` is only supported for a limited set of resources.\n[click here for a list of supported resources and properties](https://docs.aws.amazon.com/awscloudformation/latest/userguide/dynamic-references.html#template-parameters-dynamic-patterns-resources).\n\n## arn manipulation\n\nsometimes you will need to put together or pick apart amazon resource names\n(arns). the functions `stack.formatarn()` and `stack.parsearn()` exist for\nthis purpose.\n\n`formatarn()` can be used to build an arn from components. it will automatically\nuse the region and account of the stack you're calling it on:\n\n```python\n# stack: stack\n\n\n# builds \"arn:<partition>:lambda:<region>:<account>:function:myfunction\"\nstack.format_arn(\n    service=\"lambda\",\n    resource=\"function\",\n    sep=\":\",\n    resource_name=\"myfunction\"\n)\n```\n\n`parsearn()` can be used to get a single component from an arn. `parsearn()`\nwill correctly deal with both literal arns and deploy-time values (tokens),\nbut in case of a deploy-time value be aware that the result will be another\ndeploy-time value which cannot be inspected in the cdk application.\n\n```python\n# stack: stack\n\n\n# extracts the function name out of an aws lambda function arn\narn_components = stack.parse_arn(arn, \":\")\nfunction_name = arn_components.resource_name\n```\n\nnote that depending on the service, the resource separator can be either\n`:` or `/`, and the resource name can be either the 6th or 7th\ncomponent in the arn. when using these functions, you will need to know\nthe format of the arn you are dealing with.\n\nfor an exhaustive list of arn formats used in aws, see [aws arns and\nnamespaces](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html)\nin the aws general reference.\n\n## dependencies\n\n### construct dependencies\n\nsometimes aws resources depend on other resources, and the creation of one\nresource must be completed before the next one can be started.\n\nin general, cloudformation will correctly infer the dependency relationship\nbetween resources based on the property values that are used. in the cases where\nit doesn't, the aws construct library will add the dependency relationship for\nyou.\n\nif you need to add an ordering dependency that is not automatically inferred,\nyou do so by adding a dependency relationship using\n`constructa.node.adddependency(constructb)`. this will add a dependency\nrelationship between all resources in the scope of `constructa` and all\nresources in the scope of `constructb`.\n\nif you want a single object to represent a set of constructs that are not\nnecessarily in the same scope, you can use a `dependencygroup`. the\nfollowing creates a single object that represents a dependency on two\nconstructs, `constructb` and `constructc`:\n\n```python\n# declare the dependable object\nb_and_c = dependencygroup()\nb_and_c.add(construct_b)\nb_and_c.add(construct_c)\n\n# take the dependency\nconstruct_a.node.add_dependency(b_and_c)\n```\n\n### stack dependencies\n\ntwo different stack instances can have a dependency on one another. this\nhappens when an resource from one stack is referenced in another stack. in\nthat case, cdk records the cross-stack referencing of resources,\nautomatically produces the right cloudformation primitives, and adds a\ndependency between the two stacks. you can also manually add a dependency\nbetween two stacks by using the `stacka.adddependency(stackb)` method.\n\na stack dependency has the following implications:\n\n* cyclic dependencies are not allowed, so if `stacka` is using resources from\n  `stackb`, the reverse is not possible anymore.\n* stacks with dependencies between them are treated specially by the cdk\n  toolkit:\n\n  * if `stacka` depends on `stackb`, running `cdk deploy stacka` will also\n    automatically deploy `stackb`.\n  * `stackb`'s deployment will be performed *before* `stacka`'s deployment.\n\n### cfnresource dependencies\n\nto make declaring dependencies between `cfnresource` objects easier, you can declare dependencies from one `cfnresource` object on another by using the `cfnresource1.adddependency(cfnresource2)` method. this method will work for resources both within the same stack and across stacks as it detects the relative location of the two resources and adds the dependency either to the resource or between the relevant stacks, as appropriate. if more complex logic is in needed, you can similarly remove, replace, or view dependencies between `cfnresource` objects with the `cfnresource` `removedependency`, `replacedependency`, and `obtaindependencies` methods, respectively.\n\n## custom resources\n\ncustom resources are cloudformation resources that are implemented by arbitrary\nuser code. they can do arbitrary lookups or modifications during a\ncloudformation deployment.\n\ncustom resources are backed by *custom resource providers*. commonly, these are\nlambda functions that are deployed in the same deployment as the one that\ndefines the custom resource itself, but they can also be backed by lambda\nfunctions deployed previously, or code responding to sns topic events running on\nec2 instances in a completely different account. for more information on custom\nresource providers, see the next section.\n\nonce you have a provider, each definition of a `customresource` construct\nrepresents one invocation. a single provider can be used for the implementation\nof arbitrarily many custom resource definitions. a single definition looks like\nthis:\n\n```python\ncustomresource(self, \"mymagicalresource\",\n    resource_type=\"custom::mycustomresource\",  # must start with 'custom::'\n\n    # the resource properties\n    properties={\n        \"property1\": \"foo\",\n        \"property2\": \"bar\"\n    },\n\n    # the arn of the provider (sns/lambda) which handles\n    # create, update or delete events for this resource type\n    # see next section for details\n    service_token=\"arn\"\n)\n```\n\n### custom resource providers\n\ncustom resources are backed by a **custom resource provider** which can be\nimplemented in one of the following ways. the following table compares the\nvarious provider types (ordered from low-level to high-level):\n\n| provider                                                             | compute type | error handling | submit to cloudformation |   max timeout   | language | footprint |\n| -------------------------------------------------------------------- | :----------: | :------------: | :----------------------: | :-------------: | :------: | :-------: |\n| [sns.topic](#amazon-sns-topic)                                       | self-managed |     manual     |          manual          |    unlimited    |   any    |  depends  |\n| [lambda.function](#aws-lambda-function)                              |  aws lambda  |     manual     |          manual          |      15min      |   any    |   small   |\n| [core.customresourceprovider](#the-corecustomresourceprovider-class) |  aws lambda  |      auto      |           auto           |      15min      | node.js  |   small   |\n| [custom-resources.provider](#the-custom-resource-provider-framework) |  aws lambda  |      auto      |           auto           | unlimited async |   any    |   large   |\n\nlegend:\n\n* **compute type**: which type of compute can be used to execute the handler.\n* **error handling**: whether errors thrown by handler code are automatically\n  trapped and a failed response is submitted to cloudformation. if this is\n  \"manual\", developers must take care of trapping errors. otherwise, events\n  could cause stacks to hang.\n* **submit to cloudformation**: whether the framework takes care of submitting\n  success/failed responses to cloudformation through the event's response url.\n* **max timeout**: maximum allows/possible timeout.\n* **language**: which programming languages can be used to implement handlers.\n* **footprint**: how many resources are used by the provider framework itself.\n\n**a note about singletons**\n\nwhen defining resources for a custom resource provider, you will likely want to\ndefine them as a *stack singleton* so that only a single instance of the\nprovider is created in your stack and which is used by all custom resources of\nthat type.\n\nhere is a basic pattern for defining stack singletons in the cdk. the following\nexamples ensures that only a single sns topic is defined:\n\n```python\ndef get_or_create(self, scope):\n    stack = stack.of(scope)\n    uniqueid = \"globallyuniqueidforsingleton\" # for example, a uuid from `uuidgen`\n    existing = stack.node.try_find_child(uniqueid)\n    if existing:\n        return existing\n    return sns.topic(stack, uniqueid)\n```\n\n#### amazon sns topic\n\nevery time a resource event occurs (create/update/delete), an sns notification\nis sent to the sns topic. users must process these notifications (e.g. through a\nfleet of worker hosts) and submit success/failure responses to the\ncloudformation service.\n\n> you only need to use this type of provider if your custom resource cannot run on aws lambda, for reasons other than the 15\n> minute timeout. if you are considering using this type of provider because you want to write a custom resource provider that may need\n> to wait for more than 15 minutes for the api calls to stabilize, have a look at the [`custom-resources`](#the-custom-resource-provider-framework) module first.\n>\n> refer to the [cloudformation custom resource documentation](https://docs.aws.amazon.com/awscloudformation/latest/userguide/template-custom-resources.html) for information on the contract your custom resource needs to adhere to.\n\nset `servicetoken` to `topic.topicarn`  in order to use this provider:\n\n```python\ntopic = sns.topic(self, \"myprovider\")\n\ncustomresource(self, \"myresource\",\n    service_token=topic.topic_arn\n)\n```\n\n#### aws lambda function\n\nan aws lambda function is called *directly* by cloudformation for all resource\nevents. the handler must take care of explicitly submitting a success/failure\nresponse to the cloudformation service and handle various error cases.\n\n> **we do not recommend you use this provider type.** the cdk has wrappers around lambda functions that make them easier to work with.\n>\n> if you do want to use this provider, refer to the [cloudformation custom resource documentation](https://docs.aws.amazon.com/awscloudformation/latest/userguide/template-custom-resources.html) for information on the contract your custom resource needs to adhere to.\n\nset `servicetoken` to `lambda.functionarn` to use this provider:\n\n```python\nfn = lambda_.function(self, \"myprovider\", function_props)\n\ncustomresource(self, \"myresource\",\n    service_token=fn.function_arn\n)\n```\n\n#### the `core.customresourceprovider` class\n\nthe class [`@aws-cdk/core.customresourceprovider`](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_core.customresourceprovider.html) offers a basic low-level\nframework designed to implement simple and slim custom resource providers. it\ncurrently only supports node.js-based user handlers, represents permissions as raw\njson blobs instead of `iam.policystatement` objects, and it does not have\nsupport for asynchronous waiting (handler cannot exceed the 15min lambda\ntimeout).\n\n> **as an application builder, we do not recommend you use this provider type.** this provider exists purely for custom resources that are part of the aws construct library.\n>\n> the [`custom-resources`](#the-custom-resource-provider-framework) provider is more convenient to work with and more fully-featured.\n\nthe provider has a built-in singleton method which uses the resource type as a\nstack-unique identifier and returns the service token:\n\n```python\nservice_token = customresourceprovider.get_or_create(self, \"custom::mycustomresourcetype\",\n    code_directory=f\"{__dirname}/my-handler\",\n    runtime=customresourceproviderruntime.nodejs_18_x,\n    description=\"lambda function created by the custom resource provider\"\n)\n\ncustomresource(self, \"myresource\",\n    resource_type=\"custom::mycustomresourcetype\",\n    service_token=service_token\n)\n```\n\nthe directory (`my-handler` in the above example) must include an `index.js` file. it cannot import\nexternal dependencies or files outside this directory. it must export an async\nfunction named `handler`. this function accepts the cloudformation resource\nevent object and returns an object with the following structure:\n\n```js\nexports.handler = async function(event) {\n  const id = event.physicalresourceid; // only for \"update\" and \"delete\"\n  const props = event.resourceproperties;\n  const oldprops = event.oldresourceproperties; // only for \"update\"s\n\n  switch (event.requesttype) {\n    case \"create\":\n      // ...\n\n    case \"update\":\n      // ...\n\n      // if an error is thrown, a failed response will be submitted to cfn\n      throw new error('failed!');\n\n    case \"delete\":\n      // ...\n  }\n\n  return {\n    // (optional) the value resolved from `resource.ref`\n    // defaults to \"event.physicalresourceid\" or \"event.requestid\"\n    physicalresourceid: \"ref\",\n\n    // (optional) calling `resource.getatt(\"att1\")` on the custom resource in the cdk app\n    // will return the value \"bar\".\n    data: {\n      att1: \"bar\",\n      att2: \"baz\"\n    },\n\n    // (optional) user-visible message\n    reason: \"user-visible message\",\n\n    // (optional) hides values from the console\n    noecho: true\n  };\n}\n```\n\nhere is an complete example of a custom resource that summarizes two numbers:\n\n`sum-handler/index.js`:\n\n```js\nexports.handler = async (e) => {\n  return {\n    data: {\n      result: e.resourceproperties.lhs + e.resourceproperties.rhs,\n    },\n  };\n};\n```\n\n`sum.ts`:\n\n```python\nfrom constructs import construct\nfrom aws_cdk import customresource, customresourceprovider, customresourceproviderruntime, token\n\nclass sum(construct):\n\n    def __init__(self, scope, id, *, lhs, rhs):\n        super().__init__(scope, id)\n\n        resource_type = \"custom::sum\"\n        service_token = customresourceprovider.get_or_create(self, resource_type,\n            code_directory=f\"{__dirname}/sum-handler\",\n            runtime=customresourceproviderruntime.nodejs_18_x\n        )\n\n        resource = customresource(self, \"resource\",\n            resource_type=resource_type,\n            service_token=service_token,\n            properties={\n                \"lhs\": lhs,\n                \"rhs\": rhs\n            }\n        )\n\n        self.result = token.as_number(resource.get_att(\"result\"))\n```\n\nusage will look like this:\n\n```python\nsum = sum(self, \"mysum\", lhs=40, rhs=2)\ncfnoutput(self, \"result\", value=token.as_string(sum.result))\n```\n\nto access the arn of the provider's aws lambda function role, use the `getorcreateprovider()`\nbuilt-in singleton method:\n\n```python\nprovider = customresourceprovider.get_or_create_provider(self, \"custom::mycustomresourcetype\",\n    code_directory=f\"{__dirname}/my-handler\",\n    runtime=customresourceproviderruntime.nodejs_18_x\n)\n\nrole_arn = provider.role_arn\n```\n\nthis role arn can then be used in resource-based iam policies.\n\nto add iam policy statements to this role, use `addtorolepolicy()`:\n\n```python\nprovider = customresourceprovider.get_or_create_provider(self, \"custom::mycustomresourcetype\",\n    code_directory=f\"{__dirname}/my-handler\",\n    runtime=customresourceproviderruntime.nodejs_18_x\n)\nprovider.add_to_role_policy({\n    \"effect\": \"allow\",\n    \"action\": \"s3:getobject\",\n    \"resource\": \"*\"\n})\n```\n\nnote that `addtorolepolicy()` uses direct iam json policy blobs, *not* a\n`iam.policystatement` object like you will see in the rest of the cdk.\n\n#### the custom resource provider framework\n\nthe [`@aws-cdk/custom-resources`](https://docs.aws.amazon.com/cdk/api/latest/docs/custom-resources-readme.html) module includes an advanced framework for\nimplementing custom resource providers.\n\nhandlers are implemented as aws lambda functions, which means that they can be\nimplemented in any lambda-supported runtime. furthermore, this provider has an\nasynchronous mode, which means that users can provide an `iscomplete` lambda\nfunction which is called periodically until the operation is complete. this\nallows implementing providers that can take up to two hours to stabilize.\n\nset `servicetoken` to `provider.servicetoken` to use this type of provider:\n\n```python\nprovider = customresources.provider(self, \"myprovider\",\n    on_event_handler=on_event_handler,\n    is_complete_handler=is_complete_handler\n)\n\ncustomresource(self, \"myresource\",\n    service_token=provider.service_token\n)\n```\n\nsee the [documentation](https://docs.aws.amazon.com/cdk/api/latest/docs/aws-cdk-lib.custom_resources-readme.html) for more details.\n\n## aws cloudformation features\n\na cdk stack synthesizes to an aws cloudformation template. this section\nexplains how this module allows users to access low-level cloudformation\nfeatures when needed.\n\n### stack outputs\n\ncloudformation [stack outputs](https://docs.aws.amazon.com/awscloudformation/latest/userguide/outputs-section-structure.html) and exports are created using\nthe `cfnoutput` class:\n\n```python\ncfnoutput(self, \"outputname\",\n    value=my_bucket.bucket_name,\n    description=\"the name of an s3 bucket\",  # optional\n    export_name=\"theawesomebucket\"\n)\n```\n\n### parameters\n\ncloudformation templates support the use of [parameters](https://docs.aws.amazon.com/awscloudformation/latest/userguide/parameters-section-structure.html) to\ncustomize a template. they enable cloudformation users to input custom values to\na template each time a stack is created or updated. while the cdk design\nphilosophy favors using build-time parameterization, users may need to use\ncloudformation in a number of cases (for example, when migrating an existing\nstack to the aws cdk).\n\ntemplate parameters can be added to a stack by using the `cfnparameter` class:\n\n```python\ncfnparameter(self, \"myparameter\",\n    type=\"number\",\n    default=1337\n)\n```\n\nthe value of parameters can then be obtained using one of the `value` methods.\nas parameters are only resolved at deployment time, the values obtained are\nplaceholder tokens for the real value (`token.isunresolved()` would return `true`\nfor those):\n\n```python\nparam = cfnparameter(self, \"parametername\")\n\n# if the parameter is a string\nparam.value_as_string\n\n# if the parameter is a number\nparam.value_as_number\n\n# if the parameter is a list\nparam.value_as_list\n```\n\n### pseudo parameters\n\ncloudformation supports a number of [pseudo parameters](https://docs.aws.amazon.com/awscloudformation/latest/userguide/pseudo-parameter-reference.html),\nwhich resolve to useful values at deployment time. cloudformation pseudo\nparameters can be obtained from static members of the `aws` class.\n\nit is generally recommended to access pseudo parameters from the scope's `stack`\ninstead, which guarantees the values produced are qualifying the designated\nstack, which is essential in cases where resources are shared cross-stack:\n\n```python\n# \"this\" is the current construct\nstack = stack.of(self)\n\nstack.account # returns the aws::accountid for this stack (or the literal value if known)\nstack.region # returns the aws::region for this stack (or the literal value if known)\nstack.partition\n```\n\n### resource options\n\ncloudformation resources can also specify [resource\nattributes](https://docs.aws.amazon.com/awscloudformation/latest/userguide/aws-product-attribute-reference.html). the `cfnresource` class allows\naccessing those through the `cfnoptions` property:\n\n```python\nraw_bucket = s3.cfnbucket(self, \"bucket\")\n# -or-\nraw_bucket_alt = my_bucket.node.default_child\n\n# then\nraw_bucket.cfn_options.condition = cfncondition(self, \"enablebucket\")\nraw_bucket.cfn_options.metadata = {\n    \"metadata_key\": \"metadatavalue\"\n}\n```\n\nresource dependencies (the `dependson` attribute) is modified using the\n`cfnresource.adddependency` method:\n\n```python\nresource_a = cfnresource(self, \"resourcea\", resource_props)\nresource_b = cfnresource(self, \"resourceb\", resource_props)\n\nresource_b.add_dependency(resource_a)\n```\n\n#### creationpolicy\n\nsome resources support a [creationpolicy](https://docs.aws.amazon.com/awscloudformation/latest/userguide/aws-attribute-creationpolicy.html) to be specified as a cfnoption.\n\nthe creation policy is invoked only when aws cloudformation creates the associated resource. currently, the only aws cloudformation resources that support creation policies are `cfnautoscalinggroup`, `cfninstance`, `cfnwaitcondition` and `cfnfleet`.\n\nthe `cfnfleet` resource from the `aws-appstream` module supports specifying `startfleet` as\na property of the creationpolicy on the resource options. setting it to true will make aws cloudformation wait until the fleet is started before continuing with the creation of\nresources that depend on the fleet resource.\n\n```python\nfleet = appstream.cfnfleet(self, \"fleet\",\n    instance_type=\"stream.standard.small\",\n    name=\"fleet\",\n    compute_capacity=appstream.cfnfleet.computecapacityproperty(\n        desired_instances=1\n    ),\n    image_name=\"appstream-amazonlinux2-09-21-2022\"\n)\nfleet.cfn_options.creation_policy = cfncreationpolicy(\n    start_fleet=true\n)\n```\n\nthe properties passed to the level 2 constructs `autoscalinggroup` and `instance` from the\n`aws-ec2` module abstract what is passed into the `cfnoption` properties `resourcesignal` and\n`autoscalingcreationpolicy`, but when using level 1 constructs you can specify these yourself.\n\nthe cfnwaitcondition resource from the `aws-cloudformation` module suppports the `resourcesignal`.\nthe format of the timeout is `pt#h#m#s`. in the example below aws cloudformation will wait for\n3 success signals to occur within 15 minutes before the status of the resource will be set to\n`create_complete`.\n\n```python\n# resource: cfnresource\n\n\nresource.cfn_options.creation_policy = cfncreationpolicy(\n    resource_signal=cfnresourcesignal(\n        count=3,\n        timeout=\"pr15m\"\n    )\n)\n```\n\n### intrinsic functions and condition expressions\n\ncloudformation supports [intrinsic functions](https://docs.aws.amazon.com/awscloudformation/latest/userguide/intrinsic-function-reference.html). these functions\ncan be accessed from the `fn` class, which provides type-safe methods for each\nintrinsic function as well as condition expressions:\n\n```python\n# my_object_or_array: any\n# my_array: any\n\n\n# to use fn::base64\nfn.base64(\"sgvsbg8gq0rliqo=\")\n\n# to compose condition expressions:\nenvironment_parameter = cfnparameter(self, \"environment\")\nfn.condition_and(\n    # the \"environment\" cloudformation template parameter evaluates to \"production\"\n    fn.condition_equals(\"production\", environment_parameter),\n    # the aws::region pseudo-parameter value is not equal to \"us-east-1\"\n    fn.condition_not(fn.condition_equals(\"us-east-1\", aws.region)))\n\n# to use fn::tojsonstring\nfn.to_json_string(my_object_or_array)\n\n# to use fn::length\nfn.len(fn.split(\",\", my_array))\n```\n\nwhen working with deploy-time values (those for which `token.isunresolved`\nreturns `true`), idiomatic conditionals from the programming language cannot be\nused (the value will not be known until deployment time). when conditional logic\nneeds to be expressed with un-resolved values, it is necessary to use\ncloudformation conditions by means of the `cfncondition` class:\n\n```python\nenvironment_parameter = cfnparameter(self, \"environment\")\nis_prod = cfncondition(self, \"isproduction\",\n    expression=fn.condition_equals(\"production\", environment_parameter)\n)\n\n# configuration value that is a different string based on isproduction\nstage = fn.condition_if(is_prod.logical_id, \"beta\", \"prod\").to_string()\n\n# make bucket creation condition to isproduction by accessing\n# and overriding the cloudformation resource\nbucket = s3.bucket(self, \"bucket\")\ncfn_bucket = my_bucket.node.default_child\ncfn_bucket.cfn_options.condition = is_prod\n```\n\n### mappings\n\ncloudformation [mappings](https://docs.aws.amazon.com/awscloudformation/latest/userguide/mappings-section-structure.html) are created and queried using the\n`cfnmappings` class:\n\n```python\nregion_table = cfnmapping(self, \"regiontable\",\n    mapping={\n        \"us-east-1\": {\n            \"region_name\": \"us east (n. virginia)\"\n        },\n        \"us-east-2\": {\n            \"region_name\": \"us east (ohio)\"\n        }\n    }\n)\n\nregion_table.find_in_map(aws.region, \"regionname\")\n```\n\nthis will yield the following template:\n\n```yaml\nmappings:\n  regiontable:\n    us-east-1:\n      regionname: us east (n. virginia)\n    us-east-2:\n      regionname: us east (ohio)\n```\n\nmappings can also be synthesized \"lazily\"; lazy mappings will only render a \"mappings\"\nsection in the synthesized cloudformation template if some `findinmap` call is unable to\nimmediately return a concrete value due to one or both of the keys being unresolved tokens\n(some value only available at deploy-time).\n\nfor example, the following code will not produce anything in the \"mappings\" section. the\ncall to `findinmap` will be able to resolve the value during synthesis and simply return\n`'us east (ohio)'`.\n\n```python\nregion_table = cfnmapping(self, \"regiontable\",\n    mapping={\n        \"us-east-1\": {\n            \"region_name\": \"us east (n. virginia)\"\n        },\n        \"us-east-2\": {\n            \"region_name\": \"us east (ohio)\"\n        }\n    },\n    lazy=true\n)\n\nregion_table.find_in_map(\"us-east-2\", \"regionname\")\n```\n\non the other hand, the following code will produce the \"mappings\" section shown above,\nsince the top-level key is an unresolved token. the call to `findinmap` will return a token that resolves to\n`{ \"fn::findinmap\": [ \"regiontable\", { \"ref\": \"aws::region\" }, \"regionname\" ] }`.\n\n```python\n# region_table: cfnmapping\n\n\nregion_table.find_in_map(aws.region, \"regionname\")\n```\n\n### dynamic references\n\ncloudformation supports [dynamically resolving](https://docs.aws.amazon.com/awscloudformation/latest/userguide/dynamic-references.html) values\nfor ssm parameters (including secure strings) and secrets manager. encoding such\nreferences is done using the `cfndynamicreference` class:\n\n```python\ncfndynamicreference(cfndynamicreferenceservice.secrets_manager, \"secret-id:secret-string:json-key:version-stage:version-id\")\n```\n\n### template options & transform\n\ncloudformation templates support a number of options, including which macros or\n[transforms](https://docs.aws.amazon.com/awscloudformation/latest/userguide/transform-section-structure.html) to use when deploying the stack. those can be\nconfigured using the `stack.templateoptions` property:\n\n```python\nstack = stack(app, \"stackname\")\n\nstack.template_options.description = \"this will appear in the aws console\"\nstack.template_options.transforms = [\"aws::serverless-2016-10-31\"]\nstack.template_options.metadata = {\n    \"metadata_key\": \"metadatavalue\"\n}\n```\n\n### emitting raw resources\n\nthe `cfnresource` class allows emitting arbitrary entries in the\n[resources](https://docs.aws.amazon.com/awscloudformation/latest/userguide/resources-section-structure.html) section of the cloudformation template.\n\n```python\ncfnresource(self, \"resourceid\",\n    type=\"aws::s3::bucket\",\n    properties={\n        \"bucketname\": \"bucket-name\"\n    }\n)\n```\n\nas for any other resource, the logical id in the cloudformation template will be\ngenerated by the aws cdk, but the type and properties will be copied verbatim in\nthe synthesized template.\n\n### including raw cloudformation template fragments\n\nwhen migrating a cloudformation stack to the aws cdk, it can be useful to\ninclude fragments of an existing template verbatim in the synthesized template.\nthis can be achieved using the `cfninclude` class.\n\n```python\ncfninclude(self, \"id\",\n    template={\n        \"resources\": {\n            \"bucket\": {\n                \"type\": \"aws::s3::bucket\",\n                \"properties\": {\n                    \"bucketname\": \"my-shiny-bucket\"\n                }\n            }\n        }\n    }\n)\n```\n\n### termination protection\n\nyou can prevent a stack from being accidentally deleted by enabling termination\nprotection on the stack. if a user attempts to delete a stack with termination\nprotection enabled, the deletion fails and the stack--including its status--remains\nunchanged. enabling or disabling termination protection on a stack sets it for any\nnested stacks belonging to that stack as well. you can enable termination protection\non a stack by setting the `terminationprotection` prop to `true`.\n\n```python\nstack = stack(app, \"stackname\",\n    termination_protection=true\n)\n```\n\nby default, termination protection is disabled.\n\n### description\n\nyou can add a description of the stack in the same way as `stackprops`.\n\n```python\nstack = stack(app, \"stackname\",\n    description=\"this is a description.\"\n)\n```\n\n### cfnjson\n\n`cfnjson` allows you to postpone the resolution of a json blob from\ndeployment-time. this is useful in cases where the cloudformation json template\ncannot express a certain value.\n\na common example is to use `cfnjson` in order to render a json map which needs\nto use intrinsic functions in keys. since json map keys must be strings, it is\nimpossible to use intrinsics in keys and `cfnjson` can help.\n\nthe following example defines an iam role which can only be assumed by\nprincipals that are tagged with a specific tag.\n\n```python\ntag_param = cfnparameter(self, \"tagname\")\n\nstring_equals = cfnjson(self, \"conditionjson\",\n    value={\n        \"f\"aws:principaltag/{tagparam.valueasstring}\"\": true\n    }\n)\n\nprincipal = iam.accountrootprincipal().with_conditions({\n    \"stringequals\": string_equals\n})\n\niam.role(self, \"myrole\", assumed_by=principal)\n```\n\n**explanation**: since in this example we pass the tag name through a parameter, it\ncan only be resolved during deployment. the resolved value can be represented in\nthe template through a `{ \"ref\": \"tagname\" }`. however, since we want to use\nthis value inside a [`aws:principaltag/tag-name`](https://docs.aws.amazon.com/iam/latest/userguide/reference_policies_condition-keys.html#condition-keys-principaltag)\niam operator, we need it in the *key* of a `stringequals` condition. json keys\n*must be* strings, so to circumvent this limitation, we use `cfnjson`\nto \"delay\" the rendition of this template section to deploy-time. this means\nthat the value of `stringequals` in the template will be `{ \"fn::getatt\": [ \"conditionjson\", \"value\" ] }`, and will only \"expand\" to the operator we synthesized during deployment.\n\n### stack resource limit\n\nwhen deploying to aws cloudformation, it needs to keep in check the amount of resources being added inside a stack. currently it's possible to check the limits in the [aws cloudformation quotas](https://docs.aws.amazon.com/awscloudformation/latest/userguide/cloudformation-limits.html) page.\n\nit's possible to synthesize the project with more resources than the allowed (or even reduce the number of resources).\n\nset the context key `@aws-cdk/core:stackresourcelimit` with the proper value, being 0 for disable the limit of resources.\n\n## app context\n\n[context values](https://docs.aws.amazon.com/cdk/v2/guide/context.html) are key-value pairs that can be associated with an app, stack, or construct.\none common use case for context is to use it for enabling/disabling [feature flags](https://docs.aws.amazon.com/cdk/v2/guide/featureflags.html). there are several places\nwhere context can be specified. they are listed below in the order they are evaluated (items at the\ntop take precedence over those below).\n\n* the `node.setcontext()` method\n* the `postclicontext` prop when you create an `app`\n* the cli via the `--context` cli argument\n* the `cdk.json` file via the `context` key:\n* the `cdk.context.json` file:\n* the `~/.cdk.json` file via the `context` key:\n* the `context` prop when you create an `app`\n\n### examples of setting context\n\n```python\napp(\n    context={\n        \"@aws-cdk/core:newstylestacksynthesis\": true\n    }\n)\n```\n\n```python\napp = app()\napp.node.set_context(\"@aws-cdk/core:newstylestacksynthesis\", true)\n```\n\n```python\napp(\n    post_cli_context={\n        \"@aws-cdk/core:newstylestacksynthesis\": true\n    }\n)\n```\n\n```console\ncdk synth --context @aws-cdk/core:newstylestacksynthesis=true\n```\n\n*cdk.json*\n\n```json\n{\n  \"context\": {\n    \"@aws-cdk/core:newstylestacksynthesis\": true\n  }\n}\n```\n\n*cdk.context.json*\n\n```json\n{\n  \"@aws-cdk/core:newstylestacksynthesis\": true\n}\n```\n\n*~/.cdk.json*\n\n```json\n{\n  \"context\": {\n    \"@aws-cdk/core:newstylestacksynthesis\": true\n  }\n}\n```\n\n## iam permissions boundary\n\nit is possible to apply an [iam permissions boundary](https://docs.aws.amazon.com/iam/latest/userguide/access_policies_boundaries.html)\nto all roles within a specific construct scope. the most common use case would\nbe to apply a permissions boundary at the `stage` level.\n\n```python\nprod_stage = stage(app, \"prodstage\",\n    permissions_boundary=permissionsboundary.from_name(\"cdk-${qualifier}-permissionsboundary\")\n)\n```\n\nany iam roles or users created within this stage will have the default\npermissions boundary attached.\n\nfor more details see the [permissions boundary](https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_iam-readme.html#permissions-boundaries) section in the iam guide.\n\n## policy validation\n\nif you or your organization use (or would like to use) any policy validation tool, such as\n[cloudformation\nguard](https://docs.aws.amazon.com/cfn-guard/latest/ug/what-is-guard.html) or\n[opa](https://www.openpolicyagent.org/), to define constraints on your\ncloudformation template, you can incorporate them into the cdk application.\nby using the appropriate plugin, you can make the cdk application check the\ngenerated cloudformation templates against your policies immediately after\nsynthesis. if there are any violations, the synthesis will fail and a report\nwill be printed to the console or to a file (see below).\n\n> **note**\n> this feature is considered experimental, and both the plugin api and the\n> format of the validation report are subject to change in the future.\n\n### for application developers\n\nto use one or more validation plugins in your application, use the\n`policyvalidationbeta1` property of `stage`:\n\n```python\n# globally for the entire app (an app is a stage)\napp = app(\n    policy_validation_beta1=[\n        # these hypothetical classes implement ipolicyvalidationpluginbeta1:\n        thirdpartypluginx(),\n        thirdpartypluginy()\n    ]\n)\n\n# only apply to a particular stage\nprod_stage = stage(app, \"prodstage\",\n    policy_validation_beta1=[\n        thirdpartypluginx()\n    ]\n)\n```\n\nimmediately after synthesis, all plugins registered this way will be invoked to\nvalidate all the templates generated in the scope you defined. in particular, if\nyou register the templates in the `app` object, all templates will be subject to\nvalidation.\n\n> **warning**\n> other than modifying the cloud assembly, plugins can do anything that your cdk\n> application can. they can read data from the filesystem, access the network\n> etc. it's your responsibility as the consumer of a plugin to verify that it is\n> secure to use.\n\nby default, the report will be printed in a human readable format. if you want a\nreport in json format, enable it using the `@aws-cdk/core:validationreportjson`\ncontext passing it directly to the application:\n\n```python\napp = app(\n    context={\"@aws-cdk/core:validationreportjson\": true}\n)\n```\n\nalternatively, you can set this context key-value pair using the `cdk.json` or\n`cdk.context.json` files in your project directory (see\n[runtime context](https://docs.aws.amazon.com/cdk/v2/guide/context.html)).\n\nif you choose the json format, the cdk will print the policy validation report\nto a file called `policy-validation-report.json` in the cloud assembly\ndirectory. for the default, human-readable format, the report will be printed to\nthe standard output.\n\n### for plugin authors\n\nthe communication protocol between the cdk core module and your policy tool is\ndefined by the `ipolicyvalidationpluginbeta1` interface. to create a new plugin you must\nwrite a class that implements this interface. there are two things you need to\nimplement: the plugin name (by overriding the `name` property), and the\n`validate()` method.\n\nthe framework will call `validate()`, passing an `ipolicyvalidationcontextbeta1` object.\nthe location of the templates to be validated is given by `templatepaths`. the\nplugin should return an instance of `policyvalidationpluginreportbeta1`. this object\nrepresents the report that the user wil receive at the end of the synthesis.\n\n```python\n@jsii.implements(ipolicyvalidationpluginbeta1)\nclass myplugin:\n\n    def validate(self, context):\n        # first read the templates using context.templatepaths...\n\n        # ...then perform the validation, and then compose and return the report.\n        # using hard-coded values here for better clarity:\n        return policyvalidationpluginreportbeta1(\n            success=false,\n            violations=[policyviolationbeta1(\n                rule_name=\"ckv_aws_117\",\n                description=\"ensure that aws lambda function is configured inside a vpc\",\n                fix=\"https://docs.bridgecrew.io/docs/ensure-that-aws-lambda-function-is-configured-inside-a-vpc-1\",\n                violating_resources=[policyviolatingresourcebeta1(\n                    resource_logical_id=\"myfunction3baa72d1\",\n                    template_path=\"/home/johndoe/myapp/cdk.out/myservice.template.json\",\n                    locations=[\"properties/vpcconfig\"]\n                )]\n            )]\n        )\n```\n\nnote that plugins are not allowed to modify anything in the cloud assembly. any\nattempt to do so will result in synthesis failure.\n\nif your plugin depends on an external tool, keep in mind that some developers may\nnot have that tool installed in their workstations yet. to minimize friction, we\nhighly recommend that you provide some installation script along with your\nplugin package, to automate the whole process. better yet, run that script as\npart of the installation of your package. with `npm`, for example, you can run\nadd it to the `postinstall`\n[script](https://docs.npmjs.com/cli/v9/using-npm/scripts) in the `package.json`\nfile.\n\n<!--end core documentation-->\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache-2.0",
  "name": "aws-cdk-lib",
  "package_url": "https://pypi.org/project/aws-cdk-lib/",
  "project_url": "https://pypi.org/project/aws-cdk-lib/",
  "project_urls": {
    "Homepage": "https://github.com/aws/aws-cdk",
    "Source": "https://github.com/aws/aws-cdk.git"
  },
  "release_url": "https://pypi.org/project/aws-cdk-lib/2.116.1/",
  "requires_dist": [
    "aws-cdk.asset-awscli-v1 <3.0.0,>=2.2.201",
    "aws-cdk.asset-kubectl-v20 <3.0.0,>=2.1.2",
    "aws-cdk.asset-node-proxy-agent-v6 <3.0.0,>=2.0.1",
    "constructs <11.0.0,>=10.0.0",
    "jsii <2.0.0,>=1.93.0",
    "publication >=0.0.3",
    "typeguard ~=2.13.3"
  ],
  "requires_python": "~=3.8",
  "summary": "version 2 of the aws cloud development kit library",
  "version": "2.116.1",
  "releases": [],
  "developers": [
    "amazon_web_services"
  ],
  "kwds": "aws_cdk cdk_core cdk dependencies aws_iam",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_aws_cdk_lib",
  "homepage": "https://github.com/aws/aws-cdk",
  "release_count": 203,
  "dependency_ids": [
    "pypi_aws_cdk.asset_awscli_v1",
    "pypi_aws_cdk.asset_kubectl_v20",
    "pypi_aws_cdk.asset_node_proxy_agent_v6",
    "pypi_constructs",
    "pypi_jsii",
    "pypi_publication",
    "pypi_typeguard"
  ]
}