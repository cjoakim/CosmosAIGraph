{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "intended audience :: science/research",
    "license :: osi approved :: gnu general public license (gpl)",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "topic :: education",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "<div align=\"center\">\n  <p>\n    <a align=\"center\" href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n      <img width=\"850\" src=\"https://github.com/ultralytics/assets/blob/master/yolov5/v62/splash_readme.png\"></a>\n  </p>\n\n  english | [\u7b80\u4f53\u4e2d\u6587](.github/readme_cn.md)\n  <br>\n  <div>\n    <a href=\"https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml\"><img src=\"https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg\" alt=\"yolov5 ci\"></a>\n    <a href=\"https://zenodo.org/badge/latestdoi/264818686\"><img src=\"https://zenodo.org/badge/264818686.svg\" alt=\"yolov5 citation\"></a>\n    <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"docker pulls\"></a>\n    <br>\n    <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"run on gradient\"></a>\n    <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"open in colab\"></a>\n    <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"open in kaggle\"></a>\n  </div>\n\n  <br>\n  <p>\n    yolov5 \ud83d\ude80 is the world's most loved vision ai, representing <a href=\"https://ultralytics.com\">ultralytics</a>\n    open-source research into future vision ai methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.\n    <br><br>\n    to request a commercial license please complete the form at <a href=\"https://ultralytics.com/license\">ultralytics licensing</a>.\n    <br><br>\n  </p>\n\n  <div align=\"center\">\n    <a href=\"https://github.com/ultralytics\" style=\"text-decoration:none;\">\n      <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-github.png\" width=\"2%\" alt=\"\" /></a>\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"2%\" alt=\"\" />\n    <a href=\"https://www.linkedin.com/company/ultralytics\" style=\"text-decoration:none;\">\n      <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-linkedin.png\" width=\"2%\" alt=\"\" /></a>\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"2%\" alt=\"\" />\n    <a href=\"https://twitter.com/ultralytics\" style=\"text-decoration:none;\">\n      <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-twitter.png\" width=\"2%\" alt=\"\" /></a>\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"2%\" alt=\"\" />\n    <a href=\"https://www.producthunt.com/@glenn_jocher\" style=\"text-decoration:none;\">\n      <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-producthunt.png\" width=\"2%\" alt=\"\" /></a>\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"2%\" alt=\"\" />\n    <a href=\"https://youtube.com/ultralytics\" style=\"text-decoration:none;\">\n      <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-youtube.png\" width=\"2%\" alt=\"\" /></a>\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"2%\" alt=\"\" />\n    <a href=\"https://www.facebook.com/ultralytics\" style=\"text-decoration:none;\">\n      <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-facebook.png\" width=\"2%\" alt=\"\" /></a>\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"2%\" alt=\"\" />\n    <a href=\"https://www.instagram.com/ultralytics/\" style=\"text-decoration:none;\">\n      <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-instagram.png\" width=\"2%\" alt=\"\" /></a>\n  </div>\n</div>\n\n\n## <div align=\"center\">documentation</div>\n\nsee the [yolov5 docs](https://docs.ultralytics.com) for full documentation on training, testing and deployment.\n\n## <div align=\"center\">quick start examples</div>\n\n<details open>\n<summary>install</summary>\n\nclone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a\n[**python>=3.7.0**](https://www.python.org/) environment, including\n[**pytorch>=1.7**](https://pytorch.org/get-started/locally/).\n\n```bash\ngit clone https://github.com/ultralytics/yolov5  # clone\ncd yolov5\npip install -r requirements.txt  # install\n```\n\n</details>\n\n<details open>\n<summary>inference</summary>\n\nyolov5 [pytorch hub](https://github.com/ultralytics/yolov5/issues/36) inference. [models](https://github.com/ultralytics/yolov5/tree/master/models) download automatically from the latest\nyolov5 [release](https://github.com/ultralytics/yolov5/releases).\n\n```python\nimport torch\n\n# model\nmodel = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom\n\n# images\nimg = 'https://ultralytics.com/images/zidane.jpg'  # or file, path, pil, opencv, numpy, list\n\n# inference\nresults = model(img)\n\n# results\nresults.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n```\n\n</details>\n\n<details>\n<summary>inference with detect.py</summary>\n\n`detect.py` runs inference on a variety of sources, downloading [models](https://github.com/ultralytics/yolov5/tree/master/models) automatically from\nthe latest yolov5 [release](https://github.com/ultralytics/yolov5/releases) and saving results to `runs/detect`.\n\n```bash\npython detect.py --source 0  # webcam\n                          img.jpg  # image\n                          vid.mp4  # video\n                          screen  # screenshot\n                          path/  # directory\n                          'path/*.jpg'  # glob\n                          'https://youtu.be/zgi9g1ksqhc'  # youtube\n                          'rtsp://example.com/media.mp4'  # rtsp, rtmp, http stream\n```\n\n</details>\n\n<details>\n<summary>training</summary>\n\nthe commands below reproduce yolov5 [coco](https://github.com/ultralytics/yolov5/blob/master/data/scripts/get_coco.sh)\nresults. [models](https://github.com/ultralytics/yolov5/tree/master/models)\nand [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest\nyolov5 [release](https://github.com/ultralytics/yolov5/releases). training times for yolov5n/s/m/l/x are\n1/2/4/6/8 days on a v100 gpu ([multi-gpu](https://github.com/ultralytics/yolov5/issues/475) times faster). use the\nlargest `--batch-size` possible, or pass `--batch-size -1` for\nyolov5 [autobatch](https://github.com/ultralytics/yolov5/pull/5092). batch sizes shown for v100-16gb.\n\n```bash\npython train.py --data coco.yaml --cfg yolov5n.yaml --weights '' --batch-size 128\n                                       yolov5s                                64\n                                       yolov5m                                40\n                                       yolov5l                                24\n                                       yolov5x                                16\n```\n\n<img width=\"800\" src=\"https://user-images.githubusercontent.com/26833433/90222759-949d8800-ddc1-11ea-9fa1-1c97eed2b963.png\">\n\n</details>\n\n<details open>\n<summary>tutorials</summary>\n\n- [train custom data](https://github.com/ultralytics/yolov5/wiki/train-custom-data)\u00a0 \ud83d\ude80 recommended\n- [tips for best training results](https://github.com/ultralytics/yolov5/wiki/tips-for-best-training-results)\u00a0 \u2618\ufe0f\n  recommended\n- [multi-gpu training](https://github.com/ultralytics/yolov5/issues/475)\n- [pytorch hub](https://github.com/ultralytics/yolov5/issues/36) \ud83c\udf1f new\n- [tflite, onnx, coreml, tensorrt export](https://github.com/ultralytics/yolov5/issues/251) \ud83d\ude80\n- [nvidia jetson nano deployment](https://github.com/ultralytics/yolov5/issues/9627) \ud83c\udf1f new\n- [test-time augmentation (tta)](https://github.com/ultralytics/yolov5/issues/303)\n- [model ensembling](https://github.com/ultralytics/yolov5/issues/318)\n- [model pruning/sparsity](https://github.com/ultralytics/yolov5/issues/304)\n- [hyperparameter evolution](https://github.com/ultralytics/yolov5/issues/607)\n- [transfer learning with frozen layers](https://github.com/ultralytics/yolov5/issues/1314)\n- [architecture summary](https://github.com/ultralytics/yolov5/issues/6998) \ud83c\udf1f new\n- [roboflow for datasets, labeling, and active learning](https://github.com/ultralytics/yolov5/issues/4975)\u00a0 \ud83c\udf1f new\n- [clearml logging](https://github.com/ultralytics/yolov5/tree/master/utils/loggers/clearml) \ud83c\udf1f new\n- [deci platform](https://github.com/ultralytics/yolov5/wiki/deci-platform) \ud83c\udf1f new\n- [comet logging](https://github.com/ultralytics/yolov5/tree/master/utils/loggers/comet) \ud83c\udf1f new\n\n</details>\n\n\n## <div align=\"center\">integrations</div>\n\n<img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/image-integrations-loop.png\" width=\"100%\" />\n\n<div align=\"center\">\n  <a href=\"https://roboflow.com/?ref=ultralytics\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-roboflow.png\" width=\"10%\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"15%\" height=\"0\" alt=\"\" />\n  <a href=\"https://cutt.ly/yolov5-readme-clearml\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-clearml.png\" width=\"10%\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"15%\" height=\"0\" alt=\"\" />\n  <a href=\"https://bit.ly/yolov5-readme-comet\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-comet.png\" width=\"10%\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"15%\" height=\"0\" alt=\"\" />\n  <a href=\"https://bit.ly/yolov5-deci-platform\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-deci.png\" width=\"10%\" /></a>\n</div>\n\n|roboflow|clearml \u2b50 new|comet \u2b50 new|deci \u2b50 new|\n|:-:|:-:|:-:|:-:|\n|label and export your custom datasets directly to yolov5 for training with [roboflow](https://roboflow.com/?ref=ultralytics)|automatically track, visualize and even remotely train yolov5 using [clearml](https://cutt.ly/yolov5-readme-clearml) (open-source!)|free forever, [comet](https://bit.ly/yolov5-readme-comet) lets you save yolov5 models, resume training, and interactively visualise and debug predictions|automatically compile and quantize yolov5 for better inference performance in one click at [deci](https://bit.ly/yolov5-deci-platform)|\n\n\n## <div align=\"center\">why yolov5</div>\n\nyolov5 has been designed to be super easy to get started and simple to learn. we prioritize real-world results.\n\n<p align=\"left\"><img width=\"800\" src=\"https://user-images.githubusercontent.com/26833433/155040763-93c22a27-347c-4e3c-847a-8094621d3f4e.png\"></p>\n<details>\n  <summary>yolov5-p5 640 figure (click to expand)</summary>\n\n<p align=\"left\"><img width=\"800\" src=\"https://user-images.githubusercontent.com/26833433/155040757-ce0934a3-06a6-43dc-a979-2edbbd69ea0e.png\"></p>\n</details>\n<details>\n  <summary>figure notes (click to expand)</summary>\n\n- **coco ap val** denotes map@0.5:0.95 metric measured on the 5000-image [coco val2017](http://cocodataset.org) dataset over various inference sizes from 256 to 1536.\n- **gpu speed** measures average inference time per image on [coco val2017](http://cocodataset.org) dataset using a [aws p3.2xlarge](https://aws.amazon.com/ec2/instance-types/p3/) v100 instance at batch-size 32.\n- **efficientdet** data from [google/automl](https://github.com/google/automl) at batch size 8.\n- **reproduce** by `python val.py --task study --data coco.yaml --iou 0.7 --weights yolov5n6.pt yolov5s6.pt yolov5m6.pt yolov5l6.pt yolov5x6.pt`\n\n</details>\n\n### pretrained checkpoints\n\n| model                                                                                                | size<br><sup>(pixels) | map<sup>val<br>0.5:0.95 | map<sup>val<br>0.5 | speed<br><sup>cpu b1<br>(ms) | speed<br><sup>v100 b1<br>(ms) | speed<br><sup>v100 b32<br>(ms) | params<br><sup>(m) | flops<br><sup>@640 (b) |\n|------------------------------------------------------------------------------------------------------|-----------------------|-------------------------|--------------------|------------------------------|-------------------------------|--------------------------------|--------------------|------------------------|\n| [yolov5n](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n.pt)                   | 640                   | 28.0                    | 45.7               | **45**                       | **6.3**                       | **0.6**                        | **1.9**            | **4.5**                |\n| [yolov5s](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt)                   | 640                   | 37.4                    | 56.8               | 98                           | 6.4                           | 0.9                            | 7.2                | 16.5                   |\n| [yolov5m](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m.pt)                   | 640                   | 45.4                    | 64.1               | 224                          | 8.2                           | 1.7                            | 21.2               | 49.0                   |\n| [yolov5l](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5l.pt)                   | 640                   | 49.0                    | 67.3               | 430                          | 10.1                          | 2.7                            | 46.5               | 109.1                  |\n| [yolov5x](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x.pt)                   | 640                   | 50.7                    | 68.9               | 766                          | 12.1                          | 4.8                            | 86.7               | 205.7                  |\n|                                                                                                      |                       |                         |                    |                              |                               |                                |                    |                        |\n| [yolov5n6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n6.pt)                 | 1280                  | 36.0                    | 54.4               | 153                          | 8.1                           | 2.1                            | 3.2                | 4.6                    |\n| [yolov5s6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s6.pt)                 | 1280                  | 44.8                    | 63.7               | 385                          | 8.2                           | 3.6                            | 12.6               | 16.8                   |\n| [yolov5m6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m6.pt)                 | 1280                  | 51.3                    | 69.3               | 887                          | 11.1                          | 6.8                            | 35.7               | 50.0                   |\n| [yolov5l6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5l6.pt)                 | 1280                  | 53.7                    | 71.3               | 1784                         | 15.8                          | 10.5                           | 76.8               | 111.4                  |\n| [yolov5x6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x6.pt)<br>+ [tta][tta] | 1280<br>1536          | 55.0<br>**55.8**        | 72.7<br>**72.7**   | 3136<br>-                    | 26.2<br>-                     | 19.4<br>-                      | 140.7<br>-         | 209.8<br>-             |\n\n<details>\n  <summary>table notes (click to expand)</summary>\n\n- all checkpoints are trained to 300 epochs with default settings. nano and small models use [hyp.scratch-low.yaml](https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-low.yaml) hyps, all others use [hyp.scratch-high.yaml](https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-high.yaml).\n- **map<sup>val</sup>** values are for single-model single-scale on [coco val2017](http://cocodataset.org) dataset.<br>reproduce by `python val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65`\n- **speed** averaged over coco val images using a [aws p3.2xlarge](https://aws.amazon.com/ec2/instance-types/p3/) instance. nms times (~1 ms/img) not included.<br>reproduce by `python val.py --data coco.yaml --img 640 --task speed --batch 1`\n- **tta** [test time augmentation](https://github.com/ultralytics/yolov5/issues/303) includes reflection and scale augmentations.<br>reproduce by `python val.py --data coco.yaml --img 1536 --iou 0.7 --augment`\n\n</details>\n\n## <div align=\"center\">classification \u2b50 new</div>\n\nyolov5 [release v6.2](https://github.com/ultralytics/yolov5/releases) brings support for classification model training, validation, prediction and export! we've made training classifier models super simple. click below to get started.\n\n<details>\n  <summary>classification checkpoints (click to expand)</summary>\n\n<br>\n\nwe trained yolov5-cls classification models on imagenet for 90 epochs using a 4xa100 instance, and we trained resnet and efficientnet models alongside with the same default training settings to compare. we exported all models to onnx fp32 for cpu speed tests and to tensorrt fp16 for gpu speed tests. we ran all speed tests on google [colab pro](https://colab.research.google.com/signup) for easy reproducibility.\n\n| model                                                                                              | size<br><sup>(pixels) | acc<br><sup>top1 | acc<br><sup>top5 | training<br><sup>90 epochs<br>4xa100 (hours) | speed<br><sup>onnx cpu<br>(ms) | speed<br><sup>tensorrt v100<br>(ms) | params<br><sup>(m) | flops<br><sup>@224 (b) |\n|----------------------------------------------------------------------------------------------------|-----------------------|------------------|------------------|----------------------------------------------|--------------------------------|-------------------------------------|--------------------|------------------------|\n| [yolov5n-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n-cls.pt)         | 224                   | 64.6             | 85.4             | 7:59                                         | **3.3**                        | **0.5**                             | **2.5**            | **0.5**                |\n| [yolov5s-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s-cls.pt)         | 224                   | 71.5             | 90.2             | 8:09                                         | 6.6                            | 0.6                                 | 5.4                | 1.4                    |\n| [yolov5m-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m-cls.pt)         | 224                   | 75.9             | 92.9             | 10:06                                        | 15.5                           | 0.9                                 | 12.9               | 3.9                    |\n| [yolov5l-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5l-cls.pt)         | 224                   | 78.0             | 94.0             | 11:56                                        | 26.9                           | 1.4                                 | 26.5               | 8.5                    |\n| [yolov5x-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x-cls.pt)         | 224                   | **79.0**         | **94.4**         | 15:04                                        | 54.3                           | 1.8                                 | 48.1               | 15.9                   |\n|                                                                                                    |\n| [resnet18](https://github.com/ultralytics/yolov5/releases/download/v6.2/resnet18.pt)               | 224                   | 70.3             | 89.5             | **6:47**                                     | 11.2                           | 0.5                                 | 11.7               | 3.7                    |\n| [resnet34](https://github.com/ultralytics/yolov5/releases/download/v6.2/resnet34.pt)               | 224                   | 73.9             | 91.8             | 8:33                                         | 20.6                           | 0.9                                 | 21.8               | 7.4                    |\n| [resnet50](https://github.com/ultralytics/yolov5/releases/download/v6.2/resnet50.pt)               | 224                   | 76.8             | 93.4             | 11:10                                        | 23.4                           | 1.0                                 | 25.6               | 8.5                    |\n| [resnet101](https://github.com/ultralytics/yolov5/releases/download/v6.2/resnet101.pt)             | 224                   | 78.5             | 94.3             | 17:10                                        | 42.1                           | 1.9                                 | 44.5               | 15.9                   |\n|                                                                                                    |\n| [efficientnet_b0](https://github.com/ultralytics/yolov5/releases/download/v6.2/efficientnet_b0.pt) | 224                   | 75.1             | 92.4             | 13:03                                        | 12.5                           | 1.3                                 | 5.3                | 1.0                    |\n| [efficientnet_b1](https://github.com/ultralytics/yolov5/releases/download/v6.2/efficientnet_b1.pt) | 224                   | 76.4             | 93.2             | 17:04                                        | 14.9                           | 1.6                                 | 7.8                | 1.5                    |\n| [efficientnet_b2](https://github.com/ultralytics/yolov5/releases/download/v6.2/efficientnet_b2.pt) | 224                   | 76.6             | 93.4             | 17:10                                        | 15.9                           | 1.6                                 | 9.1                | 1.7                    |\n| [efficientnet_b3](https://github.com/ultralytics/yolov5/releases/download/v6.2/efficientnet_b3.pt) | 224                   | 77.7             | 94.0             | 19:19                                        | 18.9                           | 1.9                                 | 12.2               | 2.4                    |\n\n<details>\n  <summary>table notes (click to expand)</summary>\n\n- all checkpoints are trained to 90 epochs with sgd optimizer with `lr0=0.001` and `weight_decay=5e-5` at image size 224 and all default settings.<br>runs logged to https://wandb.ai/glenn-jocher/yolov5-classifier-v6-2\n- **accuracy** values are for single-model single-scale on [imagenet-1k](https://www.image-net.org/index.php) dataset.<br>reproduce by `python classify/val.py --data ../datasets/imagenet --img 224`\n- **speed** averaged over 100 inference images using a google [colab pro](https://colab.research.google.com/signup) v100 high-ram instance.<br>reproduce by `python classify/val.py --data ../datasets/imagenet --img 224 --batch 1`\n- **export** to onnx at fp32 and tensorrt at fp16 done with `export.py`. <br>reproduce by `python export.py --weights yolov5s-cls.pt --include engine onnx --imgsz 224`\n</details>\n</details>\n\n<details>\n  <summary>classification usage examples (click to expand)</summary>\n\n### train\nyolov5 classification training supports auto-download of mnist, fashion-mnist, cifar10, cifar100, imagenette, imagewoof, and imagenet datasets with the `--data` argument. to start training on mnist for example use `--data mnist`.\n\n```bash\n# single-gpu\npython classify/train.py --model yolov5s-cls.pt --data cifar100 --epochs 5 --img 224 --batch 128\n\n# multi-gpu ddp\npython -m torch.distributed.run --nproc_per_node 4 --master_port 1 classify/train.py --model yolov5s-cls.pt --data imagenet --epochs 5 --img 224 --device 0,1,2,3\n```\n\n### val\nvalidate yolov5m-cls accuracy on imagenet-1k dataset:\n```bash\nbash data/scripts/get_imagenet.sh --val  # download imagenet val split (6.3g, 50000 images)\npython classify/val.py --weights yolov5m-cls.pt --data ../datasets/imagenet --img 224  # validate\n```\n\n### predict\nuse pretrained yolov5s-cls.pt to predict bus.jpg:\n```bash\npython classify/predict.py --weights yolov5s-cls.pt --data data/images/bus.jpg\n```\n```python\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s-cls.pt')  # load from pytorch hub\n```\n\n### export\nexport a group of trained yolov5s-cls, resnet and efficientnet models to onnx and tensorrt:\n```bash\npython export.py --weights yolov5s-cls.pt resnet50.pt efficientnet_b0.pt --include onnx engine --img 224\n```\n</details>\n\n\n## <div align=\"center\">environments</div>\n\nget started in seconds with our verified environments. click each icon below for details.\n\n<div align=\"center\">\n  <a href=\"https://bit.ly/yolov5-paperspace-notebook\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-gradient.png\" width=\"10%\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"5%\" alt=\"\" />\n  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-colab-small.png\" width=\"10%\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"5%\" alt=\"\" />\n  <a href=\"https://www.kaggle.com/ultralytics/yolov5\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-kaggle-small.png\" width=\"10%\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"5%\" alt=\"\" />\n  <a href=\"https://hub.docker.com/r/ultralytics/yolov5\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-docker-small.png\" width=\"10%\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"5%\" alt=\"\" />\n  <a href=\"https://github.com/ultralytics/yolov5/wiki/aws-quickstart\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-aws-small.png\" width=\"10%\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"5%\" alt=\"\" />\n  <a href=\"https://github.com/ultralytics/yolov5/wiki/gcp-quickstart\">\n    <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-gcp-small.png\" width=\"10%\" /></a>\n</div>\n\n\n## <div align=\"center\">contribute</div>\n\nwe love your input! we want to make contributing to yolov5 as easy and transparent as possible. please see our [contributing guide](contributing.md) to get started, and fill out the [yolov5 survey](https://ultralytics.com/survey?utm_source=github&utm_medium=social&utm_campaign=survey) to send us feedback on your experiences. thank you to all our contributors!\n\n<!-- svg image from https://opencollective.com/ultralytics/contributors.svg?width=990 -->\n<a href=\"https://github.com/ultralytics/yolov5/graphs/contributors\"><img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/image-contributors-1280.png\" /></a>\n\n## <div align=\"center\">contact</div>\n\nfor yolov5 bugs and feature requests please visit [github issues](https://github.com/ultralytics/yolov5/issues). for professional support please [contact us](https://ultralytics.com/contact). to request a commercial license please complete the form at [ultralytics licensing](https://ultralytics.com/license).\n\n<br>\n<div align=\"center\">\n  <a href=\"https://github.com/ultralytics\" style=\"text-decoration:none;\">\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-github.png\" width=\"3%\" alt=\"\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"3%\" alt=\"\" />\n  <a href=\"https://www.linkedin.com/company/ultralytics\" style=\"text-decoration:none;\">\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-linkedin.png\" width=\"3%\" alt=\"\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"3%\" alt=\"\" />\n  <a href=\"https://twitter.com/ultralytics\" style=\"text-decoration:none;\">\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-twitter.png\" width=\"3%\" alt=\"\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"3%\" alt=\"\" />\n  <a href=\"https://www.producthunt.com/@glenn_jocher\" style=\"text-decoration:none;\">\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-producthunt.png\" width=\"3%\" alt=\"\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"3%\" alt=\"\" />\n  <a href=\"https://youtube.com/ultralytics\" style=\"text-decoration:none;\">\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-youtube.png\" width=\"3%\" alt=\"\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"3%\" alt=\"\" />\n  <a href=\"https://www.facebook.com/ultralytics\" style=\"text-decoration:none;\">\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-facebook.png\" width=\"3%\" alt=\"\" /></a>\n  <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-transparent.png\" width=\"3%\" alt=\"\" />\n  <a href=\"https://www.instagram.com/ultralytics/\" style=\"text-decoration:none;\">\n    <img src=\"https://github.com/ultralytics/assets/raw/master/social/logo-social-instagram.png\" width=\"3%\" alt=\"\" /></a>\n</div>\n\n[assets]: https://github.com/ultralytics/yolov5/releases\n[tta]: https://github.com/ultralytics/yolov5/issues/303\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "nm-yolov5",
  "package_url": "https://pypi.org/project/nm-yolov5/",
  "project_url": "https://pypi.org/project/nm-yolov5/",
  "project_urls": {
    "Homepage": "https://github.com/neuralmagic/yolov5"
  },
  "release_url": "https://pypi.org/project/nm-yolov5/1.6.0.60200/",
  "requires_dist": [
    "matplotlib >=3.2.2",
    "numpy >=1.18.5",
    "opencv-python <=4.6.0.66,>=4.1.1",
    "Pillow <10.0.0,>=7.1.2",
    "PyYAML >=5.3.1",
    "requests >=2.23.0",
    "scipy >=1.4.1",
    "torch >=1.7.0",
    "torchvision >=0.8.1",
    "tqdm >=4.64.0",
    "tensorboard >=2.4.1",
    "pandas >=1.1.4",
    "seaborn >=0.11.0",
    "ipython <=8.12",
    "psutil",
    "thop >=0.1.1"
  ],
  "requires_python": ">=3.6",
  "summary": "",
  "version": "1.6.0.60200",
  "releases": [],
  "developers": [],
  "kwds": "yolov5x6 yolov5x yolov5l6 yolov5s6 yolov5l",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_nm_yolov5",
  "homepage": "https://github.com/neuralmagic/yolov5",
  "release_count": 3,
  "dependency_ids": [
    "pypi_ipython",
    "pypi_matplotlib",
    "pypi_numpy",
    "pypi_opencv_python",
    "pypi_pandas",
    "pypi_pillow",
    "pypi_psutil",
    "pypi_pyyaml",
    "pypi_requests",
    "pypi_scipy",
    "pypi_seaborn",
    "pypi_tensorboard",
    "pypi_thop",
    "pypi_torch",
    "pypi_torchvision",
    "pypi_tqdm"
  ]
}