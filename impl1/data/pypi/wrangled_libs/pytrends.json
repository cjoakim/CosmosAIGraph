{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# pytrends\n\n## introduction\n\nunofficial api for google trends\n\nallows simple interface for automating downloading of reports from google trends. \nonly good until google changes their backend again :-p. when that happens feel free to contribute!\n\n**looking for maintainers!** please open an issue with a method of contacting you if you're interested.\n\n\n## table of contents\n\n* [installation](#installation)\n\n* [api](#api)\n\n  * [api methods](#api-methods)\n\n  * [common api parameters](#common-api-parameters)\n\n    * [interest over time](#interest-over-time)\n    * [multirange interest over time](#multirange-interest-over-time)\n    * [historical hourly interest](#historical-hourly-interest)\n    * [interest by region](#interest-by-region)\n    * [related topics](#related-topics)\n    * [related queries](#related-queries)\n    * [trending searches](#trending-searches)\n    * [realtime search trends](#realtime-search-trends)\n    * [top charts](#top-charts)\n    * [suggestions](#suggestions)\n\n  * [caveats](#caveats)\n\n* [credits](#credits)\n\n## installation\n\n    pip install pytrends\n\n## requirements\n\n* written for python 3.3+\n* requires requests, lxml, pandas\n\n<sub><sup>[back to top](#pytrends)</sub></sup>\n\n## api\n\n### connect to google\n\n    from pytrends.request import trendreq\n\n    pytrends = trendreq(hl='en-us', tz=360)\n\nor if you want to use proxies as you are blocked due to google rate limit:\n\n\n    from pytrends.request import trendreq\n\n    pytrends = trendreq(hl='en-us', tz=360, timeout=(10,25), proxies=['https://34.203.233.13:80',], retries=2, backoff_factor=0.1, requests_args={'verify':false})\n\n* `timeout(connect, read)`\n  - see explantation on this on [requests docs](https://requests.readthedocs.io/en/master/user/advanced/#timeouts)\n* tz\n  - timezone offset\n  - for example us cst is ```'360'``` (note **not** -360, google uses timezone this way...)\n\n* `proxies`\n\n  - https proxies google passed only\n  - list ```['https://34.203.233.13:80','https://35.201.123.31:880', ..., ...]```\n  \n* `retries`\n\n  - number of retries total/connect/read all represented by one scalar\n\n* `backoff_factor`\n\n  - a backoff factor to apply between attempts after the second try (most errors are resolved immediately by a second try without a delay). urllib3 will sleep for: ```{backoff factor} * (2 ^ ({number of total retries} - 1))``` seconds. if the backoff_factor is 0.1, then sleep() will sleep for [0.0s, 0.2s, 0.4s, \u2026] between retries. it will never be longer than retry.backoff_max. by default, backoff is disabled (set to 0).\n\n* `requests_args`\n  - a dict with additional parameters to pass along to the underlying requests library, for example verify=false to ignore ssl errors\n\nnote: the parameter `hl` specifies host language for accessing google trends. \nnote: only https proxies will work, and you need to add the port number after the proxy ip address\n\n### build payload\n    kw_list = [\"blockchain\"]\n    pytrends.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='', gprop='')\n\nparameters\n\n* `kw_list`\n\n  - *required*\n  - keywords to get data for\n\n\n<sub><sup>[back to top](#api)</sub></sup>\n\n## api methods\n\nthe following api methods are available:\n\n* [interest over time](#interest-over-time): returns historical, indexed data for when the keyword was searched most as shown on google trends' interest over time section.\n\n* [multirange interest over time](#multirange_interest_over_time): returns historical, indexed data similar to interest over time, but across multiple time date ranges. \n\n* [historical hourly interest](#historical-hourly-interest): returns historical, indexed, hourly data for when the keyword was searched most as shown on google trends' interest over time section. it sends multiple requests to google, each retrieving one week of hourly data. it seems like this would be the only way to get historical, hourly data. \n\n* [interest by region](#interest-by-region): returns data for where the keyword is most searched as shown on google trends' interest by region section.\n\n* [related topics](#related-topics): returns data for the related keywords to a provided keyword shown on google trends' related topics section.\n\n* [related queries](#related-queries): returns data for the related keywords to a provided keyword shown on google trends' related queries section.\n\n* [trending searches](#trending-searches): returns data for latest trending searches shown on google trends' trending searches section.\n\n* [top charts](#top-charts): returns the data for a given topic shown in google trends' top charts section.\n\n* [suggestions](#suggestions): returns a list of additional suggested keywords that can be used to refine a trend search.\n\n<sub><sup>[back to top](#api-methods)</sub></sup>\n\n## common api parameters\n\nmany api methods use the following:\n\n* `kw_list`\n\n  - keywords to get data for\n  - example ```['pizza']```\n  - up to five terms in a list: ```['pizza', 'italian', 'spaghetti', 'breadsticks', 'sausage']```\n\n    * advanced keywords\n\n      - when using google trends dashboard google may provide suggested narrowed search terms.\n      - for example ```\"iron\"``` will have a drop down of ```\"iron chemical element, iron cross, iron man, etc\"```.\n      - find the encoded topic by using the get_suggestions() function and choose the most relevant one for you.\n      - for example: ```https://www.google.com/trends/explore#q=%2fm%2f025rw19&cmpt=q```\n      - ```\"/m/025rw19\"``` is the topic \"iron chemical element\" to use this with pytrends\n      - you can also use `pytrends.suggestions()` to automate this.\n\n* `cat`\n\n  - category to narrow results\n  - find available categories by inspecting the url when manually using google trends. the category starts after ```cat=``` and ends before the next ```&``` or view this [wiki page containing all available categories](https://github.com/pat310/google-trends-api/wiki/google-trends-categories)\n  - for example: ```\"https://www.google.com/trends/explore#q=pizza&cat=71\"```\n  - ```'71'``` is the category\n  - defaults to no category\n\n* `geo`\n\n  - two letter country abbreviation\n  - for example united states is ```'us'```\n  - defaults to world\n  - more detail available for states/provinces by specifying additional abbreviations\n  - for example: alabama would be ```'us-al'```\n  - for example: england would be ```'gb-eng'```\n\n* `tz`\n\n  - timezone offset (in minutes)\n  - for more information of timezone offset, [view this wiki page containing about uct offset](https://en.wikipedia.org/wiki/utc_offset)\n  - for example us cst is ```'360'``` \n\n* `timeframe`\n\n  - date to start from\n  - defaults to last 5yrs, `'today 5-y'`.\n  - everything `'all'`\n  - specific dates, 'yyyy-mm-dd yyyy-mm-dd' example `'2016-12-14 2017-01-25'`\n  - specific datetimes, 'yyyy-mm-ddthh yyyy-mm-ddthh' example `'2017-02-06t10 2017-02-12t07'`\n      - note time component is based off utc\n\n  - current time minus time pattern:\n\n    - by month: ```'today #-m'``` where # is the number of months from that date to pull data for\n      - for example: ``'today 3-m'`` would get data from today to 3months ago\n      - **note** google uses utc date as *'today'*\n      - **works for 1, 3, 12 months only!**\n\n    - daily: ```'now #-d'``` where # is the number of days from that date to pull data for\n      - for example: ``'now 7-d'`` would get data from the last week\n      - **works for 1, 7 days only!**\n\n    - hourly: ```'now #-h'``` where # is the number of hours from that date to pull data for\n      - for example: ``'now 1-h'`` would get data from the last hour\n      - **works for 1, 4 hours only!**\n\n* `gprop`\n\n  - what google property to filter to\n  - example ```'images'```\n  - defaults to web searches\n  - can be ```images```, ```news```, ```youtube``` or ```froogle``` (for google shopping results)\n\n\n<sub><sup>[back to top](#api-payload-keys)</sub></sup>\n\n### interest over time\n\n    pytrends.interest_over_time()\n\nreturns pandas.dataframe\n\n<sub><sup>[back to top](#interest_over_time)</sub></sup>\n\n### multirange interest over time\n\n    pytrends.build_payload(kw_list=['pizza', 'bagel'], timeframe=['2022-09-04 2022-09-10', '2022-09-18 2022-09-24']))\n    pytrends.multirange_interest_over_time()\n\nreturns pandas.dataframe. it includes the average in the first row.\n\n<sub><sup>[back to top](#multirange_interest_over_time)</sub></sup>\n\n### historical hourly interest\n\n    pytrends.get_historical_interest(kw_list, year_start=2018, month_start=1, day_start=1, hour_start=0, year_end=2018, month_end=2, day_end=1, hour_end=0, cat=0, geo='', gprop='', sleep=0)\n    \nparameters \n\n* `kw_list`\n\n  - *required*\n  - list of keywords that you would like the historical data\n\n* `year_start, month_start, day_start, hour_start, year_end, month_end, day_end, hour_end`\n\n  - the time period for which you would like the historical data\n  \n* `sleep`\n\n  - if you are rate-limited by google, you should set this parameter to something (i.e. 60) to space off each api call. \n  \nreturns pandas.dataframe\n\n<sub><sup>[back to top](#historical-hourly-interest)</sub></sup>\n\n### interest by region\n\n    pytrends.interest_by_region(resolution='country', inc_low_vol=true, inc_geo_code=false)\n\nparameters\n\n* `resolution`\n\n  - 'city' returns city level data\n  - 'country' returns country level data\n  - 'dma'  returns metro level data\n  - 'region'  returns region level data\n\n* `inc_low_vol`\n\n  - true/false (includes google trends data for low volume countries/regions as well)\n\n* `inc_geo_code`\n  \n  - true/false (includes iso codes of countries along with the names in the data)\n\nreturns pandas.dataframe\n\n<sub><sup>[back to top](#interest_by_region)</sub></sup>\n\n### related topics\n\n    pytrends.related_topics()\n\nreturns dictionary of pandas.dataframes\n\n<sub><sup>[back to top](#related_topics)</sub></sup>\n\n### related queries\n\n    pytrends.related_queries()\n\nreturns dictionary of pandas.dataframes\n\n<sub><sup>[back to top](#related_queries)</sub></sup>\n\n### trending searches\n\n\tpytrends.trending_searches(pn='united_states') # trending searches in real time for united states\n\tpytrends.trending_searches(pn='japan') # japan\n\nreturns pandas.dataframe\n\n<sub><sup>[back to top](#trending_searches)</sub></sup>\n\n### realtime search trends\n\n\tpytrends.realtime_trending_searches(pn='us') # realtime search trends for united states\n\tpytrends.realtime_trending_searches(pn='in') # india\n\nreturns pandas.dataframe\n\n<sub><sup>[back to top](#realtime-search-trends)</sub></sup>\n\n### top charts\n\n    pytrends.top_charts(date, hl='en-us', tz=300, geo='global')\n\nparameters\n\n* `date`\n\n  - *required*\n  - yyyy integer\n  - example `2019` for the year 2019 top chart data\n  - **note** google removed support for monthly queries (e.g. yyyy-mm)\n  - **note** google does not return data for the current year\n\nreturns pandas.dataframe\n\n<sub><sup>[back to top](#top_charts)</sub></sup>\n\n### suggestions\n\n    pytrends.suggestions(keyword)\n\nparameters\n\n* `keyword`\n\n  - *required*\n  - keyword to get suggestions for\n\nreturns dictionary\n\n<sub><sup>[back to top](#suggestions)</sub></sup>\n\n### categories\n\n    pytrends.categories()\n\nreturns dictionary\n\n<sub><sup>[back to top](#suggestions)</sub></sup>\n\n# caveats\n\n* this is not an official or supported api\n* google may change aggregation level for items with very large or very small search volume\n* rate limit is not publicly known, let me know if you have a consistent estimate\n  * one user reports that 1,400 sequential requests of a 4 hours timeframe got them to the limit. (replicated on 2 networks)\n  * it has been tested, and 60 seconds of sleep between requests (successful or not) appears to be the correct amount once you reach the limit.\n* for certain configurations the dependency lib certifi requires the environment variable requests_ca_bundle to be explicitly set and exported. this variable must contain the path where the ca-certificates are saved or a sslerror: [ssl: certificate_verify_failed] error is given at runtime. \n\n# contributing\n\nsee the [contributing](contributing.md) file.\n\n# credits\n\n* major json revision ideas taken from pat310's javascript library\n\n  - https://github.com/pat310/google-trends-api\n\n* connecting to google code heavily based off stack overflow post\n\n  - http://stackoverflow.com/questions/6754709/logging-in-to-google-using-python\n\n* with some ideas pulled from matt reid's google trends api\n\n  - https://bitbucket.org/mattreid9956/google-trend-api/overview\n",
  "docs_url": null,
  "keywords": "google trends api search",
  "license": "apache 2.0",
  "name": "pytrends",
  "package_url": "https://pypi.org/project/pytrends/",
  "project_url": "https://pypi.org/project/pytrends/",
  "project_urls": {
    "homepage": "https://github.com/dreyco676/pytrends"
  },
  "release_url": "https://pypi.org/project/pytrends/4.9.2/",
  "requires_dist": [
    "requests (>=2.0)",
    "pandas (>=0.25)",
    "lxml"
  ],
  "requires_python": ">=3.7",
  "summary": "pseudo api for google trends",
  "version": "4.9.2",
  "releases": [],
  "developers": [
    "dreyco676@gmail.com",
    "john_hogue"
  ],
  "kwds": "realtime_trending_searches trending_searches trendreq trending trend",
  "license_kwds": "apache 2.0",
  "libtype": "pypi",
  "id": "pypi_pytrends",
  "homepage": "",
  "release_count": 30,
  "dependency_ids": [
    "pypi_lxml",
    "pypi_pandas",
    "pypi_requests"
  ]
}