{
  "classifiers": [
    "intended audience :: science/research",
    "license :: osi approved :: mit license",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "topic :: scientific/engineering :: artificial intelligence"
  ],
  "description": "<p align=\"center\">\n  <img src=\"docs/fairseq_logo.png\" width=\"150\">\n  <br />\n  <br />\n  <a href=\"https://opensource.fb.com/support-ukraine\"><img alt=\"support ukraine\" src=\"https://img.shields.io/badge/support-ukraine-ffd500?style=flat&labelcolor=005bbb\" /></a>\n  <a href=\"https://github.com/pytorch/fairseq/blob/main/license\"><img alt=\"mit license\" src=\"https://img.shields.io/badge/license-mit-blue.svg\" /></a>\n  <a href=\"https://github.com/pytorch/fairseq/releases\"><img alt=\"latest release\" src=\"https://img.shields.io/github/release/pytorch/fairseq.svg\" /></a>\n  <a href=\"https://github.com/pytorch/fairseq/actions?query=workflow:build\"><img alt=\"build status\" src=\"https://github.com/pytorch/fairseq/workflows/build/badge.svg\" /></a>\n  <a href=\"https://fairseq.readthedocs.io/en/latest/?badge=latest\"><img alt=\"documentation status\" src=\"https://readthedocs.org/projects/fairseq/badge/?version=latest\" /></a>\n  <a href=\"https://app.circleci.com/pipelines/github/facebookresearch/fairseq/\"><img alt=\"cicleci status\" src=\"https://circleci.com/gh/facebookresearch/fairseq.svg?style=shield\" /></a>\n</p>\n\n--------------------------------------------------------------------------------\n\nfairseq(-py) is a sequence modeling toolkit that allows researchers and\ndevelopers to train custom models for translation, summarization, language\nmodeling and other text generation tasks.\n\nwe provide reference implementations of various sequence modeling papers:\n\n<details><summary>list of implemented papers</summary><p>\n\n* **convolutional neural networks (cnn)**\n  + [language modeling with gated convolutional networks (dauphin et al., 2017)](examples/language_model/conv_lm/readme.md)\n  + [convolutional sequence to sequence learning (gehring et al., 2017)](examples/conv_seq2seq/readme.md)\n  + [classical structured prediction losses for sequence to sequence learning (edunov et al., 2018)](https://github.com/pytorch/fairseq/tree/classic_seqlevel)\n  + [hierarchical neural story generation (fan et al., 2018)](examples/stories/readme.md)\n  + [wav2vec: unsupervised pre-training for speech recognition (schneider et al., 2019)](examples/wav2vec/readme.md)\n* **lightconv and dynamicconv models**\n  + [pay less attention with lightweight and dynamic convolutions (wu et al., 2019)](examples/pay_less_attention_paper/readme.md)\n* **long short-term memory (lstm) networks**\n  + effective approaches to attention-based neural machine translation (luong et al., 2015)\n* **transformer (self-attention) networks**\n  + attention is all you need (vaswani et al., 2017)\n  + [scaling neural machine translation (ott et al., 2018)](examples/scaling_nmt/readme.md)\n  + [understanding back-translation at scale (edunov et al., 2018)](examples/backtranslation/readme.md)\n  + [adaptive input representations for neural language modeling (baevski and auli, 2018)](examples/language_model/readme.adaptive_inputs.md)\n  + [lexically constrained decoding with dynamic beam allocation (post & vilar, 2018)](examples/constrained_decoding/readme.md)\n  + [transformer-xl: attentive language models beyond a fixed-length context (dai et al., 2019)](examples/truncated_bptt/readme.md)\n  + [adaptive attention span in transformers (sukhbaatar et al., 2019)](examples/adaptive_span/readme.md)\n  + [mixture models for diverse machine translation: tricks of the trade (shen et al., 2019)](examples/translation_moe/readme.md)\n  + [roberta: a robustly optimized bert pretraining approach (liu et al., 2019)](examples/roberta/readme.md)\n  + [facebook fair's wmt19 news translation task submission (ng et al., 2019)](examples/wmt19/readme.md)\n  + [jointly learning to align and translate with transformer models (garg et al., 2019)](examples/joint_alignment_translation/readme.md )\n  + [multilingual denoising pre-training for neural machine translation (liu et at., 2020)](examples/mbart/readme.md)\n  + [neural machine translation with byte-level subwords (wang et al., 2020)](examples/byte_level_bpe/readme.md)\n  + [unsupervised quality estimation for neural machine translation (fomicheva et al., 2020)](examples/unsupervised_quality_estimation/readme.md)\n  + [wav2vec 2.0: a framework for self-supervised learning of speech representations (baevski et al., 2020)](examples/wav2vec/readme.md)\n  + [generating medical reports from patient-doctor conversations using sequence-to-sequence models (enarvi et al., 2020)](examples/pointer_generator/readme.md)\n  + [linformer: self-attention with linear complexity (wang et al., 2020)](examples/linformer/readme.md)\n  + [cross-lingual retrieval for iterative self-supervised training (tran et al., 2020)](examples/criss/readme.md)\n  + [deep transformers with latent depth (li et al., 2020)](examples/latent_depth/readme.md)\n  + [unsupervised cross-lingual representation learning for speech recognition (conneau et al., 2020)](https://arxiv.org/abs/2006.13979)\n  + [self-training and pre-training are complementary for speech recognition (xu et al., 2020)](https://arxiv.org/abs/2010.11430)\n  + [robust wav2vec 2.0: analyzing domain shift in self-supervised pre-training (hsu, et al., 2021)](https://arxiv.org/abs/2104.01027)\n  + [unsupervised speech recognition (baevski, et al., 2021)](https://arxiv.org/abs/2105.11084)\n  + [simple and effective zero-shot cross-lingual phoneme recognition (xu et al., 2021)](https://arxiv.org/abs/2109.11680)\n  + [videoclip: contrastive pre-training for zero-shot video-text understanding (xu et. al., 2021)](https://arxiv.org/pdf/2109.14084.pdf)\n  + [vlm: task-agnostic video-language model pre-training for video understanding (xu et. al., 2021)](https://aclanthology.org/2021.findings-acl.370.pdf)\n  + [normformer: improved transformer pretraining with extra normalization (shleifer et. al, 2021)](examples/normformer/readme.md)\n* **non-autoregressive transformers**\n  + non-autoregressive neural machine translation (gu et al., 2017)\n  + deterministic non-autoregressive neural sequence modeling by iterative refinement (lee et al. 2018)\n  + insertion transformer: flexible sequence generation via insertion operations (stern et al. 2019)\n  + mask-predict: parallel decoding of conditional masked language models (ghazvininejad et al., 2019)\n  + [levenshtein transformer (gu et al., 2019)](examples/nonautoregressive_translation/readme.md)\n* **finetuning**\n  + [better fine-tuning by reducing representational collapse (aghajanyan et al. 2020)](examples/rxf/readme.md)\n\n</p></details>\n\n### what's new:\n* june 2022 [released code for wav2vec-u 2.0 from towards end-to-end unsupervised speech recognition (liu, et al., 2022)](examples/wav2vec/unsupervised/readme.md)\n* may 2022 [integration with xformers](https://github.com/facebookresearch/xformers)\n* december 2021 [released direct speech-to-speech translation code](examples/speech_to_speech/readme.md)\n* october 2021 [released videoclip and vlm models](examples/mmpt/readme.md)\n* october 2021 [released multilingual finetuned xlsr-53 model](examples/wav2vec/readme.md)\n* september 2021 [`master` branch renamed to `main`](https://github.com/github/renaming).\n* july 2021 [released drnmt code](examples/discriminative_reranking_nmt/readme.md)\n* july 2021 [released robust wav2vec 2.0 model](examples/wav2vec/readme.md)\n* june 2021 [released xlmr-xl and xlmr-xxl models](examples/xlmr/readme.md)\n* may 2021 [released unsupervised speech recognition code](examples/wav2vec/unsupervised/readme.md)\n* march 2021 [added full parameter and optimizer state sharding + cpu offloading](examples/fully_sharded_data_parallel/readme.md)\n* february 2021 [added laser training code](examples/laser/readme.md)\n* december 2020: [added adaptive attention span code](examples/adaptive_span/readme.md)\n* december 2020: [gottbert model and code released](examples/gottbert/readme.md)\n* november 2020: adopted the [hydra](https://github.com/facebookresearch/hydra) configuration framework\n  * [see documentation explaining how to use it for new and existing projects](docs/hydra_integration.md)\n* november 2020: [fairseq 0.10.0 released](https://github.com/pytorch/fairseq/releases/tag/v0.10.0)\n* october 2020: [added r3f/r4f (better fine-tuning) code](examples/rxf/readme.md)\n* october 2020: [deep transformer with latent depth code released](examples/latent_depth/readme.md)\n* october 2020: [added criss models and code](examples/criss/readme.md)\n\n<details><summary>previous updates</summary><p>\n\n* september 2020: [added linformer code](examples/linformer/readme.md)\n* september 2020: [added pointer-generator networks](examples/pointer_generator/readme.md)\n* august 2020: [added lexically constrained decoding](examples/constrained_decoding/readme.md)\n* august 2020: [wav2vec2 models and code released](examples/wav2vec/readme.md)\n* july 2020: [unsupervised quality estimation code released](examples/unsupervised_quality_estimation/readme.md)\n* may 2020: [follow fairseq on twitter](https://twitter.com/fairseq)\n* april 2020: [monotonic multihead attention code released](examples/simultaneous_translation/readme.md)\n* april 2020: [quant-noise code released](examples/quant_noise/readme.md)\n* april 2020: [initial model parallel support and 11b parameters unidirectional lm released](examples/megatron_11b/readme.md)\n* march 2020: [byte-level bpe code released](examples/byte_level_bpe/readme.md)\n* february 2020: [mbart model and code released](examples/mbart/readme.md)\n* february 2020: [added tutorial for back-translation](https://github.com/pytorch/fairseq/tree/main/examples/backtranslation#training-your-own-model-wmt18-english-german)\n* december 2019: [fairseq 0.9.0 released](https://github.com/pytorch/fairseq/releases/tag/v0.9.0)\n* november 2019: [vizseq released (a visual analysis toolkit for evaluating fairseq models)](https://facebookresearch.github.io/vizseq/docs/getting_started/fairseq_example)\n* november 2019: [camembert model and code released](examples/camembert/readme.md)\n* november 2019: [bart model and code released](examples/bart/readme.md)\n* november 2019: [xlm-r models and code released](examples/xlmr/readme.md)\n* september 2019: [nonautoregressive translation code released](examples/nonautoregressive_translation/readme.md)\n* august 2019: [wmt'19 models released](examples/wmt19/readme.md)\n* july 2019: fairseq relicensed under mit license\n* july 2019: [roberta models and code released](examples/roberta/readme.md)\n* june 2019: [wav2vec models and code released](examples/wav2vec/readme.md)\n\n</p></details>\n\n### features:\n\n* multi-gpu training on one machine or across multiple machines (data and model parallel)\n* fast generation on both cpu and gpu with multiple search algorithms implemented:\n  + beam search\n  + diverse beam search ([vijayakumar et al., 2016](https://arxiv.org/abs/1610.02424))\n  + sampling (unconstrained, top-k and top-p/nucleus)\n  + [lexically constrained decoding](examples/constrained_decoding/readme.md) (post & vilar, 2018)\n* [gradient accumulation](https://fairseq.readthedocs.io/en/latest/getting_started.html#large-mini-batch-training-with-delayed-updates) enables training with large mini-batches even on a single gpu\n* [mixed precision training](https://fairseq.readthedocs.io/en/latest/getting_started.html#training-with-half-precision-floating-point-fp16) (trains faster with less gpu memory on [nvidia tensor cores](https://developer.nvidia.com/tensor-cores))\n* [extensible](https://fairseq.readthedocs.io/en/latest/overview.html): easily register new models, criterions, tasks, optimizers and learning rate schedulers\n* [flexible configuration](docs/hydra_integration.md) based on [hydra](https://github.com/facebookresearch/hydra) allowing a combination of code, command-line and file based configuration\n* [full parameter and optimizer state sharding](examples/fully_sharded_data_parallel/readme.md)\n* [offloading parameters to cpu](examples/fully_sharded_data_parallel/readme.md)\n\nwe also provide [pre-trained models for translation and language modeling](#pre-trained-models-and-examples)\nwith a convenient `torch.hub` interface:\n\n``` python\nen2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model')\nen2de.translate('hello world', beam=5)\n# 'hallo welt'\n```\n\nsee the pytorch hub tutorials for [translation](https://pytorch.org/hub/pytorch_fairseq_translation/)\nand [roberta](https://pytorch.org/hub/pytorch_fairseq_roberta/) for more examples.\n\n# requirements and installation\n\n* [pytorch](http://pytorch.org/) version >= 1.5.0\n* python version >= 3.6\n* for training new models, you'll also need an nvidia gpu and [nccl](https://github.com/nvidia/nccl)\n* **to install fairseq** and develop locally:\n\n``` bash\ngit clone https://github.com/pytorch/fairseq\ncd fairseq\npip install --editable ./\n\n# on macos:\n# cflags=\"-stdlib=libc++\" pip install --editable ./\n\n# to install the latest stable release (0.10.x)\n# pip install fairseq\n```\n\n* **for faster training** install nvidia's [apex](https://github.com/nvidia/apex) library:\n\n``` bash\ngit clone https://github.com/nvidia/apex\ncd apex\npip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" \\\n  --global-option=\"--deprecated_fused_adam\" --global-option=\"--xentropy\" \\\n  --global-option=\"--fast_multihead_attn\" ./\n```\n\n* **for large datasets** install [pyarrow](https://arrow.apache.org/docs/python/install.html#using-pip): `pip install pyarrow`\n* if you use docker make sure to increase the shared memory size either with `--ipc=host` or `--shm-size`\n as command line options to `nvidia-docker run` .\n\n# getting started\n\nthe [full documentation](https://fairseq.readthedocs.io/) contains instructions\nfor getting started, training new models and extending fairseq with new model\ntypes and tasks.\n\n# pre-trained models and examples\n\nwe provide pre-trained models and pre-processed, binarized test sets for several tasks listed below,\nas well as example training and evaluation commands.\n\n* [translation](examples/translation/readme.md): convolutional and transformer models are available\n* [language modeling](examples/language_model/readme.md): convolutional and transformer models are available\n\nwe also have more detailed readmes to reproduce results from specific papers:\n\n* [xls-r: self-supervised cross-lingual speech representation learning at scale (babu et al., 2021)](examples/wav2vec/xlsr/readme.md)\n* [cross-lingual retrieval for iterative self-supervised training (tran et al., 2020)](examples/criss/readme.md)\n* [wav2vec 2.0: a framework for self-supervised learning of speech representations (baevski et al., 2020)](examples/wav2vec/readme.md)\n* [unsupervised quality estimation for neural machine translation (fomicheva et al., 2020)](examples/unsupervised_quality_estimation/readme.md)\n* [training with quantization noise for extreme model compression ({fan*, stock*} et al., 2020)](examples/quant_noise/readme.md)\n* [neural machine translation with byte-level subwords (wang et al., 2020)](examples/byte_level_bpe/readme.md)\n* [multilingual denoising pre-training for neural machine translation (liu et at., 2020)](examples/mbart/readme.md)\n* [reducing transformer depth on demand with structured dropout (fan et al., 2019)](examples/layerdrop/readme.md)\n* [jointly learning to align and translate with transformer models (garg et al., 2019)](examples/joint_alignment_translation/readme.md)\n* [levenshtein transformer (gu et al., 2019)](examples/nonautoregressive_translation/readme.md)\n* [facebook fair's wmt19 news translation task submission (ng et al., 2019)](examples/wmt19/readme.md)\n* [roberta: a robustly optimized bert pretraining approach (liu et al., 2019)](examples/roberta/readme.md)\n* [wav2vec: unsupervised pre-training for speech recognition (schneider et al., 2019)](examples/wav2vec/readme.md)\n* [mixture models for diverse machine translation: tricks of the trade (shen et al., 2019)](examples/translation_moe/readme.md)\n* [pay less attention with lightweight and dynamic convolutions (wu et al., 2019)](examples/pay_less_attention_paper/readme.md)\n* [understanding back-translation at scale (edunov et al., 2018)](examples/backtranslation/readme.md)\n* [classical structured prediction losses for sequence to sequence learning (edunov et al., 2018)](https://github.com/pytorch/fairseq/tree/classic_seqlevel)\n* [hierarchical neural story generation (fan et al., 2018)](examples/stories/readme.md)\n* [scaling neural machine translation (ott et al., 2018)](examples/scaling_nmt/readme.md)\n* [convolutional sequence to sequence learning (gehring et al., 2017)](examples/conv_seq2seq/readme.md)\n* [language modeling with gated convolutional networks (dauphin et al., 2017)](examples/language_model/readme.conv.md)\n\n# join the fairseq community\n\n* twitter: https://twitter.com/fairseq\n* facebook page: https://www.facebook.com/groups/fairseq.users\n* google group: https://groups.google.com/forum/#!forum/fairseq-users\n\n# license\n\nfairseq(-py) is mit-licensed.\nthe license applies to the pre-trained models as well.\n\n# citation\n\nplease cite as:\n\n``` bibtex\n@inproceedings{ott2019fairseq,\n  title = {fairseq: a fast, extensible toolkit for sequence modeling},\n  author = {myle ott and sergey edunov and alexei baevski and angela fan and sam gross and nathan ng and david grangier and michael auli},\n  booktitle = {proceedings of naacl-hlt 2019: demonstrations},\n  year = {2019},\n}\n```\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "fairseq",
  "package_url": "https://pypi.org/project/fairseq/",
  "project_url": "https://pypi.org/project/fairseq/",
  "project_urls": {
    "Homepage": "https://github.com/pytorch/fairseq"
  },
  "release_url": "https://pypi.org/project/fairseq/0.12.2/",
  "requires_dist": [
    "cffi",
    "cython",
    "hydra-core (<1.1,>=1.0.7)",
    "omegaconf (<2.1)",
    "regex",
    "sacrebleu (>=1.4.12)",
    "torch",
    "tqdm",
    "bitarray",
    "torchaudio (>=0.8.0)",
    "dataclasses ; python_version < \"3.7\"",
    "numpy (<1.20.0) ; python_version < \"3.7\"",
    "numpy ; python_version >= \"3.7\""
  ],
  "requires_python": "",
  "summary": "facebook ai research sequence-to-sequence toolkit",
  "version": "0.12.2",
  "releases": [],
  "developers": [],
  "kwds": "fairseq_logo fairseq pytorch_fairseq_translation shields badge",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_fairseq",
  "homepage": "https://github.com/pytorch/fairseq",
  "release_count": 13,
  "dependency_ids": [
    "pypi_bitarray",
    "pypi_cffi",
    "pypi_cython",
    "pypi_dataclasses",
    "pypi_hydra_core",
    "pypi_numpy",
    "pypi_omegaconf",
    "pypi_regex",
    "pypi_sacrebleu",
    "pypi_torch",
    "pypi_torchaudio",
    "pypi_tqdm"
  ]
}