{
  "classifiers": [
    "framework :: pytest",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "programming language :: python",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.9"
  ],
  "description": "![tests](https://github.com/str0zzapreti/pytest-retry/actions/workflows/tests.yaml/badge.svg)\n# pytest-retry\n\npytest-retry is a plugin for pytest which adds the ability to retry flaky tests,\nthereby improving the consistency of the test suite results. \n\n## requirements\n\npytest-retry is designed for the latest versions of python and pytest. python 3.9+\nand pytest 7.0.0 are required. \n\n## installation\n\nuse pip to install pytest-retry:\n```\n$ pip install pytest-retry\n```\n\n## usage\n\nthere are two main ways to use pytest-retry:\n\n### 1. global settings\n\nonce installed, pytest-retry adds new command line and ini config options for pytest.\nrun pytest with the command line argument --retries in order to retry every test in \nthe event of a failure. the following example will retry each failed up to two times\nbefore proceeding to the next test:\n\n```\n$ python -m pytest --retries 2\n```\n\nan optional delay can be specified using the --retry-delay argument. this will insert\na fixed delay (in seconds) between each attempt when a test fails. this can be useful\nif the test failures are due to intermittent environment issues which clear up after\na few seconds\n\n```\n$ python -m pytest --retries 2 --retry-delay 5\n```\n\n#### advanced options:\nthere are two custom hooks provided for the purpose of setting global exception\nfilters for your entire pytest suite. `pytest_set_filtered_exceptions`\nand `pytest_set_excluded_exceptions`. you can define either of them in your \nconftest.py file and return a list of exception types. note: these hooks are \nmutually exclusive and cannot both be defined at the same time.\n\nexample:\n```\ndef pytest_set_excluded_exceptions():\n    \"\"\"\n    all tests will be retried unless they fail due to an assertionerror or customerror\n    \"\"\"\n    return [assertionerror, customerror]\n```\n\nthere is a command line option to specify the test timing method, which can either\nbe `overwrite` (default) or `cumulative`. with cumulative timing, the duration of \neach test attempt is summed for the reported overall test duration. the default\nbehavior simply reports the timing of the final attempt.\n\n```\n$ python -m pytest --retries 2 --cumulative-timing 1\n```\n\nif you're not sure which to use, stick with the default `overwrite` method. this\ngenerally plays nicer with time-based test splitting algorithms and will result in\nmore even splits.\n\ninstead of command line arguments, you can set any of these config options in your\npytest.ini, tox.ini, or pyproject.toml file. any command line arguments will take\nprecedence over options specified in one of these config files. here are some\nsample configs that you can copy into your project to get started:\n\n_pyproject.toml_\n```\n[tool.pytest.ini_options]\nretries = 2\nretry_delay = 0.5\ncumulative_timing = false\n```\n\n_config.ini/tox.ini_\n```\n[pytest]\nretries = 2\nretry_delay = 0.5\ncumulative_timing = false\n```\n\n### 2. pytest flaky mark\n\nmark individual tests as 'flaky' to retry them when they fail. if no command line\narguments are passed, only the marked tests will be retried. the default values\nare 1 retry attempt with a 0-second delay\n\n```\n@pytest.mark.flaky\ndef test_unreliable_service():\n    ...\n```\n\nthe number of times each test will be retried and/or the delay can be manually\nspecified as well\n\n```\n@pytest.mark.flaky(retries=3, delay=1)\ndef test_unreliable_service():\n    # this test will be retried up to 3 times (4 attempts total) with a\n    # one second delay between each attempt\n    ...\n```\n\nif you want to control filtered or excluded exceptions per-test, the flaky mark\nprovides the `only_on` and `exclude` arguments which both take a list of exception\ntypes, including any custom types you may have defined for your project. note that \nonly one of these arguments may be used at a time.\n\na test with a list of `only_on` exceptions will only be retried if it fails with\none of the listed exceptions. a test with a list of `exclude` exceptions will\nonly be retried if it fails with an exception which does not match any of the\nlisted exceptions.\n\nif the exception for a subsequent attempt changes and no longer matches the filter,\nno further attempts will be made and the test will immediately fail.\n\n```\n@pytest.mark.flaky(retries=2, only_on=[valueerror, indexerror])\ndef test_unreliable_service():\n    # this test will only be retried if it fails due to raising a valueerror\n    # or an indexerror. e.g., an assertionerror will fail without retrying\n    ...\n```\n\nif you want some other generalized condition to control whether a test is retried, use the\n`condition` argument. any statement which results in a bool can be used here to add granularity\nto your retries. the test will only be retried if `condition` is `true`. note, there is no\nmatching command line option for `condition`, but if you need to globally apply this type of logic\nto all of your tests, consider invoking the `pytest_collection_modifyitems` hook.\n\n```\n@pytest.mark.flaky(retries=2, condition=sys.platform.startswith('win32'))\ndef test_only_flaky_on_some_systems():\n    # this test will only be retried if sys.platform.startswith('win32') evaluates to `true`\n```\n\nfinally, there is a flaky mark argument for the test timing method, which can either\nbe `overwrite` (default) or `cumulative`. see **command line** > **advanced options** \nfor more information\n\n```\n@pytest.mark.flaky(timing='overwrite')\ndef test_unreliable_service():\n    ...\n```\n\na flaky mark will override any command line options and exception filter hooks\nspecified when running pytest.\n\n### things to consider\n\n- **currently, failing test fixtures are not retried.** in the future, flaky test setup \nmay be retried, although given the undesirability of flaky tests in general, flaky setup \nshould be avoided at all costs. any failures during teardown will immediately halt\nfurther attempts so that they can be addressed immediately. make sure your teardowns\nalways work reliably regardless of the number of retries when using this plugin\n\n- when a flaky test is retried, the plugin runs teardown steps for the test as if it \nhad passed. this is to ensure that any partial state created by the test is cleaned up \nbefore the next attempt so that subsequent attempts do not conflict with one another.\nclass and module fixtures are included in this teardown with the assumption that false\ntest failures should be a rare occurrence and the performance hit from re-running \nthese potentially expensive fixtures is worth it to ensure clean initial test state. \nwith feedback, the option to not re-run class and module fixtures may be added, but \nin general, these types of fixtures should be avoided for known flaky tests.\n\n- flaky tests are not sustainable. this plugin is designed as an easy short-term\nsolution while a permanent fix is implemented. use the reports generated by this plugin\nto identify issues with the tests or testing environment and resolve them.\n\n## reporting\n\npytest-retry intercepts the standard pytest report flow in order to retry tests and\nupdate the reports as required. when a test is retried at least once, an r is printed\nto the live test output and the counter of retried tests is incremented by 1. after\nthe test session has completed, an additional report is generated below the standard\noutput which lists all of the tests which were retried, along with the exceptions\nthat occurred during each failed attempt. \n\n```\nplugins: retry-1.1.0\ncollected 1 item\n\ntest_retry_passes_after_temporary_test_failure.py r.                     [100%]\n\n======================= the following tests were retried =======================\n\n\ttest_eventually_passes failed on attempt 1! retrying!\n\ttraceback (most recent call last):\n\t  file \"tests/test_example.py\", line 4, in test_eventually_passes\n\t    assert len(a) > 1\n\tassertionerror: assert 1 > 1\n\t +  where 1 = len([1])\n\n=========================== end of test retry report ===========================\n\n\n========================= 1 passed, 1 retried in 0.01s =========================\n```\n\ntests which have been retried but eventually pass are counted as both retried and\npassed, and tests which have been retried but eventually fail are counted as both\nretried and failed. skipped, xfailed, and xpassed tests are never retried.\n\nthree pytest stash keys are available to import from the pytest_retry plugin:\n`attempts_key`, `outcome_key`, and `duration_key`. these keys are used by the plugin\nto store the number of attempts each item has undergone, whether the test passed or\nfailed, and the total duration from setup to teardown, respectively. (if any stage of \nsetup, call, or teardown fails, a test is considered failed overall). these stash keys \ncan be used to retrieve these reports for use in your own hooks or plugins.\n",
  "docs_url": null,
  "keywords": "rerun,pytest,flaky",
  "license": "mit license  copyright (c) 2022 silas  permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"software\"), to deal in the software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software, and to permit persons to whom the software is furnished to do so, subject to the following conditions:  the above copyright notice and this permission notice shall be included in all copies or substantial portions of the software.  the software is provided \"as is\", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. in no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software. ",
  "name": "pytest-retry",
  "package_url": "https://pypi.org/project/pytest-retry/",
  "project_url": "https://pypi.org/project/pytest-retry/",
  "project_urls": {
    "Homepage": "https://github.com/str0zzapreti/pytest-retry"
  },
  "release_url": "https://pypi.org/project/pytest-retry/1.5.0/",
  "requires_dist": [
    "pytest >=7.0.0",
    "black ; extra == 'dev'",
    "isort ; extra == 'dev'",
    "mypy ; extra == 'dev'",
    "flake8 ; extra == 'dev'"
  ],
  "requires_python": ">=3.9",
  "summary": "adds the ability to retry flaky tests in ci environments",
  "version": "1.5.0",
  "releases": [],
  "developers": [
    "str0zzapreti"
  ],
  "kwds": "pytest_retry test_retry_passes_after_temporary_test_failure pytest_set_filtered_exceptions pytest pytest_set_excluded_exceptions",
  "license_kwds": "copyright liable license liability mit",
  "libtype": "pypi",
  "id": "pypi_pytest_retry",
  "homepage": "",
  "release_count": 11,
  "dependency_ids": [
    "pypi_black",
    "pypi_flake8",
    "pypi_isort",
    "pypi_mypy",
    "pypi_pytest"
  ]
}