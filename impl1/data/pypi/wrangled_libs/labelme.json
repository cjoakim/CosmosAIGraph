{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "intended audience :: science/research",
    "natural language :: english",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "<h1 align=\"center\">\n  <img src=\"https://github.com/wkentaro/labelme/blob/main/labelme/icons/icon.png?raw=true\"><br/>labelme\n</h1>\n\n<h4 align=\"center\">\n  image polygonal annotation with python\n</h4>\n\n<div align=\"center\">\n  <a href=\"https://pypi.python.org/pypi/labelme\"><img src=\"https://img.shields.io/pypi/v/labelme.svg\"></a>\n  <a href=\"https://pypi.org/project/labelme\"><img src=\"https://img.shields.io/pypi/pyversions/labelme.svg\"></a>\n  <a href=\"https://github.com/wkentaro/labelme/actions\"><img src=\"https://github.com/wkentaro/labelme/workflows/ci/badge.svg?branch=main&event=push\"></a>\n</div>\n\n<div align=\"center\">\n  <a href=\"https://github.com/wkentaro/labelme/blob/main/#starter-kit\"><b>starter kit</b></a>\n  | <a href=\"https://github.com/wkentaro/labelme/blob/main/#installation?raw=true\"><b>installation</b></a>\n  | <a href=\"https://github.com/wkentaro/labelme/blob/main/#usage\"><b>usage</b></a>\n  | <a href=\"https://github.com/wkentaro/labelme/tree/main/examples\"><b>examples</b></a>\n  | <a href=\"https://github.com/wkentaro/labelme/discussions\"><b>community</b></a>\n  <!-- | <a href=\"https://www.youtube.com/playlist?list=pli6lvfw0iflh3o33yynvifopao0hc5dzw\"><b>youtube faq</b></a> -->\n</div>\n\n<br/>\n\n<div align=\"center\">\n  <img src=\"https://github.com/wkentaro/labelme/blob/main/examples/instance_segmentation/.readme/annotation.jpg?raw=true\" width=\"70%\">\n</div>\n\n## description\n\nlabelme is a graphical image annotation tool inspired by <http://labelme.csail.mit.edu>.  \nit is written in python and uses qt for its graphical interface.\n\n<img src=\"https://github.com/wkentaro/labelme/blob/main/examples/instance_segmentation/data_dataset_voc/jpegimages/2011_000006.jpg?raw=true\" width=\"19%\" /> <img src=\"examples/instance_segmentation/data_dataset_voc/segmentationclasspng/2011_000006.png\" width=\"19%\" /> <img src=\"examples/instance_segmentation/data_dataset_voc/segmentationclassvisualization/2011_000006.jpg\" width=\"19%\" /> <img src=\"examples/instance_segmentation/data_dataset_voc/segmentationobjectpng/2011_000006.png\" width=\"19%\" /> <img src=\"examples/instance_segmentation/data_dataset_voc/segmentationobjectvisualization/2011_000006.jpg\" width=\"19%\" />  \n<i>voc dataset example of instance segmentation.</i>\n\n<img src=\"https://github.com/wkentaro/labelme/blob/main/examples/semantic_segmentation/.readme/annotation.jpg?raw=true\" width=\"30%\" /> <img src=\"examples/bbox_detection/.readme/annotation.jpg\" width=\"30%\" /> <img src=\"examples/classification/.readme/annotation_cat.jpg\" width=\"35%\" />  \n<i>other examples (semantic segmentation, bbox detection, and classification).</i>\n\n<img src=\"https://user-images.githubusercontent.com/4310419/47907116-85667800-de82-11e8-83d0-b9f4eb33268f.gif\" width=\"30%\" /> <img src=\"https://user-images.githubusercontent.com/4310419/47922172-57972880-deae-11e8-84f8-e4324a7c856a.gif\" width=\"30%\" /> <img src=\"https://user-images.githubusercontent.com/14256482/46932075-92145f00-d080-11e8-8d09-2162070ae57c.png\" width=\"32%\" />  \n<i>various primitives (polygon, rectangle, circle, line, and point).</i>\n\n\n## features\n\n- [x] image annotation for polygon, rectangle, circle, line and point. ([tutorial](https://github.com/wkentaro/labelme/blob/main/examples/tutorial))\n- [x] image flag annotation for classification and cleaning. ([#166](https://github.com/wkentaro/labelme/pull/166))\n- [x] video annotation. ([video annotation](https://github.com/wkentaro/labelme/blob/main/examples/video_annotation?raw=true))\n- [x] gui customization (predefined labels / flags, auto-saving, label validation, etc). ([#144](https://github.com/wkentaro/labelme/pull/144))\n- [x] exporting voc-format dataset for semantic/instance segmentation. ([semantic segmentation](https://github.com/wkentaro/labelme/blob/main/examples/semantic_segmentation?raw=true), [instance segmentation](https://github.com/wkentaro/labelme/blob/main/examples/instance_segmentation?raw=true))\n- [x] exporting coco-format dataset for instance segmentation. ([instance segmentation](https://github.com/wkentaro/labelme/blob/main/examples/instance_segmentation?raw=true))\n\n\n## starter kit\n\nyou can get [labelme starter kit](https://wkentaro.gumroad.com/l/labelmeapp) on gumroad for free, which contains:\n\n- **installation guides** for all platforms: windows, macos, and linux \ud83d\udcbb\n- **step-by-step tutorials**: first annotation to editing, exporting, and integrating with other programs \ud83d\udcd5\n- **a compilation of valuable resources** for further exploration \ud83d\udd17.\n\n\n\n<!-- ## requirements -->\n<!--  -->\n<!-- - ubuntu / macos / windows -->\n<!-- - python3 -->\n<!-- - [pyqt5 / pyside2](http://www.riverbankcomputing.co.uk/software/pyqt/intro) -->\n\n\n## installation\n\nthere are options:\n\n- platform agnostic installation: [anaconda](https://github.com/wkentaro/labelme/blob/main/#anaconda)\n- platform specific installation: [ubuntu](https://github.com/wkentaro/labelme/blob/main/#ubuntu), [macos](https://github.com/wkentaro/labelme/blob/main/#macos), [windows](https://github.com/wkentaro/labelme/blob/main/#windows)\n- pre-build binaries from [the release section](https://github.com/wkentaro/labelme/releases)\n\n### anaconda\n\nyou need install [anaconda](https://www.continuum.io/downloads), then run below:\n\n```bash\n# python3\nconda create --name=labelme python=3\nsource activate labelme\n# conda install -c conda-forge pyside2\n# conda install pyqt\n# pip install pyqt5  # pyqt5 can be installed via pip on python3\npip install labelme\n# or you can install everything by conda command\n# conda install labelme -c conda-forge\n```\n\n### ubuntu\n\n```bash\nsudo apt-get install labelme\n\n# or\nsudo pip3 install labelme\n\n# or install standalone executable from:\n# https://github.com/wkentaro/labelme/releases\n```\n\n### macos\n\n```bash\nbrew install pyqt  # maybe pyqt5\npip install labelme\n\n# or\nbrew install wkentaro/labelme/labelme  # command line interface\n# brew install --cask wkentaro/labelme/labelme  # app\n\n# or install standalone executable/app from:\n# https://github.com/wkentaro/labelme/releases\n```\n\n### windows\n\ninstall [anaconda](https://www.continuum.io/downloads), then in an anaconda prompt run:\n\n```bash\nconda create --name=labelme python=3\nconda activate labelme\npip install labelme\n\n# or install standalone executable/app from:\n# https://github.com/wkentaro/labelme/releases\n```\n\n\n## usage\n\nrun `labelme --help` for detail.  \nthe annotations are saved as a [json](http://www.json.org/) file.\n\n```bash\nlabelme  # just open gui\n\n# tutorial (single image example)\ncd examples/tutorial\nlabelme apc2016_obj3.jpg  # specify image file\nlabelme apc2016_obj3.jpg -o apc2016_obj3.json  # close window after the save\nlabelme apc2016_obj3.jpg --nodata  # not include image data but relative image path in json file\nlabelme apc2016_obj3.jpg \\\n  --labels highland_6539_self_stick_notes,mead_index_cards,kong_air_dog_squeakair_tennis_ball  # specify label list\n\n# semantic segmentation example\ncd examples/semantic_segmentation\nlabelme data_annotated/  # open directory to annotate all images in it\nlabelme data_annotated/ --labels labels.txt  # specify label list with a file\n```\n\nfor more advanced usage, please refer to the examples:\n\n* [semantic segmentation example](https://github.com/wkentaro/labelme/blob/main/examples/semantic_segmentation?raw=true)\n* [instance segmentation example](https://github.com/wkentaro/labelme/blob/main/examples/instance_segmentation?raw=true)\n* [video annotation example](https://github.com/wkentaro/labelme/blob/main/examples/video_annotation?raw=true)\n\n### command line arguments\n- `--output` specifies the location that annotations will be written to. if the location ends with .json, a single annotation will be written to this file. only one image can be annotated if a location is specified with .json. if the location does not end with .json, the program will assume it is a directory. annotations will be stored in this directory with a name that corresponds to the image that the annotation was made on.\n- the first time you run labelme, it will create a config file in `~/.labelmerc`. you can edit this file and the changes will be applied the next time that you launch labelme. if you would prefer to use a config file from another location, you can specify this file with the `--config` flag.\n- without the `--nosortlabels` flag, the program will list labels in alphabetical order. when the program is run with this flag, it will display labels in the order that they are provided.\n- flags are assigned to an entire image. [example](https://github.com/wkentaro/labelme/blob/main/examples/classification?raw=true)\n- labels are assigned to a single polygon. [example](https://github.com/wkentaro/labelme/blob/main/examples/bbox_detection?raw=true)\n\n## faq\n\n- **how to convert json file to numpy array?** see [examples/tutorial](https://github.com/wkentaro/labelme/blob/main/examples/tutorial#convert-to-dataset).\n- **how to load label png file?** see [examples/tutorial](https://github.com/wkentaro/labelme/blob/main/examples/tutorial#how-to-load-label-png-file).\n- **how to get annotations for semantic segmentation?** see [examples/semantic_segmentation](https://github.com/wkentaro/labelme/blob/main/examples/semantic_segmentation?raw=true).\n- **how to get annotations for instance segmentation?** see [examples/instance_segmentation](https://github.com/wkentaro/labelme/blob/main/examples/instance_segmentation?raw=true).\n\n\n## developing\n\n```bash\ngit clone https://github.com/wkentaro/labelme.git\ncd labelme\n\n# install anaconda3 and labelme\ncurl -l https://github.com/wkentaro/dotfiles/raw/main/local/bin/install_anaconda3.sh | bash -s .\nsource .anaconda3/bin/activate\npip install -e .\n```\n\n\n## how to build standalone executable\n\nbelow shows how to build the standalone executable on macos, linux and windows.  \n\n```bash\n# setup conda\nconda create --name labelme python=3.9\nconda activate labelme\n\n# build the standalone executable\npip install .\npip install 'matplotlib<3.3'\npip install pyinstaller\npyinstaller labelme.spec\ndist/labelme --version\n```\n\n\n## how to contribute\n\nmake sure below test passes on your environment.  \nsee `.github/workflows/ci.yml` for more detail.\n\n```bash\npip install -r requirements-dev.txt\n\nflake8 .\nblack --line-length 79 --check labelme/\nmplbackend='agg' pytest -vsx tests/\n```\n\n\n## acknowledgement\n\nthis repo is the fork of [mpitid/pylabelme](https://github.com/mpitid/pylabelme).\n",
  "docs_url": null,
  "keywords": "image annotation,machine learning",
  "license": "gplv3",
  "name": "labelme",
  "package_url": "https://pypi.org/project/labelme/",
  "project_url": "https://pypi.org/project/labelme/",
  "project_urls": {
    "Homepage": "https://github.com/wkentaro/labelme"
  },
  "release_url": "https://pypi.org/project/labelme/5.3.1/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "image polygonal annotation with python",
  "version": "5.3.1",
  "releases": [],
  "developers": [
    "kentaro_wada",
    "www.kentaro.wada@gmail.com"
  ],
  "kwds": "icons icon svg images png",
  "license_kwds": "gplv3",
  "libtype": "pypi",
  "id": "pypi_labelme",
  "homepage": "https://github.com/wkentaro/labelme",
  "release_count": 194,
  "dependency_ids": []
}