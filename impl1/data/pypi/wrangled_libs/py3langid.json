{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "intended audience :: information technology",
    "intended audience :: science/research",
    "license :: osi approved :: bsd license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: text processing :: linguistic"
  ],
  "description": "=============\n``py3langid``\n=============\n\n\n``py3langid`` is a fork of the standalone language identification tool ``langid.py`` by marco lui.\n\noriginal license: bsd-2-clause. fork license: bsd-3-clause.\n\n\n\nchanges in this fork\n--------------------\n\nexecution speed has been improved and the code base has been optimized for python 3.6+:\n\n- import: loading the package (``import py3langid``) is about 30% faster\n- startup: loading the default classification model is 25-30x faster\n- execution: language detection with ``langid.classify`` is 5-6x faster on paragraphs (less on longer texts)\n\nfor implementation details see this blog post: `how to make language detection with langid.py faster <https://adrien.barbaresi.eu/blog/language-detection-langid-py-faster.html>`_.\n\n\nusage\n-----\n\ndrop-in replacement\n~~~~~~~~~~~~~~~~~~~\n\n\n1. install the package:\n\n   * ``pip3 install py3langid`` (or ``pip`` where applicable)\n\n2. use it:\n\n   * with python: ``import py3langid as langid``\n   * on the command-line: ``langid``\n\n\nwith python\n~~~~~~~~~~~\n\nbasics:\n\n.. code-block:: python\n\n    >>> import py3langid as langid\n\n    >>> text = 'this text is in english.'\n    # identified language and probability\n    >>> langid.classify(text)\n    ('en', -56.77429)\n    # unpack the result tuple in variables\n    >>> lang, prob = langid.classify(text)\n    # all potential languages\n    >>> langid.rank(text)\n\n\nmore options:\n\n.. code-block:: python\n\n    >>> from py3langid.langid import languageidentifier, model_file\n\n    # subset of target languages\n    >>> identifier = languageidentifier.from_pickled_model(model_file)\n    >>> identifier.set_languages(['de', 'en', 'fr'])\n    # this won't work well...\n    >>> identifier.classify('\u8fd9\u6837\u4e0d\u597d')\n    ('en', -81.831665)\n\n    # normalization of probabilities to an interval between 0 and 1\n    >>> identifier = languageidentifier.from_pickled_model(model_file, norm_probs=true)\n    >>> identifier.classify('this should be enough text.')\n    ('en', 1.0)\n\n\nnote: the numpy data type for the feature vector has been changed to optimize for speed. if results are inconsistent, try restoring the original setting:\n\n.. code-block:: python\n\n    >>> langid.classify(text, datatype='uint32')\n\n\non the command-line\n~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n    # basic usage with probability normalization\n    $ echo \"this should be enough text.\" | langid -n\n    ('en', 1.0)\n\n    # define a subset of target languages\n    $ echo \"this won't be recognized properly.\" | langid -n -l fr,it,tr\n    ('it', 0.97038305)\n\n\n\nlegacy documentation\n--------------------\n\n\n**the docs below are provided for reference, only part of the functions are currently tested and maintained.**\n\n\nintroduction\n------------\n\n``langid.py`` is a standalone language identification (langid) tool.\n\nthe design principles are as follows:\n\n1. fast\n2. pre-trained over a large number of languages (currently 97)\n3. not sensitive to domain-specific features (e.g. html/xml markup)\n4. single .py file with minimal dependencies\n5. deployable as a web service\n\nall that is required to run ``langid.py`` is python >= 3.6 and numpy. \n\nthe accompanying training tools are still python2-only.\n\n``langid.py`` is wsgi-compliant.  ``langid.py`` will use ``fapws3`` as a web server if \navailable, and default to ``wsgiref.simple_server`` otherwise.\n\n``langid.py`` comes pre-trained on 97 languages (iso 639-1 codes given):\n\n    af, am, an, ar, as, az, be, bg, bn, br, \n    bs, ca, cs, cy, da, de, dz, el, en, eo, \n    es, et, eu, fa, fi, fo, fr, ga, gl, gu, \n    he, hi, hr, ht, hu, hy, id, is, it, ja, \n    jv, ka, kk, km, kn, ko, ku, ky, la, lb, \n    lo, lt, lv, mg, mk, ml, mn, mr, ms, mt, \n    nb, ne, nl, nn, no, oc, or, pa, pl, ps, \n    pt, qu, ro, ru, rw, se, si, sk, sl, sq, \n    sr, sv, sw, ta, te, th, tl, tr, ug, uk, \n    ur, vi, vo, wa, xh, zh, zu\n\nthe training data was drawn from 5 different sources:\n\n* jrc-acquis \n* clueweb 09\n* wikipedia\n* reuters rcv2\n* debian i18n\n\n\nusage\n-----\n\n    langid [options]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -s, --serve           launch web service\n  --host=host           host/ip to bind to\n  --port=port           port to listen on\n  -v                    increase verbosity (repeat for greater effect)\n  -m model              load model from file\n  -l langs, --langs=langs\n                        comma-separated set of target iso639 language codes\n                        (e.g en,de)\n  -r, --remote          auto-detect ip address for remote access\n  -b, --batch           specify a list of files on the command line\n  -d, --dist            show full distribution over languages\n  -u url, --url=url     langid of url\n  --line                process pipes line-by-line rather than as a document\n  -n, --normalize       normalize confidence scores to probability values\n\n\nthe simplest way to use ``langid.py`` is as a command-line tool, and you can \ninvoke using ``python langid.py``. if you installed ``langid.py`` as a python \nmodule (e.g. via ``pip install langid``), you can invoke ``langid`` instead of \n``python langid.py -n`` (the two are equivalent).  this will cause a prompt to \ndisplay. enter text to identify, and hit enter::\n\n  >>> this is a test\n  ('en', -54.41310358047485)\n  >>> questa e una prova\n  ('it', -35.41771221160889)\n\n\n``langid.py`` can also detect when the input is redirected (only tested under linux), and in this\ncase will process until eof rather than until newline like in interactive mode::\n\n  python langid.py < readme.rst \n  ('en', -22552.496054649353)\n\n\nthe value returned is the unnormalized probability estimate for the language. calculating \nthe exact probability estimate is disabled by default, but can be enabled through a flag::\n\n  python langid.py -n < readme.rst \n  ('en', 1.0)\n\nmore details are provided in this readme in the section on `probability normalization`.\n\nyou can also use ``langid.py`` as a python library::\n\n  # python\n  python 2.7.2+ (default, oct  4 2011, 20:06:09) \n  [gcc 4.6.1] on linux2\n  type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n  >>> import langid\n  >>> langid.classify(\"this is a test\")\n  ('en', -54.41310358047485)\n\nfinally, ``langid.py`` can use python's built-in ``wsgiref.simple_server`` (or ``fapws3`` if available) to\nprovide language identification as a web service. to do this, launch ``python langid.py -s``, and\naccess http://localhost:9008/detect . the web service supports get, post and put. if get is performed\nwith no data, a simple html forms interface is displayed.\n\nthe response is generated in json, here is an example::\n\n  {\"responsedata\": {\"confidence\": -54.41310358047485, \"language\": \"en\"}, \"responsedetails\": null, \"responsestatus\": 200}\n\na utility such as curl can be used to access the web service::\n\n  # curl -d \"q=this is a test\" localhost:9008/detect\n  {\"responsedata\": {\"confidence\": -54.41310358047485, \"language\": \"en\"}, \"responsedetails\": null, \"responsestatus\": 200}\n\nyou can also use http put::\n\n  # curl -t readme.rst localhost:9008/detect\n    % total    % received % xferd  average speed   time    time     time  current\n                                 dload  upload   total   spent    left  speed\n  100  2871  100   119  100  2752    117   2723  0:00:01  0:00:01 --:--:--  2727\n  {\"responsedata\": {\"confidence\": -22552.496054649353, \"language\": \"en\"}, \"responsedetails\": null, \"responsestatus\": 200}\n\nif no \"q=xxx\" key-value pair is present in the http post payload, ``langid.py`` will interpret the entire\nfile as a single query. this allows for redirection via curl::\n\n  # echo \"this is a test\" | curl -d @- localhost:9008/detect\n  {\"responsedata\": {\"confidence\": -54.41310358047485, \"language\": \"en\"}, \"responsedetails\": null, \"responsestatus\": 200}\n\n``langid.py`` will attempt to discover the host ip address automatically. often, this is set to localhost(127.0.1.1), even \nthough the machine has a different external ip address. ``langid.py`` can attempt to automatically discover the external\nip address. to enable this functionality, start ``langid.py`` with the ``-r`` flag.\n\n``langid.py`` supports constraining of the output language set using the ``-l`` flag and a comma-separated list of iso639-1 \nlanguage codes (the ``-n`` flag enables probability normalization)::\n\n  # python langid.py -n -l it,fr\n  >>> io non parlo italiano\n  ('it', 0.99999999988965627)\n  >>> je ne parle pas fran\u00e7ais\n  ('fr', 1.0)\n  >>> i don't speak english\n  ('it', 0.92210605672341062)\n\nwhen using ``langid.py`` as a library, the set_languages method can be used to constrain the language set::\n\n  python                      \n  python 2.7.2+ (default, oct  4 2011, 20:06:09) \n  [gcc 4.6.1] on linux2\n  type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n  >>> import langid\n  >>> langid.classify(\"i do not speak english\")\n  ('en', 0.57133487679900674)\n  >>> langid.set_languages(['de','fr','it'])\n  >>> langid.classify(\"i do not speak english\")\n  ('it', 0.99999835791478453)\n  >>> langid.set_languages(['en','it'])\n  >>> langid.classify(\"i do not speak english\")\n  ('en', 0.99176190378750373)\n\n\nbatch mode\n----------\n\n``langid.py`` supports batch mode processing, which can be invoked with the ``-b`` flag.\nin this mode, ``langid.py`` reads a list of paths to files to classify as arguments.\nif no arguments are supplied, ``langid.py`` reads the list of paths from ``stdin``,\nthis is useful for using ``langid.py`` with unix utilities such as ``find``.\n\nin batch mode, ``langid.py`` uses ``multiprocessing`` to invoke multiple instances of\nthe classifier, utilizing all available cpus to classify documents in parallel. \n\n\nprobability normalization\n-------------------------\n\nthe probabilistic model implemented by ``langid.py`` involves the multiplication of a\nlarge number of probabilities. for computational reasons, the actual calculations are\nimplemented in the log-probability space (a common numerical technique for dealing with\nvanishingly small probabilities). one side-effect of this is that it is not necessary to\ncompute a full probability in order to determine the most probable language in a set\nof candidate languages. however, users sometimes find it helpful to have a \"confidence\"\nscore for the probability prediction. thus, ``langid.py`` implements a re-normalization\nthat produces an output in the 0-1 range.\n\n``langid.py`` disables probability normalization by default. for\ncommand-line usages of ``langid.py``, it can be enabled by passing the ``-n`` flag. for\nprobability normalization in library use, the user must instantiate their own \n``languageidentifier``. an example of such usage is as follows::\n\n  >> from py3langid.langid import languageidentifier, model_file\n  >> identifier = languageidentifier.from_pickled_model(model_file, norm_probs=true)\n  >> identifier.classify(\"this is a test\")\n  ('en', 0.9999999909903544)\n\n\ntraining a model\n----------------\n\nso far python 2.7 only, see the `original instructions <https://github.com/saffsd/langid.py#training-a-model>`_.\n\n\nread more\n---------\n\n``langid.py`` is based on published research. [1] describes the ld feature selection technique in detail,\nand [2] provides more detail about the module ``langid.py`` itself.\n\n[1] lui, marco and timothy baldwin (2011) cross-domain feature selection for language identification, \nin proceedings of the fifth international joint conference on natural language processing (ijcnlp 2011), \nchiang mai, thailand, pp. 553\u2014561. available from http://www.aclweb.org/anthology/i11-1062\n\n[2] lui, marco and timothy baldwin (2012) langid.py: an off-the-shelf language identification tool, \nin proceedings of the 50th annual meeting of the association for computational linguistics (acl 2012), \ndemo session, jeju, republic of korea. available from www.aclweb.org/anthology/p12-3005\n\n\n",
  "docs_url": null,
  "keywords": "language detection,language identification,langid",
  "license": "bsd",
  "name": "py3langid",
  "package_url": "https://pypi.org/project/py3langid/",
  "project_url": "https://pypi.org/project/py3langid/",
  "project_urls": {
    "Homepage": "https://github.com/adbar/py3langid"
  },
  "release_url": "https://pypi.org/project/py3langid/0.2.2/",
  "requires_dist": [
    "numpy"
  ],
  "requires_python": ">=3.6",
  "summary": "fork of the language identification tool langid.py, featuring a modernized codebase and faster execution times.",
  "version": "0.2.2",
  "releases": [],
  "developers": [
    "adrien_barbaresi",
    "barbaresi@bbaw.de"
  ],
  "kwds": "py3langid langid languageidentifier languages language",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_py3langid",
  "homepage": "https://github.com/adbar/py3langid",
  "release_count": 6,
  "dependency_ids": [
    "pypi_numpy"
  ]
}