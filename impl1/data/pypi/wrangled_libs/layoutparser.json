{
  "classifiers": [
    "intended audience :: developers",
    "intended audience :: education",
    "intended audience :: science/research",
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering :: artificial intelligence"
  ],
  "description": "<p align=\"center\">\n  <img src=\"https://github.com/layout-parser/layout-parser/raw/main/.github/layout-parser.png\" alt=\"layout parser logo\" width=\"35%\">\n  <h3 align=\"center\">\n  a unified toolkit for deep learning based document image analysis\n  </h3>\n</p>\n\n<p align=center>\n<a href=\"https://pypi.org/project/layoutparser/\"><img src=\"https://img.shields.io/pypi/v/layoutparser?color=%23099cec&label=pypi%20package&logo=pypi&logocolor=white\" title=\"the current version of layout parser\"></a>\n<a href=\"https://github.com/layout-parser/layout-parser/blob/main/license\"><img src=\"https://img.shields.io/pypi/l/layoutparser\" title=\"layout parser uses apache 2 license\"></a>\n<img alt=\"pypi - downloads\" src=\"https://img.shields.io/pypi/dm/layoutparser\">\n</p>\n\n<p align=center>\n<a href=\"https://arxiv.org/abs/2103.15348\"><img src=\"https://img.shields.io/badge/paper-2103.15348-b31b1b.svg\" title=\"layout parser paper\"></a>\n<a href=\"https://layout-parser.github.io\"><img src=\"https://img.shields.io/badge/website-layout--parser.github.io-informational.svg\" title=\"layout parser paper\"></a>\n<a href=\"https://layout-parser.readthedocs.io/en/latest/\"><img src=\"https://img.shields.io/badge/doc-layout--parser.readthedocs.io-light.svg\" title=\"layout parser documentation\"></a>\n</p>\n\n---\n\n## what is layoutparser\n\n![example usage](https://github.com/layout-parser/layout-parser/raw/main/.github/example.png)\n\nlayoutparser aims to provide a wide range of tools that aims to streamline document image analysis (dia) tasks. please check the layoutparser [demo video](https://youtu.be/8ya5xb4dg8c) (1 min) or [full talk](https://www.youtube.com/watch?v=yg0qeppgygy) (15 min) for details. and here are some key features:\n\n- layoutparser provides a rich repository of deep learning models for layout detection as well as a set of unified apis for using them. for example, \n  \n  <details>\n  <summary>perform dl layout detection in 4 lines of code</summary>\n  \n  ```python\n  import layoutparser as lp\n  model = lp.autolayoutmodel('lp://efficientdete/publaynet')\n  # image = image.open(\"path/to/image\")\n  layout = model.detect(image) \n  ```\n  \n  </details>\n\n- layoutparser comes with a set of layout data structures with carefully designed apis that are optimized for document image analysis tasks. for example, \n\n  <details>\n  <summary>selecting layout/textual elements in the left column of a page</summary>\n  \n  ```python\n  image_width = image.size[0]\n  left_column = lp.interval(0, image_width/2, axis='x')\n  layout.filter_by(left_column, center=true) # select objects in the left column \n  ```\n  \n  </details>\n\n  <details>\n  <summary>performing ocr for each detected layout region</summary>\n  \n  ```python\n  ocr_agent = lp.tesseractagent()\n  for layout_region in layout: \n      image_segment = layout_region.crop(image)\n      text = ocr_agent.detect(image_segment)\n  ```\n  \n  </details>  \n    \n  <details>\n  <summary>flexible apis for visualizing the detected layouts</summary>\n  \n  ```python\n  lp.draw_box(image, layout, box_width=1, show_element_id=true, box_alpha=0.25)\n  ```\n  \n  </details>  \n    \n  </details>  \n    \n  <details>\n  <summary>loading layout data stored in json, csv, and even pdfs</summary>\n  \n  ```python \n  layout = lp.load_json(\"path/to/json\")\n  layout = lp.load_csv(\"path/to/csv\")\n  pdf_layout = lp.load_pdf(\"path/to/pdf\")\n  ```\n  \n  </details>\n\n- layoutparser is also a open platform that enables the sharing of layout detection models and dia pipelines among the community. \n  <details>\n  <summary><a href=\"https://layout-parser.github.io/platform/\">check</a> the layoutparser open platform</summary>\n  </details>\n\n  <details>\n  <summary><a href=\"https://github.com/layout-parser/platform\">submit</a> your models/pipelines to layoutparser</summary>\n  </details>\n\n## installation \n\nafter several major updates, layoutparser provides various functionalities and deep learning models from different backends. but it still easy to install layoutparser, and we designed the installation method in a way such that you can choose to install only the needed dependencies for your project:\n\n```bash\npip install layoutparser # install the base layoutparser library with  \npip install \"layoutparser[layoutmodels]\" # install dl layout model toolkit \npip install \"layoutparser[ocr]\" # install ocr toolkit\n```\n\nextra steps are needed if you want to use detectron2-based models. please check [installation.md](installation.md) for additional details on layoutparser installation. \n\n## examples \n\nwe provide a series of examples for to help you start using the layout parser library: \n\n1. [table ocr and results parsing](https://github.com/layout-parser/layout-parser/blob/main/examples/ocr%20tables%20and%20parse%20the%20output.ipynb): `layoutparser` can be used for conveniently ocr documents and convert the output in to structured data. \n\n2. [deep layout parsing example](https://github.com/layout-parser/layout-parser/blob/main/examples/deep%20layout%20parsing.ipynb): with the help of deep learning, `layoutparser` supports the analysis very complex documents and processing of the hierarchical structure in the layouts. \n\n## contributing\n\nwe encourage you to contribute to layout parser! please check out the [contributing guidelines](.github/contributing.md) for guidelines about how to proceed. join us!\n\n## citing `layoutparser`\n\nif you find `layoutparser` helpful to your work, please consider citing our tool and [paper](https://arxiv.org/pdf/2103.15348.pdf) using the following bibtex entry.\n\n```\n@article{shen2021layoutparser,\n  title={layoutparser: a unified toolkit for deep learning based document image analysis},\n  author={shen, zejiang and zhang, ruochen and dell, melissa and lee, benjamin charles germain and carlson, jacob and li, weining},\n  journal={arxiv preprint arxiv:2103.15348},\n  year={2021}\n}\n```\n\n",
  "docs_url": null,
  "keywords": "layout analysis,deep learning",
  "license": "apache-2.0",
  "name": "layoutparser",
  "package_url": "https://pypi.org/project/layoutparser/",
  "project_url": "https://pypi.org/project/layoutparser/",
  "project_urls": {
    "Homepage": "https://github.com/Layout-Parser/layout-parser"
  },
  "release_url": "https://pypi.org/project/layoutparser/0.3.4/",
  "requires_dist": [
    "numpy",
    "opencv-python",
    "scipy",
    "pandas",
    "pillow",
    "pyyaml (>=5.1)",
    "iopath",
    "pdfplumber",
    "pdf2image",
    "torch ; extra == 'effdet'",
    "torchvision ; extra == 'effdet'",
    "effdet ; extra == 'effdet'",
    "google-cloud-vision (==1) ; extra == 'gcv'",
    "torch ; extra == 'layoutmodels'",
    "torchvision ; extra == 'layoutmodels'",
    "effdet ; extra == 'layoutmodels'",
    "google-cloud-vision (==1) ; extra == 'ocr'",
    "pytesseract ; extra == 'ocr'",
    "paddlepaddle (==2.1.0) ; extra == 'paddledetection'",
    "pytesseract ; extra == 'tesseract'"
  ],
  "requires_python": ">=3.6",
  "summary": "a unified toolkit for deep learning based document image analysis",
  "version": "0.3.4",
  "releases": [],
  "developers": [
    "layoutparser@gmail.com",
    "zejiang_shen"
  ],
  "kwds": "layout layouts layoutparser image_width pdf_layout",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_layoutparser",
  "homepage": "https://github.com/layout-parser/layout-parser",
  "release_count": 11,
  "dependency_ids": [
    "pypi_effdet",
    "pypi_google_cloud_vision",
    "pypi_iopath",
    "pypi_numpy",
    "pypi_opencv_python",
    "pypi_paddlepaddle",
    "pypi_pandas",
    "pypi_pdf2image",
    "pypi_pdfplumber",
    "pypi_pillow",
    "pypi_pytesseract",
    "pypi_pyyaml",
    "pypi_scipy",
    "pypi_torch",
    "pypi_torchvision"
  ]
}