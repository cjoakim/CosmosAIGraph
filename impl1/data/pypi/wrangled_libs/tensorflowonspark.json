{
  "classifiers": [
    "intended audience :: developers",
    "intended audience :: science/research",
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: software development :: libraries"
  ],
  "description": "<!--\ncopyright 2019 yahoo inc.\nlicensed under the terms of the apache 2.0 license.\nplease see license file in the project root for terms.\n-->\n# tensorflowonspark\n> _tensorflowonspark brings scalable deep learning to apache hadoop and apache spark\nclusters._\n\n[![build status](https://cd.screwdriver.cd/pipelines/6384/badge)](https://cd.screwdriver.cd/pipelines/6384)\n[![package](https://img.shields.io/badge/package-pypi-blue.svg)](https://pypi.org/project/tensorflowonspark/)\n[![downloads](https://img.shields.io/pypi/dm/tensorflowonspark.svg)](https://img.shields.io/pypi/dm/tensorflowonspark.svg)\n[![documentation](https://img.shields.io/badge/documentation-latest-blue.svg)](https://yahoo.github.io/tensorflowonspark/)\n\nby combining salient features from the [tensorflow](https://www.tensorflow.org) deep learning framework with [apache spark](http://spark.apache.org) and [apache hadoop](http://hadoop.apache.org), tensorflowonspark enables distributed\ndeep learning on a cluster of gpu and cpu servers.\n\nit enables both distributed tensorflow training and\ninferencing on spark clusters, with a goal to minimize the amount\nof code changes required to run existing tensorflow programs on a\nshared grid.  its spark-compatible api helps manage the tensorflow\ncluster with the following steps:\n\n1. **startup** - launches the tensorflow main function on the executors, along with listeners for data/control messages.\n1. **data ingestion**\n   - **inputmode.tensorflow** - leverages tensorflow's built-in apis to read data files directly from hdfs.\n   - **inputmode.spark** - sends spark rdd data to the tensorflow nodes via a `tfnode.datafeed` class.  note that we leverage the [hadoop input/output format](https://github.com/tensorflow/ecosystem/tree/master/hadoop) to access tfrecords on hdfs.\n1. **shutdown** - shuts down the tensorflow workers and ps nodes on the executors.\n\n## table of contents\n\n- [background](#background)\n- [install](#install)\n- [usage](#usage)\n- [api](#api)\n- [contribute](#contribute)\n- [license](#license)\n\n## background\n\ntensorflowonspark was developed by yahoo for large-scale distributed\ndeep learning on our hadoop clusters in yahoo's private cloud.\n\ntensorflowonspark provides some important benefits (see [our\nblog](https://developer.yahoo.com/blogs/157196317141/))\nover alternative deep learning solutions.\n   * easily migrate existing tensorflow programs with <10 lines of code change.\n   * support all tensorflow functionalities: synchronous/asynchronous training, model/data parallelism, inferencing and tensorboard.\n   * server-to-server direct communication achieves faster learning when available.\n   * allow datasets on hdfs and other sources pushed by spark or pulled by tensorflow.\n   * easily integrate with your existing spark data processing pipelines.\n   * easily deployed on cloud or on-premise and on cpus or gpus.\n\n## install\n\ntensorflowonspark is provided as a pip package, which can be installed on single machines via:\n```\n# for tensorflow>=2.0.0\npip install tensorflowonspark\n\n# for tensorflow<2.0.0\npip install tensorflowonspark==1.4.4\n```\n\nfor distributed clusters, please see our [wiki site](../../wiki) for detailed documentation for specific environments, such as our getting started guides for [single-node spark standalone](https://github.com/yahoo/tensorflowonspark/wiki/getstarted_standalone), [yarn clusters](../../wiki/getstarted_yarn) and [aws ec2](../../wiki/getstarted_ec2).  note: the windows operating system is not currently supported due to [this issue](https://github.com/yahoo/tensorflowonspark/issues/36).\n\n## usage\n\nto use tensorflowonspark with an existing tensorflow application, you can follow our [conversion guide](../../wiki/conversion-guide) to describe the required changes.  additionally, our [wiki site](../../wiki) has pointers to some presentations which provide an overview of the platform.\n\n**note: since tensorflow 2.x breaks api compatibility with tensorflow 1.x, the examples have been updated accordingly.  if you are using tensorflow 1.x, you will need to checkout the `v1.4.4` tag for compatible examples and instructions.**\n\n## api\n\n[api documentation](https://yahoo.github.io/tensorflowonspark/) is automatically generated from the code.\n\n## contribute\n\nplease join the [tensorflowonspark user group](https://groups.google.com/forum/#!forum/tensorflowonspark-users) for discussions and questions.  if you have a question, please review our [faq](../../wiki/frequently-asked-questions) before posting.\n\ncontributions are always welcome.  for more information, please see our [guide for getting involved](contributing.md).\n\n## license\n\nthe use and distribution terms for this software are covered by the apache 2.0 license.\nsee [license](license) file for terms.\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache 2.0",
  "name": "tensorflowonspark",
  "package_url": "https://pypi.org/project/tensorflowonspark/",
  "project_url": "https://pypi.org/project/tensorflowonspark/",
  "project_urls": {
    "Homepage": "https://github.com/yahoo/TensorFlowOnSpark"
  },
  "release_url": "https://pypi.org/project/tensorflowonspark/2.2.5/",
  "requires_dist": [],
  "requires_python": ">=\"3.6\"",
  "summary": "deep learning with tensorflow on apache spark clusters",
  "version": "2.2.5",
  "releases": [],
  "developers": [
    "lee_yang",
    "leewyang@gmail.com"
  ],
  "kwds": "_tensorflowonspark tensorflowonspark tensorflow spark tensorboard",
  "license_kwds": "apache 2.0",
  "libtype": "pypi",
  "id": "pypi_tensorflowonspark",
  "homepage": "https://github.com/yahoo/tensorflowonspark",
  "release_count": 33,
  "dependency_ids": []
}