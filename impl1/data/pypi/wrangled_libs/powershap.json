{
  "classifiers": [
    "license :: osi approved :: mit license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "\t\n<p align=\"center\">\n    <a href=\"#readme\">\n        <img alt=\"powershap logo\" src=\"https://raw.githubusercontent.com/predict-idlab/powershap/main/powershap_full_scaled.png\" width=70%>\n    </a>\n</p>\n\n[![pypi latest release](https://img.shields.io/pypi/v/powershap.svg)](https://pypi.org/project/powershap/)\n[![support-version](https://img.shields.io/pypi/pyversions/powershap)](https://img.shields.io/pypi/pyversions/powershap)\n[![codecov](https://img.shields.io/codecov/c/github/predict-idlab/powershap?logo=codecov)](https://codecov.io/gh/predict-idlab/powershap)\n[![downloads](https://pepy.tech/badge/powershap)](https://pepy.tech/project/powershap)\n[![prs welcome](https://img.shields.io/badge/prs-welcome-brightgreen.svg?)](http://makeapullrequest.com)\n[![testing](https://github.com/predict-idlab/powershap/actions/workflows/test.yml/badge.svg)](https://github.com/predict-idlab/powershap/actions/workflows/test.yml)\n[![doi](https://zenodo.org/badge/470633431.svg)](https://zenodo.org/badge/latestdoi/470633431)\n\n> *powershap* is a **feature selection method** that uses statistical hypothesis testing and power calculations on **shapley values**, enabling fast and intuitive wrapper-based feature selection.  \n\n## installation \u2699\ufe0f\n\n| [**pip**](https://pypi.org/project/powershap/) | `pip install powershap` | \n| ---| ----|\n\n## usage \ud83d\udee0\n\n*powershap* is built to be intuitive, it supports various models including linear, tree-based, and even deep learning models for classification and regression tasks.  \n<!-- it is also implented as sklearn `transformer` component, allowing convenient integration in `sklearn` pipelines. -->\n\n```py\nfrom powershap import powershap\nfrom catboost import catboostclassifier\n\nx, y = ...  # your classification dataset\n\nselector = powershap(\n    model=catboostclassifier(n_estimators=250, verbose=0, use_best_model=true)\n)\n\nselector.fit(x, y)  # fit the powershap feature selector\nselector.transform(x)  # reduce the dataset to the selected features\n\n```\n\n## features \u2728\n\n* default automatic mode\n* `scikit-learn` compatible\n* supports various models\n* insights into the feature selection method: call the `._processed_shaps_df` on a fitted `powershap` feature selector.\n* tested code!\n\n## benchmarks \u23f1\n\ncheck out our benchmark results [here](examples/results/).  \n\n## how does it work \u2049\ufe0f\n\npowershap is built on the core assumption that *an informative feature will have a larger impact on the prediction compared to a known random feature.*\n\n* powershap trains multiple models with different random seeds on different subsets of the data. each iteration it adds a random uniform feature to the dataset for training.\n* in a single iteration after training a model, powershap calculates the absolute shapley values of all features, including the random feature. if there are multiple outputs or multiple classes, powershap uses the maximum across these multiple outputs. these values are then averaged for each feature, symbolising the impact of the feature in this iteration.\n* after performing all iterations, each feature then has an array of impacts. the impact array of each feature is then compared to the average of the random feature impact array using the percentile formula to provide a p-value. this tests whether the feature has a larger impact than the random feature and outputs a low p-value if true. \n* powershap then outputs all features with a p-value below the provided threshold. the threshold is by default 0.01.\n\n\n### automatic mode \ud83e\udd16\n\nthe required number of iterations and the threshold values are hyperparameters of powershap. however, to *avoid manually optimizing the hyperparameters* powershap by default uses an automatic mode that automatically determines these hyperparameters. \n\n* the automatic mode first starts with executing powershap using ten iterations.\n* then, for each feature powershap calculates the effect size and the statistical power of the test using a student-t power test. \n* using the calculated effect size, powershap then calculates the required iterations to achieve a predefined power requirement. by default this is 0.99, which represents a false positive probability of 0.01.\n* if the required iterations are larger than the already performed iterations, powershap then further executes for the extra required iterations. \n* afterward, powershap re-calculates the required iterations and it keeps re-executing until the required iterations are met.\n\n## referencing our package :memo:\n\nif you use *powershap* in a scientific publication, we would highly appreciate citing us as:\n\n```bibtex\n@misc{https://doi.org/10.48550/arxiv.2206.08394,\n  doi = {10.48550/arxiv.2206.08394},\n  url = {https://arxiv.org/abs/2206.08394},\n  author = {verhaeghe, jarne and van der donckt, jeroen and ongenae, femke and van hoecke, sofie},\n  keywords = {machine learning (cs.lg), machine learning (stat.ml), fos: computer and information sciences, fos: computer and information sciences},\n  title = {powershap: a power-full shapley feature selection method},\n  publisher = {arxiv},\n  year = {2022}\n  copyright = {arxiv.org perpetual, non-exclusive license}\n}\n\n```\n\npaper is accepted at ecml pkdd 2022 and will be presented there. the preprint can be found on arxiv ([link](https://arxiv.org/abs/2206.08394)) and on the github.\n\n---\n\n<p align=\"center\">\n\ud83d\udc64 <i>jarne verhaeghe, jeroen van der donckt</i>\n</p>\n",
  "docs_url": null,
  "keywords": "feature selection,shap,data-science,machine learning",
  "license": "mit",
  "name": "powershap",
  "package_url": "https://pypi.org/project/powershap/",
  "project_url": "https://pypi.org/project/powershap/",
  "project_urls": {
    "Homepage": "https://github.com/predict-idlab/powershap",
    "Repository": "https://github.com/predict-idlab/powershap"
  },
  "release_url": "https://pypi.org/project/powershap/0.0.9/",
  "requires_dist": [
    "catboost (>=1.0.5,<2.0.0)",
    "statsmodels (>=0.13.2,<0.14.0)",
    "numpy (>=1.21,<2.0)",
    "pandas (>=1.3,<2.0)",
    "shap (>=0.40,<0.41)",
    "scikit-learn"
  ],
  "requires_python": ">=3.7,<3.11",
  "summary": "feature selection using statistical significance of shap values",
  "version": "0.0.9",
  "releases": [],
  "developers": [
    "jarne_verhaeghe"
  ],
  "kwds": "powershap powershap_full_scaled features shap feature",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_powershap",
  "homepage": "https://github.com/predict-idlab/powershap",
  "release_count": 13,
  "dependency_ids": [
    "pypi_catboost",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_scikit_learn",
    "pypi_shap",
    "pypi_statsmodels"
  ]
}