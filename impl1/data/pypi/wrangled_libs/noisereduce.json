{
  "classifiers": [
    "intended audience :: science/research",
    "license :: osi approved :: bsd license",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "topic :: education",
    "topic :: scientific/engineering"
  ],
  "description": "[![build status](https://travis-ci.com/timsainb/noisereduce.svg?branch=master)](https://travis-ci.com/timsainb/noisereduce)\n[![coverage status](https://coveralls.io/repos/github/timsainb/noisereduce/badge.svg?branch=master)](https://coveralls.io/github/timsainb/noisereduce?branch=master)\n[![binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/timsainb/noisereduce/master?filepath=notebooks%2f1.0-test-noise-reduction.ipynb)\n[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timsainb/noisereduce/blob/master/notebooks/1.0-test-noise-reduction.ipynb)\n[![pypi version](https://badge.fury.io/py/noisereduce.svg)](https://badge.fury.io/py/noisereduce)\n\n<div style=\"text-align:center\">\n<p align=\"center\">\n  <img src=\"assets/noisereduce.png\", width=\"100%\">\n</p>\n</div>\n\n# noise reduction in python using spectral gating\nnoisereduce is a noise reduction algorithm in python that reduces noise in time-domain signals like speech, bioacoustics, and physiological signals. it relies on a method called \"spectral gating\" which is a form of [noise gate](https://en.wikipedia.org/wiki/noise_gate). it works by computing a spectrogram of a signal (and optionally a noise signal) and estimating a noise threshold (or gate) for each frequency band of that signal/noise. that threshold is used to compute a mask, which gates noise below the frequency-varying threshold. \n\nthe most recent version of noisereduce comprises two algorithms:\n1. **stationary noise reduction**: keeps the estimated noise threshold at the same level across the whole signal\n2. **non-stationary noise reduction**: continuously updates the estimated noise threshold over time\n\n### version 3 updates:\n- includes a pytorch-based implementation of spectral gating, an algorithm for denoising audio signals. \n- you can now create a noisereduce nn.module object which allows it to be used either as a standalone module or as part of a larger neural network architecture.\n- the run time of the algorithm decreases substantially.\n\n### version 2 updates:\n- added two forms of spectral gating noise reduction: stationary noise reduction, and non-stationary noise reduction. \n- added multiprocessing so you can perform noise reduction on bigger data.\n- the new version breaks the api of the old version. \n- the previous version is still available at `from noisereduce.noisereducev1 import reduce_noise`\n- you can now create a noisereduce object which allows you to reduce noise on subsets of longer recordings\n\n# stationary noise reduction\n- the basic intuition is that statistics are calculated on  each frequency channel to determine a noise gate. then the gate is applied to the signal.\n- this algorithm is based (but not completely reproducing) on the one [outlined by audacity](https://wiki.audacityteam.org/wiki/how_audacity_noise_reduction_works) for the **noise reduction effect** ([link to c++ code](https://github.com/audacity/audacity/blob/master/src/effects/noisereduction.cpp))\n- the algorithm takes two inputs: \n    1. a *noise* clip containing prototypical noise of clip (optional)\n    2. a *signal* clip containing the signal and the noise intended to be removed\n\n### steps of the stationary noise reduction algorithm\n1. a spectrogram is calculated over the noise audio clip\n2. statistics are calculated over spectrogram of the the noise (in frequency)\n3. a threshold is calculated based upon the statistics of the noise (and the desired sensitivity of the algorithm) \n4. a spectrogram is calculated over the signal\n5. a mask is determined by comparing the signal spectrogram to the threshold\n6. the mask is smoothed with a filter over frequency and time\n7. the mask is appled to the spectrogram of the signal, and is inverted\n*if the noise signal is not provided, the algorithm will treat the signal as the noise clip, which tends to work pretty well*\n\n# non-stationary noise reduction\n- the non-stationary noise reduction algorithm is an extension of the stationary noise reduction algorithm, but allowing the noise gate to change over time. \n- when you know the timescale that your signal occurs on (e.g. a bird call can be a few hundred milliseconds), you can set your noise threshold based on the assumption that events occuring on longer timescales are noise. \n- this algorithm was motivated by a recent method in bioacoustics called per-channel energy normalization. \n\n### steps of the non-stationary noise reduction algorithm\n1. a spectrogram is calculated over the signal\n2. a time-smoothed version of the spectrogram is computed using an iir filter aplied forward and backward on each frequency channel.\n3. a mask is computed based on that time-smoothed spectrogram\n4. the mask is smoothed with a filter over frequency and time\n5. the mask is appled to the spectrogram of the signal, and is inverted\n\n# installation\n`pip install noisereduce`\n\n# usage\nsee example notebook: [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timsainb/noisereduce/blob/master/notebooks/1.0-test-noise-reduction.ipynb)\nparallel computing example: [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timsainb/noisereduce/blob/master/notebooks/2.0-test-noisereduce-pytorch.ipynb)\n\n## reduce_noise\n\n### simplest usage\n```\nfrom scipy.io import wavfile\nimport noisereduce as nr\n# load data\nrate, data = wavfile.read(\"mywav.wav\")\n# perform noise reduction\nreduced_noise = nr.reduce_noise(y=data, sr=rate)\nwavfile.write(\"mywav_reduced_noise.wav\", rate, reduced_noise)\n```\n\n### arguments to `reduce_noise`\n```\ny : np.ndarray [shape=(# frames,) or (# channels, # frames)], real-valued\n      input signal\n  sr : int\n      sample rate of input signal / noise signal\n  y_noise : np.ndarray [shape=(# frames,) or (# channels, # frames)], real-valued\n      noise signal to compute statistics over (only for non-stationary noise reduction).\n  stationary : bool, optional\n      whether to perform stationary, or non-stationary noise reduction, by default false\n  prop_decrease : float, optional\n      the proportion to reduce the noise by (1.0 = 100%), by default 1.0\n  time_constant_s : float, optional\n      the time constant, in seconds, to compute the noise floor in the non-stationary\n      algorithm, by default 2.0\n  freq_mask_smooth_hz : int, optional\n      the frequency range to smooth the mask over in hz, by default 500\n  time_mask_smooth_ms : int, optional\n      the time range to smooth the mask over in milliseconds, by default 50\n  thresh_n_mult_nonstationary : int, optional\n      only used in nonstationary noise reduction., by default 1\n  sigmoid_slope_nonstationary : int, optional\n      only used in nonstationary noise reduction., by default 10\n  n_std_thresh_stationary : int, optional\n      number of standard deviations above mean to place the threshold between\n      signal and noise., by default 1.5\n  tmp_folder : [type], optional\n      temp folder to write waveform to during parallel processing. defaults to \n      default temp folder for python., by default none\n  chunk_size : int, optional\n      size of signal chunks to reduce noise over. larger sizes\n      will take more space in memory, smaller sizes can take longer to compute.\n      , by default 60000\n      padding : int, optional\n      how much to pad each chunk of signal by. larger pads are\n      needed for larger time constants., by default 30000\n  n_fft : int, optional\n      length of the windowed signal after padding with zeros.\n      the number of rows in the stft matrix ``d`` is ``(1 + n_fft/2)``.\n      the default value, ``n_fft=2048`` samples, corresponds to a physical\n      duration of 93 milliseconds at a sample rate of 22050 hz, i.e. the\n      default sample rate in librosa. this value is well adapted for music\n      signals. however, in speech processing, the recommended value is 512,\n      corresponding to 23 milliseconds at a sample rate of 22050 hz.\n      in any case, we recommend setting ``n_fft`` to a power of two for\n      optimizing the speed of the fast fourier transform (fft) algorithm., by default 1024\n  win_length : [type], optional\n      each frame of audio is windowed by ``window`` of length ``win_length``\n      and then padded with zeros to match ``n_fft``.\n      smaller values improve the temporal resolution of the stft (i.e. the\n      ability to discriminate impulses that are closely spaced in time)\n      at the expense of frequency resolution (i.e. the ability to discriminate\n      pure tones that are closely spaced in frequency). this effect is known\n      as the time-frequency localization trade-off and needs to be adjusted\n      according to the properties of the input signal ``y``.\n      if unspecified, defaults to ``win_length = n_fft``., by default none\n  hop_length : [type], optional\n      number of audio samples between adjacent stft columns.\n      smaller values increase the number of columns in ``d`` without\n      affecting the frequency resolution of the stft.\n      if unspecified, defaults to ``win_length // 4`` (see below)., by default none\n  n_jobs : int, optional\n      number of parallel jobs to run. set at -1 to use all cpu cores, by default 1\n  torch_flag: bool, optional\n      whether to use the torch version of spectral gating, by default false\n  device: str, optional\n      a device to run the torch spectral gating on, by default \"cuda\"\n```\n\n## torch\nsee example notebook: [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timsainb/noisereduce/blob/master/notebooks/3.0-torchgate-as-nn-module.ipynb)\n### simplest usage\n```\nimport torch\nfrom noisereduce.torchgate import torchgate as tg\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\n# create torchgating instance\ntg = tg(sr=8000, nonstationary=true).to(device)\n\n# apply spectral gate to noisy speech signal\nnoisy_speech = torch.randn(3, 32000, device=device)\nenhanced_speech = tg(noisy_speech)\n```\n### arguments\n| parameter                | description                                                                                           |\n|--------------------------|-------------------------------------------------------------------------------------------------------|\n| sr                       | sample rate of the input signal.                                                                      |\n| n_fft                    | the size of the fft.                                                                                  |\n| hop_length               | the number of samples between adjacent stft columns.                                                  |\n| win_length               | the window size for the stft. if none, defaults to n_fft.                                             |\n| freq_mask_smooth_hz      | the frequency smoothing width in hz for the masking filter. if none, no frequency masking is applied. |\n| time_mask_smooth_ms      | the time smoothing width in milliseconds for the masking filter. if none, no time masking is applied. |\n| n_std_thresh_stationary  | the number of standard deviations above the noise mean to consider as signal for stationary noise.    |\n| nonstationary            | whether to use non-stationary noise masking.                                                          |\n| n_movemean_nonstationary | the number of frames to use for the moving average in the non-stationary noise mask.                  |\n| n_thresh_nonstationary   | the multiplier to apply to the sigmoid function in the non-stationary noise mask.                     |\n| temp_coeff_nonstationary | the temperature coefficient to apply to the sigmoid function in the non-stationary noise mask.        |\n| prop_decrease            | the proportion of decrease to apply to the mask.                                                      |\n\n## choosing between stationary and non-stantionary noise reduction \n\ni discuss stationary and non-stationary noise reduction in [this paper](https://www.frontiersin.org/articles/10.3389/fnbeh.2021.811737/full). \n\n<div style=\"text-align:center\">\n<p align=\"center\">\n  <img src=\"assets/stationary-vs-nonstationary.jpg\", width=\"100%\">\n</p>\n</div>\n\n*figure caption: stationary and non-stationary spectral gating noise reduction. (a) an overview of each algorithm. stationary noise reduction typically takes in an explicit noise signal to calculate statistics and performs noise reduction over the entire signal uniformly. non-stationary noise reduction dynamically estimates and reduces noise concurrently. (b) stationary and non-stationary spectral gating noise reduction using the noisereduce python package (sainburg, 2019) applied to a common chiffchaff (phylloscopus collybita) song (stowell et al., 2019) with an airplane noise in the background. the bottom frame depicts the difference between the two algorithms.*\n\n## citation\nif you use this code in your research, please cite it:\n```\n\n@article{sainburg2020finding,\n  title={finding, visualizing, and quantifying latent structure across diverse animal vocal repertoires},\n  author={sainburg, tim and thielk, marvin and gentner, timothy q},\n  journal={plos computational biology},\n  volume={16},\n  number={10},\n  pages={e1008228},\n  year={2020},\n  publisher={public library of science}\n}\n\n@software{tim_sainburg_2019_3243139,\n  author       = {tim sainburg},\n  title        = {timsainb/noisereduce: v1.0},\n  month        = jun,\n  year         = 2019,\n  publisher    = {zenodo},\n  version      = {db94fe2},\n  doi          = {10.5281/zenodo.3243139},\n  url          = {https://doi.org/10.5281/zenodo.3243139}\n}\n\n\n```\n--------\n\n<p><small>project based on the <a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "noisereduce",
  "package_url": "https://pypi.org/project/noisereduce/",
  "project_url": "https://pypi.org/project/noisereduce/",
  "project_urls": {
    "Homepage": "https://github.com/timsainb/noisereduce"
  },
  "release_url": "https://pypi.org/project/noisereduce/3.0.0/",
  "requires_dist": [
    "scipy",
    "matplotlib",
    "librosa",
    "numpy",
    "tqdm",
    "torch >=1.9.0 ; extra == 'pytorch'"
  ],
  "requires_python": "",
  "summary": "noise reduction using spectral gating in python",
  "version": "3.0.0",
  "releases": [],
  "developers": [
    "tim_sainburg"
  ],
  "kwds": "noisereduce noisereducev1 noise_gate badge_logo mywav_reduced_noise",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_noisereduce",
  "homepage": "https://github.com/timsainb/noisereduce",
  "release_count": 9,
  "dependency_ids": [
    "pypi_librosa",
    "pypi_matplotlib",
    "pypi_numpy",
    "pypi_scipy",
    "pypi_torch",
    "pypi_tqdm"
  ]
}