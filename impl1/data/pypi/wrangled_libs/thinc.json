{
  "classifiers": [
    "development status :: 5 - production/stable",
    "environment :: console",
    "intended audience :: developers",
    "intended audience :: science/research",
    "license :: osi approved :: mit license",
    "operating system :: macos :: macos x",
    "operating system :: microsoft :: windows",
    "operating system :: posix :: linux",
    "programming language :: cython",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering"
  ],
  "description": "<a href=\"https://explosion.ai\"><img src=\"https://explosion.ai/assets/img/logo.svg\" width=\"125\" height=\"125\" align=\"right\" /></a>\n\n# thinc: a refreshing functional take on deep learning, compatible with your favorite libraries\n\n### from the makers of [spacy](https://spacy.io) and [prodigy](https://prodi.gy)\n\n[thinc](https://thinc.ai) is a **lightweight deep learning library** that offers\nan elegant, type-checked, functional-programming api for **composing models**,\nwith support for layers defined in other frameworks such as **pytorch,\ntensorflow and mxnet**. you can use thinc as an interface layer, a standalone\ntoolkit or a flexible way to develop new models. previous versions of thinc have\nbeen running quietly in production in thousands of companies, via both\n[spacy](https://spacy.io) and [prodigy](https://prodi.gy). we wrote the new\nversion to let users **compose, configure and deploy custom models** built with\ntheir favorite framework.\n\n[![tests](https://github.com/explosion/thinc/actions/workflows/tests.yml/badge.svg)](https://github.com/explosion/thinc/actions/workflows/tests.yml)\n[![current release version](https://img.shields.io/github/v/release/explosion/thinc.svg?include_prereleases&sort=semver&style=flat-square&logo=github)](https://github.com/explosion/thinc/releases)\n[![pypi version](https://img.shields.io/pypi/v/thinc.svg?include_prereleases&sort=semver&style=flat-square&logo=pypi&logocolor=white)](https://pypi.python.org/pypi/thinc)\n[![conda version](https://img.shields.io/conda/vn/conda-forge/thinc.svg?style=flat-square&logo=conda-forge&logocolor=white)](https://anaconda.org/conda-forge/thinc)\n[![python wheels](https://img.shields.io/badge/wheels-%e2%9c%93-4c1.svg?longcache=true&style=flat-square&logo=python&logocolor=white)](https://github.com/explosion/wheelwright/releases)\n[![code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/ambv/black)\n[![open demo in colab][colab]][intro_to_thinc_colab]\n\n## \ud83d\udd25 features\n\n- **type-check** your model definitions with custom types and\n  [`mypy`](https://mypy.readthedocs.io/en/latest/) plugin.\n- wrap **pytorch**, **tensorflow** and **mxnet** models for use in your network.\n- concise **functional-programming** approach to model definition, using\n  composition rather than inheritance.\n- optional custom infix notation via **operator overloading**.\n- integrated **config system** to describe trees of objects and hyperparameters.\n- choice of **extensible backends**.\n- **[read more &rarr;](https://thinc.ai/docs)**\n\n## \ud83d\ude80 quickstart\n\nthinc is compatible with **python 3.6+** and runs on **linux**, **macos** and\n**windows**. the latest releases with binary wheels are available from\n[pip](https://pypi.python.org/pypi/thinc). before you install thinc and its\ndependencies, make sure that your `pip`, `setuptools` and `wheel` are up to\ndate. for the most recent releases, pip 19.3 or newer is recommended.\n\n```bash\npip install -u pip setuptools wheel\npip install thinc\n```\n\nsee the [extended installation docs](https://thinc.ai/docs/install#extended) for\ndetails on optional dependencies for different backends and gpu. you might also\nwant to\n[set up static type checking](https://thinc.ai/docs/install#type-checking) to\ntake advantage of thinc's type system.\n\n> \u26a0\ufe0f if you have installed pytorch and you are using python 3.7+, uninstall the\n> package `dataclasses` with `pip uninstall dataclasses`, since it may have been\n> installed by pytorch and is incompatible with python 3.7+.\n\n### \ud83d\udcd3 selected examples and notebooks\n\nalso see the [`/examples`](examples) directory and\n[usage documentation](https://thinc.ai/docs) for more examples. most examples\nare jupyter notebooks \u2013 to launch them on\n[google colab](https://colab.research.google.com) (with gpu support!) click on\nthe button next to the notebook name.\n\n| notebook                                                                                                              | description                                                                                                                                                                                       |\n| --------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [`intro_to_thinc`][intro_to_thinc]<br />[![open in colab][colab]][intro_to_thinc_colab]                               | everything you need to know to get started. composing and training a model on the mnist data, using config files, registering custom functions and wrapping pytorch, tensorflow and mxnet models. |\n| [`transformers_tagger_bert`][transformers_tagger_bert]<br />[![open in colab][colab]][transformers_tagger_bert_colab] | how to use thinc, `transformers` and pytorch to train a part-of-speech tagger. from model definition and config to the training loop.                                                             |\n| [`pos_tagger_basic_cnn`][pos_tagger_basic_cnn]<br />[![open in colab][colab]][pos_tagger_basic_cnn_colab]             | implementing and training a basic cnn for part-of-speech tagging model without external dependencies and using different levels of thinc's config system.                                         |\n| [`parallel_training_ray`][parallel_training_ray]<br />[![open in colab][colab]][parallel_training_ray_colab]          | how to set up synchronous and asynchronous parameter server training with thinc and [ray](https://ray.readthedocs.io/en/latest/).                                                                 |\n\n**[view more &rarr;](examples)**\n\n[colab]:\n  https://gistcdn.githack.com/ines/dcf354aa71a7665ae19871d7fd14a4e0/raw/461fc1f61a7bc5860f943cd4b6bcfabb8c8906e7/colab-badge.svg\n[intro_to_thinc]: examples/00_intro_to_thinc.ipynb\n[intro_to_thinc_colab]:\n  https://colab.research.google.com/github/explosion/thinc/blob/master/examples/00_intro_to_thinc.ipynb\n[transformers_tagger_bert]: examples/02_transformers_tagger_bert.ipynb\n[transformers_tagger_bert_colab]:\n  https://colab.research.google.com/github/explosion/thinc/blob/master/examples/02_transformers_tagger_bert.ipynb\n[pos_tagger_basic_cnn]: examples/03_pos_tagger_basic_cnn.ipynb\n[pos_tagger_basic_cnn_colab]:\n  https://colab.research.google.com/github/explosion/thinc/blob/master/examples/03_pos_tagger_basic_cnn.ipynb\n[parallel_training_ray]: examples/04_parallel_training_ray.ipynb\n[parallel_training_ray_colab]:\n  https://colab.research.google.com/github/explosion/thinc/blob/master/examples/04_parallel_training_ray.ipynb\n\n### \ud83d\udcd6 documentation & usage guides\n\n| documentation                                                                     | description                                           |\n| --------------------------------------------------------------------------------- | ----------------------------------------------------- |\n| [introduction](https://thinc.ai/docs)                                             | everything you need to know.                          |\n| [concept & design](https://thinc.ai/docs/concept)                                 | thinc's conceptual model and how it works.            |\n| [defining and using models](https://thinc.ai/docs/usage-models)                   | how to compose models and update state.               |\n| [configuration system](https://thinc.ai/docs/usage-config)                        | thinc's config system and function registry.          |\n| [integrating pytorch, tensorflow & mxnet](https://thinc.ai/docs/usage-frameworks) | interoperability with machine learning frameworks     |\n| [layers api](https://thinc.ai/docs/api-layers)                                    | weights layers, transforms, combinators and wrappers. |\n| [type checking](https://thinc.ai/docs/usage-type-checking)                        | type-check your model definitions and more.           |\n\n## \ud83d\uddfa what's where\n\n| module                                    | description                                                                       |\n| ----------------------------------------- | --------------------------------------------------------------------------------- |\n| [`thinc.api`](thinc/api.py)               | **user-facing api.** all classes and functions should be imported from here.      |\n| [`thinc.types`](thinc/types.py)           | custom [types and dataclasses](https://thinc.ai/docs/api-types).                  |\n| [`thinc.model`](thinc/model.py)           | the `model` class. all thinc models are an instance (not a subclass) of `model`.  |\n| [`thinc.layers`](thinc/layers)            | the layers. each layer is implemented in its own module.                          |\n| [`thinc.shims`](thinc/shims)              | interface for external models implemented in pytorch, tensorflow etc.             |\n| [`thinc.loss`](thinc/loss.py)             | functions to calculate losses.                                                    |\n| [`thinc.optimizers`](thinc/optimizers.py) | functions to create optimizers. currently supports \"vanilla\" sgd, adam and radam. |\n| [`thinc.schedules`](thinc/schedules.py)   | generators for different rates, schedules, decays or series.                      |\n| [`thinc.backends`](thinc/backends)        | backends for `numpy` and `cupy`.                                                  |\n| [`thinc.config`](thinc/config.py)         | config parsing and validation and function registry system.                       |\n| [`thinc.util`](thinc/util.py)             | utilities and helper functions.                                                   |\n\n## \ud83d\udc0d development notes\n\nthinc uses [`black`](https://github.com/psf/black) for auto-formatting,\n[`flake8`](http://flake8.pycqa.org/en/latest/) for linting and\n[`mypy`](https://mypy.readthedocs.io/en/latest/) for type checking. all code is\nwritten compatible with **python 3.6+**, with type hints wherever possible. see\nthe [type reference](https://thinc.ai/docs/api-types) for more details on\nthinc's custom types.\n\n### \ud83d\udc77\u200d\u2640\ufe0f building thinc from source\n\nbuilding thinc from source requires the full dependencies listed in\n[`requirements.txt`](requirements.txt) to be installed. you'll also need a\ncompiler to build the c extensions.\n\n```bash\ngit clone https://github.com/explosion/thinc\ncd thinc\npython -m venv .env\nsource .env/bin/activate\npip install -u pip setuptools wheel\npip install -r requirements.txt\npip install --no-build-isolation .\n```\n\nalternatively, install in editable mode:\n\n```bash\npip install -r requirements.txt\npip install --no-build-isolation --editable .\n```\n\nor by setting `pythonpath`:\n\n```bash\nexport pythonpath=`pwd`\npip install -r requirements.txt\npython setup.py build_ext --inplace\n```\n\n### \ud83d\udea6 running tests\n\nthinc comes with an [extensive test suite](thinc/tests). the following should\nall pass and not report any warnings or errors:\n\n```bash\npython -m pytest thinc    # test suite\npython -m mypy thinc      # type checks\npython -m flake8 thinc    # linting\n```\n\nto view test coverage, you can run `python -m pytest thinc --cov=thinc`. we aim\nfor a 100% test coverage. this doesn't mean that we meticulously write tests for\nevery single line \u2013 we ignore blocks that are not relevant or difficult to test\nand make sure that the tests execute all code paths.\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "thinc",
  "package_url": "https://pypi.org/project/thinc/",
  "project_url": "https://pypi.org/project/thinc/",
  "project_urls": {
    "Homepage": "https://github.com/explosion/thinc"
  },
  "release_url": "https://pypi.org/project/thinc/8.2.2/",
  "requires_dist": [
    "blis <0.8.0,>=0.7.8",
    "murmurhash <1.1.0,>=1.0.2",
    "cymem <2.1.0,>=2.0.2",
    "preshed <3.1.0,>=3.0.2",
    "wasabi <1.2.0,>=0.8.1",
    "srsly <3.0.0,>=2.4.0",
    "catalogue <2.1.0,>=2.0.4",
    "confection <1.0.0,>=0.0.1",
    "setuptools",
    "pydantic !=1.8,!=1.8.1,<3.0.0,>=1.7.4",
    "packaging >=20.0",
    "dataclasses <1.0,>=0.6 ; python_version < \"3.7\"",
    "contextvars <3,>=2.4 ; python_version < \"3.7\"",
    "typing-extensions <4.5.0,>=3.7.4.1 ; python_version < \"3.8\"",
    "numpy >=1.15.0 ; python_version < \"3.9\"",
    "numpy >=1.19.0 ; python_version >= \"3.9\"",
    "cupy >=5.0.0b4 ; extra == 'cuda'",
    "cupy-wheel >=11.0.0 ; extra == 'cuda-autodetect'",
    "cupy-cuda100 >=5.0.0b4 ; extra == 'cuda100'",
    "cupy-cuda101 >=5.0.0b4 ; extra == 'cuda101'",
    "cupy-cuda102 >=5.0.0b4 ; extra == 'cuda102'",
    "cupy-cuda110 >=5.0.0b4 ; extra == 'cuda110'",
    "cupy-cuda111 >=5.0.0b4 ; extra == 'cuda111'",
    "cupy-cuda112 >=5.0.0b4 ; extra == 'cuda112'",
    "cupy-cuda113 >=5.0.0b4 ; extra == 'cuda113'",
    "cupy-cuda114 >=5.0.0b4 ; extra == 'cuda114'",
    "cupy-cuda115 >=5.0.0b4 ; extra == 'cuda115'",
    "cupy-cuda116 >=5.0.0b4 ; extra == 'cuda116'",
    "cupy-cuda117 >=5.0.0b4 ; extra == 'cuda117'",
    "cupy-cuda11x >=11.0.0 ; extra == 'cuda11x'",
    "cupy-cuda12x >=11.5.0 ; extra == 'cuda12x'",
    "cupy-cuda80 >=5.0.0b4 ; extra == 'cuda80'",
    "cupy-cuda90 >=5.0.0b4 ; extra == 'cuda90'",
    "cupy-cuda91 >=5.0.0b4 ; extra == 'cuda91'",
    "cupy-cuda92 >=5.0.0b4 ; extra == 'cuda92'",
    "ml-datasets <0.3.0,>=0.2.0 ; extra == 'datasets'",
    "mxnet <1.6.0,>=1.5.1 ; extra == 'mxnet'",
    "tensorflow <2.6.0,>=2.0.0 ; extra == 'tensorflow'",
    "torch >=1.6.0 ; extra == 'torch'"
  ],
  "requires_python": ">=3.6",
  "summary": "a refreshing functional take on deep learning, compatible with your favorite libraries",
  "version": "8.2.2",
  "releases": [],
  "developers": [
    "contact@explosion.ai",
    "explosion"
  ],
  "kwds": "thinc intro_to_thinc tensorflow 00_intro_to_thinc toolkit",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_thinc",
  "homepage": "https://github.com/explosion/thinc",
  "release_count": 228,
  "dependency_ids": [
    "pypi_blis",
    "pypi_catalogue",
    "pypi_confection",
    "pypi_contextvars",
    "pypi_cupy",
    "pypi_cupy_cuda100",
    "pypi_cupy_cuda101",
    "pypi_cupy_cuda102",
    "pypi_cupy_cuda110",
    "pypi_cupy_cuda111",
    "pypi_cupy_cuda112",
    "pypi_cupy_cuda113",
    "pypi_cupy_cuda114",
    "pypi_cupy_cuda115",
    "pypi_cupy_cuda116",
    "pypi_cupy_cuda117",
    "pypi_cupy_cuda11x",
    "pypi_cupy_cuda12x",
    "pypi_cupy_cuda80",
    "pypi_cupy_cuda90",
    "pypi_cupy_cuda91",
    "pypi_cupy_cuda92",
    "pypi_cupy_wheel",
    "pypi_cymem",
    "pypi_dataclasses",
    "pypi_ml_datasets",
    "pypi_murmurhash",
    "pypi_mxnet",
    "pypi_numpy",
    "pypi_packaging",
    "pypi_preshed",
    "pypi_pydantic",
    "pypi_setuptools",
    "pypi_srsly",
    "pypi_tensorflow",
    "pypi_torch",
    "pypi_typing_extensions",
    "pypi_wasabi"
  ]
}