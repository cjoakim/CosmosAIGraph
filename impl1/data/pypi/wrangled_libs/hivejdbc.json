{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "programming language :: java",
    "programming language :: python :: 3",
    "topic :: database",
    "topic :: software development :: libraries :: java libraries",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "# hivejdbc\nhivejdbc is `db-api-2.0` compliant **apache hive** driver that supports\n- kerberos\n- ssl\n- service discovery via zookeeper\n- host-connection list\n- and all other jdbc driver options\n\n# installation\n```properties\npip3 install hivejdbc\n```\n\n## cursors\n`hivejdbc` can use a `dictonary` cursor if desired.\n\n```python\nfrom hivejdbc import connect, dictcursor\nconn = connect('example.com', 'default', cursor=dictcursor)\n\n```\n\n### cursors support `with`\n```python\nfrom hivejdbc import connect\nconn = connect('example.com', database='default')\nwith conn.cursor() as cursor:\n    cursor.execute('select * from test.persons')\n    rows = cursor.fetchall()\n```\n\n### cursors are iterable\n```python\nfrom hivejdbc import connect\nconn = connect('example.com', database='default')\ncursor = conn.cursor()\ncursor.execute('select * from test.persons')\nfor row in cursor:\n    print(row[0])\ncursor.close()\n```\n\n### cursors support\n- `fetchone()`\n- `fetchmany()`\n- `fetchall()`\n\n```python\nfrom hivejdbc import connect\nconn = connect('example.com', database='default')\ncursor = conn.cursor()\ncursor.execute('select * from test.persons')\ncursor.fetchone() # fetch first row or none\ncursor.fetchmany(5) # fetch next 5 rows\ncursor.fetchall() # fetch remaining rows or empty list\ncursor.close()\n```\n\n## connection strings\n`hivejdbc` features many `connect` function arguments. many of these arguments can be ignored \nand are simply present to offer the full options provided by the **hive** jdbc driver.\n\nto import the `hivejdbc` connect function:\n```python\nfrom hivejdbc import connect\n```\n\n### unsecured hive instance\nto connect to an unsecured hive instance listening on the default port `10000`, and the `default` database:\n```python\nconn = connect('example.com', 'default')\n```\n\nunless all required `hive-jars` are on the classpath already you'll need to define the driver path  \njava uses `jar` files to combine many libraries into one. we'll use our `fatjar` to provide all the required \ndependencies in one place.  \nmake sure you're using the correct driver for your **hive** version.\n```python\nconn = connect('example.com', 'default', driver='hive-client-hive-2.1.1-hdfs-3.0.3-fatjar.jar')\n```\n\nto connect with a custom port of `10015`\n```python\nconn = connect('example.com', 'default', port=10015)\n```\n\n### username and password\n```python\nconn = connect(host='example.com', \n               database='default', \n               port=10015, \n               user='hive_user', \n               password='secret')\n```\n\n### ssl\nif the hive-server has `ssl` enabled you'll need to provide a `jks` trust store that contains the servers public \ncertificate.\n```python\nconn = connect(host='hive2.example.com',\n               port=10015,\n               database='default',\n               driver='hive-client-hive-2.1.1-hdfs-3.0.3-fatjar.jar',\n               ssl=true,\n               trust_store='./truststore.jks',\n               trust_password='changeit',\n               principal='hive/hive2.example.com@example.com',\n               user_principal='hive/hive2.example.com',\n               user_keytab='hive.keytab',\n               realm='example.com',\n               kdc='kerberosdc.example.com:88')\n```\n\n### kerberos\nauthenticating with kerberos can be done a few ways:\n1. get valid kerberos credentials via `kinit` before running `hivejdbc`\n1. rely on `hivejdbc` to obtain kerberos credentials via a `user-principal` and `user-keytab` provided \n   to the program.\n\n\n#### operating system `kinit`\nconnect to...\n- a `ssl` enabled cluster\n- a secured cluster (`kerberos`)\n- using the operating systems kerberos configuration\n  default locations are searched depending on platform\n- using the operating system `kinit` token  \n  default locations for the `token-cache` are searched\n- if `kinit` has not been performed, or a `token-cache` cannot be found an exception will be thrown\n```python\nconn = connect(host='hive2.example.com',\n               port=10015,\n               database='default',\n               driver='hive-client-hive-2.1.1-hdfs-3.0.3-fatjar.jar',\n               ssl=true,\n               trust_store='./truststore.jks',\n               trust_password='changeit',\n               principal='hive/hive2.example.com@example.com')\n```\n\n#### `hivejdbc` does the `kinit` via `keytab` and a custom `krb5.conf`\nconnect to... \n- a `ssl` enabled cluster\n- a secured cluster (`kerberos`)\n- using the operating systems kerberos configuration krb5.conf\n- using a `keytab` for authentication  \n  the keytab will be used to login via java's built-in kerberos implementation\n  avoiding the need for any operating system dependency\n- we will provide the `kdc` and `realm` via the `krb5_conf` argument\n  if we didn't provide `krb5_conf` argument default locations would be searched within various system paths\n```python\nconn = connect(host='hive2.example.com',\n               port=10015,\n               database='default',\n               driver='hive-client-hive-2.1.1-hdfs-3.0.3-fatjar.jar',\n               ssl=true,\n               trust_store='./truststore.jks',\n               trust_password='changeit',\n               principal='hive/hive2.example.com@example.com',\n               krb5_conf='kerberos/custom_krb5.conf',\n               user_principal='hive/hive2.example.com',\n               user_keytab='user.keytab')\n```\n\n\n\n#### `hivejdbc` does the `kinit` via `keytab` with no `krb5.conf`\nconnect to...\n- an ssl enabled cluster\n- a secured cluster (kerberos)\n- not using the operating system or relying on any of its configurations\n- manually setting the realm, and the kerberos \"kdc\" to authenticate to\n- using a keytab for authentication\n- this configuration is the most portable...\n```python\nconn = connect(host='hive2.example.com',\n               port=10015,\n               database='default',\n               driver='hive-client-hive-2.1.1-hdfs-3.0.3-fatjar.jar',\n               ssl=true,\n               trust_store='./truststore.jks',\n               trust_password='changeit',\n               principal='hive/hive2.example.com@example.com',\n               user_principal='hive/hive2.example.com',\n               user_keytab='hive.keytab',\n               realm='example.com',\n               kdc='kerberosdc.example.com:88')\n```\n\n## queries and parameters\n\nfor these examples we'll setup a `test` database with a `persons` table...\n\n```python\ncursor = conn.cursor()\ncursor.execute('create database if not exists test')\ncursor.execute('drop table if exists test.persons')\ncursor.execute('create table test.persons (name varchar(64), age int, address string, '\n               'first timestamp, balance decimal(12,2))')\n```\n\nour table sql will have 5 columns defined in the above statement:\n```sql\ncreate table test.persons (\n    name varchar(64), \n    age int, \n    address string,\n    first timestamp, \n    balance decimal(12,2)\n)\n```\n\n### single insert\nlet's insert a single record:\n```python\ncursor.execute('''    \ninsert into table test.persons (name, age, address, first, balance)\nvalues ('john doe', 35, '1583 whistling pines dr, redstone co 80612', '08-22-1981 00:00:00', '100.10')\n''')\n```\n\n### `positional` parameterized sql query\ninsert a single record, using paramterized arguments that will automatically be escaped.    \nthis prevents sql injection as well\n\n```python\ncursor.execute('''    \ninsert into table test.persons (name, age, address, first, balance)\nvalues (%s, %s, %s, %s, %s)\n''', ['kevin jones', 28, '802 1st st, raleigh nc', '12-23-2020 00:00:00', 85.25])\n```\n\nthe signature of `execute` is:\n```python\ndef execute(sql, params=none):\n    \"\"\n```\n- **sql** is the sql statement\n- **params** are `named (dict)` or `positional (sequence)` arguments used by the sql statement for variable \n  substitution\n\n### `named` parameterized sql query\n**insert** with named parameters \n\nin addition to positional parameters using `%s` we support `named parameters` as well.\n\nyou can see the named arguments are defined below in the `sql` statement as: `(:name, :age, :addr, :dt, :bal)`  \n\nthe second parameter to the `execute` method is a `dictionary` where the keys are equal to the parameters defined in the sql\n```python\ncursor.execute('''\ninsert into table test.persons (name, age, address, first, balance)\nvalues (:name, :age, :addr, :dt, :bal)\n''', {'name': 'bob clark',\n      'age': 41,\n      'addr': '348 w dickinson rd, norfolk va',\n      'dt': '12-23-2020 00:00:00',\n      'bal': 200.20})\n```\n\n### using `executemany`\nyou can execute many queries in one python statement using `executemany`  \n\nnote that this is for programmer ease of use; hive's `jdbc` driver does not support `batch-mode`, so this functionality is faked and is no more \nefficient than executing 3 statements individually.\n```\ncursor.executemany('''\ninsert into table test.persons (name, age, address, first, balance)\nvalues (%s, %s, %s, %s, %s)\n''', [\n    ('john doe', 35, '1583 whistling pines dr, redstone co 80612', '08-22-1981 00:00:00', 100.10),\n    ('kevin jones', 28, '802 1st st, raleigh nc', '12-23-2020 00:00:00', 85.25),\n    ('bob clark', 41, '348 w dickinson rd, norfolk va', '12-23-2020 00:00:00', 200.20)\n])\n```\n\n\n",
  "docs_url": null,
  "keywords": "dbapi jdbc hive hadoop",
  "license": "apache-2.0",
  "name": "hivejdbc",
  "package_url": "https://pypi.org/project/hivejdbc/",
  "project_url": "https://pypi.org/project/hivejdbc/",
  "project_urls": {
    "Homepage": "https://github.com/OpenBigDataPlatform/hivejdbc"
  },
  "release_url": "https://pypi.org/project/hivejdbc/0.2.3/",
  "requires_dist": [
    "pyjdbc (==0.2.2)"
  ],
  "requires_python": "",
  "summary": "hive database driver via jdbc",
  "version": "0.2.3",
  "releases": [],
  "developers": [
    "openbigdataplatform"
  ],
  "kwds": "hivejdbc hive_user hive hive2 jdbc",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_hivejdbc",
  "homepage": "https://github.com/openbigdataplatform/hivejdbc",
  "release_count": 5,
  "dependency_ids": [
    "pypi_pyjdbc"
  ]
}