{
  "classifiers": [],
  "description": "the example code shown in the below explanation can also be found in [this example jupyter notebook](./overview_demo.ipynb).\n\n# feature statistics protocol buffer\n\nthe overview visualization is powered by the feature statistics protocol buffer.\nthe feature statistics protocol buffer messages store summary statistics for individual feature columns of a set of input data for an ml system (although it will be general enough to be used for summary statistics of any set of data).\n\nthe top-level proto is datasetfeaturestatisticslist, which is a list of datasetfeaturestatistics.\neach datasetfeaturestatistics represents the feature statistics for a single dataset.\neach datasetfeaturestatistics contains a list of featurenamestatistics, which contain the statistics for a single feature in a single dataset.\n\nthe feature statistics are different depending on the feature data type (numeric, string, or raw bytes).\nfor numeric features, the statistics include metrics such as min, mean, median, max and standard deviation.\nfor string feature, the statistics include metrics such as average length, number of unique values and mode.\n\nfeature statistics includes an optional field for weighted statistics.\nif the dataset has an example weight feature, it can be used to calculate weighted statistics for every feature in addition to standard statistics.\nif a proto contains weighted fields, then the visualization will show the weighted statistics and the user will be able to toggle between unweighted and weighted versions of the charts per feature.\n\nfeature statistics includes an optional field for custom statistics.\nif there are additional statistics for features in a dataset that a team wants to track and visualize they can be added to the custom stats field, which is a map of custom stat names to custom stat values (either numbers or strings).\nthese custom stats will be displayed alongside the standard statistics.\n\n# feature statistics generation\n\nthe feature statistics protocol buffer can be created for datasets by the python code provided in the facets_overview/facets-overview directory.\nthis code can be installed through `pip install facets-overview`. tensorflow should also be installed but is not included as a\npip dependency, so as to allow a user to depend on either the tensorflow or tensorflow-gpu package as necessary.\ndatasets can be analyzed either from a tfrecord files of tensorflow example protocol buffers, or from pandas dataframes.\nas of version 1.1.0, the `facets-overview` package requires a version of `protobuf` at version 3.20.0 or later.\n\nto create the proto from a pandas dataframe, use the `protofromdataframes` method of the [genericfeaturestatisticsgenerator class](./python/generic_feature_statistics_generator.py).\nto create the proto from a tfrecord file, use the `protofromtfrecordfiles` method of the [featurestatisticsgenerator class](./python/feature_statistics_generator.py).\nthese generators have dependencies on the numpy and pandas python libraries.\nuse of the featurestatisticsgenerator class also requires having tensorflow installed.\nsee those files for further documentation.\n\nexample code:\n```python\nfrom facets_overview.generic_feature_statistics_generator import genericfeaturestatisticsgenerator\nimport pandas as pd\ndf =  pd.dataframe({'num' : [1, 2, 3, 4], 'str' : ['a', 'a', 'b', none]})\nproto = genericfeaturestatisticsgenerator().protofromdataframes([{'name': 'test', 'table': df}])\n```\n\n## large datasets\n\nthe python code in this repository for generating feature stats only works on datasets that are small enough to fit into memory on your local machine. for distributed generation of feature stats for large datasets, check out the independently-developed [facets overview spark project](https://github.com/gopro/facets-overview-spark).\n\n# visualization\n\na proto can easily be visualized in a jupyter notebook using the installed nbextension.\nthe proto is stingified and then provided as input to a facets-overview polymer web component, via the `protoinput` property on the element.\nthe web component is then displayed in output cell of the notebook.\n\nexample code (continued from above example):\n```python\nfrom ipython.core.display import display, html\nimport base64\nprotostr = base64.b64encode(proto.serializetostring()).decode(\"utf-8\")\nhtml_template = \"\"\"\n        <script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n        <link rel=\"import\" href=\"/nbextensions/facets-dist/facets-jupyter.html\" >\n        <facets-overview id=\"elem\"></facets-overview>\n        <script>\n          document.queryselector(\"#elem\").protoinput = \"{protostr}\";\n        </script>\"\"\"\nhtml = html_template.format(protostr=protostr)\ndisplay(html(html))\n```\n\nthe `protoinput` property accepts any of the following three forms of the datasetfeaturestatisticslist protocol buffer:\n* an instance of the datasetfeaturestatisticslist javascript class, which is the class created by the protocol buffer compiler buffer.\n* a uint8array containing the serialized binary of a protocol buffer.\n* a string containing the base-64 encoded serialized protocol buffer, as shown in the code example above.\n\n### understanding the visualization\n\nthe visualization contains two tables: one for numeric features and one for categorical (string) features.\neach table contains a row for each feature of that type.\nthe rows contains calculated statistics and charts showing the distribution of values for that feature across the dataset(s).\n\npotentially problematic statistics, such as a feature is missing (has no value) for a large number of the examples in a dataset, are shown in red and bolded.\n\n### global controls\n\nat the top of the visualization are controls that affect the individual tables.\n\nthe sort-by dropdown changes the sort order for the features in each table. the options are:\n* feature order: ordered by their natural order in the feature statistics proto\n* non-uniformity: ordered by how non-uniform the distribution of values is (using entropy)\n* alphabetical\n* amount missing/zero: ordered by how many values of the feature are missing or contain the number 0, with the largest amount being first.\n* distribution distance (only available when comparing multiple datasets): ordered by the largest difference between distribution shapes for each feature (using chi-square test for shape).\n\nthe name filter input box allows filtering the tables by feature names that match the text provided.\nthe currently-set filter is exposed as the property `searchstring`.\n\nthe feature checkboxes allow filtering by the type of value for each feature, such as float, int or string.\n\n### charts\n\nwhich chart is displayed for the features in a table is controlled by a dropdown above the charts.\nthe options for numeric features are:\n* a histogram of all values, with 10 equal-width buckets\n* a visualization of the deciles of all values\n* a visualization of the deciles of the number of values per example\n* for datasets that are pandas dataframes, each example has one value per example, so the visualization is trivial, showing all deciles having the value 1.\n  but for tf.examples, for a given example, a feature can have any number of values.\n  one example would be an address feature that lists all known addresses for a person (each example represents one person).\n\nthe options for string features are:\n* a column chart of the count of each value in the dataset (this is used if a feature has 20 or fewer unique values).\n  a toggle exists to instead show a table of the counts.\n* a cumulative distribution function graph of the percentage of all values in the entire dataset that each feature value represents (this is used if a feature has more than 20 unique values).\n  a toggle exists to instead show a table of the counts.\n* a visualization of the deciles of the number of values per example.\n\nadditionally, the feature statistics proto allows for custom charts to be stored for any feature.\nif the input proto to the visualization contains any custom charts, they will be listed in the dropdown as well.\n\ncheckboxes next to the dropdown control some other features of the charts:\n* the log checkbox changes the y-axis to log from linear.\n* the expand checkbox shows a larger version of the charts.\n* the weighted checkbox (only shown when a dataset contains weighted statistics in addition to normal statistics) shows weighted versions of the charts, along with weighted versions of the statistics.\n* the percentages checkbox (only shown when the visualization is comparing more than one dataset) changes the y-axis to be percentages of each entire dataset as opposed to raw counts.\n  this allows easy comparison of distributions between datasets that have significantly different total numbers of examples (such as a test and train dataset).\n\n# running demos (functional tests)\n\nthere are multiple demos of overview that can be used as functional tests to ensure new builds are working correctly.\nthese demos are all found under facets_overview/functional_tests.\nto run one, for example the \u201csimple\u201d test, run ```bazel run facets_overview/functional_tests/simple:devserver``` and then navigate your browser to \"localhost:6006/facets-overview/functional-tests/simple/index.html\u201d to see the resulting visualization.\n \n# running visualization unit tests\n\nrun ```bazel run facets_overview/common/test:devserver``` and then navigate your browser to \u201clocalhost:6006/facets-overview/facets-overview/common/test/runner.html\u201d.\nthe output from the tests can be seen in the developer console.\n\n# building the facets-overview pip package\n\n1) update the version number in setup.py and commit it to github.\n2) from this directory run `python setup.py bdist_wheel --universal`\n3) from this directory run `twine upload dist/*` to upload it to pypi.\n\n# running python unit tests\n\nafter installing the python package, run `python -m feature_statistics_generator_test` and `python -m generic_feature_statistics_generator_test`.\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache 2.0",
  "name": "facets-overview",
  "package_url": "https://pypi.org/project/facets-overview/",
  "project_url": "https://pypi.org/project/facets-overview/",
  "project_urls": {
    "Homepage": "http://github.com/pair-code/facets"
  },
  "release_url": "https://pypi.org/project/facets-overview/1.1.1/",
  "requires_dist": [
    "numpy (>=1.16.0)",
    "pandas (>=0.22.0)",
    "protobuf (>=3.20.0)"
  ],
  "requires_python": "",
  "summary": "python code to support the facets overview visualization",
  "version": "1.1.1",
  "releases": [],
  "developers": [
    "google_inc",
    "opensource@google.com"
  ],
  "kwds": "datasetfeaturestatistics feature_statistics_generator datasetfeaturestatisticslist generic_feature_statistics_generator feature_statistics_generator_test",
  "license_kwds": "apache 2.0",
  "libtype": "pypi",
  "id": "pypi_facets_overview",
  "homepage": "http://github.com/pair-code/facets",
  "release_count": 9,
  "dependency_ids": [
    "pypi_numpy",
    "pypi_pandas",
    "pypi_protobuf"
  ]
}