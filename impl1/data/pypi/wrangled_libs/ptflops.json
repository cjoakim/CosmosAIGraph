{
  "classifiers": [
    "license :: osi approved :: mit license",
    "programming language :: python :: 3.7"
  ],
  "description": "# flops counting tool for neural networks in pytorch framework\n[![pypi version](https://img.shields.io/pypi/v/ptflops.svg)](https://pypi.org/project/ptflops/)\n[![build status](https://travis-ci.com/sovrasov/flops-counter.pytorch.svg?branch=master)](https://travis-ci.com/sovrasov/flops-counter.pytorch)\n\nthis script is designed to compute the theoretical amount of multiply-add operations\nin convolutional neural networks. it can also compute the number of parameters and\nprint per-layer computational cost of a given network.\n\nsupported layers:\n- conv1d/2d/3d (including grouping)\n- convtranspose1d/2d/3d (including grouping)\n- batchnorm1d/2d/3d, groupnorm, instancenorm1d/2d/3d, layernorm\n- activations (relu, prelu, elu, relu6, leakyrelu, gelu)\n- linear\n- upsample\n- poolings (avgpool1d/2d/3d, maxpool1d/2d/3d and adaptive ones)\n\nexperimental support:\n- rnn, lstm, gru (nlh layout is assumed)\n- rnncell, lstmcell, grucell\n- torch.nn.multiheadattention\n- torchvision.ops.deformconv2d\n- visual transformers from [timm](https://github.com/huggingface/pytorch-image-models)\n\nrequirements: pytorch >= 1.1, torchvision >= 0.3\n\nthanks to @warmspringwinds for the initial version of script.\n\n## usage tips\n\n- this tool doesn't take into account some of the `torch.nn.functional.*` and `tensor.*` operations. therefore unsupported operations are\nnot contributing to the final complexity estimation. see `ptflops/pytorch_ops.py:functional_mapping,tensor_ops_mapping` to check supported ops.\n- `ptflops` launches a given model on a random tensor and estimates amount of computations during inference. complicated models can have several inputs, some of them could be optional. to construct non-trivial input one can use the `input_constructor` argument of the `get_model_complexity_info`. `input_constructor` is a function that takes the input spatial resolution as a tuple and returns a dict with named input arguments of the model. next this dict would be passed to the model as a keyword arguments.\n- `verbose` parameter allows to get information about modules that don't contribute to the final numbers.\n- `ignore_modules` option forces `ptflops` to ignore the listed modules. this can be useful\nfor research purposes. for instance, one can drop all convolutions from the counting process\nspecifying `ignore_modules=[torch.nn.conv2d]`.\n\n## install the latest version\nfrom pypi:\n```bash\npip install ptflops\n```\n\nfrom this repository:\n```bash\npip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git\n```\n\n## example\n```python\nimport torchvision.models as models\nimport torch\nfrom ptflops import get_model_complexity_info\n\nwith torch.cuda.device(0):\n  net = models.densenet161()\n  macs, params = get_model_complexity_info(net, (3, 224, 224), as_strings=true,\n                                           print_per_layer_stat=true, verbose=true)\n  print('{:<30}  {:<8}'.format('computational complexity: ', macs))\n  print('{:<30}  {:<8}'.format('number of parameters: ', params))\n```\n\n## citation\nif ptflops was useful for your paper or tech report, please cite me:\n```\n@online{ptflops,\n  author = {vladislav sovrasov},\n  title = {ptflops: a flops counting tool for neural networks in pytorch framework},\n  year = 2018-2023,\n  url = {https://github.com/sovrasov/flops-counter.pytorch},\n}\n```\n\n## benchmark\n\n### [torchvision](https://pytorch.org/vision/0.16/models.html)\n\nmodel                  | input resolution | params(m) | macs(g)\n---                    |---               |---        |---\nalexnet                | 224x224          | 61.10     | 0.72\nconvnext_base          | 224x224          | 88.59     | 15.43\ndensenet121            | 224x224          | 7.98      | 2.90\nefficientnet_b0        | 224x224          | 5.29      | 0.41\nefficientnet_v2_m      | 224x224          | 54.14     | 5.43\ngooglenet              | 224x224          | 13.00     | 1.51\ninception_v3           | 224x224          | 27.16     | 2.86\nmaxvit_t               | 224x224          | 30.92     | 5.48\nmnasnet1_0             | 224x224          | 4.38      | 0.33\nmobilenet_v2           | 224x224          | 3.50      | 0.32\nmobilenet_v3_large     | 224x224          | 5.48      | 0.23\nregnet_y_1_6gf         | 224x224          | 11.20     | 1.65\nresnet18               | 224x224          | 11.69     | 1.83\nresnet50               | 224x224          | 25.56     | 4.13\nresnext50_32x4d        | 224x224          | 25.03     | 4.29\nshufflenet_v2_x1_0     | 224x224          | 2.28      | 0.15\nsqueezenet1_0          | 224x224          | 1.25      | 0.84\nvgg16                  | 224x224          | 138.36    | 15.52\nvit_b_16               | 224x224          | 86.57     | 17.60\nwide_resnet50_2        | 224x224          | 68.88     | 11.45\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "ptflops",
  "package_url": "https://pypi.org/project/ptflops/",
  "project_url": "https://pypi.org/project/ptflops/",
  "project_urls": {
    "Homepage": "https://github.com/sovrasov/flops-counter.pytorch"
  },
  "release_url": "https://pypi.org/project/ptflops/0.7.2.1/",
  "requires_dist": [],
  "requires_python": ">=3.7",
  "summary": "flops counter for convolutional networks inpytorch framework",
  "version": "0.7.2.1",
  "releases": [],
  "developers": [
    "sovrasov.vlad@gmail.com",
    "vladislav_sovrasov"
  ],
  "kwds": "print_per_layer_stat pytorch_ops computations get_model_complexity_info pytorch",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_ptflops",
  "homepage": "https://github.com/sovrasov/flops-counter.pytorch",
  "release_count": 22,
  "dependency_ids": []
}