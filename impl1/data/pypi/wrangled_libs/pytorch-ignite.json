{
  "classifiers": [],
  "description": "<div align=\"center\">\n\n<!-- ![ignite logo](assets/logo/ignite_logo_mixed.svg) -->\n\n<img src=\"https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo_mixed.svg\" width=512>\n\n<!-- [![image](https://travis-ci.com/pytorch/ignite.svg?branch=master)](https://travis-ci.com/pytorch/ignite) -->\n\n| ![image](https://img.shields.io/badge/-tests:-black?style=flat-square) [![image](https://github.com/pytorch/ignite/actions/workflows/unit-tests.yml/badge.svg?branch=master)](https://github.com/pytorch/ignite/actions/workflows/unit-tests.yml) [![image](https://github.com/pytorch/ignite/actions/workflows/gpu-tests.yml/badge.svg)](https://github.com/pytorch/ignite/actions/workflows/gpu-tests.yml) [![image](https://codecov.io/gh/pytorch/ignite/branch/master/graph/badge.svg)](https://codecov.io/gh/pytorch/ignite) [![image](https://img.shields.io/badge/dynamic/json.svg?label=docs&url=https%3a%2f%2fpypi.org%2fpypi%2fpytorch-ignite%2fjson&query=%24.info.version&colorb=brightgreen&prefix=v)](https://pytorch.org/ignite/index.html) |\n|:---\n| ![image](https://img.shields.io/badge/-stable%20releases:-black?style=flat-square) [![image](https://anaconda.org/pytorch/ignite/badges/version.svg)](https://anaconda.org/pytorch/ignite) \u30fb [![image](https://img.shields.io/badge/dynamic/json.svg?label=pypi&url=https%3a%2f%2fpypi.org%2fpypi%2fpytorch-ignite%2fjson&query=%24.info.version&colorb=brightgreen&prefix=v)](https://pypi.org/project/pytorch-ignite/) [![image](https://static.pepy.tech/badge/pytorch-ignite)](https://pepy.tech/project/pytorch-ignite) \u30fb [![image](https://img.shields.io/badge/docker-hub-blue)](https://hub.docker.com/u/pytorchignite) |\n| ![image](https://img.shields.io/badge/-nightly%20releases:-black?style=flat-square) [![image](https://anaconda.org/pytorch-nightly/ignite/badges/version.svg)](https://anaconda.org/pytorch-nightly/ignite) [![image](https://img.shields.io/badge/pypi-pre%20releases-brightgreen)](https://pypi.org/project/pytorch-ignite/#history)|\n| ![image](https://img.shields.io/badge/-community:-black?style=flat-square) [![twitter](https://img.shields.io/badge/news-twitter-blue)](https://twitter.com/pytorch_ignite) [![discord](https://img.shields.io/badge/chat-discord-blue?logo=discord)](https://discord.gg/djztm3emkj) [![numfocus](https://img.shields.io/badge/numfocus-affiliated%20project-green)](https://numfocus.org/sponsored-projects/affiliated-projects) |\n| ![image](https://img.shields.io/badge/-supported_pytorch/python_versions:-black?style=flat-square) [![link](https://img.shields.io/badge/-check_here-blue)](https://github.com/pytorch/ignite/actions?query=workflow%3a%22pytorch+version+tests%22)|\n\n</div>\n\n## tl;dr\n\nignite is a high-level library to help with training and evaluating neural networks in pytorch flexibly and transparently.\n\n<div align=\"center\">\n\n<a href=\"https://colab.research.google.com/github/pytorch/ignite/blob/master/assets/tldr/teaser.ipynb\">\n <img alt=\"pytorch-ignite teaser\"\n      src=\"https://raw.githubusercontent.com/pytorch/ignite/master/assets/tldr/pytorch-ignite-teaser.gif\"\n      width=532>\n</a>\n\n_click on the image to see complete code_\n\n</div>\n\n### features\n\n- [less code than pure pytorch](https://raw.githubusercontent.com/pytorch/ignite/master/assets/ignite_vs_bare_pytorch.png)\n  while ensuring maximum control and simplicity\n\n- library approach and no program's control inversion - _use ignite where and when you need_\n\n- extensible api for metrics, experiment managers, and other components\n\n<!-- ############################################################################################################### -->\n\n# table of contents\n\n- [table of contents](#table-of-contents)\n- [why ignite?](#why-ignite)\n  - [simplified training and validation loop](#simplified-training-and-validation-loop)\n  - [power of events & handlers](#power-of-events--handlers)\n    - [execute any number of functions whenever you wish](#execute-any-number-of-functions-whenever-you-wish)\n    - [built-in events filtering](#built-in-events-filtering)\n    - [stack events to share some actions](#stack-events-to-share-some-actions)\n    - [custom events to go beyond standard events](#custom-events-to-go-beyond-standard-events)\n  - [out-of-the-box metrics](#out-of-the-box-metrics)\n- [installation](#installation)\n  - [nightly releases](#nightly-releases)\n  - [docker images](#docker-images)\n    - [using pre-built images](#using-pre-built-images)\n- [getting started](#getting-started)\n- [documentation](#documentation)\n  - [additional materials](#additional-materials)\n- [examples](#examples)\n  - [tutorials](#tutorials)\n  - [reproducible training examples](#reproducible-training-examples)\n- [communication](#communication)\n  - [user feedback](#user-feedback)\n- [contributing](#contributing)\n- [projects using ignite](#projects-using-ignite)\n- [citing ignite](#citing-ignite)\n- [about the team & disclaimer](#about-the-team--disclaimer)\n\n<!-- ############################################################################################################### -->\n\n# why ignite?\n\nignite is a **library** that provides three high-level features:\n\n- extremely simple engine and event system\n- out-of-the-box metrics to easily evaluate models\n- built-in handlers to compose training pipeline, save artifacts and log parameters and metrics\n\n## simplified training and validation loop\n\nno more coding `for/while` loops on epochs and iterations. users instantiate engines and run them.\n\n<details>\n<summary>\nexample\n</summary>\n\n```python\nfrom ignite.engine import engine, events, create_supervised_evaluator\nfrom ignite.metrics import accuracy\n\n\n# setup training engine:\ndef train_step(engine, batch):\n    # users can do whatever they need on a single iteration\n    # eg. forward/backward pass for any number of models, optimizers, etc\n    # ...\n\ntrainer = engine(train_step)\n\n# setup single model evaluation engine\nevaluator = create_supervised_evaluator(model, metrics={\"accuracy\": accuracy()})\n\ndef validation():\n    state = evaluator.run(validation_data_loader)\n    # print computed metrics\n    print(trainer.state.epoch, state.metrics)\n\n# run model's validation at the end of each epoch\ntrainer.add_event_handler(events.epoch_completed, validation)\n\n# start the training\ntrainer.run(training_data_loader, max_epochs=100)\n```\n\n</details>\n\n## power of events & handlers\n\nthe cool thing with handlers is that they offer unparalleled flexibility (compared to, for example, callbacks). handlers can be any function: e.g. lambda, simple function, class method, etc. thus, we do not require to inherit from an interface and override its abstract methods which could unnecessarily bulk up your code and its complexity.\n\n### execute any number of functions whenever you wish\n\n<details>\n<summary>\nexamples\n</summary>\n\n```python\ntrainer.add_event_handler(events.started, lambda _: print(\"start training\"))\n\n# attach handler with args, kwargs\nmydata = [1, 2, 3, 4]\nlogger = ...\n\ndef on_training_ended(data):\n    print(f\"training is ended. mydata={data}\")\n    # user can use variables from another scope\n    logger.info(\"training is ended\")\n\n\ntrainer.add_event_handler(events.completed, on_training_ended, mydata)\n# call any number of functions on a single event\ntrainer.add_event_handler(events.completed, lambda engine: print(engine.state.times))\n\n@trainer.on(events.iteration_completed)\ndef log_something(engine):\n    print(engine.state.output)\n```\n\n</details>\n\n### built-in events filtering\n\n<details>\n<summary>\nexamples\n</summary>\n\n```python\n# run the validation every 5 epochs\n@trainer.on(events.epoch_completed(every=5))\ndef run_validation():\n    # run validation\n\n# change some training variable once on 20th epoch\n@trainer.on(events.epoch_started(once=20))\ndef change_training_variable():\n    # ...\n\n# trigger handler with customly defined frequency\n@trainer.on(events.iteration_completed(event_filter=first_x_iters))\ndef log_gradients():\n    # ...\n```\n\n</details>\n\n### stack events to share some actions\n\n<details>\n<summary>\nexamples\n</summary>\n\nevents can be stacked together to enable multiple calls:\n\n```python\n@trainer.on(events.completed | events.epoch_completed(every=10))\ndef run_validation():\n    # ...\n```\n\n</details>\n\n### custom events to go beyond standard events\n\n<details>\n<summary>\nexamples\n</summary>\n\ncustom events related to backward and optimizer step calls:\n\n```python\nfrom ignite.engine import eventenum\n\n\nclass backpropevents(eventenum):\n    backward_started = 'backward_started'\n    backward_completed = 'backward_completed'\n    optim_step_completed = 'optim_step_completed'\n\ndef update(engine, batch):\n    # ...\n    loss = criterion(y_pred, y)\n    engine.fire_event(backpropevents.backward_started)\n    loss.backward()\n    engine.fire_event(backpropevents.backward_completed)\n    optimizer.step()\n    engine.fire_event(backpropevents.optim_step_completed)\n    # ...\n\ntrainer = engine(update)\ntrainer.register_events(*backpropevents)\n\n@trainer.on(backpropevents.backward_started)\ndef function_before_backprop(engine):\n    # ...\n```\n\n- complete snippet is found [here](https://pytorch.org/ignite/faq.html#creating-custom-events-based-on-forward-backward-pass).\n- another use-case of custom events: [trainer for truncated backprop through time](https://pytorch.org/ignite/contrib/engines.html#ignite.contrib.engines.create_supervised_tbptt_trainer).\n\n</details>\n\n## out-of-the-box metrics\n\n- [metrics](https://pytorch.org/ignite/metrics.html#complete-list-of-metrics) for various tasks:\n  precision, recall, accuracy, confusion matrix, iou etc, ~20 [regression metrics](https://pytorch.org/ignite/contrib/metrics.html#regression-metrics).\n\n- users can also [compose their metrics](https://pytorch.org/ignite/metrics.html#metric-arithmetics) with ease from\n  existing ones using arithmetic operations or torch methods.\n\n<details>\n<summary>\nexample\n</summary>\n\n```python\nprecision = precision(average=false)\nrecall = recall(average=false)\nf1_per_class = (precision * recall * 2 / (precision + recall))\nf1_mean = f1_per_class.mean()  # torch mean method\nf1_mean.attach(engine, \"f1\")\n```\n\n</details>\n\n<!-- ############################################################################################################### -->\n\n# installation\n\nfrom [pip](https://pypi.org/project/pytorch-ignite/):\n\n```bash\npip install pytorch-ignite\n```\n\nfrom [conda](https://anaconda.org/pytorch/ignite):\n\n```bash\nconda install ignite -c pytorch\n```\n\nfrom source:\n\n```bash\npip install git+https://github.com/pytorch/ignite\n```\n\n## nightly releases\n\nfrom pip:\n\n```bash\npip install --pre pytorch-ignite\n```\n\nfrom conda (this suggests to install [pytorch nightly release](https://anaconda.org/pytorch-nightly/pytorch) instead of stable\nversion as dependency):\n\n```bash\nconda install ignite -c pytorch-nightly\n```\n\n## docker images\n\n### using pre-built images\n\npull a pre-built docker image from [our docker hub](https://hub.docker.com/u/pytorchignite) and run it with docker v19.03+.\n\n```bash\ndocker run --gpus all -it -v $pwd:/workspace/project --network=host --shm-size 16g pytorchignite/base:latest /bin/bash\n```\n\n<details>\n\n<summary>\nlist of available pre-built images\n</summary>\n\nbase\n- `pytorchignite/base:latest` \n- `pytorchignite/apex:latest`\n- `pytorchignite/hvd-base:latest`\n- `pytorchignite/hvd-apex:latest` \n- `pytorchignite/msdp-apex:latest`\n\nvision:\n- `pytorchignite/vision:latest`\n- `pytorchignite/hvd-vision:latest`\n- `pytorchignite/apex-vision:latest`\n- `pytorchignite/hvd-apex-vision:latest`\n- `pytorchignite/msdp-apex-vision:latest`\n\nnlp:\n- `pytorchignite/nlp:latest`\n- `pytorchignite/hvd-nlp:latest`\n- `pytorchignite/apex-nlp:latest` \n- `pytorchignite/hvd-apex-nlp:latest` \n- `pytorchignite/msdp-apex-nlp:latest`\n\n</details>\n\nfor more details, see [here](docker).\n\n<!-- ############################################################################################################### -->\n\n# getting started\n\nfew pointers to get you started:\n\n- [quick start guide: essentials of getting a project up and running](https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/)\n- [concepts of the library: engine, events & handlers, state, metrics](https://pytorch-ignite.ai/concepts/)\n- full-featured template examples (coming soon)\n\n<!-- ############################################################################################################### -->\n\n# documentation\n\n- stable api documentation and an overview of the library: https://pytorch.org/ignite/\n- development version api documentation: https://pytorch.org/ignite/master/\n- [faq](https://pytorch.org/ignite/faq.html),\n  [\"questions on github\"](https://github.com/pytorch/ignite/issues?q=is%3aissue+label%3aquestion+) and\n  [\"questions on discuss.pytorch\"](https://discuss.pytorch.org/c/ignite).\n- [project's roadmap](https://github.com/pytorch/ignite/wiki/roadmap)\n\n## additional materials\n\n- [distributed training made easy with pytorch-ignite](https://labs.quansight.org/blog/2021/06/distributed-made-easy-with-ignite/)\n- [pytorch ecosystem day 2021 breakout session presentation](https://colab.research.google.com/drive/1qhugwq0n2u71ivshlpocyey4ahldcprd)\n- [tutorial blog post about pytorch-ignite](https://labs.quansight.org/blog/2020/09/pytorch-ignite/)\n- [8 creators and core contributors talk about their model training libraries from pytorch ecosystem](https://neptune.ai/blog/model-training-libraries-pytorch-ecosystem?utm_source=reddit&utm_medium=post&utm_campaign=blog-model-training-libraries-pytorch-ecosystem)\n- ignite posters from pytorch developer conferences:\n  - [2021](https://drive.google.com/file/d/1yxrkjieppk_kltsg1zfwrta5irgpfz_u)\n  - [2019](https://drive.google.com/open?id=1bqil-em6gcccosixfzxhibuf25f2qtzg)\n  - [2018](https://drive.google.com/open?id=1_2vzbj0kecjgv1srojmhijrvcesvbvr5)\n\n<!-- ############################################################################################################### -->\n\n# examples\n\n## tutorials\n\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/textcnn.ipynb) [text classification using convolutional neural\n  networks](https://github.com/pytorch/ignite/blob/master/examples/notebooks/textcnn.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/vae.ipynb) [variational auto\n  encoders](https://github.com/pytorch/ignite/blob/master/examples/notebooks/vae.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/fashionmnist.ipynb) [convolutional neural networks for classifying fashion-mnist\n  dataset](https://github.com/pytorch/ignite/blob/master/examples/notebooks/fashionmnist.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/cyclegan_with_nvidia_apex.ipynb) [training cycle-gan on horses to\n  zebras with nvidia/apex](https://github.com/pytorch/ignite/blob/master/examples/notebooks/cyclegan_with_nvidia_apex.ipynb) - [ logs on w&b](https://app.wandb.ai/vfdev-5/ignite-cyclegan-apex)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/cyclegan_with_torch_cuda_amp.ipynb) [another training cycle-gan on horses to\n  zebras with native torch cuda amp](https://github.com/pytorch/ignite/blob/master/examples/notebooks/cyclegan_with_torch_cuda_amp.ipynb) - [logs on w&b](https://app.wandb.ai/vfdev-5/ignite-cyclegan-torch-amp)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/efficientnet_cifar100_finetuning.ipynb) [finetuning efficientnet-b0 on\n  cifar100](https://github.com/pytorch/ignite/blob/master/examples/notebooks/efficientnet_cifar100_finetuning.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/cifar10_ax_hyperparam_tuning.ipynb) [hyperparameters tuning with\n  ax](https://github.com/pytorch/ignite/blob/master/examples/notebooks/cifar10_ax_hyperparam_tuning.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/fastailrfinder_mnist.ipynb) [basic example of lr finder on\n  mnist](https://github.com/pytorch/ignite/blob/master/examples/notebooks/fastailrfinder_mnist.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/cifar100_bench_amp.ipynb) [benchmark mixed precision training on cifar100:\n  torch.cuda.amp vs nvidia/apex](https://github.com/pytorch/ignite/blob/master/examples/notebooks/cifar100_bench_amp.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/mnist_on_tpu.ipynb) [mnist training on a single\n  tpu](https://github.com/pytorch/ignite/blob/master/examples/notebooks/mnist_on_tpu.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1e9zjrptnlj_pkhmap5vhb6dtvrvyrkhx) [cifar10 training on multiple tpus](https://github.com/pytorch/ignite/tree/master/examples/cifar10)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/handlerstimeprofiler_mnist.ipynb) [basic example of handlers\n  time profiling on mnist training example](https://github.com/pytorch/ignite/blob/master/examples/notebooks/handlerstimeprofiler_mnist.ipynb)\n\n## reproducible training examples\n\ninspired by [torchvision/references](https://github.com/pytorch/vision/tree/master/references),\nwe provide several reproducible baselines for vision tasks:\n\n- [imagenet](examples/references/classification/imagenet) - logs on ignite trains server coming soon ...\n- [pascal voc2012](examples/references/segmentation/pascal_voc2012) - logs on ignite trains server coming soon ...\n\nfeatures:\n\n- distributed training: native or horovod and using [pytorch native amp](https://pytorch.org/docs/stable/notes/amp_examples.html)\n\n## code-generator application\n\nthe easiest way to create your training scripts with pytorch-ignite:\n- https://code-generator.pytorch-ignite.ai/\n\n\n<!-- ############################################################################################################### -->\n\n# communication\n\n- [github issues](https://github.com/pytorch/ignite/issues): questions, bug reports, feature requests, etc.\n\n- [discuss.pytorch](https://discuss.pytorch.org/c/ignite), category \"ignite\".\n\n- [pytorch-ignite discord server](https://discord.gg/djztm3emkj): to chat with the community\n\n- [github discussions](https://github.com/pytorch/ignite/discussions): general library-related discussions, ideas, q&a, etc.\n\n## user feedback\n\nwe have created a form for [\"user feedback\"](https://github.com/pytorch/ignite/issues/new/choose). we\nappreciate any type of feedback, and this is how we would like to see our\ncommunity:\n\n- if you like the project and want to say thanks, this the right\n  place.\n- if you do not like something, please, share it with us, and we can\n  see how to improve it.\n\nthank you!\n\n<!-- ############################################################################################################### -->\n\n# contributing\n\nplease see the [contribution guidelines](https://github.com/pytorch/ignite/blob/master/contributing.md) for more information.\n\nas always, prs are welcome :)\n\n<!-- ############################################################################################################### -->\n\n# projects using ignite\n\n<details>\n\n<summary>\nresearch papers\n</summary>\n\n- [batchbald: efficient and diverse batch acquisition for deep bayesian active learning](https://github.com/blackhc/batchbald)\n- [a model to search for synthesizable molecules](https://github.com/john-bradshaw/molecule-chef)\n- [localised generative flows](https://github.com/jrmcornish/lgf)\n- [extracting t cell function and differentiation characteristics from the biomedical literature](https://github.com/hammerlab/t-cell-relation-extraction)\n- [variational information distillation for knowledge transfer](https://github.com/amzn/xfer/tree/master/var_info_distil)\n- [xpersona: evaluating multilingual personalized chatbot](https://github.com/hltchkust/xpersona)\n- [cnn-cass: cnn for classification of coronary artery stenosis score in mpr images](https://github.com/ucuapps/coronaryarterystenosisscoreclassification)\n- [bridging text and video: a universal multimodal transformer for video-audio scene-aware dialog](https://github.com/ictnlp/dstc8-avsd)\n- [adversarial decomposition of text representation](https://github.com/text-machine-lab/adversarial_decomposition)\n- [uncertainty estimation using a single deep deterministic neural network](https://github.com/y0ast/deterministic-uncertainty-quantification)\n- [deepsphere: a graph-based spherical cnn](https://github.com/deepsphere/deepsphere-pytorch)\n- [norm-in-norm loss with faster convergence and better performance for image quality assessment](https://github.com/lidq92/linearityiqa)\n- [unified quality assessment of in-the-wild videos with mixed datasets training](https://github.com/lidq92/mdtvsfa)\n- [deep signature transforms](https://github.com/patrick-kidger/deep-signature-transforms)\n- [neural cdes for long time-series via the log-ode method](https://github.com/jambo6/neuralcdes-via-logodes)\n- [volumetric grasping network](https://github.com/ethz-asl/vgn)\n- [mood classification using listening data](https://github.com/fdlm/listening-moods)\n- [deterministic uncertainty estimation (due)](https://github.com/y0ast/due)\n- [pytorch-hebbian: facilitating local learning in a deep learning framework](https://github.com/joxis/pytorch-hebbian)\n- [stochastic weight matrix-based regularization methods for deep neural networks](https://github.com/rpatrik96/lod-wmm-2019)\n- [learning explanations that are hard to vary](https://github.com/gibipara92/learning-explanations-hard-to-vary)\n- [the role of disentanglement in generalisation](https://github.com/mmrl/disent-and-gen)\n- [a probabilistic programming approach to protein structure superposition](https://github.com/lyssanzmoreta/theseus-pp)\n- [padchest: a large chest x-ray image dataset with multi-label annotated reports](https://github.com/auriml/rx-thorax-automatic-captioning)\n\n</details>\n\n<details>\n\n<summary>\nblog articles, tutorials, books\n</summary>\n\n- [state-of-the-art conversational ai with transfer learning](https://github.com/huggingface/transfer-learning-conv-ai)\n- [tutorial on transfer learning in nlp held at naacl 2019](https://github.com/huggingface/naacl_transfer_learning_tutorial)\n- [deep-reinforcement-learning-hands-on-second-edition, published by packt](https://github.com/packtpublishing/deep-reinforcement-learning-hands-on-second-edition)\n- [once upon a repository: how to write readable, maintainable code with pytorch](https://towardsdatascience.com/once-upon-a-repository-how-to-write-readable-maintainable-code-with-pytorch-951f03f6a829)\n- [the hero rises: build your own ssd](https://allegro.ai/blog/the-hero-rises-build-your-own-ssd/)\n- [using optuna to optimize pytorch ignite hyperparameters](https://medium.com/pytorch/using-optuna-to-optimize-pytorch-ignite-hyperparameters-626ffe6d4783)\n- [pytorch ignite\u200a-\u200aclassifying tiny imagenet with efficientnet](https://towardsdatascience.com/pytorch-ignite-classifying-tiny-imagenet-with-efficientnet-e5b1768e5e8f)\n \n</details>\n\n<details>\n\n<summary>\ntoolkits\n</summary>\n\n- [project monai - ai toolkit for healthcare imaging](https://github.com/project-monai/monai)\n- [deepseismic - deep learning for seismic imaging and interpretation](https://github.com/microsoft/seismic-deeplearning)\n- [nussl - a flexible, object-oriented python audio source separation library](https://github.com/nussl/nussl)\n- [pytorch adapt - a fully featured and modular domain adaptation library](https://github.com/kevinmusgrave/pytorch-adapt)\n- [gnina-torch: pytorch implementation of gnina scoring function](https://github.com/rmeli/gnina-torch)\n \n</details>\n\n<details>\n\n<summary>\nothers\n</summary>\n\n- [implementation of \"attention is all you need\" paper](https://github.com/akurniawan/pytorch-transformer)\n- [implementation of dropblock: a regularization method for convolutional networks in pytorch](https://github.com/miguelvr/dropblock)\n- [kaggle kuzushiji recognition: 2nd place solution](https://github.com/lopuhin/kaggle-kuzushiji-2019)\n- [unsupervised data augmentation experiments in pytorch](https://github.com/vfdev-5/uda-pytorch)\n- [hyperparameters tuning with optuna](https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_ignite_simple.py)\n- [logging with chainerui](https://chainerui.readthedocs.io/en/latest/reference/module.html#external-library-support)\n- [fixmatch experiments in pytorch and ignite (cta dataaug policy)](https://github.com/vfdev-5/fixmatch-pytorch)\n- [kaggle birdcall identification competition: 1st place solution](https://github.com/ryanwongsa/kaggle-birdsong-recognition)\n- [logging with aim - an open-source experiment tracker](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite)\n\n</details>\n\nsee other projects at [\"used by\"](https://github.com/pytorch/ignite/network/dependents?package_id=ugfja2fnzs02nzi5odewna%3d%3d)\n\nif your project implements a paper, represents other use-cases not\ncovered in our official tutorials, kaggle competition's code, or just\nyour code presents interesting results and uses ignite. we would like to\nadd your project to this list, so please send a pr with brief\ndescription of the project.\n\n<!-- ############################################################################################################### -->\n\n# citing ignite\n\nif you use pytorch-ignite in a scientific publication, we would appreciate citations to our project.\n\n```\n@misc{pytorch-ignite,\n  author = {v. fomin and j. anmol and s. desroziers and j. kriss and a. tejani},\n  title = {high-level library to help with training neural networks in pytorch},\n  year = {2020},\n  publisher = {github},\n  journal = {github repository},\n  howpublished = {\\url{https://github.com/pytorch/ignite}},\n}\n```\n\n<!-- ############################################################################################################### -->\n\n# about the team & disclaimer\n\npytorch-ignite is a [numfocus affiliated project](https://www.numfocus.org/), operated and maintained by volunteers in the pytorch community in their capacities as individuals\n(and not as representatives of their employers). see the [\"about us\"](https://pytorch-ignite.ai/about/community/#about-us)\npage for a list of core contributors. for usage questions and issues, please see the various channels\n[here](#communication). for all other questions and inquiries, please send an email\nto contact@pytorch-ignite.ai.\n",
  "docs_url": null,
  "keywords": "",
  "license": "bsd",
  "name": "pytorch-ignite",
  "package_url": "https://pypi.org/project/pytorch-ignite/",
  "project_url": "https://pypi.org/project/pytorch-ignite/",
  "project_urls": {
    "Homepage": "https://github.com/pytorch/ignite"
  },
  "release_url": "https://pypi.org/project/pytorch-ignite/0.4.13/",
  "requires_dist": [
    "torch <3,>=1.3",
    "packaging"
  ],
  "requires_python": "",
  "summary": "a lightweight library to help with training neural networks in pytorch.",
  "version": "0.4.13",
  "releases": [],
  "developers": [
    "contact@pytorch-ignite.ai",
    "pytorch"
  ],
  "kwds": "ignite_logo_mixed logo ignite badge badges",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_pytorch_ignite",
  "homepage": "https://github.com/pytorch/ignite",
  "release_count": 1483,
  "dependency_ids": [
    "pypi_packaging",
    "pypi_torch"
  ]
}