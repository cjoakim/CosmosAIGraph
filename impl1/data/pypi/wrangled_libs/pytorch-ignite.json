{
  "classifiers": [],
  "description": "a lightweight library to help with training neural networks in pytorch.\n<div align=\"center\">\n\n<!-- ![ignite logo](assets/logo/ignite_logo_mixed.svg) -->\n\n<img src=\"https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo_mixed.svg\" width=512>\n\n<!-- [![image](https://travis-ci.com/pytorch/ignite.svg?branch=master)](https://travis-ci.com/pytorch/ignite) -->\n\n| ![image](https://img.shields.io/badge/-tests:-black?style=flat-square) [![image](https://github.com/pytorch/ignite/actions/workflows/unit-tests.yml/badge.svg?branch=master)](https://github.com/pytorch/ignite/actions/workflows/unit-tests.yml) [![image](https://github.com/pytorch/ignite/actions/workflows/gpu-tests.yml/badge.svg)](https://github.com/pytorch/ignite/actions/workflows/gpu-tests.yml) [![image](https://codecov.io/gh/pytorch/ignite/branch/master/graph/badge.svg)](https://codecov.io/gh/pytorch/ignite) [![image](https://img.shields.io/badge/dynamic/json.svg?label=docs&url=https%3a%2f%2fpypi.org%2fpypi%2fpytorch-ignite%2fjson&query=%24.info.version&colorb=brightgreen&prefix=v)](https://pytorch.org/ignite/index.html) |\n|:---\n| ![image](https://img.shields.io/badge/-stable%20releases:-black?style=flat-square) [![image](https://anaconda.org/pytorch/ignite/badges/version.svg)](https://anaconda.org/pytorch/ignite) \u30fb [![image](https://img.shields.io/badge/dynamic/json.svg?label=pypi&url=https%3a%2f%2fpypi.org%2fpypi%2fpytorch-ignite%2fjson&query=%24.info.version&colorb=brightgreen&prefix=v)](https://pypi.org/project/pytorch-ignite/) [![image](https://static.pepy.tech/badge/pytorch-ignite)](https://pepy.tech/project/pytorch-ignite) \u30fb [![image](https://img.shields.io/badge/docker-hub-blue)](https://hub.docker.com/u/pytorchignite) |\n| ![image](https://img.shields.io/badge/-nightly%20releases:-black?style=flat-square) [![image](https://anaconda.org/pytorch-nightly/ignite/badges/version.svg)](https://anaconda.org/pytorch-nightly/ignite) [![image](https://img.shields.io/badge/pypi-pre%20releases-brightgreen)](https://pypi.org/project/pytorch-ignite/#history)|\n| ![image](https://img.shields.io/badge/-community:-black?style=flat-square) [![twitter](https://img.shields.io/badge/news-twitter-blue)](https://twitter.com/pytorch_ignite) [![discord](https://img.shields.io/badge/chat-discord-blue?logo=discord)](https://discord.gg/djztm3emkj) [![numfocus](https://img.shields.io/badge/numfocus-affiliated%20project-green)](https://numfocus.org/sponsored-projects/affiliated-projects) |\n| ![image](https://img.shields.io/badge/-supported_pytorch/python_versions:-black?style=flat-square) [![link](https://img.shields.io/badge/-check_here-blue)](https://github.com/pytorch/ignite/actions?query=workflow%3a%22pytorch+version+tests%22)|\n\n</div>\n\n## tl;dr\n\nignite is a high-level library to help with training and evaluating neural networks in pytorch flexibly and transparently.\n\n<div align=\"center\">\n\n<a href=\"https://colab.research.google.com/github/pytorch/ignite/blob/master/assets/tldr/teaser.ipynb\">\n <img alt=\"pytorch-ignite teaser\"\n      src=\"https://raw.githubusercontent.com/pytorch/ignite/master/assets/tldr/pytorch-ignite-teaser.gif\"\n      width=532>\n</a>\n\n_click on the image to see complete code_\n\n</div>\n\n### features\n\n- [less code than pure pytorch](https://raw.githubusercontent.com/pytorch/ignite/master/assets/ignite_vs_bare_pytorch.png)\n  while ensuring maximum control and simplicity\n\n- library approach and no program's control inversion - _use ignite where and when you need_\n\n- extensible api for metrics, experiment managers, and other components\n\n<!-- ############################################################################################################### -->\n\n# table of contents\n\n- [table of contents](#table-of-contents)\n- [why ignite?](#why-ignite)\n  - [simplified training and validation loop](#simplified-training-and-validation-loop)\n  - [power of events & handlers](#power-of-events--handlers)\n    - [execute any number of functions whenever you wish](#execute-any-number-of-functions-whenever-you-wish)\n    - [built-in events filtering](#built-in-events-filtering)\n    - [stack events to share some actions](#stack-events-to-share-some-actions)\n    - [custom events to go beyond standard events](#custom-events-to-go-beyond-standard-events)\n  - [out-of-the-box metrics](#out-of-the-box-metrics)\n- [installation](#installation)\n  - [nightly releases](#nightly-releases)\n  - [docker images](#docker-images)\n    - [using pre-built images](#using-pre-built-images)\n- [getting started](#getting-started)\n- [documentation](#documentation)\n  - [additional materials](#additional-materials)\n- [examples](#examples)\n  - [tutorials](#tutorials)\n  - [reproducible training examples](#reproducible-training-examples)\n- [communication](#communication)\n  - [user feedback](#user-feedback)\n- [contributing](#contributing)\n- [projects using ignite](#projects-using-ignite)\n- [citing ignite](#citing-ignite)\n- [about the team & disclaimer](#about-the-team--disclaimer)\n\n<!-- ############################################################################################################### -->\n\n# why ignite?\n\nignite is a **library** that provides three high-level features:\n\n- extremely simple engine and event system\n- out-of-the-box metrics to easily evaluate models\n- built-in handlers to compose training pipeline, save artifacts and log parameters and metrics\n\n## simplified training and validation loop\n\nno more coding `for/while` loops on epochs and iterations. users instantiate engines and run them.\n\n<details>\n<summary>\nexample\n</summary>\n\n```python\nfrom ignite.engine import engine, events, create_supervised_evaluator\nfrom ignite.metrics import accuracy\n\n\n# setup training engine:\ndef train_step(engine, batch):\n    # users can do whatever they need on a single iteration\n    # eg. forward/backward pass for any number of models, optimizers, etc\n    # ...\n\ntrainer = engine(train_step)\n\n# setup single model evaluation engine\nevaluator = create_supervised_evaluator(model, metrics={\"accuracy\": accuracy()})\n\ndef validation():\n    state = evaluator.run(validation_data_loader)\n    # print computed metrics\n    print(trainer.state.epoch, state.metrics)\n\n# run model's validation at the end of each epoch\ntrainer.add_event_handler(events.epoch_completed, validation)\n\n# start the training\ntrainer.run(training_data_loader, max_epochs=100)\n```\n\n</details>\n\n## power of events & handlers\n\nthe cool thing with handlers is that they offer unparalleled flexibility (compared to, for example, callbacks). handlers can be any function: e.g. lambda, simple function, class method, etc. thus, we do not require to inherit from an interface and override its abstract methods which could unnecessarily bulk up your code and its complexity.\n\n### execute any number of functions whenever you wish\n\n<details>\n<summary>\nexamples\n</summary>\n\n```python\ntrainer.add_event_handler(events.started, lambda _: print(\"start training\"))\n\n# attach handler with args, kwargs\nmydata = [1, 2, 3, 4]\nlogger = ...\n\ndef on_training_ended(data):\n    print(f\"training is ended. mydata={data}\")\n    # user can use variables from another scope\n    logger.info(\"training is ended\")\n\n\ntrainer.add_event_handler(events.completed, on_training_ended, mydata)\n# call any number of functions on a single event\ntrainer.add_event_handler(events.completed, lambda engine: print(engine.state.times))\n\n@trainer.on(events.iteration_completed)\ndef log_something(engine):\n    print(engine.state.output)\n```\n\n</details>\n\n### built-in events filtering\n\n<details>\n<summary>\nexamples\n</summary>\n\n```python\n# run the validation every 5 epochs\n@trainer.on(events.epoch_completed(every=5))\ndef run_validation():\n    # run validation\n\n# change some training variable once on 20th epoch\n@trainer.on(events.epoch_started(once=20))\ndef change_training_variable():\n    # ...\n\n# trigger handler with customly defined frequency\n@trainer.on(events.iteration_completed(event_filter=first_x_iters))\ndef log_gradients():\n    # ...\n```\n\n</details>\n\n### stack events to share some actions\n\n<details>\n<summary>\nexamples\n</summary>\n\nevents can be stacked together to enable multiple calls:\n\n```python\n@trainer.on(events.completed | events.epoch_completed(every=10))\ndef run_validation():\n    # ...\n```\n\n</details>\n\n### custom events to go beyond standard events\n\n<details>\n<summary>\nexamples\n</summary>\n\ncustom events related to backward and optimizer step calls:\n\n```python\nfrom ignite.engine import eventenum\n\n\nclass backpropevents(eventenum):\n    backward_started = 'backward_started'\n    backward_completed = 'backward_completed'\n    optim_step_completed = 'optim_step_completed'\n\ndef update(engine, batch):\n    # ...\n    loss = criterion(y_pred, y)\n    engine.fire_event(backpropevents.backward_started)\n    loss.backward()\n    engine.fire_event(backpropevents.backward_completed)\n    optimizer.step()\n    engine.fire_event(backpropevents.optim_step_completed)\n    # ...\n\ntrainer = engine(update)\ntrainer.register_events(*backpropevents)\n\n@trainer.on(backpropevents.backward_started)\ndef function_before_backprop(engine):\n    # ...\n```\n\n- complete snippet is found [here](https://pytorch.org/ignite/faq.html#creating-custom-events-based-on-forward-backward-pass).\n- another use-case of custom events: [trainer for truncated backprop through time](https://pytorch.org/ignite/contrib/engines.html#ignite.contrib.engines.create_supervised_tbptt_trainer).\n\n</details>\n\n## out-of-the-box metrics\n\n- [metrics](https://pytorch.org/ignite/metrics.html#complete-list-of-metrics) for various tasks:\n  precision, recall, accuracy, confusion matrix, iou etc, ~20 [regression metrics](https://pytorch.org/ignite/contrib/metrics.html#regression-metrics).\n\n- users can also [compose their metrics](https://pytorch.org/ignite/metrics.html#metric-arithmetics) with ease from\n  existing ones using arithmetic operations or torch methods.\n\n<details>\n<summary>\nexample\n</summary>\n\n```python\nprecision = precision(average=false)\nrecall = recall(average=false)\nf1_per_class = (precision * recall * 2 / (precision + recall))\nf1_mean = f1_per_class.mean()  # torch mean method\nf1_mean.attach(engine, \"f1\")\n```\n\n</details>\n\n<!-- ############################################################################################################### -->\n\n# installation\n\nfrom [pip](https://pypi.org/project/pytorch-ignite/):\n\n```bash\npip install pytorch-ignite\n```\n\nfrom [conda](https://anaconda.org/pytorch/ignite):\n\n```bash\nconda install ignite -c pytorch\n```\n\nfrom source:\n\n```bash\npip install git+https://github.com/pytorch/ignite\n```\n\n## nightly releases\n\nfrom pip:\n\n```bash\npip install --pre pytorch-ignite\n```\n\nfrom conda (this suggests to install [pytorch nightly release](https://anaconda.org/pytorch-nightly/pytorch) instead of stable\nversion as dependency):\n\n```bash\nconda install ignite -c pytorch-nightly\n```\n\n## docker images\n\n### using pre-built images\n\npull a pre-built docker image from [our docker hub](https://hub.docker.com/u/pytorchignite) and run it with docker v19.03+.\n\n```bash\ndocker run --gpus all -it -v $pwd:/workspace/project --network=host --shm-size 16g pytorchignite/base:latest /bin/bash\n```\n\n<details>\n\n<summary>\nlist of available pre-built images\n</summary>\n\nbase\n- `pytorchignite/base:latest` \n- `pytorchignite/apex:latest`\n- `pytorchignite/hvd-base:latest`\n- `pytorchignite/hvd-apex:latest` \n- `pytorchignite/msdp-apex:latest`\n\nvision:\n- `pytorchignite/vision:latest`\n- `pytorchignite/hvd-vision:latest`\n- `pytorchignite/apex-vision:latest`\n- `pytorchignite/hvd-apex-vision:latest`\n- `pytorchignite/msdp-apex-vision:latest`\n\nnlp:\n- `pytorchignite/nlp:latest`\n- `pytorchignite/hvd-nlp:latest`\n- `pytorchignite/apex-nlp:latest` \n- `pytorchignite/hvd-apex-nlp:latest` \n- `pytorchignite/msdp-apex-nlp:latest`\n\n</details>\n\nfor more details, see [here](docker).\n\n<!-- ############################################################################################################### -->\n\n# getting started\n\nfew pointers to get you started:\n\n- [quick start guide: essentials of getting a project up and running](https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/)\n- [concepts of the library: engine, events & handlers, state, metrics](https://pytorch-ignite.ai/concepts/)\n- full-featured template examples (coming soon)\n\n<!-- ############################################################################################################### -->\n\n# documentation\n\n- stable api documentation and an overview of the library: https://pytorch.org/ignite/\n- development version api documentation: https://pytorch.org/ignite/master/\n- [faq](https://pytorch.org/ignite/faq.html),\n  [\"questions on github\"](https://github.com/pytorch/ignite/issues?q=is%3aissue+label%3aquestion+) and\n  [\"questions on discuss.pytorch\"](https://discuss.pytorch.org/c/ignite).\n- [project's roadmap](https://github.com/pytorch/ignite/wiki/roadmap)\n\n## additional materials\n\n- [distributed training made easy with pytorch-ignite](https://labs.quansight.org/blog/2021/06/distributed-made-easy-with-ignite/)\n- [pytorch ecosystem day 2021 breakout session presentation](https://colab.research.google.com/drive/1qhugwq0n2u71ivshlpocyey4ahldcprd)\n- [tutorial blog post about pytorch-ignite](https://labs.quansight.org/blog/2020/09/pytorch-ignite/)\n- [8 creators and core contributors talk about their model training libraries from pytorch ecosystem](https://neptune.ai/blog/model-training-libraries-pytorch-ecosystem?utm_source=reddit&utm_medium=post&utm_campaign=blog-model-training-libraries-pytorch-ecosystem)\n- ignite posters from pytorch developer conferences:\n  - [2021](https://drive.google.com/file/d/1yxrkjieppk_kltsg1zfwrta5irgpfz_u)\n  - [2019](https://drive.google.com/open?id=1bqil-em6gcccosixfzxhibuf25f2qtzg)\n  - [2018](https://drive.google.com/open?id=1_2vzbj0kecjgv1srojmhijrvcesvbvr5)\n\n<!-- ############################################################################################################### -->\n\n# examples\n\n## tutorials\n\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/textcnn.ipynb) [text classification using convolutional neural\n  networks](https://github.com/pytorch/ignite/blob/master/examples/notebooks/textcnn.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/vae.ipynb) [variational auto\n  encoders](https://github.com/pytorch/ignite/blob/master/examples/notebooks/vae.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/fashionmnist.ipynb) [convolutional neural networks for classifying fashion-mnist\n  dataset](https://github.com/pytorch/ignite/blob/master/examples/notebooks/fashionmnist.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/cyclegan_with_nvidia_apex.ipynb) [training cycle-gan on horses to\n  zebras with nvidia/apex](https://github.com/pytorch/ignite/blob/master/examples/notebooks/cyclegan_with_nvidia_apex.ipynb) - [ logs on w&b](https://app.wandb.ai/vfdev-5/ignite-cyclegan-apex)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/cyclegan_with_torch_cuda_amp.ipynb) [another training cycle-gan on horses to\n  zebras with native torch cuda amp](https://github.com/pytorch/ignite/blob/master/examples/notebooks/cyclegan_with_torch_cuda_amp.ipynb) - [logs on w&b](https://app.wandb.ai/vfdev-5/ignite-cyclegan-torch-amp)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/efficientnet_cifar100_finetuning.ipynb) [finetuning efficientnet-b0 on\n  cifar100](https://github.com/pytorch/ignite/blob/master/examples/notebooks/efficientnet_cifar100_finetuning.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/cifar10_ax_hyperparam_tuning.ipynb) [hyperparameters tuning with\n  ax](https://github.com/pytorch/ignite/blob/master/examples/notebooks/cifar10_ax_hyperparam_tuning.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/fastailrfinder_mnist.ipynb) [basic example of lr finder on\n  mnist](https://github.com/pytorch/ignite/blob/master/examples/notebooks/fastailrfinder_mnist.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/cifar100_bench_amp.ipynb) [benchmark mixed precision training on cifar100:\n  torch.cuda.amp vs nvidia/apex](https://github.com/pytorch/ignite/blob/master/examples/notebooks/cifar100_bench_amp.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/mnist_on_tpu.ipynb) [mnist training on a single\n  tpu](https://github.com/pytorch/ignite/blob/master/examples/notebooks/mnist_on_tpu.ipynb)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1e9zjrptnlj_pkhmap5vhb6dtvrvyrkhx) [cifar10 training on multiple tpus](https://github.com/pytorch/ignite/tree/master/examples/cifar10)\n- [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/handlerstimeprofiler_mnist.ipynb) [basic example of handlers\n  time profiling on mnist training example](https://github.com/pytorch/ignite/blob/master/examples/notebooks/handlerstimeprofiler_mnist.ipynb)\n\n## reproducible training examples\n\ninspired by [torchvision/references](https://github.com/pytorch/vision/tree/master/references),\nwe provide several reproducible baselines for vision tasks:\n\n- [imagenet](examples/references/classification/imagenet) - logs on ignite trains server coming soon ...\n- [pascal voc2012](examples/references/segmentation/pascal_voc2012) - logs on ignite trains server coming soon ...\n\nfeatures:\n\n- distributed training: native or horovod and using [pytorch native amp](https://pytorch.org/docs/stable/notes/amp_examples.html)\n\n## code-generator application\n\nthe easiest way to create your training scripts with pytorch-ignite:\n- https://code-generator.pytorch-ignite.ai/\n\n\n<!-- ############################################################################################################### -->\n\n# communication\n\n- [github issues](https://github.com/pytorch/ignite/issues): questions, bug reports, feature requests, etc.\n\n- [discuss.pytorch](https://discuss.pytorch.org/c/ignite), category \"ignite\".\n\n- [pytorch-ignite discord server](https://discord.gg/djztm3emkj): to chat with the community\n\n- [github discussions](https://github.com/pytorch/ignite/discussions): general library-related discussions, ideas, q&a, etc.\n\n## user feedback\n\nwe have created a form for [\"user feedback\"](https://github.com/pytorch/ignite/issues/new/choose). we\nappreciate any type of feedback, and this is how we would like to see our\ncommunity:\n\n- if you like the project and want to say thanks, this the right\n  place.\n- if you do not like something, please, share it with us, and we can\n  see how to improve it.\n\nthank you!\n\n<!-- ############################################################################################################### -->\n\n# contributing\n\nplease see the [contribution guidelines](https://github.com/pytorch/ignite/blob/master/contributing.md) for more information.\n\nas always, prs are welcome :)\n\n<!-- ############################################################################################################### -->\n\n# projects using ignite\n\n<details>\n\n<summary>\nresearch papers\n</summary>\n\n- [batchbald: efficient and diverse batch acquisition for deep bayesian active learning](https://github.com/blackhc/batchbald)\n- [a model to search for synthesizable molecules](https://github.com/john-bradshaw/molecule-chef)\n- [localised generative flows](https://github.com/jrmcornish/lgf)\n- [extracting t cell function and differentiation characteristics from the biomedical literature](https://github.com/hammerlab/t-cell-relation-extraction)\n- [variational information distillation for knowledge transfer](https://github.com/amzn/xfer/tree/master/var_info_distil)\n- [xpersona: evaluating multilingual personalized chatbot](https://github.com/hltchkust/xpersona)\n- [cnn-cass: cnn for classification of coronary artery stenosis score in mpr images](https://github.com/ucuapps/coronaryarterystenosisscoreclassification)\n- [bridging text and video: a universal multimodal transformer for video-audio scene-aware dialog](https://github.com/ictnlp/dstc8-avsd)\n- [adversarial decomposition of text representation](https://github.com/text-machine-lab/adversarial_decomposition)\n- [uncertainty estimation using a single deep deterministic neural network](https://github.com/y0ast/deterministic-uncertainty-quantification)\n- [deepsphere: a graph-based spherical cnn](https://github.com/deepsphere/deepsphere-pytorch)\n- [norm-in-norm loss with faster convergence and better performance for image quality assessment](https://github.com/lidq92/linearityiqa)\n- [unified quality assessment of in-the-wild videos with mixed datasets training](https://github.com/lidq92/mdtvsfa)\n- [deep signature transforms](https://github.com/patrick-kidger/deep-signature-transforms)\n- [neural cdes for long time-series via the log-ode method](https://github.com/jambo6/neuralcdes-via-logodes)\n- [volumetric grasping network](https://github.com/ethz-asl/vgn)\n- [mood classification using listening data](https://github.com/fdlm/listening-moods)\n- [deterministic uncertainty estimation (due)](https://github.com/y0ast/due)\n- [pytorch-hebbian: facilitating local learning in a deep learning framework](https://github.com/joxis/pytorch-hebbian)\n- [stochastic weight matrix-based regularization methods for deep neural networks](https://github.com/rpatrik96/lod-wmm-2019)\n- [learning explanations that are hard to vary](https://github.com/gibipara92/learning-explanations-hard-to-vary)\n- [the role of disentanglement in generalisation](https://github.com/mmrl/disent-and-gen)\n- [a probabilistic programming approach to protein structure superposition](https://github.com/lyssanzmoreta/theseus-pp)\n- [padchest: a large chest x-ray image dataset with multi-label annotated reports](https://github.com/auriml/rx-thorax-automatic-captioning)\n\n</details>\n\n<details>\n\n<summary>\nblog articles, tutorials, books\n</summary>\n\n- [state-of-the-art conversational ai with transfer learning](https://github.com/huggingface/transfer-learning-conv-ai)\n- [tutorial on transfer learning in nlp held at naacl 2019](https://github.com/huggingface/naacl_transfer_learning_tutorial)\n- [deep-reinforcement-learning-hands-on-second-edition, published by packt](https://github.com/packtpublishing/deep-reinforcement-learning-hands-on-second-edition)\n- [once upon a repository: how to write readable, maintainable code with pytorch](https://towardsdatascience.com/once-upon-a-repository-how-to-write-readable-maintainable-code-with-pytorch-951f03f6a829)\n- [the hero rises: build your own ssd](https://allegro.ai/blog/the-hero-rises-build-your-own-ssd/)\n- [using optuna to optimize pytorch ignite hyperparameters](https://medium.com/pytorch/using-optuna-to-optimize-pytorch-ignite-hyperparameters-626ffe6d4783)\n- [pytorch ignite\u200a-\u200aclassifying tiny imagenet with efficientnet](https://towardsdatascience.com/pytorch-ignite-classifying-tiny-imagenet-with-efficientnet-e5b1768e5e8f)\n \n</details>\n\n<details>\n\n<summary>\ntoolkits\n</summary>\n\n- [project monai - ai toolkit for healthcare imaging](https://github.com/project-monai/monai)\n- [deepseismic - deep learning for seismic imaging and interpretation](https://github.com/microsoft/seismic-deeplearning)\n- [nussl - a flexible, object-oriented python audio source separation library](https://github.com/nussl/nussl)\n- [pytorch adapt - a fully featured and modular domain adaptation library](https://github.com/kevinmusgrave/pytorch-adapt)\n- [gnina-torch: pytorch implementation of gnina scoring function](https://github.com/rmeli/gnina-torch)\n \n</details>\n\n<details>\n\n<summary>\nothers\n</summary>\n\n- [implementation of \"attention is all you need\" paper](https://github.com/akurniawan/pytorch-transformer)\n- [implementation of dropblock: a regularization method for convolutional networks in pytorch](https://github.com/miguelvr/dropblock)\n- [kaggle kuzushiji recognition: 2nd place solution](https://github.com/lopuhin/kaggle-kuzushiji-2019)\n- [unsupervised data augmentation experiments in pytorch](https://github.com/vfdev-5/uda-pytorch)\n- [hyperparameters tuning with optuna](https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_ignite_simple.py)\n- [logging with chainerui](https://chainerui.readthedocs.io/en/latest/reference/module.html#external-library-support)\n- [fixmatch experiments in pytorch and ignite (cta dataaug policy)](https://github.com/vfdev-5/fixmatch-pytorch)\n- [kaggle birdcall identification competition: 1st place solution](https://github.com/ryanwongsa/kaggle-birdsong-recognition)\n- [logging with aim - an open-source experiment tracker](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite)\n\n</details>\n\nsee other projects at [\"used by\"](https://github.com/pytorch/ignite/network/dependents?package_id=ugfja2fnzs02nzi5odewna%3d%3d)\n\nif your project implements a paper, represents other use-cases not\ncovered in our official tutorials, kaggle competition's code, or just\nyour code presents interesting results and uses ignite. we would like to\nadd your project to this list, so please send a pr with brief\ndescription of the project.\n\n<!-- ############################################################################################################### -->\n\n# citing ignite\n\nif you use pytorch-ignite in a scientific publication, we would appreciate citations to our project.\n\n```\n@misc{pytorch-ignite,\n  author = {v. fomin and j. anmol and s. desroziers and j. kriss and a. tejani},\n  title = {high-level library to help with training neural networks in pytorch},\n  year = {2020},\n  publisher = {github},\n  journal = {github repository},\n  howpublished = {\\url{https://github.com/pytorch/ignite}},\n}\n```\n\n<!-- ############################################################################################################### -->\n\n# about the team & disclaimer\n\npytorch-ignite is a [numfocus affiliated project](https://www.numfocus.org/), operated and maintained by volunteers in the pytorch community in their capacities as individuals\n(and not as representatives of their employers). see the [\"about us\"](https://pytorch-ignite.ai/about/community/#about-us)\npage for a list of core contributors. for usage questions and issues, please see the various channels\n[here](#communication). for all other questions and inquiries, please send an email\nto contact@pytorch-ignite.ai.\n",
  "docs_url": null,
  "keywords": "",
  "license": "bsd",
  "name": "pytorch-ignite",
  "package_url": "https://pypi.org/project/pytorch-ignite/",
  "project_url": "https://pypi.org/project/pytorch-ignite/",
  "project_urls": {
    "Homepage": "https://github.com/pytorch/ignite"
  },
  "release_url": "https://pypi.org/project/pytorch-ignite/0.4.13/",
  "requires_dist": [
    "torch <3,>=1.3",
    "packaging"
  ],
  "requires_python": "",
  "summary": "a lightweight library to help with training neural networks in pytorch.",
  "version": "0.4.13",
  "releases": [],
  "developers": [
    "contact@pytorch-ignite.ai",
    "pytorch"
  ],
  "kwds": "ignite_logo_mixed logo ignite badge badges",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_pytorch_ignite",
  "homepage": "https://github.com/pytorch/ignite",
  "release_count": 1483,
  "dependency_ids": [
    "pypi_packaging",
    "pypi_torch"
  ],
  "documentation_summary": "PyTorch-Ignite 0.4.13, released on October 19, 2023, is a lightweight library designed to assist in training neural networks with PyTorch. It simplifies and makes the training and evaluation process more transparent and flexible. Key features include a simplified training and validation loop, the power of events and handlers for flexible function execution, built-in events filtering, custom events for extended functionality, and out-of-the-box metrics for easy model evaluation. It supports various installation methods, including pip, conda, and Docker images. The library is extensible, allowing for custom metrics, experiment managers, and other components. PyTorch-Ignite is BSD licensed and maintained by the PyTorch-Ignite Team and contributors.",
  "embedding": [
    -0.03532404080033302,
    -0.0016980657819658518,
    -0.0030011911876499653,
    -0.008432511240243912,
    0.013776659965515137,
    0.009087187238037586,
    0.012381915003061295,
    -0.016566148027777672,
    -0.02356833592057228,
    -0.045798853039741516,
    0.030029702931642532,
    0.007422033231705427,
    -0.018032053485512733,
    0.008404047228395939,
    0.0016108943382278085,
    -0.0021614981815218925,
    0.028620725497603416,
    -0.030001237988471985,
    -0.005685718730092049,
    -0.001164362533017993,
    0.006454251240938902,
    -0.022130895406007767,
    -0.018942907452583313,
    -0.0045471517369151115,
    -0.01630997098982334,
    -0.012737717479467392,
    0.028464173898100853,
    -0.023212533444166183,
    0.0007058225455693901,
    0.002656063064932823,
    0.04278165102005005,
    -0.008667340502142906,
    -0.015569902956485748,
    0.009827256202697754,
    -0.02483499050140381,
    -0.008105173707008362,
    0.015086011961102486,
    0.00012597620661836118,
    0.03438472002744675,
    0.004034796729683876,
    0.03728806599974632,
    0.015413349494338036,
    0.0005252529517747462,
    -0.015214100480079651,
    -0.032079122960567474,
    0.0343562588095665,
    -0.0028926716186106205,
    -0.020266491919755936,
    -0.0005492696072906256,
    0.013356813229620457,
    0.020850006490945816,
    0.015954168513417244,
    -0.0043479022569954395,
    0.007350872736424208,
    -0.007834763266146183,
    -0.0020814426243305206,
    -0.006681964732706547,
    0.027112124487757683,
    0.00032533661578781903,
    -0.0023998855613172054,
    -0.004401272628456354,
    -0.0051199933513998985,
    -0.027524854987859726,
    -0.018615569919347763,
    0.02849263697862625,
    -0.01885751448571682,
    -0.014068417251110077,
    0.03410007804632187,
    -0.012154201976954937,
    -0.021903181448578835,
    0.01757662743330002,
    0.024607278406620026,
    0.004319438245147467,
    -0.0175054669380188,
    0.03745885193347931,
    -0.03355925902724266,
    -0.02046574093401432,
    0.011414133943617344,
    -0.00027774806949310005,
    -0.01871519349515438,
    0.0010095885954797268,
    -0.017163896933197975,
    -0.0181601420044899,
    0.032989975064992905,
    -0.01221824623644352,
    0.03227837383747101,
    0.004952766001224518,
    0.005817365366965532,
    -0.012581164948642254,
    -0.018914442509412766,
    -0.0010353842517361045,
    -0.008325770497322083,
    0.01645229198038578,
    0.019654512405395508,
    -0.021988574415445328,
    0.014509612694382668,
    -0.02177509292960167,
    0.004052586853504181,
    -0.008396930992603302,
    -0.0015548554947599769,
    -0.0089021697640419,
    0.022970587015151978,
    -0.01016170997172594,
    -0.015043315477669239,
    -0.02765294350683689,
    -0.0069381422363221645,
    -0.006610804237425327,
    -0.003896033624187112,
    0.011485293507575989,
    0.038540489971637726,
    -0.014872530475258827,
    0.041130729019641876,
    -0.005066622979938984,
    -0.03871127590537071,
    0.001254202681593597,
    -0.005041716620326042,
    0.027112124487757683,
    0.002150824060663581,
    -0.021504683420062065,
    -0.010104781948029995,
    0.016366899013519287,
    0.01464481744915247,
    0.01497215498238802,
    -0.006845633499324322,
    0.011983416974544525,
    -0.003252031747251749,
    0.01065271720290184,
    0.0004260730929672718,
    0.0013822914334014058,
    -0.03162369504570961,
    0.0029958542436361313,
    -0.004628986120223999,
    -0.008475207723677158,
    -0.008012664504349232,
    -0.013221608474850655,
    -0.021220041438937187,
    -0.008653108961880207,
    -0.023041747510433197,
    -0.020124170929193497,
    -0.010261334478855133,
    0.0008481434197165072,
    0.011670310981571674,
    -0.0003884914913214743,
    -0.022372839972376823,
    -0.029090385884046555,
    0.05066622793674469,
    -0.005016810726374388,
    -0.0017834583995863795,
    -0.006183841731399298,
    -0.017391609027981758,
    0.007671094499528408,
    -0.009457221254706383,
    -0.023653728887438774,
    0.010716761462390423,
    0.00942875724285841,
    0.011556454002857208,
    -0.0073579889722168446,
    0.011613382957875729,
    -0.00796996895223856,
    0.014168042689561844,
    0.009229508228600025,
    0.01418939046561718,
    -0.007735139224678278,
    -0.012018997222185135,
    0.004525803495198488,
    0.01831669546663761,
    0.01951219141483307,
    -0.003945846110582352,
    -0.013356813229620457,
    -0.02615857496857643,
    0.0005821812665089965,
    0.03856895491480827,
    -0.05103626102209091,
    0.0007556348573416471,
    -0.014787138439714909,
    0.011627614498138428,
    0.02126273699104786,
    0.024678438901901245,
    -0.02149045094847679,
    0.015740687027573586,
    0.030086630955338478,
    0.0065858978778123856,
    0.01899983547627926,
    0.0265570729970932,
    -0.008624644950032234,
    0.0002368308196309954,
    -0.001038942369632423,
    -0.006084217224270105,
    -0.014146693982183933,
    -0.022913658991456032,
    0.002508405363187194,
    0.020736150443553925,
    -0.028834206983447075,
    -0.0006858086562715471,
    -0.5793028473854065,
    -0.007820531725883484,
    0.008980446495115757,
    -0.035950250923633575,
    -0.003750154748558998,
    0.0037786189932376146,
    0.005671486724168062,
    -0.00603796262294054,
    -0.006005940493196249,
    0.028079906478524208,
    -0.02287096343934536,
    0.029858916997909546,
    -0.010047852993011475,
    -0.002871323376893997,
    -0.009542614221572876,
    -0.03549482300877571,
    -0.017975125461816788,
    -0.037231139838695526,
    -0.0028446384239941835,
    0.007350872736424208,
    -0.01922754943370819,
    0.02903345599770546,
    0.0029602739959955215,
    0.0009153010905720294,
    0.00568216061219573,
    -0.00156197149772197,
    -0.012061693705618382,
    0.007183645851910114,
    0.036747246980667114,
    0.004251835867762566,
    -0.009421641007065773,
    0.012332103215157986,
    0.023724887520074844,
    0.0007173861376941204,
    0.05593210086226463,
    0.008140753954648972,
    -0.017021575942635536,
    0.07047729194164276,
    -0.010994287207722664,
    0.05274411290884018,
    -0.03498246893286705,
    -0.010026505216956139,
    0.009628006257116795,
    0.024977311491966248,
    0.017135431990027428,
    0.014381523244082928,
    0.013783776201307774,
    0.01183397974818945,
    0.029204241931438446,
    -0.010360958985984325,
    -0.008909285999834538,
    -0.009051606990396976,
    0.004475991241633892,
    -0.006443577352911234,
    0.0042696259915828705,
    -0.0009748979355208576,
    0.010752341710031033,
    0.012716369703412056,
    0.019142156466841698,
    0.013029475696384907,
    -0.004401272628456354,
    0.00945010595023632,
    0.011513758450746536,
    -0.044119469821453094,
    -0.021319665014743805,
    0.003437048988416791,
    0.0009295331547036767,
    -0.022885195910930634,
    -0.005212501622736454,
    -0.035551752895116806,
    0.030940556898713112,
    0.009058723226189613,
    0.021732395514845848,
    -0.022415537387132645,
    0.04659585282206535,
    0.016423828899860382,
    0.03913823887705803,
    0.010147477500140667,
    0.004636102356016636,
    0.044517967849969864,
    0.029972774907946587,
    -0.005699950736016035,
    -0.015057547949254513,
    -0.032989975064992905,
    0.025760076940059662,
    0.008147869259119034,
    -0.004447527229785919,
    -0.013328349217772484,
    0.0057035088539123535,
    0.013114867731928825,
    0.01640959642827511,
    0.03190833702683449,
    -0.02433686889708042,
    -0.03407161682844162,
    0.011492409743368626,
    0.03216451406478882,
    -0.020906934514641762,
    0.02214512601494789,
    -0.0030598987359553576,
    -0.01369838323444128,
    -0.008944866247475147,
    -0.015954168513417244,
    -0.007614166475832462,
    0.0030598987359553576,
    0.009756095707416534,
    0.012730601243674755,
    -0.011520873755216599,
    -0.00861041247844696,
    0.01663730852305889,
    -0.020309187471866608,
    -0.012623860500752926,
    -0.011407017707824707,
    -0.0004563162801787257,
    -0.017918197438120842,
    0.014701745472848415,
    -0.028905367478728294,
    0.006215863861143589,
    0.006390206981450319,
    -0.006326162721961737,
    -0.01347778644412756,
    0.013605874963104725,
    -0.0065076216123998165,
    0.008596180006861687,
    0.019682975485920906,
    0.006013056728988886,
    -0.0024674879387021065,
    0.006336836609989405,
    -0.013178911991417408,
    -0.022116662934422493,
    0.006617920473217964,
    0.02681325189769268,
    0.0023892114404588938,
    0.011933604255318642,
    -0.01105121523141861,
    0.045656535774469376,
    0.02422301098704338,
    0.016466524451971054,
    0.00857483223080635,
    0.019469494000077248,
    -0.013719731941819191,
    0.002803720999509096,
    0.017277752980589867,
    0.023426014930009842,
    -0.023582568392157555,
    -0.020892703905701637,
    -0.010104781948029995,
    -0.010439235717058182,
    0.019796833395957947,
    0.010453467257320881,
    0.003394352737814188,
    -0.015498742461204529,
    0.006265676114708185,
    -0.024536117911338806,
    0.002688085427507758,
    -0.0068812137469649315,
    -0.004283857997506857,
    -0.027667175978422165,
    -0.03398622199892998,
    -0.009307784959673882,
    -0.035807929933071136,
    -0.010012272745370865,
    0.029261169955134392,
    0.009748979471623898,
    0.019924921914935112,
    -0.025304650887846947,
    -0.002483499003574252,
    -0.04081762582063675,
    0.03279072791337967,
    -0.018145911395549774,
    -0.03096901997923851,
    -0.0036416351795196533,
    -0.017605090513825417,
    0.013271421194076538,
    0.023625263944268227,
    0.013897632248699665,
    0.006397322751581669,
    -0.016395363956689835,
    -0.016324203461408615,
    0.001051395433023572,
    -0.001869740430265665,
    -0.007254806347191334,
    0.027823729440569878,
    -0.04278165102005005,
    -0.004867373500019312,
    0.020764613524079323,
    0.01139990147203207,
    0.004653892479836941,
    0.00127199268899858,
    -0.015199868939816952,
    -0.001797690405510366,
    -0.015512974001467228,
    0.006034404505044222,
    -0.0181601420044899,
    0.013292768970131874,
    -0.03392929583787918,
    0.006756683345884085,
    0.005796017125248909,
    -0.01692195050418377,
    -0.017021575942635536,
    0.019569119438529015,
    0.019142156466841698,
    0.009571078233420849,
    0.001972923055291176,
    -0.027496391907334328,
    -0.02053690142929554,
    -0.0076639787293970585,
    0.025418506935238838,
    -0.01090889424085617,
    0.01333546545356512,
    -0.007784951478242874,
    0.011556454002857208,
    -0.01663730852305889,
    -0.02783796191215515,
    -0.015740687027573586,
    -0.0070342086255550385,
    0.02473536692559719,
    -0.01061713695526123,
    0.014687513001263142,
    -0.013257188722491264,
    -0.027126356959342957,
    0.029716596007347107,
    -0.008774081245064735,
    0.002150824060663581,
    6.826953904237598e-05,
    -0.0001589990861248225,
    0.026685163378715515,
    0.011563570238649845,
    0.010332494974136353,
    0.0197683684527874,
    -0.022202055901288986,
    -0.0027699198108166456,
    0.011499525979161263,
    0.00913699995726347,
    -0.023909905925393105,
    0.014616353437304497,
    0.01766202040016651,
    0.029574276879429817,
    -0.021675467491149902,
    0.02800874598324299,
    -0.02994430996477604,
    -0.0009944670600816607,
    0.01132874097675085,
    0.016423828899860382,
    -0.0121470857411623,
    0.01666577346622944,
    0.03316076099872589,
    -0.005461563356220722,
    -0.013008126989006996,
    -0.01061713695526123,
    -0.0017603312153369188,
    0.014452683739364147,
    0.019896456971764565,
    -0.00114657252561301,
    0.019853761419653893,
    0.012296522967517376,
    -0.019142156466841698,
    0.0013351476518437266,
    0.00014788027328904718,
    0.01787550002336502,
    0.02287096343934536,
    -0.00018835277296602726,
    -0.00547223724424839,
    0.007457613479346037,
    -0.023767584934830666,
    0.017021575942635536,
    -0.033103834837675095,
    0.003447722876444459,
    -0.009599542245268822,
    -0.007258363999426365,
    -0.014929458498954773,
    -0.0233121570199728,
    -0.022742874920368195,
    -0.007770719472318888,
    -0.024279939010739326,
    0.050466980785131454,
    0.006404438987374306,
    0.005223175976425409,
    0.04753516986966133,
    0.005692834500223398,
    0.029488883912563324,
    -0.021860485896468163,
    -0.020693454891443253,
    0.028435708954930305,
    0.011371437460184097,
    -0.009051606990396976,
    -0.04585578292608261,
    -0.04744977504014969,
    0.0029478210490196943,
    -0.001462346874177456,
    -0.0012782192789018154,
    0.0074504972435534,
    0.020010313019156456,
    -0.01864403299987316,
    0.005746204871684313,
    -0.009507033973932266,
    0.006315488368272781,
    0.045798853039741516,
    -0.017306217923760414,
    -0.006119797471910715,
    -0.012751949951052666,
    0.012538468465209007,
    -0.004984788130968809,
    -0.013506250455975533,
    0.00857483223080635,
    0.02279980294406414,
    -0.01951219141483307,
    0.0025937978643924,
    -0.014210738241672516,
    -0.006091332994401455,
    -0.010958706960082054,
    0.01936987042427063,
    0.007735139224678278,
    0.02436533197760582,
    -0.04557114094495773,
    0.02268594689667225,
    0.004874489735811949,
    0.009713399223983288,
    0.0055505139753222466,
    0.012972546741366386,
    -0.005778227001428604,
    0.0011768157128244638,
    -0.011407017707824707,
    -0.005973918363451958,
    -0.01666577346622944,
    0.04912916198372841,
    0.0233121570199728,
    -0.017790108919143677,
    0.004355018492788076,
    -0.044119469821453094,
    -0.02046574093401432,
    -0.03082669898867607,
    0.003782177111133933,
    0.01048904750496149,
    0.00554339773952961,
    -0.022557856515049934,
    0.005212501622736454,
    0.006358184851706028,
    0.011200652457773685,
    0.0203945804387331,
    0.012139969505369663,
    -0.011663194745779037,
    0.0007018197793513536,
    -0.007336640730500221,
    0.0027699198108166456,
    0.011485293507575989,
    -0.0004543148970697075,
    0.017235057428479195,
    -0.015555670484900475,
    0.032477620989084244,
    -0.006265676114708185,
    0.024137618020176888,
    0.012139969505369663,
    -0.02539004199206829,
    -0.01703580841422081,
    -0.01689348742365837,
    -0.0005203606560826302,
    0.005785343237221241,
    0.0024247916880995035,
    -0.03575100004673004,
    0.020821543410420418,
    0.014787138439714909,
    0.038141991943120956,
    -0.0006631262949667871,
    0.014431335963308811,
    0.030912091955542564,
    0.01309351995587349,
    0.0029424838721752167,
    0.006955932360142469,
    0.011079679243266582,
    -0.005514933727681637,
    0.014687513001263142,
    0.045144177973270416,
    -0.015384885482490063,
    -0.003874685615301132,
    0.03196526691317558,
    0.00536193884909153,
    -0.06011633574962616,
    -0.026144342496991158,
    0.023155605420470238,
    0.008041128516197205,
    0.013449321500957012,
    -0.018444783985614777,
    0.013527598232030869,
    -0.025631988421082497,
    -0.0035064304247498512,
    -0.02079307846724987,
    0.008688689209520817,
    -0.0007494083256460726,
    0.009265088476240635,
    -0.02214512601494789,
    0.003607833990827203,
    -0.0016704911831766367,
    -0.026756322011351585,
    0.024607278406620026,
    -0.043094757944345474,
    -0.050495442003011703,
    -0.018330927938222885,
    0.009364712983369827,
    0.016466524451971054,
    0.01185532845556736,
    0.0005697282031178474,
    0.008539251983165741,
    -0.0036718782503157854,
    0.008019780740141869,
    0.01801782101392746,
    -0.009457221254706383,
    -0.01757662743330002,
    -0.06375975161790848,
    -0.00532635860145092,
    -0.017277752980589867,
    -0.002250448800623417,
    0.0042696259915828705,
    0.009265088476240635,
    0.01645229198038578,
    0.017633555456995964,
    -0.004934975877404213,
    0.01457365695387125,
    0.0022949238773435354,
    0.0014276561560109258,
    0.013178911991417408,
    0.023909905925393105,
    0.002410559682175517,
    0.0027218866162002087,
    -0.020522668957710266,
    0.00628346623852849,
    -0.03290458396077156,
    0.010809269733726978,
    -0.00571774085983634,
    -0.011976300738751888,
    0.013356813229620457,
    0.007535889744758606,
    -0.009599542245268822,
    -0.009514150209724903,
    -0.010709645226597786,
    0.008909285999834538,
    -0.016808094456791878,
    -0.0025795656256377697,
    0.003764386987313628,
    -0.004426178988069296,
    -0.004525803495198488,
    -0.020380347967147827,
    0.03563714399933815,
    -0.020992327481508255,
    -0.008019780740141869,
    0.001754994154907763,
    -0.012381915003061295,
    0.021689699962735176,
    0.02093539945781231,
    -0.0009748979355208576,
    0.0023091561160981655,
    -0.024166082963347435,
    -0.005995266605168581,
    -0.028578029945492744,
    0.021077720448374748,
    0.03472629189491272,
    0.0037786189932376146,
    0.0007538558566011488,
    -0.022785570472478867,
    -0.010802153497934341,
    -0.019526422023773193,
    -0.012004764750599861,
    0.003207556437700987,
    -0.004596963990479708,
    -0.01787550002336502,
    -0.0197683684527874,
    -0.015840312466025352,
    -0.002841080306097865,
    0.0087527334690094,
    0.007635514251887798,
    -0.02863495796918869,
    -0.03190833702683449,
    0.009051606990396976,
    0.014303247444331646,
    0.010538860224187374,
    -0.005643022246658802,
    -0.017533930018544197,
    -0.01808898150920868,
    -0.019654512405395508,
    -0.021362362429499626,
    -0.002711212495341897,
    -0.015712223947048187,
    0.0035313365515321493,
    0.03706035390496254,
    0.029346562922000885,
    0.02560352347791195,
    0.011577802710235119,
    0.024906150996685028,
    0.00857483223080635,
    -0.0016713807126507163,
    0.006240770220756531,
    -0.004714378621429205,
    0.004945650231093168,
    0.0041059572249650955,
    -0.01528526097536087,
    0.009307784959673882,
    0.005842271726578474,
    0.004365692380815744,
    -0.052801042795181274,
    -0.029133081436157227,
    0.0036612043622881174,
    -0.008382699452340603,
    -0.01324295625090599,
    -0.005739089101552963,
    -0.037373460829257965,
    -0.01808898150920868,
    0.03600718080997467,
    -0.008517904207110405,
    0.006678406614810228,
    -0.03045666590332985,
    -0.010353842750191689,
    0.027880657464265823,
    -0.0008525909506715834,
    0.030741307884454727,
    0.03965059295296669,
    0.011229116469621658,
    0.0002412783505860716,
    0.015384885482490063,
    0.018772121518850327,
    0.0242941714823246,
    0.0007956625777296722,
    -0.017932429909706116,
    -0.03910977393388748,
    -0.015384885482490063,
    0.022202055901288986,
    0.009279320947825909,
    0.01324295625090599,
    0.006158935371786356,
    0.011271812953054905,
    0.0007405132637359202,
    0.02473536692559719,
    -0.009300668723881245,
    0.019426798447966576,
    0.02191741392016411,
    -0.03669032081961632,
    -0.012524235993623734,
    0.008951982483267784,
    -0.02669939398765564,
    -0.006973722483962774,
    0.01458788849413395,
    -0.003326750360429287,
    0.0016633751802146435,
    0.018914442509412766,
    -0.02812260389328003,
    -0.009998041205108166,
    0.02483499050140381,
    -0.0029282518662512302,
    0.04363557696342468,
    0.007977084256708622,
    0.025034239515662193,
    0.017847036942839622,
    0.019455261528491974,
    -0.020451508462429047,
    -0.01065271720290184,
    -0.005650138482451439,
    0.002282470930367708,
    0.02149045094847679,
    -0.0020867798011749983,
    -0.02060806192457676,
    -0.030257416889071465,
    0.033246155828237534,
    0.00864599272608757,
    -0.030399737879633904,
    -0.01169165875762701,
    0.022885195910930634,
    0.03344540297985077,
    0.019270244985818863,
    -0.03703188896179199,
    -0.02159007452428341,
    -0.005166247487068176,
    0.01450249645859003,
    -0.008375583216547966,
    0.013299885205924511,
    0.005397518631070852,
    -0.008083824999630451,
    -0.007176529616117477,
    0.03976444900035858,
    0.03082669898867607,
    0.00726903835311532,
    -0.0020583155564963818,
    -0.019199084490537643,
    0.004066818859428167,
    0.0027521296869963408,
    -0.02812260389328003,
    -0.000983792939223349,
    0.02228744700551033,
    0.02279980294406414,
    -0.02326946146786213,
    0.007137391250580549,
    0.05761148780584335,
    -0.014602120965719223,
    0.004379924852401018,
    -0.009371829219162464,
    -0.002919356804341078,
    0.03745885193347931,
    -0.020878471434116364,
    0.011990533210337162,
    -0.02009570598602295,
    -0.025560827925801277,
    0.01766202040016651,
    -0.02112041600048542,
    -0.009435873478651047,
    0.002287807874381542,
    0.0158687774091959,
    0.0017176349647343159,
    0.0033107390627264977,
    -0.013634338974952698,
    -0.02060806192457676,
    0.0034904193598777056,
    0.004091724753379822,
    -0.005539839621633291,
    -0.014659048989415169,
    -0.015569902956485748,
    0.0038141992408782244,
    -0.03407161682844162,
    -0.0005826260312460363,
    -0.02746792696416378,
    -0.03407161682844162,
    -0.007550121750682592,
    0.025162329897284508,
    0.006966606248170137,
    -0.01535642147064209,
    0.04690895602107048,
    -0.01663730852305889,
    -0.016096489503979683,
    -0.011677427217364311,
    -0.0027539087459445,
    -0.012645209208130836,
    0.010930242948234081,
    -0.023411782458424568,
    0.007254806347191334,
    0.03856895491480827,
    0.01094447448849678,
    -0.0395367369055748,
    -0.004504455253481865,
    0.009144115261733532,
    0.017348913475871086,
    0.009571078233420849,
    -0.012104389257729053,
    -0.013036591000854969,
    0.016253042966127396,
    -0.0034014687407761812,
    -0.026756322011351585,
    0.0008792760781943798,
    0.008987562730908394,
    -0.014787138439714909,
    0.017975125461816788,
    0.01969720795750618,
    -0.0039743101224303246,
    0.028606494888663292,
    -0.00038337684236466885,
    0.012830225750803947,
    0.024237243458628654,
    -0.043350934982299805,
    -0.026386288926005363,
    -0.011670310981571674,
    -0.012090157717466354,
    -0.018473248928785324,
    0.025945093482732773,
    0.016978878527879715,
    -0.014673281461000443,
    -0.013719731941819191,
    0.026614002883434296,
    0.009763211011886597,
    0.004084608983248472,
    0.023767584934830666,
    0.006753125227987766,
    -0.023938369005918503,
    0.008460975252091885,
    -0.005678602494299412,
    -0.005233849864453077,
    0.004856699611991644,
    0.009265088476240635,
    -0.04588424786925316,
    -0.024166082963347435,
    0.0031719764228910208,
    0.05337032675743103,
    0.01808898150920868,
    -0.04184233397245407,
    -0.018330927938222885,
    -0.027638712897896767,
    -0.018359391018748283,
    -0.009770327247679234,
    -0.04394868388772011,
    0.033360011875629425,
    -0.004027680493891239,
    0.012830225750803947,
    0.018985603004693985,
    0.02455035038292408,
    -2.729669722612016e-05,
    0.022415537387132645,
    0.001193716307170689,
    0.010645600967109203,
    -0.0022095313761383295,
    0.0074647292494773865,
    -0.002889113500714302,
    -0.015512974001467228,
    -0.03358772397041321,
    -0.020238026976585388,
    0.009841487742960453,
    -0.002864207373932004,
    0.001579761621542275,
    0.028407244011759758,
    -0.02732560597360134,
    0.01579761691391468,
    -0.0009748979355208576,
    -0.0030332135502249002,
    -0.0059988247230648994,
    0.007628398481756449,
    0.025589291006326675,
    -0.027553319931030273,
    -0.004500897601246834,
    0.012730601243674755,
    -0.011805515736341476,
    0.012132854200899601,
    -0.0017407621489837766,
    0.012517119757831097,
    -0.016494987532496452,
    0.006681964732706547,
    -0.02721174992620945,
    0.010396539233624935,
    0.007571469992399216,
    0.015527206473052502,
    0.02867765538394451,
    -0.01582607999444008,
    0.011214883998036385,
    0.03671878203749657,
    -0.0056465803645551205,
    0.018373623490333557,
    -0.04033373296260834,
    0.0009944670600816607,
    -0.03575100004673004,
    -0.013100636191666126,
    0.04201311990618706,
    -0.035466358065605164,
    -0.007955736480653286,
    -0.014886762946844101,
    0.03170908987522125,
    0.00536193884909153,
    -0.0019444588106125593,
    -0.006091332994401455,
    0.011734355241060257,
    -0.04024834185838699,
    0.005689276847988367,
    0.004351460374891758,
    -0.019241781905293465,
    0.008738500997424126,
    0.005514933727681637,
    0.032079122960567474,
    0.00592766422778368,
    -0.027809496968984604,
    0.01747700199484825,
    -0.012232478708028793,
    -0.011812631972134113,
    0.014331711456179619,
    0.009265088476240635,
    -0.04505878686904907,
    -0.008759849704802036,
    0.02097809500992298,
    -0.012211130000650883,
    -0.0012204013764858246,
    0.19537808001041412,
    -0.0030332135502249002,
    0.018330927938222885,
    0.022159358486533165,
    -0.008048244751989841,
    0.009990924969315529,
    -0.006593014113605022,
    -0.00575332110747695,
    -0.006080659106373787,
    0.027154821902513504,
    0.0017354250885546207,
    -0.02305597998201847,
    -0.023838745430111885,
    -0.007155181374400854,
    -0.013975908979773521,
    -0.004401272628456354,
    -0.034897077828645706,
    -0.03765810281038284,
    -0.012787530198693275,
    -0.016494987532496452,
    0.019142156466841698,
    0.000743626500479877,
    -0.011791284196078777,
    -0.017960892990231514,
    0.014815602451562881,
    -0.014267667196691036,
    0.00596324447542429,
    0.014047069475054741,
    0.023326389491558075,
    0.019739903509616852,
    -0.022031269967556,
    0.020949631929397583,
    -0.0068776560947299,
    0.00586361950263381,
    -0.03333154693245888,
    -0.010353842750191689,
    0.01845901645720005,
    -0.014495380222797394,
    0.016680005937814713,
    0.03612103685736656,
    0.021760860458016396,
    -0.028976527974009514,
    0.010716761462390423,
    -0.027012500911951065,
    0.0014774685259908438,
    -0.02450765296816826,
    -0.022088197991251945,
    0.0298019889742136,
    0.0038889176212251186,
    0.015697991475462914,
    -0.03281919285655022,
    -0.00900891050696373,
    0.008169217966496944,
    0.005269430112093687,
    0.012837341986596584,
    0.006123355124145746,
    -0.017932429909706116,
    0.023611031472682953,
    0.03589332103729248,
    -0.005379728972911835,
    -0.028464173898100853,
    0.002680969424545765,
    -0.011584918946027756,
    0.007905923761427402,
    -0.03905284404754639,
    0.020593829452991486,
    -0.032591477036476135,
    0.01612495444715023,
    0.010168826207518578,
    -0.01033961120992899,
    -0.03034280799329281,
    -0.024194547906517982,
    -0.030912091955542564,
    -0.02235860750079155,
    -0.02709789387881756,
    -0.03910977393388748,
    0.021718164905905724,
    -0.0074433814734220505,
    0.017277752980589867,
    0.0226574819535017,
    -0.0018839724361896515,
    0.007336640730500221,
    -0.009677818976342678,
    0.016694238409399986,
    -0.011648963205516338,
    -0.002490615239366889,
    0.011293160729110241,
    -0.025333113968372345,
    -0.011357204988598824,
    -0.004415505100041628,
    -0.027496391907334328,
    -0.041415371000766754,
    0.008034013211727142,
    -0.009933996014297009,
    0.003289391053840518,
    -0.0006168719846755266,
    -0.006023730617016554,
    0.0213765949010849,
    -0.008019780740141869,
    0.006069984752684832,
    -0.04861680790781975,
    0.04534342885017395,
    0.018843282014131546,
    -0.00015221661305986345,
    -0.026030486449599266,
    0.01598263345658779,
    -0.0012204013764858246,
    0.022017037495970726,
    0.0025315324310213327,
    -0.018032053485512733,
    -0.007599934469908476,
    -0.0349540039896965,
    0.010111897252500057,
    -0.004525803495198488,
    -0.011371437460184097,
    0.004856699611991644,
    -0.019455261528491974,
    -0.001159025589004159,
    0.00603796262294054,
    -0.018515944480895996,
    0.004440410993993282,
    -0.01331411674618721,
    -0.0018483923049643636,
    -0.0049954624846577644,
    -0.009763211011886597,
    -0.018032053485512733,
    -0.029133081436157227,
    0.032192979007959366,
    -0.020053010433912277,
    0.0018661823123693466,
    0.02702673338353634,
    -0.030769770964980125,
    0.03034280799329281,
    -0.006941700354218483,
    -0.007048441097140312,
    -0.012872922234237194,
    -0.01502908393740654,
    -0.018174374476075172,
    -0.008880821987986565,
    0.025703148916363716,
    -0.010738109238445759,
    0.00448666512966156,
    0.011954952962696552,
    -0.00913699995726347,
    0.029346562922000885,
    -0.006955932360142469,
    0.0006564549985341728,
    0.011769935488700867,
    0.003485082183033228,
    0.007977084256708622,
    0.00035135462530888617,
    0.021405057981610298,
    0.019284477457404137,
    -0.016295738518238068,
    0.02513386495411396,
    -0.03455550596117973,
    0.008069593459367752,
    -0.010545976459980011,
    0.010645600967109203,
    -0.00035557980299927294,
    -0.024749599397182465,
    -0.002638273173943162,
    -0.007948620244860649,
    0.01094447448849678,
    -0.016110721975564957,
    -0.01619611494243145,
    -0.18080443143844604,
    -0.002878439612686634,
    0.026215502992272377,
    -0.029204241931438446,
    0.03253455087542534,
    -0.012033229693770409,
    0.030399737879633904,
    0.005820923484861851,
    -0.015484509989619255,
    -0.0025973557494580746,
    0.011499525979161263,
    -0.026685163378715515,
    -0.023255228996276855,
    -0.02093539945781231,
    -0.004867373500019312,
    0.016836559399962425,
    0.007436265237629414,
    0.035580217838287354,
    0.04070376604795456,
    0.012374799698591232,
    0.026386288926005363,
    -0.024094922468066216,
    0.01090889424085617,
    0.01732044853270054,
    -0.009492801502346992,
    -0.027624480426311493,
    -0.0023144930601119995,
    -0.012865805998444557,
    0.01794666051864624,
    -0.021647004410624504,
    -0.01221824623644352,
    -0.009229508228600025,
    -0.0023127140011638403,
    0.0023998855613172054,
    -0.007308176718652248,
    0.00024261260114144534,
    0.027994513511657715,
    -0.014630584977567196,
    -0.02305597998201847,
    0.029232706874608994,
    0.04198465496301651,
    0.019654512405395508,
    0.006838517729192972,
    -0.015569902956485748,
    -0.017747411504387856,
    0.006977280601859093,
    -0.004276742227375507,
    -0.009051606990396976,
    0.036462604999542236,
    -0.012559816241264343,
    0.055248960852622986,
    0.001051395433023572,
    0.0036060549318790436,
    0.00208322168327868,
    0.0236394964158535,
    -0.002883776556700468,
    0.013833587989211082,
    0.014452683739364147,
    0.028321852907538414,
    -0.01801782101392746,
    -0.005337032489478588,
    -0.026528609916567802,
    0.008966214954853058,
    -0.0026952014304697514,
    -0.009535497985780239,
    -0.0259308610111475,
    0.0017265300266444683,
    0.026343591511249542,
    -0.00932201649993658,
    0.013933212496340275,
    0.03373004496097565,
    -0.012438843958079815,
    -0.02812260389328003,
    -0.001709629432298243,
    0.004020564258098602,
    -0.0009909090586006641,
    -0.01670846901834011,
    0.016068026423454285,
    0.007991316728293896,
    -0.00025439856108278036,
    -0.013228724710643291,
    0.03876820579171181,
    0.000640888640191406,
    0.011677427217364311,
    -0.0043265544809401035,
    0.0013556062476709485,
    0.029346562922000885,
    0.009955344721674919,
    -0.03871127590537071,
    -0.0033231922425329685,
    0.018800586462020874,
    -0.021405057981610298,
    -0.008567715995013714,
    -0.017121199518442154,
    -0.006176725495606661,
    0.018772121518850327,
    0.01059578824788332,
    0.003349877428263426,
    0.02378181740641594,
    -0.01601109839975834,
    0.014659048989415169,
    0.017775876447558403,
    -0.0073010604828596115,
    0.002170393243432045,
    0.045144177973270416,
    0.011848212219774723,
    -0.018615569919347763,
    -0.0034904193598777056,
    0.029133081436157227,
    0.01999608241021633,
    -0.014281898736953735,
    0.02181778848171234,
    0.015854544937610626,
    0.021504683420062065,
    -0.02133389748632908,
    0.020878471434116364,
    -0.011200652457773685,
    -0.012695020996034145,
    0.026357823982834816,
    -0.018288230523467064,
    0.03572253882884979,
    0.00045053448411636055,
    -0.009001795202493668,
    0.02968813292682171,
    -0.021433522924780846,
    -0.03651953488588333,
    -0.1024140939116478,
    -0.045172642916440964,
    0.019056763499975204,
    0.0059134322218596935,
    -0.0007591928588226438,
    -0.001324473530985415,
    -0.0020547574386000633,
    0.032563015818595886,
    -0.005251639988273382,
    0.02867765538394451,
    -0.019569119438529015,
    0.01724928990006447,
    -0.01482983399182558,
    0.02462150901556015,
    -0.019640279933810234,
    -0.0038391053676605225,
    -0.018871746957302094,
    0.010752341710031033,
    -0.001730088028125465,
    0.01761932298541069,
    -0.00610200734809041,
    0.0033605515491217375,
    -0.00020325198420323431,
    0.004668124485760927,
    -0.018145911395549774,
    0.0027894889935851097,
    -0.027994513511657715,
    0.024521885439753532,
    -0.0009499918087385595,
    0.014424219727516174,
    0.031054412946105003,
    -0.007998432964086533,
    0.013890516944229603,
    0.0011181082809343934,
    -0.000974008406046778,
    -0.003977868240326643,
    -0.009891300462186337,
    -0.01798935793340206,
    -0.0033712254371494055,
    -0.024379564449191093,
    0.002835743362084031,
    -0.013876284472644329,
    0.019355637952685356,
    0.002839301247149706,
    -0.008909285999834538,
    0.009585310705006123,
    -0.01017594151198864,
    0.004084608983248472,
    0.016694238409399986,
    -0.02410915493965149,
    -0.00893775001168251,
    -0.018003590404987335,
    -0.01227517519146204,
    -0.0059988247230648994,
    0.01302235946059227,
    -0.009983808733522892,
    0.017918197438120842,
    -0.014915226958692074,
    -0.008147869259119034,
    -0.006091332994401455,
    0.008147869259119034,
    -0.021476218476891518,
    0.0052053858526051044,
    0.02312714047729969,
    0.00508797075599432,
    -0.002666737185791135,
    -0.019426798447966576,
    0.0015966622158885002,
    0.018074750900268555,
    -0.03461243584752083,
    -0.01722082495689392,
    -5.2258441428421065e-05,
    -0.006977280601859093,
    0.017903964966535568,
    -0.029090385884046555,
    -0.01444556750357151,
    -0.0041842334903776646,
    -0.026855947449803352,
    -0.013641455210745335,
    -0.0033356454223394394,
    -0.012723485007882118,
    -0.0023767584934830666,
    -0.014715977944433689,
    -0.014801369979977608,
    0.01988222450017929,
    -0.0029140196274966,
    -0.004223371855914593,
    -0.0007929941057227552,
    0.03017202392220497,
    -0.029887381941080093,
    0.022785570472478867,
    -0.00906583946198225,
    0.024080689996480942,
    -0.001291561871767044,
    -0.021547378972172737,
    -0.003775060875341296,
    0.006977280601859093,
    0.0068812137469649315,
    -0.004358576610684395,
    0.036861103028059006,
    -0.0034886403009295464,
    -0.006272792350500822,
    -0.07081886380910873,
    0.03176601603627205,
    0.006212305743247271,
    -0.00903025921434164,
    0.011214883998036385,
    -0.024635741487145424,
    -0.016096489503979683,
    -0.017861269414424896,
    0.01019729021936655,
    0.010588672012090683,
    -0.020565364509820938,
    -0.001960469875484705,
    -0.012759065255522728,
    0.014659048989415169,
    0.017405841499567032,
    -0.0226574819535017,
    0.035807929933071136,
    0.00607354287058115,
    0.019199084490537643,
    -7.482964429073036e-05,
    -0.020437275990843773,
    -0.005796017125248909,
    0.029716596007347107,
    0.018800586462020874,
    -0.04443257302045822,
    -0.014374407939612865,
    -0.02534734643995762,
    0.008831010200083256,
    0.007293944247066975,
    -0.009983808733522892,
    0.0230132844299078,
    -0.003849779488518834,
    0.023625263944268227,
    0.022700177505612373,
    0.0103751914575696,
    -0.008766965009272099,
    0.013712615706026554,
    -0.007087578997015953,
    0.006632152479141951,
    -0.0025528804399073124,
    -0.023411782458424568,
    -0.0343562588095665,
    0.020252259448170662,
    0.03227837383747101,
    -0.0003004304599016905,
    -0.010019388981163502,
    0.0026364941149950027,
    -0.008361350744962692,
    0.03390083089470863,
    0.020366115495562553,
    0.035694073885679245,
    0.01761932298541069,
    -0.0275106243789196,
    -0.032733798027038574,
    -0.008923518471419811,
    -0.001832381123676896,
    0.02294212393462658,
    -0.006432902999222279,
    -0.004141537006944418,
    -0.010396539233624935,
    0.03999216482043266,
    -0.0014854740584269166,
    0.012581164948642254,
    0.00897333025932312,
    0.015327957458794117,
    -0.035295575857162476,
    -0.04064683988690376,
    0.001241749501787126,
    -0.015626830980181694,
    -0.0008850579033605754,
    -0.0017149664927273989,
    -0.036747246980667114,
    0.004426178988069296,
    0.015527206473052502,
    0.032961513847112656,
    -0.016608845442533493,
    0.0021223598159849644,
    -0.00472505297511816,
    -0.015712223947048187,
    0.01722082495689392,
    0.027752568945288658,
    -0.02991584688425064,
    0.0031684183049947023,
    0.00871715322136879,
    0.030257416889071465,
    -0.000896176730748266,
    -0.030485128983855247,
    0.0021241388749331236,
    -0.0030901418067514896,
    -0.010090549476444721,
    -0.020223794505000114,
    -0.0031097109895199537,
    -0.023070212453603745,
    0.009250856004655361,
    0.004294532351195812,
    -0.007571469992399216,
    0.014274782501161098,
    0.0009508812800049782,
    0.0047001466155052185,
    0.013897632248699665,
    0.01999608241021633,
    -0.0034103638026863337,
    0.014360175468027592,
    -0.013961677439510822,
    -0.015840312466025352,
    -0.005251639988273382,
    -0.00021759526862297207,
    -0.0009028479689732194,
    -0.004365692380815744,
    0.005578977987170219,
    6.371082417899743e-05,
    -0.018046285957098007,
    -0.03250608593225479,
    0.01801782101392746,
    -0.013114867731928825,
    0.01633843593299389,
    0.011670310981571674,
    -0.022045502439141273,
    -0.008553484454751015,
    0.011093911714851856,
    0.02695557288825512,
    0.003700342494994402,
    0.060970257967710495,
    -0.028321852907538414,
    0.02217359095811844,
    0.01754816249012947,
    0.011705891229212284,
    -0.024422260001301765,
    0.030428200960159302,
    0.0023963276762515306,
    0.0005826260312460363,
    0.012773297727108002,
    -0.032733798027038574,
    -0.012680789455771446,
    -0.010396539233624935,
    -0.01666577346622944,
    0.0008823893731459975,
    -0.007272596471011639,
    0.004020564258098602,
    0.10582979768514633,
    -0.004294532351195812,
    -0.0018644033698365092,
    -0.007208551745861769,
    -0.016580380499362946,
    0.0213765949010849,
    -0.006689080502837896,
    0.012097273953258991,
    -0.022444000467658043,
    0.0018537292489781976,
    -0.011136608198285103,
    -0.009179695509374142,
    -0.012844458222389221,
    -0.039195165038108826,
    -0.015484509989619255,
    -0.015271028503775597,
    -0.023440247401595116,
    0.004137979354709387,
    -0.004963440354913473,
    -0.017078503966331482,
    0.022387072443962097,
    -0.002214868552982807,
    0.007027092855423689,
    -0.009941112250089645,
    -0.04090301692485809,
    -0.0010078096529468894,
    0.03432779386639595,
    0.013470670208334923,
    -0.013292768970131874,
    -0.05482199788093567,
    0.04198465496301651,
    -0.008916402235627174,
    -0.025745844468474388,
    -0.01995338499546051,
    -0.013008126989006996,
    0.01645229198038578,
    -0.0029157986864447594,
    -0.005902757868170738,
    0.03230683505535126,
    0.02768140845000744,
    0.0009499918087385595,
    -0.013114867731928825,
    -0.03486861288547516,
    -0.030371272936463356,
    0.03017202392220497,
    0.009129883721470833,
    -0.02053690142929554,
    -0.010916010476648808,
    -0.05140629783272743
  ]
}