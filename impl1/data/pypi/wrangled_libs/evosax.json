{
  "classifiers": [
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering :: artificial intelligence"
  ],
  "description": "# `evosax`: jax-based evolution strategies \ud83e\udd8e\n[![pyversions](https://img.shields.io/pypi/pyversions/evosax.svg?style=flat-square)](https://pypi.python.org/pypi/evosax) [![pypi version](https://badge.fury.io/py/evosax.svg)](https://badge.fury.io/py/evosax)\n[![code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![codecov](https://codecov.io/gh/roberttlange/evosax/branch/main/graph/badge.svg?token=5fusx35kwo)](https://codecov.io/gh/roberttlange/evosax)\n[![paper](http://img.shields.io/badge/paper-arxiv.2212.04180-b31b1b.svg)](http://arxiv.org/abs/2212.04180)\n<a href=\"https://github.com/roberttlange/evosax/blob/main/docs/logo.png?raw=true\"><img src=\"https://github.com/roberttlange/evosax/blob/main/docs/logo.png?raw=true\" width=\"170\" align=\"right\" /></a>\n\ntired of having to handle asynchronous processes for neuroevolution? do you want to leverage massive vectorization and high-throughput accelerators for evolution strategies (es)? `evosax` allows you to leverage jax, xla compilation and auto-vectorization/parallelization to scale es to your favorite accelerators. the api is based on the classical `ask`, `evaluate`, `tell` cycle of es. both `ask` and `tell` calls are compatible with `jit`, `vmap`/`pmap` and `lax.scan`. it includes a vast set of both classic (e.g. cma-es, differential evolution, etc.) and modern neuroevolution (e.g. openai-es, augmented rs, etc.) strategies. you can get started here \ud83d\udc49 [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/00_getting_started.ipynb)\n\n## basic `evosax` api usage \ud83c\udf72\n\n```python\nimport jax\nfrom evosax import cma_es\n\n# instantiate the search strategy\nrng = jax.random.prngkey(0)\nstrategy = cma_es(popsize=20, num_dims=2, elite_ratio=0.5)\nes_params = strategy.default_params\nstate = strategy.initialize(rng, es_params)\n\n# run ask-eval-tell loop - note: by default minimization!\nfor t in range(num_generations):\n    rng, rng_gen, rng_eval = jax.random.split(rng, 3)\n    x, state = strategy.ask(rng_gen, state, es_params)\n    fitness = ...  # your population evaluation fct \n    state = strategy.tell(x, fitness, state, es_params)\n\n# get best overall population member & its fitness\nstate.best_member, state.best_fitness\n```\n\n## implemented evolution strategies \ud83e\udd8e\n\n| strategy | reference | import | example |\n| --- | --- | ---  | --- |\n| openai-es | [salimans et al. (2017)](https://arxiv.org/pdf/1703.03864.pdf) | [`openes`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/open_es.py) | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/03_cnn_mnist.ipynb)\n| pgpe | [sehnke et al. (2010)](https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=a64d1ae8313a364b814998e9e245b40a?doi=10.1.1.180.7104&rep=rep1&type=pdf) | [`pgpe`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/pgpe.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/02_mlp_control.ipynb)\n| ars | [mania et al. (2018)](https://arxiv.org/pdf/1803.07055.pdf) | [`ars`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/ars.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/00_getting_started.ipynb)\n| esmc | [merchant et al. (2021)](https://proceedings.mlr.press/v139/merchant21a.html) | [`esmc`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/esmc.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| persistent es | [vicol et al. (2021)](http://proceedings.mlr.press/v139/vicol21a.html) | [`persistentes`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/persistent_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/04_lrate_pes.ipynb)\n| noise-reuse es | [li et al. (2023)](https://arxiv.org/pdf/2304.12180.pdf) | [`noisereusees`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/noise_reuse_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/04_lrate_pes.ipynb)\n| xnes | [wierstra et al. (2014)](https://www.jmlr.org/papers/volume15/wierstra14a/wierstra14a.pdf) | [`xnes`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/xnes.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| snes | [wierstra et al. (2014)](https://www.jmlr.org/papers/volume15/wierstra14a/wierstra14a.pdf) | [`snes`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/sxnes.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| cr-fm-nes | [nomura & ono (2022)](https://arxiv.org/abs/2201.11422) | [`cr_fm_nes`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/cr_fm_nes.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| guided es | [maheswaranathan et al. (2018)](https://arxiv.org/abs/1806.10230) | [`guidedes`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/guided_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| asebo | [choromanski et al. (2019)](https://arxiv.org/abs/1903.04268) | [`asebo`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/asebo.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| cma-es | [hansen & ostermeier (2001)](http://www.cmap.polytechnique.fr/~nikolaus.hansen/cmaartic.pdf) | [`cma_es`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/cma_es.py) | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| sep-cma-es | [ros & hansen (2008)](https://hal.inria.fr/inria-00287367/document) | [`sep_cma_es`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/sep_cma_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| bipop-cma-es | [hansen (2009)](https://hal.inria.fr/inria-00382093/document) | [`bipop_cma_es`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/bipop_cma_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/06_restart_es.ipynb)\n| ipop-cma-es | [auer & hansen (2005)](http://www.cmap.polytechnique.fr/~nikolaus.hansen/cec2005ipopcmaes.pdf) | [`ipop_cma_es`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/ipop_cma_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/06_restart_es.ipynb)\n| full-iamalgam | [bosman et al. (2013)](https://tinyurl.com/y9fcccx2) | [`full_iamalgam`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/full_iamalgam.py)  |[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| independent-iamalgam | [bosman et al. (2013)](https://tinyurl.com/y9fcccx2) | [`indep_iamalgam`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/indep_iamalgam.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| ma-es | [bayer & sendhoff (2017)](https://www.honda-ri.de/pubs/pdf/3376.pdf) | [`ma_es`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/ma_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| lm-ma-es | [loshchilov et al. (2017)](https://arxiv.org/pdf/1705.06693.pdf) | [`lm_ma_es`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/lm_ma_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| rmes | [li & zhang (2017)](https://ieeexplore.ieee.org/document/8080257) | [`rmes`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/rm_es.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| simple genetic | [such et al. (2017)](https://arxiv.org/abs/1712.06567) | [`simplega`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/simple_ga.py) | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| samr-ga | [clune et al. (2008)](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000187) | [`samr_ga`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/samr_ga.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| gesmr-ga | [kumar et al. (2022)](https://arxiv.org/abs/2204.04817) | [`gesmr_ga`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/gesmr_ga.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| mr15-ga | [rechenberg (1978)](https://link.springer.com/chapter/10.1007/978-3-642-81283-5_8) | [`mr15_ga`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/mr15_ga.py) | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| lga | [lange et al. (2023b)](https://arxiv.org/abs/2304.03995) | [`lga`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/lga.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| simple gaussian | [rechenberg (1978)](https://link.springer.com/chapter/10.1007/978-3-642-81283-5_8) | [`simplees`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/simple_es.py) | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| des | [lange et al. (2023a)](https://arxiv.org/abs/2211.11260) | [`des`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/des.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| les | [lange et al. (2023a)](https://arxiv.org/abs/2211.11260) | [`les`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/les.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| particle swarm optimization | [kennedy & eberhart (1995)](https://ieeexplore.ieee.org/document/488968) | [`pso`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/pso.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| differential evolution | [storn & price (1997)](https://www.metabolic-economics.de/pages/seminar_theoretische_biologie_2007/literatur/schaber/storn1997jglobopt11.pdf) | [`de`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/de.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| gld | [golovin et al. (2019)](https://arxiv.org/pdf/1911.06317.pdf) | [`gld`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/gld.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| simulated annealing | [rasdi rere et al. (2015)](https://www.sciencedirect.com/science/article/pii/s1877050915035759) | [`simanneal`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/sim_anneal.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n| population-based training | [jaderberg et al. (2017)](https://arxiv.org/abs/1711.09846) | [`pbt`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/pbt.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/05_quadratic_pbt.ipynb)\n| random search | [bergstra & bengio (2012)](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf) | [`randomsearch`](https://github.com/roberttlange/evosax/tree/main/evosax/strategies/random.py)  | [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb)\n\n\n\n\n## installation \u23f3\n\nthe latest `evosax` release can directly be installed from pypi:\n\n```\npip install evosax\n```\n\nif you want to get the most recent commit, please install directly from the repository:\n\n```\npip install git+https://github.com/roberttlange/evosax.git@main\n```\n\nin order to use jax on your accelerators, you can find more details in the [jax documentation](https://github.com/google/jax#installation).\n\n## examples \ud83d\udcd6\n* \ud83d\udcd3 [classic es tasks](https://github.com/roberttlange/evosax/blob/main/examples/01_classic_benchmark.ipynb): api introduction on rosenbrock function (cma-es, simple ga, etc.).\n* \ud83d\udcd3 [cartpole-control](https://github.com/roberttlange/evosax/blob/main/examples/02_mlp_control.ipynb): openes & pepg on the `cartpole-v1` gym task (mlp/lstm controller).\n* \ud83d\udcd3 [mnist-classifier](https://github.com/roberttlange/evosax/blob/main/examples/03_cnn_mnist.ipynb): openes on mnist with cnn network.\n* \ud83d\udcd3 [lratetune-pes](https://github.com/roberttlange/evosax/blob/main/examples/04_lrate_pes.ipynb): persistent/noise-reuse es on meta-learning problem as in [vicol et al. (2021)](http://proceedings.mlr.press/v139/vicol21a.html).\n* \ud83d\udcd3 [quadratic-pbt](https://github.com/roberttlange/evosax/blob/main/examples/05_quadratic_pbt.ipynb): pbt on toy quadratic problem as in [jaderberg et al. (2017)](https://arxiv.org/abs/1711.09846).\n* \ud83d\udcd3 [restart-wrappers](https://github.com/roberttlange/evosax/blob/main/examples/06_restart_es.ipynb): custom restart wrappers as e.g. used in (b)ipop-cma-es.\n* \ud83d\udcd3 [brax control](https://github.com/roberttlange/evosax/blob/main/examples/07_brax_control.ipynb): evolve tanh mlps on brax tasks using the `evojax` wrapper.\n* \ud83d\udcd3 [bbob visualizer](https://github.com/roberttlange/evosax/blob/main/examples/08_bbo_visualizer.ipynb): visualize evolution rollouts on 2d fitness landscapes.\n\n## key features \ud83d\udcb5\n\n- **strategy diversity**: `evosax` implements more than 30 classical and modern neuroevolution strategies. all of them follow the same simple `ask`/`eval` api and come with tailored tools such as the [clipup](https://arxiv.org/abs/2008.02387) optimizer, parameter reshaping into pytrees and fitness shaping (see below).\n\n- **vectorization/parallelization of `ask`/`tell` calls**: both `ask` and `tell` calls can leverage `jit`, `vmap`/`pmap`. this enables vectorized/parallel rollouts of different evolution strategies.\n\n```python\nfrom evosax.strategies.ars import ars, evoparams\n# e.g. vectorize over different initial perturbation stds\nstrategy = ars(popsize=100, num_dims=20)\nes_params = evoparams(sigma_init=jnp.array([0.1, 0.01, 0.001]), sigma_decay=0.999, ...)\n\n# specify how to map over es hyperparameters \nmap_dict = evoparams(sigma_init=0, sigma_decay=none, ...)\n\n# vmap-composed batch initialize, ask and tell functions \nbatch_init = jax.vmap(strategy.init, in_axes=(none, map_dict))\nbatch_ask = jax.vmap(strategy.ask, in_axes=(none, 0, map_dict))\nbatch_tell = jax.vmap(strategy.tell, in_axes=(0, 0, 0, map_dict))\n```\n\n- **scan through evolution rollouts**: you can also `lax.scan` through entire `init`, `ask`, `eval`, `tell` loops for fast compilation of es loops:\n\n```python\n@partial(jax.jit, static_argnums=(1,))\ndef run_es_loop(rng, num_steps):\n    \"\"\"run evolution ask-eval-tell loop.\"\"\"\n    es_params = strategy.default_params\n    state = strategy.initialize(rng, es_params)\n\n    def es_step(state_input, tmp):\n        \"\"\"helper es step to lax.scan through.\"\"\"\n        rng, state = state_input\n        rng, rng_iter = jax.random.split(rng)\n        x, state = strategy.ask(rng_iter, state, es_params)\n        fitness = ...\n        state = strategy.tell(y, fitness, state, es_params)\n        return [rng, state], fitness[jnp.argmin(fitness)]\n\n    _, scan_out = jax.lax.scan(es_step,\n                               [rng, state],\n                               [jnp.zeros(num_steps)])\n    return jnp.min(scan_out)\n```\n\n- **population parameter reshaping**: we provide a `paramaterreshaper` wrapper to reshape flat parameter vectors into pytrees. the wrapper is compatible with jax neural network libraries such as flax/haiku and makes it easier to afterwards evaluate network populations.\n\n```python\nfrom flax import linen as nn\nfrom evosax import parameterreshaper\n\nclass mlp(nn.module):\n    num_hidden_units: int\n    ...\n\n    @nn.compact\n    def __call__(self, obs):\n        ...\n        return ...\n\nnetwork = mlp(64)\nnet_params = network.init(rng, jnp.zeros(4,), rng)\n\n# initialize reshaper based on placeholder network shapes\nparam_reshaper = parameterreshaper(net_params)\n\n# get population candidates & reshape into stacked pytrees\nx = strategy.ask(...)\nx_shaped = param_reshaper.reshape(x)\n```\n\n\n- **flexible fitness shaping**: by default `evosax` assumes that the fitness objective is to be minimized. if you would like to maximize instead, perform rank centering, z-scoring or add weight regularization you can use the `fitnessshaper`: \n\n```python\nfrom evosax import fitnessshaper\n\n# instantiate jittable fitness shaper (e.g. for open es)\nfit_shaper = fitnessshaper(centered_rank=true,\n                           z_score=false,\n                           weight_decay=0.01,\n                           maximize=true)\n\n# shape the evaluated fitness scores\nfit_shaped = fit_shaper.apply(x, fitness) \n```\n<details>\n  <summary>additonal work-in-progress</summary>\n    **strategy restart wrappers**: *work-in-progress*. you can also choose from a set of different restart mechanisms, which will relaunch a strategy (with e.g. new population size) based on termination criteria. note: for all restart strategies which alter the population size the ask and tell methods will have to be re-compiled at the time of change. note that all strategies can also be executed without explicitly providing `es_params`. in this case the default parameters will be used.\n\n    ```python\n    from evosax import cma_es\n    from evosax.restarts import bipop_restarter\n\n    # define a termination criterion (kwargs - fitness, state, params)\n    def std_criterion(fitness, state, params):\n        \"\"\"restart strategy if fitness std across population is small.\"\"\"\n        return fitness.std() < 0.001\n\n    # instantiate base cma-es & wrap with bipop restarts\n    # pass strategy-specific kwargs separately (e.g. elite_ration or opt_name)\n    strategy = cma_es(num_dims, popsize, elite_ratio)\n    re_strategy = bipop_restarter(\n                    strategy,\n                    stop_criteria=[std_criterion],\n                    strategy_kwargs={\"elite_ratio\": elite_ratio}\n                )\n    state = re_strategy.initialize(rng)\n\n    # ask/tell loop - restarts are automatically handled \n    rng, rng_gen, rng_eval = jax.random.split(rng, 3)\n    x, state = re_strategy.ask(rng_gen, state)\n    fitness = ...  # your population evaluation fct \n    state = re_strategy.tell(x, fitness, state)\n    ```\n\n    - **batch strategy rollouts**: *work-in-progress*. we are currently also working on different ways of incorporating multiple subpopulations with different communication protocols.\n\n    ```python\n    from evosax.experimental.subpops import batchstrategy\n\n    # instantiates 5 cma-es subpops of 20 members\n    strategy = batchstrategy(\n            strategy_name=\"cma_es\",\n            num_dims=4096,\n            popsize=100,\n            num_subpops=5,\n            strategy_kwargs={\"elite_ratio\": 0.5},\n            communication=\"best_subpop\",\n        )\n\n    state = strategy.initialize(rng)\n    # ask for evaluation candidates of different subpopulation es\n    x, state = strategy.ask(rng_iter, state)\n    fitness = ...\n    state = strategy.tell(x, fitness, state)\n    ```\n\n    - **indirect encodings**: *work-in-progress*. es can struggle with high-dimensional search spaces (e.g. due to harder estimation of covariances). one potential way to alleviate this challenge, is to use indirect parameter encodings in a lower dimensional space. so far we provide jax-compatible encodings with random projections (gaussian/rademacher) and hypernetworks for mlps. they act as drop-in replacements for the `parameterreshaper`:\n\n    ```python\n    from evosax.experimental.decodings import randomdecoder, hyperdecoder\n\n    # for arbitrary network architectures / search spaces\n    num_encoding_dims = 6\n    param_reshaper = randomdecoder(num_encoding_dims, net_params)\n    x_shaped = param_reshaper.reshape(x)\n\n    # for mlp-based models we also support a hypernetwork en/decoding\n    reshaper = hyperdecoder(\n            net_params,\n            hypernet_config={\n                \"num_latent_units\": 3,  # latent units per module kernel/bias\n                \"num_hidden_units\": 2,  # hidden dimensionality of a_i^j embedding\n            },\n        )\n    x_shaped = param_reshaper.reshape(x)\n    ```\n</details>\n\n\n## resources & other great jax-es tools \ud83d\udcdd\n* \ud83d\udcfa [rob's mlc research jam talk](https://www.youtube.com/watch?v=wn6lq2bexla&t=51s): small motivation talk at the ml collective research jam.\n* \ud83d\udcdd [rob's 02/2021 blog](https://roberttlange.github.io/posts/2021/02/cma-es-jax/): tutorial on cma-es & leveraging jax's primitives.\n* \ud83d\udcbb [evojax](https://github.com/google/evojax): jax-es library by google brain with great rollout wrappers.\n* \ud83d\udcbb [qdax](https://github.com/adaptive-intelligent-robotics/qdax): quality-diversity algorithms in jax.\n\n## acknowledgements & citing `evosax` \u270f\ufe0f\n\nif you use `evosax` in your research, please cite the following [paper](https://arxiv.org/abs/2212.04180):\n\n```\n@article{evosax2022github,\n  author = {robert tjarko lange},\n  title = {evosax: jax-based evolution strategies},\n  journal={arxiv preprint arxiv:2212.04180},\n  year = {2022},\n}\n```\n\nwe acknowledge financial support by the [google trc](https://sites.research.google/trc/about/) and the deutsche\nforschungsgemeinschaft (dfg, german research foundation) under germany's excellence strategy - exc 2002/1 [\"science of intelligence\"](https://www.scienceofintelligence.de/) - project number 390523135.\n\n## development \ud83d\udc77\n\nyou can run the test suite via `python -m pytest -vv --all`. if you find a bug or are missing your favourite feature, feel free to create an issue and/or start [contributing](contributing.md) \ud83e\udd17.\n\n## disclaimer \u26a0\ufe0f\n\nthis repository contains an independent reimplementation of les and des based on the corresponding iclr 2023 publication [(lange et al., 2023)](https://arxiv.org/abs/2211.11260). it is unrelated to google or deepmind. the implementation has been tested to roughly reproduce the official results on a range of tasks.\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "evosax",
  "package_url": "https://pypi.org/project/evosax/",
  "project_url": "https://pypi.org/project/evosax/",
  "project_urls": {
    "Download": "https://github.com/RobertTLange/evosax/archive/v0.1.5.tar.gz",
    "Homepage": "https://github.com/RobertTLange/evosax"
  },
  "release_url": "https://pypi.org/project/evosax/0.1.5/",
  "requires_dist": [
    "jax",
    "chex",
    "flax",
    "numpy",
    "pyyaml",
    "matplotlib",
    "pickle5 ; python_version < \"3.8\""
  ],
  "requires_python": ">=3.7",
  "summary": "jax-based evolution strategies",
  "version": "0.1.5",
  "releases": [],
  "developers": [
    "robert_tjarko_lange",
    "robertlange0@gmail.com"
  ],
  "kwds": "evosax evojax badge evosax2022github evoparams",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_evosax",
  "homepage": "https://github.com/roberttlange/evosax",
  "release_count": 15,
  "dependency_ids": [
    "pypi_chex",
    "pypi_flax",
    "pypi_jax",
    "pypi_matplotlib",
    "pypi_numpy",
    "pypi_pickle5",
    "pypi_pyyaml"
  ]
}