{
  "classifiers": [
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# glum\n\n[![ci](https://github.com/quantco/glm_benchmarks/workflows/ci/badge.svg)](https://github.com/quantco/glum/actions)\n[![docs](https://readthedocs.org/projects/pip/badge/?version=latest&style=flat)](https://glum.readthedocs.io/)\n[![conda-forge](https://img.shields.io/conda/vn/conda-forge/glum?logocolor=white&logo=conda-forge)](https://anaconda.org/conda-forge/glum)\n[![pypiversion](https://img.shields.io/pypi/v/glum.svg?logo=pypi&logocolor=white)](https://pypi.org/project/glum)\n[![pythonversion](https://img.shields.io/pypi/pyversions/glum?logocolor=white&logo=python)](https://pypi.org/project/glum)\n\n\n[documentation](https://glum.readthedocs.io/en/latest/)\n\ngeneralized linear models (glm) are a core statistical tool that include many common methods like least-squares regression, poisson regression and logistic regression as special cases. at quantco, we have used glms in e-commerce pricing, insurance claims prediction and more. we have developed `glum`, a fast python-first glm library. the development was based on [a fork of scikit-learn](https://github.com/scikit-learn/scikit-learn/pull/9405), so it has a scikit-learn-like api. we are thankful for the starting point provided by christian lorentzen in that pr!\n\nthe goal of `glum` is to be at least as feature-complete as existing glm libraries like `glmnet` or `h2o`. it supports\n\n* built-in cross validation for optimal regularization, efficiently exploiting a \u201cregularization path\u201d\n* l1 regularization, which produces sparse and easily interpretable solutions\n* l2 regularization, including variable matrix-valued (tikhonov) penalties, which are useful in modeling correlated effects\n* elastic net regularization\n* normal, poisson, logistic, gamma, and tweedie distributions, plus varied and customizable link functions\n* box constraints, linear inequality constraints, sample weights, offsets\n\nthis repo also includes tools for benchmarking glm implementations in the `glum_benchmarks` module. for details on the benchmarking, [see here](src/glum_benchmarks/readme.md). although the performance of `glum` relative to `glmnet` and `h2o` depends on the specific problem, we find that when n >> k (there are more observations than predictors), it is consistently much faster for a wide range of problems.\n\n![performance benchmarks](docs/_static/headline_benchmark.png#gh-light-mode-only)\n![performance benchmarks](docs/_static/headline_benchmark_dark.png#gh-dark-mode-only)\n\nfor more information on `glum`, including tutorials and api reference, please see [the documentation](https://glum.readthedocs.io/en/latest/).\n\nwhy did we choose the name `glum`? we wanted a name that had the letters glm and wasn't easily confused with any existing implementation. and we thought glum sounded like a funny name (and not glum at all!). if you need a more professional sounding name, feel free to pronounce it as g-l-um. or maybe it stands for \"generalized linear... ummm... modeling?\"\n\n# a classic example predicting housing prices\n\n```python\n>>> from sklearn.datasets import fetch_openml\n>>> from glum import generalizedlinearregressor\n>>>\n>>> # this dataset contains house sale prices for king county, which includes\n>>> # seattle. it includes homes sold between may 2014 and may 2015.\n>>> house_data = fetch_openml(name=\"house_sales\", version=3, as_frame=true)\n>>>\n>>> # use only select features\n>>> x = house_data.data[\n...     [\n...         \"bedrooms\",\n...         \"bathrooms\",\n...         \"sqft_living\",\n...         \"floors\",\n...         \"waterfront\",\n...         \"view\",\n...         \"condition\",\n...         \"grade\",\n...         \"yr_built\",\n...         \"yr_renovated\",\n...     ]\n... ].copy()\n>>>\n>>>\n>>> # model whether a house had an above or below median price via a binomial\n>>> # distribution. we'll be doing l1-regularized logistic regression.\n>>> price = house_data.target\n>>> y = (price < price.median()).values.astype(int)\n>>> model = generalizedlinearregressor(\n...     family='binomial',\n...     l1_ratio=1.0,\n...     alpha=0.001\n... )\n>>>\n>>> _ = model.fit(x=x, y=y)\n>>>\n>>> # .report_diagnostics shows details about the steps taken by the iterative solver\n>>> diags = model.get_formatted_diagnostics(full_report=true)\n>>> diags[['objective_fct']]\n        objective_fct\nn_iter               \n0            0.693091\n1            0.489500\n2            0.449585\n3            0.443681\n4            0.443498\n5            0.443497\n\n```\n\n# installation\n\nplease install the package through conda-forge:\n```bash\nconda install glum -c conda-forge\n```\n",
  "docs_url": null,
  "keywords": "",
  "license": "bsd",
  "name": "glum",
  "package_url": "https://pypi.org/project/glum/",
  "project_url": "https://pypi.org/project/glum/",
  "project_urls": {
    "Homepage": "https://github.com/Quantco/glum"
  },
  "release_url": "https://pypi.org/project/glum/2.6.0/",
  "requires_dist": [
    "joblib",
    "numexpr",
    "numpy",
    "pandas",
    "scikit-learn >=0.23",
    "scipy",
    "tabmat <4.0.0,>=3.1.0"
  ],
  "requires_python": "",
  "summary": "high performance python glms with all the features!",
  "version": "2.6.0",
  "releases": [],
  "developers": [
    "noreply@quantco.com",
    "quantco"
  ],
  "kwds": "glum_benchmarks glum glms glm_benchmarks glm",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_glum",
  "homepage": "https://github.com/quantco/glum",
  "release_count": 17,
  "dependency_ids": [
    "pypi_joblib",
    "pypi_numexpr",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_scikit_learn",
    "pypi_scipy",
    "pypi_tabmat"
  ]
}