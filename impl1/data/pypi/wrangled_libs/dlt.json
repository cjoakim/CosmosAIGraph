{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "license :: osi approved :: apache software license",
    "operating system :: macos :: macos x",
    "operating system :: microsoft :: windows",
    "operating system :: posix :: linux",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.9",
    "topic :: software development :: libraries"
  ],
  "description": "<h1 align=\"center\">\n    <strong>data load tool (dlt) \u2014 the open-source python library for data loading</strong>\n</h1>\n<p align=\"center\">\nbe it a google colab notebook, aws lambda function, an airflow dag, your local laptop,<br/>or a gpt-4 assisted development playground\u2014<strong>dlt</strong> can be dropped in anywhere.\n</p>\n\n\n<h3 align=\"center\">\n\n\ud83d\ude80 join our thriving community of likeminded developers and build the future together!\n\n</h3>\n\n<div align=\"center\">\n  <a target=\"_blank\" href=\"https://join.slack.com/t/dlthub-community/shared_invite/zt-1n5193dbq-rcbmj6p~ckpsfk4hcf2dya\" style=\"background:none\">\n    <img src=\"https://img.shields.io/badge/slack-join-dlt.svg?labelcolor=191937&color=6f6ff7&logo=slack\" style=\"width: 260px;\"  />\n  </a>\n</div>\n<div align=\"center\">\n  <a target=\"_blank\" href=\"https://pypi.org/project/dlt/\" style=\"background:none\">\n    <img src=\"https://img.shields.io/pypi/v/dlt?labelcolor=191937&color=6f6ff7\">\n  </a>\n  <a target=\"_blank\" href=\"https://pypi.org/project/dlt/\" style=\"background:none\">\n    <img src=\"https://img.shields.io/pypi/pyversions/dlt?labelcolor=191937&color=6f6ff7\">\n  </a>\n</div>\n\n## installation\n\ndlt supports python 3.8+.\n\n```bash\npip install dlt\n```\n\n## quick start\n\nload chess game data from chess.com api and save it in duckdb:\n\n```python\nimport dlt\nfrom dlt.sources.helpers import requests\n# create a dlt pipeline that will load\n# chess player data to the duckdb destination\npipeline = dlt.pipeline(\n    pipeline_name='chess_pipeline',\n    destination='duckdb',\n    dataset_name='player_data'\n)\n# grab some player data from chess.com api\ndata = []\nfor player in ['magnuscarlsen', 'rpragchess']:\n    response = requests.get(f'https://api.chess.com/pub/player/{player}')\n    response.raise_for_status()\n    data.append(response.json())\n# extract, normalize, and load the data\npipeline.run(data, table_name='player')\n```\n\n\ntry it out in our **[colab demo](https://colab.research.google.com/drive/1nfsb1dpwbbhx9_t5vlalbtf13utwpmgx?usp=sharing)**\n\n## features\n\n- **automatic schema:** data structure inspection and schema creation for the destination.\n- **data normalization:** consistent and verified data before loading.\n- **seamless integration:** colab, aws lambda, airflow, and local environments.\n- **scalable:** adapts to growing data needs in production.\n- **easy maintenance:** clear data pipeline structure for updates.\n- **rapid exploration:** quickly explore and gain insights from new data sources.\n- **versatile usage:** suitable for ad-hoc exploration to advanced loading infrastructures.\n- **start in seconds with cli:** powerful cli for managing, deploying and inspecting local pipelines.\n- **incremental loading:** load only new or changed data and avoid loading old records again.\n- **open source:** free and apache 2.0 licensed.\n\n## ready to use sources and destinations\n\nexplore ready to use sources (e.g. google sheets) in the [verified sources docs](https://dlthub.com/docs/dlt-ecosystem/verified-sources) and supported destinations (e.g. duckdb) in the [destinations docs](https://dlthub.com/docs/dlt-ecosystem/destinations).\n\n## documentation\n\nfor detailed usage and configuration, please refer to the [official documentation](https://dlthub.com/docs).\n\n## examples\n\nyou can find examples for various use cases in the [examples](docs/examples) folder.\n\n## adding as dependency\n\n`dlt` follows the semantic versioning with the [`major.minor.patch`](https://peps.python.org/pep-0440/#semantic-versioning) pattern. currently, we are using **pre-release versioning** with the major version being 0.\n\n- `minor` version change means breaking changes\n- `patch` version change means new features that should be backward compatible\n- any suffix change, e.g., `post10` -> `post11`, is considered a patch\n\nwe suggest that you allow only `patch` level updates automatically:\n* using the [compatible release specifier](https://packaging.python.org/en/latest/specifications/version-specifiers/#compatible-release). for example **dlt~=0.3.10** allows only versions **>=0.3.10** and less than **<0.4**\n* poetry [caret requirements](https://python-poetry.org/docs/dependency-specification/). for example **^0.3.10** allows only versions **>=0.3.10** to **<0.4**\n## get involved\n\nthe dlt project is quickly growing, and we're excited to have you join our community! here's how you can get involved:\n\n- **connect with the community**: join other dlt users and contributors on our [slack](https://join.slack.com/t/dlthub-community/shared_invite/zt-1n5193dbq-rcbmj6p~ckpsfk4hcf2dya)\n- **report issues and suggest features**: please use the [github issues](https://github.com/dlt-hub/dlt/issues) to report bugs or suggest new features. before creating a new issue, make sure to search the tracker for possible duplicates and add a comment if you find one.\n- **track progress of our work and our plans**: please check out our [public github project](https://github.com/orgs/dlt-hub/projects/9)\n- **contribute verified sources**: contribute your custom sources to the [dlt-hub/verified-sources](https://github.com/dlt-hub/verified-sources) to help other folks in handling their data tasks.\n- **contribute code**: check out our [contributing guidelines](contributing.md) for information on how to make a pull request.\n- **improve documentation**: help us enhance the dlt documentation.\n\n## license\n\ndlt is released under the [apache 2.0 license](license.txt).\n",
  "docs_url": null,
  "keywords": "etl",
  "license": "apache-2.0",
  "name": "dlt",
  "package_url": "https://pypi.org/project/dlt/",
  "project_url": "https://pypi.org/project/dlt/",
  "project_urls": {
    "Homepage": "https://github.com/dlt-hub",
    "Repository": "https://github.com/dlt-hub/dlt"
  },
  "release_url": "https://pypi.org/project/dlt/0.4.1/",
  "requires_dist": [
    "requests (>=2.26.0)",
    "pendulum (>=2.1.2)",
    "simplejson (>=3.17.5)",
    "PyYAML (>=5.4.1)",
    "semver (>=2.13.0)",
    "hexbytes (>=0.2.2)",
    "tzdata (>=2022.1)",
    "tomlkit (>=0.11.3)",
    "pathvalidate (>=2.5.2)",
    "SQLAlchemy (>=1.4.0)",
    "typing-extensions (>=4.0.0)",
    "makefun (>=1.15.0)",
    "click (>=7.1)",
    "requirements-parser (>=0.5.0)",
    "setuptools (>=65.6.0)",
    "humanize (>=4.4.0)",
    "astunparse (>=1.6.3)",
    "gitpython (>=3.1.29)",
    "pytz (>=2022.6)",
    "giturlparse (>=0.10.0)",
    "orjson (>=3.6.7); platform_python_implementation != \"PyPy\"",
    "tenacity (>=8.0.2)",
    "jsonpath-ng (>=1.5.3)",
    "fsspec (>=2022.4.0)",
    "packaging (>=21.1)",
    "win-precise-time (>=1.4.2); os_name == \"nt\"",
    "psycopg2-binary (>=2.9.1); extra == \"postgres\" or extra == \"redshift\"",
    "psycopg2cffi (>=2.9.0); (platform_python_implementation == \"PyPy\") and (extra == \"postgres\" or extra == \"redshift\")",
    "grpcio (>=1.50.0); extra == \"gcp\" or extra == \"bigquery\"",
    "google-cloud-bigquery (>=2.26.0); extra == \"gcp\" or extra == \"bigquery\"",
    "pyarrow (>=12.0.0); extra == \"bigquery\" or extra == \"parquet\" or extra == \"motherduck\" or extra == \"athena\"",
    "duckdb (>=0.6.1,<0.10.0); extra == \"duckdb\" or extra == \"motherduck\"",
    "dbt-core (>=1.2.0); extra == \"dbt\"",
    "dbt-redshift (>=1.2.0); extra == \"dbt\"",
    "dbt-bigquery (>=1.2.0); extra == \"dbt\"",
    "dbt-duckdb (>=1.2.0); extra == \"dbt\"",
    "dbt-snowflake (>=1.2.0); extra == \"dbt\"",
    "dbt-athena-community (>=1.2.0); extra == \"dbt\"",
    "s3fs (>=2022.4.0); extra == \"filesystem\" or extra == \"s3\" or extra == \"athena\"",
    "gcsfs (>=2022.4.0); extra == \"gcp\" or extra == \"bigquery\" or extra == \"gs\"",
    "botocore (>=1.28); extra == \"filesystem\" or extra == \"s3\" or extra == \"athena\"",
    "snowflake-connector-python (>=3.5.0); extra == \"snowflake\"",
    "cron-descriptor (>=1.2.32); extra == \"cli\"",
    "pipdeptree (>=2.9.0,<2.10); extra == \"cli\"",
    "pyathena (>=2.9.6); extra == \"athena\"",
    "weaviate-client (>=3.22); extra == \"weaviate\"",
    "adlfs (>=2022.4.0); extra == \"az\"",
    "pyodbc (>=4.0.39,<5.0.0); extra == \"mssql\"",
    "qdrant-client[fastembed] (>=1.6.4,<2.0.0); extra == \"qdrant\""
  ],
  "requires_python": ">=3.8.1,<3.13",
  "summary": "dlt is an open-source python-first scalable data loading library that does not require any backend to run.",
  "version": "0.4.1",
  "releases": [],
  "developers": [
    "dlthub_inc",
    "marcin@dlthub.com",
    "marcin_rudolf",
    "services@dlthub.com"
  ],
  "kwds": "slack aws background colab pip",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_dlt",
  "homepage": "https://github.com/dlt-hub",
  "release_count": 68,
  "dependency_ids": [
    "pypi_adlfs",
    "pypi_astunparse",
    "pypi_botocore",
    "pypi_click",
    "pypi_cron_descriptor",
    "pypi_dbt_athena_community",
    "pypi_dbt_bigquery",
    "pypi_dbt_core",
    "pypi_dbt_duckdb",
    "pypi_dbt_redshift",
    "pypi_dbt_snowflake",
    "pypi_duckdb",
    "pypi_fsspec",
    "pypi_gcsfs",
    "pypi_gitpython",
    "pypi_giturlparse",
    "pypi_google_cloud_bigquery",
    "pypi_grpcio",
    "pypi_hexbytes",
    "pypi_humanize",
    "pypi_jsonpath_ng",
    "pypi_makefun",
    "pypi_orjson",
    "pypi_packaging",
    "pypi_pathvalidate",
    "pypi_pendulum",
    "pypi_pipdeptree",
    "pypi_psycopg2_binary",
    "pypi_psycopg2cffi",
    "pypi_pyarrow",
    "pypi_pyathena",
    "pypi_pyodbc",
    "pypi_pytz",
    "pypi_pyyaml",
    "pypi_qdrant_client",
    "pypi_requests",
    "pypi_requirements_parser",
    "pypi_s3fs",
    "pypi_semver",
    "pypi_setuptools",
    "pypi_simplejson",
    "pypi_snowflake_connector_python",
    "pypi_sqlalchemy",
    "pypi_tenacity",
    "pypi_tomlkit",
    "pypi_typing_extensions",
    "pypi_tzdata",
    "pypi_weaviate_client",
    "pypi_win_precise_time"
  ]
}