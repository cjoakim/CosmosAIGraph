{
  "classifiers": [
    "intended audience :: developers"
  ],
  "description": "spanner dialect for sqlalchemy\n==============================\n\nspanner dialect for sqlalchemy represents an interface api designed to\nmake it possible to control cloud spanner databases with sqlalchemy api.\nthe dialect is built on top of `the spanner db\napi <https://github.com/googleapis/python-spanner/tree/master/google/cloud/spanner_dbapi>`__,\nwhich is designed in accordance with\n`pep-249 <https://www.python.org/dev/peps/pep-0249/>`__.\n\nknown limitations are listed `here <#features-and-limitations>`__. all\nsupported features have been tested and verified to work with the test\nconfigurations. there may be configurations and/or data model variations\nthat have not yet been covered by the tests and that show unexpected\nbehavior. please report any problems that you might encounter by\n`creating a new\nissue <https://github.com/googleapis/python-spanner-sqlalchemy/issues/new>`__.\n\n-  `cloud spanner product\n   documentation <https://cloud.google.com/spanner/docs>`__\n-  `sqlalchemy product documentation <https://www.sqlalchemy.org/>`__\n\nquick start\n-----------\n\nin order to use this package, you first need to go through the following\nsteps:\n\n1. `select or create a cloud platform\n   project. <https://console.cloud.google.com/project>`__\n2. `enable billing for your\n   project. <https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project>`__\n3. `enable the google cloud spanner\n   api. <https://cloud.google.com/spanner>`__\n4. `setup\n   authentication. <https://googleapis.dev/python/google-api-core/latest/auth.html>`__\n\ninstallation\n------------\nstable released version of the package is available on pypi:\n\n::\n\n   pip install sqlalchemy-spanner\n\nto install an in-development version of the package, clone its\ngit-repository:\n\n::\n\n   git clone https://github.com/googleapis/python-spanner-sqlalchemy.git\n\nnext install the package from the package ``setup.py`` file:\n\n::\n\n   python setup.py install\n\nduring setup the dialect will be registered with entry points.\n\na minimal app\n-------------\n\ndatabase url\n~~~~~~~~~~~~\n\nin order to connect to a database one have to use its url on connection\ncreation step. sqlalchemy 1.3 and 1.4 versions have a bit of difference\non this step in a dialect prefix part:\n\n.. code:: python\n\n   # for sqlalchemy 1.3:\n   spanner:///projects/project-id/instances/instance-id/databases/database-id\n\n   # for sqlalchemy 1.4:\n   spanner+spanner:///projects/project-id/instances/instance-id/databases/database-id\n\nto pass your custom client object directly to be be used, create engine as following:\n\n.. code:: python\n\n    engine = create_engine(\n        \"spanner+spanner:///projects/project-id/instances/instance-id/databases/database-id\",\n        connect_args={'client': spanner.client(project=\"project-id\")}\n    )\n\ncreate a table\n~~~~~~~~~~~~~~\n\n.. code:: python\n\n   from sqlalchemy import (\n       column,\n       integer,\n       metadata,\n       string,\n       table,\n       create_engine,\n   )\n\n   engine = create_engine(\n       \"spanner:///projects/project-id/instances/instance-id/databases/database-id\"\n   )\n   metadata = metadata(bind=engine)\n\n   user = table(\n       \"users\",\n       metadata,\n       column(\"user_id\", integer, primary_key=true),\n       column(\"user_name\", string(16), nullable=false),\n   )\n\n   metadata.create_all(engine)\n\ninsert a row\n~~~~~~~~~~~~\n\n.. code:: python\n\n   import uuid\n\n   from sqlalchemy import (\n       metadata,\n       table,\n       create_engine,\n   )\n\n   engine = create_engine(\n       \"spanner:///projects/project-id/instances/instance-id/databases/database-id\"\n   )\n   user = table(\"users\", metadata(bind=engine), autoload=true)\n   user_id = uuid.uuid4().hex[:6].lower()\n\n   with engine.begin() as connection:\n       connection.execute(user.insert(), {\"user_id\": user_id, \"user_name\": \"full name\"})\n\nread\n~~~~\n\n.. code:: python\n\n   from sqlalchemy import metadata, table, create_engine, select\n\n   engine = create_engine(\n       \"spanner:///projects/project-id/instances/instance-id/databases/database-id\"\n   )\n   table = table(\"users\", metadata(bind=engine), autoload=true)\n\n   with engine.begin() as connection:\n       for row in connection.execute(select([\"*\"], from_obj=table)).fetchall():\n           print(row)\n\nmigration\n---------\n\nsqlalchemy uses `alembic <https://alembic.sqlalchemy.org/en/latest/#>`__\ntool to organize database migrations.\n\nspanner dialect doesn't provide a default migration environment, it's up\nto user to write it. one thing to be noted here - one should explicitly\nset ``alembic_version`` table not to use migration revision id as a\nprimary key:\n\n.. code:: python\n\n   with connectable.connect() as connection:\n       context.configure(\n           connection=connection,\n           target_metadata=target_metadata,\n           version_table_pk=false,  # don't use primary key in the versions table\n       )\n\nas spanner restricts changing a primary key value, not setting the ``version_table_pk`` flag\nto ``false`` can cause migration problems. if ``alembic_versions`` table was already created with a primary key, setting the flag to ``false`` will not work, because the flag is only applied on table creation.    \n\nnotice that ddl statements in spanner are not transactional. they will not be automatically reverted in case of a migration fail. also spanner encourage use of the `autocommit_block() <https://alembic.sqlalchemy.org/en/latest/api/runtime.html#alembic.runtime.migration.migrationcontext.autocommit_block>`__ for migrations in order to prevent ddls from aborting migration transactions with schema modifications.\n\n| **warning!**\n| a migration script can produce a lot of ddl statements. if each of the\n  statements is executed separately, performance issues can occur. to\n  avoid it, it's highly recommended to use the `alembic batch\n  context <https://alembic.sqlalchemy.org/en/latest/batch.html>`__\n  feature to pack ddl statements into groups of statements.\n\nfeatures and limitations\n------------------------\n\ninterleaved tables\n~~~~~~~~~~~~~~~~~~\n\n| cloud spanner dialect includes two dialect-specific arguments for\n  ``table`` constructor, which help to define interleave relations:\n  ``spanner_interleave_in`` - a parent table name\n  ``spanner_inverleave_on_delete_cascade`` - a flag specifying if\n  ``on delete cascade`` statement must be used for the interleave\n  relation\n| an example of interleave relations definition:\n\n.. code:: python\n\n   team = table(\n       \"team\",\n       metadata,\n       column(\"team_id\", integer, primary_key=true),\n       column(\"team_name\", string(16), nullable=false),\n   )\n   team.create(engine)\n\n   client = table(\n       \"client\",\n       metadata,\n       column(\"team_id\", integer, primary_key=true),\n       column(\"client_id\", integer, primary_key=true),\n       column(\"client_name\", string(16), nullable=false),\n       spanner_interleave_in=\"team\",\n       spanner_interleave_on_delete_cascade=true,\n   )\n   client.add_is_dependent_on(team)\n\n   client.create(engine)\n\n**note**: interleaved tables have a dependency between them, so the\nparent table must be created before the child table. when creating\ntables with this feature, make sure to call ``add_is_dependent_on()`` on\nthe child table to request sqlalchemy to create the parent table before\nthe child table.\n\nunique constraints\n~~~~~~~~~~~~~~~~~~\n\ncloud spanner doesn't support direct unique constraints creation. in\norder to achieve column values uniqueness unique indexes should be used.\n\ninstead of direct unique constraint creation:\n\n.. code:: python\n\n   table(\n       'table',\n       metadata,\n       column('col1', integer),\n       uniqueconstraint('col1', name='uix_1')\n   )\n\ncreate a unique index:\n\n.. code:: python\n\n   table(\n       'table',\n       metadata,\n       column('col1', integer),\n       index(\"uix_1\", \"col1\", unique=true),\n   )\n\nautocommit mode\n~~~~~~~~~~~~~~~\n\nspanner dialect supports both ``serializable`` and ``autocommit``\nisolation levels. ``serializable`` is the default one, where\ntransactions need to be committed manually. ``autocommit`` mode\ncorresponds to automatically committing of a query right in its\nexecution time.\n\nisolation level change example:\n\n.. code:: python\n\n   from sqlalchemy import create_engine\n\n   eng = create_engine(\"spanner:///projects/project-id/instances/instance-id/databases/database-id\")\n   autocommit_engine = eng.execution_options(isolation_level=\"autocommit\")\n\nautomatic transactions retry\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nin the default ``serializable`` mode transactions may fail with ``aborted`` exception. this is a transient kind of errors, which mostly happen to prevent data corruption by concurrent modifications. though the original transaction becomes non operational, a simple retry of the queries solves the issue.\n\nthis, however, may require to manually repeat a long list of operations, executed in the failed transaction. to simplify it, spanner connection api tracks all the operations, executed inside current transaction, and their result checksums. if the transaction failed with ``aborted`` exception, the connection api will automatically start a new transaction and will re-run all the tracked operations, checking if their results are the same as they were in the original transaction. in case data changed, and results differ, the transaction is dropped, as there is no way to automatically retry it.\n\nin ``autocommit`` mode automatic transactions retry mechanism is disabled, as every operation is committed just in time, and there is no way an ``aborted`` exception can happen.\n\nautoincremented ids\n~~~~~~~~~~~~~~~~~~~\n\ncloud spanner doesn't support autoincremented ids mechanism due to\nperformance reasons (`see for more\ndetails <https://cloud.google.com/spanner/docs/schema-design#primary-key-prevent-hotspots>`__).\nwe recommend that you use the python\n`uuid <https://docs.python.org/3/library/uuid.html>`__ module to\ngenerate primary key fields to avoid creating monotonically increasing\nkeys.\n\nthough it's not encouraged to do so, in case you *need* the feature, you\ncan simulate it manually as follows:\n\n.. code:: python\n\n   with engine.begin() as connection:\n       top_id = connection.execute(\n           select([user.c.user_id]).order_by(user.c.user_id.desc()).limit(1)\n       ).fetchone()\n       next_id = top_id[0] + 1 if top_id else 1\n\n       connection.execute(user.insert(), {\"user_id\": next_id})\n\nquery hints\n~~~~~~~~~~~\n\nspanner dialect supports `query\nhints <https://cloud.google.com/spanner/docs/query-syntax#table_hints>`__,\nwhich give the ability to set additional query execution parameters.\nusage example:\n\n.. code:: python\n\n   session = session(engine)\n\n   base = declarative_base()\n\n   class user(base):\n       \"\"\"data model.\"\"\"\n\n       __tablename__ = \"users\"\n       id = column(integer, primary_key=true)\n       name = column(string(50))\n\n\n   query = session.query(user)\n   query = query.with_hint(\n       selectable=user, text=\"@{force_index=index_name}\"\n   )\n   query = query.filter(user.name.in_([\"val1\", \"val2\"]))\n   query.statement.compile(session.bind)\n\nreadonly transactions\n~~~~~~~~~~~~~~~~~~~~~\n\nby default, transactions produced by a spanner connection are in\nreadwrite mode. however, some applications require an ability to grant\nreadonly access to users/methods; for these cases spanner dialect\nsupports the ``read_only`` execution option, which switches a connection\ninto readonly mode:\n\n.. code:: python\n\n   with engine.connect().execution_options(read_only=true) as connection:\n       connection.execute(select([\"*\"], from_obj=table)).fetchall()\n\nnote that execution options are applied lazily - on the ``execute()``\nmethod call, right before it.\n\nreadonly/readwrite mode of a connection can't be changed while a\ntransaction is in progress - first you must commit or rollback it.\n\nstale reads\n~~~~~~~~~~~\n\nto use the spanner `stale\nreads <https://cloud.google.com/spanner/docs/reads#perform-stale-read>`__\nwith sqlalchemy you can tweak the connection execution options with a\nwanted staleness value. for example:\n\n.. code:: python\n\n   # maximum staleness\n   with engine.connect().execution_options(\n       read_only=true,\n       staleness={\"max_staleness\": datetime.timedelta(seconds=5)}\n   ) as connection:\n       connection.execute(select([\"*\"], from_obj=table)).fetchall()\n\n.. code:: python\n\n   # exact staleness\n   with engine.connect().execution_options(\n       read_only=true,\n       staleness={\"exact_staleness\": datetime.timedelta(seconds=5)}\n   ) as connection:\n       connection.execute(select([\"*\"], from_obj=table)).fetchall()\n\n.. code:: python\n\n   # min read timestamp\n   with engine.connect().execution_options(\n       read_only=true,\n       staleness={\"min_read_timestamp\": datetime.datetime(2021, 11, 17, 12, 55, 30)}\n   ) as connection:\n       connection.execute(select([\"*\"], from_obj=table)).fetchall()\n\n.. code:: python\n\n   # read timestamp\n   with engine.connect().execution_options(\n       read_only=true,\n       staleness={\"read_timestamp\": datetime.datetime(2021, 11, 17, 12, 55, 30)}\n   ) as connection:\n       connection.execute(select([\"*\"], from_obj=table)).fetchall()\n\nnote that the set option will be dropped when the connection is returned\nback to the pool.\n\nrequest priority\n~~~~~~~~~~~~~~~~~~~~~\nin order to use request priorities feature in cloud spanner, sqlalchemy provides an ``execution_options`` parameter:\n\n.. code:: python\n\n   from google.cloud.spanner_v1 import requestoptions\n\n   with engine.connect().execution_options(\n       request_priority=requestoptions.priority.priority_medium\n   ) as connection:\n       connection.execute(select([\"*\"], from_obj=table)).fetchall()\n\nddl and transactions\n~~~~~~~~~~~~~~~~~~~~\n\nddl statements are executed outside the regular transactions mechanism,\nwhich means ddl statements will not be rolled back on normal transaction\nrollback.\n\ndropping a table\n~~~~~~~~~~~~~~~~\n\ncloud spanner, by default, doesn't drop tables, which have secondary\nindexes and/or foreign key constraints. in spanner dialect for\nsqlalchemy, however, this restriction is omitted - if a table you are\ntrying to delete has indexes/foreign keys, they will be dropped\nautomatically right before dropping the table.\n\ndata types\n~~~~~~~~~~\n\ndata types table mapping sqlalchemy types to cloud spanner types:\n\n========== =========\nsqlalchemy spanner\n========== =========\ninteger    int64\nbigint     int64\ndecimal    numeric\nfloat      float64\ntext       string\narray      array\nbinary     bytes\nvarchar    string\nchar       string\nboolean    bool\ndatetime   timestamp\nnumeric    numeric\n========== =========\n\nother limitations\n~~~~~~~~~~~~~~~~~\n\n-  with recursive statement is not supported.\n-  named schemas are not supported.\n-  temporary tables are not supported.\n-  numeric type dimensions (scale and precision) are constant. see the\n   `docs <https://cloud.google.com/spanner/docs/data-types#numeric_types>`__.\n\nbest practices\n--------------\n\nwhen a sqlalchemy function is called, a new connection to a database is\nestablished and a spanner session object is fetched. in case of\nconnectionless execution these fetches are done for every ``execute()``\ncall, which can cause a significant latency. to avoid initiating a\nspanner session on every ``execute()`` call it's recommended to write\ncode in connection-bounded fashion. once a ``connection()`` object is\nexplicitly initiated, it fetches a spanner session object and uses it\nfor all the following calls made on this ``connection()`` object.\n\nnon-optimal connectionless use:\n\n.. code:: python\n\n   # execute() is called on object, which is not a connection() object\n   insert(user).values(user_id=1, user_name=\"full name\").execute()\n\noptimal connection-bounded use:\n\n.. code:: python\n\n   with engine.begin() as connection:\n       # execute() is called on a connection() object\n       connection.execute(user.insert(), {\"user_id\": 1, \"user_name\": \"full name\"})\n\nconnectionless way of use is also deprecated since sqlalchemy 2.0 and\nsoon will be removed (see in `sqlalchemy\ndocs <https://docs.sqlalchemy.org/en/14/core/connections.html#connectionless-execution-implicit-execution>`__).\n\nrunning tests\n-------------\n\nspanner dialect includes a compliance, migration and unit test suite. to\nrun the tests the ``nox`` package commands can be used:\n\n::\n\n   # run the whole suite\n   $ nox\n\n   # run a particular test session\n   $ nox -s migration_test\n\nrunning tests on spanner emulator\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nthe dialect test suite can be runned on `spanner\nemulator <https://cloud.google.com/spanner/docs/emulator>`__. several\ntests, relating to ``null`` values of data types, are skipped when\nexecuted on emulator.\n\ncontributing\n------------\n\ncontributions to this library are welcome and encouraged. please report\nissues, file feature requests, and send pull requests. see\n`contributing <https://github.com/googleapis/python-spanner-sqlalchemy/blob/main/contributing.md>`__\nfor more information on how to get started.\n\n**note that this project is not officially supported by google as part\nof the cloud spanner product.**\n\nplease note that this project is released with a contributor code of\nconduct. by participating in this project you agree to abide by its\nterms. see the `code of\nconduct <https://github.com/googleapis/python-spanner-sqlalchemy/blob/main/code-of-conduct.md>`__\nfor more information.\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "sqlalchemy-spanner",
  "package_url": "https://pypi.org/project/sqlalchemy-spanner/",
  "project_url": "https://pypi.org/project/sqlalchemy-spanner/",
  "project_urls": {
    "Homepage": "https://github.com/cloudspannerecosystem/python-spanner-sqlalchemy"
  },
  "release_url": "https://pypi.org/project/sqlalchemy-spanner/1.6.2/",
  "requires_dist": [
    "sqlalchemy (>=1.1.13)",
    "google-cloud-spanner (>=3.12.0)",
    "alembic",
    "opentelemetry-api (>=1.1.0) ; extra == 'tracing'",
    "opentelemetry-sdk (>=1.1.0) ; extra == 'tracing'",
    "opentelemetry-instrumentation (>=0.20b0) ; extra == 'tracing'"
  ],
  "requires_python": "",
  "summary": "sqlalchemy dialect integrated into cloud spanner database",
  "version": "1.6.2",
  "releases": [],
  "developers": [
    "cloud-spanner-developers@googlegroups.com",
    "google_llc"
  ],
  "kwds": "spanner_dbapi sqlalchemy spanner_inverleave_on_delete_cascade spanner_v1 spanner_interleave_in",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_sqlalchemy_spanner",
  "homepage": "https://github.com/cloudspannerecosystem/python-spanner-sqlalchemy",
  "release_count": 12,
  "dependency_ids": [
    "pypi_alembic",
    "pypi_google_cloud_spanner",
    "pypi_opentelemetry_api",
    "pypi_opentelemetry_instrumentation",
    "pypi_opentelemetry_sdk",
    "pypi_sqlalchemy"
  ]
}