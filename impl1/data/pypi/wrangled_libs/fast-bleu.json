{
  "classifiers": [
    "development status :: 3 - alpha",
    "license :: osi approved :: mit license",
    "operating system :: macos",
    "operating system :: posix :: linux",
    "programming language :: python :: 3"
  ],
  "description": "# fast-bleu package\n\nthis is a fast multithreaded c++ implementation of nltk bleu with python wrapper; computing bleu and selfbleu scores for a fixed reference set.\nit can return (self)bleu for different (max) n-grams simultaneously and efficiently (e.g. bleu-2, bleu-3, etc.).\n\n## installation\n\nthe installation requires `c++11`.\nthe `requirements.txt` file is the required python packages to run the `test_cases.py` file.\n\n### linux and wsl\n\ninstalling [pypi latest stable release](https://pypi.org/project/fast-bleu/):\n\n``` bash\npip install --user fast-bleu\n```\n\n### macos\n\nas the macos uses clang and it does not support openmp, one workaround is to first install gcc with `brew install gcc`. after that, gcc specific binaries will be added (for example, it will be maybe `gcc-10`\nand `g++-10`).\n\nto change the default compiler, an option to the installation command is added, so you can install the [pypi latest stable release](https://pypi.org/project/fast-bleu/) with the following command:\n\n``` bash\npip install --user fast-bleu --install-option=\"--cc=<path-to-gcc>\" --install-option=\"--cxx=<path-to-g++>\"\n```\n\n### windows\n\nnot tested yet!\n\n## sample usage\n\nhere is an example to compute bleu-2, bleu-3, selfbleu-2 and selfbleu-3:\n\n``` python\n>>> from fast_bleu import bleu, selfbleu\n>>> ref1 = ['it', 'is', 'a', 'guide', 'to', 'action', 'that',\n...          'ensures', 'that', 'the', 'military', 'will', 'forever',\n...          'heed', 'party', 'commands']\n>>> ref2 = ['it', 'is', 'the', 'guiding', 'principle', 'which',\n...          'guarantees', 'the', 'military', 'forces', 'always',\n...          'being', 'under', 'the', 'command', 'of', 'the', 'party']\n>>> ref3 = ['it', 'is', 'the', 'practical', 'guide', 'for', 'the',\n...          'army', 'always', 'to', 'heed', 'the', 'directions',\n...          'of', 'the', 'party']\n\n>>> hyp1 = ['it', 'is', 'a', 'guide', 'to', 'action', 'which',\n...         'ensures', 'that', 'the', 'military', 'always',\n...         'obeys', 'the', 'commands', 'of', 'the', 'party']\n>>> hyp2 = ['he', 'read', 'the', 'book', 'because', 'he', 'was',\n...         'interested', 'in', 'world', 'history']\n\n>>> list_of_references = [ref1, ref2, ref3]\n>>> hypotheses = [hyp1, hyp2]\n>>> weights = {'bigram': (1/2., 1/2.), 'trigram': (1/3., 1/3., 1/3.)}\n\n>>> bleu = bleu(list_of_references, weights)\n>>> bleu.get_score(hypotheses)\n{'bigram': [0.7453559924999299, 0.0191380231127159], 'trigram': [0.6240726901657495, 0.013720869575946234]}\n```\n\nwhich means:\n\n* bleu-2 for hyp1 is 0.7453559924999299\n* bleu-2 for hyp2 is 0.0191380231127159\n\n* bleu-3 for hyp1 is 0.6240726901657495\n* bleu-3 for hyp2 is 0.013720869575946234\n\n```python\n>>> self_bleu = selfbleu(list_of_references, weights)\n>>> self_bleu.get_score()\n{'bigram': [0.25819888974716115, 0.3615507630310936, 0.37080992435478316],\n        'trigram': [0.07808966062765045, 0.20140620205719248, 0.21415334758254043]}\n```\n\nwhich means:\n\n* selfbleu-2 for ref1 is 0.25819888974716115\n* selfbleu-2 for ref2 is 0.3615507630310936\n* selfbleu-2 for ref3 is 0.37080992435478316\n\n* selfbleu-3 for ref1 is 0.07808966062765045\n* selfbleu-3 for ref2 is 0.20140620205719248\n* selfbleu-3 for ref3 is 0.21415334758254043\n\n**caution** each token of reference set is converted to string format during computation.\n\nfor further details, refer to the documentation provided in the source codes.\n\n## citation\n\nplease cite our paper if it helps with your research.\n\n* acl anthology: <https://www.aclweb.org/anthology/w19-2311>\n* arxiv link: <https://arxiv.org/abs/1904.03971>\n\n```latex\n@inproceedings{alihosseini-etal-2019-jointly,\n    title = {jointly measuring diversity and quality in text generation models},\n    author = {alihosseini, danial  and\n      montahaei, ehsan  and\n      soleymani baghshah, mahdieh},\n    booktitle = {proceedings of the workshop on methods for optimizing and evaluating neural language generation},\n    month = {jun},\n    year = {2019},\n    address = {minneapolis, minnesota},\n    publisher = {association for computational linguistics},\n    url = {https://www.aclweb.org/anthology/w19-2311},\n    doi = {10.18653/v1/w19-2311},\n    pages = {90--98},\n}\n\n```",
  "docs_url": null,
  "keywords": "",
  "license": "osi approved :: mit license",
  "name": "fast-bleu",
  "package_url": "https://pypi.org/project/fast-bleu/",
  "project_url": "https://pypi.org/project/fast-bleu/",
  "project_urls": {
    "Homepage": "https://github.com/Danial-Alh/fast-bleu"
  },
  "release_url": "https://pypi.org/project/fast-bleu/0.0.90/",
  "requires_dist": [],
  "requires_python": ">=3.3",
  "summary": "a fast multithreaded c++ implementation of nltk bleu with python wrapper.",
  "version": "0.0.90",
  "releases": [],
  "developers": [
    "danial.alihosseini@gmail.com",
    "danial_alihosseini"
  ],
  "kwds": "fast_bleu self_bleu bleu binaries pypi",
  "license_kwds": "osi approved :: mit license",
  "libtype": "pypi",
  "id": "pypi_fast_bleu",
  "homepage": "https://github.com/danial-alh/fast-bleu",
  "release_count": 14,
  "dependency_ids": []
}