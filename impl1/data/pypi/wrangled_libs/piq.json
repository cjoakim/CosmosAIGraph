{
  "classifiers": [
    "license :: osi approved :: apache software license",
    "operating system :: os independent",
    "programming language :: python :: 3"
  ],
  "description": "\n.. image:: https://raw.githubusercontent.com/photosynthesis-team/piq/master/docs/source/_static/piq_logo_main.png\n    :target: https://github.com/photosynthesis-team/piq\n\n..\n\n  pytorch image quality (piq) is not endorsed by facebook, inc.;\n\n  pytorch, the pytorch logo and any related marks are trademarks of facebook, inc.\n\n|pypy| |conda| |flake8| |tests| |codecov| |quality_gate|\n\n.. |pypy| image:: https://badge.fury.io/py/piq.svg\n   :target: https://pypi.org/project/piq/\n   :alt: pypi version\n.. |conda| image:: https://anaconda.org/photosynthesis-team/piq/badges/version.svg\n   :target: https://anaconda.org/photosynthesis-team/piq\n   :alt: conda version\n.. |flake8| image:: https://github.com/photosynthesis-team/piq/workflows/flake-8%20style%20check/badge.svg\n   :alt: ci flake-8 style check\n.. |tests| image:: https://github.com/photosynthesis-team/piq/workflows/testing/badge.svg\n   :alt: ci testing\n.. |codecov| image:: https://codecov.io/gh/photosynthesis-team/piq/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/photosynthesis-team/piq\n   :alt: codecov\n.. |quality_gate| image:: https://sonarcloud.io/api/project_badges/measure?project=photosynthesis-team_photosynthesis.metrics&metric=alert_status\n   :target: https://sonarcloud.io/dashboard?id=photosynthesis-team_photosynthesis.metrics\n   :alt: quality gate status\n\n\n\n.. intro-section-start\n\n`pytorch image quality (piq) <https://github.com/photosynthesis-team/piq>`_ is a collection of measures and metrics for\nimage quality assessment. piq helps you to concentrate on your experiments without the boilerplate code.\nthe library contains a set of measures and metrics that is continually getting extended.\nfor measures/metrics that can be used as loss functions, corresponding pytorch modules are implemented.\n\nwe provide:\n\n* unified interface, which is easy to use and extend.\n* written on pure pytorch with bare minima of additional dependencies.\n* extensive user input validation. your code will not crash in the middle of the training.\n* fast (gpu computations available) and reliable.\n* most metrics can be backpropagated for model optimization.\n* supports python 3.7-3.10.\n\npiq was initially named `photosynthesis.metrics <https://pypi.org/project/photosynthesis-metrics/0.4.0/>`_.\n\n.. intro-section-end\n\n.. installation-section-start\n\ninstallation\n------------\n`pytorch image quality (piq) <https://github.com/photosynthesis-team/piq>`_ can be installed using ``pip``, ``conda`` or ``git``.\n\n\nif you use ``pip``, you can install it with:\n\n.. code-block:: sh\n\n    $ pip install piq\n\n\nif you use ``conda``, you can install it with:\n\n.. code-block:: sh\n\n    $ conda install piq -c photosynthesis-team -c conda-forge -c pytorch\n\n\nif you want to use the latest features straight from the master, clone `piq repo <https://github.com/photosynthesis-team/piq>`_:\n\n.. code-block:: sh\n\n   git clone https://github.com/photosynthesis-team/piq.git\n   cd piq\n   python setup.py install\n\n.. installation-section-end\n\n.. documentation-section-start\n\ndocumentation\n-------------\n\nthe full documentation is available at https://piq.readthedocs.io.\n\n.. documentation-section-end\n\n.. usage-examples-start\n\nusage examples\n---------------\n\nimage-based metrics\n^^^^^^^^^^^^^^^^^^^\nthe group of metrics (such as psnr, ssim, brisque) takes an image or a pair of images as input to compute a distance between them.\nwe have a functional interface, which returns a metric value, and a class interface, which allows to use any metric\nas a loss function.\n\n.. code-block:: python\n\n   import torch\n   from piq import ssim, ssimloss\n\n   x = torch.rand(4, 3, 256, 256, requires_grad=true)\n   y = torch.rand(4, 3, 256, 256)\n\n   ssim_index: torch.tensor = ssim(x, y, data_range=1.)\n\n   loss = ssimloss(data_range=1.)\n   output: torch.tensor = loss(x, y)\n   output.backward()\n\nfor a full list of examples, see `image metrics <https://github.com/photosynthesis-team/piq/blob/master/examples/image_metrics.py>`_ examples.\n\ndistribution-based metrics\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nthe group of metrics (such as is, fid, kid) takes a list of image features to compute the distance between distributions.\nimage features can be extracted by some feature extractor network separately or by using the ``compute_feats`` method of a\nclass.\n\nnote:\n    ``compute_feats`` consumes a data loader of a predefined format.\n\n.. code-block:: python\n\n   import torch\n   from torch.utils.data import dataloader\n   from piq import fid\n\n   first_dl, second_dl = dataloader(), dataloader()\n   fid_metric = fid()\n   first_feats = fid_metric.compute_feats(first_dl)\n   second_feats = fid_metric.compute_feats(second_dl)\n   fid: torch.tensor = fid_metric(first_feats, second_feats)\n\n\nif you already have image features, use the class interface for score computation:\n\n.. code-block:: python\n\n    import torch\n    from piq import fid\n\n    x_feats = torch.rand(10000, 1024)\n    y_feats = torch.rand(10000, 1024)\n    msid_metric = msid()\n    msid: torch.tensor = msid_metric(x_feats, y_feats)\n\n\nfor a full list of examples, see `feature metrics <https://github.com/photosynthesis-team/piq/blob/master/examples/feature_metrics.py>`_ examples.\n\n.. usage-examples-end\n\n.. list-of-metrics-start\n\nlist of metrics\n---------------\n\nfull-reference (fr)\n^^^^^^^^^^^^^^^^^^^\n\n===========  ======  ==========\nacronym      year    metric\n===========  ======  ==========\npsnr         \\-      `peak signal-to-noise ratio <https://en.wikipedia.org/wiki/peak_signal-to-noise_ratio>`_\nssim         2003    `structural similarity <https://en.wikipedia.org/wiki/structural_similarity>`_\nms-ssim      2004    `multi-scale structural similarity <https://ieeexplore.ieee.org/abstract/document/1292216>`_\niw-ssim      2011    `information content weighted structural similarity index <https://ece.uwaterloo.ca/~z70wang/publications/iwssim.pdf>`_\nvifp         2004    `visual information fidelity <https://ieeexplore.ieee.org/document/1576816>`_\nfsim         2011    `feature similarity index measure <https://ieeexplore.ieee.org/document/5705575>`_\nsr-sim       2012    `spectral residual based similarity <https://sse.tongji.edu.cn/linzhang/icip12/icip-sr-sim.pdf>`_\ngmsd         2013    `gradient magnitude similarity deviation <https://arxiv.org/abs/1308.3052>`_\nms-gmsd      2017    `multi-scale gradient magnitude similarity deviation <https://ieeexplore.ieee.org/document/7952357>`_\nvsi          2014    `visual saliency-induced index <https://ieeexplore.ieee.org/document/6873260>`_\ndss          2015    `dct subband similarity index <https://ieeexplore.ieee.org/document/7351172>`_\n\\-           2016    `content score <https://arxiv.org/abs/1508.06576>`_\n\\-           2016    `style score <https://arxiv.org/abs/1508.06576>`_\nhaarpsi      2016    `haar perceptual similarity index <https://arxiv.org/abs/1607.06140>`_\nmdsi         2016    `mean deviation similarity index <https://arxiv.org/abs/1608.07433>`_\nlpips        2018    `learned perceptual image patch similarity <https://arxiv.org/abs/1801.03924>`_\npieapp       2018    `perceptual image-error assessment through pairwise preference <https://arxiv.org/abs/1806.02067>`_\ndists        2020    `deep image structure and texture similarity <https://arxiv.org/abs/2004.07728>`_\n===========  ======  ==========\n\nno-reference (nr)\n^^^^^^^^^^^^^^^^^\n\n===========  ======  ==========\nacronym      year    metric\n===========  ======  ==========\ntv           1937    `total variation <https://en.wikipedia.org/wiki/total_variation>`_\nbrisque      2012    `blind/referenceless image spatial quality evaluator <https://ieeexplore.ieee.org/document/6272356>`_\nclip-iqa     2022    `clip-iqa <https://arxiv.org/pdf/2207.12396.pdf>`_\n===========  ======  ==========\n\ndistribution-based (db)\n^^^^^^^^^^^^^^^^^^^^^^^\n\n===========  ======  ==========\nacronym      year    metric\n===========  ======  ==========\nis           2016    `inception score <https://arxiv.org/abs/1606.03498>`_\nfid          2017    `frechet inception distance <https://arxiv.org/abs/1706.08500>`_\ngs           2018    `geometry score <https://arxiv.org/abs/1802.02664>`_\nkid          2018    `kernel inception distance <https://arxiv.org/abs/1801.01401>`_\nmsid         2019    `multi-scale intrinsic distance <https://arxiv.org/abs/1905.11141>`_\npr           2019    `improved precision and recall <https://arxiv.org/abs/1904.06991>`_\n===========  ======  ==========\n\n.. list-of-metrics-end\n\n.. benchmark-section-start\n\nbenchmark\n---------\n\nas part of our library we provide `code to benchmark <tests/results_benchmark.py>`_ all metrics on a set of common mean opinon scores databases.\ncurrently we support several full-reference (`tid2013`_,  `kadid10k`_ and `pipal`_) and no-reference (`koniq10k`_ and `live-itw`_) datasets.\nyou need to download them separately and provide path to images as an argument to the script.\n\nhere is an example how to evaluate ssim and ms-ssim metrics on tid2013 dataset:\n\n.. code-block:: bash\n\n   python3 tests/results_benchmark.py --dataset tid2013 --metrics ssim ms-ssim --path ~/datasets/tid2013 --batch_size 16\n\nbelow we provide a comparison between `spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/spearman%27s_rank_correlation_coefficient>`_ (srcc) values obtained with piq and reported in surveys.\ncloser srcc values indicate the higher degree of agreement between results of computations on given datasets.\nwe do not report `kendall rank correlation coefficient <https://en.wikipedia.org/wiki/kendall_rank_correlation_coefficient>`_ (krcc)\nas it is highly correlated with srcc and provides limited additional information.\nwe do not report `pearson linear correlation coefficient <https://en.wikipedia.org/wiki/pearson_correlation_coefficient>`_ (plcc)\nas it's highly dependent on fitting method and is biased towards simple examples.\n\nfor metrics that can take greyscale or colour images, ``c`` means chromatic version.\n\nfull-reference (fr) datasets\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n===========  ===========================  ===========================  ===========================\n     \\                  tid2013                    kadid10k                       pipal\n-----------  ---------------------------  ---------------------------  ---------------------------\n  source            piq / reference            piq / reference                piq / reference\n===========  ===========================  ===========================  ===========================\npsnr         0.69 / 0.69 `tid2013`_       0.68 / -                     0.41 / 0.41 `pipal`_\nssim         0.72 / 0.64 `tid2013`_       0.72 / 0.72 `kadid10k`_      0.50 / 0.53 `pipal`_\nms-ssim      0.80 / 0.79 `tid2013`_       0.80 / 0.80 `kadid10k`_      0.55 / 0.46 `pipal`_\niw-ssim      0.78 / 0.78 `eval2019`_      0.85 / 0.85 `kadid10k`_      0.60 / -\nvifp         0.61 / 0.61 `tid2013`_       0.65 / 0.65 `kadid10k`_      0.50 / -\nfsim         0.80 / 0.80 `tid2013`_       0.83 / 0.83 `kadid10k`_      0.59 / 0.60 `pipal`_\nfsimc        0.85 / 0.85 `tid2013`_       0.85 / 0.85 `kadid10k`_      0.59 / -\nsr-sim       0.81 / 0.81 `eval2019`_      0.84 / 0.84 `kadid10k`_      0.57 / -\nsr-simc      0.87 / -                     0.87 / -                     0.57 / -\ngmsd         0.80 / 0.80 `ms-gmsd`_       0.85 / 0.85 `kadid10k`_      0.58 / -\nvsi          0.90 / 0.90 `eval2019`_      0.88 / 0.86 `kadid10k`_      0.54 / -\ndss          0.79 / 0.79 `eval2019`_      0.86 / 0.86 `kadid10k`_      0.63 / -\ncontent      0.71 / -                     0.72 / -                     0.45 / -\nstyle        0.54 / -                     0.65 / -                     0.34 / -\nhaarpsi      0.87 / 0.87 `haarpsi`_       0.89 / 0.89 `kadid10k`_      0.59 / -\nmdsi         0.89 / 0.89 `mdsi`_          0.89 / 0.89 `kadid10k`_      0.59 / -\nms-gmsd      0.81 / 0.81 `ms-gmsd`_       0.85 / -                     0.59 / -\nms-gmsdc     0.89 / 0.89 `ms-gmsd`_       0.87 / -                     0.59 / -\nlpips-vgg    0.67 / 0.67 `dists`_         0.72 / -                     0.57 / 0.58 `pipal`_\npieapp       0.84 / 0.88 `dists`_         0.87 / -                     0.70 / 0.71 `pipal`_\ndists        0.81 / 0.83 `dists`_         0.88 / -                     0.62 / 0.66 `pipal`_\nbrisque      0.37 / 0.84 `eval2019`_      0.33 / 0.53 `kadid10k`_      0.21 / -\nclip-iqa     0.50 / -                     0.48 / -                     0.26 / -\nis           0.26 / -                     0.25 / -                     0.09 / -\nfid          0.67 / -                     0.66 / -                     0.18 / -\nkid          0.42 / -                     0.66 / -                     0.12 / -\nmsid         0.21 / -                     0.32 / -                     0.01 / -\ngs           0.37 / -                     0.37 / -                     0.02 / -\n===========  ===========================  ===========================  ===========================\n\nno-reference (nr) datasets\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n===========  ===========================  ===========================\n     \\                  koniq10k                    live-itw\n-----------  ---------------------------  ---------------------------\n  source            piq / reference            piq / reference\n===========  ===========================  ===========================\nbrisque      0.22 / -                     0.31 / -\nclip-iqa     0.68 / 0.68 `clip-iqa off`_  0.64 / 0.64 `clip-iqa off`_\n===========  ===========================  ===========================\n\n.. _tid2013: http://www.ponomarenko.info/tid2013.htm\n.. _kadid10k: http://database.mmsp-kn.de/kadid-10k-database.html\n.. _eval2019: https://ieeexplore.ieee.org/abstract/document/8847307/\n.. _`mdsi`: https://arxiv.org/abs/1608.07433\n.. _ms-gmsd: https://ieeexplore.ieee.org/document/7952357\n.. _dists: https://arxiv.org/abs/2004.07728\n.. _haarpsi: https://arxiv.org/abs/1607.06140\n.. _pipal: https://arxiv.org/pdf/2011.15002.pdf\n.. _iw-ssim: https://ieeexplore.ieee.org/document/7442122\n.. _koniq10k: http://database.mmsp-kn.de/koniq-10k-database.html\n.. _live-itw: https://live.ece.utexas.edu/research/challengedb/index.html\n.. _clip-iqa off: https://github.com/iceclear/clip-iqa\n\nunlike fr and nr iqms, designed to compute an image-wise distance, the db metrics compare distributions of *sets* of images.\nto address these problems, we adopt a different way of computing the db iqms proposed in `<https://arxiv.org/abs/2203.07809>`_.\ninstead of extracting features from the whole images, we crop them into overlapping tiles of size ``96 \u00d7 96`` with ``stride = 32``.\nthis pre-processing allows us to treat each pair of images as a pair of distributions of tiles, enabling further comparison.\nthe other stages of computing the db iqms are kept intact.\n\n.. benchmark-section-end\n\n.. assertions-section-start\n\nassertions\n----------\nin piq we use assertions to raise meaningful messages when some component doesn't receive an input of the expected type.\nthis makes prototyping and debugging easier, but it might hurt the performance.\nto disable all checks, use the python ``-o`` flag: ``python -o your_script.py``\n\n.. assertions-section-end\n\n\nroadmap\n-------\n\nsee the `open issues <https://github.com/photosynthesis-team/piq/issues>`_ for a list of proposed\nfeatures and known issues.\n\ncontributing\n------------\n\nif you would like to help develop this library, you'll find more information in our `contribution guide <contributing.rst>`_.\n\n.. citation-section-start\n\ncitation\n--------\nif you use piq in your project, please, cite it as follows.\n\n.. code-block:: tex\n\n   @misc{kastryulin2022piq,\n     title = {pytorch image quality: metrics for image quality assessment},\n     url = {https://arxiv.org/abs/2208.14818},\n     author = {kastryulin, sergey and zakirov, jamil and prokopenko, denis and dylov, dmitry v.},\n     doi = {10.48550/arxiv.2208.14818},\n     publisher = {arxiv},\n     year = {2022}\n   }\n\n.. code-block:: tex\n\n   @misc{piq,\n     title={{pytorch image quality}: metrics and measure for image quality assessment},\n     url={https://github.com/photosynthesis-team/piq},\n     note={open-source software available at https://github.com/photosynthesis-team/piq},\n     author={sergey kastryulin and dzhamil zakirov and denis prokopenko},\n     year={2019}\n   }\n\n.. citation-section-end\n\n.. contacts-section-start\n\ncontacts\n--------\n\n**sergey kastryulin** - `@snk4tr <https://github.com/snk4tr>`_ - ``snk4tr@gmail.com``\n\n**jamil zakirov** - `@zakajd <https://github.com/zakajd>`_ - ``djamilzak@gmail.com``\n\n**denis prokopenko** - `@denproc <https://github.com/denproc>`_ - ``d.prokopenko@outlook.com``\n\n.. contacts-section-end\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "piq",
  "package_url": "https://pypi.org/project/piq/",
  "project_url": "https://pypi.org/project/piq/",
  "project_urls": {
    "Homepage": "https://github.com/photosynthesis-team/piq"
  },
  "release_url": "https://pypi.org/project/piq/0.8.0/",
  "requires_dist": [
    "torchvision (>=0.10.0)"
  ],
  "requires_python": "",
  "summary": "measures and metrics for image2image tasks. pytorch.",
  "version": "0.8.0",
  "releases": [],
  "developers": [
    "sergey_kastryulin",
    "snk4tr@gmail.com"
  ],
  "kwds": "piq_logo_main team_photosynthesis png piq quality_gate",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_piq",
  "homepage": "https://github.com/photosynthesis-team/piq",
  "release_count": 10,
  "dependency_ids": [
    "pypi_torchvision"
  ]
}