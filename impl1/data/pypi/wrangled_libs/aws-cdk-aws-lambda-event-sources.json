{
  "classifiers": [
    "development status :: 7 - inactive",
    "framework :: aws cdk",
    "framework :: aws cdk :: 1",
    "intended audience :: developers",
    "license :: osi approved",
    "operating system :: os independent",
    "programming language :: javascript",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "typing :: typed"
  ],
  "description": "# aws lambda event sources\n\n<!--begin stability banner-->---\n\n\n![end-of-support](https://img.shields.io/badge/end--of--support-critical.svg?style=for-the-badge)\n\n> aws cdk v1 has reached end-of-support on 2023-06-01.\n> this package is no longer being updated, and users should migrate to aws cdk v2.\n>\n> for more information on how to migrate, see the [*migrating to aws cdk v2* guide](https://docs.aws.amazon.com/cdk/v2/guide/migrating-v2.html).\n\n---\n<!--end stability banner-->\n\nan event source mapping is an aws lambda resource that reads from an event source and invokes a lambda function.\nyou can use event source mappings to process items from a stream or queue in services that don't invoke lambda\nfunctions directly. lambda provides event source mappings for the following services. read more about lambda\nevent sources [here](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html).\n\nthis module includes classes that allow using various aws services as event\nsources for aws lambda via the high-level `lambda.addeventsource(source)` api.\n\nnote: in most cases, it is also possible to use the resource apis to invoke an\naws lambda function. this library provides a uniform api for all lambda event\nsources regardless of the underlying mechanism they use.\n\nthe following code sets up a lambda function with an sqs queue event source -\n\n```python\nfrom aws_cdk.aws_lambda_event_sources import sqseventsource\n\n# fn: lambda.function\n\nqueue = sqs.queue(self, \"myqueue\")\nevent_source = sqseventsource(queue)\nfn.add_event_source(event_source)\n\nevent_source_id = event_source.event_source_mapping_id\n```\n\nthe `eventsourceid` property contains the event source id. this will be a\n[token](https://docs.aws.amazon.com/cdk/latest/guide/tokens.html) that will resolve to the final value at the time of\ndeployment.\n\n## sqs\n\namazon simple queue service (amazon sqs) allows you to build asynchronous\nworkflows. for more information about amazon sqs, see amazon simple queue\nservice. you can configure aws lambda to poll for these messages as they arrive\nand then pass the event to a lambda function invocation. to view a sample event,\nsee [amazon sqs event](https://docs.aws.amazon.com/lambda/latest/dg/eventsources.html#eventsources-sqs).\n\nto set up amazon simple queue service as an event source for aws lambda, you\nfirst create or update an amazon sqs queue and select custom values for the\nqueue parameters. the following parameters will impact amazon sqs's polling\nbehavior:\n\n* **visibilitytimeout**: may impact the period between retries.\n* **receivemessagewaittime**: will determine [long\n  poll](https://docs.aws.amazon.com/awssimplequeueservice/latest/sqsdeveloperguide/sqs-long-polling.html)\n  duration. the default value is 20 seconds.\n* **batchsize**: determines how many records are buffered before invoking your lambda function.\n* **maxbatchingwindow**: the maximum amount of time to gather records before invoking the lambda. this increases the likelihood of a full batch at the cost of delayed processing.\n* **enabled**: if the sqs event source mapping should be enabled. the default is true.\n\n```python\nfrom aws_cdk.aws_lambda_event_sources import sqseventsource\n# fn: lambda.function\n\n\nqueue = sqs.queue(self, \"myqueue\",\n    visibility_timeout=duration.seconds(30),  # default,\n    receive_message_wait_time=duration.seconds(20)\n)\n\nfn.add_event_source(sqseventsource(queue,\n    batch_size=10,  # default\n    max_batching_window=duration.minutes(5),\n    report_batch_item_failures=true\n))\n```\n\n## s3\n\nyou can write lambda functions to process s3 bucket events, such as the\nobject-created or object-deleted events. for example, when a user uploads a\nphoto to a bucket, you might want amazon s3 to invoke your lambda function so\nthat it reads the image and creates a thumbnail for the photo.\n\nyou can use the bucket notification configuration feature in amazon s3 to\nconfigure the event source mapping, identifying the bucket events that you want\namazon s3 to publish and which lambda function to invoke.\n\n```python\nimport aws_cdk.aws_s3 as s3\nfrom aws_cdk.aws_lambda_event_sources import s3eventsource\n# fn: lambda.function\n\n\nbucket = s3.bucket(self, \"mybucket\")\n\nfn.add_event_source(s3eventsource(bucket,\n    events=[s3.eventtype.object_created, s3.eventtype.object_removed],\n    filters=[s3.notificationkeyfilter(prefix=\"subdir/\")]\n))\n```\n\n## sns\n\nyou can write lambda functions to process amazon simple notification service\nnotifications. when a message is published to an amazon sns topic, the service\ncan invoke your lambda function by passing the message payload as a parameter.\nyour lambda function code can then process the event, for example publish the\nmessage to other amazon sns topics, or send the message to other aws services.\n\nthis also enables you to trigger a lambda function in response to amazon\ncloudwatch alarms and other aws services that use amazon sns.\n\nfor an example event, see [appendix: message and json\nformats](https://docs.aws.amazon.com/sns/latest/dg/json-formats.html) and\n[amazon sns sample\nevent](https://docs.aws.amazon.com/lambda/latest/dg/eventsources.html#eventsources-sns).\nfor an example use case, see [using aws lambda with amazon sns from different\naccounts](https://docs.aws.amazon.com/lambda/latest/dg/with-sns.html).\n\n```python\nimport aws_cdk.aws_sns as sns\nfrom aws_cdk.aws_lambda_event_sources import snseventsource\n\n# topic: sns.topic\n\n# fn: lambda.function\n\ndead_letter_queue = sqs.queue(self, \"deadletterqueue\")\nfn.add_event_source(snseventsource(topic,\n    filter_policy={},\n    dead_letter_queue=dead_letter_queue\n))\n```\n\nwhen a user calls the sns publish api on a topic that your lambda function is\nsubscribed to, amazon sns will call lambda to invoke your function\nasynchronously. lambda will then return a delivery status. if there was an error\ncalling lambda, amazon sns will retry invoking the lambda function up to three\ntimes. after three tries, if amazon sns still could not successfully invoke the\nlambda function, then amazon sns will send a delivery status failure message to\ncloudwatch.\n\n## dynamodb streams\n\nyou can write lambda functions to process change events from a dynamodb table. an event is emitted to a dynamodb stream (if configured) whenever a write (put, delete, update)\noperation is performed against the table. see [using aws lambda with amazon dynamodb](https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html) for more information about configuring lambda function event sources with dynamodb.\n\nto process events with a lambda function, first create or update a dynamodb table and enable a `stream` specification. then, create a `dynamoeventsource`\nand add it to your lambda function. the following parameters will impact amazon dynamodb's polling behavior:\n\n* **batchsize**: determines how many records are buffered before invoking your lambda function - could impact your function's memory usage (if too high) and ability to keep up with incoming data velocity (if too low).\n* **bisectbatchonerror**: if a batch encounters an error, this will cause the batch to be split in two and have each new smaller batch retried, allowing the records in error to be isolated.\n* **reportbatchitemfailures**: allow functions to return partially successful responses for a batch of records.\n* **maxbatchingwindow**: the maximum amount of time to gather records before invoking the lambda. this increases the likelihood of a full batch at the cost of delayed processing.\n* **maxrecordage**: the maximum age of a record that will be sent to the function for processing. records that exceed the max age will be treated as failures.\n* **onfailure**: in the event a record fails after all retries or if the record age has exceeded the configured value, the record will be sent to sqs queue or sns topic that is specified here\n* **parallelizationfactor**: the number of batches to concurrently process on each shard.\n* **retryattempts**: the maximum number of times a record should be retried in the event of failure.\n* **startingposition**: will determine where to being consumption, either at the most recent ('latest') record or the oldest record ('trim_horizon'). 'trim_horizon' will ensure you process all available data, while 'latest' will ignore all records that arrived prior to attaching the event source.\n* **tumblingwindow**: the duration in seconds of a processing window when using streams.\n* **enabled**: if the dynamodb streams event source mapping should be enabled. the default is true.\n\n```python\nimport aws_cdk.aws_dynamodb as dynamodb\nfrom aws_cdk.aws_lambda_event_sources import dynamoeventsource, sqsdlq\n\n# table: dynamodb.table\n\n# fn: lambda.function\n\n\ndead_letter_queue = sqs.queue(self, \"deadletterqueue\")\nfn.add_event_source(dynamoeventsource(table,\n    starting_position=lambda_.startingposition.trim_horizon,\n    batch_size=5,\n    bisect_batch_on_error=true,\n    on_failure=sqsdlq(dead_letter_queue),\n    retry_attempts=10\n))\n```\n\n## kinesis\n\nyou can write lambda functions to process streaming data in amazon kinesis streams. for more information about amazon kinesis, see [amazon kinesis\nservice](https://aws.amazon.com/kinesis/data-streams/). to learn more about configuring lambda function event sources with kinesis and view a sample event,\nsee [amazon kinesis event](https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html).\n\nto set up amazon kinesis as an event source for aws lambda, you\nfirst create or update an amazon kinesis stream and select custom values for the\nevent source parameters. the following parameters will impact amazon kinesis's polling\nbehavior:\n\n* **batchsize**: determines how many records are buffered before invoking your lambda function - could impact your function's memory usage (if too high) and ability to keep up with incoming data velocity (if too low).\n* **bisectbatchonerror**: if a batch encounters an error, this will cause the batch to be split in two and have each new smaller batch retried, allowing the records in error to be isolated.\n* **reportbatchitemfailures**: allow functions to return partially successful responses for a batch of records.\n* **maxbatchingwindow**: the maximum amount of time to gather records before invoking the lambda. this increases the likelihood of a full batch at the cost of possibly delaying processing.\n* **maxrecordage**: the maximum age of a record that will be sent to the function for processing. records that exceed the max age will be treated as failures.\n* **onfailure**: in the event a record fails and consumes all retries, the record will be sent to sqs queue or sns topic that is specified here\n* **parallelizationfactor**: the number of batches to concurrently process on each shard.\n* **retryattempts**: the maximum number of times a record should be retried in the event of failure.\n* **startingposition**: will determine where to being consumption, either at the most recent ('latest') record or the oldest record ('trim_horizon'). 'trim_horizon' will ensure you process all available data, while 'latest' will ignore all records that arrived prior to attaching the event source.\n* **tumblingwindow**: the duration in seconds of a processing window when using streams.\n* **enabled**: if the dynamodb streams event source mapping should be enabled. the default is true.\n\n```python\nimport aws_cdk.aws_kinesis as kinesis\nfrom aws_cdk.aws_lambda_event_sources import kinesiseventsource\n\n# my_function: lambda.function\n\n\nstream = kinesis.stream(self, \"mystream\")\nmy_function.add_event_source(kinesiseventsource(stream,\n    batch_size=100,  # default\n    starting_position=lambda_.startingposition.trim_horizon\n))\n```\n\n## kafka\n\nyou can write lambda functions to process data either from [amazon msk](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html) or a [self managed kafka](https://docs.aws.amazon.com/lambda/latest/dg/kafka-smaa.html) cluster.\n\nthe following code sets up amazon msk as an event source for a lambda function. credentials will need to be configured to access the\nmsk cluster, as described in [username/password authentication](https://docs.aws.amazon.com/msk/latest/developerguide/msk-password.html).\n\n```python\nfrom aws_cdk.aws_secretsmanager import secret\nfrom aws_cdk.aws_lambda_event_sources import managedkafkaeventsource\n\n# my_function: lambda.function\n\n\n# your msk cluster arn\ncluster_arn = \"arn:aws:kafka:us-east-1:0123456789019:cluster/salescluster/abcd1234-abcd-cafe-abab-9876543210ab-4\"\n\n# the kafka topic you want to subscribe to\ntopic = \"some-cool-topic\"\n\n# the secret that allows access to your msk cluster\n# you still have to make sure that it is associated with your cluster as described in the documentation\nsecret = secret(self, \"secret\", secret_name=\"amazonmsk_kafkasecret\")\nmy_function.add_event_source(managedkafkaeventsource(\n    cluster_arn=cluster_arn,\n    topic=topic,\n    secret=secret,\n    batch_size=100,  # default\n    starting_position=lambda_.startingposition.trim_horizon\n))\n```\n\nthe following code sets up a self managed kafka cluster as an event source. username and password based authentication\nwill need to be set up as described in [managing access and permissions](https://docs.aws.amazon.com/lambda/latest/dg/smaa-permissions.html#smaa-permissions-add-secret).\n\n```python\nfrom aws_cdk.aws_secretsmanager import secret\nfrom aws_cdk.aws_lambda_event_sources import selfmanagedkafkaeventsource\n\n# the secret that allows access to your self hosted kafka cluster\n# secret: secret\n\n# my_function: lambda.function\n\n\n# the list of kafka brokers\nbootstrap_servers = [\"kafka-broker:9092\"]\n\n# the kafka topic you want to subscribe to\ntopic = \"some-cool-topic\"\nmy_function.add_event_source(selfmanagedkafkaeventsource(\n    bootstrap_servers=bootstrap_servers,\n    topic=topic,\n    secret=secret,\n    batch_size=100,  # default\n    starting_position=lambda_.startingposition.trim_horizon\n))\n```\n\nif your self managed kafka cluster is only reachable via vpc also configure `vpc` `vpcsubnets` and `securitygroup`.\n\n## roadmap\n\neventually, this module will support all the event sources described under\n[supported event\nsources](https://docs.aws.amazon.com/lambda/latest/dg/invoking-lambda-function.html)\nin the aws lambda developer guide.\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache-2.0",
  "name": "aws-cdk.aws-lambda-event-sources",
  "package_url": "https://pypi.org/project/aws-cdk.aws-lambda-event-sources/",
  "project_url": "https://pypi.org/project/aws-cdk.aws-lambda-event-sources/",
  "project_urls": {
    "Homepage": "https://github.com/aws/aws-cdk",
    "Source": "https://github.com/aws/aws-cdk.git"
  },
  "release_url": "https://pypi.org/project/aws-cdk.aws-lambda-event-sources/1.204.0/",
  "requires_dist": [
    "aws-cdk.aws-apigateway (==1.204.0)",
    "aws-cdk.aws-dynamodb (==1.204.0)",
    "aws-cdk.aws-ec2 (==1.204.0)",
    "aws-cdk.aws-events (==1.204.0)",
    "aws-cdk.aws-iam (==1.204.0)",
    "aws-cdk.aws-kinesis (==1.204.0)",
    "aws-cdk.aws-lambda (==1.204.0)",
    "aws-cdk.aws-s3-notifications (==1.204.0)",
    "aws-cdk.aws-s3 (==1.204.0)",
    "aws-cdk.aws-secretsmanager (==1.204.0)",
    "aws-cdk.aws-sns-subscriptions (==1.204.0)",
    "aws-cdk.aws-sns (==1.204.0)",
    "aws-cdk.aws-sqs (==1.204.0)",
    "aws-cdk.core (==1.204.0)",
    "constructs (<4.0.0,>=3.3.69)",
    "jsii (<2.0.0,>=1.84.0)",
    "publication (>=0.0.3)",
    "typeguard (~=2.13.3)"
  ],
  "requires_python": "~=3.7",
  "summary": "event sources for aws lambda",
  "version": "1.204.0",
  "releases": [],
  "developers": [
    "amazon_web_services"
  ],
  "kwds": "aws_lambda_event_sources aws_cdk awssimplequeueservice lambda aws_kinesis",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_aws_cdk.aws_lambda_event_sources",
  "homepage": "https://github.com/aws/aws-cdk",
  "release_count": 258,
  "dependency_ids": [
    "pypi_aws_cdk.aws_apigateway",
    "pypi_aws_cdk.aws_dynamodb",
    "pypi_aws_cdk.aws_ec2",
    "pypi_aws_cdk.aws_events",
    "pypi_aws_cdk.aws_iam",
    "pypi_aws_cdk.aws_kinesis",
    "pypi_aws_cdk.aws_lambda",
    "pypi_aws_cdk.aws_s3",
    "pypi_aws_cdk.aws_s3_notifications",
    "pypi_aws_cdk.aws_secretsmanager",
    "pypi_aws_cdk.aws_sns",
    "pypi_aws_cdk.aws_sns_subscriptions",
    "pypi_aws_cdk.aws_sqs",
    "pypi_aws_cdk.core",
    "pypi_constructs",
    "pypi_jsii",
    "pypi_publication",
    "pypi_typeguard"
  ]
}