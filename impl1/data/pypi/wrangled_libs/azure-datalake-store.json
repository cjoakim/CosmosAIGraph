{
  "classifiers": [
    "development status :: 4 - beta",
    "license :: osi approved :: mit license",
    "programming language :: python",
    "programming language :: python :: 2",
    "programming language :: python :: 2.7",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.3",
    "programming language :: python :: 3.4",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "microsoft azure data lake store filesystem library for python\r\n=============================================================\r\n\r\n.. image:: https://travis-ci.org/azure/azure-data-lake-store-python.svg?branch=dev\r\n    :target: https://travis-ci.org/azure/azure-data-lake-store-python\r\n.. image:: https://coveralls.io/repos/github/azure/azure-data-lake-store-python/badge.svg?branch=master\r\n    :target: https://coveralls.io/github/azure/azure-data-lake-store-python?branch=master\r\n\r\nthis project is the python filesystem library for azure data lake store.\r\n\r\ninstallation\r\n============\r\n\r\nto install from source instead of pip (for local testing and development):\r\n\r\n.. code-block:: bash\r\n\r\n    > pip install -r dev_requirements.txt\r\n    > python setup.py develop\r\n\r\nusage: sample code\r\n==================\r\n\r\nto play with the code, here is a starting point:\r\n\r\n.. code-block:: python\r\n\r\n    from azure.datalake.store import core, lib, multithread\r\n    token = lib.auth(tenant_id, username, password)\r\n    adl = core.azuredlfilesystem(token, store_name=store_name)\r\n\r\n    # typical operations\r\n    adl.ls('')\r\n    adl.ls('tmp/', detail=true)\r\n    adl.ls('tmp/', detail=true, invalidate_cache=true)\r\n    adl.cat('littlefile')\r\n    adl.head('gdelt20150827.csv')\r\n\r\n    # file-like object\r\n    with adl.open('gdelt20150827.csv', blocksize=2**20) as f:\r\n        print(f.readline())\r\n        print(f.readline())\r\n        print(f.readline())\r\n        # could have passed f to any function requiring a file object:\r\n        # pandas.read_csv(f)\r\n\r\n    with adl.open('anewfile', 'wb') as f:\r\n        # data is written on flush/close, or when buffer is bigger than\r\n        # blocksize\r\n        f.write(b'important data')\r\n\r\n    adl.du('anewfile')\r\n\r\n    # recursively download the whole directory tree with 5 threads and\r\n    # 16mb chunks\r\n    multithread.adldownloader(adl, \"\", 'my_temp_dir', 5, 2**24)\r\n\r\nprogress can be tracked using a callback function in the form `track(current, total)`\r\nwhen passed, this will keep track of transferred bytes and be called on each complete chunk.\r\n\r\nhere's an example using the azure cli progress controller as the `progress_callback`:\r\n\r\n.. code-block:: python\r\n\r\n    from cli.core.application import application\r\n\r\n    def _update_progress(current, total):\r\n        hook = application.get_progress_controller(det=true)\r\n        hook.add(message='alive', value=current, total_val=total)\r\n        if total == current:\r\n            hook.end()\r\n\r\n    ...\r\n    adluploader(client, destination_path, source_path, thread_count, overwrite=overwrite,\r\n            chunksize=chunk_size,\r\n            buffersize=buffer_size,\r\n            blocksize=block_size,\r\n            progress_callback=_update_progress)\r\n\r\nthis will output a progress bar to the stdout:\r\n\r\n.. code-block:: bash\r\n\r\n    alive[#########################                                       ]  40.0881%\r\n    \r\n    finished[#############################################################]  100.0000%\r\n\r\nusage: command line sample\r\n==========================\r\n\r\nto interact with the api at a higher-level, you can use the provided\r\ncommand-line interface in \"samples/cli.py\". you will need to set\r\nthe appropriate environment variables \r\n\r\n* :code:`azure_username`\r\n\r\n* :code:`azure_password`\r\n\r\n* :code:`azure_data_lake_store_name`\r\n\r\n* :code:`azure_subscription_id`\r\n\r\n* :code:`azure_resource_group_name`\r\n\r\n* :code:`azure_service_principal`\r\n\r\n* :code:`azure_service_principal_secret`\r\n\r\nto connect to the azure data lake store. optionally, you may need to define :code:`azure_tenant_id` or :code:`azure_data_lake_store_url_suffix`.\r\n\r\nbelow is a simple sample, with more details beyond.\r\n\r\n\r\n.. code-block:: bash\r\n\r\n    python samples\\cli.py ls -l\r\n\r\nexecute the program without arguments to access documentation.\r\n\r\nto start the cli in interactive mode, run \"python samples/cli.py\"\r\nand then type \"help\" to see all available commands (similiar to unix utilities):\r\n\r\n.. code-block:: bash\r\n\r\n    > python samples/cli.py\r\n    azure> help\r\n\r\n    documented commands (type help <topic>):\r\n    ========================================\r\n    cat    chmod  close  du      get   help  ls     mv   quit  rmdir  touch\r\n    chgrp  chown  df     exists  head  info  mkdir  put  rm    tail\r\n\r\n    azure>\r\n\r\n\r\nwhile still in interactive mode, you can run \"ls -l\" to list the entries in the\r\nhome directory (\"help ls\" will show the command's usage details). if you're not\r\nfamiliar with the unix/linux \"ls\" command, the columns represent 1) permissions,\r\n2) file owner, 3) file group, 4) file size, 5-7) file's modification time, and\r\n8) file name.\r\n\r\n.. code-block:: bash\r\n\r\n    > python samples/cli.py\r\n    azure> ls -l\r\n    drwxrwx--- 0123abcd 0123abcd         0 aug 02 12:44 azure1\r\n    -rwxrwx--- 0123abcd 0123abcd   1048576 jul 25 18:33 abc.csv\r\n    -r-xr-xr-x 0123abcd 0123abcd        36 jul 22 18:32 xyz.csv\r\n    drwxrwx--- 0123abcd 0123abcd         0 aug 03 13:46 tmp\r\n    azure> ls -l --human-readable\r\n    drwxrwx--- 0123abcd 0123abcd   0b aug 02 12:44 azure1\r\n    -rwxrwx--- 0123abcd 0123abcd   1m jul 25 18:33 abc.csv\r\n    -r-xr-xr-x 0123abcd 0123abcd  36b jul 22 18:32 xyz.csv\r\n    drwxrwx--- 0123abcd 0123abcd   0b aug 03 13:46 tmp\r\n    azure>\r\n\r\n\r\nto download a remote file, run \"get remote-file [local-file]\". the second\r\nargument, \"local-file\", is optional. if not provided, the local file will be\r\nnamed after the remote file minus the directory path.\r\n\r\n.. code-block:: bash\r\n\r\n    > python samples/cli.py\r\n    azure> ls -l\r\n    drwxrwx--- 0123abcd 0123abcd         0 aug 02 12:44 azure1\r\n    -rwxrwx--- 0123abcd 0123abcd   1048576 jul 25 18:33 abc.csv\r\n    -r-xr-xr-x 0123abcd 0123abcd        36 jul 22 18:32 xyz.csv\r\n    drwxrwx--- 0123abcd 0123abcd         0 aug 03 13:46 tmp\r\n    azure> get xyz.csv\r\n    2016-08-04 18:57:48,603 - adlfs - debug - creating empty file xyz.csv\r\n    2016-08-04 18:57:48,604 - adlfs - debug - fetch: xyz.csv, 0-36\r\n    2016-08-04 18:57:49,726 - adlfs - debug - downloaded to xyz.csv, byte offset 0\r\n    2016-08-04 18:57:49,734 - adlfs - debug - file downloaded (xyz.csv -> xyz.csv)\r\n    azure>\r\n\r\n\r\nit is also possible to run in command-line mode, allowing any available command\r\nto be executed separately without remaining in the interpreter.\r\n\r\nfor example, listing the entries in the home directory:\r\n\r\n.. code-block:: bash\r\n\r\n    > python samples/cli.py ls -l\r\n    drwxrwx--- 0123abcd 0123abcd         0 aug 02 12:44 azure1\r\n    -rwxrwx--- 0123abcd 0123abcd   1048576 jul 25 18:33 abc.csv\r\n    -r-xr-xr-x 0123abcd 0123abcd        36 jul 22 18:32 xyz.csv\r\n    drwxrwx--- 0123abcd 0123abcd         0 aug 03 13:46 tmp\r\n    >\r\n\r\n\r\nalso, downloading a remote file:\r\n\r\n.. code-block:: bash\r\n\r\n    > python samples/cli.py get xyz.csv\r\n    2016-08-04 18:57:48,603 - adlfs - debug - creating empty file xyz.csv\r\n    2016-08-04 18:57:48,604 - adlfs - debug - fetch: xyz.csv, 0-36\r\n    2016-08-04 18:57:49,726 - adlfs - debug - downloaded to xyz.csv, byte offset 0\r\n    2016-08-04 18:57:49,734 - adlfs - debug - file downloaded (xyz.csv -> xyz.csv)\r\n    >\r\n\r\ntests\r\n=====\r\n\r\nfor detailed documentation about our test framework, please visit the \r\n`tests folder <https://github.com/azure/azure-data-lake-store-python/tree/master/tests>`__.\r\n\r\nneed help?\r\n==========\r\n\r\nbe sure to check out the microsoft azure `developer forums on stack overflow <http://go.microsoft.com/fwlink/?linkid=234489>`__\r\nif you have trouble with the provided code. most questions are tagged `azure and python <https://stackoverflow.com/questions/tagged/azure+python>`__.\r\n\r\n\r\ncontribute code or provide feedback\r\n===================================\r\n\r\nif you would like to become an active contributor to this project please\r\nfollow the instructions provided in `microsoft azure projects contribution guidelines <http://azure.github.io/guidelines/>`__. \r\nfurthermore, check out `guidance.md <https://github.com/azure/azure-data-lake-store-python/blob/master/guidance.md>`__ \r\nfor specific information related to this project.\r\n\r\nif you encounter any bugs with the library please file an issue in the\r\n`issues <https://github.com/azure/azure-data-lake-store-python/issues>`__\r\nsection of the project.\r\n\r\n\r\ncode of conduct\r\n===============\r\nthis project has adopted the `microsoft open source code of conduct <https://opensource.microsoft.com/codeofconduct/>`__. \r\nfor more information see the `code of conduct faq <https://opensource.microsoft.com/codeofconduct/faq/>`__ or contact \r\n`opencode@microsoft.com <mailto:opencode@microsoft.com>`__ with any additional questions or comments.\r\n\r\n\r\n.. :changelog:\r\n\r\nrelease history\r\n===============\r\n\r\n0.0.53 (2023-04-11)\r\n+++++++++++++++++++\r\n* add msal support. remove adal support\r\n* suppress deprecation warning when detecting pyopenssl existence.\r\n\r\n0.0.52 (2020-11-25)\r\n+++++++++++++++++++\r\n* changed logging verbosity when closing a stream\r\n* filter out default acl for files when using recursive acl operations\r\n\r\n0.0.51 (2020-10-15)\r\n+++++++++++++++++++\r\n* add more logging for zero byte reads to investigate root cause.\r\n\r\n0.0.50 (2020-09-10)\r\n+++++++++++++++++++\r\n* fix bug with retrying for adal exception parsing.\r\n\r\n0.0.49 (2020-08-05)\r\n+++++++++++++++++++\r\n* fix bug with noretrypolicy\r\n* remove python 3.4,5 in travis configuration.\r\n* fix logging for unicode\r\n\r\n0.0.48 (2019-10-18)\r\n+++++++++++++++++++\r\n* buffer writes to prevent out of memory problems\r\n* add python 3.7 in travis configuration\r\n\r\n0.0.47 (2019-08-14)\r\n+++++++++++++++++++\r\n* remove logging of bearer token\r\n* documentation related changes(add readme.md and correct some formatting)\r\n\r\n0.0.46 (2019-06-25)\r\n+++++++++++++++++++\r\n* expose per request timeout. default to 60.\r\n* concat will not retry by default.\r\n* bug fixes.\r\n\r\n0.0.45 (2019-05-10)\r\n+++++++++++++++++++\r\n* update open and close adlfile semantics\r\n* refactor code and improve performance for opening a file\r\n\r\n0.0.44 (2019-03-05)\r\n+++++++++++++++++++\r\n* add continuation token to liststatus api call\r\n* update api-version to 2018-09-01\r\n\r\n0.0.43 (2019-03-01)\r\n+++++++++++++++++++\r\n* fix bug in downloader when glob returns a single file\r\n\r\n0.0.42 (2019-02-26)\r\n+++++++++++++++++++\r\n* update docstrings\r\n* remove logging setlevel to debug for recursive acl operations\r\n\r\n0.0.41 (2019-01-31)\r\n+++++++++++++++++++\r\n* remove getcontentsummary api call\r\n* move check_token() under retry block\r\n* expose timeout parameter for adldownloader and adluploader\r\n* raise an exception instead of silently break for zero length reads\r\n\r\n0.0.40 (2019-01-08)\r\n+++++++++++++++++++\r\n* fix zero length read\r\n* remove dependence on custom wheel and conform to pep 420\r\n\r\n0.0.39 (2018-11-14)\r\n+++++++++++++++++++\r\n* fix for chunked decoding exception thrown while reading response.content\r\n\r\n0.0.38 (2018-11-12)\r\n+++++++++++++++++++\r\n* added support for recursive acl functions\r\n* fixed bug due to missing filesessionid in get_chunk\r\n\r\n0.0.37 (2018-11-02)\r\n+++++++++++++++++++\r\n* reverted some changes introduced in 0.0.35 that didn't work with other tokens\r\n\r\n0.0.36 (2018-10-31)\r\n+++++++++++++++++++\r\n* fixed typo in refresh_token call\r\n\r\n0.0.35 (2018-10-29)\r\n+++++++++++++++++++\r\n* added retry for getting tokens\r\n* added requests>=2.20 because of cve 2018-18074\r\n* fixed test parameters and updated test recordings\r\n\r\n0.0.34 (2018-10-15)\r\n+++++++++++++++++++\r\n* fixed concat issue with plus(or other symbols) in filename\r\n* added readinto method\r\n* changed api-version to 2018-05-01 for all.\r\n\r\n0.0.32 (2018-10-04)\r\n+++++++++++++++++++\r\n* fixed test bug\r\n* fixed empty folder upload bug\r\n* fixed adl downloader block size bug\r\n\r\n0.0.31 (2018-09-10)\r\n+++++++++++++++++++\r\n* added support for batched ls\r\n\r\n0.0.30 (2018-08-28)\r\n+++++++++++++++++++\r\n* fixed .travis.yml order to add azure-nspg dependency\r\n\r\n0.0.29 (2018-08-22)\r\n+++++++++++++++++++\r\n* fixed history.rst and pypi documentation\r\n\r\n0.0.28 (2018-08-20)\r\n+++++++++++++++++++\r\n* added recovery from datalakebadoffsetexception\r\n\r\n0.0.27 (2018-08-08)\r\n+++++++++++++++++++\r\n* fixed bug in single file check\r\n* added python2 exception compatibility\r\n\r\n0.0.26 (2018-08-03)\r\n+++++++++++++++++++\r\n* fixed bug due to not importing errno\r\n* fixed bug in os.makedirs race condition\r\n* updated readme with correct environment variables and fixed some links\r\n\r\n0.0.25 (2018-07-26)\r\n+++++++++++++++++++\r\n* fixed downloading of empty directories and download of directory structure with only a single file\r\n\r\n0.0.24 (2018-07-16)\r\n+++++++++++++++++++\r\n* retry policy implemented for all operations, default being exponential retry policy\r\n\r\n0.0.23 (2018-07-11)\r\n+++++++++++++++++++\r\n* fixed the incorrect download location in case of unc local paths\r\n\r\n0.0.22 (2018-06-02)\r\n+++++++++++++++++++\r\n* encoding filepaths in uri\r\n\r\n0.0.21 (2018-06-01)\r\n+++++++++++++++++++\r\n* remove unused msrest dependency\r\n\r\n0.0.20 (2018-05-25)\r\n+++++++++++++++++++\r\n* compatibility of the sdist with wheel 0.31.0\r\n\r\n0.0.19 (2018-03-14)\r\n-------------------\r\n* fixed upload issue where destination filename was wrong while upload of directory with single file #208\r\n\r\n0.0.18 (2018-02-05)\r\n-------------------\r\n* fixed read issue where whole file was cached while doing positional reads #198\r\n* fixed readline as well for the same\r\n\r\n0.0.17 (2017-09-21)\r\n-------------------\r\n* fixed readme.rst indentation error\r\n* changed management endpoint\r\n\r\n0.0.16 (2017-09-11)\r\n-------------------\r\n* fixed multi chunk transfer hangs as merging chunks fails #187\r\n* added syncflag and leaseid in create, append calls.\r\n* added filesessionid in create, append and open calls.\r\n\r\n0.0.15 (2017-07-26)\r\n-------------------\r\n* enable data lake store progress controller callback #174\r\n* fix file state incorrectly marked as \"errored\" if contains chunks is \"pending\" state #182\r\n* fix race condition due to `transfer` future `done_callback` #177\r\n\r\n0.0.14 (2017-07-10)\r\n-------------------\r\n* fix an issue where common prefixes in paths for upload and download were collapsed into only unique paths.\r\n\r\n0.0.13 (2017-06-28)\r\n-------------------\r\n* add support for automatic refreshing of service principal credentials\r\n\r\n0.0.12 (2017-06-20)\r\n-------------------\r\n* fix a regression with ls returning the top level folder if it has no contents. it now properly returns an empty array if a folder has no children.\r\n\r\n0.0.11 (2017-06-02)\r\n-------------------\r\n* update to name incomplete file downloads with a `.inprogress` suffix. this suffix is removed when the download completes successfully.\r\n\r\n0.0.10 (2017-05-24)\r\n-------------------\r\n* allow users to explicitly use or invalidate the internal, local cache of the filesystem that is built up from previous `ls` calls. it is now set to always call the service instead of the cache by default.\r\n* update to properly create the wheel package during build to ensure all pip packages are available.\r\n* update folder upload/download to properly throw early in the event that the destination files exist and overwrite was not specified. note: target folder existence (or sub folder existence) does not automatically cause failure. only leaf node existence will result in failure.\r\n* fix a bug that caused file not found errors when attempting to get information about the root folder.\r\n\r\n0.0.9 (2017-05-09)\r\n------------------\r\n* enforce basic ssl utilization to ensure performance due to `github issue 625 <https://github.com/pyca/pyopenssl/issues/625>`\r\n\r\n0.0.8 (2017-04-26)\r\n------------------\r\n* fix server-side throttling retry support. this is not a guarantee that if the server is throttling the upload (or download) it will eventually succeed, but there is now a back-off retry in place to make it more likely.\r\n\r\n0.0.7 (2017-04-19)\r\n------------------\r\n* update the build process to more efficiently handle multi-part namespaces for pip.\r\n\r\n0.0.6 (2017-03-15)\r\n------------------\r\n* fix an issue with path caching that should drastically improve performance for download\r\n\r\n0.0.5 (2017-03-01)\r\n------------------\r\n* fix for downloader to ensure there is access to the source path before creating destination files\r\n* fix for credential objects to inherit from msrest.authentication for more universal authentication support\r\n* add support for the following:\r\n\r\n  * set_expiry: allows for setting expiration on files\r\n  * acl management:\r\n\r\n    * set_acl: allows for the full replacement of an acl on a file or folder\r\n    * set_acl_entries: allows for \"patching\" an existing acl on a file or folder\r\n    * get_acl_status: retrieves the acl information for a file or folder\r\n    * remove_acl_entries: removes the specified entries from an acl on a file or folder\r\n    * remove_acl: removes all non-default acl entries from a file or folder\r\n    * remove_default_acl: removes all default acl entries from a folder\r\n\r\n* remove unsupported and unused \"truncate\" operation.\r\n* added api-version support with a default of the latest api version (2016-11-01)\r\n\r\n0.0.4 (2017-02-07)\r\n------------------\r\n* fix for folder upload to properly delete folders with contents when overwrite specified.\r\n* fix to set verbose output to false/off by default. this removes progress tracking output by default but drastically improves performance.\r\n\r\n0.0.3 (2017-02-02)\r\n------------------\r\n* fix to setup.py to include the history.rst file. no other changes\r\n\r\n0.0.2 (2017-01-30)\r\n------------------\r\n* addresses an issue with lib.auth() not properly defaulting to 2fa\r\n* fixes an issue with overwrite for adluploader sometimes not being honored.\r\n* fixes an issue with empty files not properly being uploaded and resulting in a hang in progress tracking.\r\n* addition of a samples directory showcasing examples of how to use the client and upload and download logic.\r\n* general cleanup of documentation and comments.\r\n* this is still based on api version 2016-11-01\r\n\r\n0.0.1 (2016-11-21)\r\n------------------\r\n* initial preview release. based on api version 2016-11-01.\r\n* includes initial adls filesystem functionality and extended upload and download support.\r\n",
  "docs_url": null,
  "keywords": "azure",
  "license": "mit license",
  "name": "azure-datalake-store",
  "package_url": "https://pypi.org/project/azure-datalake-store/",
  "project_url": "https://pypi.org/project/azure-datalake-store/",
  "project_urls": {
    "Homepage": "https://github.com/Azure/azure-data-lake-store-python"
  },
  "release_url": "https://pypi.org/project/azure-datalake-store/0.0.53/",
  "requires_dist": [
    "cffi",
    "msal (<2,>=1.16.0)",
    "requests (>=2.20.0)",
    "azure-nspkg ; python_version<'3.0'",
    "pathlib2 ; python_version<'3.4'",
    "futures ; python_version<='2.7'"
  ],
  "requires_python": "",
  "summary": "azure data lake store filesystem client library for python",
  "version": "0.0.53",
  "releases": [],
  "developers": [
    "akshat.harit@microsoft.com",
    "microsoft_corporation"
  ],
  "kwds": "azuredlfilesystem azure_data_lake_store_name azure_data_lake_store_url_suffix azure_password azure_username",
  "license_kwds": "mit license",
  "libtype": "pypi",
  "id": "pypi_azure_datalake_store",
  "homepage": "https://github.com/azure/azure-data-lake-store-python",
  "release_count": 50,
  "dependency_ids": [
    "pypi_azure_nspkg",
    "pypi_cffi",
    "pypi_futures",
    "pypi_msal",
    "pypi_pathlib2",
    "pypi_requests"
  ]
}