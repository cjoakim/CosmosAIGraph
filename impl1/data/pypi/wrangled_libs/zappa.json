{
  "classifiers": [
    "environment :: console",
    "framework :: django",
    "framework :: django :: 1.11",
    "framework :: django :: 2.0",
    "framework :: django :: 3.0",
    "license :: osi approved :: apache software license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: internet :: www/http",
    "topic :: internet :: www/http :: dynamic content"
  ],
  "description": "<p align=\"center\">\n  <img src=\"http://i.imgur.com/oepnhjn.jpg\" alt=\"zappa rocks!\"/>\n</p>\n\n## zappa - serverless python\n\n[![ci](https://github.com/zappa/zappa/actions/workflows/ci.yaml/badge.svg?branch=master&event=push)](https://github.com/zappa/zappa/actions/workflows/ci.yaml)\n[![coverage](https://img.shields.io/coveralls/zappa/zappa.svg)](https://coveralls.io/github/zappa/zappa)\n[![pypi](https://img.shields.io/pypi/v/zappa.svg)](https://pypi.python.org/pypi/zappa)\n[![slack](https://img.shields.io/badge/chat-slack-ff69b4.svg)](https://zappateam.slack.com/)\n\n<!-- start doctoc generated toc please keep comment here to allow auto update -->\n<!-- don't edit this section, instead re-run doctoc to update -->\n\n\n- [about](#about)\n- [installation and configuration](#installation-and-configuration)\n  - [running the initial setup / settings](#running-the-initial-setup--settings)\n- [basic usage](#basic-usage)\n  - [initial deployments](#initial-deployments)\n  - [updates](#updates)\n    - [docker workflows](#docker-workflows)\n  - [rollback](#rollback)\n  - [scheduling](#scheduling)\n    - [advanced scheduling](#advanced-scheduling)\n      - [multiple expressions](#multiple-expressions)\n      - [disabled event](#disabled-event)\n  - [undeploy](#undeploy)\n  - [package](#package)\n    - [how zappa makes packages](#how-zappa-makes-packages)\n  - [template](#template)\n  - [status](#status)\n  - [tailing logs](#tailing-logs)\n  - [remote function invocation](#remote-function-invocation)\n  - [django management commands](#django-management-commands)\n  - [ssl certification](#ssl-certification)\n    - [deploying to a domain with aws certificate manager](#deploying-to-a-domain-with-aws-certificate-manager)\n    - [deploying to a domain with a let's encrypt certificate (dns auth)](#deploying-to-a-domain-with-a-lets-encrypt-certificate-dns-auth)\n    - [deploying to a domain with a let's encrypt certificate (http auth)](#deploying-to-a-domain-with-a-lets-encrypt-certificate-http-auth)\n    - [deploying to a domain with your own ssl certs](#deploying-to-a-domain-with-your-own-ssl-certs)\n- [executing in response to aws events](#executing-in-response-to-aws-events)\n- [asynchronous task execution](#asynchronous-task-execution)\n  - [catching exceptions](#catching-exceptions)\n  - [task sources](#task-sources)\n  - [direct invocation](#direct-invocation)\n  - [remote invocations](#remote-invocations)\n  - [restrictions](#restrictions)\n  - [running tasks in a vpc](#running-tasks-in-a-vpc)\n  - [responses](#responses)\n- [advanced settings](#advanced-settings)\n    - [yaml settings](#yaml-settings)\n- [advanced usage](#advanced-usage)\n  - [keeping the server warm](#keeping-the-server-warm)\n    - [serving static files / binary uploads](#serving-static-files--binary-uploads)\n  - [enabling cors](#enabling-cors)\n  - [large projects](#large-projects)\n  - [enabling bash completion](#enabling-bash-completion)\n  - [enabling secure endpoints on api gateway](#enabling-secure-endpoints-on-api-gateway)\n    - [api key](#api-key)\n    - [iam policy](#iam-policy)\n    - [api gateway lambda authorizers](#api-gateway-lambda-authorizers)\n    - [cognito user pool authorizer](#cognito-user-pool-authorizer)\n    - [api gateway resource policy](#api-gateway-resource-policy)\n  - [setting environment variables](#setting-environment-variables)\n    - [local environment variables](#local-environment-variables)\n    - [remote aws environment variables](#remote-aws-environment-variables)\n    - [remote environment variables](#remote-environment-variables)\n    - [remote environment variables (via an s3 file)](#remote-environment-variables-via-an-s3-file)\n  - [api gateway context variables](#api-gateway-context-variables)\n  - [catching unhandled exceptions](#catching-unhandled-exceptions)\n  - [using custom aws iam roles and policies](#using-custom-aws-iam-roles-and-policies)\n    - [custom aws iam roles and policies for deployment](#custom-aws-iam-roles-and-policies-for-deployment)\n    - [custom aws iam roles and policies for execution](#custom-aws-iam-roles-and-policies-for-execution)\n  - [aws x-ray](#aws-x-ray)\n  - [globally available server-less architectures](#globally-available-server-less-architectures)\n  - [raising aws service limits](#raising-aws-service-limits)\n  - [dead letter queues](#dead-letter-queues)\n  - [unique package id](#unique-package-id)\n  - [application load balancer event source](#application-load-balancer-event-source)\n  - [endpoint configuration](#endpoint-configuration)\n    - [example private api gateway configuration](#example-private-api-gateway-configuration)\n  - [cold starts (experimental)](#cold-starts-experimental)\n- [zappa guides](#zappa-guides)\n- [zappa in the press](#zappa-in-the-press)\n- [sites using zappa](#sites-using-zappa)\n- [related projects](#related-projects)\n- [hacks](#hacks)\n- [contributing](#contributing)\n    - [using a local repo](#using-a-local-repo)\n\n<!-- end doctoc generated toc please keep comment here to allow auto update -->\n\n## about\n\n<p align=\"center\">\n  <a href=\"https://htmlpreview.github.io/?https://raw.githubusercontent.com/miserlou/talks/master/serverless-sf/big.quickstart.html\"><img src=\"http://i.imgur.com/c23kdnt.png?1\" alt=\"zappa slides\"/></a>\n</p>\n<p align=\"center\">\n  <i>in a hurry? click to see <a href=\"https://htmlpreview.github.io/?https://raw.githubusercontent.com/miserlou/talks/master/serverless-sf/big.quickstart.html\">(now slightly out-dated) slides from serverless sf</a>!</i>\n</p>\n\n**zappa** makes it super easy to build and deploy server-less, event-driven python applications (including, but not limited to, wsgi web apps) on aws lambda + api gateway. think of it as \"serverless\" web hosting for your python apps. that means **infinite scaling**, **zero downtime**, **zero maintenance** - and at a fraction of the cost of your current deployments!\n\nif you've got a python web app (including django and flask apps), it's as easy as:\n\n```\n$ pip install zappa\n$ zappa init\n$ zappa deploy\n```\n\nand now you're server-less! _wow!_\n\n> what do you mean \"serverless\"?\n\nokay, so there still is a server - but it only has a _40 millisecond_ life cycle! serverless in this case means **\"without any permanent infrastructure.\"**\n\nwith a traditional http server, the server is online 24/7, processing requests one by one as they come in. if the queue of incoming requests grows too large, some requests will time out. with zappa, **each request is given its own virtual http \"server\"** by amazon api gateway. aws handles the horizontal scaling automatically, so no requests ever time out. each request then calls your application from a memory cache in aws lambda and returns the response via python's wsgi interface. after your app returns, the \"server\" dies.\n\nbetter still, with zappa you only pay for the milliseconds of server time that you use, so it's many **orders of magnitude cheaper** than vps/paas hosts like linode or heroku - and in most cases, it's completely free. plus, there's no need to worry about load balancing or keeping servers online ever again.\n\nit's great for deploying serverless microservices with frameworks like flask and bottle, and for hosting larger web apps and cmses with django. or, you can use any wsgi-compatible app you like! you **probably don't need to change your existing applications** to use it, and you're not locked into using it.\n\nzappa also lets you build hybrid event-driven applications that can scale to **trillions of events** a year with **no additional effort** on your part! you also get **free ssl certificates**, **global app deployment**, **api access management**, **automatic security policy generation**, **precompiled c-extensions**, **auto keep-warms**, **oversized lambda packages**, and **many other exclusive features**!\n\nand finally, zappa is **super easy to use**. you can deploy your application with a single command out of the box!\n\n__awesome!__\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/f1pjxcq.gif\" alt=\"zappa demo gif\"/>\n</p>\n\n## installation and configuration\n\n_before you begin, make sure you are running python 3.7/3.8/3.9/3.10/3.11 and you have a valid aws account and your [aws credentials file](https://blogs.aws.amazon.com/security/post/tx3d6u6wsfgok2h/a-new-and-standardized-way-to-manage-credentials-in-the-aws-sdks) is properly installed._\n\n**zappa** can easily be installed through pip, like so:\n\n    $ pip install zappa\n\nplease note that zappa _**must**_ be installed into your project's [virtual environment](http://docs.python-guide.org/en/latest/dev/virtualenvs/). the virtual environment name should not be the same as the zappa project name, as this may cause errors.\n\n_(if you use [pyenv](https://github.com/yyuu/pyenv) and love to manage virtualenvs with **pyenv-virtualenv**, you just have to call `pyenv local [your_venv_name]` and it's ready. [conda](http://conda.pydata.org/docs/) users should comment [here](https://github.com/miserlou/zappa/pull/108).)_\n\nnext, you'll need to define your local and server-side settings.\n\n### running the initial setup / settings\n\n**zappa** can automatically set up your deployment settings for you with the `init` command:\n\n    $ zappa init\n\nthis will automatically detect your application type (flask/django - pyramid users [see here](https://github.com/miserlou/zappa/issues/278#issuecomment-241917956)) and help you define your deployment configuration settings. once you finish initialization, you'll have a file named *zappa_settings.json* in your project directory defining your basic deployment settings. it will probably look something like this for most wsgi apps:\n\n```javascript\n{\n    // the name of your stage\n    \"dev\": {\n        // the name of your s3 bucket\n        \"s3_bucket\": \"lambda\",\n\n        // the modular python path to your wsgi application function.\n        // in flask and bottle, this is your 'app' object.\n        // flask (your_module.py):\n        // app = flask()\n        // bottle (your_module.py):\n        // app = bottle.default_app()\n        \"app_function\": \"your_module.app\"\n    }\n}\n```\n\nor for django:\n\n```javascript\n{\n    \"dev\": { // the name of your stage\n       \"s3_bucket\": \"lambda\", // the name of your s3 bucket\n       \"django_settings\": \"your_project.settings\" // the python path to your django settings.\n    }\n}\n```\n\n_psst: if you're deploying a django application with zappa for the first time, you might want to read edgar roman's [django zappa guide](https://edgarroman.github.io/zappa-django-guide/)._\n\nyou can define as many stages as your like - we recommend having _dev_, _staging_, and _production_.\n\nnow, you're ready to deploy!\n\n## basic usage\n\n### initial deployments\n\nonce your settings are configured, you can package and deploy your application to a stage called \"production\" with a single command:\n\n    $ zappa deploy production\n    deploying..\n    your application is now live at: https://7k6anj0k99.execute-api.us-east-1.amazonaws.com/production\n\nand now your app is **live!** how cool is that?!\n\nto explain what's going on, when you call `deploy`, zappa will automatically package up your application and local virtual environment into a lambda-compatible archive, replace any dependencies with versions with wheels compatible with lambda, set up the function handler and necessary wsgi middleware, upload the archive to s3, create and manage the necessary amazon iam policies and roles, register it as a new lambda function, create a new api gateway resource, create wsgi-compatible routes for it, link it to the new lambda function, and finally delete the archive from your s3 bucket. handy!\n\nbe aware that the default iam role and policy created for executing lambda applies a liberal set of permissions.\nthese are most likely not appropriate for production deployment of important applications.  see the section\n[custom aws iam roles and policies for execution](#custom-aws-iam-roles-and-policies-for-execution) for more detail.\n\n### updates\n\nif your application has already been deployed and you only need to upload new python code, but not touch the underlying routes, you can simply:\n\n    $ zappa update production\n    updating..\n    your application is now live at: https://7k6anj0k99.execute-api.us-east-1.amazonaws.com/production\n\nthis creates a new archive, uploads it to s3 and updates the lambda function to use the new code, but doesn't touch the api gateway routes.\n\n#### docker workflows\n\nin [version 0.53.0](https://github.com/zappa/zappa/blob/master/changelog.md), support was added to deploy & update lambda functions using docker. \n\nyou can specify an ecr image using the `--docker-image-uri` option to the zappa command on `deploy` and `update`.\nzappa expects that the image is built and pushed to a amazon ecr repository. \n\ndeploy example:\n\n    $ zappa deploy --docker-image-uri {aws account id}.dkr.ecr.{region}.amazonaws.com/{repository name}:latest\n\nupdate example:\n\n    $ zappa update --docker-image-uri {aws account id}.dkr.ecr.{region}.amazonaws.com/{repository name}:latest\n\nrefer to [the blog post](https://ianwhitestone.work/zappa-serverless-docker/) for more details about how to leverage this functionality, and when you may want to.\n\nif you are using a custom docker image for your lambda runtime (e.g. if you want to use a newer version of python that is not yet supported by lambda out of the box) and you would like to bypass the python version check, you can set an environment variable to do so:\n\n    $ export zappa_running_in_docker=true\n\nyou can also add this to your dockerfile like this:\n\n```\nenv zappa_running_in_docker=true\n```\n\n### rollback\n\nyou can also `rollback` the deployed code to a previous version by supplying the number of revisions to return to. for instance, to rollback to the version deployed 3 versions ago:\n\n    $ zappa rollback production -n 3\n\n### scheduling\n\nzappa can be used to easily schedule functions to occur on regular intervals. this provides a much nicer, maintenance-free alternative to celery!\nthese functions will be packaged and deployed along with your `app_function` and called from the handler automatically.\njust list your functions and the expression to schedule them using [cron or rate syntax](http://docs.aws.amazon.com/lambda/latest/dg/tutorial-scheduled-events-schedule-expressions.html) in your *zappa_settings.json* file:\n\n```javascript\n{\n    \"production\": {\n       ...\n       \"events\": [{\n           \"function\": \"your_module.your_function\", // the function to execute\n           \"expression\": \"rate(1 minute)\" // when to execute it (in cron or rate format)\n       }],\n       ...\n    }\n}\n```\n\nand then:\n\n    $ zappa schedule production\n\nand now your function will execute every minute!\n\nif you want to cancel these, you can simply use the `unschedule` command:\n\n    $ zappa unschedule production\n\nand now your scheduled event rules are deleted.\n\nsee the [example](example/) for more details.\n\n#### advanced scheduling\n\n##### multiple expressions\n\nsometimes a function needs multiple expressions to describe its schedule. to set multiple expressions, simply list your functions, and the list of expressions to schedule them using [cron or rate syntax](http://docs.aws.amazon.com/lambda/latest/dg/tutorial-scheduled-events-schedule-expressions.html) in your *zappa_settings.json* file:\n\n```javascript\n{\n    \"production\": {\n       ...\n       \"events\": [{\n           \"function\": \"your_module.your_function\", // the function to execute\n           \"expressions\": [\"cron(0 20-23 ? * sun-thu *)\", \"cron(0 0-8 ? * mon-fri *)\"] // when to execute it (in cron or rate format)\n       }],\n       ...\n    }\n}\n```\n\nthis can be used to deal with issues arising from the utc timezone crossing midnight during business hours in your local timezone.\n\nit should be noted that overlapping expressions will not throw a warning, and should be checked for, to prevent duplicate triggering of functions.\n\n##### disabled event\n\nsometimes an event should be scheduled, yet disabled.\nfor example, perhaps an event should only run in your production environment, but not sandbox.\nyou may still want to deploy it to sandbox to ensure there is no issue with your expression(s) before deploying to production.\n\nin this case, you can disable it from running by setting `enabled` to `false` in the event definition:\n\n```javascript\n{\n    \"sandbox\": {\n       ...\n       \"events\": [{\n           \"function\": \"your_module.your_function\", // the function to execute\n           \"expression\": \"rate(1 minute)\", // when to execute it (in cron or rate format)\n           \"enabled\": false\n       }],\n       ...\n    }\n}\n```\n\n### undeploy\n\nif you need to remove the api gateway and lambda function that you have previously published, you can simply:\n\n    $ zappa undeploy production\n\nyou will be asked for confirmation before it executes.\n\nif you enabled cloudwatch logs for your api gateway service and you don't\nwant to keep those logs, you can specify the `--remove-logs` argument to purge the logs for your api gateway and your lambda function:\n\n    $ zappa undeploy production --remove-logs\n\n### package\n\nif you want to build your application package without actually uploading and registering it as a lambda function, you can use the `package` command:\n\n    $ zappa package production\n\nif you have a `zip` callback in your `callbacks` setting, this will also be invoked.\n\n```javascript\n{\n    \"production\": { // the name of your stage\n        \"callbacks\": {\n            \"zip\": \"my_app.zip_callback\"// after creating the package\n        }\n    }\n}\n```\n\nyou can also specify the output filename of the package with `-o`:\n\n    $ zappa package production -o my_awesome_package.zip\n\n#### how zappa makes packages\n\nzappa will automatically package your active virtual environment into a package which runs smoothly on aws lambda.\n\nduring this process, it will replace any local dependencies with aws lambda compatible versions. dependencies are included in this order:\n\n  * lambda-compatible `manylinux` wheels from a local cache\n  * lambda-compatible `manylinux` wheels from pypi\n  * packages from the active virtual environment\n  * packages from the local project directory\n\nit also skips certain unnecessary files, and ignores any .py files if .pyc files are available.\n\nin addition, zappa will also automatically set the correct execution permissions, configure package settings, and create a unique, auditable package manifest file.\n\nto further reduce the final package file size, you can:\n\n* set `slim_handler` to `true` to upload a small handler to lambda and the rest of the package to s3. for more details, see the [merged pull request](https://github.com/miserlou/zappa/pull/548) and the [discussion in the original issue](https://github.com/miserlou/zappa/issues/510). see also: [large projects](#large-projects).\n* use the `exclude` or `exclude_glob` setting and provide a list of patterns to exclude from the archive. by default, zappa will exclude boto, because [it's already available in the lambda execution environment](http://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html).\n\n### template\n\nsimilarly to `package`, if you only want the api gateway cloudformation template, use the `template` command:\n\n    $ zappa template production --l your-lambda-arn -r your-role-arn\n\nnote that you must supply your own lambda arn and role arns in this case, as they may not have been created for you.\n\nyou can get the json output directly with `--json`, and specify the output file with `--output`.\n\n### status\n\nif you need to see the status of your deployment and event schedules, simply use the `status` command.\n\n    $ zappa status production\n\n### tailing logs\n\nyou can watch the logs of a deployment by calling the `tail` management command.\n\n    $ zappa tail production\n\nby default, this will show all log items. in addition to http and other events, anything `print`ed to `stdout` or `stderr` will be shown in the logs.\n\nyou can use the argument `--http` to filter for http requests, which will be in the apache common log format.\n\n    $ zappa tail production --http\n\nsimilarly, you can do the inverse and only show non-http events and log messages:\n\n    $ zappa tail production --non-http\n\nif you don't like the default log colors, you can turn them off with `--no-color`.\n\nyou can also limit the length of the tail with `--since`, which accepts a simple duration string:\n\n    $ zappa tail production --since 4h # 4 hours\n    $ zappa tail production --since 1m # 1 minute\n    $ zappa tail production --since 1mm # 1 month\n\nyou can filter out the contents of the logs with `--filter`, like so:\n\n    $ zappa tail production --http --filter \"post\" # only show post http requests\n\nnote that this uses the [cloudwatch logs filter syntax](http://docs.aws.amazon.com/amazoncloudwatch/latest/logs/filterandpatternsyntax.html).\n\nto tail logs without following (to exit immediately after displaying the end of the requested logs), pass `--disable-keep-open`:\n\n    $ zappa tail production --since 1h --disable-keep-open\n\n\n### remote function invocation\n\nyou can execute any function in your application directly at any time by using the `invoke` command.\n\nfor instance, suppose you have a basic application in a file called \"my_app.py\", and you want to invoke a function in it called \"my_function\". once your application is deployed, you can invoke that function at any time by calling:\n\n    $ zappa invoke production my_app.my_function\n\nany remote print statements made and the value the function returned will then be printed to your local console. **nifty!**\n\nyou can also invoke interpretable python 3.7/3.8/3.9/3.10/3.11 strings directly by using `--raw`, like so:\n\n    $ zappa invoke production \"print(1 + 2 + 3)\" --raw\n\nfor instance, it can come in handy if you want to create your first `superuser` on a rds database running in a vpc (like serverless aurora):\n    $ zappa invoke staging \"from django.contrib.auth import get_user_model; user = get_user_model(); user.objects.create_superuser('username', 'email', 'password')\" --raw\n\n### django management commands\n\nas a convenience, zappa can also invoke remote django 'manage.py' commands with the `manage` command. for instance, to perform the basic django status check:\n\n    $ zappa manage production showmigrations admin\n\nobviously, this only works for django projects which have their settings properly defined.\n\nfor commands which have their own arguments, you can also pass the command in as a string, like so:\n\n    $ zappa manage production \"shell --version\"\n\ncommands which require direct user input, such as `createsuperuser`, should be [replaced by commands](http://stackoverflow.com/a/26091252) which use `zappa invoke <env> --raw`.\n\nfor more django integration, take a look at the [zappa-django-utils](https://github.com/miserlou/zappa-django-utils) project.\n\n### ssl certification\n\nzappa can be deployed to custom domain names and subdomains with custom ssl certificates, let's encrypt certificates, and [aws certificate manager](https://aws.amazon.com/certificate-manager/) (acm) certificates.\n\ncurrently, the easiest of these to use are the aws certificate manager certificates, as they are free, self-renewing, and require the least amount of work.\n\nonce configured as described below, all of these methods use the same command:\n\n    $ zappa certify\n\nwhen deploying from a ci/cd system, you can use:\n\n    $ zappa certify --yes\n\nto skip the confirmation prompt.\n\n#### deploying to a domain with aws certificate manager\n\namazon provides their own free alternative to let's encrypt called [aws certificate manager](https://aws.amazon.com/certificate-manager/) (acm). to use this service with zappa:\n\n1. verify your domain in the aws certificate manager console.\n2. in the console, select the n. virginia (us-east-1) region and request a certificate for your domain or subdomain (`sub.yourdomain.tld`), or request a wildcard domain (`*.yourdomain.tld`).\n3. copy the entire arn of that certificate and place it in the zappa setting `certificate_arn`.\n4. set your desired domain in the `domain` setting.\n5. call `$ zappa certify` to create and associate the api gateway distribution using that certificate.\n\n#### deploying to a domain with a let's encrypt certificate (dns auth)\n\nif you want to use zappa on a domain with a free let's encrypt certificate using automatic route 53 based dns authentication, you can follow [this handy guide](https://github.com/zappa/zappa/blob/master/docs/domain_with_free_ssl_dns.md).\n\n#### deploying to a domain with a let's encrypt certificate (http auth)\n\nif you want to use zappa on a domain with a free let's encrypt certificate using http authentication, you can follow [this guide](https://github.com/zappa/zappa/blob/master/docs/domain_with_free_ssl_http.md).\n\nhowever, it's now far easier to use route 53-based dns authentication, which will allow you to use a let's encrypt certificate with a single `$ zappa certify` command.\n\n#### deploying to a domain with your own ssl certs\n\n1. the first step is to create a custom domain and obtain your ssl cert / key / bundle.\n2. ensure you have set the `domain` setting within your zappa settings json - this will avoid problems with the base path mapping between the custom domain and the api invoke url, which gets the stage name appended in the uri\n3. add the paths to your ssl cert / key / bundle to the `certificate`, `certificate_key`, and `certificate_chain` settings, respectively, in your zappa settings json\n4. set `route53_enabled` to `false` if you plan on using your own dns provider, and not an aws route53 hosted zone.\n5. deploy or update your app using zappa\n6. run `$ zappa certify` to upload your certificates and register the custom domain name with your api gateway.\n\n## executing in response to aws events\n\nsimilarly, you can have your functions execute in response to events that happen in the aws ecosystem, such as s3 uploads, dynamodb entries, kinesis streams, sns messages, and sqs queues.\n\nin your *zappa_settings.json* file, define your [event sources](http://docs.aws.amazon.com/lambda/latest/dg/invoking-lambda-function.html) and the function you wish to execute. for instance, this will execute `your_module.process_upload_function` in response to new objects in your `my-bucket` s3 bucket. note that `process_upload_function` must accept `event` and `context` parameters.\n\n```javascript\n{\n    \"production\": {\n       ...\n       \"events\": [{\n            \"function\": \"your_module.process_upload_function\",\n            \"event_source\": {\n                  \"arn\":  \"arn:aws:s3:::my-bucket\",\n                  \"events\": [\n                    \"s3:objectcreated:*\" // supported event types: http://docs.aws.amazon.com/amazons3/latest/dev/notificationhowto.html#supported-notification-event-types\n                  ],\n                  \"key_filters\": [{ // optional\n                    \"type\": \"suffix\",\n                    \"value\": \"yourfile.json\"\n                  },\n                  {\n                    \"type\": \"prefix\",\n                    \"value\": \"prefix/for/your/object\"\n                  }]\n               }\n            }],\n       ...\n    }\n}\n```\n\nand then:\n\n    $ zappa schedule production\n\nand now your function will execute every time a new upload appears in your bucket!\n\nto access the key's information in your application context, you'll want `process_upload_function` to look something like this:\n\n```python\nimport boto3\ns3_client = boto3.client('s3')\n\ndef process_upload_function(event, context):\n    \"\"\"\n    process a file upload.\n    \"\"\"\n\n    # get the uploaded file's information\n    bucket = event['records'][0]['s3']['bucket']['name'] # will be `my-bucket`\n    key = event['records'][0]['s3']['object']['key'] # will be the file path of whatever file was uploaded.\n\n    # get the bytes from s3\n    s3_client.download_file(bucket, key, '/tmp/' + key) # download this file to writable tmp space.\n    file_bytes = open('/tmp/' + key).read()\n```\n\nsimilarly, for a [simple notification service](https://aws.amazon.com/sns/) event:\n\n```javascript\n        \"events\": [\n            {\n                \"function\": \"your_module.your_function\",\n                \"event_source\": {\n                    \"arn\":  \"arn:aws:sns:::your-event-topic-arn\",\n                    \"events\": [\n                        \"sns:publish\"\n                    ]\n                }\n            }\n        ]\n```\n\noptionally you can add [sns message filters](http://docs.aws.amazon.com/sns/latest/dg/message-filtering.html):\n\n```javascript\n        \"events\": [\n            {\n                \"function\": \"your_module.your_function\",\n                \"event_source\": {\n                    \"arn\":  \"arn:aws:sns:::your-event-topic-arn\",\n                    \"filters\": {\n                        \"interests\": [\"python\", \"aws\", \"zappa\"],\n                        \"version\": [\"1.0\"]\n                    },\n                    ...\n                }\n            }\n        ]\n```\n\n[dynamodb](http://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html) and [kinesis](http://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html) are slightly different as it is not event based but pulling from a stream:\n\n```javascript\n       \"events\": [\n           {\n               \"function\": \"replication.replicate_records\",\n               \"event_source\": {\n                    \"arn\":  \"arn:aws:dynamodb:us-east-1:1234554:table/yourtable/stream/2016-05-11t00:00:00.000\",\n                    \"starting_position\": \"trim_horizon\", // supported values: trim_horizon, latest\n                    \"batch_size\": 50, // max: 1000\n                    \"enabled\": true // default is false\n               }\n           }\n       ]\n```\n\n[sqs](https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html) is also pulling messages from a stream.  at this time, [only \"standard\" queues can trigger lambda events, not \"fifo\" queues](https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html).  read the aws documentation carefully since lambda calls the sqs deletemessage api on your behalf once your function completes successfully.\n\n```javascript\n       \"events\": [\n           {\n               \"function\": \"your_module.process_messages\",\n               \"event_source\": {\n                    \"arn\":  \"arn:aws:sqs:us-east-1:12341234:your-queue-name-arn\",\n                    \"batch_size\": 10, // max: 10. use 1 to trigger immediate processing\n                    \"enabled\": true // default is false\n               }\n           }\n       ]\n```\n\nfor configuring lex bot's intent triggered events:\n```javascript\n    \"bot_events\": [\n        {\n            \"function\": \"lexbot.handlers.book_appointment.handler\",\n            \"event_source\": {\n                \"arn\": \"arn:aws:lex:us-east-1:01234123123:intent:testlexeventnames:$latest\", // optional. in future it will be used to configure the intent\n                \"intent\":\"intentname\", // name of the bot event configured\n                \"invocation_source\":\"dialogcodehook\", // either fulfillmentcodehook or dialogcodehook\n            }\n        }\n    ]\n\n```\n\nevents can also take keyword arguments:\n```javascript\n       \"events\": [\n            {\n                \"function\": \"your_module.your_recurring_function\", // the function to execute\n                \"kwargs\": {\"key\": \"val\", \"key2\": \"val2\"},  // keyword arguments to pass. these are available in the event\n                \"expression\": \"rate(1 minute)\" // when to execute it (in cron or rate format)\n            }\n       ]\n```\n\nto get the keyword arguments you will need to look inside the event dictionary:\n\n```python\ndef your_recurring_function(event, context):\n    my_kwargs = event.get(\"kwargs\")  # dict of kwargs given in zappa_settings file\n\n```\n\n\nyou can find more [example event sources here](http://docs.aws.amazon.com/lambda/latest/dg/eventsources.html).\n\n## asynchronous task execution\n\nzappa also now offers the ability to seamlessly execute functions asynchronously in a completely separate aws lambda instance!\n\nfor example, if you have a flask api for ordering a pie, you can call your `bake` function seamlessly in a completely separate lambda instance by using the `zappa.asynchronous.task` decorator like so:\n\n```python\nfrom flask import flask\nfrom zappa.asynchronous import task\napp = flask(__name__)\n\n@task\ndef make_pie():\n    \"\"\" this takes a long time! \"\"\"\n    ingredients = get_ingredients()\n    pie = bake(ingredients)\n    deliver(pie)\n\n@app.route('/api/order/pie')\ndef order_pie():\n    \"\"\" this returns immediately! \"\"\"\n    make_pie()\n    return \"your pie is being made!\"\n\n```\n\nand that's it! your api response will return immediately, while the `make_pie` function executes in a completely different lambda instance.\n\nwhen calls to @task decorated functions or the zappa.asynchronous.run command occur outside of lambda, such as your local dev environment,\nthe functions will execute immediately and locally. the zappa asynchronous functionality only works\nwhen in the lambda environment or when specifying [remote invocations](https://github.com/zappa/zappa#remote-invocations).\n\n### catching exceptions\nputting a try..except block on an asynchronous task like this:\n\n```python\n@task\ndef make_pie():\n    try:\n        ingredients = get_ingredients()\n        pie = bake(ingredients)\n        deliver(pie)\n    except fault as error:\n        \"\"\"send an email\"\"\"\n    ...\n    return response('web services down', status=503)\n```\n\nwill cause an email to be sent twice for the same error. see [asynchronous retries at aws](https://docs.aws.amazon.com/lambda/latest/dg/retries-on-errors.html). to work around this side-effect, and have the fault handler execute only once, change the return value to:\n\n```python\n@task\ndef make_pie():\n    try:\n        \"\"\"code block\"\"\"\n    except fault as error:\n        \"\"\"send an email\"\"\"\n    ...\n    return {} #or return true\n```\n\n### task sources\n\nby default, this feature uses direct aws lambda invocation. you can instead use aws simple notification service as the task event source by using the `task_sns` decorator, like so:\n\n```python\nfrom zappa.asynchronous import task_sns\n@task_sns\n```\n\nusing sns also requires setting the following settings in your `zappa_settings`:\n\n```javascript\n{\n  \"dev\": {\n    ..\n      \"async_source\": \"sns\", // source of async tasks. defaults to \"lambda\"\n      \"async_resources\": true, // create the sns topic to use. defaults to true.\n    ..\n    }\n}\n```\n\nthis will automatically create and subscribe to the sns topic the code will use when you call the `zappa schedule` command.\n\nusing sns will also return a message id in case you need to track your invocations.\n\n### direct invocation\n\nyou can also use this functionality without a decorator by passing your function to `zappa.asynchronous.run`, like so:\n\n```python\nfrom zappa.asynchronous import run\n\nrun(your_function, args, kwargs) # using lambda\nrun(your_function, args, kwargs, service='sns') # using sns\n```\n\n### remote invocations\n\nby default, zappa will use lambda's current function name and current aws region. if you wish to invoke a lambda with\n  a different function name/region or invoke your lambda from outside of lambda, you must specify the\n  `remote_aws_lambda_function_name` and `remote_aws_region` arguments so that the application knows which function and\n  region to use. for example, if some part of our pizza making application had to live on an ec2 instance, but we\n  wished to call the make_pie() function on its own lambda instance, we would do it as follows:\n\n ```python\n@task(remote_aws_lambda_function_name='pizza-pie-prod', remote_aws_region='us-east-1')\ndef make_pie():\n    \"\"\" this takes a long time! \"\"\"\n    ingredients = get_ingredients()\n    pie = bake(ingredients)\n    deliver(pie)\n\n```\nif those task() parameters were not used, then ec2 would execute the function locally. these same\n `remote_aws_lambda_function_name` and `remote_aws_region` arguments can be used on the zappa.asynchronous.run() function as well.\n\n### restrictions\n\nthe following restrictions to this feature apply:\n\n* functions must have a clean import path -- i.e. no closures, lambdas, or methods.\n* `args` and `kwargs` must be json-serializable.\n* the json-serialized arguments must be within the size limits for lambda (256k) or sns (256k) events.\n\nall of this code is still backwards-compatible with non-lambda environments - it simply executes in a blocking fashion and returns the result.\n\n### running tasks in a vpc\n\nif you're running zappa in a virtual private cloud (vpc), you'll need to configure your subnets to allow your lambda to communicate with services inside your vpc as well as the public internet. a minimal setup requires two subnets.\n\nin __subnet-a__:\n* create a nat\n* create an internet gateway\n* in the route table, create a route pointing the internet gateway to 0.0.0.0/0.\n\nin __subnet-b__:\n* place your lambda function\n* in the route table, create a route pointing the nat that belongs to __subnet-a__ to 0.0.0.0/0.\n\nyou can place your lambda in multiple subnets that are configured the same way as __subnet-b__ for high availability.\n\nsome helpful resources are [this tutorial](http://docs.aws.amazon.com/amazonrds/latest/userguide/chap_tutorials.webserverdb.createvpc.html), [this other tutorial](https://gist.github.com/reggi/dc5f2620b7b4f515e68e46255ac042a7) and [this aws doc page](http://docs.aws.amazon.com/lambda/latest/dg/vpc.html#vpc-internet).\n\n### responses\n\nit is possible to capture the responses of asynchronous tasks.\n\nzappa uses dynamodb as the backend for these.\n\nto capture responses, you must configure a `async_response_table` in `zappa_settings`. this is the dynamodb table name. then, when decorating with `@task`, pass `capture_response=true`.\n\nasync responses are assigned a `response_id`. this is returned as a property of the `lambdaasyncresponse` (or `snsasyncresponse`) object that is returned by the `@task` decorator.\n\nexample:\n\n```python\nfrom zappa.asynchronous import task, get_async_response\nfrom flask import flask, make_response, abort, url_for, redirect, request, jsonify\nfrom time import sleep\n\napp = flask(__name__)\n\n@app.route('/payload')\ndef payload():\n    delay = request.args.get('delay', 60)\n    x = longrunner(delay)\n    return redirect(url_for('response', response_id=x.response_id))\n\n@app.route('/async-response/<response_id>')\ndef response(response_id):\n    response = get_async_response(response_id)\n    if response is none:\n        abort(404)\n\n    if response['status'] == 'complete':\n        return jsonify(response['response'])\n\n    sleep(5)\n\n    return \"not yet ready. redirecting.\", 302, {\n        'content-type': 'text/plain; charset=utf-8',\n        'location': url_for('response', response_id=response_id, backoff=5),\n        'x-redirect-reason': \"not yet ready.\",\n    }\n\n@task(capture_response=true)\ndef longrunner(delay):\n    sleep(float(delay))\n    return {'message': \"it took {} seconds to generate this.\".format(delay)}\n\n```\n\n## advanced settings\n\nthere are other settings that you can define in your local settings\nto change zappa's behavior. use these at your own risk!\n\n```javascript\n {\n    \"dev\": {\n        \"additional_text_mimetypes\": [], // allows you to provide additional mimetypes to be handled as text when binary_support is true.\n        \"alb_enabled\": false, // enable provisioning of application load balancing resources. if set to true, you _must_ fill out the alb_vpc_config option as well.\n        \"alb_vpc_config\": {\n            \"certificatearn\": \"your_acm_certificate_arn\", // acm certificate arn for alb\n            \"subnetids\": [], // list of subnets for alb\n            \"securitygroupids\": [] // list of security groups for alb\n        },\n        \"api_key_required\": false, // enable securing api gateway endpoints with x-api-key header (default false)\n        \"api_key\": \"your_api_key_id\", // optional, use an existing api key. the option \"api_key_required\" must be true to apply\n        \"apigateway_enabled\": true, // set to false if you don't want to create an api gateway resource. default true.\n        \"apigateway_description\": \"my funky application!\", // define a custom description for the api gateway console. default none.\n        \"assume_policy\": \"my_assume_policy.json\", // optional, iam assume policy json file\n        \"attach_policy\": \"my_attach_policy.json\", // optional, iam attach policy json file\n        \"apigateway_policy\": \"my_apigateway_policy.json\", // optional, api gateway resource policy json file\n        \"async_source\": \"sns\", // source of async tasks. defaults to \"lambda\"\n        \"async_resources\": true, // create the sns topic and dynamodb table to use. defaults to true.\n        \"async_response_table\": \"your_dynamodb_table_name\",  // the dynamodb table name to use for captured async responses; defaults to none (can't capture)\n        \"async_response_table_read_capacity\": 1,  // dynamodb table read capacity; defaults to 1\n        \"async_response_table_write_capacity\": 1,  // dynamodb table write capacity; defaults to 1\n        \"aws_endpoint_urls\": { \"aws_service_name\": \"endpoint_url\" }, // a dictionary of endpoint_urls that emulate the appropriate service.  usually used for testing, for instance with `localstack`.\n        \"aws_environment_variables\" : {\"your_key\": \"your_value\"}, // a dictionary of environment variables that will be available to your deployed app via aws lambdas native environment variables. see also \"environment_variables\" and \"remote_env\" . default {}.\n        \"aws_kms_key_arn\": \"your_aws_kms_key_arn\", // your aws kms key arn\n        \"aws_region\": \"aws-region-name\", // optional, uses region set in profile or environment variables if not set here,\n        \"binary_support\": true, // enable automatic mime-type based response encoding through api gateway. default true.\n        \"callbacks\": { // call custom functions during the local zappa deployment/update process\n            \"settings\": \"my_app.settings_callback\", // after loading the settings\n            \"zip\": \"my_app.zip_callback\", // after creating the package\n            \"post\": \"my_app.post_callback\", // after command has executed\n        },\n        \"cache_cluster_enabled\": false, // use apigw cache cluster (default false)\n        \"cache_cluster_size\": 0.5, // apigw cache cluster size (default 0.5)\n        \"cache_cluster_ttl\": 300, // apigw cache cluster time-to-live (default 300)\n        \"cache_cluster_encrypted\": false, // whether or not apigw cache cluster encrypts data (default false)\n        \"certificate\": \"my_cert.crt\", // ssl certificate file location. used to manually certify a custom domain\n        \"certificate_key\": \"my_key.key\", // ssl key file location. used to manually certify a custom domain\n        \"certificate_chain\": \"my_cert_chain.pem\", // ssl certificate chain file location. used to manually certify a custom domain\n        \"certificate_arn\": \"arn:aws:acm:us-east-1:1234512345:certificate/aaaa-bbb-cccc-dddd\", // acm certificate arn (needs to be in us-east-1 region).\n        \"cloudwatch_log_level\": \"off\", // enables/configures a level of logging for the given staging. available options: \"off\", \"info\", \"error\", default \"off\".\n        \"cloudwatch_data_trace\": false, // logs all data about received events. default false.\n        \"cloudwatch_metrics_enabled\": false, // additional metrics for the api gateway. default false.\n        \"cognito\": { // for cognito event triggers\n            \"user_pool\": \"user-pool-id\", // user pool id from aws cognito\n            \"triggers\": [{\n                \"source\": \"presignup_signup\", // triggersource from http://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools-working-with-aws-lambda-triggers.html#cognito-user-pools-lambda-trigger-syntax-pre-signup\n                \"function\": \"my_app.pre_signup_function\"\n            }]\n        },\n        \"context_header_mappings\": { \"http_header_name\": \"api_gateway_context_variable\" }, // a dictionary mapping http header names to api gateway context variables\n        \"cors\": false, // enable cross-origin resource sharing. default false. if true, simulates the \"enable cors\" button on the api gateway console. can also be a dictionary specifying lists of \"allowed_headers\", \"allowed_methods\", and string of \"allowed_origin\"\n        \"dead_letter_arn\": \"arn:aws:<sns/sqs>:::my-topic/queue\", // optional dead letter configuration for when lambda async invoke fails thrice\n        \"debug\": true, // print zappa configuration errors tracebacks in the 500. default true.\n        \"delete_local_zip\": true, // delete the local zip archive after code updates. default true.\n        \"delete_s3_zip\": true, // delete the s3 zip archive. default true.\n        \"django_settings\": \"your_project.production_settings\", // the modular path to your django project's settings. for django projects only.\n        \"domain\": \"yourapp.yourdomain.com\", // required if you're using a domain\n        \"base_path\": \"your-base-path\", // optional base path for api gateway custom domain base path mapping. default none. not supported for use with application load balancer event sources.\n        \"environment_variables\": {\"your_key\": \"your_value\"}, // a dictionary of environment variables that will be available to your deployed app. see also \"remote_env\" and \"aws_environment_variables\". default {}.\n        \"events\": [\n            {   // recurring events\n                \"function\": \"your_module.your_recurring_function\", // the function to execute\n                \"expression\": \"rate(1 minute)\" // when to execute it (in cron or rate format)\n            },\n            {   // aws reactive events\n                \"function\": \"your_module.your_reactive_function\", // the function to execute\n                \"event_source\": {\n                    \"arn\":  \"arn:aws:s3:::my-bucket\", // the arn of this event source\n                    \"events\": [\n                        \"s3:objectcreated:*\" // the specific event to execute in response to.\n                    ]\n                }\n            }\n        ],\n        \"endpoint_configuration\": [\"edge\", \"regional\", \"private\"],  // specify apigateway endpoint none (default) or list `edge`, `region`, `private`\n        \"exception_handler\": \"your_module.report_exception\", // function that will be invoked in case zappa sees an unhandled exception raised from your code\n        \"exclude\": [\"file.gz\", \"tests\"], // a list of filename patterns to exclude from the archive (see `fnmatch` module for patterns).\n        \"exclude_glob\": [\"*.gz\", \"*.rar\", \"tests/**/*\"], // a list of glob patterns to exclude from the archive. to exclude boto3 and botocore (available in an older version on lambda), add \"boto3*\" and \"botocore*\".\n        \"extends\": \"stage_name\", // duplicate and extend another stage's settings. for example, `dev-asia` could extend from `dev-common` with a different `s3_bucket` value.\n        \"extra_permissions\": [{ // attach any extra permissions to this policy. default none\n            \"effect\": \"allow\",\n            \"action\": [\"rekognition:*\"], // aws service arn\n            \"resource\": \"*\"\n        }],\n        \"iam_authorization\": false, // optional, use iam to require request signing. default false. note that enabling this will override the authorizer configuration.\n        \"include\": [\"your_special_library_to_load_at_handler_init\"], // load special libraries into pythonpath at handler init that certain modules cannot find on path\n        \"authorizer\": {\n            \"function\": \"your_module.your_auth_function\", // local function to run for token validation. for more information about the function see below.\n            \"arn\": \"arn:aws:lambda:<region>:<account_id>:function:<function_name>\", // existing lambda function to run for token validation.\n            \"result_ttl\": 300, // optional. default 300. the time-to-live (ttl) period, in seconds, that specifies how long api gateway caches authorizer results. currently, the maximum ttl value is 3600 seconds.\n            \"token_header\": \"authorization\", // optional. default 'authorization'. the name of a custom authorization header containing the token that clients submit as part of their requests.\n            \"validation_expression\": \"^bearer \\\\w+$\", // optional. a validation expression for the incoming token, specify a regular expression.\n        },\n        \"keep_warm\": true, // create cloudwatch events to keep the server warm. default true. to remove, set to false and then `unschedule`.\n        \"keep_warm_expression\": \"rate(4 minutes)\", // how often to execute the keep-warm, in cron and rate format. default 4 minutes.\n        \"lambda_description\": \"your description\", // however you want to describe your project for the aws console. default \"zappa deployment\".\n        \"lambda_handler\": \"your_custom_handler\", // the name of lambda handler. default: handler.lambda_handler\n        \"layers\": [\"arn:aws:lambda:<region>:<account_id>:layer:<layer_name>:<layer_version>\"], // optional lambda layers\n        \"lambda_concurrency\": 10, // sets the maximum number of simultaneous executions for a function, and reserves capacity for that concurrency level. default is none.\n        \"lets_encrypt_key\": \"s3://your-bucket/account.key\", // let's encrypt account key path. can either be an s3 path or a local file path.\n        \"log_level\": \"debug\", // set the zappa log level. can be one of critical, error, warning, info and debug. default: debug\n        \"manage_roles\": true, // have zappa automatically create and define iam execution roles and policies. default true. if false, you must define your own iam role and role_name setting.\n        \"memory_size\": 512, // lambda function memory in mb. default 512.\n        \"ephemeral_storage\": { \"size\": 512 }, // lambda function ephemeral_storage size in mb, default 512, max 10240\n        \"num_retained_versions\":null, // indicates the number of old versions to retain for the lambda. if absent, keeps all the versions of the function.\n        \"payload_compression\": true, // whether or not to enable api gateway payload compression (default: true)\n        \"payload_minimum_compression_size\": 0, // the threshold size (in bytes) below which payload compression will not be applied (default: 0)\n        \"prebuild_script\": \"your_module.your_function\", // function to execute before uploading code\n        \"profile_name\": \"your-profile-name\", // aws profile credentials to use. default 'default'. removing this setting will use the aws_access_key_id and aws_secret_access_key environment variables instead.\n        \"project_name\": \"myproject\", // the name of the project as it appears on aws. defaults to a slugified `pwd`.\n        \"remote_env\": \"s3://my-project-config-files/filename.json\", // optional file in s3 bucket containing a flat json object which will be used to set custom environment variables.\n        \"role_name\": \"mylambdarole\", // name of zappa execution role. default <project_name>-<env>-zappaexecutionrole. to use a different, pre-existing policy, you must also set manage_roles to false.\n        \"role_arn\": \"arn:aws:iam::12345:role/app-zappalambdaexecutionrole\", // arn of zappa execution role. default to none. to use a different, pre-existing policy, you must also set manage_roles to false. this overrides role_name. use with temporary credentials via getfederationtoken.\n        \"route53_enabled\": true, // have zappa update your route53 hosted zones when certifying with a custom domain. default true.\n        \"runtime\": \"python3.11\", // python runtime to use on lambda. can be one of \"python3.7\", \"python3.8\", \"python3.9\", or \"python3.10\", or \"python3.11\". defaults to whatever the current python being used is.\n        \"s3_bucket\": \"dev-bucket\", // zappa zip bucket,\n        \"slim_handler\": false, // useful if project >50m. set true to just upload a small handler to lambda and load actual project from s3 at runtime. default false.\n        \"settings_file\": \"~/projects/myapp/settings/dev_settings.py\", // server side settings file location,\n        \"tags\": { // attach additional tags to aws resources\n            \"key\": \"value\",  // example key and value\n            \"key2\": \"value2\",\n            },\n        \"timeout_seconds\": 30, // maximum lifespan for the lambda function (default 30, max 900.)\n        \"touch\": true, // get the production url upon initial deployment (default true)\n        \"touch_path\": \"/\", // the endpoint path to get when checking the initial deployment (default \"/\")\n        \"use_precompiled_packages\": true, // if possible, use c-extension packages which have been pre-compiled for aws lambda. default true.\n        \"vpc_config\": { // optional virtual private cloud (vpc) configuration for lambda function\n            \"subnetids\": [ \"subnet-12345678\" ], // note: not all availability zones support lambda!\n            \"securitygroupids\": [ \"sg-12345678\" ]\n        },\n        \"xray_tracing\": false // optional, enable aws x-ray tracing on your lambda function.\n    }\n}\n```\n\n#### yaml settings\n\nif you prefer yaml over json, you can also use a `zappa_settings.yml`, like so:\n\n```yaml\n---\ndev:\n  app_function: your_module.your_app\n  s3_bucket: your-code-bucket\n  events:\n  - function: your_module.your_function\n    event_source:\n      arn: arn:aws:s3:::your-event-bucket\n      events:\n      - s3:objectcreated:*\n```\n\nyou can also supply a custom settings file at any time with the `-s` argument, ex:\n\n```\n$ zappa deploy dev -s my-custom-settings.yml\n```\n\nsimilarly, you can supply a `zappa_settings.toml` file:\n\n```toml\n[dev]\n  app_function = \"your_module.your_app\"\n  s3_bucket = \"your-code-bucket\"\n```\n\n## advanced usage\n\n### keeping the server warm\n\nzappa will automatically set up a regularly occurring execution of your application in order to keep the lambda function warm. this can be disabled via the `keep_warm` setting.\n\n#### serving static files / binary uploads\n\nzappa is now able to serve and receive binary files, as detected by their mime-type.\n\nhowever, generally zappa is designed for running your application code, not for serving static web assets. if you plan on serving custom static assets in your web application (css/javascript/images/etc.,), you'll likely want to use a combination of aws s3 and aws cloudfront.\n\nyour web application framework will likely be able to handle this for you automatically. for flask, there is [flask-s3](https://github.com/e-dard/flask-s3), and for django, there is [django-storages](https://django-storages.readthedocs.io/en/latest/).\n\nsimilarly, you may want to design your application so that static binary uploads go [directly to s3](http://docs.aws.amazon.com/awsjavascriptsdk/guide/browser-examples.html#uploading_a_local_file_using_the_file_api), which then triggers an event response defined in your `events` setting! that's thinking serverlessly!\n\n### enabling cors\n\nthe simplest way to enable cors (cross-origin resource sharing) for your zappa application is to set `cors` to `true` in your zappa settings file and update, which is the equivalent of pushing the \"enable cors\" button in the aws api gateway console. this is disabled by default, but you may wish to enable it for apis which are accessed from other domains, etc.\n\nyou can also simply handle cors directly in your application. your web framework will probably have an extension to do this, such as [django-cors-headers](https://github.com/ottoyiu/django-cors-headers) or [flask-cors](https://github.com/corydolphin/flask-cors). using these will make your code more portable.\n\n### large projects\n\naws currently limits lambda zip sizes to 50 megabytes. if your project is larger than that, set `slim_handler: true` in your `zappa_settings.json`. in this case, your fat application package will be replaced with a small handler-only package. the handler file then pulls the rest of the large project down from s3 at run time! the initial load of the large project may add to startup overhead, but the difference should be minimal on a warm lambda function. note that this will also eat into the storage space of your application function. note that aws [supports](https://aws.amazon.com/blogs/compute/using-larger-ephemeral-storage-for-aws-lambda/) custom `/tmp` directory storage size in a range of 512 - 10240 mb. use `ephemeral_storage` in `zappa_settings.json` to adjust to your needs if your project is larger than default 512 mb.\n\n### enabling bash completion\n\nbash completion can be enabled by adding the following to your .bashrc:\n\n```bash\n  eval \"$(register-python-argcomplete zappa)\"\n```\n\n`register-python-argcomplete` is provided by the argcomplete python package. if this package was installed in a virtualenv\nthen the command must be run there. alternatively you can execute:\n\n  activate-global-python-argcomplete --dest=- > file\n\nthe file's contents should then be sourced in e.g. ~/.bashrc.\n\n### enabling secure endpoints on api gateway\n\n#### api key\n\nyou can use the `api_key_required` setting to generate an api key to all the routes of your api gateway. the process is as follows:\n1. deploy/redeploy (update won't work) and write down the *id* for the key that has been created\n2. go to aws console > amazon api gateway and\n    * select \"api keys\" and find the key *value* (for example `key_value`)\n    * select \"usage plans\", create a new usage plan and link the api key and the api that zappa has created for you\n3. send a request where you pass the key value as a header called `x-api-key` to access the restricted endpoints (for example with curl: `curl --header \"x-api-key: key_value\"`). note that without the x-api-key header, you will receive a 403.\n\n#### iam policy\n\nyou can enable iam-based (v4 signing) authorization on an api by setting the `iam_authorization` setting to `true`. your api will then require signed requests and access can be controlled via [iam policy](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-iam-policy-examples.html). unsigned requests will receive a 403 response, as will requesters who are not authorized to access the api. enabling this will override the authorizer configuration (see below).\n\n#### api gateway lambda authorizers\nif you deploy an api endpoint with zappa, you can take advantage of [api gateway lambda authorizers](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html) to implement a token-based authentication - all you need to do is to provide a function to create the required output, zappa takes care of the rest. a good start for the function is the [aws labs blueprint example](https://github.com/awslabs/aws-apigateway-lambda-authorizer-blueprints/blob/master/blueprints/python/api-gateway-authorizer-python.py).\n\nif you are wondering for what you would use an authorizer, here are some potential use cases:\n\n1. call out to oauth provider\n2. decode a jwt token inline\n3. lookup in a self-managed db (for example dynamodb)\n\nzappa can be configured to call a function inside your code to do the authorization, or to call some other existing lambda function (which lets you share the authorizer between multiple lambdas). you control the behavior by specifying either the `arn` or `function_name` values in the `authorizer` settings block.\n\nfor example, to get the cognito identity, add this to a `zappa_settings.yaml`:\n\n```yaml\n  context_header_mappings:\n    user_id: authorizer.user_id\n```\n\nwhich can now be accessed in flask like this:\n\n```python\nfrom flask import request\n\n@route('/hello')\ndef hello_world:\n   print(request.headers.get('user_id'))\n```\n\n#### cognito user pool authorizer\n\nyou can also use aws cognito user pool authorizer by adding:\n\n```javascript\n{\n    \"authorizer\": {\n        \"type\": \"cognito_user_pools\",\n        \"provider_arns\": [\n            \"arn:aws:cognito-idp:{region}:{account_id}:userpool/{user_pool_id}\"\n        ]\n    }\n}\n```\n\n#### api gateway resource policy\n\nyou can also use api gateway resource policies. example of ip whitelisting:\n\n```javascript\n{\n    \"version\": \"2012-10-17\",\n    \"statement\": [\n        {\n            \"effect\": \"allow\",\n            \"principal\": \"*\",\n            \"action\": \"execute-api:invoke\",\n            \"resource\": \"execute-api:/*\",\n            \"condition\": {\n                \"ipaddress\": {\n                    \"aws:sourceip\": [\n                        \"1.2.3.4/32\"\n                    ]\n                }\n            }\n        }\n    ]\n}\n```\n\n### setting environment variables\n\n#### local environment variables\n\nif you want to set local environment variables for a deployment stage, you can simply set them in your `zappa_settings.json`:\n\n```javascript\n{\n    \"dev\": {\n        ...\n        \"environment_variables\": {\n            \"your_key\": \"your_value\"\n        }\n    },\n    ...\n}\n```\n\nyou can then access these inside your application with:\n\n```python\nimport os\nyour_value = os.environ.get('your_key')\n```\n\nif your project needs to be aware of the type of environment you're deployed to, you'll also be able to get `servertype` (aws lambda), `framework` (zappa), `project` (your project name) and `stage` (_dev_, _production_, etc.) variables at any time.\n\n#### remote aws environment variables\n\nif you want to use native aws lambda environment variables you can use the `aws_environment_variables` configuration setting. these are useful as you can easily change them via the aws lambda console or cli at runtime. they are also useful for storing sensitive credentials and to take advantage of kms encryption of environment variables.\n\n\nduring development, you can add your zappa defined variables to your locally running app by, for example, using the below (for django, to manage.py).\n\n```python\nif 'servertype' in os.environ and os.environ['servertype'] == 'aws lambda':\n    import json\n    import os\n    json_data = open('zappa_settings.json')\n    env_vars = json.load(json_data)['dev']['environment_variables']\n    for key, val in env_vars.items():\n        os.environ[key] = val\n\n```\n\n#### remote environment variables\n\nany environment variables that you have set outside of zappa (via aws lambda console or cli) will remain as they are when running `update`, unless they are also in `aws_environment_variables`, in which case the remote value will be overwritten by the one in the settings file. if you are using kms-encrypted aws environment variables, you can set your kms key arn in the `aws_kms_key_arn` setting. make sure that the values you set are encrypted in such case.\n\n_note: if you rely on these as well as `environment_variables`, and you have the same key names, then those in `environment_variables` will take precedence as they are injected in the lambda handler._\n\n#### remote environment variables (via an s3 file)\n\n_s3 remote environment variables were added to zappa before aws introduced native environment variables for lambda (via the console and cli). before going down this route check if above make more sense for your usecase._\n\n\nif you want to use remote environment variables to configure your application (which is especially useful for things like sensitive credentials), you can create a file and place it in an s3 bucket to which your zappa application has access. to do this, add the `remote_env` key to zappa_settings pointing to a file containing a flat json object, so that each key-value pair on the object will be set as an environment variable and value whenever a new lambda instance spins up.\n\nfor example, to ensure your application has access to the database credentials without storing them in your version control, you can add a file to s3 with the connection string and load it into the lambda environment using the `remote_env` configuration setting.\n\nsuper-secret-config.json (uploaded to my-config-bucket):\n```javascript\n{\n    \"db_connection_string\": \"super-secret:database\"\n}\n```\n\nzappa_settings.json:\n```javascript\n{\n    \"dev\": {\n        ...\n        \"remote_env\": \"s3://my-config-bucket/super-secret-config.json\",\n    },\n    ...\n}\n```\n\nnow in your application you can use:\n```python\nimport os\ndb_string = os.environ.get('db_connection_string')\n```\n\n### api gateway context variables\n\nif you want to map an api gateway context variable (http://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-mapping-template-reference.html) to an http header you can set up the mapping in `zappa_settings.json`:\n\n```javascript\n{\n    \"dev\": {\n        ...\n        \"context_header_mappings\": {\n            \"http_header_name\": \"api_gateway_context_variable\"\n        }\n    },\n    ...\n}\n```\n\nfor example, if you want to expose the $context.identity.cognitoidentityid variable as the http header cognitoidentityid, and $context.stage as apistage, you would have:\n\n```javascript\n{\n    \"dev\": {\n        ...\n        \"context_header_mappings\": {\n            \"cognitoidentityid\": \"identity.cognitoidentityid\",\n            \"apistage\": \"stage\"\n        }\n    },\n    ...\n}\n```\n\n### catching unhandled exceptions\n\nby default, if an _unhandled_ exception happens in your code, zappa will just print the stacktrace into a cloudwatch log. if you wish to use an external reporting tool to take note of those exceptions, you can use the `exception_handler` configuration option.\n\nzappa_settings.json:\n```javascript\n{\n    \"dev\": {\n        ...\n        \"exception_handler\": \"your_module.unhandled_exceptions\",\n    },\n    ...\n}\n```\n\nthe function has to accept three arguments: exception, event, and context:\n\nyour_module.py\n```python\ndef unhandled_exceptions(e, event, context):\n    send_to_raygun(e, event)  # gather data you need and send\n    return true # prevent invocation retry\n```\nyou may still need a similar exception handler inside your application, this is just a way to catch exception which happen at the zappa/wsgi layer (typically event-based invocations, misconfigured settings, bad lambda packages, and permissions issues).\n\nby default, aws lambda will attempt to retry an event based (non-api gateway, e.g. cloudwatch) invocation if an exception has been thrown. however, you can prevent this by returning true, as in example above, so zappa that will not re-raise the uncaught exception, thus preventing aws lambda from retrying the current invocation.\n\n### using custom aws iam roles and policies\n\n#### custom aws iam roles and policies for deployment\n\nyou can specify which _local_ profile to use for deploying your zappa application by defining\nthe `profile_name` setting, which will correspond to a profile in your aws credentials file.\n\n#### custom aws iam roles and policies for execution\n\nthe default iam policy created by zappa for executing the lambda is very permissive.\nit grants access to all actions for\nall resources for types cloudwatch, s3, kinesis, sns, sqs, dynamodb, and route53; lambda:invokefunction\nfor all lambda resources; put to all x-ray resources; and all network interface operations to all ec2\nresources. while this allows most lambdas to work correctly with no extra permissions, it is\ngenerally not an acceptable set of permissions for most continuous integration pipelines or\nproduction deployments. instead, you will probably want to manually manage your iam policies.\n\nto manually define the policy of your lambda execution role, you must set *manage_roles* to false and define\neither the *role_name* or *role_arn* in your zappa settings file.\n\n```javascript\n{\n    \"dev\": {\n        ...\n        \"manage_roles\": false, // disable zappa client managing roles.\n        \"role_name\": \"mylambdarole\", // name of your zappa execution role. optional, default: <project_name>-<env>-zappaexecutionrole.\n        \"role_arn\": \"arn:aws:iam::12345:role/app-zappalambdaexecutionrole\", // arn of your zappa execution role. optional.\n        ...\n    },\n    ...\n}\n```\n\nongoing discussion about the minimum policy requirements necessary for a zappa deployment [can be found here](https://github.com/miserlou/zappa/issues/244).\na more robust solution to managing these entitlements will likely be implemented soon.\n\nto add permissions to the default zappa execution policy, use the `extra_permissions` setting:\n\n```javascript\n{\n    \"dev\": {\n        ...\n        \"extra_permissions\": [{ // attach any extra permissions to this policy.\n            \"effect\": \"allow\",\n            \"action\": [\"rekognition:*\"], // aws service arn\n            \"resource\": \"*\"\n        }]\n    },\n    ...\n}\n```\n\n### aws x-ray\n\nzappa can enable [aws x-ray](https://aws.amazon.com/xray/) support on your function with a configuration setting:\n\n```javascript\n{\n    \"dev\": {\n        ...\n        \"xray_tracing\": true\n    },\n    ...\n}\n```\n\nthis will enable it on the lambda function and allow you to instrument your code with x-ray.\nfor example, with flask:\n\n```python\nfrom aws_xray_sdk.core import xray_recorder\n\napp = flask(__name__)\n\nxray_recorder.configure(service='my_app_name')\n\n@route('/hello')\n@xray_recorder.capture('hello')\ndef hello_world:\n    return 'hello'\n```\n\nyou may use the capture decorator to create subsegments around functions, or `xray_recorder.begin_subsegment('subsegment_name')` and `xray_recorder.end_subsegment()` within a function. the official [x-ray documentation for python](http://docs.aws.amazon.com/xray-sdk-for-python/latest/reference/) has more information on how to use this with your code.\n\nnote that you may create subsegments in your code but an exception will be raised if you try to create a segment, as it is [created by the lambda worker](https://github.com/aws/aws-xray-sdk-python/issues/2). this also means that if you use flask you must not use the [xraymiddleware the documentation suggests](https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-python-middleware.html).\n\n### globally available server-less architectures\n\n\n<p align=\"center\">\n  <a href=\"https://htmlpreview.github.io/?https://github.com/miserlou/talks/blob/master/serverless-london/global.html#0\"><img src=\"http://i.imgur.com/or61qau.png\" alt=\"global zappa slides\"/></a>\n</p>\n<p align=\"center\">\n  <i>click to see <a href=\"https://htmlpreview.github.io/?https://github.com/miserlou/talks/blob/master/serverless-london/global.html#0\">slides from serverlessconf london</a>!</i>\n</p>\n\nduring the `init` process, you will be given the option to deploy your application \"globally.\" this will allow you to deploy your application to all available aws regions simultaneously in order to provide a consistent global speed, increased redundancy, data isolation, and legal compliance. you can also choose to deploy only to \"primary\" locations, the aws regions with `-1` in their names.\n\nto learn more about these capabilities, see [these slides](https://htmlpreview.github.io/?https://github.com/miserlou/talks/blob/master/serverless-london/global.html#0) from serverlessconf london.\n\n### raising aws service limits\n\nout of the box, aws sets a limit of [1000 concurrent executions](http://docs.aws.amazon.com/lambda/latest/dg/limits.html) for your functions. if you start to breach these limits, you may start to see errors like `clienterror: an error occurred (limitexceededexception) when calling the puttargets..\"` or something similar.\n\nto avoid this, you can file a [service ticket](https://console.aws.amazon.com/support/home#/) with amazon to raise your limits up to the many tens of thousands of concurrent executions which you may need. this is a fairly common practice with amazon, designed to prevent you from accidentally creating extremely expensive bug reports. so, before raising your service limits, make sure that you don't have any rogue scripts which could accidentally create tens of thousands of parallel executions that you don't want to pay for.\n\n### dead letter queues\n\nif you want to utilise [aws lambda's dead letter queue feature](http://docs.aws.amazon.com/lambda/latest/dg/dlq.html) simply add the key `dead_letter_arn`, with the value being the complete arn to the corresponding sns topic or sqs queue in your `zappa_settings.json`.\n\nyou must have already created the corresponding sns/sqs topic/queue, and the lambda function execution role must have been provisioned with read/publish/sendmessage access to the dlq resource.\n\n### unique package id\n\nfor monitoring of different deployments, a unique uuid for each package is available in `package_info.json` in the root directory of your application's package.  you can use this information or a hash of this file for such things as tracking errors across different deployments, monitoring status of deployments and other such things on services such as sentry and new relic. the package will contain:\n\n```json\n{\n  \"build_platform\": \"darwin\",\n  \"build_user\": \"frank\",\n  \"build_time\": \"1509732511\",\n  \"uuid\": \"9c2df9e6-30f4-4c0a-ac4d-4ecb51831a74\"\n}\n```\n\n### application load balancer event source\n\nzappa can be used to handle events triggered by application load balancers (alb). this can be useful in a few circumstances:\n- since api gateway has a hard limit of 30 seconds before timing out, you can use an alb for longer running requests.\n- api gateway is billed per-request; therefore, costs can become excessive with high throughput services. albs pricing model makes much more sense financially if you're expecting a lot of traffic to your lambda.\n- albs can be placed within a vpc, which may make more sense for private endpoints than using api gateway's private model (using aws privatelink).\n\nlike api gateway, zappa can automatically provision alb resources for you.  you'll need to add the following to your `zappa_settings`:\n```\n\"alb_enabled\": true,\n\"alb_vpc_config\": {\n    \"certificatearn\": \"arn:aws:acm:us-east-1:[your-account-id]:certificate/[certificate-id]\",\n    \"subnetids\": [\n        // here, you'll want to provide a list of subnets for your alb, eg. 'subnet-02a58266'\n    ],\n    \"securitygroupids\": [\n        // and here, a list of security group ids, eg. 'sg-fbacb791'\n    ]\n}\n```\n\nmore information on using alb as an event source for lambda can be found [here](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/lambda-functions.html).\n\n*an important note*: right now, zappa will provision one lambda to one load balancer, which means using `base_path` along with alb configuration is currently unsupported.\n\n### endpoint configuration\n\napi gateway can be configured to be only accessible in a vpc. to enable this; [configure your vpc to support](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-private-apis.html) then set the `endpoint_configuration` to `private` and set up resource policy on the api gateway. a note about this; if you're using a private endpoint, zappa won't be able to tell if the api is returning a successful status code upon deploy or update, so you'll have to check it manually to ensure your setup is working properly.\n\nfor full list of options for endpoint configuration refer to [api gateway endpointconfiguration documentation](https://docs.aws.amazon.com/awscloudformation/latest/userguide/aws-properties-apigateway-restapi-endpointconfiguration.html)\n\n#### example private api gateway configuration\n\nzappa_settings.json:\n```json\n{\n    \"dev\": {\n        ...\n        \"endpoint_configuration\": [\"private\"],\n        \"apigateway_policy\": \"apigateway_resource_policy.json\",\n        ...\n    },\n    ...\n}\n```\n\napigateway_resource_policy.json:\n```json\n{\n    \"version\": \"2012-10-17\",\n    \"statement\": [\n        {\n            \"effect\": \"deny\",\n            \"principal\": \"*\",\n            \"action\": \"execute-api:invoke\",\n            \"resource\": \"execute-api:/*\",\n            \"condition\": {\n                \"stringnotequals\": {\n                    \"aws:sourcevpc\": \"{{vpcid}}\" // update me\n                }\n            }\n        },\n        {\n            \"effect\": \"allow\",\n            \"principal\": \"*\",\n            \"action\": \"execute-api:invoke\",\n            \"resource\": \"execute-api:/*\"\n        }\n    ]\n}\n```\n\n### cold starts (experimental)\n\nlambda may provide additional resources than provisioned during cold start initialization. set `instantiate_lambda_handler_on_import=true` to instantiate the lambda handler on import. this is an experimental feature - if startup time is critical, look into using provisioned concurrency.\n\n## zappa guides\n\n* [django-zappa tutorial (screencast)](https://www.youtube.com/watch?v=plurbpn0xc8&feature=youtu.be).\n* [using django-zappa, part 1](https://serverlesscode.com/post/zappa-wsgi-for-python/).\n* [using django-zappa, part 2: vpcs](https://serverlesscode.com/post/zappa-wsgi-for-python-pt-2/).\n* [building serverless microservices with zappa and flask](https://gun.io/blog/serverless-microservices-with-zappa-and-flask/)\n* [zappa \u3067 hello world \u3059\u308b\u307e\u3067 (japanese)](http://qiita.com/satoshi_iwashita/items/505492193317819772c7)\n* [how to deploy zappa with cloudfront, rds and vpc](https://jinwright.net/how-deploy-serverless-wsgi-app-using-zappa/)\n* [secure 'serverless' file uploads with aws lambda, s3, and zappa](http://blog.stratospark.com/secure-serverless-file-uploads-with-aws-lambda-s3-zappa.html)\n* [deploy a serverless wsgi app using zappa, cloudfront, rds, and vpc](https://docs.google.com/presentation/d/1ayeomgql4v_ffgt5vnoycdxtob1v6xvuwlyxoteitw0/edit#slide=id.p)\n* [aws: deploy alexa ask skills with flask-ask and zappa](https://developer.amazon.com/blogs/post/8e8ad73a-99e9-4c0f-a7b3-60f92287b0bf/new-alexa-tutorial-deploy-flask-ask-skills-to-aws-lambda-with-zappa)\n* [guide to using django with zappa](https://edgarroman.github.io/zappa-django-guide/)\n* [zappa and lambci](https://seancoates.com/blogs/zappa-and-lambci/)\n* [building a serverless image processing saas using zappa](https://medium.com/99serverless/building-a-serverless-image-processing-saas-9ef68b594076)\n* [serverless slack slash commands with python and zappa](https://renzo.lucioni.xyz/serverless-slash-commands-with-python/)\n* [bringing tokusatsu to aws using python, flask, zappa and contentful](https://www.contentful.com/blog/2018/03/07/bringing-tokusatsu-to-aws-using-python-flask-zappa-and-contentful/)\n* [aws summit 2018 seoul - zappa\uc640 \ud568\uaed8\ud558\ub294 serverless microservice](https://www.slideshare.net/yunseopsong/zappa-serverless-microservice-94410308/)\n* [book - building serverless python web services with zappa](https://github.com/packtpublishing/building-serverless-python-web-services-with-zappa)\n* [vider sa flask dans une lambda](http://free_zed.gitlab.io/articles/2019/11/vider-sa-flask-dans-une-lambda/)[french]\n* _your guide here?_\n\n## zappa in the press\n\n* _[zappa serves python, minus the servers](http://www.infoworld.com/article/3031665/application-development/zappa-serves-python-web-apps-minus-the-servers.html)_\n* _[zappa lyfter serverl\u00f6sa applikationer med python](http://computersweden.idg.se/2.2683/1.649895/zappa-lyfter-python)_\n* _[interview: rich jones on zappa](https://serverlesscode.com/post/rich-jones-interview-django-zappa/)_\n* [top 10 python libraries of 2016](https://tryolabs.com/blog/2016/12/20/top-10-python-libraries-of-2016/)\n\n## sites using zappa\n\n* [mailchimp signup utility](https://github.com/sasha42/mailchimp-utility) - a microservice for adding people to a mailing list via api.\n* [zappa slack inviter](https://github.com/miserlou/zappa-slack-inviter) - a tiny, server-less service for inviting new users to your slack channel.\n* [serverless image host](https://github.com/miserlou/serverless-imagehost) - a thumbnailing service with flask, zappa and pillow.\n* [zappa bittorrent tracker](https://github.com/miserlou/zappa-bittorrent-tracker) - an experimental server-less bittorrent tracker. work in progress.\n* [jankyglance](https://github.com/miserlou/jankyglance) - a server-less yahoo! pipes replacement.\n* [lambdamailer](https://github.com/tryolabs/lambda-mailer) - a server-less endpoint for processing a contact form.\n* [voter registration microservice](https://topics.arlingtonva.us/2016/11/voter-registration-search-microservice/) - official backup to to the virginia department of elections portal.\n* [freepoll online](https://www.freepoll.online) - a simple and awesome say for groups to make decisions.\n* [pasteofcode](https://paste.ofcode.org/) - a zappa-powered paste bin.\n* and many more, including banks, governments, startups, enterprises and schools!\n\nare you using zappa? let us know and we'll list your site here!\n\n## related projects\n\n* [mackenzie](http://github.com/miserlou/mackenzie) - aws lambda infection toolkit\n* [nodb](https://github.com/miserlou/nodb) - a simple, server-less, pythonic object store based on s3.\n* [zappa-cms](http://github.com/miserlou/zappa-cms) - a tiny server-less cms for busy hackers. work in progress.\n* [zappa-django-utils](https://github.com/miserlou/zappa-django-utils) - utility commands to help django deployments.\n* [flask-ask](https://github.com/johnwheeler/flask-ask) - a framework for building amazon alexa applications. uses zappa for deployments.\n* [zappa-file-widget](https://github.com/anush0247/zappa-file-widget) - a django plugin for supporting binary file uploads in django on zappa.\n* [zops](https://github.com/bjinwright/zops) - utilities for teams and continuous integrations using zappa.\n* [cookiecutter-mobile-backend](https://github.com/narfman0/cookiecutter-mobile-backend/) - a `cookiecutter` django project with zappa and s3 uploads support.\n* [zappa-examples](https://github.com/narfman0/zappa-examples/) - flask, django, image uploads, and more!\n* [zappa-hug-example](https://github.com/mcrowson/zappa-hug-example) - example of a hug application using zappa.\n* [zappa docker image](https://github.com/danielwhatmuff/zappa) - a docker image for running zappa locally, based on lambda docker.\n* [zappa-dashing](https://github.com/nikos/zappa-dashing) - monitor your aws environment (health/metrics) with zappa and cloudwatch.\n* [s3env](https://github.com/cameronmaske/s3env) - manipulate a remote zappa environment variable key/value json object file in an s3 bucket through the cli.\n* [zappa_resize_image_on_fly](https://github.com/wobeng/zappa_resize_image_on_fly) - resize images on the fly using flask, zappa, pillow, and opencv-python.\n* [zappa-ffmpeg](https://github.com/ubergarm/zappa-ffmpeg) - run ffmpeg inside a lambda for serverless transformations.\n* [gdrive-lambda](https://github.com/richiverse/gdrive-lambda) - pass json data to a csv file for end users who use gdrive across the organization.\n* [travis-build-repeat](https://github.com/bcongdon/travis-build-repeat) - repeat travisci builds to avoid stale test results.\n* [wunderskill-alexa-skill](https://github.com/mcrowson/wunderlist-alexa-skill) - an alexa skill for adding to a wunderlist.\n* [xrayvision](https://github.com/mathom/xrayvision) - utilities and wrappers for using aws x-ray with zappa.\n* [terraform-aws-zappa](https://github.com/dpetzold/terraform-aws-zappa) - terraform modules for creating a vpc, rds instance, elasticache redis and cloudfront distribution for use with zappa.\n* [zappa-sentry](https://github.com/jneves/zappa-sentry) - integration with zappa and sentry\n* [iopipe](https://github.com/iopipe/iopipe-python#zappa) - monitor, profile and analyze your zappa apps.\n\n\n## hacks\n\nzappa goes quite far beyond what lambda and api gateway were ever intended to handle. as a result, there are quite a few hacks in here that allow it to work. some of those include, but aren't limited to..\n\n* using vtl to map body, headers, method, params and query strings into json, and then turning that into valid wsgi.\n* attaching response codes to response bodies, base64 encoding the whole thing, using that as a regex to route the response code, decoding the body in vtl, and mapping the response body to that.\n* packing and _base58_ encoding multiple cookies into a single cookie because we can only map one kind.\n* forcing the case permutations of \"set-cookie\" in order to return multiple headers at the same time.\n* turning cookie-setting 301/302 responses into 200 responses with html redirects, because we have no way to set headers on redirects.\n\n## contributing\n\ncontributions are very welcome!\n\nplease file tickets for discussion before submitting patches. pull requests should target `master` and should leave zappa in a \"shippable\" state if merged.\n\nif you are adding a non-trivial amount of new code, please include a functioning test in your pr. for aws calls, we use the `placebo` library, which you can learn to use [in their readme](https://github.com/garnaat/placebo#usage-as-a-decorator). the test suite will be run by [travis ci](https://travis-ci.org/zappa/zappa) once you open a pull request.\n\nplease include the github issue or pull request url that has discussion related to your changes as a comment in the code ([example](https://github.com/zappa/zappa/blob/fae2925431b820eaedf088a632022e4120a29f89/zappa/zappa.py#l241-l243)). this greatly helps for project maintainability, as it allows us to trace back use cases and explain decision making. similarly, please make sure that you meet all of the requirements listed in the [pull request template](https://raw.githubusercontent.com/zappa/zappa/master/.github/pull_request_template.md).\n\nplease feel free to work on any open ticket, especially any ticket marked with the \"help-wanted\" label. if you get stuck or want to discuss an issue further, please join [our slack channel](https://zappateam.slack.com/), where you'll find a community of smart and interesting people working dilligently on hard problems.\n[zappa slack auto invite](https://slackautoinviter.herokuapp.com)\n\nzappa does not intend to conform to pep8, isolate your commits so that changes to functionality with changes made by your linter.\n\n#### using a local repo\n\nto use the git head, you *probably can't* use `pip install -e `. instead, you should clone the repo to your machine and then `pip install /path/to/zappa/repo` or `ln -s /path/to/zappa/repo/zappa zappa` in your local project.\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit license",
  "name": "zappa",
  "package_url": "https://pypi.org/project/zappa/",
  "project_url": "https://pypi.org/project/zappa/",
  "project_urls": {
    "Homepage": "https://github.com/zappa/Zappa"
  },
  "release_url": "https://pypi.org/project/zappa/0.58.0/",
  "requires_dist": [
    "argcomplete",
    "boto3 >=1.17.28",
    "durationpy",
    "hjson",
    "jmespath",
    "kappa ==0.6.0",
    "pip >=9.0.1",
    "placebo <0.10",
    "python-dateutil",
    "python-slugify",
    "pyyaml",
    "requests >=2.20.0",
    "toml",
    "tqdm",
    "troposphere >=3.0",
    "werkzeug",
    "wheel"
  ],
  "requires_python": ">=3.7",
  "summary": "server-less python web services for aws lambda and api gateway",
  "version": "0.58.0",
  "releases": [],
  "developers": [
    "rich@openwatch.net",
    "rich_jones"
  ],
  "kwds": "zappaexecutionrole zappa zappa_settings zappa_resize_image_on_fly zappateam",
  "license_kwds": "mit license",
  "libtype": "pypi",
  "id": "pypi_zappa",
  "homepage": "https://github.com/zappa/zappa",
  "release_count": 134,
  "dependency_ids": [
    "pypi_argcomplete",
    "pypi_boto3",
    "pypi_durationpy",
    "pypi_hjson",
    "pypi_jmespath",
    "pypi_kappa",
    "pypi_pip",
    "pypi_placebo",
    "pypi_python_dateutil",
    "pypi_python_slugify",
    "pypi_pyyaml",
    "pypi_requests",
    "pypi_toml",
    "pypi_tqdm",
    "pypi_troposphere",
    "pypi_werkzeug",
    "pypi_wheel"
  ]
}