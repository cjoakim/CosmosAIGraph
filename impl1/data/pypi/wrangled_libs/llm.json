{
  "classifiers": [],
  "description": "# llm\n\n[![pypi](https://img.shields.io/pypi/v/llm.svg)](https://pypi.org/project/llm/)\n[![documentation](https://readthedocs.org/projects/llm/badge/?version=latest)](https://llm.datasette.io/)\n[![changelog](https://img.shields.io/github/v/release/simonw/llm?include_prereleases&label=changelog)](https://llm.datasette.io/en/stable/changelog.html)\n[![tests](https://github.com/simonw/llm/workflows/test/badge.svg)](https://github.com/simonw/llm/actions?query=workflow%3atest)\n[![license](https://img.shields.io/badge/license-apache%202.0-blue.svg)](https://github.com/simonw/llm/blob/main/license)\n[![discord](https://img.shields.io/discord/823971286308356157?label=discord)](https://datasette.io/discord-llm)\n[![homebrew](https://img.shields.io/homebrew/installs/dy/llm?color=yellow&label=homebrew&logo=homebrew)](https://formulae.brew.sh/formula/llm)\n\na cli utility and python library for interacting with large language models, both via remote apis and models that can be installed and run on your own machine.\n\n[run prompts from the command-line](https://llm.datasette.io/en/stable/usage.html#executing-a-prompt), [store the results in sqlite](https://llm.datasette.io/en/stable/logging.html), [generate embeddings](https://llm.datasette.io/en/stable/embeddings/index.html) and more.\n\nfull documentation: **[llm.datasette.io](https://llm.datasette.io/)**\n\nbackground on this project:\n- [llm, ttok and strip-tags\u2014cli tools for working with chatgpt and other llms](https://simonwillison.net/2023/may/18/cli-tools-for-llms/)\n- [the llm cli tool now supports self-hosted language models via plugins](https://simonwillison.net/2023/jul/12/llm/)\n- [accessing llama 2 from the command-line with the llm-replicate plugin](https://simonwillison.net/2023/jul/18/accessing-llama-2/)\n- [run llama 2 on your own mac using llm and homebrew](https://simonwillison.net/2023/aug/1/llama-2-mac/)\n- [catching up on the weird world of llms](https://simonwillison.net/2023/aug/3/weird-world-of-llms/)\n- [llm now provides tools for working with embeddings](https://simonwillison.net/2023/sep/4/llm-embeddings/)\n- [build an image search engine with llm-clip, chat with models with llm chat](https://simonwillison.net/2023/sep/12/llm-clip-and-chat/)\n\n## installation\n\ninstall this tool using `pip`:\n```bash\npip install llm\n```\nor using [pipx](https://pipxproject.github.io/pipx/):\n```bash\npipx install llm\n```\n[detailed installation instructions](https://llm.datasette.io/en/stable/setup.html).\n\n## getting started\n\nif you have an [openai api key](https://platform.openai.com/account/api-keys) you can get started using the openai models right away.\n\nas an alternative to openai, you can [install plugins](https://llm.datasette.io/en/stable/plugins/installing-plugins.html) to access models by other providers, including models that can be installed and run on your own device.\n\nsave your openai api key like this:\n\n```bash\nllm keys set openai\n```\nthis will prompt you for your key like so:\n```\nenter key: <paste here>\n```\nnow that you've saved a key you can run a prompt like this:\n```bash\nllm \"five cute names for a pet penguin\"\n```\n```\n1. waddles\n2. pebbles\n3. bubbles\n4. flappy\n5. chilly\n```\nread the [usage instructions](https://llm.datasette.io/en/stable/usage.html) for more.\n\n## installing a model that runs on your own machine\n\n[llm plugins](https://llm.datasette.io/en/stable/plugins/index.html) can add support for alternative models, including models that run on your own machine.\n\nto download and run llama 2 13b locally, you can install the [llm-mlc](https://github.com/simonw/llm-mlc) plugin:\n```bash\nllm install llm-mlc\nllm mlc pip install --pre --force-reinstall \\\n  mlc-ai-nightly \\\n  mlc-chat-nightly \\\n  -f https://mlc.ai/wheels\nllm mlc setup\n```\nthen download the 15gb llama 2 13b model like this:\n```bash\nllm mlc download-model llama-2-13b-chat --alias llama2\n```\nand run a prompt through it:\n```bash\nllm -m llama2 'difference between a llama and an alpaca'\n```\nyou can also start a chat session with the model using the `llm chat` command:\n```bash\nllm chat -m llama2\n```\n```\nchatting with mlc-chat-llama-2-13b-chat-hf-q4f16_1\ntype 'exit' or 'quit' to exit\ntype '!multi' to enter multiple lines, then '!end' to finish\n> \n```\n\n## using a system prompt\n\nyou can use the `-s/--system` option to set a system prompt, providing instructions for processing other input to the tool.\n\nto describe how the code a file works, try this:\n\n```bash\ncat mycode.py | llm -s \"explain this code\"\n```\n\n## help\n\nfor help, run:\n\n    llm --help\n\nyou can also use:\n\n    python -m llm --help\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache license, version 2.0",
  "name": "llm",
  "package_url": "https://pypi.org/project/llm/",
  "project_url": "https://pypi.org/project/llm/",
  "project_urls": {
    "CI": "https://github.com/simonw/llm/actions",
    "Changelog": "https://github.com/simonw/llm/releases",
    "Documentation": "https://llm.datasette.io/",
    "Homepage": "https://github.com/simonw/llm",
    "Issues": "https://github.com/simonw/llm/issues"
  },
  "release_url": "https://pypi.org/project/llm/0.12/",
  "requires_dist": [
    "click",
    "openai <1.0",
    "click-default-group >=1.2.3",
    "sqlite-utils >=3.35.0",
    "sqlite-migrate >=0.1a2",
    "pydantic >=1.10.2",
    "PyYAML",
    "pluggy",
    "python-ulid",
    "setuptools",
    "pip",
    "pytest ; extra == 'test'",
    "numpy ; extra == 'test'",
    "requests-mock ; extra == 'test'",
    "cogapp ; extra == 'test'",
    "mypy ; extra == 'test'",
    "black ; extra == 'test'",
    "ruff ; extra == 'test'",
    "types-click ; extra == 'test'",
    "types-PyYAML ; extra == 'test'",
    "types-requests ; extra == 'test'",
    "types-setuptools ; extra == 'test'"
  ],
  "requires_python": ">=3.7",
  "summary": "a cli utility and python library for interacting with large language models, including openai, palm and local models installed on your own machine.",
  "version": "0.12",
  "releases": [],
  "developers": [
    "simon_willison"
  ],
  "kwds": "llm llms badge changelog workflows",
  "license_kwds": "apache license, version 2.0",
  "libtype": "pypi",
  "id": "pypi_llm",
  "homepage": "https://github.com/simonw/llm",
  "release_count": 22,
  "dependency_ids": [
    "pypi_black",
    "pypi_click",
    "pypi_click_default_group",
    "pypi_cogapp",
    "pypi_mypy",
    "pypi_numpy",
    "pypi_openai",
    "pypi_pip",
    "pypi_pluggy",
    "pypi_pydantic",
    "pypi_pytest",
    "pypi_python_ulid",
    "pypi_pyyaml",
    "pypi_requests_mock",
    "pypi_ruff",
    "pypi_setuptools",
    "pypi_sqlite_migrate",
    "pypi_sqlite_utils",
    "pypi_types_click",
    "pypi_types_pyyaml",
    "pypi_types_requests",
    "pypi_types_setuptools"
  ]
}