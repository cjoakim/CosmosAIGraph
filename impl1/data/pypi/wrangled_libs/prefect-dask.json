{
  "classifiers": [
    "intended audience :: developers",
    "intended audience :: system administrators",
    "license :: osi approved :: apache software license",
    "natural language :: english",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: software development :: libraries"
  ],
  "description": "# coordinate and parallelize your dataflow with `prefect-dask`\n\n<p align=\"center\">\n    <img src=\"https://user-images.githubusercontent.com/15331990/211682578-3e341709-6509-4c95-a6af-3b1160fe2961.png\" width=40% height=40%>\n    <br>\n    <a href=\"https://pypi.python.org/pypi/prefect-dask/\" alt=\"pypi version\">\n        <img alt=\"pypi\" src=\"https://img.shields.io/pypi/v/prefect-dask?color=0052ff&labelcolor=090422\"></a>\n    <a href=\"https://github.com/prefecthq/prefect-dask/\" alt=\"stars\">\n        <img src=\"https://img.shields.io/github/stars/prefecthq/prefect-dask?color=0052ff&labelcolor=090422\" /></a>\n    <a href=\"https://pepy.tech/badge/prefect-dask/\" alt=\"downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-dask?color=0052ff&labelcolor=090422\" /></a>\n    <a href=\"https://github.com/prefecthq/prefect-dask/pulse\" alt=\"activity\">\n        <img src=\"https://img.shields.io/github/commit-activity/m/prefecthq/prefect-dask?color=0052ff&labelcolor=090422\" /></a>\n    <br>\n    <a href=\"https://prefect-community.slack.com\" alt=\"slack\">\n        <img src=\"https://img.shields.io/badge/slack-join_community-red.svg?color=0052ff&labelcolor=090422&logo=slack\" /></a>\n    <a href=\"https://discourse.prefect.io/\" alt=\"discourse\">\n        <img src=\"https://img.shields.io/badge/discourse-browse_forum-red.svg?color=0052ff&labelcolor=090422&logo=discourse\" /></a>\n</p>\n\nvisit the full docs [here](https://prefecthq.github.io/prefect-dask) to see additional examples and the api reference.\n\nthe `prefect-dask` collection makes it easy to include distributed processing for your flows. check out the examples below to get started!\n\n## getting started\n\n### integrate with prefect flows\n\nperhaps you're already working with prefect flows. say your flow downloads many images to train your machine learning model. unfortunately, it takes a long time to download your flows because your code is running sequentially.\n\nafter installing `prefect-dask` you can parallelize your flow in three simple steps:\n\n1. add the import: `from prefect_dask import dasktaskrunner`\n2. specify the task runner in the flow decorator: `@flow(task_runner=dasktaskrunner)`\n3. submit tasks to the flow's task runner: `a_task.submit(*args, **kwargs)`\n\nthe parallelized code  runs in about 1/3 of the time in our test!  and that's without distributing the workload over multiple machines.\nhere's the before and after!\n\n=== \"before\"\n    ```python hl_lines=\"1\"\n    # completed in 15.2 seconds\n\n    from typing import list\n    from pathlib import path\n\n    import httpx\n    from prefect import flow, task\n\n    url_format = (\n        \"https://www.cpc.ncep.noaa.gov/products/nmme/archive/\"\n        \"{year:04d}{month:02d}0800/current/images/nino34.rescaling.ensmean.png\"\n    )\n\n    @task\n    def download_image(year: int, month: int, directory: path) -> path:\n        # download image from url\n        url = url_format.format(year=year, month=month)\n        resp = httpx.get(url)\n\n        # save content to directory/yyyymm.png\n        file_path = (directory / url.split(\"/\")[-1]).with_stem(f\"{year:04d}{month:02d}\")\n        file_path.write_bytes(resp.content)\n        return file_path\n\n    @flow\n    def download_nino_34_plumes_from_year(year: int) -> list[path]:\n        # create a directory to hold images\n        directory = path(\"data\")\n        directory.mkdir(exist_ok=true)\n\n        # download all images\n        file_paths = []\n        for month in range(1, 12 + 1):\n            file_path = download_image(year, month, directory)\n            file_paths.append(file_path)\n        return file_paths\n\n    if __name__ == \"__main__\":\n        download_nino_34_plumes_from_year(2022)\n    ```\n\n=== \"after\"\n\n    ```python hl_lines=\"1 8 26 35\"\n    # completed in 5.7 seconds\n\n    from typing import list\n    from pathlib import path\n\n    import httpx\n    from prefect import flow, task\n    from prefect_dask import dasktaskrunner\n\n    url_format = (\n        \"https://www.cpc.ncep.noaa.gov/products/nmme/archive/\"\n        \"{year:04d}{month:02d}0800/current/images/nino34.rescaling.ensmean.png\"\n    )\n\n    @task\n    def download_image(year: int, month: int, directory: path) -> path:\n        # download image from url\n        url = url_format.format(year=year, month=month)\n        resp = httpx.get(url)\n\n        # save content to directory/yyyymm.png\n        file_path = (directory / url.split(\"/\")[-1]).with_stem(f\"{year:04d}{month:02d}\")\n        file_path.write_bytes(resp.content)\n        return file_path\n\n    @flow(task_runner=dasktaskrunner(cluster_kwargs={\"processes\": false}))\n    def download_nino_34_plumes_from_year(year: int) -> list[path]:\n        # create a directory to hold images\n        directory = path(\"data\")\n        directory.mkdir(exist_ok=true)\n\n        # download all images\n        file_paths = []\n        for month in range(1, 12 + 1):\n            file_path = download_image.submit(year, month, directory)\n            file_paths.append(file_path)\n        return file_paths\n\n    if __name__ == \"__main__\":\n        download_nino_34_plumes_from_year(2022)\n    ```\n\nthe original flow completes in 15.2 seconds.\n\nhowever, with just a few minor tweaks, we were able to reduce the runtime by nearly **three** folds, down to just **5.7** seconds!\n\n### integrate with dask client/cluster and collections\n\nsuppose you have an existing dask client/cluster and collection, like a `dask.dataframe.dataframe`, and you want to add observability.\n\nwith `prefect-dask`, there's no major overhaul necessary because prefect was designed with incremental adoption in mind! it's as easy as:\n\n1. adding the imports\n2. sprinkling a few `task` and `flow` decorators\n3. using `get_dask_client` context manager on collections to distribute work across workers\n4. specifying the task runner and client's address in the flow decorator\n5. submitting the tasks to the flow's task runner\n\n=== \"before\"\n\n    ```python\n    import dask.dataframe\n    import dask.distributed\n\n\n\n    client = dask.distributed.client()\n\n\n    def read_data(start: str, end: str) -> dask.dataframe.dataframe:\n        df = dask.datasets.timeseries(start, end, partition_freq=\"4w\")\n        return df\n\n\n    def process_data(df: dask.dataframe.dataframe) -> dask.dataframe.dataframe:\n\n        df_yearly_avg = df.groupby(df.index.year).mean()\n        return df_yearly_avg.compute()\n\n\n    def dask_pipeline():\n        df = read_data(\"1988\", \"2022\")\n        df_yearly_average = process_data(df)\n        return df_yearly_average\n\n    dask_pipeline()\n    ```\n\n\n=== \"after\"\n\n    ```python hl_lines=\"3 4 8 13 15 19 21 22\"\n    import dask.dataframe\n    import dask.distributed\n    from prefect import flow, task\n    from prefect_dask import dasktaskrunner, get_dask_client\n\n    client = dask.distributed.client()\n\n    @task\n    def read_data(start: str, end: str) -> dask.dataframe.dataframe:\n        df = dask.datasets.timeseries(start, end, partition_freq=\"4w\")\n        return df\n\n    @task\n    def process_data(df: dask.dataframe.dataframe) -> dask.dataframe.dataframe:\n        with get_dask_client():\n            df_yearly_avg = df.groupby(df.index.year).mean()\n            return df_yearly_avg.compute()\n\n    @flow(task_runner=dasktaskrunner(address=client.scheduler.address))\n    def dask_pipeline():\n        df = read_data.submit(\"1988\", \"2022\")\n        df_yearly_average = process_data.submit(df)\n        return df_yearly_average\n\n    dask_pipeline()\n    ```\n\nnow, you can conveniently see when each task completed, both in the terminal and the ui!\n\n```bash\n14:10:09.845 | info    | prefect.engine - created flow run 'chocolate-pony' for flow 'dask-flow'\n14:10:09.847 | info    | prefect.task_runner.dask - connecting to an existing dask cluster at tcp://127.0.0.1:59255\n14:10:09.857 | info    | distributed.scheduler - receive client connection: client-8c1e0f24-9133-11ed-800e-86f2469c4e7a\n14:10:09.859 | info    | distributed.core - starting established connection to tcp://127.0.0.1:59516\n14:10:09.862 | info    | prefect.task_runner.dask - the dask dashboard is available at http://127.0.0.1:8787/status\n14:10:11.344 | info    | flow run 'chocolate-pony' - created task run 'read_data-5bc97744-0' for task 'read_data'\n14:10:11.626 | info    | flow run 'chocolate-pony' - submitted task run 'read_data-5bc97744-0' for execution.\n14:10:11.795 | info    | flow run 'chocolate-pony' - created task run 'process_data-090555ba-0' for task 'process_data'\n14:10:11.798 | info    | flow run 'chocolate-pony' - submitted task run 'process_data-090555ba-0' for execution.\n14:10:13.279 | info    | task run 'read_data-5bc97744-0' - finished in state completed()\n14:11:43.539 | info    | task run 'process_data-090555ba-0' - finished in state completed()\n14:11:43.883 | info    | flow run 'chocolate-pony' - finished in state completed('all states completed.')\n```\n\n## resources\n\nfor additional examples, check out the [usage guide](usage_guide)!\n\n### installation\n\nget started by installing `prefect-dask`!\n\n=== \"pip\"\n\n    ```bash\n    pip install -u prefect-dask\n    ```\n\n=== \"conda\"\n\n    ```bash\n    conda install -c conda-forge prefect-dask\n    ```\n\nrequires an installation of python 3.7+.\n\nwe recommend using a python virtual environment manager such as pipenv, conda, or virtualenv.\n\nthese tasks are designed to work with prefect 2. for more information about how to use prefect, please refer to the [prefect documentation](https://docs.prefect.io/).\n\n### feedback\n\nif you encounter any bugs while using `prefect-dask`, feel free to open an issue in the [prefect-dask](https://github.com/prefecthq/prefect-dask) repository.\n\nif you have any questions or issues while using `prefect-dask`, you can find help in either the [prefect discourse forum](https://discourse.prefect.io/) or the [prefect slack community](https://prefect.io/slack).\n\nfeel free to star or watch [`prefect-dask`](https://github.com/prefecthq/prefect-dask) for updates too!\n\n### contributing\n\nif you'd like to help contribute to fix an issue or add a feature to `prefect-dask`, please [propose changes through a pull request from a fork of the repository](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork).\n\nhere are the steps:\n\n1. [fork the repository](https://docs.github.com/en/get-started/quickstart/fork-a-repo#forking-a-repository)\n2. [clone the forked repository](https://docs.github.com/en/get-started/quickstart/fork-a-repo#cloning-your-forked-repository)\n3. install the repository and its dependencies:\n```\npip install -e \".[dev]\"\n```\n4. make desired changes\n5. add tests\n6. insert an entry to [changelog.md](https://github.com/prefecthq/prefect-dask/blob/main/changelog.md)\n7. install `pre-commit` to perform quality checks prior to commit:\n```\npre-commit install\n```\n8. `git commit`, `git push`, and create a pull request\n",
  "docs_url": null,
  "keywords": "prefect",
  "license": "apache license 2.0",
  "name": "prefect-dask",
  "package_url": "https://pypi.org/project/prefect-dask/",
  "project_url": "https://pypi.org/project/prefect-dask/",
  "project_urls": {
    "Homepage": "https://github.com/PrefectHQ/prefect-dask"
  },
  "release_url": "https://pypi.org/project/prefect-dask/0.2.6/",
  "requires_dist": [
    "prefect >=2.13.5",
    "distributed ==2022.2.0 ; python_version < \"3.8\"",
    "distributed !=2023.3.2,!=2023.3.2.1,!=2023.4.*,!=2023.5.*,>=2022.5.0 ; python_version >= \"3.8\"",
    "pytest ; extra == 'dev'",
    "black ; extra == 'dev'",
    "flake8 ; extra == 'dev'",
    "flaky ; extra == 'dev'",
    "mypy ; extra == 'dev'",
    "mkdocs ; extra == 'dev'",
    "mkdocs-material ; extra == 'dev'",
    "mkdocstrings[python] ; extra == 'dev'",
    "isort ; extra == 'dev'",
    "pre-commit ; extra == 'dev'",
    "pytest-asyncio ; extra == 'dev'",
    "mkdocs-gen-files ; extra == 'dev'",
    "interrogate ; extra == 'dev'",
    "coverage ; extra == 'dev'",
    "pillow ; extra == 'dev'",
    "mock ; (python_version < \"3.8\") and extra == 'dev'"
  ],
  "requires_python": ">=3.7",
  "summary": "prefect integrations with the dask execution framework.",
  "version": "0.2.6",
  "releases": [],
  "developers": [
    "help@prefect.io",
    "prefect_technologies"
  ],
  "kwds": "dataflow dask_pipeline prefect_dask pypi python",
  "license_kwds": "apache license 2.0",
  "libtype": "pypi",
  "id": "pypi_prefect_dask",
  "homepage": "https://github.com/prefecthq/prefect-dask",
  "release_count": 11,
  "dependency_ids": [
    "pypi_black",
    "pypi_coverage",
    "pypi_distributed",
    "pypi_flake8",
    "pypi_flaky",
    "pypi_interrogate",
    "pypi_isort",
    "pypi_mkdocs",
    "pypi_mkdocs_gen_files",
    "pypi_mkdocs_material",
    "pypi_mkdocstrings",
    "pypi_mock",
    "pypi_mypy",
    "pypi_pillow",
    "pypi_pre_commit",
    "pypi_prefect",
    "pypi_pytest",
    "pypi_pytest_asyncio"
  ]
}