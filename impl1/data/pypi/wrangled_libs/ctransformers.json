{
  "classifiers": [
    "development status :: 1 - planning",
    "intended audience :: developers",
    "intended audience :: education",
    "intended audience :: science/research",
    "license :: osi approved :: mit license",
    "programming language :: python :: 3",
    "topic :: scientific/engineering",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: scientific/engineering :: mathematics",
    "topic :: software development",
    "topic :: software development :: libraries",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "python bindings for the transformer models implemented in c/c++ using ggml library.\n# [ctransformers](https://github.com/marella/ctransformers) [![pypi](https://img.shields.io/pypi/v/ctransformers)](https://pypi.org/project/ctransformers/) [![tests](https://github.com/marella/ctransformers/actions/workflows/tests.yml/badge.svg)](https://github.com/marella/ctransformers/actions/workflows/tests.yml) [![build](https://github.com/marella/ctransformers/actions/workflows/build.yml/badge.svg)](https://github.com/marella/ctransformers/actions/workflows/build.yml)\n\npython bindings for the transformer models implemented in c/c++ using [ggml](https://github.com/ggerganov/ggml) library.\n\n> also see [chatdocs](https://github.com/marella/chatdocs)\n\n- [supported models](#supported-models)\n- [installation](#installation)\n- [usage](#usage)\n  - [\ud83e\udd17 transformers](#transformers)\n  - [langchain](#langchain)\n  - [gpu](#gpu)\n  - [gptq](#gptq)\n- [documentation](#documentation)\n- [license](#license)\n\n## supported models\n\n| models              | model type    | cuda | metal |\n| :------------------ | ------------- | :--: | :---: |\n| gpt-2               | `gpt2`        |      |       |\n| gpt-j, gpt4all-j    | `gptj`        |      |       |\n| gpt-neox, stablelm  | `gpt_neox`    |      |       |\n| falcon              | `falcon`      |  \u2705  |       |\n| llama, llama 2      | `llama`       |  \u2705  |  \u2705   |\n| mpt                 | `mpt`         |  \u2705  |       |\n| starcoder, starchat | `gpt_bigcode` |  \u2705  |       |\n| dolly v2            | `dolly-v2`    |      |       |\n| replit              | `replit`      |      |       |\n\n## installation\n\n```sh\npip install ctransformers\n```\n\n## usage\n\nit provides a unified interface for all models:\n\n```py\nfrom ctransformers import automodelforcausallm\n\nllm = automodelforcausallm.from_pretrained(\"/path/to/ggml-model.bin\", model_type=\"gpt2\")\n\nprint(llm(\"ai is going to\"))\n```\n\n[run in google colab](https://colab.research.google.com/drive/1gmhymuav_tyzkpfvui1nirm8-9mcxqyl)\n\nto stream the output, set `stream=true`:\n\n```py\nfor text in llm(\"ai is going to\", stream=true):\n    print(text, end=\"\", flush=true)\n```\n\nyou can load models from hugging face hub directly:\n\n```py\nllm = automodelforcausallm.from_pretrained(\"marella/gpt-2-ggml\")\n```\n\nif a model repo has multiple model files (`.bin` or `.gguf` files), specify a model file using:\n\n```py\nllm = automodelforcausallm.from_pretrained(\"marella/gpt-2-ggml\", model_file=\"ggml-model.bin\")\n```\n\n<a id=\"transformers\"></a>\n\n### \ud83e\udd17 transformers\n\n> **note:** this is an experimental feature and may change in the future.\n\nto use it with \ud83e\udd17 transformers, create model and tokenizer using:\n\n```py\nfrom ctransformers import automodelforcausallm, autotokenizer\n\nmodel = automodelforcausallm.from_pretrained(\"marella/gpt-2-ggml\", hf=true)\ntokenizer = autotokenizer.from_pretrained(model)\n```\n\n[run in google colab](https://colab.research.google.com/drive/1fvslftj2ibbq1ou2rqz0mkpjbab_5got)\n\nyou can use \ud83e\udd17 transformers text generation pipeline:\n\n```py\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\nprint(pipe(\"ai is going to\", max_new_tokens=256))\n```\n\nyou can use \ud83e\udd17 transformers generation [parameters](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.generationconfig):\n\n```py\npipe(\"ai is going to\", max_new_tokens=256, do_sample=true, temperature=0.8, repetition_penalty=1.1)\n```\n\nyou can use \ud83e\udd17 transformers tokenizers:\n\n```py\nfrom ctransformers import automodelforcausallm\nfrom transformers import autotokenizer\n\nmodel = automodelforcausallm.from_pretrained(\"marella/gpt-2-ggml\", hf=true)  # load model from ggml model repo.\ntokenizer = autotokenizer.from_pretrained(\"gpt2\")  # load tokenizer from original model repo.\n```\n\n### langchain\n\nit is integrated into langchain. see [langchain docs](https://python.langchain.com/docs/ecosystem/integrations/ctransformers).\n\n### gpu\n\nto run some of the model layers on gpu, set the `gpu_layers` parameter:\n\n```py\nllm = automodelforcausallm.from_pretrained(\"thebloke/llama-2-7b-ggml\", gpu_layers=50)\n```\n\n[run in google colab](https://colab.research.google.com/drive/1ihn7ipcyiqltotpkqa1tohuipjbrj1tp)\n\n#### cuda\n\ninstall cuda libraries using:\n\n```sh\npip install ctransformers[cuda]\n```\n\n#### rocm\n\nto enable rocm support, install the `ctransformers` package using:\n\n```sh\nct_hipblas=1 pip install ctransformers --no-binary ctransformers\n```\n\n#### metal\n\nto enable metal support, install the `ctransformers` package using:\n\n```sh\nct_metal=1 pip install ctransformers --no-binary ctransformers\n```\n\n### gptq\n\n> **note:** this is an experimental feature and only llama models are supported using [exllama](https://github.com/turboderp/exllama).\n\ninstall additional dependencies using:\n\n```sh\npip install ctransformers[gptq]\n```\n\nload a gptq model using:\n\n```py\nllm = automodelforcausallm.from_pretrained(\"thebloke/llama-2-7b-gptq\")\n```\n\n[run in google colab](https://colab.research.google.com/drive/1szhslj4ciycmogrppqecj4vycwfnyrn0)\n\n> if model name or path doesn't contain the word `gptq` then specify `model_type=\"gptq\"`.\n\nit can also be used with langchain. low-level apis are not fully supported.\n\n## documentation\n\n<!-- api_docs -->\n\n### config\n\n| parameter            | type        | description                                                     | default |\n| :------------------- | :---------- | :-------------------------------------------------------------- | :------ |\n| `top_k`              | `int`       | the top-k value to use for sampling.                            | `40`    |\n| `top_p`              | `float`     | the top-p value to use for sampling.                            | `0.95`  |\n| `temperature`        | `float`     | the temperature to use for sampling.                            | `0.8`   |\n| `repetition_penalty` | `float`     | the repetition penalty to use for sampling.                     | `1.1`   |\n| `last_n_tokens`      | `int`       | the number of last tokens to use for repetition penalty.        | `64`    |\n| `seed`               | `int`       | the seed value to use for sampling tokens.                      | `-1`    |\n| `max_new_tokens`     | `int`       | the maximum number of new tokens to generate.                   | `256`   |\n| `stop`               | `list[str]` | a list of sequences to stop generation when encountered.        | `none`  |\n| `stream`             | `bool`      | whether to stream the generated text.                           | `false` |\n| `reset`              | `bool`      | whether to reset the model state before generating text.        | `true`  |\n| `batch_size`         | `int`       | the batch size to use for evaluating tokens in a single prompt. | `8`     |\n| `threads`            | `int`       | the number of threads to use for evaluating tokens.             | `-1`    |\n| `context_length`     | `int`       | the maximum context length to use.                              | `-1`    |\n| `gpu_layers`         | `int`       | the number of layers to run on gpu.                             | `0`     |\n\n> **note:** currently only llama, mpt and falcon models support the `context_length` parameter.\n\n### <kbd>class</kbd> `automodelforcausallm`\n\n---\n\n#### <kbd>classmethod</kbd> `automodelforcausallm.from_pretrained`\n\n```python\nfrom_pretrained(\n    model_path_or_repo_id: str,\n    model_type: optional[str] = none,\n    model_file: optional[str] = none,\n    config: optional[ctransformers.hub.autoconfig] = none,\n    lib: optional[str] = none,\n    local_files_only: bool = false,\n    revision: optional[str] = none,\n    hf: bool = false,\n    **kwargs\n) \u2192 llm\n```\n\nloads the language model from a local file or remote repo.\n\n**args:**\n\n- <b>`model_path_or_repo_id`</b>: the path to a model file or directory or the name of a hugging face hub model repo.\n- <b>`model_type`</b>: the model type.\n- <b>`model_file`</b>: the name of the model file in repo or directory.\n- <b>`config`</b>: `autoconfig` object.\n- <b>`lib`</b>: the path to a shared library or one of `avx2`, `avx`, `basic`.\n- <b>`local_files_only`</b>: whether or not to only look at local files (i.e., do not try to download the model).\n- <b>`revision`</b>: the specific model version to use. it can be a branch name, a tag name, or a commit id.\n- <b>`hf`</b>: whether to create a hugging face transformers model.\n\n**returns:**\n`llm` object.\n\n### <kbd>class</kbd> `llm`\n\n### <kbd>method</kbd> `llm.__init__`\n\n```python\n__init__(\n    model_path: str,\n    model_type: optional[str] = none,\n    config: optional[ctransformers.llm.config] = none,\n    lib: optional[str] = none\n)\n```\n\nloads the language model from a local file.\n\n**args:**\n\n- <b>`model_path`</b>: the path to a model file.\n- <b>`model_type`</b>: the model type.\n- <b>`config`</b>: `config` object.\n- <b>`lib`</b>: the path to a shared library or one of `avx2`, `avx`, `basic`.\n\n---\n\n##### <kbd>property</kbd> llm.bos_token_id\n\nthe beginning-of-sequence token.\n\n---\n\n##### <kbd>property</kbd> llm.config\n\nthe config object.\n\n---\n\n##### <kbd>property</kbd> llm.context_length\n\nthe context length of model.\n\n---\n\n##### <kbd>property</kbd> llm.embeddings\n\nthe input embeddings.\n\n---\n\n##### <kbd>property</kbd> llm.eos_token_id\n\nthe end-of-sequence token.\n\n---\n\n##### <kbd>property</kbd> llm.logits\n\nthe unnormalized log probabilities.\n\n---\n\n##### <kbd>property</kbd> llm.model_path\n\nthe path to the model file.\n\n---\n\n##### <kbd>property</kbd> llm.model_type\n\nthe model type.\n\n---\n\n##### <kbd>property</kbd> llm.pad_token_id\n\nthe padding token.\n\n---\n\n##### <kbd>property</kbd> llm.vocab_size\n\nthe number of tokens in vocabulary.\n\n---\n\n#### <kbd>method</kbd> `llm.detokenize`\n\n```python\ndetokenize(tokens: sequence[int], decode: bool = true) \u2192 union[str, bytes]\n```\n\nconverts a list of tokens to text.\n\n**args:**\n\n- <b>`tokens`</b>: the list of tokens.\n- <b>`decode`</b>: whether to decode the text as utf-8 string.\n\n**returns:**\nthe combined text of all tokens.\n\n---\n\n#### <kbd>method</kbd> `llm.embed`\n\n```python\nembed(\n    input: union[str, sequence[int]],\n    batch_size: optional[int] = none,\n    threads: optional[int] = none\n) \u2192 list[float]\n```\n\ncomputes embeddings for a text or list of tokens.\n\n> **note:** currently only llama and falcon models support embeddings.\n\n**args:**\n\n- <b>`input`</b>: the input text or list of tokens to get embeddings for.\n- <b>`batch_size`</b>: the batch size to use for evaluating tokens in a single prompt. default: `8`\n- <b>`threads`</b>: the number of threads to use for evaluating tokens. default: `-1`\n\n**returns:**\nthe input embeddings.\n\n---\n\n#### <kbd>method</kbd> `llm.eval`\n\n```python\neval(\n    tokens: sequence[int],\n    batch_size: optional[int] = none,\n    threads: optional[int] = none\n) \u2192 none\n```\n\nevaluates a list of tokens.\n\n**args:**\n\n- <b>`tokens`</b>: the list of tokens to evaluate.\n- <b>`batch_size`</b>: the batch size to use for evaluating tokens in a single prompt. default: `8`\n- <b>`threads`</b>: the number of threads to use for evaluating tokens. default: `-1`\n\n---\n\n#### <kbd>method</kbd> `llm.generate`\n\n```python\ngenerate(\n    tokens: sequence[int],\n    top_k: optional[int] = none,\n    top_p: optional[float] = none,\n    temperature: optional[float] = none,\n    repetition_penalty: optional[float] = none,\n    last_n_tokens: optional[int] = none,\n    seed: optional[int] = none,\n    batch_size: optional[int] = none,\n    threads: optional[int] = none,\n    reset: optional[bool] = none\n) \u2192 generator[int, nonetype, nonetype]\n```\n\ngenerates new tokens from a list of tokens.\n\n**args:**\n\n- <b>`tokens`</b>: the list of tokens to generate tokens from.\n- <b>`top_k`</b>: the top-k value to use for sampling. default: `40`\n- <b>`top_p`</b>: the top-p value to use for sampling. default: `0.95`\n- <b>`temperature`</b>: the temperature to use for sampling. default: `0.8`\n- <b>`repetition_penalty`</b>: the repetition penalty to use for sampling. default: `1.1`\n- <b>`last_n_tokens`</b>: the number of last tokens to use for repetition penalty. default: `64`\n- <b>`seed`</b>: the seed value to use for sampling tokens. default: `-1`\n- <b>`batch_size`</b>: the batch size to use for evaluating tokens in a single prompt. default: `8`\n- <b>`threads`</b>: the number of threads to use for evaluating tokens. default: `-1`\n- <b>`reset`</b>: whether to reset the model state before generating text. default: `true`\n\n**returns:**\nthe generated tokens.\n\n---\n\n#### <kbd>method</kbd> `llm.is_eos_token`\n\n```python\nis_eos_token(token: int) \u2192 bool\n```\n\nchecks if a token is an end-of-sequence token.\n\n**args:**\n\n- <b>`token`</b>: the token to check.\n\n**returns:**\n`true` if the token is an end-of-sequence token else `false`.\n\n---\n\n#### <kbd>method</kbd> `llm.prepare_inputs_for_generation`\n\n```python\nprepare_inputs_for_generation(\n    tokens: sequence[int],\n    reset: optional[bool] = none\n) \u2192 sequence[int]\n```\n\nremoves input tokens that are evaluated in the past and updates the llm context.\n\n**args:**\n\n- <b>`tokens`</b>: the list of input tokens.\n- <b>`reset`</b>: whether to reset the model state before generating text. default: `true`\n\n**returns:**\nthe list of tokens to evaluate.\n\n---\n\n#### <kbd>method</kbd> `llm.reset`\n\n```python\nreset() \u2192 none\n```\n\ndeprecated since 0.2.27.\n\n---\n\n#### <kbd>method</kbd> `llm.sample`\n\n```python\nsample(\n    top_k: optional[int] = none,\n    top_p: optional[float] = none,\n    temperature: optional[float] = none,\n    repetition_penalty: optional[float] = none,\n    last_n_tokens: optional[int] = none,\n    seed: optional[int] = none\n) \u2192 int\n```\n\nsamples a token from the model.\n\n**args:**\n\n- <b>`top_k`</b>: the top-k value to use for sampling. default: `40`\n- <b>`top_p`</b>: the top-p value to use for sampling. default: `0.95`\n- <b>`temperature`</b>: the temperature to use for sampling. default: `0.8`\n- <b>`repetition_penalty`</b>: the repetition penalty to use for sampling. default: `1.1`\n- <b>`last_n_tokens`</b>: the number of last tokens to use for repetition penalty. default: `64`\n- <b>`seed`</b>: the seed value to use for sampling tokens. default: `-1`\n\n**returns:**\nthe sampled token.\n\n---\n\n#### <kbd>method</kbd> `llm.tokenize`\n\n```python\ntokenize(text: str, add_bos_token: optional[bool] = none) \u2192 list[int]\n```\n\nconverts a text into list of tokens.\n\n**args:**\n\n- <b>`text`</b>: the text to tokenize.\n- <b>`add_bos_token`</b>: whether to add the beginning-of-sequence token.\n\n**returns:**\nthe list of tokens.\n\n---\n\n#### <kbd>method</kbd> `llm.__call__`\n\n```python\n__call__(\n    prompt: str,\n    max_new_tokens: optional[int] = none,\n    top_k: optional[int] = none,\n    top_p: optional[float] = none,\n    temperature: optional[float] = none,\n    repetition_penalty: optional[float] = none,\n    last_n_tokens: optional[int] = none,\n    seed: optional[int] = none,\n    batch_size: optional[int] = none,\n    threads: optional[int] = none,\n    stop: optional[sequence[str]] = none,\n    stream: optional[bool] = none,\n    reset: optional[bool] = none\n) \u2192 union[str, generator[str, nonetype, nonetype]]\n```\n\ngenerates text from a prompt.\n\n**args:**\n\n- <b>`prompt`</b>: the prompt to generate text from.\n- <b>`max_new_tokens`</b>: the maximum number of new tokens to generate. default: `256`\n- <b>`top_k`</b>: the top-k value to use for sampling. default: `40`\n- <b>`top_p`</b>: the top-p value to use for sampling. default: `0.95`\n- <b>`temperature`</b>: the temperature to use for sampling. default: `0.8`\n- <b>`repetition_penalty`</b>: the repetition penalty to use for sampling. default: `1.1`\n- <b>`last_n_tokens`</b>: the number of last tokens to use for repetition penalty. default: `64`\n- <b>`seed`</b>: the seed value to use for sampling tokens. default: `-1`\n- <b>`batch_size`</b>: the batch size to use for evaluating tokens in a single prompt. default: `8`\n- <b>`threads`</b>: the number of threads to use for evaluating tokens. default: `-1`\n- <b>`stop`</b>: a list of sequences to stop generation when encountered. default: `none`\n- <b>`stream`</b>: whether to stream the generated text. default: `false`\n- <b>`reset`</b>: whether to reset the model state before generating text. default: `true`\n\n**returns:**\nthe generated text.\n\n<!-- api_docs -->\n\n## license\n\n[mit](https://github.com/marella/ctransformers/blob/main/license)\n\n\n",
  "docs_url": null,
  "keywords": "ctransformers transformers ai llm",
  "license": "mit",
  "name": "ctransformers",
  "package_url": "https://pypi.org/project/ctransformers/",
  "project_url": "https://pypi.org/project/ctransformers/",
  "project_urls": {
    "Homepage": "https://github.com/marella/ctransformers"
  },
  "release_url": "https://pypi.org/project/ctransformers/0.2.27/",
  "requires_dist": [
    "huggingface-hub",
    "py-cpuinfo (<10.0.0,>=9.0.0)",
    "nvidia-cublas-cu12 ; extra == 'cuda'",
    "nvidia-cuda-runtime-cu12 ; extra == 'cuda'",
    "exllama (==0.1.0) ; extra == 'gptq'",
    "pytest ; extra == 'tests'"
  ],
  "requires_python": "",
  "summary": "python bindings for the transformer models implemented in c/c++ using ggml library.",
  "version": "0.2.27",
  "releases": [],
  "developers": [
    "mv.ravindra007@gmail.com",
    "ravindra_marella"
  ],
  "kwds": "ctransformers transformer transformers yml badge",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_ctransformers",
  "homepage": "https://github.com/marella/ctransformers",
  "release_count": 30,
  "dependency_ids": [
    "pypi_exllama",
    "pypi_huggingface_hub",
    "pypi_nvidia_cublas_cu12",
    "pypi_nvidia_cuda_runtime_cu12",
    "pypi_py_cpuinfo",
    "pypi_pytest"
  ],
  "documentation_summary": "CTransformers is a Python package available on PyPI, offering Python bindings for Transformer models implemented in C/C++ using the GGML library. The latest version, 0.2.27, was released on September 10, 2023. It provides a unified interface for various models, including GPT-2, GPT-J, GPT-NeoX, LLaMA, and others, supporting CUDA and Metal for GPU acceleration. Installation is straightforward via pip, and it includes features for text generation, integration with \ud83e\udd17 Transformers, and experimental support for GPTQ models. The package is licensed under the MIT License, developed by Ravindra Marella, and targets developers, educators, and researchers in AI and scientific computing.",
  "embedding": [
    -0.034648194909095764,
    -0.002889687428250909,
    0.002982620382681489,
    -0.025866910815238953,
    0.002286500297486782,
    0.007631019689142704,
    0.003626137040555477,
    -0.007034846115857363,
    -0.004124117083847523,
    -0.03058018907904625,
    0.019049493595957756,
    0.03697677701711655,
    -0.039249252527952194,
    0.0016122983070090413,
    0.002861632267013192,
    -0.005165667273104191,
    -0.0019095083698630333,
    -0.007645047269761562,
    0.004183734301477671,
    -0.009910506196320057,
    0.03868814557790756,
    -0.01541634276509285,
    -0.029878808185458183,
    -0.03649983927607536,
    -0.0072592878714203835,
    0.016805076971650124,
    0.018207836896181107,
    -0.032515998929739,
    -0.0023636522237211466,
    0.02470261976122856,
    0.01843227818608284,
    0.014125802554190159,
    -0.0352092981338501,
    -0.01059785857796669,
    -0.0039031822234392166,
    -0.0286443792283535,
    0.039417583495378494,
    0.00025337369879707694,
    0.014448437839746475,
    0.009552801959216595,
    0.030439913272857666,
    0.016945352777838707,
    0.0014764058869332075,
    -0.011123894713819027,
    -0.005814444273710251,
    0.008079903200268745,
    0.004720290657132864,
    -0.024983173236250877,
    -0.017632704228162766,
    -0.007673102430999279,
    -0.005516357254236937,
    0.03680844604969025,
    0.014238023199141026,
    -0.040259238332509995,
    -0.00609148945659399,
    -0.008655034936964512,
    0.008486703969538212,
    0.002402228070423007,
    -0.002523216186091304,
    0.00035178614780306816,
    0.014125802554190159,
    0.0020936205983161926,
    -0.03358209505677223,
    0.0019024945795536041,
    0.001967372139915824,
    -0.01281422097235918,
    -0.015598701313138008,
    0.04264393076300621,
    0.014097747392952442,
    0.001106427749618888,
    0.005085008218884468,
    0.027003148570656776,
    0.0012282925890758634,
    -0.012323254719376564,
    0.03837953880429268,
    -0.007904557511210442,
    -0.02454831637442112,
    0.0032929813023656607,
    -0.027914943173527718,
    -0.004565986804664135,
    0.012379365041851997,
    -0.01402760948985815,
    0.00636853463947773,
    0.027928970754146576,
    0.006358013954013586,
    0.02639996074140072,
    0.0075398399494588375,
    -0.0008960135746747255,
    -0.020732806995511055,
    -0.0026196560356765985,
    0.01059785857796669,
    -0.010689038783311844,
    0.01927393488585949,
    0.011095838621258736,
    0.011116879992187023,
    0.019905177876353264,
    -0.021714739501476288,
    0.03344181925058365,
    -0.002965085906907916,
    -0.014378299936652184,
    0.01235130988061428,
    0.019652681425213814,
    -0.004464286845177412,
    -0.008521772921085358,
    -0.040006741881370544,
    0.003692768281325698,
    0.011074797250330448,
    0.009615926072001457,
    0.014644823968410492,
    0.01256873831152916,
    -0.019470321014523506,
    0.033469874411821365,
    -0.0285602118819952,
    -0.053501300513744354,
    0.002898454898968339,
    0.009075863286852837,
    0.02813938446342945,
    -0.00737150851637125,
    0.0004447190440259874,
    0.0071049840189516544,
    0.0027529182843863964,
    0.009103918448090553,
    0.009952588938176632,
    -0.0056881955824792385,
    0.011313267052173615,
    -0.007602964527904987,
    -0.0045870281755924225,
    0.003973320592194796,
    -0.029429923743009567,
    -0.018306029960513115,
    -0.00720317754894495,
    0.0002529353369027376,
    0.022402092814445496,
    -0.0019533445592969656,
    -0.020564476028084755,
    0.00544271245598793,
    -0.022303899750113487,
    0.0005172680830582976,
    -0.03804287686944008,
    -0.0013773358659818769,
    -0.004551959224045277,
    0.007806364446878433,
    0.0073013706132769585,
    0.0016692854696884751,
    -0.009573843330144882,
    0.023271804675459862,
    0.02042420022189617,
    -0.016819104552268982,
    -0.002495161024853587,
    -0.005716250743716955,
    0.010899452492594719,
    -0.05195826664566994,
    -0.015009541995823383,
    0.0018113150727003813,
    0.016819104552268982,
    0.018109643831849098,
    -0.0015561878681182861,
    0.015458425506949425,
    -0.031281568109989166,
    -0.017899230122566223,
    -0.0017955340445041656,
    0.016131751239299774,
    -0.02085905522108078,
    0.002083099912852049,
    -0.0035472316667437553,
    0.035966791212558746,
    0.023089444264769554,
    -0.001389609999023378,
    -0.007567895110696554,
    -0.009447595104575157,
    0.01632813736796379,
    0.03938952833414078,
    -0.03703288733959198,
    0.01164992991834879,
    -0.01867074891924858,
    0.007848447188735008,
    0.004467793740332127,
    0.010457582771778107,
    -0.013466505333781242,
    0.004643138498067856,
    0.00858489703387022,
    0.020073508843779564,
    -0.009700091555714607,
    0.043597809970378876,
    -0.006333465687930584,
    -0.03961396962404251,
    -0.03624734282493591,
    -0.0035121627151966095,
    0.004685221705585718,
    -0.0015447904588654637,
    0.028756599873304367,
    0.04817081242799759,
    0.005930171813815832,
    -0.019722819328308105,
    -0.5763664245605469,
    -0.011804233305156231,
    -0.014757045544683933,
    -0.03714510798454285,
    -0.007224218919873238,
    -0.0010810026433318853,
    -0.016398275271058083,
    0.00904780812561512,
    -0.04132533818483353,
    0.026778707280755043,
    -0.015570646151900291,
    -0.008164068683981895,
    -0.003882140852510929,
    0.0026810269337147474,
    -0.01080125942826271,
    -0.029682422056794167,
    -0.01850241608917713,
    -0.018053533509373665,
    0.006968215107917786,
    0.016272027045488358,
    -0.008479690179228783,
    0.02104141376912594,
    -0.020718779414892197,
    0.014462465420365334,
    -0.00540413660928607,
    0.04239143431186676,
    0.02129391022026539,
    -0.009117946028709412,
    0.04463585466146469,
    -0.007013804744929075,
    -0.04483224079012871,
    0.00988946482539177,
    0.0004528287681750953,
    -0.009784257970750332,
    0.047721926122903824,
    -0.008388509973883629,
    -0.028602296486496925,
    0.04491640627384186,
    0.01449052058160305,
    0.03734149783849716,
    -0.03327348828315735,
    -0.01725395955145359,
    0.013550670817494392,
    0.01615980640053749,
    0.026371905580163002,
    0.006484262645244598,
    0.015318149700760841,
    0.01841825060546398,
    -0.018544498831033707,
    0.0007649430772289634,
    -0.005831978749483824,
    0.02127988263964653,
    0.015135790221393108,
    -0.02788688801229,
    0.01900741085410118,
    -0.00012493340182118118,
    0.03742566332221031,
    -0.012723041698336601,
    0.02077488973736763,
    -0.005099035799503326,
    0.006712211295962334,
    0.027452031150460243,
    -0.007385536562651396,
    -0.029429923743009567,
    -0.00883739348500967,
    -0.006968215107917786,
    0.0014264325145632029,
    -0.011285211890935898,
    -0.0014869265723973513,
    -0.015949392691254616,
    0.008058861829340458,
    0.008570869453251362,
    -0.005085008218884468,
    -0.026245657354593277,
    0.02094322070479393,
    0.042840320616960526,
    0.020915165543556213,
    0.00022663356503471732,
    0.022402092814445496,
    0.04491640627384186,
    0.04488835111260414,
    0.010527720674872398,
    0.00521125691011548,
    -0.01959657110273838,
    0.02120974473655224,
    0.007119011599570513,
    0.002337350510060787,
    0.0003235117474105209,
    0.0006777088856324553,
    0.01512176264077425,
    -0.006617524661123753,
    0.022388065233826637,
    -0.0295702014118433,
    -0.03877231106162071,
    -0.005940692499279976,
    0.008227192796766758,
    -0.02112557925283909,
    -0.0007623129058629274,
    -0.01641230285167694,
    -0.030720464885234833,
    0.009082877077162266,
    -0.008704131469130516,
    0.005351533181965351,
    0.024436095729470253,
    0.011797219514846802,
    0.0037453717086464167,
    -0.025600386783480644,
    -0.008577883243560791,
    0.0025021748151630163,
    -0.03700483217835426,
    -0.027858832851052284,
    -0.010920493863523006,
    -0.014174899086356163,
    -0.0005479534738697112,
    0.005453233141452074,
    -0.03459208458662033,
    0.006771828513592482,
    0.001472898991778493,
    0.010191057808697224,
    -0.03274044021964073,
    0.0027125889901071787,
    0.0028879339806735516,
    -0.004832511302083731,
    0.021728767082095146,
    0.033554039895534515,
    -0.0009021506411954761,
    0.018277974799275398,
    -0.039080921560525894,
    -0.029710477218031883,
    0.03826731815934181,
    0.01617383398115635,
    -0.001681559719145298,
    0.018811024725437164,
    -0.013214007951319218,
    0.037650104612112045,
    0.008367468602955341,
    0.04640333354473114,
    0.005519864149391651,
    0.01836214028298855,
    0.00655440054833889,
    -0.009054821915924549,
    0.01918976940214634,
    0.002060305094346404,
    0.003240377875044942,
    -0.0335259847342968,
    -0.02078891731798649,
    -0.012751096859574318,
    0.01336831133812666,
    0.007511784788221121,
    -0.025025255978107452,
    -0.021826960146427155,
    -0.004962266888469458,
    -0.02070475183427334,
    0.012119854800403118,
    -0.007122518494725227,
    -0.004583521280437708,
    -0.030972961336374283,
    -0.003924223594367504,
    -0.0068068974651396275,
    -0.026540236547589302,
    0.01927393488585949,
    0.02388901822268963,
    0.0033736401237547398,
    0.02136404998600483,
    -0.028924930840730667,
    0.014967459253966808,
    -0.01993323303759098,
    0.020227812230587006,
    -0.02245820313692093,
    -0.027592306956648827,
    0.00030049768975004554,
    -0.04637527838349342,
    -0.0018481375882402062,
    0.018642693758010864,
    0.008430593647062778,
    0.00038027972914278507,
    -0.003247391665354371,
    0.021251827478408813,
    -0.012302213348448277,
    -0.009980644099414349,
    -0.01152368076145649,
    0.007210191339254379,
    -0.0295702014118433,
    -0.013143870048224926,
    0.0304960235953331,
    0.021967235952615738,
    0.007659074850380421,
    0.011741109192371368,
    -0.03125351294875145,
    0.007567895110696554,
    -0.027452031150460243,
    0.000779409019742161,
    -0.026259684935212135,
    0.025866910815238953,
    0.0027581786271184683,
    0.012779152020812035,
    0.02764841727912426,
    -0.012624848634004593,
    -0.0022829934023320675,
    0.015767032280564308,
    -0.006568428128957748,
    0.013880319893360138,
    -0.003941758070141077,
    -0.0295702014118433,
    -0.010247169062495232,
    -0.02345416322350502,
    0.012779152020812035,
    -0.016482440754771233,
    0.025165531784296036,
    -0.005565454252064228,
    0.03327348828315735,
    -0.00010120701335836202,
    -0.026203574612736702,
    -0.016103696078062057,
    -0.00429244851693511,
    0.024436095729470253,
    0.006757800932973623,
    0.02011559158563614,
    -0.014504548162221909,
    -0.019498376175761223,
    0.005200736224651337,
    0.02379082515835762,
    0.0045694936998188496,
    0.007420605514198542,
    0.005888089071959257,
    0.020718779414892197,
    -0.008816352114081383,
    -0.008493717759847641,
    0.0025828336365520954,
    -0.012218047864735126,
    -0.005393615923821926,
    0.03978230059146881,
    -0.0014501041732728481,
    -0.018123671412467957,
    0.014476493000984192,
    -0.012126868590712547,
    0.03978230059146881,
    -0.005162160377949476,
    0.030552133917808533,
    -0.021742794662714005,
    0.009903492406010628,
    0.00820615142583847,
    -0.002854618476703763,
    -0.02446415089070797,
    0.01760464906692505,
    -0.004958759993314743,
    -0.0011537708342075348,
    -0.005249832756817341,
    -0.001391363563016057,
    -0.00525684654712677,
    -0.02362249419093132,
    0.0289810411632061,
    -0.02488497830927372,
    0.007687130011618137,
    0.015079679898917675,
    -0.0028581253718584776,
    0.010660982690751553,
    -0.002775713102892041,
    0.0335259847342968,
    0.0009565076325088739,
    0.020746834576129913,
    -0.0004611576732713729,
    0.017871174961328506,
    0.0014001308009028435,
    0.028784655034542084,
    -0.0067893629893660545,
    -0.0031386776827275753,
    -0.023776797577738762,
    -0.012239089235663414,
    0.0022461710032075644,
    -0.016973407939076424,
    -0.020311977714300156,
    0.0031404311303049326,
    -0.038070932030677795,
    0.03624734282493591,
    0.00997363030910492,
    0.017716871574521065,
    0.029457978904247284,
    0.0016535044414922595,
    0.018656721338629723,
    0.00494122551754117,
    -0.04096062108874321,
    0.038996752351522446,
    -0.008823365904390812,
    -0.0024004746228456497,
    -0.0160896684974432,
    -0.037818435579538345,
    0.012175965122878551,
    -0.01106076966971159,
    0.014153857715427876,
    0.017646731808781624,
    0.012554710730910301,
    0.03260016441345215,
    0.013417408801615238,
    -0.023987211287021637,
    0.004004882648587227,
    0.026175519451498985,
    -0.009237180463969707,
    -0.016145778819918633,
    -0.016356192529201508,
    -0.007511784788221121,
    0.011285211890935898,
    -0.02748008631169796,
    0.013641850091516972,
    0.028181467205286026,
    -0.017029518261551857,
    -0.02104141376912594,
    0.004590535070747137,
    -0.0028335771057754755,
    -0.01843227818608284,
    0.021097524091601372,
    0.02278083749115467,
    -0.004758866503834724,
    -0.0136488638818264,
    0.011663957498967648,
    -0.0053199706599116325,
    0.015051624737679958,
    -0.002738890703767538,
    0.02077488973736763,
    0.016398275271058083,
    -0.020143646746873856,
    -0.0147430170327425,
    -0.003815509844571352,
    0.00017611225484870374,
    0.026624402031302452,
    0.01883907988667488,
    -0.010815287008881569,
    -0.003173746634274721,
    -0.04783414676785469,
    -0.006161627359688282,
    -0.015360232442617416,
    -0.007841433398425579,
    -0.029037151485681534,
    0.020311977714300156,
    -0.01617383398115635,
    0.0010959069477394223,
    0.004229324404150248,
    -0.0039031822234392166,
    0.027928970754146576,
    0.01910560391843319,
    -0.013845250941812992,
    -0.007925598882138729,
    0.00517268106341362,
    3.429846401559189e-06,
    0.026624402031302452,
    -0.0063369725830852985,
    0.0036892613861709833,
    0.008697117678821087,
    0.043176982551813126,
    -0.011229101568460464,
    0.019316017627716064,
    0.01043654140084982,
    -0.024323875084519386,
    -0.012989566661417484,
    -0.002628423273563385,
    -0.010247169062495232,
    0.0066525936126708984,
    0.02806924656033516,
    -0.0313376784324646,
    0.02254236862063408,
    0.029710477218031883,
    0.0048254975117743015,
    -0.0032912278547883034,
    0.003563012694939971,
    0.010001685470342636,
    0.043513644486665726,
    0.0026477111969143152,
    0.005972254555672407,
    -0.010127933695912361,
    -0.0304960235953331,
    -0.008535800501704216,
    0.014616768807172775,
    -0.001423802343197167,
    -0.00876024179160595,
    0.006238779053092003,
    0.008493717759847641,
    -0.02999102883040905,
    -0.008998711593449116,
    0.04926496371626854,
    0.006526345387101173,
    0.012512627989053726,
    -0.017015490680933,
    -0.0017367934342473745,
    -0.023061389103531837,
    -0.002382940147072077,
    -0.044776130467653275,
    0.004173213616013527,
    0.00024504479370079935,
    0.022402092814445496,
    0.01573897711932659,
    -0.02338402532041073,
    0.013221021741628647,
    -0.033133212476968765,
    0.017464373260736465,
    -0.011853329837322235,
    -0.025670524686574936,
    -0.02372068725526333,
    -0.010113906115293503,
    0.017899230122566223,
    0.009924533776938915,
    0.010829314589500427,
    0.003461312735453248,
    0.02092919312417507,
    0.009686063975095749,
    0.005705730058252811,
    -0.021995291113853455,
    0.016945352777838707,
    -0.032544054090976715,
    0.02597913332283497,
    -0.026007188484072685,
    0.017015490680933,
    -0.016145778819918633,
    -0.008276289328932762,
    0.025600386783480644,
    0.009440581314265728,
    0.01816575415432453,
    -0.014714961871504784,
    -0.021812932565808296,
    0.0005076241213828325,
    0.0315060093998909,
    -0.011327294632792473,
    -0.008998711593449116,
    0.018825052306056023,
    -0.00705588748678565,
    -0.012323254719376564,
    -0.037818435579538345,
    0.005470767617225647,
    -0.023159584030508995,
    0.0018796996446326375,
    0.019498376175761223,
    0.021911125630140305,
    0.017239931970834732,
    -0.015346204861998558,
    0.00185865827370435,
    -0.0021479777060449123,
    -0.00668415566906333,
    -0.008802324533462524,
    -0.005628578364849091,
    -0.0032982416450977325,
    -0.01875491440296173,
    -0.003612109459936619,
    0.013003594242036343,
    -0.0025337368715554476,
    -0.022219732403755188,
    0.01615980640053749,
    -0.029878808185458183,
    0.027031203731894493,
    0.029037151485681534,
    0.02120974473655224,
    0.049966346472501755,
    -0.00013172802573535591,
    0.012933455407619476,
    -0.014995514415204525,
    0.022317927330732346,
    0.0007846694206818938,
    0.03501291200518608,
    -0.01348754670470953,
    -0.0031456914730370045,
    -0.014090733602643013,
    0.0013650617329403758,
    -0.023818880319595337,
    0.008725172840058804,
    -0.001366815180517733,
    0.009349402040243149,
    -0.019989343360066414,
    0.007532826159149408,
    -0.014160871505737305,
    -0.002635437063872814,
    -0.012982552871108055,
    -0.01841825060546398,
    -0.005000842735171318,
    0.020971275866031647,
    0.00571975763887167,
    0.01850241608917713,
    0.0022409106604754925,
    0.02203737385571003,
    -0.028868820518255234,
    -0.04101673141121864,
    -0.011215073987841606,
    0.003822523634880781,
    -0.00297560659237206,
    -0.019919205456972122,
    0.022514313459396362,
    0.020227812230587006,
    0.0700819343328476,
    0.009945575147867203,
    0.002775713102892041,
    0.02070475183427334,
    -0.007799350656569004,
    0.01013494748622179,
    -0.009847382083535194,
    0.029345758259296417,
    -0.022388065233826637,
    0.00782740581780672,
    -0.007574908901005983,
    0.0306643545627594,
    0.006919118110090494,
    -0.04659971967339516,
    -0.004604562651365995,
    0.0014895567437633872,
    -0.011376391164958477,
    0.002854618476703763,
    -0.015598701313138008,
    -0.0272977277636528,
    -0.015556618571281433,
    -0.0012002373114228249,
    -0.00016339973080903292,
    0.010205085389316082,
    -0.03361015394330025,
    -0.022682644426822662,
    0.0336943194270134,
    0.011418473906815052,
    0.02043822780251503,
    0.017969368025660515,
    0.003459559055045247,
    -0.02067669667303562,
    0.02345416322350502,
    0.0076520610600709915,
    0.016720909625291824,
    0.00013260474952403456,
    -0.0079185850918293,
    -0.04707665741443634,
    -0.010752162896096706,
    0.0018358633387833834,
    -0.005000842735171318,
    0.019736846908926964,
    -0.0019428238738328218,
    -0.011215073987841606,
    -0.0142801059409976,
    -0.007567895110696554,
    -0.0026827803812921047,
    -0.018123671412467957,
    0.017043545842170715,
    -0.02621760219335556,
    -0.0007382029434666038,
    -0.032964881509542465,
    -0.02380485273897648,
    -0.016819104552268982,
    -0.01478510070592165,
    -0.004169706720858812,
    -0.0055864956229925156,
    0.023917073383927345,
    -0.005000842735171318,
    -0.020550448447465897,
    0.02940186858177185,
    0.016692854464054108,
    0.07210191339254379,
    0.00975620187819004,
    0.008893504738807678,
    -0.00024044199381023645,
    -0.001794657320715487,
    0.001620188937522471,
    -0.0033175295684486628,
    -0.012204020284116268,
    0.0010660983389243484,
    0.012288185767829418,
    0.004804456140846014,
    -0.00037260836688801646,
    -0.022991251200437546,
    0.023271804675459862,
    -0.009903492406010628,
    -0.033974871039390564,
    -0.023566383868455887,
    0.028335770592093468,
    0.03700483217835426,
    0.0029808669351041317,
    -0.031113237142562866,
    -0.012596793472766876,
    -0.01651049591600895,
    -0.005912637338042259,
    -0.015795087441802025,
    0.005835485644638538,
    0.011916453950107098,
    -0.011067783460021019,
    -0.022570423781871796,
    0.040511734783649445,
    0.024422068148851395,
    -0.0066525936126708984,
    0.003129910444840789,
    0.0065088109113276005,
    0.021251827478408813,
    -0.01900741085410118,
    -0.012028675526380539,
    0.012140896171331406,
    0.022500285878777504,
    0.0335259847342968,
    -0.017113683745265007,
    -0.004225817508995533,
    0.05033106356859207,
    -0.026175519451498985,
    -0.01181124709546566,
    0.016734937205910683,
    -0.0026126422453671694,
    0.03478847071528435,
    -0.03240377828478813,
    -0.003678740467876196,
    -0.0014623783063143492,
    -0.015458425506949425,
    0.012007633224129677,
    -0.0020024413242936134,
    -0.015542590990662575,
    0.007946641184389591,
    -0.01775895431637764,
    0.002603875007480383,
    0.009517733007669449,
    -0.0034209832083433867,
    -0.03512513265013695,
    -0.00249340757727623,
    0.0003042237658519298,
    -0.0073013706132769585,
    -0.01934407278895378,
    0.0022935140877962112,
    0.04126922786235809,
    -0.02755022421479225,
    -0.019652681425213814,
    -0.025249697268009186,
    -0.011916453950107098,
    0.02395915612578392,
    0.002849358133971691,
    0.012007633224129677,
    -0.00395929254591465,
    0.05035911872982979,
    0.009812313131988049,
    0.01118000503629446,
    -0.0006759554380550981,
    0.0011020440142601728,
    -0.004678207915276289,
    0.002353131538257003,
    0.012393392622470856,
    0.00276343896985054,
    0.0011467570438981056,
    -0.008171082474291325,
    -0.02547413855791092,
    -0.02153238095343113,
    -0.0044853282161056995,
    0.014532603323459625,
    0.03173045068979263,
    -0.01759062148630619,
    -0.012547696940600872,
    0.011144936084747314,
    -0.007059394381940365,
    -0.01801145076751709,
    0.0005725017981603742,
    0.02673662267625332,
    0.010962576605379581,
    -0.004534424748271704,
    0.006901583634316921,
    -0.0005019254167564213,
    0.010506679303944111,
    -0.00980529934167862,
    0.00795365497469902,
    0.003357859095558524,
    -0.022836947813630104,
    0.0004295955295674503,
    -0.0013685686280950904,
    -0.014146843925118446,
    -0.004324010573327541,
    0.04163394495844841,
    -0.008921559900045395,
    -0.021967235952615738,
    -0.023257777094841003,
    0.036303453147411346,
    -0.01449052058160305,
    0.0010161249665543437,
    0.011460556648671627,
    0.024520261213183403,
    0.02721356227993965,
    0.0088444072753191,
    -0.009314333088696003,
    -0.021013358607888222,
    0.005909130442887545,
    0.008619965985417366,
    -0.03826731815934181,
    -0.03147795423865318,
    -0.010106892324984074,
    0.03147795423865318,
    0.012288185767829418,
    -0.03644372895359993,
    -0.020410170778632164,
    -0.012982552871108055,
    -0.023776797577738762,
    -0.0006097626173868775,
    -0.030103249475359917,
    0.031534064561128616,
    0.008430593647062778,
    0.019133659079670906,
    0.0038049891591072083,
    0.009847382083535194,
    0.012765124440193176,
    0.013971499167382717,
    -0.0075819226913154125,
    0.03961396962404251,
    0.022640561684966087,
    0.017197849228978157,
    -0.011762150563299656,
    -0.00934238824993372,
    -0.044439464807510376,
    0.013915388844907284,
    0.03231961280107498,
    0.001027522375807166,
    0.01651049591600895,
    0.04011896252632141,
    -0.0144063550978899,
    -0.008697117678821087,
    -0.0011020440142601728,
    -0.010499665513634682,
    -0.008269275538623333,
    0.005186708644032478,
    0.016819104552268982,
    -0.010170016437768936,
    -0.011628888547420502,
    -0.0028388374485075474,
    -0.010752162896096706,
    0.007883516140282154,
    -0.023650549352169037,
    0.007066408172249794,
    0.011488611809909344,
    -0.0035367109812796116,
    0.014504548162221909,
    -0.011144936084747314,
    0.019372127950191498,
    0.011088824830949306,
    0.031365733593702316,
    0.016720909625291824,
    0.0010406732326373458,
    0.02313152700662613,
    0.0050394185818731785,
    0.013263104483485222,
    -0.0009530007373541594,
    0.00456247990950942,
    0.0046291109174489975,
    -0.016103696078062057,
    0.03534957394003868,
    -0.02370665967464447,
    -0.012800193391740322,
    -0.005477781407535076,
    0.023762769997119904,
    -0.010773204267024994,
    0.0017990409396588802,
    -0.017296042293310165,
    -0.0003868551575578749,
    -0.024899005889892578,
    0.013087759725749493,
    -0.001258977921679616,
    -0.0330209918320179,
    -0.0010704819578677416,
    -0.0020515378564596176,
    0.025530248880386353,
    0.00841656606644392,
    -0.026778707280755043,
    -0.012344296090304852,
    -0.019708791747689247,
    0.0013019375037401915,
    0.006694676820188761,
    -0.014686906710267067,
    -0.02286500297486782,
    0.0004109651199541986,
    0.012337282299995422,
    -0.024057351052761078,
    0.01575300469994545,
    0.1935810148715973,
    -0.024169571697711945,
    0.01357171218842268,
    0.033301543444395065,
    0.011586805805563927,
    -0.001699094194918871,
    0.010015713050961494,
    0.02739592082798481,
    -0.008234206587076187,
    0.01573897711932659,
    -0.012014647014439106,
    -0.025067338719964027,
    -0.032291557639837265,
    0.0006763937999494374,
    -0.003636657726019621,
    0.004965773783624172,
    -0.034648194909095764,
    -0.05538100376725197,
    -0.02630176767706871,
    0.008276289328932762,
    0.009005725383758545,
    -0.012084785848855972,
    -0.016272027045488358,
    -0.04884413629770279,
    0.0020322499331086874,
    -0.029794642701745033,
    -0.0005711867124773562,
    -0.01478510070592165,
    0.02119571715593338,
    0.010163002647459507,
    -0.02505331113934517,
    0.038323428481817245,
    -0.007315398193895817,
    -0.01385927852243185,
    -0.019582543522119522,
    -0.0160896684974432,
    0.0026249163784086704,
    -0.004166199825704098,
    -0.0009319593082182109,
    0.017941312864422798,
    0.0034016952849924564,
    -0.0184463057667017,
    -0.015318149700760841,
    -0.0283918809145689,
    -0.028952986001968384,
    -0.001436076476238668,
    -0.02412748895585537,
    0.0033157761208713055,
    -0.0023250761441886425,
    -0.0012581011978909373,
    -0.01733812503516674,
    -0.0037278372328728437,
    0.021546408534049988,
    0.030215470120310783,
    -0.011755136772990227,
    -0.01151666697114706,
    -0.02219167724251747,
    0.018039505928754807,
    0.018376167863607407,
    0.0013562944950535893,
    -0.027872860431671143,
    0.021897098049521446,
    0.005035911686718464,
    0.018782969564199448,
    -0.01198659185320139,
    0.010247169062495232,
    -0.02647009864449501,
    -0.0069612013176083565,
    0.002146224258467555,
    -0.0153321772813797,
    -0.030271580442786217,
    -0.005386602133512497,
    -0.034984856843948364,
    -0.01824991963803768,
    -0.019540460780262947,
    -0.03108518198132515,
    0.03257210925221443,
    0.022907085716724396,
    0.031618230044841766,
    0.04180227592587471,
    0.015023569576442242,
    0.0144063550978899,
    0.0005220900638960302,
    -0.007027832325547934,
    -0.018025478348135948,
    -0.024394012987613678,
    0.0029791134875267744,
    -0.019330045208334923,
    -0.01833408512175083,
    -0.020831000059843063,
    0.0027353838086128235,
    -0.027003148570656776,
    0.010120919905602932,
    0.01420295424759388,
    -0.019624626263976097,
    0.001332622836343944,
    -0.0029668393544852734,
    -0.0037488786038011312,
    -0.002219869289547205,
    0.01386629231274128,
    -0.04096062108874321,
    0.03843564912676811,
    0.031001016497612,
    -0.00933537445962429,
    -0.012968525290489197,
    0.011937495321035385,
    0.011558749713003635,
    -0.002751164836809039,
    -0.0058004166930913925,
    -0.003136924235150218,
    -0.005312956869602203,
    -0.026077326387166977,
    -0.00036252604331821203,
    -0.004650152288377285,
    -0.0023917073849588633,
    -0.014897321350872517,
    -0.018782969564199448,
    0.008907532319426537,
    0.013936430215835571,
    0.015262039378285408,
    -0.012800193391740322,
    0.002432036679238081,
    0.010611886158585548,
    -0.024899005889892578,
    -0.02252834104001522,
    -0.005835485644638538,
    -0.02530580759048462,
    -0.005877568386495113,
    -0.01524801179766655,
    0.01025418285280466,
    0.0022952675353735685,
    -0.03880036622285843,
    0.018376167863607407,
    -0.00912495981901884,
    -0.005768854171037674,
    -0.011762150563299656,
    0.004618590231984854,
    -0.016791047528386116,
    -0.008164068683981895,
    0.013333242386579514,
    -0.03944563865661621,
    -0.009686063975095749,
    -0.017730899155139923,
    -0.02429581992328167,
    0.019498376175761223,
    -0.017983395606279373,
    -0.005362053867429495,
    0.019806984812021255,
    -0.0009705352131277323,
    -0.0004405546060297638,
    -0.007196163758635521,
    0.017730899155139923,
    -0.004636124707758427,
    -0.01256172452121973,
    0.013789139688014984,
    -0.019161714240908623,
    -0.027185507118701935,
    -0.02813938446342945,
    0.014308162033557892,
    0.010401472449302673,
    -0.03902480751276016,
    -0.015205929055809975,
    -0.010120919905602932,
    0.005895102862268686,
    -0.008276289328932762,
    -0.04250365495681763,
    -0.17719675600528717,
    0.00443973857909441,
    0.010562789626419544,
    -0.051060497760772705,
    0.0011862097308039665,
    0.004625604022294283,
    0.009959602728486061,
    0.012218047864735126,
    -0.009082877077162266,
    -0.025418028235435486,
    0.02554427646100521,
    -0.0038786339573562145,
    -0.014757045544683933,
    -0.022065429016947746,
    -0.020732806995511055,
    0.0018481375882402062,
    -0.029486034065485,
    0.002684533828869462,
    0.025782745331525803,
    0.0057302783243358135,
    0.058018192648887634,
    -0.04289643093943596,
    0.006112530827522278,
    0.02748008631169796,
    -0.0068910629488527775,
    -0.010387444868683815,
    -0.006372041534632444,
    0.021097524091601372,
    -0.012807207182049751,
    -0.02094322070479393,
    -0.021237799897789955,
    -0.0017902737017720938,
    0.04020312801003456,
    -0.0018078081775456667,
    0.02471664734184742,
    0.017296042293310165,
    0.03526540845632553,
    -0.03512513265013695,
    -0.00866906251758337,
    0.015598701313138008,
    0.022079456597566605,
    0.014827183447778225,
    -0.009643981233239174,
    -0.011684998869895935,
    -0.021420160308480263,
    0.00980529934167862,
    0.016945352777838707,
    -0.021420160308480263,
    0.008093930780887604,
    0.005593509413301945,
    0.032039061188697815,
    -0.009566829539835453,
    0.00548830209299922,
    0.008802324533462524,
    0.010787231847643852,
    0.020564476028084755,
    0.019540460780262947,
    0.01541634276509285,
    0.020297950133681297,
    -0.0160896684974432,
    -0.00544271245598793,
    -0.006298396736383438,
    0.0159213375300169,
    -0.009286276996135712,
    -0.008542814292013645,
    -0.03282460570335388,
    -0.028868820518255234,
    0.007680116221308708,
    -0.012007633224129677,
    0.012687972746789455,
    -0.006722731981426477,
    0.014939404092729092,
    -0.02203737385571003,
    -0.0056040300987660885,
    0.042756155133247375,
    0.021013358607888222,
    -0.03557401895523071,
    0.011292225681245327,
    0.03871620073914528,
    -0.024828867986798286,
    -0.013242063112556934,
    0.044944461435079575,
    -0.013578725978732109,
    0.004162692930549383,
    0.017366180196404457,
    -0.013747056946158409,
    0.006435165647417307,
    -0.0013615548377856612,
    -0.023243749514222145,
    -0.006070448085665703,
    0.029598256573081017,
    0.003833044320344925,
    0.007126025389879942,
    -0.006463220808655024,
    -0.010794245637953281,
    0.012526655569672585,
    -0.0015079680597409606,
    -0.024604426696896553,
    0.028265632688999176,
    -0.02656829170882702,
    0.01582314260303974,
    0.012393392622470856,
    -0.011804233305156231,
    -0.010857369750738144,
    0.03548985347151756,
    0.019708791747689247,
    -0.044776130467653275,
    0.023678604513406754,
    0.015023569576442242,
    -0.014174899086356163,
    -0.014146843925118446,
    -0.005225284490734339,
    0.012112841010093689,
    0.02287903055548668,
    -0.011362363584339619,
    0.01373302936553955,
    -0.023482218384742737,
    -0.013494560495018959,
    0.03843564912676811,
    0.0024215159937739372,
    0.040343403816223145,
    0.0006742019904777408,
    -0.004194254986941814,
    0.007252274081110954,
    -0.01294748391956091,
    -0.05487600713968277,
    -0.09555607289075851,
    -0.02639996074140072,
    0.006070448085665703,
    0.023089444264769554,
    -0.030692409723997116,
    0.014757045544683933,
    -0.015051624737679958,
    0.025908995419740677,
    -0.01383122242987156,
    0.003473586868494749,
    -0.015598701313138008,
    0.005579481832683086,
    0.00544271245598793,
    0.008276289328932762,
    0.0011511406628414989,
    0.004516890272498131,
    -0.003924223594367504,
    0.015163845382630825,
    -0.023903045803308487,
    0.013052690774202347,
    -0.018642693758010864,
    -0.0019165221601724625,
    -0.007806364446878433,
    -0.00812899973243475,
    -0.015781059861183167,
    0.014434410259127617,
    -0.04999440163373947,
    0.021251827478408813,
    0.008823365904390812,
    0.01218297891318798,
    0.024604426696896553,
    -0.030131304636597633,
    -0.018306029960513115,
    -0.0024495713878422976,
    0.02104141376912594,
    -0.009861409664154053,
    -0.02689092792570591,
    -0.011418473906815052,
    0.01808158867061138,
    -0.005754826590418816,
    0.004797442350536585,
    -0.01143250148743391,
    -0.0033210364636033773,
    -0.012386378832161427,
    -0.026273712515830994,
    0.007848447188735008,
    -0.012400406412780285,
    0.03299293667078018,
    0.015262039378285408,
    -0.04615083336830139,
    -0.03248794376850128,
    -0.007175122387707233,
    -0.027508141472935677,
    0.02388901822268963,
    0.02411346137523651,
    0.011123894713819027,
    0.0030492516234517097,
    -0.003661205992102623,
    -0.011607847176492214,
    -0.03125351294875145,
    -0.001713998499326408,
    0.002475873101502657,
    -0.007462688256055117,
    0.013298173435032368,
    0.015009541995823383,
    0.008472676388919353,
    0.006782349199056625,
    0.010682024993002415,
    0.016033558174967766,
    -0.01256873831152916,
    -0.017296042293310165,
    0.023594439029693604,
    -0.012758110649883747,
    -0.010163002647459507,
    -0.030187414959073067,
    -0.016552578657865524,
    -0.0014930636389181018,
    -0.017660759389400482,
    0.00950370542705059,
    -0.025614414364099503,
    -0.007743240334093571,
    -0.004071513656526804,
    -0.00737150851637125,
    -0.016482440754771233,
    -0.0027669458650052547,
    0.005691702477633953,
    0.012421447783708572,
    -0.015500508248806,
    -0.002789740916341543,
    -0.03913703188300133,
    0.010373417288064957,
    -0.0017359167104586959,
    0.013550670817494392,
    -0.021728767082095146,
    -0.0035647661425173283,
    0.003417476313188672,
    -0.015009541995823383,
    0.0147430170327425,
    0.009791271761059761,
    0.01733812503516674,
    -0.03565818443894386,
    -0.008100944571197033,
    -0.08893503993749619,
    0.019919205456972122,
    0.0059862821362912655,
    -0.023313887417316437,
    0.006242286413908005,
    -0.027325782924890518,
    0.01799742318689823,
    -0.012407420203089714,
    0.013873306103050709,
    0.015542590990662575,
    -0.02621760219335556,
    -0.015963420271873474,
    0.00043923952034674585,
    -0.005979268345981836,
    -0.006529852282255888,
    0.011797219514846802,
    0.007771295495331287,
    -0.0048009492456912994,
    0.03961396962404251,
    0.0076520610600709915,
    -0.013263104483485222,
    0.0008276289445348084,
    0.026526208966970444,
    0.035237353295087814,
    -0.03896869719028473,
    -0.008079903200268745,
    -0.0085077453404665,
    0.0323476679623127,
    0.007108490914106369,
    -0.01641230285167694,
    0.01918976940214634,
    0.006445686332881451,
    -0.014644823968410492,
    0.009517733007669449,
    0.02355235628783703,
    0.011495625600218773,
    0.0308326855301857,
    0.007602964527904987,
    0.006841966416686773,
    0.024323875084519386,
    -0.04446751996874809,
    -0.0330209918320179,
    0.02840590849518776,
    0.004723797552287579,
    -0.00046203439706005156,
    0.0032053086906671524,
    0.02445012331008911,
    -0.012533669359982014,
    0.030552133917808533,
    0.029093261808156967,
    0.03616317734122276,
    0.021181689575314522,
    -0.012147909961640835,
    -0.04157783463597298,
    0.003356105647981167,
    -0.00045151368249207735,
    0.04154977947473526,
    -0.016692854464054108,
    -0.01775895431637764,
    0.0002040578838204965,
    0.05322074890136719,
    0.008178096264600754,
    0.02010156400501728,
    -0.00841656606644392,
    0.001344897085800767,
    -0.024323875084519386,
    -0.04239143431186676,
    -0.024099433794617653,
    0.010787231847643852,
    -0.023103471845388412,
    -0.0069857495836913586,
    -0.01227415818721056,
    0.029766587540507317,
    0.022977223619818687,
    0.006340479478240013,
    -0.0024109953083097935,
    -0.005737292114645243,
    -0.01181124709546566,
    -0.02237403765320778,
    0.019133659079670906,
    0.007136546075344086,
    -0.023271804675459862,
    -0.018193809315562248,
    0.0012966771610081196,
    0.01900741085410118,
    0.013508588075637817,
    -0.014560658484697342,
    -0.014020595699548721,
    -0.019666709005832672,
    0.002000687876716256,
    0.005663647316396236,
    0.014104761183261871,
    0.0148692661896348,
    -0.004278420936316252,
    0.010878411121666431,
    0.020971275866031647,
    0.01374004315584898,
    -0.01495343167334795,
    0.028714517131447792,
    0.012870331294834614,
    0.015374260023236275,
    -0.010780218057334423,
    0.014672879129648209,
    -0.020340032875537872,
    -0.012154923751950264,
    -0.010184044018387794,
    -0.025109421461820602,
    -0.025684552267193794,
    0.022093484178185463,
    0.014434410259127617,
    0.010219113901257515,
    -0.026526208966970444,
    -0.0015623250510543585,
    0.02329985983669758,
    -0.01893727295100689,
    0.023650549352169037,
    0.012961511500179768,
    -0.014273092150688171,
    -0.015710921958088875,
    0.015486480668187141,
    0.014090733602643013,
    -0.0033736401237547398,
    0.03734149783849716,
    0.007806364446878433,
    0.02052239328622818,
    0.03142184391617775,
    0.00613707909360528,
    0.012309227138757706,
    0.03240377828478813,
    -0.0006522838375531137,
    -0.01716979406774044,
    0.010906466282904148,
    -0.012596793472766876,
    -0.019161714240908623,
    -0.010155988857150078,
    -0.0037874544505029917,
    -0.02579677291214466,
    -0.020073508843779564,
    0.008570869453251362,
    0.08972059190273285,
    0.026245657354593277,
    -0.005947706289589405,
    -0.0001952906313817948,
    -0.003899675328284502,
    0.025824828073382378,
    0.0023496246431022882,
    0.01885310746729374,
    -0.009153014980256557,
    -0.010871397331357002,
    -0.030439913272857666,
    -0.012056730687618256,
    -0.033974871039390564,
    -0.027241617441177368,
    -0.013999554328620434,
    0.002947551431134343,
    -0.010450568981468678,
    0.021658629179000854,
    -0.0028142891824245453,
    -0.0002823056420311332,
    0.03894064202904701,
    -0.00021929098875261843,
    0.006417631171643734,
    -0.01760464906692505,
    -0.01952643319964409,
    -0.0038681132718920708,
    0.0328526608645916,
    0.03240377828478813,
    0.006571935024112463,
    -0.021055441349744797,
    0.03344181925058365,
    0.028602296486496925,
    -0.015612728893756866,
    -0.010934521444141865,
    -0.004734318237751722,
    0.0025547784753143787,
    -0.0002325514651602134,
    -0.01060487236827612,
    0.01428711973130703,
    0.009237180463969707,
    0.002488147234544158,
    -0.0013922402868047357,
    -0.02304736152291298,
    -0.030019083991646767,
    0.019316017627716064,
    6.438453419832513e-05,
    0.010443555191159248,
    -0.015388287603855133,
    -0.032123226672410965
  ]
}