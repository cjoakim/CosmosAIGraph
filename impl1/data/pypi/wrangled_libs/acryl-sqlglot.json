{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "intended audience :: science/research",
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3 :: only",
    "programming language :: sql"
  ],
  "description": "![sqlglot logo](sqlglot.svg)\n\nsqlglot is a no-dependency sql parser, transpiler, optimizer, and engine. it can be used to format sql or translate between [20 different dialects](https://github.com/tobymao/sqlglot/blob/main/sqlglot/dialects/__init__.py) like [duckdb](https://duckdb.org/), [presto](https://prestodb.io/) / [trino](https://trino.io/), [spark](https://spark.apache.org/) / [databricks](https://www.databricks.com/), [snowflake](https://www.snowflake.com/en/), and [bigquery](https://cloud.google.com/bigquery/). it aims to read a wide variety of sql inputs and output syntactically and semantically correct sql in the targeted dialects.\n\nit is a very comprehensive generic sql parser with a robust [test suite](https://github.com/tobymao/sqlglot/blob/main/tests/). it is also quite [performant](#benchmarks), while being written purely in python.\n\nyou can easily [customize](#custom-dialects) the parser, [analyze](#metadata) queries, traverse expression trees, and programmatically [build](#build-and-modify-sql) sql.\n\nsyntax [errors](#parser-errors) are highlighted and dialect incompatibilities can warn or raise depending on configurations. however, it should be noted that sql validation is not sqlglot\u2019s goal, so some syntax errors may go unnoticed.\n\nlearn more about sqlglot in the api [documentation](https://sqlglot.com/) and the expression tree [primer](https://github.com/tobymao/sqlglot/blob/main/posts/ast_primer.md).\n\ncontributions are very welcome in sqlglot; read the [contribution guide](https://github.com/tobymao/sqlglot/blob/main/contributing.md) to get started!\n\n## table of contents\n\n* [install](#install)\n* [versioning](#versioning)\n* [get in touch](#get-in-touch)\n* [faq](#faq)\n* [examples](#examples)\n   * [formatting and transpiling](#formatting-and-transpiling)\n   * [metadata](#metadata)\n   * [parser errors](#parser-errors)\n   * [unsupported errors](#unsupported-errors)\n   * [build and modify sql](#build-and-modify-sql)\n   * [sql optimizer](#sql-optimizer)\n   * [ast introspection](#ast-introspection)\n   * [ast diff](#ast-diff)\n   * [custom dialects](#custom-dialects)\n   * [sql execution](#sql-execution)\n* [used by](#used-by)\n* [documentation](#documentation)\n* [run tests and lint](#run-tests-and-lint)\n* [benchmarks](#benchmarks)\n* [optional dependencies](#optional-dependencies)\n\n## install\n\nfrom pypi:\n\n```\npip3 install sqlglot\n```\n\nor with a local checkout:\n\n```\nmake install\n```\n\nrequirements for development (optional):\n\n```\nmake install-dev\n```\n\n## versioning\n\ngiven a version number `major`.`minor`.`patch`, sqlglot uses the following versioning strategy:\n\n- the `patch` version is incremented when there are backwards-compatible fixes or feature additions.\n- the `minor` version is incremented when there are backwards-incompatible fixes or feature additions.\n- the `major` version is incremented when there are significant backwards-incompatible fixes or feature additions.\n\n## get in touch\n\nwe'd love to hear from you. join our community [slack channel](https://tobikodata.com/slack)!\n\n## faq\n\ni tried to parse sql that should be valid but it failed, why did that happen?\n  \n* you need to specify the dialect to read the sql properly, by default it is sqlglot's dialect which is designed to be a superset of all dialects `parse_one(sql, dialect=\"spark\")`. if you tried specifying the dialect and it still doesn't work, please file an issue.\n\ni tried to output sql but it's not in the correct dialect!\n  \n* you need to specify the dialect to write the sql properly, by default it is in sqlglot's dialect `parse_one(sql, dialect=\"spark\").sql(dialect=\"spark\")`.\n\ni tried to parse invalid sql and it should raise an error but it worked! why didn't it validate my sql.\n  \n* sqlglot is not a validator and designed to be very forgiving, handling things like trailing commas.\n\n## examples\n\n### formatting and transpiling\n\neasily translate from one dialect to another. for example, date/time functions vary between dialects and can be hard to deal with:\n\n```python\nimport sqlglot\nsqlglot.transpile(\"select epoch_ms(1618088028295)\", read=\"duckdb\", write=\"hive\")[0]\n```\n\n```sql\n'select from_unixtime(1618088028295 / 1000)'\n```\n\nsqlglot can even translate custom time formats:\n\n```python\nimport sqlglot\nsqlglot.transpile(\"select strftime(x, '%y-%-m-%s')\", read=\"duckdb\", write=\"hive\")[0]\n```\n\n```sql\n\"select date_format(x, 'yy-m-ss')\"\n```\n\nas another example, let's suppose that we want to read in a sql query that contains a cte and a cast to `real`, and then transpile it to spark, which uses backticks for identifiers and `float` instead of `real`:\n\n```python\nimport sqlglot\n\nsql = \"\"\"with baz as (select a, c from foo where a = 1) select f.a, b.b, baz.c, cast(\"b\".\"a\" as real) d from foo f join bar b on f.a = b.a left join baz on f.a = baz.a\"\"\"\nprint(sqlglot.transpile(sql, write=\"spark\", identify=true, pretty=true)[0])\n```\n\n```sql\nwith `baz` as (\n  select\n    `a`,\n    `c`\n  from `foo`\n  where\n    `a` = 1\n)\nselect\n  `f`.`a`,\n  `b`.`b`,\n  `baz`.`c`,\n  cast(`b`.`a` as float) as `d`\nfrom `foo` as `f`\njoin `bar` as `b`\n  on `f`.`a` = `b`.`a`\nleft join `baz`\n  on `f`.`a` = `baz`.`a`\n```\n\ncomments are also preserved on a best-effort basis when transpiling sql code:\n\n```python\nsql = \"\"\"\n/* multi\n   line\n   comment\n*/\nselect\n  tbl.cola /* comment 1 */ + tbl.colb /* comment 2 */,\n  cast(x as int), # comment 3\n  y               -- comment 4\nfrom\n  bar /* comment 5 */,\n  tbl #          comment 6\n\"\"\"\n\nprint(sqlglot.transpile(sql, read='mysql', pretty=true)[0])\n```\n\n```sql\n/* multi\n   line\n   comment\n*/\nselect\n  tbl.cola /* comment 1 */ + tbl.colb /* comment 2 */,\n  cast(x as int), /* comment 3 */\n  y /* comment 4 */\nfrom bar /* comment 5 */, tbl /*          comment 6 */\n```\n\n\n### metadata\n\nyou can explore sql with expression helpers to do things like find columns and tables:\n\n```python\nfrom sqlglot import parse_one, exp\n\n# print all column references (a and b)\nfor column in parse_one(\"select a, b + 1 as c from d\").find_all(exp.column):\n    print(column.alias_or_name)\n\n# find all projections in select statements (a and c)\nfor select in parse_one(\"select a, b + 1 as c from d\").find_all(exp.select):\n    for projection in select.expressions:\n        print(projection.alias_or_name)\n\n# find all tables (x, y, z)\nfor table in parse_one(\"select * from x join y join z\").find_all(exp.table):\n    print(table.name)\n```\n\nread the [ast primer](https://github.com/tobymao/sqlglot/blob/main/posts/ast_primer.md) to learn more about sqlglot's internals.\n\n### parser errors\n\nwhen the parser detects an error in the syntax, it raises a parseerror:\n\n```python\nimport sqlglot\nsqlglot.transpile(\"select foo( from bar\")\n```\n\n```\nsqlglot.errors.parseerror: expecting ). line 1, col: 13.\n  select foo( from bar\n              ~~~~\n```\n\nstructured syntax errors are accessible for programmatic use:\n\n```python\nimport sqlglot\ntry:\n    sqlglot.transpile(\"select foo( from bar\")\nexcept sqlglot.errors.parseerror as e:\n    print(e.errors)\n```\n\n```python\n[{\n  'description': 'expecting )',\n  'line': 1,\n  'col': 16,\n  'start_context': 'select foo( ',\n  'highlight': 'from',\n  'end_context': ' bar',\n  'into_expression': none,\n}]\n```\n\n### unsupported errors\n\npresto `approx_distinct` supports the accuracy argument which is not supported in hive:\n\n```python\nimport sqlglot\nsqlglot.transpile(\"select approx_distinct(a, 0.1) from foo\", read=\"presto\", write=\"hive\")\n```\n\n```sql\napprox_count_distinct does not support accuracy\n'select approx_count_distinct(a) from foo'\n```\n\n### build and modify sql\n\nsqlglot supports incrementally building sql expressions:\n\n```python\nfrom sqlglot import select, condition\n\nwhere = condition(\"x=1\").and_(\"y=1\")\nselect(\"*\").from_(\"y\").where(where).sql()\n```\n\n```sql\n'select * from y where x = 1 and y = 1'\n```\n\nyou can also modify a parsed tree:\n\n```python\nfrom sqlglot import parse_one\nparse_one(\"select x from y\").from_(\"z\").sql()\n```\n\n```sql\n'select x from z'\n```\n\nthere is also a way to recursively transform the parsed tree by applying a mapping function to each tree node:\n\n```python\nfrom sqlglot import exp, parse_one\n\nexpression_tree = parse_one(\"select a from x\")\n\ndef transformer(node):\n    if isinstance(node, exp.column) and node.name == \"a\":\n        return parse_one(\"fun(a)\")\n    return node\n\ntransformed_tree = expression_tree.transform(transformer)\ntransformed_tree.sql()\n```\n\n```sql\n'select fun(a) from x'\n```\n\n### sql optimizer\n\nsqlglot can rewrite queries into an \"optimized\" form. it performs a variety of [techniques](https://github.com/tobymao/sqlglot/blob/main/sqlglot/optimizer/optimizer.py) to create a new canonical ast. this ast can be used to standardize queries or provide the foundations for implementing an actual engine. for example:\n\n```python\nimport sqlglot\nfrom sqlglot.optimizer import optimize\n\nprint(\n    optimize(\n        sqlglot.parse_one(\"\"\"\n            select a or (b or (c and d))\n            from x\n            where z = date '2021-01-01' + interval '1' month or 1 = 0\n        \"\"\"),\n        schema={\"x\": {\"a\": \"int\", \"b\": \"int\", \"c\": \"int\", \"d\": \"int\", \"z\": \"string\"}}\n    ).sql(pretty=true)\n)\n```\n\n```sql\nselect\n  (\n    \"x\".\"a\" <> 0 or \"x\".\"b\" <> 0 or \"x\".\"c\" <> 0\n  )\n  and (\n    \"x\".\"a\" <> 0 or \"x\".\"b\" <> 0 or \"x\".\"d\" <> 0\n  ) as \"_col_0\"\nfrom \"x\" as \"x\"\nwhere\n  cast(\"x\".\"z\" as date) = cast('2021-02-01' as date)\n```\n\n### ast introspection\n\nyou can see the ast version of the sql by calling `repr`:\n\n```python\nfrom sqlglot import parse_one\nprint(repr(parse_one(\"select a + 1 as z\")))\n```\n\n```python\n(select expressions:\n  (alias this:\n    (add this:\n      (column this:\n        (identifier this: a, quoted: false)), expression:\n      (literal this: 1, is_string: false)), alias:\n    (identifier this: z, quoted: false)))\n```\n\n### ast diff\n\nsqlglot can calculate the difference between two expressions and output changes in a form of a sequence of actions needed to transform a source expression into a target one:\n\n```python\nfrom sqlglot import diff, parse_one\ndiff(parse_one(\"select a + b, c, d\"), parse_one(\"select c, a - b, d\"))\n```\n\n```python\n[\n  remove(expression=(add this:\n    (column this:\n      (identifier this: a, quoted: false)), expression:\n    (column this:\n      (identifier this: b, quoted: false)))),\n  insert(expression=(sub this:\n    (column this:\n      (identifier this: a, quoted: false)), expression:\n    (column this:\n      (identifier this: b, quoted: false)))),\n  move(expression=(column this:\n    (identifier this: c, quoted: false))),\n  keep(source=(identifier this: b, quoted: false), target=(identifier this: b, quoted: false)),\n  ...\n]\n```\n\nsee also: [semantic diff for sql](https://github.com/tobymao/sqlglot/blob/main/posts/sql_diff.md).\n\n### custom dialects\n\n[dialects](https://github.com/tobymao/sqlglot/tree/main/sqlglot/dialects) can be added by subclassing `dialect`:\n\n```python\nfrom sqlglot import exp\nfrom sqlglot.dialects.dialect import dialect\nfrom sqlglot.generator import generator\nfrom sqlglot.tokens import tokenizer, tokentype\n\n\nclass custom(dialect):\n    class tokenizer(tokenizer):\n        quotes = [\"'\", '\"']\n        identifiers = [\"`\"]\n\n        keywords = {\n            **tokenizer.keywords,\n            \"int64\": tokentype.bigint,\n            \"float64\": tokentype.double,\n        }\n\n    class generator(generator):\n        transforms = {exp.array: lambda self, e: f\"[{self.expressions(e)}]\"}\n\n        type_mapping = {\n            exp.datatype.type.tinyint: \"int64\",\n            exp.datatype.type.smallint: \"int64\",\n            exp.datatype.type.int: \"int64\",\n            exp.datatype.type.bigint: \"int64\",\n            exp.datatype.type.decimal: \"numeric\",\n            exp.datatype.type.float: \"float64\",\n            exp.datatype.type.double: \"float64\",\n            exp.datatype.type.boolean: \"bool\",\n            exp.datatype.type.text: \"string\",\n        }\n\nprint(dialect[\"custom\"])\n```\n\n```\n<class '__main__.custom'>\n```\n\n### sql execution\n\none can even interpret sql queries using sqlglot, where the tables are represented as python dictionaries. although the engine is not very fast (it's not supposed to be) and is in a relatively early stage of development, it can be useful for unit testing and running sql natively across python objects. additionally, the foundation can be easily integrated with fast compute kernels (arrow, pandas). below is an example showcasing the execution of a select expression that involves aggregations and joins:\n\n```python\nfrom sqlglot.executor import execute\n\ntables = {\n    \"sushi\": [\n        {\"id\": 1, \"price\": 1.0},\n        {\"id\": 2, \"price\": 2.0},\n        {\"id\": 3, \"price\": 3.0},\n    ],\n    \"order_items\": [\n        {\"sushi_id\": 1, \"order_id\": 1},\n        {\"sushi_id\": 1, \"order_id\": 1},\n        {\"sushi_id\": 2, \"order_id\": 1},\n        {\"sushi_id\": 3, \"order_id\": 2},\n    ],\n    \"orders\": [\n        {\"id\": 1, \"user_id\": 1},\n        {\"id\": 2, \"user_id\": 2},\n    ],\n}\n\nexecute(\n    \"\"\"\n    select\n      o.user_id,\n      sum(s.price) as price\n    from orders o\n    join order_items i\n      on o.id = i.order_id\n    join sushi s\n      on i.sushi_id = s.id\n    group by o.user_id\n    \"\"\",\n    tables=tables\n)\n```\n\n```python\nuser_id price\n      1   4.0\n      2   3.0\n```\n\nsee also: [writing a python sql engine from scratch](https://github.com/tobymao/sqlglot/blob/main/posts/python_sql_engine.md).\n\n## used by\n\n* [sqlmesh](https://github.com/tobikodata/sqlmesh)\n* [fugue](https://github.com/fugue-project/fugue)\n* [ibis](https://github.com/ibis-project/ibis)\n* [mysql-mimic](https://github.com/kelsin/mysql-mimic)\n* [querybook](https://github.com/pinterest/querybook)\n* [quokka](https://github.com/marsupialtail/quokka)\n* [splink](https://github.com/moj-analytical-services/splink)\n\n## documentation\n\nsqlglot uses [pdoc](https://pdoc.dev/) to serve its api documentation.\n\na hosted version is on the [sqlglot website](https://sqlglot.com/), or you can build locally with:\n\n```\nmake docs-serve\n```\n\n## run tests and lint\n\n```\nmake style  # only linter checks\nmake unit   # only unit tests\nmake check  # full test suite & linter checks\n```\n\n## benchmarks\n\n[benchmarks](https://github.com/tobymao/sqlglot/blob/main/benchmarks/bench.py) run on python 3.10.5 in seconds.\n\n|           query |         sqlglot |        sqlfluff |         sqltree |        sqlparse |  moz_sql_parser |        sqloxide |\n| --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- |\n|            tpch |   0.01308 (1.0) | 1.60626 (122.7) | 0.01168 (0.893) | 0.04958 (3.791) | 0.08543 (6.531) | 0.00136 (0.104) |\n|           short |   0.00109 (1.0) | 0.14134 (129.2) | 0.00099 (0.906) | 0.00342 (3.131) | 0.00652 (5.970) | 8.76e-5 (0.080) |\n|            long |   0.01399 (1.0) | 2.12632 (151.9) | 0.01126 (0.805) | 0.04410 (3.151) | 0.06671 (4.767) | 0.00107 (0.076) |\n|           crazy |   0.03969 (1.0) | 24.3777 (614.1) | 0.03917 (0.987) | 11.7043 (294.8) | 1.03280 (26.02) | 0.00625 (0.157) |\n\n\n## optional dependencies\n\nsqlglot uses [dateutil](https://github.com/dateutil/dateutil) to simplify literal timedelta expressions. the optimizer will not simplify expressions like the following if the module cannot be found:\n\n```sql\nx + interval '1' month\n```\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "acryl-sqlglot",
  "package_url": "https://pypi.org/project/acryl-sqlglot/",
  "project_url": "https://pypi.org/project/acryl-sqlglot/",
  "project_urls": {
    "Homepage": "https://github.com/tobymao/sqlglot"
  },
  "release_url": "https://pypi.org/project/acryl-sqlglot/20.4.1.dev14/",
  "requires_dist": [
    "autoflake ; extra == 'dev'",
    "black ; extra == 'dev'",
    "duckdb >=0.6 ; extra == 'dev'",
    "isort ; extra == 'dev'",
    "mypy >=0.990 ; extra == 'dev'",
    "pandas ; extra == 'dev'",
    "pyspark ; extra == 'dev'",
    "python-dateutil ; extra == 'dev'",
    "pdoc ; extra == 'dev'",
    "pre-commit ; extra == 'dev'",
    "types-python-dateutil ; extra == 'dev'",
    "maturin <2.0,>=1.4 ; extra == 'dev'",
    "sqlglotrs ==0.1.0 ; extra == 'rs'"
  ],
  "requires_python": ">=3.7",
  "summary": "an easily customizable sql parser and transpiler",
  "version": "20.4.1.dev14",
  "releases": [],
  "developers": [
    "toby.mao@gmail.com",
    "toby_mao"
  ],
  "kwds": "sqlglot sqlfluff sqlmesh python_sql_engine moz_sql_parser",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_acryl_sqlglot",
  "homepage": "https://github.com/tobymao/sqlglot",
  "release_count": 9,
  "dependency_ids": [
    "pypi_autoflake",
    "pypi_black",
    "pypi_duckdb",
    "pypi_isort",
    "pypi_maturin",
    "pypi_mypy",
    "pypi_pandas",
    "pypi_pdoc",
    "pypi_pre_commit",
    "pypi_pyspark",
    "pypi_python_dateutil",
    "pypi_sqlglotrs",
    "pypi_types_python_dateutil"
  ]
}