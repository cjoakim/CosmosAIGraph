{
  "classifiers": [
    "environment :: console",
    "intended audience :: developers",
    "license :: osi approved :: bsd license",
    "operating system :: macos",
    "operating system :: posix",
    "operating system :: unix",
    "programming language :: python",
    "programming language :: python :: 2",
    "programming language :: python :: 3",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "ecs deploy\n----------\n\n.. image:: https://badge.fury.io/py/ecs-deploy.svg\n    :target: https://badge.fury.io/py/ecs-deploy\n\n.. image:: https://github.com/fabfuel/ecs-deploy/actions/workflows/build.yml/badge.svg\n    :target: https://github.com/fabfuel/ecs-deploy/actions/workflows/build.yml\n\n`ecs-deploy` simplifies deployments on amazon ecs by providing a convenience cli tool for complex actions, which are executed pretty often.\n\nkey features\n------------\n- support for complex task definitions (e.g. multiple containers & task role)\n- easily redeploy the current task definition (including `docker pull` of eventually updated images)\n- deploy new versions/tags or all containers or just a single container in your task definition\n- scale up or down by adjusting the desired count of running tasks\n- add or adjust containers environment variables\n- run one-off tasks from the cli\n- automatically monitor deployments in new relic\n\ntl;dr\n-----\ndeploy a new version of your service::\n\n    $ ecs deploy my-cluster my-service --tag 1.2.3\n\nredeploy the current version of a service::\n\n    $ ecs deploy my-cluster my-service\n\nscale up or down a service::\n\n    $ ecs scale my-cluster my-service 4\n\nupdating a cron job::\n\n    $ ecs cron my-cluster my-task my-rule\n\nupdate a task definition (without running or deploying)::\n\n    $ ecs update my-task\n\n\ninstallation\n------------\n\nthe project is available on pypi. simply run::\n\n    $ pip install ecs-deploy\n\n\nrun via docker\n--------------\ninstead of installing **ecs-deploy** locally, which requires a python environment, you can run **ecs-deploy** via docker. all versions starting from 1.7.1 are available on docker hub: https://cloud.docker.com/repository/docker/fabfuel/ecs-deploy\n\nrunning **ecs-deploy** via docker is easy as::\n\n    docker run fabfuel/ecs-deploy:1.10.2\n    \nin this example, the stable version 1.10.2 is executed. alternatively you can use docker tags ``master`` or ``latest`` for the latest stable version or docker tag ``develop`` for the newest development version of **ecs-deploy**.\n\nplease be aware, that when running **ecs-deploy** via docker, the configuration - as described below - does not apply. you have to provide credentials and the aws region via the command as attributes or environment variables::\n\n    docker run fabfuel/ecs-deploy:1.10.2 ecs deploy my-cluster my-service --region eu-central-1 --access-key-id abc --secret-access-key abc\n\n\nconfiguration\n-------------\nas **ecs-deploy** is based on boto3 (the official aws python library), there are several ways to configure and store the\nauthentication credentials. please read the boto3 documentation for more details\n(http://boto3.readthedocs.org/en/latest/guide/configuration.html#configuration). the simplest way is by running::\n\n    $ aws configure\n\nalternatively you can pass the aws credentials (via `--access-key-id` and `--secret-access-key`) or the aws\nconfiguration profile (via `--profile`) as options when you run `ecs`.\n\naws iam\n-------\n\nif you are using **ecs-deploy** with a role or user account that does not have full aws access, such as in a deploy script, you will\nneed to use or create an iam policy with the correct set of permissions in order for your deploys to succeed. one option is to use the \npre-specified ``amazonecs_fullaccess`` (https://docs.aws.amazon.com/amazonecs/latest/userguide/security-iam-awsmanpol.html#security-iam-awsmanpol-amazonecs_fullaccess) policy. if you would prefer to create a role with a more minimal set of permissions,\nthe following are required:\n\n* ``ecs:listservices``\n* ``ecs:updateservice``\n* ``ecs:listtasks``\n* ``ecs:registertaskdefinition``\n* ``ecs:describeservices``\n* ``ecs:describetasks``\n* ``ecs:listtaskdefinitions``\n* ``ecs:describetaskdefinition``\n* ``ecs:deregistertaskdefinition``\n \nif using custom iam permissions, you will also need to set the ``iam:passrole`` policy for each iam role. see here https://docs.aws.amazon.com/iam/latest/userguide/id_roles_use_passrole.html for more information.\n\nnote that not every permission is required for every action you can take in **ecs-deploy**. you may be able to adjust permissions based on your specific needs.\n\nactions\n-------\ncurrently the following actions are supported:\n\ndeploy\n======\nredeploy a service either without any modifications or with a new image, environment variable, docker label, and/or command definition.\n\nscale\n=====\nscale a service up or down and change the number of running tasks.\n\nrun\n===\nrun a one-off task based on an existing task-definition and optionally override command, environment variables and/or docker labels.\n\nupdate\n======\nupdate a task definition by creating a new revision to set a new image,\nenvironment variable, docker label, and/or command definition, etc.\n\ncron (scheduled task)\n=====================\nupdate a task definition and update a events rule (scheduled task) to use the\nnew task definition.\n\n\nusage\n-----\n\nfor detailed information about the available actions, arguments and options, run::\n\n    $ ecs deploy --help\n    $ ecs scale --help\n    $ ecs run --help\n\nexamples\n--------\nall examples assume, that authentication has already been configured.\n\ndeployment\n----------\n\nsimple redeploy\n===============\nto redeploy a service without any modifications, but pulling the most recent image versions, run the following command.\nthis will duplicate the current task definition and cause the service to redeploy all running tasks.::\n\n    $ ecs deploy my-cluster my-service\n\n\ndeploy a new tag\n================\nto change the tag for **all** images in **all** containers in the task definition, run the following command::\n\n    $ ecs deploy my-cluster my-service -t 1.2.3\n\n\ndeploy a new image\n==================\nto change the image of a specific container, run the following command::\n\n    $ ecs deploy my-cluster my-service --image webserver nginx:1.11.8\n\nthis will modify the **webserver** container only and change its image to \"nginx:1.11.8\".\n\n\ndeploy several new images\n=========================\nthe `-i` or `--image` option can also be passed several times::\n\n    $ ecs deploy my-cluster my-service -i webserver nginx:1.9 -i application my-app:1.2.3\n\nthis will change the **webserver**'s container image to \"nginx:1.9\" and the **application**'s image to \"my-app:1.2.3\".\n\ndeploy a custom task definition\n===============================\nto deploy any task definition (independent of which is currently used in the service), you can use the ``--task`` parameter. the value can be:\n\na fully qualified task arn::\n\n    $ ecs deploy my-cluster my-service --task arn:aws:ecs:eu-central-1:123456789012:task-definition/my-task:20\n\na task family name with revision::\n\n    $ ecs deploy my-cluster my-service --task my-task:20\n\nor just a task family name. it this case, the most recent revision is used::\n\n    $ ecs deploy my-cluster my-service --task my-task\n\n.. important::\n   ``ecs`` will still create a new task definition, which then is used in the service.\n   this is done, to retain consistent behaviour and to ensure the ecs agent e.g. pulls all images.\n   but the newly created task definition will be based on the given task, not the currently used task.\n\n\nset an environment variable\n===========================\nto add a new or adjust an existing environment variable of a specific container, run the following command::\n\n    $ ecs deploy my-cluster my-service -e webserver some_variable some_value\n\nthis will modify the **webserver** container definition and add or overwrite the environment variable `some_variable` with the value \"some_value\". this way you can add new or adjust already existing environment variables.\n\n\nadjust multiple environment variables\n=====================================\nyou can add or change multiple environment variables at once, by adding the `-e` (or `--env`) options several times::\n\n    $ ecs deploy my-cluster my-service -e webserver some_variable some_value -e webserver other_variable other_value -e app app_variable app_value\n\nthis will modify the definition **of two containers**.\nthe **webserver**'s environment variable `some_variable` will be set to \"some_value\" and the variable `other_variable` to \"other_value\".\nthe **app**'s environment variable `app_variable` will be set to \"app_value\".\n\n\nset environment variables exclusively, remove all other pre-existing environment variables\n==========================================================================================\nto reset all existing environment variables of a task definition, use the flag ``--exclusive-env`` ::\n\n    $ ecs deploy my-cluster my-service -e webserver some_variable some_value --exclusive-env\n\nthis will remove **all other** existing environment variables of **all containers** of the task definition, except for the variable `some_variable` with the value \"some_value\" in the webserver container.\n\n\nset a secret environment variable from the aws parameter store\n==============================================================\n\n.. important::\n    this option was introduced by aws in ecs agent v1.22.0. make sure your ecs agent version is >= 1.22.0 or else your task will not deploy.\n\nto add a new or adjust an existing secret of a specific container, run the following command::\n\n    $ ecs deploy my-cluster my-service -s webserver some_secret key_of_secret_in_parameter_store\n\nyou can also specify the full arn of the parameter::\n\n    $ ecs deploy my-cluster my-service -s webserver some_secret arn:aws:ssm:<aws region>:<aws account id>:parameter/key_of_secret_in_parameter_store\n\nthis will modify the **webserver** container definition and add or overwrite the environment variable `some_secret` with the value of the `key_of_secret_in_parameter_store` in the aws parameter store of the aws systems manager.\n\n\nset secrets exclusively, remove all other pre-existing secret environment variables\n===================================================================================\nto reset all existing secrets (secret environment variables) of a task definition, use the flag ``--exclusive-secrets`` ::\n\n    $ ecs deploy my-cluster my-service -s webserver new_secret key_of_secret_in_parameter_store --exclusive-secret\n\nthis will remove **all other** existing secret environment variables of **all containers** of the task definition, except for the new secret variable `new_secret` with the value coming from the aws parameter store with the name \"key_of_secret_in_parameter_store\" in the webserver container.\n\n\nset environment via .env files\n==============================\ninstead of setting environment variables separately, you can pass a .env file per container to set the whole environment at once. you can either point to a local file or a file stored on s3, via::\n\n    $ ecs deploy my-cluster my-service --env-file my-app env/my-app.env\n\n    $ ecs deploy my-cluster my-service --s3-env-file my-app arn:aws:s3:::my-ecs-environment/my-app.env\n\nset secrets via .env files\n==============================\ninstead of setting secrets separately, you can pass a .env file per container to set all secrets at once.\n\nthis will expect an env file format, but any values will be set as the `valuefrom` parameter in the secrets config.\nthis value can be either the path or the full arn of a secret in the aws parameter store. for example, with a secrets.env\nfile like the following:\n\n```\nsome_secret=arn:aws:ssm:<aws region>:<aws account id>:parameter/key_of_secret_in_parameter_store\n```\n\n$ ecs deploy my-cluster my-service --secret-env-file webserver env/secrets.env\n\nthis will modify the **webserver** container definition and add or overwrite the environment variable `some_secret` with the value of the `key_of_secret_in_parameter_store` in the aws parameter store of the aws systems manager.\n\n\nset a docker label\n===================\nto add a new or adjust an existing docker labels of a specific container, run the following command::\n\n    $ ecs deploy my-cluster my-service -d webserver somelabel somevalue\n\nthis will modify the **webserver** container definition and add or overwrite the docker label \"somelabel\" with the value \"somevalue\". this way you can add new or adjust already existing docker labels.\n\n\nadjust multiple docker labels\n=============================\nyou can add or change multiple docker labels at once, by adding the `-d` (or `--docker-label`) options several times::\n\n    $ ecs deploy my-cluster my-service -d webserver somelabel somevalue -d webserver otherlabel othervalue -d app applabel appvalue\n\nthis will modify the definition **of two containers**.\nthe **webserver**'s docker label \"somelabel\" will be set to \"somevalue\" and the label \"otherlabel\" to \"othervalue\".\nthe **app**'s docker label \"applabel\" will be set to \"appvalue\".\n\n\nset docker labels exclusively, remove all other pre-existing docker labels\n==========================================================================\nto reset all existing docker labels of a task definition, use the flag ``--exclusive-docker-labels`` ::\n\n    $ ecs deploy my-cluster my-service -d webserver somelabel somevalue --exclusive-docker-labels\n\nthis will remove **all other** existing docker labels of **all containers** of the task definition, except for the label \"somelabel\" with the value \"somevalue\" in the webserver container.\n\n\nmodify a command\n================\nto change the command of a specific container, run the following command::\n\n    $ ecs deploy my-cluster my-service --command webserver \"nginx\"\n\nthis will modify the **webserver** container and change its command to \"nginx\". if you have \na command that requires arguments as well, then you can simply specify it like this as you would normally do:\n\n    $ ecs deploy my-cluster my-service --command webserver \"ngnix -c /etc/ngnix/ngnix.conf\"\n\nthis works fine as long as any of the arguments do not contain any spaces. in case arguments to the\ncommand itself contain spaces, then you can use the json format:\n\n$ ecs deploy my-cluster my-service --command webserver '[\"sh\", \"-c\", \"while true; do echo time files like an arrow $(date); sleep 1; done;\"]'\n\nmore about this can be looked up in documentation.\nhttps://docs.aws.amazon.com/amazonecs/latest/developerguide/task_definition_parameters.html#container_definitions\n\n\n\n\nset a task role\n===============\nto change or set the role, the service's task should run as, use the following command::\n\n    $ ecs deploy my-cluster my-service -r arn:aws:iam::123456789012:role/myspecialecstaskrole\n\nthis will set the task role to \"myspecialecstaskrole\".\n\n\nset cpu and memory reservation\n==============================\n- set the `cpu` value for a task: :code:`--task-cpu 0`.\n- set the `cpu` value for a task container: :code:`--cpu <container_name> 0`.\n- set the `memory` value (`hard limit`) for a task: :code:`--task-memory 256`.\n- set the `memory` value (`hard limit`) for a task container: :code:`--memory <container_name> 256`.\n- set the `memoryreservation` value (`soft limit`) for a task definition: :code:`--memoryreservation <container_name> 256`.\n\nset privileged or essential flags\n=================================\n- set the `privileged` value for a task definition: :code:`--privileged <container_name> true|false`.\n- set the `essential` value for a task definition: :code:`--essential <container_name> true|false`.\n\nset logging configuration\n=========================\nset the `logconfiguration` values for a task definition::\n\n    --log <container_name> awslogs awslogs-group <log_group_name>\n    --log <container_name> awslogs awslogs-region <region>\n    --log <container_name> awslogs awslogs-stream-prefix <stream_prefix>\n\n\nset port mapping\n================\n- set the `port mappings` values for a task definition: :code:`--port <container_name> <container_port> <host_port>`.\n\n  - supports :code:`--exclusive-ports`.\n  - the `protocol` is fixed to `tcp`.\n\nset volumes & mount points\n==========================\n- set the `volumes` values for a task definition :code:`--volume <volume_name> /host/path`.\n\n  - :code:`<volume_name>` can then be used with  :code:`--mount`.\n- set the `mount points` values for a task definition: :code:`--mount <container_name> <volume_name> /container/path`.\n\n  - supports :code:`--exclusive-mounts`.\n\n  - :code:`<volume_name>` is the one set by :code:`--volume`.\n- set the `ulimits` values for a task definition: :code:`--ulimit <container_name> memlock 67108864 67108864`.\n\n  - supports :code:`--exclusive-ulimits`.\n- set the `systemcontrols` values for a task definition: :code:`--system-control <container_name> net.core.somaxconn 511`.\n\n  - supports :code:`--exclusive-system-controls`.\n- set the `healthcheck` values for a task definition: :code:`--health-check <container_name> <command> <interval> <timeout> <retries> <start_period>`.\n\n\nset health checks\n=================\n  - example :code:`--health-check webserver \"curl -f http://localhost/alive/\" 30 5 3 0`\n\n\nplaceholder container\n=====================\n- add placeholder containers: :code:`--add-container <container_name>`.\n- to comply with the minimum requirements for a task definition, a placeholder container is set like this:\n    + the container name is :code:`<container_name>`.\n    + the container image is :code:`placeholder`.\n    + the container soft limit is :code:`128`.\n- the idea is to set sensible values with the deployment.\n\nit is possible to add and define a new container with the same deployment::\n\n      --add-container redis --image redis redis:6 --port redis 6379 6379\n\nremove containers\n=================\n- containers can be removed: :code:`--remove-container <container_name>`.\n\n  - leaves the original containers, if all containers would be removed.\n\n\nall but the container flags can be used with `ecs deploy` and `ecs cron`.\nthe container flags are used with `ecs deploy` only.\n\n\nignore capacity issues\n======================\nif your cluster is undersized or the service's deployment options are not optimally set, the cluster\nmight be incapable to run blue-green-deployments. in this case, you might see errors like these:\n\n    error: (service my-service) was unable to place a task because no container instance met all of\n    its requirements. the closest matching (container-instance 123456-1234-1234-1234-1234567890) is\n    already using a port required by your task. for more information, see the troubleshooting\n    section of the amazon ecs developer guide.\n\nthere might also be warnings about insufficient memory or cpu.\n\nto ignore these warnings, you can run the deployment with the flag ``--ignore-warnings``::\n\n    $ ecs deploy my-cluster my-service --ignore-warnings\n\nin that case, the warning is printed, but the script continues and waits for a successful\ndeployment until it times out.\n\ndeployment timeout\n==================\nthe deploy and scale actions allow defining a timeout (in seconds) via the ``--timeout`` parameter.\nthis instructs ecs-deploy to wait for ecs to finish the deployment for the given number of seconds.\n\nto run a deployment without waiting for the successful or failed result at all, set ``--timeout`` to the value of ``-1``.\n\n\nmulti-account setup\n===================\nif you manage different environments of your system in multiple differnt aws accounts, you can now easily assume a\ndeployment role in the target account in which your ecs cluster is running. you only need to provide ``--account``\nwith the aws account id and ``--assume-role`` with the name of the role you want to assume in the target account.\necs-deploy automatically assumes this role and deploys inside your target account:\n\nexample::\n\n    $ ecs deploy my-cluster my-service --account 1234567890 --assume-role ecsdeployrole\n\n\n\n\nscaling\n-------\n\nscale a service\n===============\nto change the number of running tasks and scale a service up and down, run this command::\n\n    $ ecs scale my-cluster my-service 4\n\n\nrunning a task\n--------------\n\nrun a one-off task\n==================\nto run a one-off task, based on an existing task-definition, run this command::\n\n    $ ecs run my-cluster my-task\n\nyou can define just the task family (e.g. ``my-task``) or you can run a specific revision of the task-definition (e.g.\n``my-task:123``). and optionally you can add or adjust environment variables like this::\n\n    $ ecs run my-cluster my-task:123 -e my-container my_variable \"my value\"\n\n\nrun a task with a custom command\n================================\n\nyou can override the command definition via option ``-c`` or ``--command`` followed by the container name and the\ncommand in a natural syntax, e.g. no conversion to comma-separation required::\n\n    $ ecs run my-cluster my-task -c my-container \"python some-script.py param1 param2\"\n\nthe json syntax explained above regarding modifying a command is also applicable here.\n\n\nrun a task in a fargate cluster\n===============================\n\nif you want to run a one-off task in a fargate cluster, additional configuration is required, to instruct aws e.g. which\nsubnets or security groups to use. the required parameters for this are:\n\n- launchtype\n- securitygroup\n- subnet\n- public-ip\n\nexample::\n\n    $ ecs run my-fargate-cluster my-task --launchtype=fargate --securitygroup sg-01234567890123456 --subnet subnet-01234567890123456 --public-ip\n\nyou can pass multiple ``subnet`` as well as multiple ``securitygroup`` values. the ``public-ip`` flag determines, if the task receives a public ip address or not.\nplease see ``ecs run --help`` for more details.\n\n\nmonitoring\n----------\nwith ecs deploy you can track your deployments automatically. currently only new relic is supported:\n\nnew relic\n=========\nto record a deployment in new relic, you can provide the the api key (**attention**: this is a specific rest api key, not the license key) and the application id in two ways:\n\nvia cli options::\n\n    $ ecs deploy my-cluster my-service --newrelic-apikey abcdefghijklmn --newrelic-appid 1234567890\n\nor implicitly via environment variables ``new_relic_api_key`` and ``new_relic_app_id`` ::\n\n    $ export new_relic_api_key=abcdefghijklmn\n    $ export new_relic_app_id=1234567890\n    $ ecs deploy my-cluster my-service\n\noptionally you can provide additional information for the deployment:\n\n- ``--comment \"new feature x\"`` - comment to the deployment\n- ``--user john.doe`` - the name of the user who deployed with\n- ``--newrelic-revision 1.0.0`` - explicitly set the revision to use for the deployment\n\nnote: if neither ``--tag`` nor ``--newrelic-revision`` are provided, the deployment will not be recorded.\n\n\ntroubleshooting\n---------------\nif the service configuration in ecs is not optimally set, you might be seeing\ntimeout or other errors during the deployment.\n\ntimeout\n=======\nthe timeout error means, that aws ecs takes longer for the full deployment cycle then ecs-deploy is told to wait. the deployment itself still might finish successfully, if there are no other problems with the deployed containers.\n\nyou can increase the time (in seconds) to wait for finishing the deployment via the ``--timeout`` parameter. this time includes the full cycle of stopping all old containers and (re)starting all new containers. different stacks require different timeout values, the default is 300 seconds.\n\nthe overall deployment time depends on different things:\n\n- the type of the application. for example node.js containers tend to take a long time to get stopped. but nginx containers tend to stop immediately, etc.\n- are old and new containers able to run in parallel (e.g. using dynamic ports)?\n- the deployment options and strategy (maximum percent > 100)?\n- the desired count of running tasks, compared to\n- the number of ecs instances in the cluster\n\n\nalternative implementation\n--------------------------\nthere are some other libraries/tools available on github, which also handle the deployment of containers in aws ecs. if you prefer another language over python, have a look at these projects:\n\nshell\n  ecs-deploy - https://github.com/silinternational/ecs-deploy\n\nruby\n  broadside - https://github.com/lumoslabs/broadside\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "bsd-3-clause",
  "name": "ecs-deploy",
  "package_url": "https://pypi.org/project/ecs-deploy/",
  "project_url": "https://pypi.org/project/ecs-deploy/",
  "project_urls": {
    "Download": "https://github.com/fabfuel/ecs-deploy/archive/1.14.0.tar.gz",
    "Homepage": "https://github.com/fabfuel/ecs-deploy"
  },
  "release_url": "https://pypi.org/project/ecs-deploy/1.14.0/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "powerful cli tool to simplify amazon ecs deployments, rollbacks & scaling",
  "version": "1.14.0",
  "releases": [],
  "developers": [
    "fabian_fuelling",
    "pypi@fabfuel.de"
  ],
  "kwds": "deployments ecs deploys deployment aws",
  "license_kwds": "bsd-3-clause",
  "libtype": "pypi",
  "id": "pypi_ecs_deploy",
  "homepage": "https://github.com/fabfuel/ecs-deploy",
  "release_count": 31,
  "dependency_ids": []
}