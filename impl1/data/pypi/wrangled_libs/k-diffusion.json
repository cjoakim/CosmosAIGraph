{
  "classifiers": [],
  "description": "# k-diffusion\n\nan implementation of [elucidating the design space of diffusion-based generative models](https://arxiv.org/abs/2206.00364) (karras et al., 2022) for pytorch, with enhancements and additional features, such as improved sampling algorithms and transformer-based diffusion models.\n\n## installation\n\n`k-diffusion` can be installed via pypi (`pip install k-diffusion`) but it will not include training and inference scripts, only library code that others can depend on. to run the training and inference scripts, clone this repository and run `pip install -e <path to repository>`.\n\n## training\n\nto train models:\n\n```sh\n$ ./train.py --config config_file --name run_name\n```\n\nfor instance, to train a model on mnist:\n\n```sh\n$ ./train.py --config configs/config_mnist_transformer.json --name run_name\n```\n\nthe configuration file allows you to specify the dataset type. currently supported types are `\"imagefolder\"` (finds all images in that folder and its subfolders, recursively), `\"cifar10\"` (cifar-10), and `\"mnist\"` (mnist). `\"huggingface\"` [hugging face datasets](https://huggingface.co/docs/datasets/index) is also supported.\n\nmulti-gpu and multi-node training is supported with [hugging face accelerate](https://huggingface.co/docs/accelerate/index). you can configure accelerate by running:\n\n```sh\n$ accelerate config\n```\n\nthen running:\n\n```sh\n$ accelerate launch train.py --config config_file --name run_name\n```\n\n## enhancements/additional features\n\n- k-diffusion has support for training transformer-based diffusion models (like [dit](https://arxiv.org/abs/2212.09748) but improved).\n\n- k-diffusion supports a soft version of [min-snr loss weighting](https://arxiv.org/abs/2303.09556) for improved training at high resolutions with less hyperparameters than the loss weighting used in karras et al. (2022).\n\n- k-diffusion has wrappers for [v-diffusion-pytorch](https://github.com/crowsonkb/v-diffusion-pytorch), [openai diffusion](https://github.com/openai/guided-diffusion), and [compvis diffusion](https://github.com/compvis/latent-diffusion) models allowing them to be used with its samplers and ode/sde.\n\n- k-diffusion implements [dpm-solver](https://arxiv.org/abs/2206.00927), which produces higher quality samples at the same number of function evalutions as karras algorithm 2, as well as supporting adaptive step size control. [dpm-solver++(2s) and (2m)](https://arxiv.org/abs/2211.01095) are implemented now too for improved quality with low numbers of steps.\n\n- k-diffusion supports [clip](https://openai.com/blog/clip/) guided sampling from unconditional diffusion models (see `sample_clip_guided.py`).\n\n- k-diffusion supports log likelihood calculation (not a variational lower bound) for native models and all wrapped models.\n\n- k-diffusion can calculate, during training, the [fid](https://papers.nips.cc/paper/2017/file/8a1d694707eb0fefe65871369074926d-paper.pdf) and [kid](https://arxiv.org/abs/1801.01401) vs the training set.\n\n- k-diffusion can calculate, during training, the gradient noise scale (1 / snr), from _an empirical model of large-batch training_, https://arxiv.org/abs/1812.06162).\n\n## to do\n\n- latent diffusion\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "k-diffusion",
  "package_url": "https://pypi.org/project/k-diffusion/",
  "project_url": "https://pypi.org/project/k-diffusion/",
  "project_urls": {
    "Homepage": "https://github.com/crowsonkb/k-diffusion"
  },
  "release_url": "https://pypi.org/project/k-diffusion/0.1.1.post1/",
  "requires_dist": [
    "accelerate",
    "clean-fid",
    "clip-anytorch",
    "dctorch",
    "einops",
    "jsonmerge",
    "kornia",
    "Pillow",
    "safetensors",
    "scikit-image",
    "scipy",
    "torch >=2.0",
    "torchdiffeq",
    "torchsde",
    "torchvision",
    "tqdm",
    "wandb"
  ],
  "requires_python": "",
  "summary": "karras et al. (2022) diffusion models for pytorch",
  "version": "0.1.1.post1",
  "releases": [],
  "developers": [
    "crowsonkb@gmail.com",
    "katherine_crowson"
  ],
  "kwds": "pytorch pip diffusion batch models",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_k_diffusion",
  "homepage": "https://github.com/crowsonkb/k-diffusion",
  "release_count": 17,
  "dependency_ids": [
    "pypi_accelerate",
    "pypi_clean_fid",
    "pypi_clip_anytorch",
    "pypi_dctorch",
    "pypi_einops",
    "pypi_jsonmerge",
    "pypi_kornia",
    "pypi_pillow",
    "pypi_safetensors",
    "pypi_scikit_image",
    "pypi_scipy",
    "pypi_torch",
    "pypi_torchdiffeq",
    "pypi_torchsde",
    "pypi_torchvision",
    "pypi_tqdm",
    "pypi_wandb"
  ]
}