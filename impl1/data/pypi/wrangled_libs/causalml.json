{
  "classifiers": [
    "license :: osi approved :: apache software license",
    "operating system :: os independent",
    "programming language :: python"
  ],
  "description": "<div align=\"center\">\n  <a href=\"https://github.com/uber/causalml\"><img width=\"380px\" height=\"140px\" src=\"https://raw.githubusercontent.com/uber/causalml/master/docs/_static/img/logo/causalml_logo.png\"></a>\n</div>\n\n------------------------------------------------------\n\n[![pypi version](https://badge.fury.io/py/causalml.svg)](https://pypi.org/project/causalml/)\n[![build status](https://github.com/uber/causalml/actions/workflows/python-test.yaml/badge.svg)](https://github.com/uber/causalml/actions/workflows/python-test.yaml)\n[![documentation status](https://readthedocs.org/projects/causalml/badge/?version=latest)](http://causalml.readthedocs.io/en/latest/?badge=latest)\n[![downloads](https://static.pepy.tech/badge/causalml)](https://pepy.tech/project/causalml)\n[![cii best practices](https://bestpractices.coreinfrastructure.org/projects/3015/badge)](https://bestpractices.coreinfrastructure.org/projects/3015)\n\n\n# disclaimer\nthis project is stable and being incubated for long-term support. it may contain new experimental code, for which apis are subject to change.\n\n# causal ml: a python package for uplift modeling and causal inference with ml\n\n**causal ml** is a python package that provides a suite of uplift modeling and causal inference methods using machine learning algorithms based on recent\nresearch [[1]](#literature). it provides a standard interface that allows user to estimate the conditional average treatment effect (cate) or individual treatment\n effect (ite) from experimental or observational data. essentially, it estimates the causal impact of intervention `t` on outcome `y` for users\n with observed features `x`, without strong assumptions on the model form. typical use cases include\n\n* **campaign targeting optimization**: an important lever to increase roi in an advertising campaign is to target the ad to the set of customers who will have a favorable response in a given kpi such as engagement or sales. cate identifies these customers by estimating the effect of the kpi from ad exposure at the individual level from a/b experiment or historical observational data.\n\n* **personalized engagement**: a company has multiple options to interact with its customers such as different product choices in up-sell or messaging channels for communications. one can use cate to estimate the heterogeneous treatment effect for each customer and treatment option combination for an optimal personalized recommendation system.\n\nthe package currently supports the following methods\n\n* **tree-based algorithms**\n    * uplift tree/random forests on kl divergence, euclidean distance, and chi-square [[2]](#literature)\n    * uplift tree/random forests on contextual treatment selection [[3]](#literature)\n    * uplift tree/random forests on ddp [[4]](#literature)\n    * uplift tree/random forests on iddp [[5]](#literature)\n    * interaction tree [[6]](#literature)\n    * conditional interaction tree [[7]](#literature)\n    * causal tree [[8]](#literature) - work-in-progress\n* **meta-learner algorithms**\n    * s-learner [[9]](#literature)\n    * t-learner [[9]](#literature)\n    * x-learner [[9]](#literature)\n    * r-learner [[10]](#literature)\n    * doubly robust (dr) learner [[11]](#literature)\n    * tmle learner [[12]](#literature)\n* **instrumental variables algorithms**\n    * 2-stage least squares (2sls)\n    * doubly robust (dr) iv [[13]](#literature)\n* **neural-network-based algorithms**\n    * cevae [[14]](#literature)\n    * dragonnet [[15]](#literature) - with `causalml[tf]` installation (see [installation](#installation))\n\n\n# installation\n\ninstallation with `conda` is recommended.\n\n`conda` environment files for python 3.7, 3.8 and 3.9 are available in the repository. to use models under the `inference.tf` module (e.g. `dragonnet`), additional dependency of `tensorflow` is required. for detailed instructions, see below.\n\n## install using `conda`:\n\ninstall `conda` with:\n\n```\nwget https://repo.anaconda.com/miniconda/miniconda3-py38_23.5.0-3-linux-x86_64.sh\nbash miniconda3-py38_23.5.0-3-linux-x86_64.sh -b\nsource miniconda3/bin/activate \nconda init\nsource ~/.bashrc \n```\n\n### install from `conda-forge`\ndirectly install from the conda-forge channel using conda.\n\n```sh\nconda install -c conda-forge causalml\n```\n\n### install with the `conda` virtual environment\nthis will create a new `conda` virtual environment named `causalml-[tf-]py3x`, where `x` is in `[6, 7, 8, 9]`. e.g. `causalml-py37` or `causalml-tf-py38`. if you want to change the name of the environment, update the relevant yaml file in `envs/`\n\n```bash\ngit clone https://github.com/uber/causalml.git\ncd causalml/envs/\nconda env create -f environment-py38.yml\t# for the virtual environment with python 3.8 and causalml\nconda activate causalml-py38\n(causalml-py38)\n```\n\n### install `causalml` with `tensorflow`\n```bash\ngit clone https://github.com/uber/causalml.git\ncd causalml/envs/\nconda env create -f environment-tf-py38.yml\t# for the virtual environment with python 3.8 and causalml\nconda activate causalml-tf-py38\n(causalml-tf-py38) pip install -u numpy\t\t\t# this step is necessary to fix [#338](https://github.com/uber/causalml/issues/338)\n```\n\n## install from `pypi`:\n\n```bash\npip install causalml\n```\n\n### install `causalml` with `tensorflow`\n```bash\npip install causalml[tf]\npip install -u numpy\t\t\t\t\t\t\t# this step is necessary to fix [#338](https://github.com/uber/causalml/issues/338)\n```\n\n## install from source:\n\n### create a clean conda environment\n\n```\nconda create -n causalml-py38 python=3.8\nconda activate causalml-py38\nconda install -c conda-forge cxx-compiler\nconda install python-graphviz\nconda install -c conda-forge xorg-libxrender\n```\n\nthen:\n\n```bash\ngit clone https://github.com/uber/causalml.git\ncd causalml\npip install .\npython setup.py build_ext --inplace\n```\n\nwith `tensorflow`:\n\n```bash\npip install .[tf]\n```\n\n\n# quick start\n\n## average treatment effect estimation with s, t, x, and r learners\n\n```python\nfrom causalml.inference.meta import lrsregressor\nfrom causalml.inference.meta import xgbtregressor, mlptregressor\nfrom causalml.inference.meta import basexregressor\nfrom causalml.inference.meta import baserregressor\nfrom xgboost import xgbregressor\nfrom causalml.dataset import synthetic_data\n\ny, x, treatment, _, _, e = synthetic_data(mode=1, n=1000, p=5, sigma=1.0)\n\nlr = lrsregressor()\nte, lb, ub = lr.estimate_ate(x, treatment, y)\nprint('average treatment effect (linear regression): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n\nxg = xgbtregressor(random_state=42)\nte, lb, ub = xg.estimate_ate(x, treatment, y)\nprint('average treatment effect (xgboost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n\nnn = mlptregressor(hidden_layer_sizes=(10, 10),\n                 learning_rate_init=.1,\n                 early_stopping=true,\n                 random_state=42)\nte, lb, ub = nn.estimate_ate(x, treatment, y)\nprint('average treatment effect (neural network (mlp)): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n\nxl = basexregressor(learner=xgbregressor(random_state=42))\nte, lb, ub = xl.estimate_ate(x, treatment, y, e)\nprint('average treatment effect (basexregressor using xgboost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n\nrl = baserregressor(learner=xgbregressor(random_state=42))\nte, lb, ub =  rl.estimate_ate(x=x, p=e, treatment=treatment, y=y)\nprint('average treatment effect (baserregressor using xgboost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n```\n\nsee the [meta-learner example notebook](https://github.com/uber/causalml/blob/master/examples/meta_learners_with_synthetic_data.ipynb) for details.\n\n\n## interpretable causal ml\n\ncausal ml provides methods to interpret the treatment effect models trained as follows:\n\n### meta learner feature importances\n\n```python\nfrom causalml.inference.meta import basesregressor, basetregressor, basexregressor, baserregressor\nfrom causalml.dataset.regression import synthetic_data\n\n# load synthetic data\ny, x, treatment, tau, b, e = synthetic_data(mode=1, n=10000, p=25, sigma=0.5)\nw_multi = np.array(['treatment_a' if x==1 else 'control' for x in treatment]) # customize treatment/control names\n\nslearner = basesregressor(lgbmregressor(), control_name='control')\nslearner.estimate_ate(x, w_multi, y)\nslearner_tau = slearner.fit_predict(x, w_multi, y)\n\nmodel_tau_feature = randomforestregressor()  # specify model for model_tau_feature\n\nslearner.get_importance(x=x, tau=slearner_tau, model_tau_feature=model_tau_feature,\n                        normalize=true, method='auto', features=feature_names)\n\n# using the feature_importances_ method in the base learner (lgbmregressor() in this example)\nslearner.plot_importance(x=x, tau=slearner_tau, normalize=true, method='auto')\n\n# using eli5's permutationimportance\nslearner.plot_importance(x=x, tau=slearner_tau, normalize=true, method='permutation')\n\n# using shap\nshap_slearner = slearner.get_shap_values(x=x, tau=slearner_tau)\n\n# plot shap values without specifying shap_dict\nslearner.plot_shap_values(x=x, tau=slearner_tau)\n\n# plot shap values with specifying shap_dict\nslearner.plot_shap_values(x=x, shap_dict=shap_slearner)\n\n# interaction_idx set to 'auto' (searches for feature with greatest approximate interaction)\nslearner.plot_shap_dependence(treatment_group='treatment_a',\n                              feature_idx=1,\n                              x=x,\n                              tau=slearner_tau,\n                              interaction_idx='auto')\n```\n<div align=\"center\">\n  <img width=\"629px\" height=\"618px\" src=\"https://raw.githubusercontent.com/uber/causalml/master/docs/_static/img/shap_vis.png\">\n</div>\n\nsee the [feature interpretations example notebook](https://github.com/uber/causalml/blob/master/examples/feature_interpretations_example.ipynb) for details.\n\n### uplift tree visualization\n\n```python\nfrom ipython.display import image\nfrom causalml.inference.tree import uplifttreeclassifier, upliftrandomforestclassifier\nfrom causalml.inference.tree import uplift_tree_string, uplift_tree_plot\n\nuplift_model = uplifttreeclassifier(max_depth=5, min_samples_leaf=200, min_samples_treatment=50,\n                                    n_reg=100, evaluationfunction='kl', control_name='control')\n\nuplift_model.fit(df[features].values,\n                 treatment=df['treatment_group_key'].values,\n                 y=df['conversion'].values)\n\ngraph = uplift_tree_plot(uplift_model.fitted_uplift_tree, features)\nimage(graph.create_png())\n```\n<div align=\"center\">\n  <img width=\"800px\" height=\"479px\" src=\"https://raw.githubusercontent.com/uber/causalml/master/docs/_static/img/uplift_tree_vis.png\">\n</div>\n\nsee the [uplift tree visualization example notebook](https://github.com/uber/causalml/blob/master/examples/uplift_tree_visualization.ipynb) for details.\n\n# contributing\n\nwe welcome community contributors to the project. before you start, please read our [code of conduct](https://github.com/uber/causalml/blob/master/code_of_conduct.md) and check out [contributing guidelines](./contributing.md) first.\n\n\n# versioning\n\nwe document versions and changes in our [changelog](https://github.com/uber/causalml/blob/master/docs/changelog.rst).\n\n\n# license\n\nthis project is licensed under the apache 2.0 license - see the [license](https://github.com/uber/causalml/blob/master/license) file for details.\n\n\n# references\n\n## documentation\n* [causal ml api documentation](https://causalml.readthedocs.io/en/latest/about.html)\n\n## conference talks and publications by causalml team\n* (talk) introduction to causalml at [causal data science meeting 2021](https://www.causalscience.org/meeting/program/day-2/)\n* (talk) introduction to causalml at [2021 conference on digital experimentation @ mit (code@mit)](https://ide.mit.edu/events/2021-conference-on-digital-experimentation-mit-codemit/)\n* (talk) causal inference and machine learning in practice with econml and causalml: industrial use cases at microsoft, tripadvisor, uber at [kdd 2021 tutorials](https://kdd.org/kdd2021/tutorials) ([website and slide links](https://causal-machine-learning.github.io/kdd2021-tutorial/))\n* (publication) causalml white paper [causalml: python package for causal machine learning](https://arxiv.org/abs/2002.11631)\n* (publication) [uplift modeling for multiple treatments with cost optimization](https://ieeexplore.ieee.org/document/8964199) at [2019 ieee international conference on data science and advanced analytics (dsaa)](http://203.170.84.89/~idawis33/dsaa2019/preliminary-program/)\n* (publication) [feature selection methods for uplift modeling](https://arxiv.org/abs/2005.03447)\n\n## citation\nto cite causalml in publications, you can refer to the following sources:\n\nwhitepaper:\n[causalml: python package for causal machine learning](https://arxiv.org/abs/2002.11631)\n\nbibtex:\n> @misc{chen2020causalml,\n>    title={causalml: python package for causal machine learning},\n>    author={huigang chen and totte harinen and jeong-yoon lee and mike yung and zhenyu zhao},\n>    year={2020},\n>    eprint={2002.11631},\n>    archiveprefix={arxiv},\n>    primaryclass={cs.cy}\n>}\n\n\n## literature\n\n1. chen, huigang, totte harinen, jeong-yoon lee, mike yung, and zhenyu zhao. \"causalml: python package for causal machine learning.\" arxiv preprint arxiv:2002.11631 (2020).\n2. radcliffe, nicholas j., and patrick d. surry. \"real-world uplift modelling with significance-based uplift trees.\" white paper tr-2011-1, stochastic solutions (2011): 1-33.\n3. zhao, yan, xiao fang, and david simchi-levi. \"uplift modeling with multiple treatments and general response types.\" proceedings of the 2017 siam international conference on data mining. society for industrial and applied mathematics, 2017.\n4. hansotia, behram, and brad rukstales. \"incremental value modeling.\" journal of interactive marketing 16.3 (2002): 35-46.\n5. jannik r\u00f6\u00dfler, richard guse, and detlef schoder. \"the best of two worlds: using recent advances from uplift modeling and heterogeneous treatment effects to optimize targeting policies\". international conference on information systems (2022)\n6. su, xiaogang, et al. \"subgroup analysis via recursive partitioning.\" journal of machine learning research 10.2 (2009).\n7. su, xiaogang, et al. \"facilitating score and causal inference trees for large observational studies.\" journal of machine learning research 13 (2012): 2955.\n8. athey, susan, and guido imbens. \"recursive partitioning for heterogeneous causal effects.\" proceedings of the national academy of sciences 113.27 (2016): 7353-7360.\n9. k\u00fcnzel, s\u00f6ren r., et al. \"metalearners for estimating heterogeneous treatment effects using machine learning.\" proceedings of the national academy of sciences 116.10 (2019): 4156-4165.\n10. nie, xinkun, and stefan wager. \"quasi-oracle estimation of heterogeneous treatment effects.\" arxiv preprint arxiv:1712.04912 (2017).\n11. bang, heejung, and james m. robins. \"doubly robust estimation in missing data and causal inference models.\" biometrics 61.4 (2005): 962-973.\n12. van der laan, mark j., and daniel rubin. \"targeted maximum likelihood learning.\" the international journal of biostatistics 2.1 (2006).\n13. kennedy, edward h. \"optimal doubly robust estimation of heterogeneous causal effects.\" arxiv preprint arxiv:2004.14497 (2020).\n14. louizos, christos, et al. \"causal effect inference with deep latent-variable models.\" arxiv preprint arxiv:1705.08821 (2017).\n15. shi, claudia, david m. blei, and victor veitch. \"adapting neural networks for the estimation of treatment effects.\" 33rd conference on neural information processing systems (neurips 2019), 2019.\n16. zhao, zhenyu, yumin zhang, totte harinen, and mike yung. \"feature selection methods for uplift modeling.\" arxiv preprint arxiv:2005.03447 (2020).\n17. zhao, zhenyu, and totte harinen. \"uplift modeling for multiple treatments with cost optimization.\" in 2019 ieee international conference on data science and advanced analytics (dsaa), pp. 422-431. ieee, 2019.\n \n\n## related projects\n\n* [uplift](https://cran.r-project.org/web/packages/uplift/index.html): uplift models in r\n* [grf](https://cran.r-project.org/web/packages/grf/index.html): generalized random forests that include heterogeneous treatment effect estimation in r\n* [rlearner](https://github.com/xnie/rlearner): a r package that implements r-learner\n* [dowhy](https://github.com/microsoft/dowhy):  causal inference in python based on judea pearl's do-calculus\n* [econml](https://github.com/microsoft/econml): a python package that implements heterogeneous treatment effect estimators from econometrics and machine learning methods\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "causalml",
  "package_url": "https://pypi.org/project/causalml/",
  "project_url": "https://pypi.org/project/causalml/",
  "project_urls": {
    "homepage": "https://github.com/uber/causalml"
  },
  "release_url": "https://pypi.org/project/causalml/0.14.1/",
  "requires_dist": [],
  "requires_python": ">=3.7",
  "summary": "python package for uplift modeling and causal inference with machine learning algorithms",
  "version": "0.14.1",
  "releases": [],
  "developers": [
    "huigang_chen",
    "jeong"
  ],
  "kwds": "causalml_logo causalml logo py3x png",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_causalml",
  "homepage": "",
  "release_count": 22,
  "dependency_ids": []
}