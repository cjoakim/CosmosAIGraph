{
  "classifiers": [
    "license :: osi approved :: gnu general public license v2 or later (gplv2+)",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "programming language :: python :: implementation :: cpython",
    "programming language :: python :: implementation :: pypy",
    "topic :: text processing",
    "topic :: text processing :: filters"
  ],
  "description": "unidecode, lossy ascii transliterations of unicode text\n=======================================================\n\nit often happens that you have text data in unicode, but you need to\nrepresent it in ascii. for example when integrating with legacy code that\ndoesn't support unicode, or for ease of entry of non-roman names on a us\nkeyboard, or when constructing ascii machine identifiers from human-readable\nunicode strings that should still be somewhat intelligible. a popular example\nof this is when making an url slug from an article title.\n\n**unidecode is not a replacement for fully supporting unicode for strings in\nyour program. there are a number of caveats that come with its use,\nespecially when its output is directly visible to users. please read the rest\nof this readme before using unidecode in your project.**\n\nin most of examples listed above you could represent unicode characters as\n``???`` or ``\\\\15ba\\\\15a0\\\\1610``, to mention two extreme cases. but that's\nnearly useless to someone who actually wants to read what the text says.\n\nwhat unidecode provides is a middle road: the function ``unidecode()`` takes\nunicode data and tries to represent it in ascii characters (i.e., the\nuniversally displayable characters between 0x00 and 0x7f), where the\ncompromises taken when mapping between two character sets are chosen to be\nnear what a human with a us keyboard would choose.\n\nthe quality of resulting ascii representation varies. for languages of\nwestern origin it should be between perfect and good. on the other hand\ntransliteration (i.e., conveying, in roman letters, the pronunciation\nexpressed by the text in some other writing system) of languages like\nchinese, japanese or korean is a very complex issue and this library does\nnot even attempt to address it. it draws the line at context-free\ncharacter-by-character mapping. so a good rule of thumb is that the further\nthe script you are transliterating is from latin alphabet, the worse the\ntransliteration will be.\n\ngenerally unidecode produces better results than simply stripping accents from\ncharacters (which can be done in python with built-in functions). it is based\non hand-tuned character mappings that for example also contain ascii\napproximations for symbols and non-latin alphabets.\n\n**note that some people might find certain transliterations offending.** most\ncommon examples include characters that are used in multiple languages. a user\nexpects a character to be transliterated in their language but unidecode uses a\ntransliteration for a different language. it's best to not use unidecode for\nstrings that are directly visible to users of your application. see also the\n*frequently asked questions* section for more info on common problems.\n\nthis is a python port of ``text::unidecode`` perl module by sean m. burke\n<sburke@cpan.org>.\n\n\nmodule content\n--------------\n\nthis library contains a function that takes a string object, possibly\ncontaining non-ascii characters, and returns a string that can be safely\nencoded to ascii::\n\n    >>> from unidecode import unidecode\n    >>> unidecode('ko\u017eu\u0161\u010dek')\n    'kozuscek'\n    >>> unidecode('30 \\u0001d5c4\\u0001d5c6/\\u0001d5c1')\n    '30 km/h'\n    >>> unidecode('\\u5317\\u4eb0')\n    'bei jing '\n\nyou can also specify an *errors* argument to ``unidecode()`` that determines\nwhat unidecode does with characters that are not present in its transliteration\ntables. the default is ``'ignore'`` meaning that unidecode will ignore those\ncharacters (replace them with an empty string). ``'strict'`` will raise a\n``unidecodeerror``. the exception object will contain an *index* attribute that\ncan be used to find the offending character. ``'replace'`` will replace them\nwith ``'?'`` (or another string, specified in the *replace_str* argument).\n``'preserve'`` will keep the original, non-ascii character in the string. note\nthat if ``'preserve'`` is used the string returned by ``unidecode()`` will not\nbe ascii-encodable!::\n\n    >>> unidecode('\\ue000') # unidecode does not have replacements for private use area characters\n    ''\n    >>> unidecode('\\ue000', errors='strict')\n    traceback (most recent call last):\n    ...\n    unidecode.unidecodeerror: no replacement found for character '\\ue000' in position 0\n\na utility is also included that allows you to transliterate text from the\ncommand line in several ways. reading from standard input::\n\n    $ echo hello | unidecode\n    hello\n\nfrom a command line argument::\n\n    $ unidecode -c hello\n    hello\n\nor from a file::\n\n    $ unidecode hello.txt\n    hello\n\nthe default encoding used by the utility depends on your system locale. you can\nspecify another encoding with the ``-e`` argument. see ``unidecode --help`` for\na full list of available options.\n\nrequirements\n------------\n\nnothing except python itself. unidecode supports python 3.5 or later.\n\nyou need a python build with \"wide\" unicode characters (also called \"ucs-4\nbuild\") in order for unidecode to work correctly with characters outside of\nbasic multilingual plane (bmp). common characters outside bmp are bold, italic,\nscript, etc. variants of the latin alphabet intended for mathematical notation.\nsurrogate pair encoding of \"narrow\" builds is not supported in unidecode.\n\nif your python build supports \"wide\" unicode the following expression will\nreturn true::\n\n    >>> import sys\n    >>> sys.maxunicode > 0xffff\n    true\n\nsee `pep 261 <https://www.python.org/dev/peps/pep-0261/>`_ for details\nregarding support for \"wide\" unicode characters in python.\n\n\ninstallation\n------------\n\nto install the latest version of unidecode from the python package index, use\nthese commands::\n\n    $ pip install unidecode\n\nto install unidecode from the source distribution and run unit tests, use::\n\n    $ python setup.py install\n    $ python setup.py test\n\nfrequently asked questions\n--------------------------\n\ngerman umlauts are transliterated incorrectly\n    latin letters \"a\", \"o\" and \"u\" with diaeresis are transliterated by\n    unidecode as \"a\", \"o\", \"u\", *not* according to german rules \"ae\", \"oe\",\n    \"ue\". this is intentional and will not be changed. rationale is that these\n    letters are used in languages other than german (for example, finnish and\n    turkish). german text transliterated without the extra \"e\" is much more\n    readable than other languages transliterated using german rules. a\n    workaround is to do your own replacements of these characters before\n    passing the string to ``unidecode()``.\n\njapanese kanji is transliterated as chinese\n    same as with latin letters with accents discussed in the answer above, the\n    unicode standard encodes letters, not letters in a certain language or\n    their meaning. with japanese and chinese this is even more evident because\n    the same letter can have very different transliterations depending on the\n    language it is used in. since unidecode does not do language-specific\n    transliteration (see next question), it must decide on one. for certain\n    characters that are used in both japanese and chinese the decision was to\n    use chinese transliterations. if you intend to transliterate japanese,\n    chinese or korean text please consider using other libraries which do\n    language-specific transliteration, such as `unihandecode\n    <https://github.com/miurahr/unihandecode>`_.\n\nunidecode should support localization (e.g. a language or country parameter, inspecting system locale, etc.)\n    language-specific transliteration is a complicated problem and beyond the\n    scope of this library. changes related to this will not be accepted. please\n    consider using other libraries which do provide this capability, such as\n    `unihandecode <https://github.com/miurahr/unihandecode>`_.\n\nunidecode should automatically detect the language of the text being transliterated\n    language detection is a completely separate problem and beyond the scope of\n    this library.\n\nunidecode should use a permissive license such as mit or the bsd license.\n    the maintainer of unidecode believes that providing access to source code\n    on redistribution is a fair and reasonable request when basing products on\n    voluntary work of many contributors. if the license is not suitable for\n    you, please consider using other libraries, such as `text-unidecode\n    <https://github.com/kmike/text-unidecode>`_.\n\nunidecode produces completely wrong results (e.g. \"u\" with diaeresis transliterating as \"a 1/4 \")\n    the strings you are passing to unidecode have been wrongly decoded\n    somewhere in your program. for example, you might be decoding utf-8 encoded\n    strings as latin1. with a misconfigured terminal, locale and/or a text\n    editor this might not be immediately apparent. inspect your strings with\n    ``repr()`` and consult the\n    `unicode howto <https://docs.python.org/3/howto/unicode.html>`_.\n\nwhy does unidecode not replace \\\\u and \\\\u backslash escapes in my strings?\n    unidecode knows nothing about escape sequences. interpreting these sequences\n    and replacing them with actual unicode characters in string literals is the\n    task of the python interpreter. if you are asking this question you are\n    very likely misunderstanding the purpose of this library. consult the\n    `unicode howto <https://docs.python.org/3/howto/unicode.html>`_ and possibly\n    the ``unicode_escape`` encoding in the standard library.\n\ni've upgraded unidecode and now some urls on my website return 404 not found.\n    this is an issue with the software that is running your website, not\n    unidecode. occasionally, new versions of unidecode library are released\n    which contain improvements to the transliteration tables. this means that\n    you cannot rely that ``unidecode()`` output will not change across\n    different versions of unidecode library. if you use ``unidecode()`` to\n    generate urls for your website, either generate the url slug once and store\n    it in the database or lock your dependency of unidecode to one specific\n    version.\n\nsome of the issues in this section are discussed in more detail in `this blog\npost <https://www.tablix.org/~avian/blog/archives/2013/09/python_unidecode_release_0_04_14/>`_.\n\n\nperformance notes\n-----------------\n\nby default, ``unidecode()`` optimizes for the use case where most of the strings\npassed to it are already ascii-only and no transliteration is necessary (this\ndefault might change in future versions).\n\nfor performance critical applications, two additional functions are exposed:\n\n``unidecode_expect_ascii()`` is optimized for ascii-only inputs (approximately\n5 times faster than ``unidecode_expect_nonascii()`` on 10 character strings,\nmore on longer strings), but slightly slower for non-ascii inputs.\n\n``unidecode_expect_nonascii()`` takes approximately the same amount of time on\nascii and non-ascii inputs, but is slightly faster for non-ascii inputs than\n``unidecode_expect_ascii()``.\n\napart from differences in run time, both functions produce identical results.\nfor most users of unidecode, the difference in performance should be\nnegligible.\n\n\nsource\n------\n\nyou can get the latest development version of unidecode with::\n\n    $ git clone https://www.tablix.org/~avian/git/unidecode.git\n\nthere is also an official mirror of this repository on github at\nhttps://github.com/avian2/unidecode\n\n\ncontact\n-------\n\nplease make sure to read the `frequently asked questions`_ section above before\ncontacting the maintainer.\n\nbug reports, patches and suggestions for unidecode can be sent to\ntomaz.solc@tablix.org.\n\nalternatively, you can also open a ticket or pull request at\nhttps://github.com/avian2/unidecode\n\n\ncopyright\n---------\n\noriginal character transliteration tables:\n\ncopyright 2001, sean m. burke <sburke@cpan.org>, all rights reserved.\n\npython code and later additions:\n\ncopyright 2022, toma\u017e \u0161olc <tomaz.solc@tablix.org>\n\nthis program is free software; you can redistribute it and/or modify it\nunder the terms of the gnu general public license as published by the free\nsoftware foundation; either version 2 of the license, or (at your option)\nany later version.\n\nthis program is distributed in the hope that it will be useful, but without\nany warranty; without even the implied warranty of merchantability or\nfitness for a particular purpose. see the gnu general public license for\nmore details.\n\nyou should have received a copy of the gnu general public license along\nwith this program; if not, write to the free software foundation, inc., 51\nfranklin street, fifth floor, boston, ma 02110-1301 usa.  the programs and\ndocumentation in this dist are distributed in the hope that they will be\nuseful, but without any warranty; without even the implied warranty of\nmerchantability or fitness for a particular purpose.\n\n..\n    vim: set filetype=rst:\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "gpl",
  "name": "unidecode",
  "package_url": "https://pypi.org/project/Unidecode/",
  "project_url": "https://pypi.org/project/Unidecode/",
  "project_urls": null,
  "release_url": "https://pypi.org/project/Unidecode/1.3.7/",
  "requires_dist": [],
  "requires_python": ">=3.5",
  "summary": "ascii transliterations of unicode text",
  "version": "1.3.7",
  "releases": [],
  "developers": [
    "tomaz.solc@tablix.org",
    "tomaz_solc"
  ],
  "kwds": "unicode_escape unicode unidecode_expect_ascii encoding encoded",
  "license_kwds": "gpl",
  "libtype": "pypi",
  "id": "pypi_unidecode",
  "homepage": "",
  "release_count": 30,
  "dependency_ids": []
}