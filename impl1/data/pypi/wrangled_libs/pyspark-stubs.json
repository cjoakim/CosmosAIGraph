{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: implementation :: cpython",
    "programming language :: python :: implementation :: pypy",
    "typing :: typed"
  ],
  "description": "pyspark stubs\n=============\n\n|build status| |pypi version| |conda forge version|\n\na collection of the apache spark `stub\nfiles <https://www.python.org/dev/peps/pep-0484/#stub-files>`__. these\nfiles were generated by\n`stubgen <https://github.com/python/mypy/blob/master/mypy/stubgen.py>`__\nand manually edited to include accurate type hints.\n\ntests and configuration files have been originally contributed to the\n`typeshed project <https://github.com/python/typeshed/>`__. please refer\nto its `contributors\nlist <https://github.com/python/typeshed/graphs/contributors>`__ and\n`license <https://github.com/python/typeshed/blob/master/license>`__ for\ndetails.\n\nimportant\n----------\n\nthis project `has been merged <https://github.com/apache/spark/commit/31a16fbb405a19dc3eb732347e0e1f873b16971d#diff-23eeeb4347bdd26bfc6b7ee9a3b755dd>`_  with the main apache spark repository (`spark-32714 <https://issues.apache.org/jira/browse/spark-32714>`_). all further development for spark 3.1 and onwards will be continued there.\n\nfor spark 2.4 and 3.0, development of this package will be continued, until their official deprecation.\n\n- if your problem is specific to spark 2.3 and 3.0 feel free to create an issue or open pull requests here.\n- otherwise, please check `the official spark jira <https://issues.apache.org/jira/projects/spark/issues/>`_ and `contributing guidelines <https://spark.apache.org/contributing.html>`_. if you create a jira ticket or spark pr related to type hints, please ping me with `[~zero323] <https://issues.apache.org/jira/secure/viewprofile.jspa?name=zero323>`_ or `@zero323 <https://github.com/zero323>`_ respectively. thanks in advance.\n\nmotivation\n----------\n\n-  static error detection (see\n   `spark-20631 <https://issues.apache.org/jira/browse/spark-20631>`__)\n\n   |spark-20631|\n\n-  improved autocompletion.\n\n   |syntax completion|\n\ninstallation and usage\n----------------------\n\nplease note that the guidelines for distribution of type information is\nstill work in progress (`pep 561 - distributing and packaging type\ninformation <https://www.python.org/dev/peps/pep-0561/>`__). currently\ninstallation script overlays existing spark installations (``pyi`` stub\nfiles are copied next to their ``py`` counterparts in the pyspark\ninstallation directory). if this approach is not acceptable you can add stub\nfiles to the search path manually.\n\naccording to `pep\n484 <https://www.python.org/dev/peps/pep-0484/#storing-and-distributing-stub-files>`__:\n\n    third-party stub packages can use any location for stub storage.\n    type checkers should search for them using pythonpath.\n\nmoreover:\n\n    third-party stub packages can use any location for stub storage.\n    type checkers should search for them using pythonpath. a default\n    fallback directory that is always checked is\n    shared/typehints/python3.5/ (or 3.6, etc.)\n\nplease check usage before proceeding.\n\nthe package is available on `pypi <https://pypi.org/project/pyspark-stubs/>`__:\n\n.. code:: bash\n\n    pip install pyspark-stubs\n\nand `conda-forge <https://anaconda.org/conda-forge/pyspark-stubs>`__:\n\n.. code:: bash\n\n    conda install -c conda-forge pyspark-stubs\n\ndepending on your environment you might also need a type checker, like `mypy`_\nor `pytype`_ [#f1]_, and autocompletion tool, like `jedi`_.\n\n\n+--------------------------------------------------+---------------------+--------------------+-------------------------------------+\n| editor                                           |  type checking      | autocompletion     | notes                               |\n+==================================================+=====================+====================+=====================================+\n|  `atom`_                                         | \u2714 [#f2]_            | \u2714 [#f3]_           | through plugins.                    |\n+--------------------------------------------------+---------------------+--------------------+-------------------------------------+\n|  `ipython`_ / `jupyter notebook`_                | \u2718 [#f4]_            | \u2714                  |                                     |\n+--------------------------------------------------+---------------------+--------------------+-------------------------------------+\n| `pycharm`_                                       | \u2714                   | \u2714                  |                                     |\n+--------------------------------------------------+---------------------+--------------------+-------------------------------------+\n|  `pydev`_                                        | \u2714 [#f5]_            | ?                  |                                     |\n+--------------------------------------------------+---------------------+--------------------+-------------------------------------+\n| `vim`_ / `neovim`_                               | \u2714 [#f6]_            | \u2714 [#f7]_           | through plugins.                    |\n+--------------------------------------------------+---------------------+--------------------+-------------------------------------+\n| `visual studio code`_                            | \u2714 [#f8]_            | \u2714 [#f9]_           | completion with plugin              |\n+--------------------------------------------------+---------------------+--------------------+-------------------------------------+\n| environment independent / other editors          | \u2714 [#f10]_           | \u2714 [#f11]_          | through `mypy`_ and `jedi`_.        |\n+--------------------------------------------------+---------------------+--------------------+-------------------------------------+\n\n\n\n\nthis package is tested against mypy development branch and in rare cases (primarily important upstrean bugfixes), is not compatible with the preceding mypy release.\n\npyspark version compatibility\n-----------------------------\n\npackage versions follow pyspark versions with exception to maintenance releases - i.e. `pyspark-stubs==2.3.0` should be compatible with `pyspark>=2.3.0,<2.4.0`.\nmaintenance releases (`post1`, `post2`, ..., `postn`) are reserved for internal annotations updates.\n\napi coverage:\n-------------\n\nas of release 2.4.0 most of the public api is covered. for details please check `api coverage document <https://github.com/zero323/pyspark-stubs/blob/master/doc/api-coverage.rst>`__.\n\nsee also\n--------\n\n- `spark-17333 <https://issues.apache.org/jira/browse/spark-17333>`__ - *make pyspark interface friendly with static analysis*.\n- `pyspark typing hints <http://apache-spark-developers-list.1001551.n3.nabble.com/python-pyspark-typing-hints-td21560.html>`__ and `revisiting pyspark type annotations <http://apache-spark-developers-list.1001551.n3.nabble.com/re-pyspark-revisiting-pyspark-type-annotations-td26232.html>`__ on `apache spark developers list <http://apache-spark-developers-list.1001551.n3.nabble.com/>`__.\n\n\ndisclaimer\n----------\n\napache spark, spark, pyspark, apache, and the spark logo are `trademarks <https://www.apache.org/foundation/marks/>`__ of `the\napache software foundation <http://www.apache.org/>`__. this project is not owned, endorsed, or\nsponsored by the apache software foundation.\n\nfootnotes\n---------\n\n.. [#f1] not supported or tested.\n.. [#f2] requires `atom-mypy <https://atom.io/packages/atom-mypy>`__ or equivalent.\n.. [#f3] requires `autocomplete-python-jedi <https://atom.io/packages/autocomplete-python-jedi>`__ or equivalent.\n.. [#f4] `it is possible <https://web.archive.org/web/20190126155957/http://journalpanic.com/post/spice-up-thy-jupyter-notebooks-with-mypy/>`__\n         to use magics to type check directly in the notebook. in general though, you'll have to export whole notebook to `.py` file and run\n         type checker on the result.\n.. [#f5] requires pydev 7.0.3 or later.\n.. [#f6] todo using `vim-mypy <https://github.com/integralist/vim-mypy>`__, `syntastic <https://github.com/vim-syntastic/syntastic>`__ or `neomake <https://github.com/neomake/neomake>`__.\n.. [#f7] with `jedi-vim <https://github.com/davidhalter/jedi-vim>`__.\n.. [#f8] with `mypy linter <https://code.visualstudio.com/docs/python/linting#_specific-linters>`__.\n.. [#f9] with `python extension for visual studio code <https://marketplace.visualstudio.com/items?itemname=ms-python.python>`__.\n.. [#f10] just use your favorite checker directly, optionally combined with tool like `entr <http://eradman.com/entrproject/>`__.\n.. [#f11] see `jedi editor plugins list <https://jedi.readthedocs.io/en/latest/docs/usage.html#editor-plugins>`__.\n\n\n.. |build status| image:: https://github.com/zero323/pyspark-stubs/actions/workflows/test.yml/badge.svg\n   :target: https://github.com/zero323/pyspark-stubs/actions/workflows/test.yml\n.. |pypi version| image:: https://img.shields.io/pypi/v/pyspark-stubs.svg\n   :target: https://pypi.org/project/pyspark-stubs/\n.. |conda forge version| image:: https://img.shields.io/conda/vn/conda-forge/pyspark-stubs.svg\n   :target: https://anaconda.org/conda-forge/pyspark-stubs\n.. |spark-20631| image:: https://i.imgur.com/gfdcgjv.gif\n     :alt: spark-20631\n.. |syntax completion| image:: https://i.imgur.com/qvkltap.gif\n     :alt: syntax completion\n\n.. _atom: https://atom.io/\n.. _ipython: https://ipython.org/\n.. _jedi: https://github.com/davidhalter/jedi\n.. _jupyter notebook: https://jupyter.org/\n.. _mypy: http://mypy-lang.org/\n.. _neovim : https://neovim.io/\n.. _pycharm: https://www.jetbrains.com/pycharm/\n.. _pydev: https://www.pydev.org/\n.. _pytype: https://github.com/google/pytype\n.. _vim: https://www.vim.org/\n.. _visual studio code: https://code.visualstudio.com/\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "pyspark-stubs",
  "package_url": "https://pypi.org/project/pyspark-stubs/",
  "project_url": "https://pypi.org/project/pyspark-stubs/",
  "project_urls": {
    "Homepage": "https://github.com/zero323/pyspark-stubs"
  },
  "release_url": "https://pypi.org/project/pyspark-stubs/3.0.0.post3/",
  "requires_dist": [
    "pyspark (<3.1.0,>=3.0.0.dev0)"
  ],
  "requires_python": "",
  "summary": "a collection of the apache spark stub files",
  "version": "3.0.0.post3",
  "releases": [],
  "developers": [],
  "kwds": "pyspark spark pip _pytype typeshed",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_pyspark_stubs",
  "homepage": "https://github.com/zero323/pyspark-stubs",
  "release_count": 38,
  "dependency_ids": [
    "pypi_pyspark"
  ]
}