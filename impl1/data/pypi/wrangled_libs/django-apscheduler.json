{
  "classifiers": [
    "development status :: 4 - beta",
    "environment :: web environment",
    "framework :: django",
    "framework :: django :: 3.2",
    "framework :: django :: 4.0",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "django apscheduler\n==================\n\n[![pypi](https://img.shields.io/pypi/v/django-apscheduler)](https://pypi.org/project/django-apscheduler/)\n[![pypi - python version](https://img.shields.io/pypi/pyversions/django-apscheduler)](https://pypi.org/project/django-apscheduler/)\n[![pypi - django version](https://img.shields.io/pypi/djversions/django-apscheduler)](https://pypi.org/project/django-apscheduler/)\n[![github workflow status](https://img.shields.io/github/workflow/status/jcass77/django-apscheduler/python%20package)](https://github.com/jcass77/django-apscheduler/actions?query=workflow%3a%22python+package%22)\n[![codecov](https://img.shields.io/codecov/c/github/jcass77/django-apscheduler?token=upz6ukiqmn)](https://codecov.io/gh/jcass77/django-apscheduler)\n[![code style:black](https://img.shields.io/badge/code%20style-black-black)](https://pypi.org/project/black)\n\n[apscheduler](https://github.com/agronholm/apscheduler) for [django](https://github.com/django/django).\n\nthis is a django app that adds a lightweight wrapper around apscheduler. it enables storing persistent jobs in the\ndatabase using django's orm.\n\ndjango-apscheduler is a great choice for quickly and easily adding basic scheduling features to your django applications\nwith minimal dependencies and very little additional configuration. the ideal use case probably involves running a\nhandful of tasks on a fixed execution schedule.\n\n**please note:** the trade-off of this simplicity is that you need to **be careful to ensure that you have only one\nscheduler actively running at a particular point in time**.\n\nthis limitation is due to the fact that apscheduler does not currently have\nany [interprocess synchronization and signalling scheme](https://apscheduler.readthedocs.io/en/latest/faq.html#how-do-i-share-a-single-job-store-among-one-or-more-worker-processes)\nthat would enable the scheduler to be notified when a job has been added, modified, or removed from a job store (in\nother words, different schedulers won't be able to tell if a job has already been run by another scheduler, and changing\na job's scheduled run time directly in the database does nothing unless you also restart the scheduler).\n\ndepending on how you are currently doing your\ndjango [deployments](https://docs.djangoproject.com/en/dev/howto/deployment/#deploying-django), working with this\nlimitation might require a bit of thought. it is quite common to start up many webserver worker process in production\nenvironments in order to scale and handle large volumes of user traffic. if each of these worker processes end up\nrunning their own scheduler then this can result in jobs being missed or executed multiple times, as well as duplicate\nentries being created in the `djangojobexecution` table.\n\nsupport for sharing a persistent job store between multiple schedulers appears to be planned for\nan [upcoming apscheduler 4.0 release](https://github.com/agronholm/apscheduler/issues/465).\n\nso for now your options are to either:\n\n1. use a custom django management command to start a single scheduler in its own dedicated process (**recommended** -\n   see the `runapscheduler.py` example below); or\n\n2. implement your\n   own [remote processing](https://apscheduler.readthedocs.io/en/latest/faq.html#how-do-i-share-a-single-job-store-among-one-or-more-worker-processes)\n   logic to ensure that a single `djangojobstore` can be used by all of the webserver's worker processes in a\n   coordinated and synchronized way (might not be worth the extra effort and increased complexity for most use cases);\n   or\n\n3. select an alternative task processing library that *does* support inter-process communication using some sort of\n   shared message broker like redis, rabbitmq, amazon sqs or the like (see:\n   https://djangopackages.org/grids/g/workers-queues-tasks/ for popular options).\n\nfeatures\n--------\n\n- a custom [apscheduler job store](https://apscheduler.readthedocs.io/en/latest/extending.html#custom-job-stores)\n  (`djangojobstore`) that persists scheduled jobs to the django database. you can view the scheduled jobs and monitor\n  the job execution directly via the django admin interface:\n\n  ![jobs](https://raw.githubusercontent.com/jcass77/django-apscheduler/main/docs/screenshots/job_overview.png)\n\n- the job store also maintains a history of all job executions of the currently scheduled jobs, along with status codes\n  and exceptions (if any):\n\n  ![jobs](https://raw.githubusercontent.com/jcass77/django-apscheduler/main/docs/screenshots/execution_overview.png)\n\n  **note:** apscheduler\n  will [automatically remove jobs](https://apscheduler.readthedocs.io/en/latest/userguide.html#removing-jobs)\n  from the job store as soon as their last scheduled execution has been triggered. this will also delete the\n  corresponding job execution entries from the database (i.e. job execution logs are only maintained for 'active'\n  jobs.):\n\n- job executions can also be triggered manually via the `djangojob` admin page:\n\n  ![jobs](https://raw.githubusercontent.com/jcass77/django-apscheduler/main/docs/screenshots/run_now.png)\n\n  **note:** in order to prevent long running jobs from causing the django http request to time out, the combined maximum\n  run time for all apscheduler jobs that are started via the django admin site is 25 seconds. this timeout value can be\n  configured via the `apscheduler_run_now_timeout` setting.\n\n\ninstallation\n------------\n\n```python\npip install django-apscheduler\n```\n\n\nquick start\n-----------\n\n- add ``django_apscheduler`` to your ``installed_apps`` setting like this:\n```python\ninstalled_apps = (\n    # ...\n    \"django_apscheduler\",\n)\n```\n\n- django-apscheduler comes with sensible configuration defaults out of the box. the defaults can be overridden by adding\n  the following settings to your django `settings.py` file:\n```python\n# format string for displaying run time timestamps in the django admin site. the default\n# just adds seconds to the standard django format, which is useful for displaying the timestamps\n# for jobs that are scheduled to run on intervals of less than one minute.\n# \n# see https://docs.djangoproject.com/en/dev/ref/settings/#datetime-format for format string\n# syntax details.\napscheduler_datetime_format = \"n j, y, f:s a\"\n\n# maximum run time allowed for jobs that are triggered manually via the django admin site, which\n# prevents admin site http requests from timing out.\n# \n# longer running jobs should probably be handed over to a background task processing library\n# that supports multiple background worker processes instead (e.g. dramatiq, celery, django-rq,\n# etc. see: https://djangopackages.org/grids/g/workers-queues-tasks/ for popular options).\napscheduler_run_now_timeout = 25  # seconds\n```\n\n- run `python manage.py migrate` to create the django_apscheduler models.\n\n- add a [custom django management command](https://docs.djangoproject.com/en/dev/howto/custom-management-commands/) to your project\n  that schedules the apscheduler jobs and starts the scheduler:\n  \n```python\n# runapscheduler.py\nimport logging\n\nfrom django.conf import settings\n\nfrom apscheduler.schedulers.blocking import blockingscheduler\nfrom apscheduler.triggers.cron import crontrigger\nfrom django.core.management.base import basecommand\nfrom django_apscheduler.jobstores import djangojobstore\nfrom django_apscheduler.models import djangojobexecution\nfrom django_apscheduler import util\n\nlogger = logging.getlogger(__name__)\n\n\ndef my_job():\n  # your job processing logic here...\n  pass\n\n\n# the `close_old_connections` decorator ensures that database connections, that have become\n# unusable or are obsolete, are closed before and after your job has run. you should use it\n# to wrap any jobs that you schedule that access the django database in any way. \n@util.close_old_connections\ndef delete_old_job_executions(max_age=604_800):\n  \"\"\"\n  this job deletes apscheduler job execution entries older than `max_age` from the database.\n  it helps to prevent the database from filling up with old historical records that are no\n  longer useful.\n  \n  :param max_age: the maximum length of time to retain historical job execution records.\n                  defaults to 7 days.\n  \"\"\"\n  djangojobexecution.objects.delete_old_job_executions(max_age)\n\n\nclass command(basecommand):\n  help = \"runs apscheduler.\"\n\n  def handle(self, *args, **options):\n    scheduler = blockingscheduler(timezone=settings.time_zone)\n    scheduler.add_jobstore(djangojobstore(), \"default\")\n\n    scheduler.add_job(\n      my_job,\n      trigger=crontrigger(second=\"*/10\"),  # every 10 seconds\n      id=\"my_job\",  # the `id` assigned to each job must be unique\n      max_instances=1,\n      replace_existing=true,\n    )\n    logger.info(\"added job 'my_job'.\")\n\n    scheduler.add_job(\n      delete_old_job_executions,\n      trigger=crontrigger(\n        day_of_week=\"mon\", hour=\"00\", minute=\"00\"\n      ),  # midnight on monday, before start of the next work week.\n      id=\"delete_old_job_executions\",\n      max_instances=1,\n      replace_existing=true,\n    )\n    logger.info(\n      \"added weekly job: 'delete_old_job_executions'.\"\n    )\n\n    try:\n      logger.info(\"starting scheduler...\")\n      scheduler.start()\n    except keyboardinterrupt:\n      logger.info(\"stopping scheduler...\")\n      scheduler.shutdown()\n      logger.info(\"scheduler shut down successfully!\")\n\n```\n\n- the management command defined above should be invoked via `./manage.py runapscheduler` whenever the webserver serving\n  your django application is started. the details of how and where this should be done is implementation specific, and\n  depends on which webserver you are using and how you are deploying your application to production. for most people\n  this should involve configuring a [supervisor](http://supervisord.org) process of sorts.\n\n- register any apscheduler jobs as you would normally. note that if you haven't set `djangojobstore` as the `'default'`\n  job store, then you will need to include `jobstore='djangojobstore'` in your `scheduler.add_job()` calls.\n\n\nadvanced usage\n--------------\n\ndjango-apscheduler assumes that you are already familiar with apscheduler and its proper use. if not, then please head\nover to the project page and have a look through\nthe [apscheduler documentation](https://apscheduler.readthedocs.io/en/latest/index.html).\n\nit is possible to make use\nof [different types of schedulers](https://apscheduler.readthedocs.io/en/latest/userguide.html#choosing-the-right-scheduler-job-store-s-executor-s-and-trigger-s)\ndepending on your environment and use case. if you would prefer running a `backgroundscheduler` instead of using a\n`blockingscheduler`, then you should be aware that using apscheduler with uwsgi requires some additional\n[configuration steps](https://apscheduler.readthedocs.io/en/latest/faq.html#how-can-i-use-apscheduler-with-uwsgi) in\norder to re-enable threading support.\n\n\nsupported databases\n-------------------\n\nplease take note of the list of databases that\nare [officially supported by django](https://docs.djangoproject.com/en/dev/ref/databases/#databases). django-apscheduler\nprobably won't work with unsupported databases like microsoft sql server, mongodb, and the like.\n\n\ndatabase connections and timeouts\n---------------------------------\n\ndjango-apscheduler is dependent on the standard django\ndatabase [configuration settings](https://docs.djangoproject.com/en/dev/ref/databases/#general-notes). these settings,\nin combination with how your database server has been configured, determine how connection management will be performed\nfor your specific deployment.\n\nthe `close_old_connections` decorator should be applied to apscheduler jobs that require database access. doing so\nensures that django's [conn_max_age](https://docs.djangoproject.com/en/dev/ref/settings/#std:setting-conn_max_age)\nconfiguration setting is enforced before and after your job is run. this mirrors the standard django functionality of\ndoing the same before and after handling each http request.\n\nif you still encounter any kind of 'lost database connection' errors then it probably means that:\n\n- your database connections timed out in the middle of executing a job. you should probably consider incorporating a\n  connection pooler as part of your deployment for more robust database connection management\n  (e.g. [pgbouncer](https://www.pgbouncer.org) for postgresql, or the equivalent for other db platforms).\n- your database server has crashed / been restarted.\n  django [will not reconnect automatically](https://code.djangoproject.com/ticket/24810)\n  and you need to re-start django-apscheduler as well.\n\ncommon footguns\n---------------\n\nunless you have a very specific set of requirements, and have intimate knowledge of the inner workings of apscheduler,\nyou really shouldn't be using `backgroundscheduler`. doing so can lead to all sorts of temptations like:\n\n* **firing up a scheduler inside of a django view:** this will most likely cause more than one scheduler to run\n  concurrently and lead to jobs running multiple times (see the above introduction to this readme for a more thorough\n  treatment of the subject).\n* **bootstrapping a scheduler somewhere else inside your django application**: it feels like this should solve the\n  problem mentioned above and guarantee that only one scheduler is running. the downside is that you have just delegated\n  the management of all of your background task processing threads to whatever webserver you are using (gunicorn, uwsgi,\n  etc.). the webserver will probably kill any long-running threads (your jobs) with extreme prejudice (thinking that\n  they are caused by misbehaving http requests).\n\nrelying on `blockingscheduler` forces you to run apscheduler in its own dedicated process that is not handled or\nmonitored by the webserver. the example code provided in `runapscheduler.py` above is a good starting point.\n\n\nproject resources\n-----------------\n\n- [changelog](docs/changelog.md)\n- [release procedures](docs/releasing.md)\n\n\n",
  "docs_url": null,
  "keywords": "django apscheduler django-apscheduler",
  "license": "mit",
  "name": "django-apscheduler",
  "package_url": "https://pypi.org/project/django-apscheduler/",
  "project_url": "https://pypi.org/project/django-apscheduler/",
  "project_urls": {
    "Homepage": "http://github.com/jcass77/django-apscheduler"
  },
  "release_url": "https://pypi.org/project/django-apscheduler/0.6.2/",
  "requires_dist": [
    "django (>=3.2)",
    "apscheduler (<4.0,>=3.2)"
  ],
  "requires_python": "",
  "summary": "apscheduler for django",
  "version": "0.6.2",
  "releases": [],
  "developers": [
    "jarek_glowacki",
    "jarekwg@gmail.com",
    "john.cass77@gmail.com",
    "staskaledin@gmail.com"
  ],
  "kwds": "django_apscheduler django djangojob djangojobexecution apscheduler",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_django_apscheduler",
  "homepage": "http://github.com/jcass77/django-apscheduler",
  "release_count": 26,
  "dependency_ids": [
    "pypi_apscheduler",
    "pypi_django"
  ]
}