{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "<div align=\"center\">\n\n<img alt=\"logo\" width=\"175\" src=\"https://raw.githubusercontent.com/fatal1ty/mashumaro/ac2f924591d488dbd9a776a6b1ae7dede2d8c73e/img/logo.svg\">\n\n###### fast and well tested serialization library\n\n[![build status](https://github.com/fatal1ty/mashumaro/workflows/tests/badge.svg)](https://github.com/fatal1ty/mashumaro/actions)\n[![coverage status](https://coveralls.io/repos/github/fatal1ty/mashumaro/badge.svg?branch=master)](https://coveralls.io/github/fatal1ty/mashumaro?branch=master)\n[![latest version](https://img.shields.io/pypi/v/mashumaro.svg)](https://pypi.python.org/pypi/mashumaro)\n[![python version](https://img.shields.io/pypi/pyversions/mashumaro.svg)](https://pypi.python.org/pypi/mashumaro)\n[![license](https://img.shields.io/badge/license-apache%202.0-blue.svg)](https://opensource.org/licenses/apache-2.0)\n</div>\n\nin python, you often need to dump and load objects based on the schema you\nhave. it can be a dataclass model, a list of third-party generic classes or\nwhatever. mashumaro not only lets you save and load things in different ways,\nbut it also does it _super quick_.\n\n**key features**\n* \ud83d\ude80 one of the fastest libraries\n* \u261d\ufe0f mature and time-tested\n* \ud83d\udc76 easy to use out of the box\n* \u2699\ufe0f highly customizable\n* \ud83c\udf89 built-in support for json, yaml, toml, messagepack\n* \ud83d\udce6 built-in support for almost all python types including typing-extensions\n* \ud83d\udcdd json schema generation\n\ntable of contents\n-------------------------------------------------------------------------------\n* [introduction](#introduction)\n* [installation](#installation)\n* [changelog](#changelog)\n* [supported data types](#supported-data-types)\n* [usage example](#usage-example)\n* [how does it work?](#how-does-it-work)\n* [benchmark](#benchmark)\n* [supported serialization formats](#supported-serialization-formats)\n  * [basic form](#basic-form)\n  * [json](#json)\n  * [yaml](#yaml)\n  * [toml](#toml)\n  * [messagepack](#messagepack)\n* [customization](#customization)\n    * [`serializabletype` interface](#serializabletype-interface)\n      * [user-defined types](#user-defined-types)\n      * [user-defined generic types](#user-defined-generic-types)\n    * [`serializationstrategy`](#serializationstrategy)\n      * [third-party types](#third-party-types)\n      * [third-party generic types](#third-party-generic-types)\n    * [field options](#field-options)\n        * [`serialize` option](#serialize-option)\n        * [`deserialize` option](#deserialize-option)\n        * [`serialization_strategy` option](#serialization_strategy-option)\n        * [`alias` option](#alias-option)\n    * [config options](#config-options)\n        * [`debug` config option](#debug-config-option)\n        * [`code_generation_options` config option](#code_generation_options-config-option)\n        * [`serialization_strategy` config option](#serialization_strategy-config-option)\n        * [`aliases` config option](#aliases-config-option)\n        * [`serialize_by_alias` config option](#serialize_by_alias-config-option)\n        * [`allow_deserialization_not_by_alias` config option](#allow_deserialization_not_by_alias-config-option)\n        * [`omit_none` config option](#omit_none-config-option)\n        * [`omit_default` config option](#omit_default-config-option)\n        * [`namedtuple_as_dict` config option](#namedtuple_as_dict-config-option)\n        * [`allow_postponed_evaluation` config option](#allow_postponed_evaluation-config-option)\n        * [`dialect` config option](#dialect-config-option)\n        * [`orjson_options`](#orjson_options-config-option)\n        * [`discriminator` config option](#discriminator-config-option)\n        * [`lazy_compilation` config option](#lazy_compilation-config-option)\n        * [`sort_keys` config option](#sort_keys-config-option)\n    * [passing field values as is](#passing-field-values-as-is)\n    * [extending existing types](#extending-existing-types)\n    * [dialects](#dialects)\n      * [`serialization_strategy` dialect option](#serialization_strategy-dialect-option)\n      * [`serialize_by_alias` dialect option](#serialize_by_alias-dialect-option)\n      * [`omit_none` dialect option](#omit_none-dialect-option)\n      * [`omit_default` dialect option](#omit_default-dialect-option)\n      * [`named_tuple_as_dict` dialect option](#namedtuple_as_dict-dialect-option)\n      * [`no_copy_collections` dialect option](#no_copy_collections-dialect-option)\n      * [changing the default dialect](#changing-the-default-dialect)\n    * [discriminator](#discriminator)\n      * [subclasses distinguishable by a field](#subclasses-distinguishable-by-a-field)\n      * [subclasses without a common field](#subclasses-without-a-common-field)\n      * [class level discriminator](#class-level-discriminator)\n      * [working with union of classes](#working-with-union-of-classes)\n      * [using a custom variant tagger function](#using-a-custom-variant-tagger-function)\n    * [code generation options](#code-generation-options)\n        * [add `omit_none` keyword argument](#add-omit_none-keyword-argument)\n        * [add `by_alias` keyword argument](#add-by_alias-keyword-argument)\n        * [add `dialect` keyword argument](#add-dialect-keyword-argument)\n        * [add `context` keyword argument](#add-context-keyword-argument)\n    * [generic dataclasses](#generic-dataclasses)\n      * [generic dataclass inheritance](#generic-dataclass-inheritance)\n      * [generic dataclass in a field type](#generic-dataclass-in-a-field-type)\n    * [`genericserializabletype` interface](#genericserializabletype-interface)\n    * [serialization hooks](#serialization-hooks)\n        * [before deserialization](#before-deserialization)\n        * [after deserialization](#after-deserialization)\n        * [before serialization](#before-serialization)\n        * [after serialization](#after-serialization)\n* [json schema](#json-schema)\n    * [building json schema](#building-json-schema)\n    * [json schema constraints](#json-schema-constraints)\n    * [extending json schema](#extending-json-schema)\n    * [json schema and custom serialization methods](#json-schema-and-custom-serialization-methods)\n\nintroduction\n-------------------------------------------------------------------------------\n\nthis library provides two fundamentally different approaches to converting\nyour data to and from various formats. each of them is useful in different\nsituations:\n\n* codecs\n* mixins\n\ncodecs are represented by a set of decoder / encoder classes and\ndecode / encode functions for each supported format. you can use them\nto convert data of any python built-in and third-party type to json, yaml,\ntoml, messagepack or a basic form accepted by other serialization formats.\nfor example, you can convert a list of datetime objects to json array\ncontaining string-represented datetimes and vice versa.\n\nmixins are primarily for dataclass models. they are represented by mixin\nclasses that add methods for converting to and from json, yaml, toml,\nmessagepack or a basic form accepted by other serialization formats.\nif you have a root dataclass model, then it will be the easiest way to make it\nserializable. all you have to do is inherit a particular mixin class.\n\nin addition to serialization functionality, this library also provides json\nschema builder that can be used in places where interoperability matters.\n\ninstallation\n-------------------------------------------------------------------------------\n\nuse pip to install:\n```shell\n$ pip install mashumaro\n```\n\nthe current version of `mashumaro` supports python versions 3.8 \u2014 3.12.\n\n\nit's not recommended to use any version of python that has reached its\n[end of life](https://devguide.python.org/versions/) and is no longer receiving\nsecurity updates or bug fixes from the python development team.\nfor convenience, there is a table below that outlines the\nlast version of `mashumaro` that can be installed on unmaintained versions\nof python.\n\n| python version | last version of mashumaro                                        | python eol |\n|----------------|--------------------------------------------------------------------|------------|\n| 3.7            | [3.9.1](https://github.com/fatal1ty/mashumaro/releases/tag/v3.9.1) | 2023-06-27 |\n| 3.6            | [3.1.1](https://github.com/fatal1ty/mashumaro/releases/tag/v3.1.1) | 2021-12-23 |\n\n\nchangelog\n-------------------------------------------------------------------------------\n\nthis project follows the principles of [semantic versioning](https://semver.org).\nchangelog is available on [github releases page](https://github.com/fatal1ty/mashumaro/releases).\n\nsupported data types\n-------------------------------------------------------------------------------\n\nthere is support for generic types from the standard [`typing`](https://docs.python.org/3/library/typing.html) module:\n* [`list`](https://docs.python.org/3/library/typing.html#typing.list)\n* [`tuple`](https://docs.python.org/3/library/typing.html#typing.tuple)\n* [`namedtuple`](https://docs.python.org/3/library/typing.html#typing.namedtuple)\n* [`set`](https://docs.python.org/3/library/typing.html#typing.set)\n* [`frozenset`](https://docs.python.org/3/library/typing.html#typing.frozenset)\n* [`deque`](https://docs.python.org/3/library/typing.html#typing.deque)\n* [`dict`](https://docs.python.org/3/library/typing.html#typing.dict)\n* [`ordereddict`](https://docs.python.org/3/library/typing.html#typing.ordereddict)\n* [`defaultdict`](https://docs.python.org/3/library/typing.html#typing.defaultdict)\n* [`typeddict`](https://docs.python.org/3/library/typing.html#typing.typeddict)\n* [`mapping`](https://docs.python.org/3/library/typing.html#typing.mapping)\n* [`mutablemapping`](https://docs.python.org/3/library/typing.html#typing.mutablemapping)\n* [`counter`](https://docs.python.org/3/library/typing.html#typing.counter)\n* [`chainmap`](https://docs.python.org/3/library/typing.html#typing.chainmap)\n* [`sequence`](https://docs.python.org/3/library/typing.html#typing.sequence)\n\nfor standard generic types on [pep 585](https://www.python.org/dev/peps/pep-0585/) compatible python (3.9+):\n* [`list`](https://docs.python.org/3/library/stdtypes.html#list)\n* [`tuple`](https://docs.python.org/3/library/stdtypes.html#tuple)\n* [`namedtuple`](https://docs.python.org/3/library/collections.html#collections.namedtuple)\n* [`set`](https://docs.python.org/3/library/stdtypes.html#set)\n* [`frozenset`](https://docs.python.org/3/library/stdtypes.html#frozenset)\n* [`collections.abc.set`](https://docs.python.org/3/library/collections.abc.html#collections.abc.set)\n* [`collections.abc.mutableset`](https://docs.python.org/3/library/collections.abc.html#collections.abc.mutableset)\n* [`collections.deque`](https://docs.python.org/3/library/collections.html#collections.deque)\n* [`dict`](https://docs.python.org/3/library/stdtypes.html#dict)\n* [`collections.ordereddict`](https://docs.python.org/3/library/collections.html#collections.ordereddict)\n* [`collections.defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict)\n* [`collections.abc.mapping`](https://docs.python.org/3/library/collections.abc.html#collections.abc.mapping)\n* [`collections.abc.mutablemapping`](https://docs.python.org/3/library/collections.abc.html#collections.abc.mutablemapping)\n* [`collections.counter`](https://docs.python.org/3/library/collections.html#collections.counter)\n* [`collections.chainmap`](https://docs.python.org/3/library/collections.html#collections.chainmap)\n* [`collections.abc.sequence`](https://docs.python.org/3/library/collections.abc.html#collections.abc.sequence)\n* [`collections.abc.mutablesequence`](https://docs.python.org/3/library/collections.abc.html#collections.abc.mutablesequence)\n\nfor special primitives from the [`typing`](https://docs.python.org/3/library/typing.html) module:\n* [`any`](https://docs.python.org/3/library/typing.html#typing.any)\n* [`optional`](https://docs.python.org/3/library/typing.html#typing.optional)\n* [`union`](https://docs.python.org/3/library/typing.html#typing.union)\n* [`typevar`](https://docs.python.org/3/library/typing.html#typing.typevar)\n* [`typevartuple`](https://docs.python.org/3/library/typing.html#typing.typevartuple)\n* [`newtype`](https://docs.python.org/3/library/typing.html#newtype)\n* [`annotated`](https://docs.python.org/3/library/typing.html#typing.annotated)\n* [`literal`](https://docs.python.org/3/library/typing.html#typing.literal)\n* [`literalstring`](https://docs.python.org/3/library/typing.html#typing.literalstring)\n* [`final`](https://docs.python.org/3/library/typing.html#typing.final)\n* [`self`](https://docs.python.org/3/library/typing.html#typing.self)\n* [`unpack`](https://docs.python.org/3/library/typing.html#typing.unpack)\n\nfor standard interpreter types from [`types`](https://docs.python.org/3/library/types.html#standard-interpreter-types) module:\n* [`nonetype`](https://docs.python.org/3/library/types.html#types.nonetype)\n* [`uniontype`](https://docs.python.org/3/library/types.html#types.uniontype)\n\nfor enumerations based on classes from the standard [`enum`](https://docs.python.org/3/library/enum.html) module:\n* [`enum`](https://docs.python.org/3/library/enum.html#enum.enum)\n* [`intenum`](https://docs.python.org/3/library/enum.html#enum.intenum)\n* [`strenum`](https://docs.python.org/3/library/enum.html#enum.strenum)\n* [`flag`](https://docs.python.org/3/library/enum.html#enum.flag)\n* [`intflag`](https://docs.python.org/3/library/enum.html#enum.intflag)\n\nfor common built-in types:\n* [`int`](https://docs.python.org/3/library/functions.html#int)\n* [`float`](https://docs.python.org/3/library/functions.html#float)\n* [`bool`](https://docs.python.org/3/library/stdtypes.html#bltin-boolean-values)\n* [`str`](https://docs.python.org/3/library/stdtypes.html#str)\n* [`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes)\n* [`bytearray`](https://docs.python.org/3/library/stdtypes.html#bytearray)\n\nfor built-in datetime oriented types (see [more](#deserialize-option) details):\n* [`datetime`](https://docs.python.org/3/library/datetime.html#datetime.datetime)\n* [`date`](https://docs.python.org/3/library/datetime.html#datetime.date)\n* [`time`](https://docs.python.org/3/library/datetime.html#datetime.time)\n* [`timedelta`](https://docs.python.org/3/library/datetime.html#datetime.timedelta)\n* [`timezone`](https://docs.python.org/3/library/datetime.html#datetime.timezone)\n* [`zoneinfo`](https://docs.python.org/3/library/zoneinfo.html#zoneinfo.zoneinfo)\n\nfor pathlike types:\n* [`purepath`](https://docs.python.org/3/library/pathlib.html#pathlib.purepath)\n* [`path`](https://docs.python.org/3/library/pathlib.html#pathlib.path)\n* [`pureposixpath`](https://docs.python.org/3/library/pathlib.html#pathlib.pureposixpath)\n* [`posixpath`](https://docs.python.org/3/library/pathlib.html#pathlib.posixpath)\n* [`purewindowspath`](https://docs.python.org/3/library/pathlib.html#pathlib.purewindowspath)\n* [`windowspath`](https://docs.python.org/3/library/pathlib.html#pathlib.windowspath)\n* [`os.pathlike`](https://docs.python.org/3/library/os.html#os.pathlike)\n\nfor other less popular built-in types:\n* [`uuid.uuid`](https://docs.python.org/3/library/uuid.html#uuid.uuid)\n* [`decimal.decimal`](https://docs.python.org/3/library/decimal.html#decimal.decimal)\n* [`fractions.fraction`](https://docs.python.org/3/library/fractions.html#fractions.fraction)\n* [`ipaddress.ipv4address`](https://docs.python.org/3/library/ipaddress.html#ipaddress.ipv4address)\n* [`ipaddress.ipv6address`](https://docs.python.org/3/library/ipaddress.html#ipaddress.ipv6address)\n* [`ipaddress.ipv4network`](https://docs.python.org/3/library/ipaddress.html#ipaddress.ipv4network)\n* [`ipaddress.ipv6network`](https://docs.python.org/3/library/ipaddress.html#ipaddress.ipv6network)\n* [`ipaddress.ipv4interface`](https://docs.python.org/3/library/ipaddress.html#ipaddress.ipv4interface)\n* [`ipaddress.ipv6interface`](https://docs.python.org/3/library/ipaddress.html#ipaddress.ipv6interface)\n\nfor backported types from [`typing-extensions`](https://github.com/python/typing_extensions):\n* [`ordereddict`](https://docs.python.org/3/library/typing.html#typing.ordereddict)\n* [`typeddict`](https://docs.python.org/3/library/typing.html#typing.typeddict)\n* [`annotated`](https://docs.python.org/3/library/typing.html#typing.annotated)\n* [`literal`](https://docs.python.org/3/library/typing.html#typing.literal)\n* [`literalstring`](https://docs.python.org/3/library/typing.html#typing.literalstring)\n* [`self`](https://docs.python.org/3/library/typing.html#typing.self)\n* [`typevartuple`](https://docs.python.org/3/library/typing.html#typing.typevartuple)\n* [`unpack`](https://docs.python.org/3/library/typing.html#typing.unpack)\n\nfor arbitrary types:\n* [user-defined types](#user-defined-types)\n* [third-party types](#third-party-types)\n* [user-defined generic types](#user-defined-generic-types)\n* [third-party generic types](#third-party-generic-types)\n\nusage example\n-------------------------------------------------------------------------------\n\nsuppose we're developing a financial application and we operate with currencies\nand stocks:\n\n```python\nfrom dataclasses import dataclass\nfrom enum import enum\n\nclass currency(enum):\n    usd = \"usd\"\n    eur = \"eur\"\n\n@dataclass\nclass currencyposition:\n    currency: currency\n    balance: float\n\n@dataclass\nclass stockposition:\n    ticker: str\n    name: str\n    balance: int\n```\n\nnow we want a dataclass for portfolio that will be serialized to and from json.\nwe inherit `dataclassjsonmixin` that adds this functionality:\n\n```python\nfrom mashumaro.mixins.json import dataclassjsonmixin\n\n...\n\n@dataclass\nclass portfolio(dataclassjsonmixin):\n    currencies: list[currencyposition]\n    stocks: list[stockposition]\n```\n\nlet's create a portfolio instance and check methods `from_json` and `to_json`:\n\n```python\nportfolio = portfolio(\n    currencies=[\n        currencyposition(currency.usd, 238.67),\n        currencyposition(currency.eur, 361.84),\n    ],\n    stocks=[\n        stockposition(\"aapl\", \"apple\", 10),\n        stockposition(\"amzn\", \"amazon\", 10),\n    ]\n)\n\nportfolio_json = portfolio.to_json()\nassert portfolio.from_json(portfolio_json) == portfolio\n```\n\nif we need to serialize something different from a root dataclass,\nwe can use codecs. in the following example we create a json decoder and encoder\nfor a list of currencies:\n\n```python\nfrom mashumaro.codecs.json import jsondecoder, jsonencoder\n\n...\n\ndecoder = jsondecoder(list[currencyposition])\nencoder = jsonencoder(list[currencyposition])\n\ncurrencies = [\n    currencyposition(currency.usd, 238.67),\n    currencyposition(currency.eur, 361.84),\n]\ncurrencies_json = encoder.encode(currencies)\nassert decoder.decode(currencies_json) == currencies\n\n```\n\nhow does it work?\n-------------------------------------------------------------------------------\n\nthis library works by taking the schema of the data and generating a\nspecific decoder and encoder for exactly that schema, taking into account the\nspecifics of serialization format. this is much faster than inspection of\ndata types on every call of decoding or encoding at runtime.\n\nthese specific decoders and encoders are generated by\n[codecs and mixins](#supported-serialization-formats). when using serialization\nmixins, these methods are compiled during import time (or at runtime in some\ncases) and are set as attributes to your dataclasses. to minimize the import\ntime, you can explicitly enable\n[lazy compilation](#lazy_compilation-config-option).\n\nbenchmark\n-------------------------------------------------------------------------------\n\n* macos 14.0 sonoma\n* apple m1\n* 16gb ram\n* python 3.12.0\n\nbenchmark using [pyperf](https://github.com/psf/pyperf) with github issue model. please note that the\nfollowing charts use logarithmic scale, as it is convenient for displaying\nvery large ranges of values.\n\n<img src=\"https://raw.githubusercontent.com/fatal1ty/mashumaro/d5f98a2bea64b8ed57c07db408beee5709969c4c/benchmark/charts/load_light.svg\" width=\"604\">\n<img src=\"https://raw.githubusercontent.com/fatal1ty/mashumaro/d5f98a2bea64b8ed57c07db408beee5709969c4c/benchmark/charts/dump_light.svg\" width=\"604\">\n\n> [!note]\\\n> benchmark results may vary depending on the specific configuration and\n> parameters used for serialization and deserialization. however, we have made\n> an attempt to use the available options that can speed up and smooth out the\n> differences in how libraries work.\n\nto run benchmark in your environment:\n```bash\ngit clone git@github.com:fatal1ty/mashumaro.git\ncd mashumaro\npython3 -m venv env && source env/bin/activate\npip install -e .\npip install -r requirements-dev.txt\n./benchmark/run.sh\n```\n\nsupported serialization formats\n-------------------------------------------------------------------------------\n\nthis library has built-in support for multiple popular formats:\n\n* [json](https://www.json.org)\n* [yaml](https://yaml.org)\n* [toml](https://toml.io)\n* [messagepack](https://msgpack.org)\n\nthere are preconfigured codecs and mixin classes. however, you're free\nto override some settings if necessary.\n\n> [!important]\\\n> as for codecs, you are\n> offered to choose between convenience and efficiency. when you need to decode\n> or encode structured data more than once, it's highly recommended to create\n> and reuse a decoder or encoder specifically for that structure. for one-time\n> use with default settings it may be convenient to use global functions that\n> create a disposable decoder or encoder under the hood. be aware not to use\n> these convenient global functions multiple times for the same structure.\n\n### basic form\n\nbasic form denotes a python object consisting only of basic data types\nsupported by most serialization formats. these types are:\n[`str`](https://docs.python.org/3/library/stdtypes.html#str),\n[`int`](https://docs.python.org/3/library/functions.html#int),\n[`float`](https://docs.python.org/3/library/functions.html#float),\n[`bool`](https://docs.python.org/3/library/stdtypes.html#bltin-boolean-values),\n[`list`](https://docs.python.org/3/library/stdtypes.html#list),\n[`dict`](https://docs.python.org/3/library/stdtypes.html#dict).\n\nthis is also a starting point you can play with for a comprehensive\ntransformation of your data.\n\nefficient decoder and encoder can be used as follows:\n\n```python\nfrom mashumaro.codecs import basicdecoder, basicencoder\n# or from mashumaro.codecs.basic import basicdecoder, basicencoder\n\ndecoder = basicdecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = basicencoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nconvenient functions are recommended to be used as follows:\n```python\nimport mashumaro.codecs.basic as basic_codec\n\nbasic_codec.decode(..., <shape_type>)\nbasic_codec.encode(..., <shape_type>)\n```\n\nmixin can be used as follows:\n```python\nfrom mashumaro import dataclassdictmixin\n# or from mashumaro.mixins.dict import dataclassdictmixin\n\n@dataclass\nclass mymodel(dataclassdictmixin):\n    ...\n\nmymodel.from_dict(...)\nmymodel(...).to_dict()\n```\n\n> [!tip]\\\n> you don't need to inherit `dataclassdictmixin` along with other serialization\n> mixins because it's a base class for them.\n\n### json\n\n[json](https://www.json.org) is a lightweight data-interchange format. you can\nchoose between standard library\n[json](https://docs.python.org/3/library/json.html) for compatibility and\nthird-party dependency [orjson](https://pypi.org/project/orjson/) for better\nperformance.\n\n#### json library\n\nefficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.json import jsondecoder, jsonencoder\n\ndecoder = jsondecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = jsonencoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nconvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.json import json_decode, json_encode\n\njson_decode(..., <shape_type>)\njson_encode(..., <shape_type>)\n```\n\nconvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.json as json_codec\n\njson_codec.decode(...<shape_type>)\njson_codec.encode(..., <shape_type>)\n```\n\nmixin can be used as follows:\n```python\nfrom mashumaro.mixins.json import dataclassjsonmixin\n\n@dataclass\nclass mymodel(dataclassjsonmixin):\n    ...\n\nmymodel.from_json(...)\nmymodel(...).to_json()\n```\n\n#### orjson library\n\nin order to use [`orjson`](https://pypi.org/project/orjson/) library, it must\nbe installed manually or using an extra option for `mashumaro`:\n\n```shell\npip install mashumaro[orjson]\n```\n\nthe following data types will be handled by\n[`orjson`](https://pypi.org/project/orjson/) library by default:\n* [`datetime`](https://docs.python.org/3/library/datetime.html#datetime.datetime)\n* [`date`](https://docs.python.org/3/library/datetime.html#datetime.date)\n* [`time`](https://docs.python.org/3/library/datetime.html#datetime.time)\n* [`uuid.uuid`](https://docs.python.org/3/library/uuid.html#uuid.uuid)\n\nefficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.orjson import orjsondecoder, orjsonencoder\n\ndecoder = orjsondecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = orjsonencoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nconvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.orjson import json_decode, json_encode\n\njson_decode(..., <shape_type>)\njson_encode(..., <shape_type>)\n```\n\nconvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.orjson as json_codec\n\njson_codec.decode(...<shape_type>)\njson_codec.encode(..., <shape_type>)\n```\n\nmixin can be used as follows:\n```python\nfrom mashumaro.mixins.orjson import dataclassorjsonmixin\n\n@dataclass\nclass mymodel(dataclassorjsonmixin):\n    ...\n\nmymodel.from_json(...)\nmymodel(...).to_json()\nmymodel(...).to_jsonb()\n```\n\n### yaml\n\n[yaml](https://yaml.org) is a human-friendly data serialization language for\nall programming languages. in order to use this format, the\n[`pyyaml`](https://pypi.org/project/pyyaml/) package must be installed.\nyou can install it manually or using an extra option for `mashumaro`:\n\n```shell\npip install mashumaro[yaml]\n```\n\nefficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.yaml import yamldecoder, yamlencoder\n\ndecoder = yamldecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = yamlencoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nconvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.yaml import yaml_decode, yaml_encode\n\nyaml_decode(..., <shape_type>)\nyaml_encode(..., <shape_type>)\n```\n\nconvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.yaml as yaml_codec\n\nyaml_codec.decode(...<shape_type>)\nyaml_codec.encode(..., <shape_type>)\n```\n\nmixin can be used as follows:\n```python\nfrom mashumaro.mixins.yaml import dataclassyamlmixin\n\n@dataclass\nclass mymodel(dataclassyamlmixin):\n    ...\n\nmymodel.from_yaml(...)\nmymodel(...).to_yaml()\n```\n\n### toml\n\n[toml](https://toml.io) is config file format for humans.\nin order to use this format, the [`tomli`](https://pypi.org/project/tomli/) and\n[`tomli-w`](https://pypi.org/project/tomli-w/) packages must be installed.\nin python 3.11+, `tomli` is included as\n[`tomlib`](https://docs.python.org/3/library/tomllib.html) standard library\nmodule and is used for this format. you can install the missing packages\nmanually or using an extra option\nfor `mashumaro`:\n\n```shell\npip install mashumaro[toml]\n```\n\nthe following data types will be handled by\n[`tomli`](https://pypi.org/project/tomli/)/\n[`tomli-w`](https://pypi.org/project/tomli-w/) library by default:\n* [`datetime`](https://docs.python.org/3/library/datetime.html#datetime.datetime)\n* [`date`](https://docs.python.org/3/library/datetime.html#datetime.date)\n* [`time`](https://docs.python.org/3/library/datetime.html#datetime.time)\n\nfields with value `none` will be omitted on serialization because toml\ndoesn't support null values.\n\nefficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.toml import tomldecoder, tomlencoder\n\ndecoder = tomldecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = tomlencoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nconvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.toml import toml_decode, toml_encode\n\ntoml_decode(..., <shape_type>)\ntoml_encode(..., <shape_type>)\n```\n\nconvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.toml as toml_codec\n\ntoml_codec.decode(...<shape_type>)\ntoml_codec.encode(..., <shape_type>)\n```\n\nmixin can be used as follows:\n```python\nfrom mashumaro.mixins.toml import dataclasstomlmixin\n\n@dataclass\nclass mymodel(dataclasstomlmixin):\n    ...\n\nmymodel.from_toml(...)\nmymodel(...).to_toml()\n```\n\n### messagepack\n\n[messagepack](https://msgpack.org) is an efficient binary serialization format.\nin order to use this mixin, the [`msgpack`](https://pypi.org/project/msgpack/)\npackage must be installed. you can install it manually or using an extra\noption for `mashumaro`:\n\n```shell\npip install mashumaro[msgpack]\n```\n\nthe following data types will be handled by\n[`msgpack`](https://pypi.org/project/msgpack/) library by default:\n* [`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes)\n* [`bytearray`](https://docs.python.org/3/library/stdtypes.html#bytearray)\n\nefficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.msgpack import messagepackdecoder, messagepackencoder\n\ndecoder = messagepackdecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = messagepackencoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nconvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.msgpack import msgpack_decode, msgpack_encode\n\nmsgpack_decode(..., <shape_type>)\nmsgpack_encode(..., <shape_type>)\n```\n\nconvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.msgpack as msgpack_codec\n\nmsgpack_codec.decode(...<shape_type>)\nmsgpack_codec.encode(..., <shape_type>)\n```\n\nmixin can be used as follows:\n```python\nfrom mashumaro.mixins.msgpack import dataclassmessagepackmixin\n\n@dataclass\nclass mymodel(dataclassmessagepackmixin):\n    ...\n\nmymodel.from_msgpack(...)\nmymodel(...).to_msgpack()\n```\n\ncustomization\n-------------------------------------------------------------------------------\n\ncustomization options of `mashumaro` are extensive and will most likely cover your needs.\nwhen it comes to non-standard data types and non-standard serialization support, you can do the following:\n* turn an existing regular or generic class into a serializable one\nby inheriting the [`serializabletype`](#serializabletype-interface) class\n* write different serialization strategies for an existing regular or generic type that is not under your control\nusing [`serializationstrategy`](#serializationstrategy) class\n* define serialization / deserialization methods:\n  * for a specific dataclass field by using [field options](#field-options)\n  * for a specific data type used in the dataclass by using [`config`](#config-options) class\n* alter input and output data with serialization / deserialization [hooks](#serialization-hooks)\n* separate serialization scheme from a dataclass in a reusable manner using [dialects](#dialects)\n* choose from predefined serialization engines for the specific data types, e.g. `datetime` and `namedtuple`\n\n### serializabletype interface\n\nif you have a custom class or hierarchy of classes whose instances you want\nto serialize with `mashumaro`, the first option is to implement\n`serializabletype` interface.\n\n#### user-defined types\n\nlet's look at this not very practicable example:\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.types import serializabletype\n\nclass airport(serializabletype):\n    def __init__(self, code, city):\n        self.code, self.city = code, city\n\n    def _serialize(self):\n        return [self.code, self.city]\n\n    @classmethod\n    def _deserialize(cls, value):\n        return cls(*value)\n\n    def __eq__(self, other):\n        return self.code, self.city == other.code, other.city\n\n@dataclass\nclass flight(dataclassdictmixin):\n    origin: airport\n    destination: airport\n\njfk = airport(\"jfk\", \"new york city\")\nlax = airport(\"lax\", \"los angeles\")\n\ninput_data = {\n    \"origin\": [\"jfk\", \"new york city\"],\n    \"destination\": [\"lax\", \"los angeles\"]\n}\nmy_flight = flight.from_dict(input_data)\nassert my_flight == flight(jfk, lax)\nassert my_flight.to_dict() == input_data\n```\n\nyou can see how `airport` instances are seamlessly created from lists of two\nstrings and serialized into them.\n\nby default `_deserialize` method will get raw input data without any\ntransformations before. this should be enough in many cases, especially when\nyou need to perform non-standard transformations yourself, but let's extend\nour example:\n\n```python\nclass itinerary(serializabletype):\n    def __init__(self, flights):\n        self.flights = flights\n\n    def _serialize(self):\n        return self.flights\n\n    @classmethod\n    def _deserialize(cls, flights):\n        return cls(flights)\n\n@dataclass\nclass travelplan(dataclassdictmixin):\n    budget: float\n    itinerary: itinerary\n\ninput_data = {\n    \"budget\": 10_000,\n    \"itinerary\": [\n        {\n            \"origin\": [\"jfk\", \"new york city\"],\n            \"destination\": [\"lax\", \"los angeles\"]\n        },\n        {\n            \"origin\": [\"lax\", \"los angeles\"],\n            \"destination\": [\"sfo\", \"san fransisco\"]\n        }\n    ]\n}\n```\n\nif we pass the flight list as is into `itinerary._deserialize`, our itinerary\nwill have something that we may not expect \u2014 `list[dict]` instead of\n`list[flight]`. the solution is quite simple. instead of calling\n`flight._deserialize` yourself, just use annotations:\n\n```python\nclass itinerary(serializabletype, use_annotations=true):\n    def __init__(self, flights):\n        self.flights = flights\n\n    def _serialize(self) -> list[flight]:\n        return self.flights\n\n    @classmethod\n    def _deserialize(cls, flights: list[flight]):\n        return cls(flights)\n\nmy_plan = travelplan.from_dict(input_data)\nassert isinstance(my_plan.itinerary.flights[0], flight)\nassert isinstance(my_plan.itinerary.flights[1], flight)\nassert my_plan.to_dict() == input_data\n```\n\nhere we add annotations to the only argument of `_deserialize` method and\nto the return value of `_serialize` method as well. the latter is needed for\ncorrect serialization.\n\n> [!important]\\\n> the importance of explicit passing `use_annotations=true` when defining a\n> class is that otherwise implicit using annotations might break compatibility\n> with old code that wasn't aware of this feature. it will be enabled by\n> default in the future major release.\n\n#### user-defined generic types\n\nthe great thing to note about using annotations in `serializabletype` is that\nthey work seamlessly with [generic](https://docs.python.org/3/library/typing.html#user-defined-generic-types)\nand [variadic generic](https://peps.python.org/pep-0646/) types.\nlet's see how this can be useful:\n\n```python\nfrom datetime import date\nfrom typing import typevar\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.types import serializabletype\n\nkt = typevar(\"kt\")\nvt = typevar(\"vt\")\n\nclass dictwrapper(dict[kt, vt], serializabletype, use_annotations=true):\n    def _serialize(self) -> dict[kt, vt]:\n        return dict(self)\n\n    @classmethod\n    def _deserialize(cls, value: dict[kt, vt]) -> 'dictwrapper[kt, vt]':\n        return cls(value)\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    x: dictwrapper[date, str]\n    y: dictwrapper[str, date]\n\ninput_data = {\n    \"x\": {\"2022-12-07\": \"2022-12-07\"},\n    \"y\": {\"2022-12-07\": \"2022-12-07\"}\n}\nobj = dataclass.from_dict(input_data)\nassert obj == dataclass(\n    x=dictwrapper({date(2022, 12, 7): \"2022-12-07\"}),\n    y=dictwrapper({\"2022-12-07\": date(2022, 12, 7)})\n)\nassert obj.to_dict() == input_data\n```\n\nyou can see that formatted date is deserialized to `date` object before passing\nto `dictwrapper._deserialize` in a key or value according to the generic\nparameters.\n\nif you have generic dataclass types, you can use `serializabletype` for them as well, but it's not necessary since\nthey're [supported](#generic-dataclasses) out of the box.\n\n### serializationstrategy\n\nif you want to add support for a custom third-party type that is not under your control,\nyou can write serialization and deserialization logic inside `serializationstrategy` class,\nwhich will be reusable and so well suited in case that third-party type is widely used.\n`serializationstrategy` is also good if you want to create strategies that are slightly different from each other,\nbecause you can add the strategy differentiator in the `__init__` method.\n\n#### third-party types\n\nto demonstrate how `serializationstrategy` works let's write a simple strategy for datetime serialization\nin different formats. in this example we will use the same strategy class for two dataclass fields,\nbut a string representing the date and time will be different.\n\n```python\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom mashumaro import dataclassdictmixin, field_options\nfrom mashumaro.types import serializationstrategy\n\nclass formatteddatetime(serializationstrategy):\n    def __init__(self, fmt):\n        self.fmt = fmt\n\n    def serialize(self, value: datetime) -> str:\n        return value.strftime(self.fmt)\n\n    def deserialize(self, value: str) -> datetime:\n        return datetime.strptime(value, self.fmt)\n\n@dataclass\nclass datetimeformats(dataclassdictmixin):\n    short: datetime = field(\n        metadata=field_options(\n            serialization_strategy=formatteddatetime(\"%d%m%y%h%m%s\")\n        )\n    )\n    verbose: datetime = field(\n        metadata=field_options(\n            serialization_strategy=formatteddatetime(\"%a %b %d, %y, %h:%m:%s\")\n        )\n    )\n\nformats = datetimeformats(\n    short=datetime(2019, 1, 1, 12),\n    verbose=datetime(2019, 1, 1, 12),\n)\ndictionary = formats.to_dict()\n# {'short': '01012019120000', 'verbose': 'tuesday january 01, 2019, 12:00:00'}\nassert datetimeformats.from_dict(dictionary) == formats\n```\n\nsimilarly to `serializabletype`, `serializationstrategy` could also take advantage of annotations:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.types import serializationstrategy\n\nclass tsserializationstrategy(serializationstrategy, use_annotations=true):\n    def serialize(self, value: datetime) -> float:\n        return value.timestamp()\n\n    def deserialize(self, value: float) -> datetime:\n        # value will be converted to float before being passed to this method\n        return datetime.fromtimestamp(value)\n\n@dataclass\nclass example(dataclassdictmixin):\n    dt: datetime\n\n    class config:\n        serialization_strategy = {\n            datetime: tsserializationstrategy(),\n        }\n\nexample = example.from_dict({\"dt\": \"1672531200\"})\nprint(example)\n# example(dt=datetime.datetime(2023, 1, 1, 3, 0))\nprint(example.to_dict())\n# {'dt': 1672531200.0}\n```\n\nhere the passed string value `\"1672531200\"` will be converted to `float` before being passed to `deserialize` method\nthanks to the `float` annotation.\n\n> [!important]\\\n> as well as for `serializabletype`, the value of `use_annotatons` will be\n> `true` by default in the future major release.\n\n#### third-party generic types\n\nto create a generic version of a serialization strategy you need to follow these steps:\n* inherit [`generic[...]`](https://docs.python.org/3/library/typing.html#typing.generic) type\nwith the number of parameters matching the number of parameters\nof the target generic type\n* write generic annotations for `serialize` method's return type and for `deserialize` method's argument type\n* use the origin type of the target generic type in the [`serialization_strategy`](#serialization_strategy-config-option) config section\n([`typing.get_origin`](https://docs.python.org/3/library/typing.html#typing.get_origin) might be helpful)\n\nthere is no need to add `use_annotations=true` here because it's enabled implicitly\nfor generic serialization strategies.\n\nfor example, there is a third-party [multidict](https://pypi.org/project/multidict/) package that has a generic `multidict` type.\na generic serialization strategy for it might look like this:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom pprint import pprint\nfrom typing import generic, list, tuple, typevar\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.types import serializationstrategy\n\nfrom multidict import multidict\n\nt = typevar(\"t\")\n\nclass multidictserializationstrategy(serializationstrategy, generic[t]):\n    def serialize(self, value: multidict[t]) -> list[tuple[str, t]]:\n        return [(k, v) for k, v in value.items()]\n\n    def deserialize(self, value: list[tuple[str, t]]) -> multidict[t]:\n        return multidict(value)\n\n\n@dataclass\nclass example(dataclassdictmixin):\n    floats: multidict[float]\n    date_lists: multidict[list[date]]\n\n    class config:\n        serialization_strategy = {\n            multidict: multidictserializationstrategy()\n        }\n\nexample = example(\n    floats=multidict([(\"x\", 1.1), (\"x\", 2.2)]),\n    date_lists=multidict(\n        [(\"x\", [date(2023, 1, 1), date(2023, 1, 2)]),\n         (\"x\", [date(2023, 2, 1), date(2023, 2, 2)])]\n    ),\n)\npprint(example.to_dict())\n# {'date_lists': [['x', ['2023-01-01', '2023-01-02']],\n#                 ['x', ['2023-02-01', '2023-02-02']]],\n#  'floats': [['x', 1.1], ['x', 2.2]]}\nassert example.from_dict(example.to_dict()) == example\n```\n\n### field options\n\nin some cases creating a new class just for one little thing could be\nexcessive. moreover, you may need to deal with third party classes that you are\nnot allowed to change. you can use[`dataclasses.field`](https://docs.python.org/3/library/dataclasses.html#dataclasses.field)\nfunction as a default field value to configure some serialization aspects\nthrough its `metadata` parameter. next section describes all supported options\nto use in `metadata` mapping.\n\n#### `serialize` option\n\nthis option allows you to change the serialization method. when using\nthis option, the serialization behaviour depends on what type of value the\noption has. it could be either `callable[[any], any]` or `str`.\n\na value of type `callable[[any], any]` is a generic way to specify any callable\nobject like a function, a class method, a class instance method, an instance\nof a callable class or even a lambda function to be called for serialization.\n\na value of type `str` sets a specific engine for serialization. keep in mind\nthat all possible engines depend on the data type that this option is used\nwith. at this moment there are next serialization engines to choose from:\n\n| applicable data types      | supported engines    | description                                                                                                                                                                                                  |\n|:---------------------------|:---------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `namedtuple`, `namedtuple` | `as_list`, `as_dict` | how to pack named tuples. by default `as_list` engine is used that means your named tuple class instance will be packed into a list of its values. you can pack it into a dictionary using `as_dict` engine. |\n| `any`                      | `omit`               | skip the field during serialization                                                                                                                                                                          |\n\n> [!tip]\\\n> you can pass a field value as is without changes on serialization using\n[`pass_through`](#passing-field-values-as-is).\n\nexample:\n\n```python\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\nfrom typing import namedtuple\nfrom mashumaro import dataclassdictmixin\n\nclass mynamedtuple(namedtuple):\n    x: int\n    y: float\n\n@dataclass\nclass a(dataclassdictmixin):\n    dt: datetime = field(\n        metadata={\n            \"serialize\": lambda v: v.strftime('%y-%m-%d %h:%m:%s')\n        }\n    )\n    t: mynamedtuple = field(metadata={\"serialize\": \"as_dict\"})\n```\n\n#### `deserialize` option\n\nthis option allows you to change the deserialization method. when using\nthis option, the deserialization behaviour depends on what type of value the\noption has. it could be either `callable[[any], any]` or `str`.\n\na value of type `callable[[any], any]` is a generic way to specify any callable\nobject like a function, a class method, a class instance method, an instance\nof a callable class or even a lambda function to be called for deserialization.\n\na value of type `str` sets a specific engine for deserialization. keep in mind\nthat all possible engines depend on the data type that this option is used\nwith. at this moment there are next deserialization engines to choose from:\n\n| applicable data types      | supported engines                                                                                                                   | description                                                                                                                                                                                                                                                                                             |\n|:---------------------------|:------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `datetime`, `date`, `time` | [`ciso8601`](https://github.com/closeio/ciso8601#supported-subset-of-iso-8601), [`pendulum`](https://github.com/sdispater/pendulum) | how to parse datetime string. by default native [`fromisoformat`](https://docs.python.org/3/library/datetime.html#datetime.datetime.fromisoformat) of corresponding class will be used for `datetime`, `date` and `time` fields. it's the fastest way in most cases, but you can choose an alternative. |\n| `namedtuple`, `namedtuple` | `as_list`, `as_dict`                                                                                                                | how to unpack named tuples. by default `as_list` engine is used that means your named tuple class instance will be created from a list of its values. you can unpack it from a dictionary using `as_dict` engine.                                                                                       |\n\n> [!tip]\\\n> you can pass a field value as is without changes on deserialization using\n[`pass_through`](#passing-field-values-as-is).\n\nexample:\n\n```python\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\nfrom typing import list, namedtuple\nfrom mashumaro import dataclassdictmixin\nimport ciso8601\nimport dateutil\n\nclass mynamedtuple(namedtuple):\n    x: int\n    y: float\n\n@dataclass\nclass a(dataclassdictmixin):\n    x: datetime = field(\n        metadata={\"deserialize\": \"pendulum\"}\n    )\n\nclass b(dataclassdictmixin):\n    x: datetime = field(\n        metadata={\"deserialize\": ciso8601.parse_datetime_as_naive}\n    )\n\n@dataclass\nclass c(dataclassdictmixin):\n    dt: list[datetime] = field(\n        metadata={\n            \"deserialize\": lambda l: list(map(dateutil.parser.isoparse, l))\n        }\n    )\n\n@dataclass\nclass d(dataclassdictmixin):\n    x: mynamedtuple = field(metadata={\"deserialize\": \"as_dict\"})\n```\n\n#### `serialization_strategy` option\n\nthis option is useful when you want to change the serialization logic\nfor a dataclass field depending on some defined parameters using a reusable\nserialization scheme. you can find an example in the\n[`serializationstrategy`](#serializationstrategy) chapter.\n\n> [!tip]\\\n> you can pass a field value as is without changes on\n> serialization / deserialization using\n[`pass_through`](#passing-field-values-as-is).\n\n#### `alias` option\n\nin some cases it's better to have different names for a field in your class and\nin its serialized view. for example, a third-party legacy api you are working\nwith might operate with camel case style, but you stick to snake case style in\nyour code base. or even you want to load data with keys that are invalid\nidentifiers in python. this problem is easily solved by using aliases:\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import dataclassdictmixin, field_options\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    a: int = field(metadata=field_options(alias=\"fielda\"))\n    b: int = field(metadata=field_options(alias=\"#invalid\"))\n\nx = dataclass.from_dict({\"fielda\": 1, \"#invalid\": 2})  # dataclass(a=1, b=2)\nx.to_dict()  # {\"a\": 1, \"b\": 2}  # no aliases on serialization by default\n```\n\nif you want to write all the field aliases in one place, there is\n[a config option](#aliases-config-option) for that.\n\nif you want to deserialize all the fields by its names along with aliases,\nthere is [a config option](#allow_deserialization_not_by_alias-config-option)\nfor that.\n\nif you want to serialize all the fields by aliases you have two options to do so:\n* [`serialize_by_alias` config option](#serialize_by_alias-config-option)\n* [`serialize_by_alias` dialect option](#serialize_by_alias-dialect-option)\n* [`by_alias` keyword argument in `to_*` methods](#add-by_alias-keyword-argument)\n\nit's hard to imagine when it might be necessary to serialize only specific\nfields by alias, but such functionality is easily added to the library. open\nthe issue if you need it.\n\nif you don't want to remember the names of the options you can use\n`field_options` helper function:\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import dataclassdictmixin, field_options\n\n@dataclass\nclass a(dataclassdictmixin):\n    x: int = field(\n        metadata=field_options(\n            serialize=str,\n            deserialize=int,\n            ...\n        )\n    )\n```\n\nmore options are on the way. if you know which option would be useful for many,\nplease don't hesitate to create an issue or pull request.\n\n### config options\n\nif inheritance is not an empty word for you, you'll fall in love with the\n`config` class. you can register `serialize` and `deserialize` methods, define\ncode generation options and other things just in one place. or in some\nclasses in different ways if you need flexibility. inheritance is always on the\nfirst place.\n\nthere is a base class `baseconfig` that you can inherit for the sake of\nconvenience, but it's not mandatory.\n\nin the following example you can see how\nthe `debug` flag is changed from class to class: `modela` will have debug mode enabled but\n`modelb` will not.\n\n```python\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\n\nclass basemodel(dataclassdictmixin):\n    class config(baseconfig):\n        debug = true\n\nclass modela(basemodel):\n    a: int\n\nclass modelb(basemodel):\n    b: int\n\n    class config(baseconfig):\n        debug = false\n```\n\nnext section describes all supported options to use in the config.\n\n#### `debug` config option\n\nif you enable the `debug` option the generated code for your data class\nwill be printed.\n\n#### `code_generation_options` config option\n\nsome users may need functionality that wouldn't exist without extra cost such\nas valuable cpu time to execute additional instructions. since not everyone\nneeds such instructions, they can be enabled by a constant in the list,\nso the fastest basic behavior of the library will always remain by default.\nthe following table provides a brief overview of all the available constants\ndescribed below.\n\n| constant                                                        | description                                                          |\n|:----------------------------------------------------------------|:---------------------------------------------------------------------|\n| [`to_dict_add_omit_none_flag`](#add-omit_none-keyword-argument) | adds `omit_none` keyword-only argument to `to_*` methods.            |\n| [`to_dict_add_by_alias_flag`](#add-by_alias-keyword-argument)   | adds `by_alias` keyword-only argument to `to_*` methods.             |\n| [`add_dialect_support`](#add-dialect-keyword-argument)          | adds `dialect` keyword-only argument to `from_*` and `to_*` methods. |\n| [`add_serialization_context`](#add-context-keyword-argument)    | adds `context` keyword-only argument to `to_*` methods.              |\n\n#### `serialization_strategy` config option\n\nyou can register custom [`serializationstrategy`](#serializationstrategy), `serialize` and `deserialize`\nmethods for specific types just in one place. it could be configured using\na dictionary with types as keys. the value could be either a\n[`serializationstrategy`](#serializationstrategy) instance or a dictionary with `serialize` and\n`deserialize` values with the same meaning as in the\n[field options](#field-options).\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import datetime, date\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\nfrom mashumaro.types import serializationstrategy\n\nclass formatteddatetime(serializationstrategy):\n    def __init__(self, fmt):\n        self.fmt = fmt\n\n    def serialize(self, value: datetime) -> str:\n        return value.strftime(self.fmt)\n\n    def deserialize(self, value: str) -> datetime:\n        return datetime.strptime(value, self.fmt)\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n\n    x: datetime\n    y: date\n\n    class config(baseconfig):\n        serialization_strategy = {\n            datetime: formatteddatetime(\"%y\"),\n            date: {\n                # you can use specific str values for datetime here as well\n                \"deserialize\": \"pendulum\",\n                \"serialize\": date.isoformat,\n            },\n        }\n\ninstance = dataclass.from_dict({\"x\": \"2021\", \"y\": \"2021\"})\n# dataclass(x=datetime.datetime(2021, 1, 1, 0, 0), y=date(2021, 1, 1))\ndictionary = instance.to_dict()\n# {'x': '2021', 'y': '2021-01-01'}\n```\n\nnote that you can register different methods for multiple logical types which\nare based on the same type using `newtype` and `annotated`,\nsee [extending existing types](#extending-existing-types) for details.\n\n#### `aliases` config option\n\nsometimes it's better to write the field aliases in one place. you can mix\naliases here with [aliases in the field options](#alias-option), but the last ones will always\ntake precedence.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    a: int\n    b: int\n\n    class config(baseconfig):\n        aliases = {\n            \"a\": \"fielda\",\n            \"b\": \"fieldb\",\n        }\n\ndataclass.from_dict({\"fielda\": 1, \"fieldb\": 2})  # dataclass(a=1, b=2)\n```\n\n#### `serialize_by_alias` config option\n\nall the fields with [aliases](#alias-option) will be serialized by them by\ndefault when this option is enabled. you can mix this config option with\n[`by_alias`](#add-by_alias-keyword-argument) keyword argument.\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import dataclassdictmixin, field_options\nfrom mashumaro.config import baseconfig\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    field_a: int = field(metadata=field_options(alias=\"fielda\"))\n\n    class config(baseconfig):\n        serialize_by_alias = true\n\ndataclass(field_a=1).to_dict()  # {'fielda': 1}\n```\n\n#### `allow_deserialization_not_by_alias` config option\n\nwhen using aliases, the deserializer defaults to requiring the keys to match\nwhat is defined as the alias.\nif the flexibility to deserialize aliased and unaliased keys is required then\nthe config option `allow_deserialization_not_by_alias = true` can be set to\nenable the feature.\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\n\n\n@dataclass\nclass aliaseddataclass(dataclassdictmixin):\n    foo: int = field(metadata={\"alias\": \"alias_foo\"})\n    bar: int = field(metadata={\"alias\": \"alias_bar\"})\n\n    class config(baseconfig):\n        allow_deserialization_not_by_alias = true\n\n\nalias_dict = {\"alias_foo\": 1, \"alias_bar\": 2}\nt1 = aliaseddataclass.from_dict(alias_dict)\n\nno_alias_dict = {\"foo\": 1, \"bar\": 2}\n# this would raise `mashumaro.exceptions.missingfield`\n# if allow_deserialization_not_by_alias was false\nt2 = aliaseddataclass.from_dict(no_alias_dict)\nassert t1 == t2\n```\n\n#### `omit_none` config option\n\nall the fields with `none` values will be skipped during serialization by\ndefault when this option is enabled. you can mix this config option with\n[`omit_none`](#add-omit_none-keyword-argument) keyword argument.\n\n```python\nfrom dataclasses import dataclass\nfrom typing import optional\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    x: optional[int] = 42\n\n    class config(baseconfig):\n        omit_none = true\n\ndataclass(x=none).to_dict()  # {}\n```\n\n#### `omit_default` config option\n\nwhen this option enabled, all the fields that have values equal to the defaults\nor the default_factory results will be skipped during serialization.\n\n```python\nfrom dataclasses import dataclass, field\nfrom typing import list, optional, tuple\nfrom mashumaro import dataclassdictmixin, field_options\nfrom mashumaro.config import baseconfig\n\n@dataclass\nclass foo:\n    foo: str\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    a: int = 42\n    b: tuple[int, ...] = field(default=(1, 2, 3))\n    c: list[foo] = field(default_factory=lambda: [foo(\"foo\")])\n    d: optional[str] = none\n\n    class config(baseconfig):\n        omit_default = true\n\ndataclass(a=42, b=(1, 2, 3), c=[foo(\"foo\")]).to_dict()  # {}\n```\n\n#### `namedtuple_as_dict` config option\n\ndataclasses are a great way to declare and use data models. but it's not the only way.\npython has a typed version of [namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple)\ncalled [namedtuple](https://docs.python.org/3/library/typing.html#typing.namedtuple)\nwhich looks similar to dataclasses:\n\n```python\nfrom typing import namedtuple\n\nclass point(namedtuple):\n    x: int\n    y: int\n```\n\nthe same with a dataclass will look like this:\n\n```python\nfrom dataclasses import dataclass\n\n@dataclass\nclass point:\n    x: int\n    y: int\n```\n\nat first glance, you can use both options. but imagine that you need to create\na bunch of instances of the `point` class. due to how dataclasses work you will\nhave more memory consumption compared to named tuples. in such a case it could\nbe more appropriate to use named tuples.\n\nby default, all named tuples are packed into lists. but with `namedtuple_as_dict`\noption you have a drop-in replacement for dataclasses:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import list, namedtuple\nfrom mashumaro import dataclassdictmixin\n\nclass point(namedtuple):\n    x: int\n    y: int\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    points: list[point]\n\n    class config:\n        namedtuple_as_dict = true\n\nobj = dataclass.from_dict({\"points\": [{\"x\": 0, \"y\": 0}, {\"x\": 1, \"y\": 1}]})\nprint(obj.to_dict())  # {\"points\": [{\"x\": 0, \"y\": 0}, {\"x\": 1, \"y\": 1}]}\n```\n\nif you want to serialize only certain named tuple fields as dictionaries, you\ncan use the corresponding [serialization](#serialize-option) and\n[deserialization](#deserialize-option) engines.\n\n#### `allow_postponed_evaluation` config option\n\n[pep 563](https://www.python.org/dev/peps/pep-0563/) solved the problem of forward references by postponing the evaluation\nof annotations, so you can write the following code:\n\n```python\nfrom __future__ import annotations\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\n\n@dataclass\nclass a(dataclassdictmixin):\n    x: b\n\n@dataclass\nclass b(dataclassdictmixin):\n    y: int\n\nobj = a.from_dict({'x': {'y': 1}})\n```\n\nyou don't need to write anything special here, forward references work out of\nthe box. if a field of a dataclass has a forward reference in the type\nannotations, building of `from_*` and `to_*` methods of this dataclass\nwill be postponed until they are called once. however, if for some reason you\ndon't want the evaluation to be possibly postponed, you can disable it using\n`allow_postponed_evaluation` option:\n\n```python\nfrom __future__ import annotations\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\n\n@dataclass\nclass a(dataclassdictmixin):\n    x: b\n\n    class config:\n        allow_postponed_evaluation = false\n\n# unresolvedtypereferenceerror: class a has unresolved type reference b\n# in some of its fields\n\n@dataclass\nclass b(dataclassdictmixin):\n    y: int\n```\n\nin this case you will get `unresolvedtypereferenceerror` regardless of whether\nclass b is declared below or not.\n\n#### `dialect` config option\n\nthis option is described [below](#changing-the-default-dialect) in the\ndialects section.\n\n#### `orjson_options` config option\n\nthis option changes default options for `orjson.dumps` encoder which is\nused in [`dataclassorjsonmixin`](#dataclassorjsonmixin). for example, you can\ntell orjson to handle non-`str` `dict` keys as the built-in `json.dumps`\nencoder does. see [orjson documentation](https://github.com/ijl/orjson#option)\nto read more about these options.\n\n```python\nimport orjson\nfrom dataclasses import dataclass\nfrom typing import dict\nfrom mashumaro.config import baseconfig\nfrom mashumaro.mixins.orjson import dataclassorjsonmixin\n\n@dataclass\nclass myclass(dataclassorjsonmixin):\n    x: dict[int, int]\n\n    class config(baseconfig):\n        orjson_options = orjson.opt_non_str_keys\n\nassert myclass({1: 2}).to_json() == {\"1\": 2}\n```\n\n#### `discriminator` config option\n\nthis option is described in the\n[class level discriminator](#class-level-discriminator) section.\n\n#### `lazy_compilation` config option\n\nby using this option, the compilation of the `from_*` and `to_*` methods will\nbe deferred until they are called first time. this will reduce the import time\nand, in certain instances, may enhance the speed of deserialization\nby leveraging the data that is accessible after the class has been created.\n\n> [!caution]\\\n> if you need to save a reference to `from_*` or `to_*` method, you should\n> do it after the method is compiled. to be safe, you can always use lambda\n> function:\n> ```python\n> from_dict = lambda x: mymodel.from_dict(x)\n> to_dict = lambda x: x.to_dict()\n> ```\n\n#### `sort_keys` config option\n\nwhen set, the keys on serialized dataclasses will be sorted in alphabetical order.\n\nunlike the `sort_keys` option in the standard library's `json.dumps` function, this option acts at class creation time and has no effect on the performance of serialization.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\n\n@dataclass\nclass sorteddataclass(dataclassdictmixin):\n    foo: int\n    bar: int\n\n    class config(baseconfig):\n        sort_keys = true\n\nt = sorteddataclass(1, 2)\nassert t.to_dict() == {\"bar\": 2, \"foo\": 1}\n```\n\n### passing field values as is\n\nin some cases it's needed to pass a field value as is without any changes\nduring serialization / deserialization. there is a predefined\n[`pass_through`](https://github.com/fatal1ty/mashumaro/blob/master/mashumaro/helper.py#l58)\nobject that can be used as `serialization_strategy` or\n`serialize` / `deserialize` options:\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import dataclassdictmixin, pass_through\n\nclass myclass:\n    def __init__(self, some_value):\n        self.some_value = some_value\n\n@dataclass\nclass a1(dataclassdictmixin):\n    x: myclass = field(\n        metadata={\n            \"serialize\": pass_through,\n            \"deserialize\": pass_through,\n        }\n    )\n\n@dataclass\nclass a2(dataclassdictmixin):\n    x: myclass = field(\n        metadata={\n            \"serialization_strategy\": pass_through,\n        }\n    )\n\n@dataclass\nclass a3(dataclassdictmixin):\n    x: myclass\n\n    class config:\n        serialization_strategy = {\n            myclass: pass_through,\n        }\n\n@dataclass\nclass a4(dataclassdictmixin):\n    x: myclass\n\n    class config:\n        serialization_strategy = {\n            myclass: {\n                \"serialize\": pass_through,\n                \"deserialize\": pass_through,\n            }\n        }\n\nmy_class_instance = myclass(42)\n\nassert a1.from_dict({'x': my_class_instance}).x == my_class_instance\nassert a2.from_dict({'x': my_class_instance}).x == my_class_instance\nassert a3.from_dict({'x': my_class_instance}).x == my_class_instance\nassert a4.from_dict({'x': my_class_instance}).x == my_class_instance\n\na1_dict = a1(my_class_instance).to_dict()\na2_dict = a2(my_class_instance).to_dict()\na3_dict = a3(my_class_instance).to_dict()\na4_dict = a4(my_class_instance).to_dict()\n\nassert a1_dict == a2_dict == a3_dict == a4_dict == {\"x\": my_class_instance}\n```\n\n### extending existing types\n\nthere are situations where you might want some values of the same type to be\ntreated as their own type. you can create new logical types with\n[`newtype`](https://docs.python.org/3/library/typing.html#newtype) or\n[`annotated`](https://docs.python.org/3/library/typing.html#typing.annotated)\nand register serialization strategies for them:\n\n```python\nfrom typing import mapping, newtype, annotated\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\n\nsessionid = newtype(\"sessionid\", str)\naccountid = annotated[str, \"accountid\"]\n\n@dataclass\nclass context(dataclassdictmixin):\n    account_sessions: mapping[accountid, sessionid]\n\n    class config:\n        serialization_strategy = {\n            accountid: {\n                \"deserialize\": lambda x: ...,\n                \"serialize\": lambda x: ...,\n            },\n            sessionid: {\n                \"deserialize\": lambda x: ...,\n                \"serialize\": lambda x: ...,\n            }\n        }\n```\n\nalthough using `newtype` is usually the most reliable way to avoid logical\nerrors, you have to pay for it with notable overhead. if you are creating\ndataclass instances manually, then you know that type checkers will\nenforce you to enclose a value in your `\"newtype\"` callable, which leads\nto performance degradation:\n\n```python\npython -m timeit -s \"from typing import newtype; myint = newtype('myint', int)\" \"myint(42)\"\n10000000 loops, best of 5: 31.1 nsec per loop\n\npython -m timeit -s \"from typing import newtype; myint = newtype('myint', int)\" \"42\"\n50000000 loops, best of 5: 4.35 nsec per loop\n```\n\nhowever, when you create dataclass instances using the `from_*` method, there\nwill be no performance degradation, because the value won't be enclosed in the\ncallable in the generated code. therefore, if performance is more important\nto you than catching logical errors by type checkers, and you are actively\ncreating or changing dataclasses manually, then you should take a closer look\nat using `annotated`.\n\n### dialects\n\nsometimes it's needed to have different serialization and deserialization\nmethods depending on the data source where entities of the dataclass are\nstored or on the api to which the entities are being sent or received from.\nthere is a special `dialect` type that may contain all the differences from the\ndefault serialization and deserialization methods. you can create different\ndialects and use each of them for the same dataclass depending on\nthe situation.\n\nsuppose we have the following dataclass with a field of type `date`:\n```python\n@dataclass\nclass entity(dataclassdictmixin):\n    dt: date\n```\n\nby default, a field of `date` type serializes to a string in iso 8601 format,\nso the serialized entity will look like `{'dt': '2021-12-31'}`. but what if we\nhave, for example, two sensitive legacy ethiopian and japanese apis that use\ntwo different formats for dates \u2014 `dd/mm/yyyy` and `yyyy\u5e74mm\u6708dd\u65e5`? instead of\ncreating two similar dataclasses we can have one dataclass and two dialects:\n```python\nfrom dataclasses import dataclass\nfrom datetime import date, datetime\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import add_dialect_support\nfrom mashumaro.dialect import dialect\nfrom mashumaro.types import serializationstrategy\n\nclass datetimeserializationstrategy(serializationstrategy):\n    def __init__(self, fmt: str):\n        self.fmt = fmt\n\n    def serialize(self, value: date) -> str:\n        return value.strftime(self.fmt)\n\n    def deserialize(self, value: str) -> date:\n        return datetime.strptime(value, self.fmt).date()\n\nclass ethiopiandialect(dialect):\n    serialization_strategy = {\n        date: datetimeserializationstrategy(\"%d/%m/%y\")\n    }\n\nclass japanesedialect(dialect):\n    serialization_strategy = {\n        date: datetimeserializationstrategy(\"%y\u5e74%m\u6708%d\u65e5\")\n    }\n\n@dataclass\nclass entity(dataclassdictmixin):\n    dt: date\n\n    class config:\n        code_generation_options = [add_dialect_support]\n\nentity = entity(date(2021, 12, 31))\nentity.to_dict(dialect=ethiopiandialect)  # {'dt': '31/12/2021'}\nentity.to_dict(dialect=japanesedialect)   # {'dt': '2021\u5e7412\u670831\u65e5'}\nentity.from_dict({'dt': '2021\u5e7412\u670831\u65e5'}, dialect=japanesedialect)\n```\n\n#### `serialization_strategy` dialect option\n\nthis dialect option has the same meaning as the\n[similar config option](#serialization_strategy-config-option)\nbut for the dialect scope. you can register custom [`serializationstrategy`](#serializationstrategy),\n`serialize` and `deserialize` methods for the specific types.\n\n#### `serialize_by_alias` dialect option\n\nthis dialect option has the same meaning as the\n[similar config option](#serialize_by_alias-config-option)\nbut for the dialect scope.\n\n#### `omit_none` dialect option\n\nthis dialect option has the same meaning as the\n[similar config option](#omit_none-config-option) but for the dialect scope.\n\n#### `omit_default` dialect option\n\nthis dialect option has the same meaning as the\n[similar config option](#omitdefault-config-option) but for the dialect scope.\n\n#### `namedtuple_as_dict` dialect option\n\nthis dialect option has the same meaning as the\n[similar config option](#namedtuple_as_dict-config-option)\nbut for the dialect scope.\n\n#### `no_copy_collections` dialect option\n\nby default, all collection data types are serialized as a copy to prevent\nmutation of the original collection. as an example, if a dataclass contains\na field of type `list[str]`, then it will be serialized as a copy of the\noriginal list, so you can safely mutate it after. the downside is that copying\nis always slower than using a reference to the original collection. in some\ncases we know beforehand that mutation doesn't take place or is even desirable,\nso we can benefit from avoiding unnecessary copies by setting\n`no_copy_collections` to a sequence of origin collection data types.\nthis is applicable only for collections containing elements that do not\nrequire conversion.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\nfrom mashumaro.dialect import dialect\n\nclass nocopydialect(dialect):\n    no_copy_collections = (list, dict, set)\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    simple_list: list[str]\n    simple_dict: dict[str, str]\n    simple_set: set[str]\n\n    class config(baseconfig):\n        dialect = nocopydialect\n\nobj = dataclass([\"foo\"], {\"bar\": \"baz\"}, {\"foobar\"})\ndata = obj.to_dict()\n\nassert data[\"simple_list\"] is obj.simple_list\nassert data[\"simple_dict\"] is obj.simple_dict\nassert data[\"simple_set\"] is obj.simple_set\n```\n\nthis option is enabled for `list` and `dict` in the default dialects that\nbelong to mixins and codecs for the following formats:\n* [json (orjson library)](#orjson-library)\n* [toml](#toml)\n* [messagepack](#messagepack)\n\n#### changing the default dialect\n\nyou can change the default serialization and deserialization methods not only\nin the [`serialization_strategy`](#serialization_strategy-config-option) config\noption but also using the `dialect` config option. if you have multiple\ndataclasses without a common parent class the default dialect can help you\nto reduce the number of code lines written:\n\n```python\n@dataclass\nclass entity(dataclassdictmixin):\n    dt: date\n\n    class config:\n        dialect = japanesedialect\n\nentity = entity(date(2021, 12, 31))\nentity.to_dict()  # {'dt': '2021\u5e7412\u670831\u65e5'}\nassert entity.from_dict({'dt': '2021\u5e7412\u670831\u65e5'}) == entity\n```\n\ndefault dialect can also be set when using codecs:\n```python\nfrom mashumaro.codecs import basicdecoder, basicencoder\n\n@dataclass\nclass entity:\n    dt: date\n\ndecoder = basicdecoder(entity, default_dialect=japanesedialect)\nencoder = basicencoder(entity, default_dialect=japanesedialect)\n\nentity = entity(date(2021, 12, 31))\nencoder.encode(entity) # {'dt': '2021\u5e7412\u670831\u65e5'}\nassert decoder.decode({'dt': '2021\u5e7412\u670831\u65e5'}) == entity\n```\n\n### discriminator\n\nthere is a special `discriminator` class that allows you to customize how\na union of dataclasses or their hierarchy will be deserialized.\nit has the following parameters that affects class selection rules:\n\n* `field` \u2014 optional name of the input dictionary key (also known as tag)\n  by which all the variants can be distinguished\n* `include_subtypes` \u2014 allow to deserialize subclasses\n* `include_supertypes` \u2014 allow to deserialize superclasses\n* `variant_tagger_fn` \u2014 a custom function used to generate a tag value\n  associated with a variant\n\nby default, each variant that you want to discriminate by tags should have a\nclass-level attribute containing an associated tag value. this attribute should\nhave a name defined by `field` parameter. the tag value coule be in the\nfollowing forms:\n\n* without annotations: `type = 42`\n* annotated as classvar: `type: classvar[int] = 42`\n* annotated as final: `type: final[int] = 42`\n* annotated as literal: `type: literal[42] = 42`\n* annotated as strenum: `type: responsetype = responsetype.ok`\n\n> [!note]\\\n> keep in mind that by default only final, literal and strenum fields are\n> processed during serialization.\n\nhowever, it is possible to use discriminator without the class-level\nattribute. you can provide a custom function that generates a variant tag\nvalue. this function should take a class as the only argument and return a\nvalue of the basic type like `str` or `int`. the common practice is to use\na class name as a tag value:\n\n```python\nvariant_tagger_fn = lambda cls: cls.__name__\n```\n\nnext, we will look at different use cases, as well as their pros and cons.\n\n#### subclasses distinguishable by a field\n\noften you have a base dataclass and multiple subclasses that are easily\ndistinguishable from each other by the value of a particular field.\nfor example, there may be different events, messages or requests with\na discriminator field \"event_type\", \"message_type\" or just \"type\". you could've\nlisted all of them within `union` type, but it would be too verbose and\nimpractical. moreover, deserialization of the union would be slow, since we\nneed to iterate over each variant in the list until we find the right one.\n\nwe can improve subclass deserialization using `discriminator` as annotation\nwithin `annotated` type. we will use `field` parameter and set\n`include_subtypes` to `true`.\n\n> [!important]\\\n> the discriminator field should be accessible from the `__dict__` attribute\n> of a specific descendant, i.e. defined at the level of that descendant.\n> a descendant class without a discriminator field will be ignored, but\n> its descendants won't.\n\nsuppose we have a hierarchy of client events distinguishable by a class\nattribute \"type\":\n\n```python\nfrom dataclasses import dataclass\nfrom ipaddress import ipv4address\nfrom mashumaro import dataclassdictmixin\n\n@dataclass\nclass clientevent(dataclassdictmixin):\n    pass\n\n@dataclass\nclass clientconnectedevent(clientevent):\n    type = \"connected\"\n    client_ip: ipv4address\n\n@dataclass\nclass clientdisconnectedevent(clientevent):\n    type = \"disconnected\"\n    client_ip: ipv4address\n```\n\nwe use base dataclass `clientevent` for a field of another dataclass:\n\n```python\nfrom typing import annotated, list\n# or from typing_extensions import annotated\nfrom mashumaro.types import discriminator\n\n\n@dataclass\nclass aggregatedevents(dataclassdictmixin):\n    list: list[\n        annotated[\n            clientevent, discriminator(field=\"type\", include_subtypes=true)\n        ]\n    ]\n```\n\nnow we can deserialize events based on \"type\" value:\n\n```python\nevents = aggregatedevents.from_dict(\n    {\n        \"list\": [\n            {\"type\": \"connected\", \"client_ip\": \"10.0.0.42\"},\n            {\"type\": \"disconnected\", \"client_ip\": \"10.0.0.42\"},\n        ]\n    }\n)\nassert events == aggregatedevents(\n    list=[\n        clientconnectedevent(client_ip=ipv4address(\"10.0.0.42\")),\n        clientdisconnectedevent(client_ip=ipv4address(\"10.0.0.42\")),\n    ]\n)\n```\n\n#### subclasses without a common field\n\nin rare cases you have to deal with subclasses that don't have a common field\nname which they can be distinguished by. since `discriminator` can be\ninitialized without \"field\" parameter you can use it with only\n`include_subclasses` enabled. the drawback is that we will have to go through all\nthe subclasses until we find the suitable one. it's almost like using `union`\ntype but with subclasses support.\n\nsuppose we're making a brunch. we have some ingredients:\n\n```python\n@dataclass\nclass ingredient(dataclassdictmixin):\n    name: str\n\n@dataclass\nclass hummus(ingredient):\n    made_of: literal[\"chickpeas\", \"beet\", \"artichoke\"]\n    grams: int\n\n@dataclass\nclass celery(ingredient):\n    pieces: int\n```\n\nlet's create a plate:\n\n```python\n@dataclass\nclass plate(dataclassdictmixin):\n    ingredients: list[\n        annotated[ingredient, discriminator(include_subtypes=true)]\n    ]\n```\n\nand now we can put our ingredients on the plate:\n\n```python\nplate = plate.from_dict(\n    {\n        \"ingredients\": [\n            {\n                \"name\": \"hummus from the shop\",\n                \"made_of\": \"chickpeas\",\n                \"grams\": 150,\n            },\n            {\"name\": \"celery from my garden\", \"pieces\": 5},\n        ]\n    }\n)\nassert plate == plate(\n    ingredients=[\n        hummus(name=\"hummus from the shop\", made_of=\"chickpeas\", grams=150),\n        celery(name=\"celery from my garden\", pieces=5),\n    ]\n)\n```\n\nin some cases it's necessary to fall back to the base class if there is no\nsuitable subclass. we can set `include_supertypes` to `true`:\n\n```python\n@dataclass\nclass plate(dataclassdictmixin):\n    ingredients: list[\n        annotated[\n            ingredient,\n            discriminator(include_subtypes=true, include_supertypes=true),\n        ]\n    ]\n\nplate = plate.from_dict(\n    {\n        \"ingredients\": [\n            {\n                \"name\": \"hummus from the shop\",\n                \"made_of\": \"chickpeas\",\n                \"grams\": 150,\n            },\n            {\"name\": \"celery from my garden\", \"pieces\": 5},\n            {\"name\": \"cumin\"}  # <- new unknown ingredient\n        ]\n    }\n)\nassert plate == plate(\n    ingredients=[\n        hummus(name=\"hummus from the shop\", made_of=\"chickpeas\", grams=150),\n        celery(name=\"celery from my garden\", pieces=5),\n        ingredient(name=\"cumin\"),  # <- unknown ingredient added\n    ]\n)\n```\n\n#### class level discriminator\n\nit may often be more convenient to specify a `discriminator` once at the class\nlevel and use that class without `annotated` type for subclass deserialization.\ndepending on the `discriminator` parameters, it can be used as a replacement for\n[subclasses distinguishable by a field](#subclasses-distinguishable-by-a-field)\nas well as for [subclasses without a common field](#subclasses-without-a-common-field).\nthe only difference is that you can't use `include_supertypes=true` because\nit would lead to a recursion error.\n\nreworked example will look like this:\n\n```python\nfrom dataclasses import dataclass\nfrom ipaddress import ipv4address\nfrom typing import list\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\nfrom mashumaro.types import discriminator\n\n@dataclass\nclass clientevent(dataclassdictmixin):\n    class config(baseconfig):\n        discriminator = discriminator(  # <- add discriminator\n            field=\"type\",\n            include_subtypes=true,\n        )\n\n@dataclass\nclass clientconnectedevent(clientevent):\n    type = \"connected\"\n    client_ip: ipv4address\n\n@dataclass\nclass clientdisconnectedevent(clientevent):\n    type = \"disconnected\"\n    client_ip: ipv4address\n\n@dataclass\nclass aggregatedevents(dataclassdictmixin):\n    list: list[clientevent]  # <- use base class here\n```\n\nand now we can deserialize events based on \"type\" value as we did earlier:\n\n```python\nevents = aggregatedevents.from_dict(\n    {\n        \"list\": [\n            {\"type\": \"connected\", \"client_ip\": \"10.0.0.42\"},\n            {\"type\": \"disconnected\", \"client_ip\": \"10.0.0.42\"},\n        ]\n    }\n)\nassert events == aggregatedevents(\n    list=[\n        clientconnectedevent(client_ip=ipv4address(\"10.0.0.42\")),\n        clientdisconnectedevent(client_ip=ipv4address(\"10.0.0.42\")),\n    ]\n)\n```\n\nwhat's more interesting is that you can now deserialize subclasses simply by\ncalling the superclass `from_*` method, which is very useful:\n```python\ndisconnected_event = clientevent.from_dict(\n    {\"type\": \"disconnected\", \"client_ip\": \"10.0.0.42\"}\n)\nassert disconnected_event == clientdisconnectedevent(ipv4address(\"10.0.0.42\"))\n```\n\nthe same is applicable for subclasses without a common field:\n\n```python\n@dataclass\nclass ingredient(dataclassdictmixin):\n    name: str\n\n    class config:\n        discriminator = discriminator(include_subtypes=true)\n\n...\n\ncelery = ingredient.from_dict({\"name\": \"celery from my garden\", \"pieces\": 5})\nassert celery == celery(name=\"celery from my garden\", pieces=5)\n```\n\n#### working with union of classes\n\ndeserialization of union of types distinguishable by a particular field will\nbe much faster using `discriminator` because there will be no traversal\nof all classes and an attempt to deserialize each of them.\nusually this approach can be used when you have multiple classes without a\ncommon superclass or when you only need to deserialize some of the subclasses.\nin the following example we will use `include_supertypes=true` to\ndeserialize two subclasses out of three:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import annotated, literal, union\n# or from typing_extensions import annotated\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.types import discriminator\n\n@dataclass\nclass event(dataclassdictmixin):\n    pass\n\n@dataclass\nclass event1(event):\n    code: literal[1] = 1\n    ...\n\n@dataclass\nclass event2(event):\n    code: literal[2] = 2\n    ...\n\n@dataclass\nclass event3(event):\n    code: literal[3] = 3\n    ...\n\n@dataclass\nclass message(dataclassdictmixin):\n    event: annotated[\n        union[event1, event2],\n        discriminator(field=\"code\", include_supertypes=true),\n    ]\n\nevent1_msg = message.from_dict({\"event\": {\"code\": 1, ...}})\nevent2_msg = message.from_dict({\"event\": {\"code\": 2, ...}})\nassert isinstance(event1_msg.event, event1)\nassert isinstance(event2_msg.event, event2)\n\n# raises invalidfieldvalue:\nmessage.from_dict({\"event\": {\"code\": 3, ...}})\n```\n\nagain, it's not necessary to have a common superclass. if you have a union of\ndataclasses without a field that they can be distinguishable by, you can still\nuse `discriminator`, but deserialization will almost be the same as for `union`\ntype without `discriminator` except that it could be possible to deserialize\nsubclasses with `include_subtypes=true`.\n\n> [!important]\\\n> when both `include_subtypes` and `include_supertypes` are enabled,\n> all subclasses will be attempted to be deserialized first,\n> superclasses \u2014 at the end.\n\nin the following example you can see how priority works \u2014 first we try\nto deserialize `chickpeahummus`, and if it fails, then we try `hummus`:\n\n```python\n@dataclass\nclass hummus(dataclassdictmixin):\n    made_of: literal[\"chickpeas\", \"artichoke\"]\n    grams: int\n\n@dataclass\nclass chickpeahummus(hummus):\n    made_of: literal[\"chickpeas\"]\n\n@dataclass\nclass celery(dataclassdictmixin):\n    pieces: int\n\n@dataclass\nclass plate(dataclassdictmixin):\n    ingredients: list[\n        annotated[\n            union[hummus, celery],\n            discriminator(include_subtypes=true, include_supertypes=true),\n        ]\n    ]\n\nplate = plate.from_dict(\n    {\n        \"ingredients\": [\n            {\"made_of\": \"chickpeas\", \"grams\": 100},\n            {\"made_of\": \"artichoke\", \"grams\": 50},\n            {\"pieces\": 4},\n        ]\n    }\n)\nassert plate == plate(\n    ingredients=[\n        chickpeahummus(made_of='chickpeas', grams=100),  # <- subclass\n        hummus(made_of='artichoke', grams=50),  # <- superclass\n        celery(pieces=4),\n    ]\n)\n```\n\n#### using a custom variant tagger function\n\nsometimes it is impractical to have a class-level attribute with a tag value,\nespecially when you have a lot of classes. we can have a custom tagger\nfunction instead. this method is applicable for all scenarios of using\nthe discriminator, but for demonstration purposes, let's focus only on one\nof them.\n\nsuppose we want to use the middle part of `client*event` as a tag value:\n\n```python\nfrom dataclasses import dataclass\nfrom ipaddress import ipv4address\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig\nfrom mashumaro.types import discriminator\n\n\ndef client_event_tagger(cls):\n    # not the best way of doing it, it's just a demo\n    return cls.__name__[6:-5].lower()\n\n@dataclass\nclass clientevent(dataclassdictmixin):\n    class config(baseconfig):\n        discriminator = discriminator(\n            field=\"type\",\n            include_subtypes=true,\n            variant_tagger_fn=client_event_tagger,\n        )\n\n@dataclass\nclass clientconnectedevent(clientevent):\n    client_ip: ipv4address\n\n@dataclass\nclass clientdisconnectedevent(clientevent):\n    client_ip: ipv4address\n```\n\nwe can now deserialize subclasses as we did it earlier\n[without variant tagger](#class-level-discriminator):\n```python\ndisconnected_event = clientevent.from_dict(\n    {\"type\": \"disconnected\", \"client_ip\": \"10.0.0.42\"}\n)\nassert disconnected_event == clientdisconnectedevent(ipv4address(\"10.0.0.42\"))\n```\n\n### code generation options\n\n#### add `omit_none` keyword argument\n\nif you want to have control over whether to skip `none` values on serialization\nyou can add `omit_none` parameter to `to_*` methods using the\n`code_generation_options` list. the default value of `omit_none`\nparameter depends on whether the [`omit_none`](#omit_none-config-option)\nconfig option or [`omit_none`](#omit_none-dialect-option) dialect option is enabled.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig, to_dict_add_omit_none_flag\n\n@dataclass\nclass inner(dataclassdictmixin):\n    x: int = none\n    # \"x\" won't be omitted since there is no to_dict_add_omit_none_flag here\n\n@dataclass\nclass model(dataclassdictmixin):\n    x: inner\n    a: int = none\n    b: str = none  # will be omitted\n\n    class config(baseconfig):\n        code_generation_options = [to_dict_add_omit_none_flag]\n\nmodel(x=inner(), a=1).to_dict(omit_none=true)  # {'x': {'x': none}, 'a': 1}\n```\n\n#### add `by_alias` keyword argument\n\nif you want to have control over whether to serialize fields by their\n[aliases](#alias-option) you can add `by_alias` parameter to `to_*` methods\nusing the `code_generation_options` list. the default value of `by_alias`\nparameter depends on whether the [`serialize_by_alias`](#serialize_by_alias-config-option)\nconfig option is enabled.\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import dataclassdictmixin, field_options\nfrom mashumaro.config import baseconfig, to_dict_add_by_alias_flag\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    field_a: int = field(metadata=field_options(alias=\"fielda\"))\n\n    class config(baseconfig):\n        code_generation_options = [to_dict_add_by_alias_flag]\n\ndataclass(field_a=1).to_dict()  # {'field_a': 1}\ndataclass(field_a=1).to_dict(by_alias=true)  # {'fielda': 1}\n```\n\n#### add `dialect` keyword argument\n\nsupport for [dialects](#dialects) is disabled by default for performance reasons. you can enable\nit using a `add_dialect_support` constant:\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig, add_dialect_support\n\n@dataclass\nclass entity(dataclassdictmixin):\n    dt: date\n\n    class config(baseconfig):\n        code_generation_options = [add_dialect_support]\n```\n\n#### add `context` keyword argument\n\nsometimes it's needed to pass a \"context\" object to the serialization hooks\nthat will take it into account. for example, you could want to have an option\nto remove sensitive data from the serialization result if you need to.\nyou can add `context` parameter to `to_*` methods that will be passed to\n[`__pre_serialize__`](#before-serialization) and\n[`__post_serialize__`](#after-serialization) hooks. the type of this context\nas well as its mutability is up to you.\n\n```python\nfrom dataclasses import dataclass\nfrom typing import dict, optional\nfrom uuid import uuid\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.config import baseconfig, add_serialization_context\n\nclass basemodel(dataclassdictmixin):\n    class config(baseconfig):\n        code_generation_options = [add_serialization_context]\n\n@dataclass\nclass account(basemodel):\n    id: uuid\n    username: str\n    name: str\n\n    def __pre_serialize__(self, context: optional[dict] = none):\n        return self\n\n    def __post_serialize__(self, d: dict, context: optional[dict] = none):\n        if context and context.get(\"remove_sensitive_data\"):\n            d[\"username\"] = \"***\"\n            d[\"name\"] = \"***\"\n        return d\n\n@dataclass\nclass session(basemodel):\n    id: uuid\n    key: str\n    account: account\n\n    def __pre_serialize__(self, context: optional[dict] = none):\n        return self\n\n    def __post_serialize__(self, d: dict, context: optional[dict] = none):\n        if context and context.get(\"remove_sensitive_data\"):\n            d[\"key\"] = \"***\"\n        return d\n\n\nfoo = session(\n    id=uuid('03321c9f-6a97-421e-9869-918ff2867a71'),\n    key=\"vq6q9bx4c8s\",\n    account=account(\n        id=uuid('4ef2baa7-edef-4d6a-b496-71e6d72c58fb'),\n        username=\"john_doe\",\n        name=\"john\"\n    )\n)\nassert foo.to_dict() == {\n    'id': '03321c9f-6a97-421e-9869-918ff2867a71',\n    'key': 'vq6q9bx4c8s',\n    'account': {\n        'id': '4ef2baa7-edef-4d6a-b496-71e6d72c58fb',\n        'username': 'john_doe',\n        'name': 'john'\n    }\n}\nassert foo.to_dict(context={\"remove_sensitive_data\": true}) == {\n    'id': '03321c9f-6a97-421e-9869-918ff2867a71',\n    'key': '***',\n    'account': {\n        'id': '4ef2baa7-edef-4d6a-b496-71e6d72c58fb',\n        'username': '***',\n        'name': '***'\n    }\n}\n```\n\n### generic dataclasses\n\nalong with [user-defined generic types](#user-defined-generic-types)\nimplementing `serializabletype` interface, generic and variadic\ngeneric dataclasses can also be used. there are two applicable scenarios\nfor them.\n\n#### generic dataclass inheritance\n\nif you have a generic dataclass and want to serialize and deserialize its\ninstances depending on the concrete types, you can use inheritance for that:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom typing import generic, mapping, typevar, typevartuple\nfrom mashumaro import dataclassdictmixin\n\nkt = typevar(\"kt\")\nvt = typevar(\"vt\", date, str)\nts = typevartuple(\"ts\")\n\n@dataclass\nclass genericdataclass(generic[kt, vt, *ts]):\n    x: mapping[kt, vt]\n    y: tuple[*ts, kt]\n\n@dataclass\nclass concretedataclass(\n    genericdataclass[str, date, *tuple[float, ...]],\n    dataclassdictmixin,\n):\n    pass\n\nconcretedataclass.from_dict({\"x\": {\"a\": \"2021-01-01\"}, \"y\": [1, 2, \"a\"]})\n# concretedataclass(x={'a': datetime.date(2021, 1, 1)}, y=(1.0, 2.0, 'a'))\n```\n\nyou can override `typevar` field with a concrete type or another `typevar`.\npartial specification of concrete types is also allowed. if a generic dataclass\nis inherited without type overriding the types of its fields remain untouched.\n\n#### generic dataclass in a field type\n\nanother approach is to specify concrete types in the field type hints. this can\nhelp to have different versions of the same generic dataclass:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom typing import generic, typevar\nfrom mashumaro import dataclassdictmixin\n\nt = typevar('t')\n\n@dataclass\nclass genericdataclass(generic[t], dataclassdictmixin):\n    x: t\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    date: genericdataclass[date]\n    str: genericdataclass[str]\n\ninstance = dataclass(\n    date=genericdataclass(x=date(2021, 1, 1)),\n    str=genericdataclass(x='2021-01-01'),\n)\ndictionary = {'date': {'x': '2021-01-01'}, 'str': {'x': '2021-01-01'}}\nassert dataclass.from_dict(dictionary) == instance\n```\n\n### genericserializabletype interface\n\nthere is a generic alternative to [`serializabletype`](#serializabletype-interface)\ncalled `genericserializabletype`. it makes it possible to decide yourself how\nto serialize and deserialize input data depending on the types provided:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom typing import dict, typevar\nfrom mashumaro import dataclassdictmixin\nfrom mashumaro.types import genericserializabletype\n\nkt = typevar(\"kt\")\nvt = typevar(\"vt\")\n\nclass dictwrapper(dict[kt, vt], genericserializabletype):\n    __packers__ = {date: lambda x: x.isoformat(), str: str}\n    __unpackers__ = {date: date.fromisoformat, str: str}\n\n    def _serialize(self, types) -> dict[kt, vt]:\n        k_type, v_type = types\n        k_conv = self.__packers__[k_type]\n        v_conv = self.__packers__[v_type]\n        return {k_conv(k): v_conv(v) for k, v in self.items()}\n\n    @classmethod\n    def _deserialize(cls, value, types) -> \"dictwrapper[kt, vt]\":\n        k_type, v_type = types\n        k_conv = cls.__unpackers__[k_type]\n        v_conv = cls.__unpackers__[v_type]\n        return cls({k_conv(k): v_conv(v) for k, v in value.items()})\n\n@dataclass\nclass dataclass(dataclassdictmixin):\n    x: dictwrapper[date, str]\n    y: dictwrapper[str, date]\n\ninput_data = {\n    \"x\": {\"2022-12-07\": \"2022-12-07\"},\n    \"y\": {\"2022-12-07\": \"2022-12-07\"},\n}\nobj = dataclass.from_dict(input_data)\nassert obj == dataclass(\n    x=dictwrapper({date(2022, 12, 7): \"2022-12-07\"}),\n    y=dictwrapper({\"2022-12-07\": date(2022, 12, 7)}),\n)\nassert obj.to_dict() == input_data\n```\n\nas you can see, the code turns out to be massive compared to the\n[alternative](#user-defined-generic-types) but in rare cases such flexibility\ncan be useful. you should think twice about whether it's really worth using it.\n\n### serialization hooks\n\nin some cases you need to prepare input / output data or do some extraordinary\nactions at different stages of the deserialization / serialization lifecycle.\nyou can do this with different types of hooks.\n\n#### before deserialization\n\nfor doing something with a dictionary that will be passed to deserialization\nyou can use `__pre_deserialize__` class method:\n\n```python\n@dataclass\nclass a(dataclassjsonmixin):\n    abc: int\n\n    @classmethod\n    def __pre_deserialize__(cls, d: dict[any, any]) -> dict[any, any]:\n        return {k.lower(): v for k, v in d.items()}\n\nprint(dataclass.from_dict({\"abc\": 123}))    # dataclass(abc=123)\nprint(dataclass.from_json('{\"abc\": 123}'))  # dataclass(abc=123)\n```\n\n#### after deserialization\n\nfor doing something with a dataclass instance that was created as a result\nof deserialization you can use `__post_deserialize__` class method:\n\n```python\n@dataclass\nclass a(dataclassjsonmixin):\n    abc: int\n\n    @classmethod\n    def __post_deserialize__(cls, obj: 'a') -> 'a':\n        obj.abc = 456\n        return obj\n\nprint(dataclass.from_dict({\"abc\": 123}))    # dataclass(abc=456)\nprint(dataclass.from_json('{\"abc\": 123}'))  # dataclass(abc=456)\n```\n\n#### before serialization\n\nfor doing something before serialization you can use `__pre_serialize__`\nmethod:\n\n```python\n@dataclass\nclass a(dataclassjsonmixin):\n    abc: int\n    counter: classvar[int] = 0\n\n    def __pre_serialize__(self) -> 'a':\n        self.counter += 1\n        return self\n\nobj = dataclass(abc=123)\nobj.to_dict()\nobj.to_json()\nprint(obj.counter)  # 2\n```\n\nnote that you can add an additional `context` argument using the\n[corresponding](#add-context-keyword-argument) code generation option.\n\n#### after serialization\n\nfor doing something with a dictionary that was created as a result of\nserialization you can use `__post_serialize__` method:\n\n```python\n@dataclass\nclass a(dataclassjsonmixin):\n    user: str\n    password: str\n\n    def __post_serialize__(self, d: dict[any, any]) -> dict[any, any]:\n        d.pop('password')\n        return d\n\nobj = dataclass(user=\"name\", password=\"secret\")\nprint(obj.to_dict())  # {\"user\": \"name\"}\nprint(obj.to_json())  # '{\"user\": \"name\"}'\n```\n\nnote that you can add an additional `context` argument using the\n[corresponding](#add-context-keyword-argument) code generation option.\n\njson schema\n-------------------------------------------------------------------------------\n\nyou can build json schema not only for dataclasses but also for any other\n[supported](#supported-data-types) data\ntypes. there is support for the following standards:\n* [draft 2022-12](https://json-schema.org/specification.html)\n* [openapi specification 3.1.0](https://spec.openapis.org/oas/v3.1.0)\n\n### building json schema\n\nfor simple one-time cases it's recommended to start from using a configurable\n`build_json_schema` function. it returns `jsonschema` object that can be\nserialized to json or to dict:\n\n```python\nfrom dataclasses import dataclass, field\nfrom typing import list\nfrom uuid import uuid\n\nfrom mashumaro.jsonschema import build_json_schema\n\n\n@dataclass\nclass user:\n    id: uuid\n    name: str = field(metadata={\"description\": \"user name\"})\n\n\nprint(build_json_schema(list[user]).to_json())\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"type\": \"object\",\n        \"title\": \"user\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"format\": \"uuid\"\n            },\n            \"name\": {\n                \"type\": \"string\",\n                \"description\": \"user name\"\n            }\n        },\n        \"additionalproperties\": false,\n        \"required\": [\n            \"id\",\n            \"name\"\n        ]\n    }\n}\n```\n</details>\n\nadditional validation keywords ([see below](#json-schema-constraints))\ncan be added using annotations:\n\n```python\nfrom typing import annotated, list\nfrom mashumaro.jsonschema import build_json_schema\nfrom mashumaro.jsonschema.annotations import maximum, maxitems\n\nprint(\n    build_json_schema(\n        annotated[\n            list[annotated[int, maximum(42)]],\n            maxitems(4)\n        ]\n    ).to_json()\n)\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"type\": \"integer\",\n        \"maximum\": 42\n    },\n    \"maxitems\": 4\n}\n```\n</details>\n\nthe [`$schema`](https://json-schema.org/draft/2020-12/json-schema-core.html#name-the-schema-keyword)\nkeyword can be added by setting `with_dialect_uri` to true:\n\n```python\nprint(build_json_schema(str, with_dialect_uri=true).to_json())\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n    \"type\": \"string\"\n}\n```\n</details>\n\nby default, draft 2022-12 dialect is being used, but you can change it to\nanother one by setting `dialect` parameter:\n\n```python\nfrom mashumaro.jsonschema import open_api_3_1\n\nprint(\n    build_json_schema(\n        str, dialect=open_api_3_1, with_dialect_uri=true\n    ).to_json()\n)\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"$schema\": \"https://spec.openapis.org/oas/3.1/dialect/base\",\n    \"type\": \"string\"\n}\n```\n</details>\n\nall dataclass json schemas can or can not be placed in the\n[definitions](https://json-schema.org/draft/2020-12/json-schema-core.html#name-schema-re-use-with-defs)\nsection, depending on the `all_refs` parameter, which default value comes\nfrom a dialect used (`false` for draft 2022-12, `true` for openapi\nspecification 3.1.0):\n\n```python\nprint(build_json_schema(list[user], all_refs=true).to_json())\n```\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"$defs\": {\n        \"user\": {\n            \"type\": \"object\",\n            \"title\": \"user\",\n            \"properties\": {\n                \"id\": {\n                    \"type\": \"string\",\n                    \"format\": \"uuid\"\n                },\n                \"name\": {\n                    \"type\": \"string\"\n                }\n            },\n            \"additionalproperties\": false,\n            \"required\": [\n                \"id\",\n                \"name\"\n            ]\n        }\n    },\n    \"items\": {\n        \"$ref\": \"#/$defs/user\"\n    }\n}\n```\n</details>\n\nthe definitions section can be omitted from the final document by setting\n`with_definitions` parameter to `false`:\n\n```python\nprint(\n    build_json_schema(\n        list[user], dialect=open_api_3_1, with_definitions=false\n    ).to_json()\n)\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"$ref\": \"#/components/schemas/user\"\n    }\n}\n```\n</details>\n\nreference prefix can be changed by using `ref_prefix` parameter:\n\n```python\nprint(\n    build_json_schema(\n        list[user],\n        all_refs=true,\n        with_definitions=false,\n        ref_prefix=\"#/components/responses\",\n    ).to_json()\n)\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"$ref\": \"#/components/responses/user\"\n    }\n}\n```\n</details>\n\nthe omitted definitions could be found later in the `context` object that\nyou could have created and passed to the function, but it could be easier\nto use `jsonschemabuilder` for that. for example, you might found it handy\nto build openapi specification step by step passing your models to the builder\nand get all the registered definitions later. this builder has reasonable\ndefaults but can be customized if necessary.\n\n```python\nfrom mashumaro.jsonschema import jsonschemabuilder, open_api_3_1\n\nbuilder = jsonschemabuilder(open_api_3_1)\n\n@dataclass\nclass user:\n    id: uuid\n    name: str\n\n@dataclass\nclass device:\n    id: uuid\n    model: str\n\nprint(builder.build(list[user]).to_json())\nprint(builder.build(list[device]).to_json())\nprint(builder.get_definitions().to_json())\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"$ref\": \"#/components/schemas/user\"\n    }\n}\n```\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"$ref\": \"#/components/schemas/device\"\n    }\n}\n```\n```json\n{\n    \"user\": {\n        \"type\": \"object\",\n        \"title\": \"user\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"format\": \"uuid\"\n            },\n            \"name\": {\n                \"type\": \"string\"\n            }\n        },\n        \"additionalproperties\": false,\n        \"required\": [\n            \"id\",\n            \"name\"\n        ]\n    },\n    \"device\": {\n        \"type\": \"object\",\n        \"title\": \"device\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"format\": \"uuid\"\n            },\n            \"model\": {\n                \"type\": \"string\"\n            }\n        },\n        \"additionalproperties\": false,\n        \"required\": [\n            \"id\",\n            \"model\"\n        ]\n    }\n}\n```\n</details>\n\n### json schema constraints\n\napart from required keywords, that are added automatically for certain data\ntypes, you're free to use additional validation keywords.\nthey're presented by the corresponding classes in\n[`mashumaro.jsonschema.annotations`](https://github.com/fatal1ty/mashumaro/blob/master/mashumaro/jsonschema/annotations.py):\n\nnumber constraints:\n* [`minimum`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-minimum)\n* [`maximum`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maximum)\n* [`exclusiveminimum`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-exclusiveminimum)\n* [`exclusivemaximum`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-exclusivemaximum)\n* [`multipleof`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-multipleof)\n\nstring constraints:\n* [`minlength`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-minlength)\n* [`maxlength`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maxlength)\n* [`pattern`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-pattern)\n\narray constraints:\n* [`minitems`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-minitems)\n* [`maxitems`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maxitems)\n* [`uniqueitems`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-uniqueitems)\n* [`contains`](https://json-schema.org/draft/2020-12/json-schema-core.html#name-contains)\n* [`mincontains`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-mincontains)\n* [`maxcontains`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maxcontains)\n\nobject constraints:\n* [`maxproperties`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maxproperties)\n* [`minproperties`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-minproperties)\n* [`dependentrequired`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-dependentrequired)\n\n### extending json schema\n\nusing a `config` class it is possible to override some parts of the schema.\ncurrently, you can do the following:\n* override some field schemas using the \"properties\" key\n* change `additionalproperties` using the \"additionalproperties\" key\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro.jsonschema import build_json_schema\n\n@dataclass\nclass foobar:\n    foo: str\n    bar: int\n\n    class config:\n        json_schema = {\n            \"properties\": {\n                \"foo\": {\n                    \"type\": \"string\",\n                    \"description\": \"bar\"\n                }\n            },\n            \"additionalproperties\": true,\n        }\n\nprint(build_json_schema(foobar).to_json())\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"type\": \"object\",\n    \"title\": \"foobar\",\n    \"properties\": {\n        \"foo\": {\n            \"type\": \"string\",\n            \"description\": \"bar\"\n        },\n        \"bar\": {\n            \"type\": \"integer\"\n        }\n    },\n    \"additionalproperties\": true,\n    \"required\": [\n        \"foo\",\n        \"bar\"\n    ]\n}\n```\n</details>\n\nyou can also change the \"additionalproperties\" key to a specific schema\nby passing it a `jsonschema` instance instead of a bool value.\n\n### json schema and custom serialization methods\n\nmashumaro provides different ways to override default serialization methods for\ndataclass fields or specific data types. in order for these overrides to be\nreflected in the schema, you need to make sure that the methods have\nannotations of the return value type.\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro.config import baseconfig\nfrom mashumaro.jsonschema import build_json_schema\n\ndef str_as_list(s: str) -> list[str]:\n    return list(s)\n\ndef int_as_str(i: int) -> str:\n    return str(i)\n\n@dataclass\nclass foobar:\n    foo: str = field(metadata={\"serialize\": str_as_list})\n    bar: int\n\n    class config(baseconfig):\n        serialization_strategy = {\n            int: {\n                \"serialize\": int_as_str\n            }\n        }\n\nprint(build_json_schema(foobar).to_json())\n```\n\n<details>\n<summary>click to show the result</summary>\n\n```json\n{\n    \"type\": \"object\",\n    \"title\": \"foobar\",\n    \"properties\": {\n        \"foo\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"string\"\n            }\n        },\n        \"bar\": {\n            \"type\": \"string\"\n        }\n    },\n    \"additionalproperties\": false,\n    \"required\": [\n        \"foo\",\n        \"bar\"\n    ]\n}\n```\n</details>\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache license, version 2.0",
  "name": "mashumaro",
  "package_url": "https://pypi.org/project/mashumaro/",
  "project_url": "https://pypi.org/project/mashumaro/",
  "project_urls": {
    "Homepage": "https://github.com/Fatal1ty/mashumaro"
  },
  "release_url": "https://pypi.org/project/mashumaro/3.11/",
  "requires_dist": [
    "typing-extensions >=4.1.0",
    "msgpack >=0.5.6 ; extra == 'msgpack'",
    "orjson ; extra == 'orjson'",
    "tomli-w >=1.0 ; extra == 'toml'",
    "tomli >=1.1.0 ; (python_version < \"3.11\") and extra == 'toml'",
    "pyyaml >=3.13 ; extra == 'yaml'"
  ],
  "requires_python": ">=3.8",
  "summary": "fast and well tested serialization library",
  "version": "3.11",
  "releases": [],
  "developers": [
    "alexander_tikhonov",
    "random.gauss@gmail.com"
  ],
  "kwds": "badge logo mashumaro svg yamldecoder",
  "license_kwds": "apache license, version 2.0",
  "libtype": "pypi",
  "id": "pypi_mashumaro",
  "homepage": "https://github.com/fatal1ty/mashumaro",
  "release_count": 82,
  "dependency_ids": [
    "pypi_msgpack",
    "pypi_orjson",
    "pypi_pyyaml",
    "pypi_tomli",
    "pypi_tomli_w",
    "pypi_typing_extensions"
  ]
}