{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "====\neli5\n====\n\n.. image:: https://img.shields.io/pypi/v/eli5.svg\n   :target: https://pypi.python.org/pypi/eli5\n   :alt: pypi version\n\n.. image:: https://github.com/eli5-org/eli5/workflows/build/badge.svg?branch=master\n   :target: https://github.com/eli5-org/eli5/actions\n   :alt: build status\n\n.. image:: https://codecov.io/github/teamhg-memex/eli5/coverage.svg?branch=master\n   :target: https://codecov.io/github/teamhg-memex/eli5?branch=master\n   :alt: code coverage\n\n.. image:: https://readthedocs.org/projects/eli5/badge/?version=latest\n   :target: https://eli5.readthedocs.io/en/latest/?badge=latest\n   :alt: documentation\n\n\neli5 is a python package which helps to debug machine learning\nclassifiers and explain their predictions.\n\n.. image:: https://raw.githubusercontent.com/teamhg-memex/eli5/master/docs/source/static/word-highlight.png\n   :alt: explain_prediction for text data\n\n.. image:: https://raw.githubusercontent.com/teamhg-memex/eli5/master/docs/source/static/gradcam-catdog.png\n   :alt: explain_prediction for image data\n\nit provides support for the following machine learning frameworks and packages:\n\n* scikit-learn_. currently eli5 allows to explain weights and predictions\n  of scikit-learn linear classifiers and regressors, print decision trees\n  as text or as svg, show feature importances and explain predictions\n  of decision trees and tree-based ensembles. eli5 understands text\n  processing utilities from scikit-learn and can highlight text data\n  accordingly. pipeline and featureunion are supported.\n  it also allows to debug scikit-learn pipelines which contain\n  hashingvectorizer, by undoing hashing.\n\n* keras_ - explain predictions of image classifiers via grad-cam visualizations.\n\n* xgboost_ - show feature importances and explain predictions of xgbclassifier,\n  xgbregressor and xgboost.booster.\n\n* lightgbm_ - show feature importances and explain predictions of\n  lgbmclassifier, lgbmregressor and lightgbm.booster.\n\n* catboost_ - show feature importances of catboostclassifier,\n  catboostregressor and catboost.catboost.\n\n* lightning_ - explain weights and predictions of lightning classifiers and\n  regressors.\n\n* sklearn-crfsuite_. eli5 allows to check weights of sklearn_crfsuite.crf\n  models.\n\n\neli5 also implements several algorithms for inspecting black-box models\n(see `inspecting black-box estimators`_):\n\n* textexplainer_ allows to explain predictions\n  of any text classifier using lime_ algorithm (ribeiro et al., 2016).\n  there are utilities for using lime with non-text data and arbitrary black-box\n  classifiers as well, but this feature is currently experimental.\n* `permutation importance`_ method can be used to compute feature importances\n  for black box estimators.\n\nexplanation and formatting are separated; you can get text-based explanation\nto display in console, html version embeddable in an ipython notebook\nor web dashboards, a ``pandas.dataframe`` object if you want to process\nresults further, or json version which allows to implement custom rendering\nand formatting on a client.\n\n.. _lightning: https://github.com/scikit-learn-contrib/lightning\n.. _scikit-learn: https://github.com/scikit-learn/scikit-learn\n.. _sklearn-crfsuite: https://github.com/teamhg-memex/sklearn-crfsuite\n.. _lime: https://eli5.readthedocs.io/en/latest/blackbox/lime.html\n.. _textexplainer: https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html\n.. _xgboost: https://github.com/dmlc/xgboost\n.. _lightgbm: https://github.com/microsoft/lightgbm\n.. _catboost: https://github.com/catboost/catboost\n.. _keras: https://keras.io/\n.. _permutation importance: https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html\n.. _inspecting black-box estimators: https://eli5.readthedocs.io/en/latest/blackbox/index.html\n\nlicense is mit.\n\ncheck `docs <https://eli5.readthedocs.io/>`_ for more.\n\n.. note::\n    this is the same project as https://github.com/teamhg-memex/eli5/,\n    but due to temporary github access issues, 0.11 release is prepared in\n    https://github.com/eli5-org/eli5 (this repo).\n\n----\n\n.. image:: https://hyperiongray.s3.amazonaws.com/define-hg.svg\n\t:target: https://www.hyperiongray.com/?pk_campaign=github&pk_kwd=eli5\n\t:alt: define hyperiongray\n\n\nchangelog\n=========\n\n0.13.0 (2022-05-11)\n-------------------\n\n* drop python2.7 support\n* fix newer xgboost with unnamed features\n\n0.12.0 (2022-05-11)\n-------------------\n\n* use jinja2 >= 3.0.0, please use eli5 0.11 if you'd prefer to use\n  an older version of jinja2\n* support lightgbm.booster\n\n0.11.0 (2021-01-23)\n-------------------\n\n* fixed scikit-learn 0.22+ and 0.24+ support.\n* allow nan inputs in permutation importance (if model supports them).\n* fix for permutation importance with sample_weight and cross-validation.\n* doc fixes (typos, keras and tf versions clarified).\n* don't use deprecated getargspec function.\n* less type ignores, mypy updated to 0.750.\n* python 3.8 and 3.9 tested on gi, python 3.4 not tested any more.\n* tests moved to github actions.\n\n0.10.1 (2019-08-29)\n-------------------\n\n* don't include typing dependency on python 3.5+\n  to fix installation on python 3.7\n\n0.10.0 (2019-08-21)\n-------------------\n\n* keras image classifiers: explaining predictions with grad-cam\n  (gsoc-2019 project by @teabolt).\n\n0.9.0 (2019-07-05)\n------------------\n\n* catboost support: show feature importances of catboostclassifier,\n  catboostregressor and catboost.catboost.\n* test fixes: fixes for scikit-learn 0.21+, use xenial base on travis\n* catch exceptions from improperly installed lightgbm\n\n0.8.2 (2019-04-04)\n------------------\n\n* fixed scikit-learn 0.21+ support (randomized linear models are removed\n  from scikit-learn);\n* fixed pandas.dataframe + xgboost support for permutationimportance;\n* fixed tests with recent numpy;\n* added conda install instructions (conda package is maintained by community);\n* tutorial is updated to use xgboost 0.81;\n* update docs to use pandoc 2.x.\n\n0.8.1 (2018-11-19)\n------------------\n\n* fixed python 3.7 support;\n* added support for xgboost > 0.6a2;\n* fixed deprecation warnings in numpy >= 1.14;\n* documentation, type annotation and test improvements.\n\n0.8 (2017-08-25)\n----------------\n\n* **backwards incompatible**: dataframe objects with explanations no longer\n  use indexes and pivot tables, they are now just plain dataframes;\n* new method for inspection black-box models is added\n  (`eli5-permutation-importance`);\n* transfor_feature_names is implemented for sklearn's minmaxscaler,\n  standardscaler, maxabsscaler and robustscaler;\n* zero and negative feature importances are no longer hidden;\n* fixed compatibility with scikit-learn 0.19;\n* fixed compatibility with lightgbm master (2.0.5 and 2.0.6 are still\n  unsupported - there are bugs in lightgbm);\n* documentation, testing and type annotation improvements.\n\n0.7 (2017-07-03)\n----------------\n\n* better pandas.dataframe integration: `eli5.explain_weights_df`,\n  `eli5.explain_weights_dfs`, `eli5.explain_prediction_df`,\n  `eli5.explain_prediction_dfs`,\n  `eli5.format_as_dataframe <eli5.formatters.as_dataframe.format_as_dataframe>`\n  and `eli5.format_as_dataframes <eli5.formatters.as_dataframe.format_as_dataframes>`\n  functions allow to export explanations to pandas.dataframes;\n* `eli5.explain_prediction` now shows predicted class for binary\n  classifiers (previously it was always showing positive class);\n* `eli5.explain_prediction` supports ``targets=[<class>]`` now\n  for binary classifiers; e.g. to show result as seen for negative class,\n  you can use ``eli5.explain_prediction(..., targets=[false])``;\n* support `eli5.explain_prediction` and `eli5.explain_weights`\n  for libsvm-based linear estimators from sklearn.svm: ``svc(kernel='linear')``\n  (only binary classification), ``nusvc(kernel='linear')`` (only\n  binary classification), ``svr(kernel='linear')``, ``nusvr(kernel='linear')``,\n  ``oneclasssvm(kernel='linear')``;\n* fixed `eli5.explain_weights` for lightgbm_ estimators in python 2 when\n  ``importance_type`` is 'split' or 'weight';\n* testing improvements.\n\n0.6.4 (2017-06-22)\n------------------\n\n* fixed `eli5.explain_prediction` for recent lightgbm_ versions;\n* fixed python 3 deprecation warning in formatters.html;\n* testing improvements.\n\n0.6.3 (2017-06-02)\n------------------\n\n* `eli5.explain_weights` and `eli5.explain_prediction`\n  works with xgboost.booster, not only with sklearn-like apis;\n* `eli5.formatters.as_dict.format_as_dict` is now available as\n  ``eli5.format_as_dict``;\n* testing and documentation fixes.\n\n0.6.2 (2017-05-17)\n------------------\n\n* readable `eli5.explain_weights` for xgboost models trained on\n  pandas.dataframe;\n* readable `eli5.explain_weights` for lightgbm models trained on\n  pandas.dataframe;\n* fixed an issue with `eli5.explain_prediction` for xgboost\n  models trained on pandas.dataframe when feature names contain dots;\n* testing improvements.\n\n0.6.1 (2017-05-10)\n------------------\n\n* better pandas support in `eli5.explain_prediction` for\n  xgboost, sklearn, lightgbm and lightning.\n\n0.6 (2017-05-03)\n----------------\n\n* better scikit-learn pipeline support in `eli5.explain_weights`:\n  it is now possible to pass a pipeline object directly. curently only\n  selectormixin-based transformers, featureunion and transformers\n  with ``get_feature_names`` are supported, but users can register other\n  transformers; built-in list of supported transformers will be expanded\n  in future. see `sklearn-pipelines` for more.\n* inverting of hashingvectorizer is now supported inside featureunion\n  via `eli5.sklearn.unhashing.invert_hashing_and_fit`.\n  see `sklearn-unhashing`.\n* fixed compatibility with jupyter notebook >= 5.0.0.\n* fixed `eli5.explain_weights` for lasso regression with a single\n  feature and no intercept.\n* fixed unhashing support in python 2.x.\n* documentation and testing improvements.\n\n\n0.5 (2017-04-27)\n----------------\n\n* lightgbm_ support: `eli5.explain_prediction` and\n  `eli5.explain_weights` are now supported for\n  ``lgbmclassifier`` and ``lgbmregressor``\n  (see `eli5 lightgbm support <library-lightgbm>`).\n* fixed text formatting if all weights are zero;\n* type checks now use latest mypy;\n* testing setup improvements: travis ci now uses ubuntu 14.04.\n\n.. _lightgbm: https://github.com/microsoft/lightgbm\n\n0.4.2 (2017-03-03)\n------------------\n\n* bug fix: eli5 should remain importable if xgboost is available, but\n  not installed correctly.\n\n0.4.1 (2017-01-25)\n------------------\n\n* feature contribution calculation fixed\n  for `eli5.xgboost.explain_prediction_xgboost`\n\n\n0.4 (2017-01-20)\n----------------\n\n* `eli5.explain_prediction`: new 'top_targets' argument allows\n  to display only predictions with highest or lowest scores;\n* `eli5.explain_weights` allows to customize the way feature importances\n  are computed for xgbclassifier and xgbregressor using ``importance_type``\n  argument (see docs for the `eli5 xgboost support <library-xgboost>`);\n* `eli5.explain_weights` uses gain for xgbclassifier and xgbregressor\n  feature importances by default; this method is a better indication of\n  what's going, and it makes results more compatible with feature importances\n  displayed for scikit-learn gradient boosting methods.\n\n0.3.1 (2017-01-16)\n------------------\n\n* packaging fix: scikit-learn is added to install_requires in setup.py.\n\n0.3 (2017-01-13)\n----------------\n\n* `eli5.explain_prediction` works for xgbclassifier, xgbregressor\n  from xgboost and for extratreesclassifier, extratreesregressor,\n  gradientboostingclassifier, gradientboostingregressor,\n  randomforestclassifier, randomforestregressor, decisiontreeclassifier\n  and decisiontreeregressor from scikit-learn.\n  explanation method is based on\n  http://blog.datadive.net/interpreting-random-forests/ .\n* `eli5.explain_weights` now supports tree-based regressors from\n  scikit-learn: decisiontreeregressor, adaboostregressor,\n  gradientboostingregressor, randomforestregressor and extratreesregressor.\n* `eli5.explain_weights` works for xgbregressor;\n* new `textexplainer <lime-tutorial>` class allows to explain predictions\n  of black-box text classification pipelines using lime algorithm;\n  many improvements in `eli5.lime <eli5-lime>`.\n* better ``sklearn.pipeline.featureunion`` support in\n  `eli5.explain_prediction`;\n* rendering performance is improved;\n* a number of remaining feature importances is shown when the feature\n  importance table is truncated;\n* styling of feature importances tables is fixed;\n* `eli5.explain_weights` and `eli5.explain_prediction` support\n  more linear estimators from scikit-learn: huberregressor, larscv, lassocv,\n  lassolars, lassolarscv, lassolarsic, orthogonalmatchingpursuit,\n  orthogonalmatchingpursuitcv, passiveaggressiveregressor,\n  ridgeclassifier, ridgeclassifiercv, theilsenregressor.\n* text-based formatting of decision trees is changed: for binary\n  classification trees only a probability of \"true\" class is printed,\n  not both probabilities as it was before.\n* `eli5.explain_weights` supports ``feature_filter`` in addition\n  to ``feature_re`` for filtering features, and `eli5.explain_prediction`\n  now also supports both of these arguments;\n* 'weight' column is renamed to 'contribution' in the output of\n  `eli5.explain_prediction`;\n* new ``show_feature_values=true`` formatter argument allows to display\n  input feature values;\n* fixed an issue with analyzer='char_wb' highlighting at the start of the\n  text.\n\n0.2 (2016-12-03)\n----------------\n\n* xgbclassifier support (from `xgboost <https://github.com/dmlc/xgboost>`__\n  package);\n* `eli5.explain_weights` support for sklearn onevsrestclassifier;\n* std deviation of feature importances is no longer printed as zero\n  if it is not available.\n\n0.1.1 (2016-11-25)\n------------------\n\n* packaging fixes: require attrs > 16.0.0, fixed readme rendering\n\n0.1 (2016-11-24)\n----------------\n\n* html output;\n* ipython integration;\n* json output;\n* visualization of scikit-learn text vectorizers;\n* `sklearn-crfsuite <https://github.com/teamhg-memex/sklearn-crfsuite>`__\n  support;\n* `lightning <https://github.com/scikit-learn-contrib/lightning>`__ support;\n* `eli5.show_weights` and `eli5.show_prediction` functions;\n* `eli5.explain_weights` and `eli5.explain_prediction`\n  functions;\n* `eli5.lime <eli5-lime>` improvements: samplers for non-text data,\n  bug fixes, docs;\n* hashingvectorizer is supported for regression tasks;\n* performance improvements - feature names are lazy;\n* sklearn elasticnetcv and ridgecv support;\n* it is now possible to customize formatting output - show/hide sections,\n  change layout;\n* sklearn onevsrestclassifier support;\n* sklearn decisiontreeclassifier visualization (text-based or svg-based);\n* dropped support for scikit-learn < 0.18;\n* basic mypy type annotations;\n* ``feature_re`` argument allows to show only a subset of features;\n* ``target_names`` argument allows to change display names of targets/classes;\n* ``targets`` argument allows to show a subset of targets/classes and\n  change their display order;\n* documentation, more examples.\n\n\n0.0.6 (2016-10-12)\n------------------\n\n* candidate features in eli5.sklearn.invertablehashingvectorizer\n  are ordered by their frequency, first candidate is always positive.\n\n0.0.5 (2016-09-27)\n------------------\n\n* hashingvectorizer support in explain_prediction;\n* add an option to pass coefficient scaling array; it is useful\n  if you want to compare coefficients for features which scale or sign\n  is different in the input;\n* bug fix: classifier weights are no longer changed by eli5 functions.\n\n0.0.4 (2016-09-24)\n------------------\n\n* eli5.sklearn.invertablehashingvectorizer and\n  eli5.sklearn.featureunhasher allow to recover feature names for\n  pipelines which use hashingvectorizer or featurehasher;\n* added support for scikit-learn linear regression models (elasticnet,\n  lars, lasso, linearregression, linearsvr, ridge, sgdregressor);\n* doc and vec arguments are swapped in explain_prediction function;\n  vec can now be omitted if an example is already vectorized;\n* fixed issue with dense feature vectors;\n* all class_names arguments are renamed to target_names;\n* feature name guessing is fixed for scikit-learn ensemble estimators;\n* testing improvements.\n\n0.0.3 (2016-09-21)\n------------------\n\n* support any black-box classifier using lime (http://arxiv.org/abs/1602.04938)\n  algorithm; text data support is built-in;\n* \"vectorized\" argument for sklearn.explain_prediction; it allows to pass\n  example which is already vectorized;\n* allow to pass feature_names explicitly;\n* support classifiers without get_feature_names method using auto-generated\n  feature names.\n\n0.0.2 (2016-09-19)\n------------------\n\n* 'top' argument of ``explain_prediction``\n  can be a tuple (num_positive, num_negative);\n* classifier name is no longer printed by default;\n* added eli5.sklearn.explain_prediction to explain individual examples;\n* fixed numpy warning.\n\n0.0.1 (2016-09-15)\n------------------\n\npre-release.\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit license",
  "name": "eli5",
  "package_url": "https://pypi.org/project/eli5/",
  "project_url": "https://pypi.org/project/eli5/",
  "project_urls": {
    "Homepage": "https://github.com/eli5-org/eli5"
  },
  "release_url": "https://pypi.org/project/eli5/0.13.0/",
  "requires_dist": [],
  "requires_python": null,
  "summary": "debug machine learning classifiers and explain their predictions",
  "version": "0.13.0",
  "releases": [],
  "developers": [
    "kmike84@gmail.com",
    "kostia.lopuhin@gmail.com",
    "mikhail_korobov"
  ],
  "kwds": "badge alt extratreesclassifier updated decisiontreeclassifier",
  "license_kwds": "mit license",
  "libtype": "pypi",
  "id": "pypi_eli5",
  "homepage": "https://github.com/eli5-org/eli5",
  "release_count": 30,
  "dependency_ids": []
}