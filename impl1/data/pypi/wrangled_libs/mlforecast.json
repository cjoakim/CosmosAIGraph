{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "license :: osi approved :: apache software license",
    "natural language :: english",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# mlforecast \u00a0\n[![tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=statistical%20forecasting%20algorithms%20by%20nixtla%20&url=https://github.com/nixtla/statsforecast&via=nixtlainc&hashtags=statisticalmodels,timeseries,forecasting)\n\u00a0[![slack](https://img.shields.io/badge/slack-4a154b?&logo=slack&logocolor=white.png)](https://join.slack.com/t/nixtlacommunity/shared_invite/zt-1pmhan9j5-f54xr20edhk0utyapcw4kq)\n\n<!-- warning: this file was autogenerated! do not edit! -->\n\n<div align=\"center\">\n\n<center>\n<img src=\"https://raw.githubusercontent.com/nixtla/mlforecast/main/nbs/figs/logo.png\" />\n</center>\n<h1 align=\"center\">\nmachine learning \ud83e\udd16 forecast\n</h1>\n<h3 align=\"center\">\nscalable machine learning for time series forecasting\n</h3>\n\n[![ci](https://github.com/nixtla/mlforecast/actions/workflows/ci.yaml/badge.svg)](https://github.com/nixtla/mlforecast/actions/workflows/ci.yaml)\n[![python](https://img.shields.io/pypi/pyversions/mlforecast.png)](https://pypi.org/project/mlforecast/)\n[![pypi](https://img.shields.io/pypi/v/mlforecast?color=blue.png)](https://pypi.org/project/mlforecast/)\n[![conda-forge](https://img.shields.io/conda/vn/conda-forge/mlforecast?color=blue.png)](https://anaconda.org/conda-forge/mlforecast)\n[![license](https://img.shields.io/github/license/nixtla/mlforecast.png)](https://github.com/nixtla/mlforecast/blob/main/license)\n\n**mlforecast** is a framework to perform time series forecasting using\nmachine learning models, with the option to scale to massive amounts of\ndata using remote clusters.\n\n</div>\n\n## install\n\n### pypi\n\n`pip install mlforecast`\n\n### conda-forge\n\n`conda install -c conda-forge mlforecast`\n\nfor more detailed instructions you can refer to the [installation\npage](https://nixtla.github.io/mlforecast/docs/getting-started/install.html).\n\n## quick start\n\n**minimal example**\n\n``` python\nimport lightgbm as lgb\n\nfrom mlforecast import mlforecast\nfrom sklearn.linear_model import linearregression\n\nmlf = mlforecast(\n    models = [linearregression(), lgb.lgbmregressor()],\n    lags=[1, 12],\n    freq = 'm'\n)\nmlf.fit(df)\nmlf.predict(12)\n```\n\n**get started with this [quick\nguide](https://nixtla.github.io/mlforecast/docs/getting-started/quick_start_local.html).**\n\n**follow this [end-to-end\nwalkthrough](https://nixtla.github.io/mlforecast/docs/getting-started/end_to_end_walkthrough.html)\nfor best practices.**\n\n### sample notebooks\n\n- [m5](https://www.kaggle.com/code/lemuz90/m5-mlforecast-eval)\n- [m5-polars](https://www.kaggle.com/code/lemuz90/m5-mlforecast-eval-polars)\n- [m4](https://www.kaggle.com/code/lemuz90/m4-competition)\n- [m4-cv](https://www.kaggle.com/code/lemuz90/m4-competition-cv)\n\n## why?\n\ncurrent python alternatives for machine learning models are slow,\ninaccurate and don\u2019t scale well. so we created a library that can be\nused to forecast in production environments. `mlforecast` includes\nefficient feature engineering to train any machine learning model (with\n`fit` and `predict` methods such as\n[`sklearn`](https://scikit-learn.org/stable/)) to fit millions of time\nseries.\n\n## features\n\n- fastest implementations of feature engineering for time series\n  forecasting in python.\n- out-of-the-box compatibility with spark, dask, and ray.\n- probabilistic forecasting with conformal prediction.\n- support for exogenous variables and static covariates.\n- familiar `sklearn` syntax: `.fit` and `.predict`.\n\nmissing something? please open an issue or write us in\n[![slack](https://img.shields.io/badge/slack-4a154b?&logo=slack&logocolor=white.png)](https://join.slack.com/t/nixtlaworkspace/shared_invite/zt-135dssye9-fwtzmpv2wbthq8nk0yvu6a)\n\n## examples and guides\n\n\ud83d\udcda [end to end\nwalkthrough](https://nixtla.github.io/mlforecast/docs/getting-started/end_to_end_walkthrough.html):\nmodel training, evaluation and selection for multiple time series.\n\n\ud83d\udd0e [probabilistic\nforecasting](https://nixtla.github.io/mlforecast/docs/how-to-guides/prediction_intervals.html):\nuse conformal prediction to produce prediciton intervals.\n\n\ud83d\udc69\u200d\ud83d\udd2c [cross\nvalidation](https://nixtla.github.io/mlforecast/docs/how-to-guides/cross_validation.html):\nrobust model\u2019s performance evaluation.\n\n\ud83d\udd0c [predict demand\npeaks](https://nixtla.github.io/mlforecast/docs/tutorials/electricity_peak_forecasting.html):\nelectricity load forecasting for detecting daily peaks and reducing\nelectric bills.\n\n\ud83d\udcc8 [transfer\nlearning](https://nixtla.github.io/mlforecast/docs/how-to-guides/transfer_learning.html):\npretrain a model using a set of time series and then predict another one\nusing that pretrained model.\n\n\ud83c\udf21\ufe0f [distributed\ntraining](https://nixtla.github.io/mlforecast/docs/getting-started/quick_start_distributed.html):\nuse a dask, ray or spark cluster to train models at scale.\n\n## how to use\n\nthe following provides a very basic overview, for a more detailed\ndescription see the\n[documentation](https://nixtla.github.io/mlforecast/).\n\n### data setup\n\nstore your time series in a pandas dataframe in long format, that is,\neach row represents an observation for a specific serie and timestamp.\n\n``` python\nfrom mlforecast.utils import generate_daily_series\n\nseries = generate_daily_series(\n    n_series=20,\n    max_length=100,\n    n_static_features=1,\n    static_as_categorical=false,\n    with_trend=true\n)\nseries.head()\n```\n\n<div>\n\n|     | unique_id | ds         | y          | static_0 |\n|-----|-----------|------------|------------|----------|\n| 0   | id_00     | 2000-01-01 | 17.519167  | 72       |\n| 1   | id_00     | 2000-01-02 | 87.799695  | 72       |\n| 2   | id_00     | 2000-01-03 | 177.442975 | 72       |\n| 3   | id_00     | 2000-01-04 | 232.704110 | 72       |\n| 4   | id_00     | 2000-01-05 | 317.510474 | 72       |\n\n</div>\n\n### models\n\nnext define your models. if you want to use the local interface this can\nbe any regressor that follows the scikit-learn api. for distributed\ntraining there are `lgbmforecast` and `xgbforecast`.\n\n``` python\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.ensemble import randomforestregressor\n\nmodels = [\n    lgb.lgbmregressor(verbosity=-1),\n    xgb.xgbregressor(),\n    randomforestregressor(random_state=0),\n]\n```\n\n### forecast object\n\nnow instantiate a `mlforecast` object with the models and the features\nthat you want to use. the features can be lags, transformations on the\nlags and date features. the lag transformations are defined as\n[numba](http://numba.pydata.org/) *jitted* functions that transform an\narray, if they have additional arguments you can either supply a tuple\n(`transform_func`, `arg1`, `arg2`, \u2026) or define new functions fixing the\narguments. you can also define differences to apply to the series before\nfitting that will be restored when predicting.\n\n``` python\nfrom mlforecast import mlforecast\nfrom mlforecast.target_transforms import differences\nfrom numba import njit\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\n\n\n@njit\ndef rolling_mean_28(x):\n    return rolling_mean(x, window_size=28)\n\n\nfcst = mlforecast(\n    models=models,\n    freq='d',\n    lags=[7, 14],\n    lag_transforms={\n        1: [expanding_mean],\n        7: [rolling_mean_28]\n    },\n    date_features=['dayofweek'],\n    target_transforms=[differences([1])],\n)\n```\n\n### training\n\nto compute the features and train the models call `fit` on your\n`forecast` object.\n\n``` python\nfcst.fit(series)\n```\n\n    mlforecast(models=[lgbmregressor, xgbregressor, randomforestregressor], freq=<day>, lag_features=['lag7', 'lag14', 'expanding_mean_lag1', 'rolling_mean_28_lag7'], date_features=['dayofweek'], num_threads=1)\n\n### predicting\n\nto get the forecasts for the next `n` days call `predict(n)` on the\nforecast object. this will automatically handle the updates required by\nthe features using a recursive strategy.\n\n``` python\npredictions = fcst.predict(14)\npredictions\n```\n\n<div>\n\n|     | unique_id | ds         | lgbmregressor | xgbregressor | randomforestregressor |\n|-----|-----------|------------|---------------|--------------|-----------------------|\n| 0   | id_00     | 2000-04-04 | 299.923771    | 309.664124   | 298.424164            |\n| 1   | id_00     | 2000-04-05 | 365.424147    | 382.150085   | 365.816014            |\n| 2   | id_00     | 2000-04-06 | 432.562441    | 453.373779   | 436.360620            |\n| 3   | id_00     | 2000-04-07 | 495.628000    | 527.965149   | 503.670100            |\n| 4   | id_00     | 2000-04-08 | 60.786223     | 75.762299    | 62.176080             |\n| ... | ...       | ...        | ...           | ...          | ...                   |\n| 275 | id_19     | 2000-03-23 | 36.266780     | 29.889120    | 34.799780             |\n| 276 | id_19     | 2000-03-24 | 44.370984     | 34.968884    | 39.920982             |\n| 277 | id_19     | 2000-03-25 | 50.746222     | 39.970238    | 46.196266             |\n| 278 | id_19     | 2000-03-26 | 58.906524     | 45.125305    | 51.653060             |\n| 279 | id_19     | 2000-03-27 | 63.073949     | 50.682716    | 56.845384             |\n\n<p>280 rows \u00d7 5 columns</p>\n</div>\n\n### visualize results\n\n``` python\nfrom utilsforecast.plotting import plot_series\n```\n\n``` python\nfig = plot_series(series, predictions, max_ids=4, plot_random=false)\nfig.savefig('figs/index.png', bbox_inches='tight')\n```\n\n![](https://raw.githubusercontent.com/nixtla/mlforecast/main/nbs/figs/index.png)\n\n## how to contribute\n\nsee\n[contributing.md](https://github.com/nixtla/mlforecast/blob/main/contributing.md).\n",
  "docs_url": null,
  "keywords": "python forecast forecasting machine-learning dask",
  "license": "apache software license 2.0",
  "name": "mlforecast",
  "package_url": "https://pypi.org/project/mlforecast/",
  "project_url": "https://pypi.org/project/mlforecast/",
  "project_urls": {
    "Homepage": "https://github.com/Nixtla/mlforecast"
  },
  "release_url": "https://pypi.org/project/mlforecast/0.11.3/",
  "requires_dist": [
    "numba",
    "packaging",
    "pandas",
    "scikit-learn",
    "utilsforecast >=0.0.22",
    "window-ops",
    "fugue ; extra == 'dask'",
    "dask[complete] ; extra == 'dask'",
    "lightgbm ; extra == 'dask'",
    "xgboost ; extra == 'dask'",
    "fugue ; extra == 'dev'",
    "nbdev ; extra == 'dev'",
    "datasetsforecast ; extra == 'dev'",
    "lightgbm ; extra == 'dev'",
    "xgboost ; extra == 'dev'",
    "mypy ; extra == 'dev'",
    "pyspark ; extra == 'dev'",
    "ruff ; extra == 'dev'",
    "pyarrow ; extra == 'dev'",
    "black ; extra == 'dev'",
    "matplotlib ; extra == 'dev'",
    "coreforecast >=0.0.3 ; extra == 'dev'",
    "polars ; extra == 'dev'",
    "fugue[ray] ; extra == 'dev'",
    "lightgbm-ray ; extra == 'dev'",
    "dask[complete] ; extra == 'dev'",
    "xgboost-ray ; extra == 'dev'",
    "coreforecast >=0.0.3 ; extra == 'lag_transforms'",
    "fugue[ray] ; extra == 'ray'",
    "lightgbm-ray ; extra == 'ray'",
    "xgboost-ray ; extra == 'ray'",
    "fugue ; extra == 'spark'",
    "pyspark ; extra == 'spark'",
    "lightgbm ; extra == 'spark'",
    "xgboost ; extra == 'spark'"
  ],
  "requires_python": ">=3.8",
  "summary": "scalable machine learning based time series forecasting",
  "version": "0.11.3",
  "releases": [],
  "developers": [
    "jmoralz92@gmail.com"
  ],
  "kwds": "electricity_peak_forecasting forecast forecasts forecasting predict",
  "license_kwds": "apache software license 2.0",
  "libtype": "pypi",
  "id": "pypi_mlforecast",
  "homepage": "https://github.com/nixtla/mlforecast",
  "release_count": 33,
  "dependency_ids": [
    "pypi_black",
    "pypi_coreforecast",
    "pypi_dask",
    "pypi_datasetsforecast",
    "pypi_fugue",
    "pypi_lightgbm",
    "pypi_lightgbm_ray",
    "pypi_matplotlib",
    "pypi_mypy",
    "pypi_nbdev",
    "pypi_numba",
    "pypi_packaging",
    "pypi_pandas",
    "pypi_polars",
    "pypi_pyarrow",
    "pypi_pyspark",
    "pypi_ruff",
    "pypi_scikit_learn",
    "pypi_utilsforecast",
    "pypi_window_ops",
    "pypi_xgboost",
    "pypi_xgboost_ray"
  ]
}