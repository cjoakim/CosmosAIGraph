{
  "classifiers": [
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "<br />\n<p align=\"center\">\n    <a href=\"https://github.com/mosaicml/streaming#gh-light-mode-only\" class=\"only-light\">\n      <img src=\"https://storage.googleapis.com/docs.mosaicml.com/images/streaming-logo-light-mode.png\" width=\"50%\"/>\n    </a>\n    <!--pypi website does not support dark mode and does not understand github tag. hence, it renders both the images.\n    the below tag is being used to remove the dark mode image on pypi website.-->\n    \n</p>\n\n<h2><p align=\"center\">fast, accurate streaming of training data from cloud storage</p></h2>\n\n<h4><p align='center'>\n<a href=\"https://www.mosaicml.com\">[website]</a>\n- <a href=\"https://streaming.docs.mosaicml.com/en/latest/getting_started/user_guide.html\">[getting started]</a>\n- <a href=\"https://streaming.docs.mosaicml.com/\">[docs]\n- <a href=\"https://www.mosaicml.com/team\">[we're hiring!]</a>\n</p></h4>\n\n<p align=\"center\">\n    <a href=\"https://pypi.org/project/mosaicml-streaming/\">\n        <img alt=\"pypi version\" src=\"https://img.shields.io/pypi/pyversions/mosaicml-streaming\">\n    </a>\n    <a href=\"https://pypi.org/project/mosaicml-streaming/\">\n        <img alt=\"pypi package version\" src=\"https://img.shields.io/pypi/v/mosaicml-streaming\">\n    </a>\n    <a href=\"https://github.com/mosaicml/streaming/actions?query=workflow%3atest\">\n        <img alt=\"unit test\" src=\"https://github.com/mosaicml/streaming/actions/workflows/pytest.yaml/badge.svg\">\n    </a>\n    <a href=\"https://pepy.tech/project/mosaicml-streaming/\">\n        <img alt=\"pypi downloads\" src=\"https://static.pepy.tech/personalized-badge/mosaicml-streaming?period=month&units=international_system&left_color=grey&right_color=blue&left_text=downloads/month\">\n    </a>\n    <a href=\"https://streaming.docs.mosaicml.com\">\n        <img alt=\"documentation\" src=\"https://readthedocs.org/projects/streaming/badge/?version=stable\">\n    </a>\n    <a href=\"https://mosaicml.me/slack\">\n        <img alt=\"chat @ slack\" src=\"https://img.shields.io/badge/slack-chat-2eb67d.svg?logo=slack\">\n    </a>\n    <a href=\"https://github.com/mosaicml/streaming/blob/main/license\">\n        <img alt=\"license\" src=\"https://img.shields.io/badge/license-apache%202.0-green.svg?logo=slack\">\n    </a>\n</p>\n<br />\n\n# \ud83d\udc4b welcome\n\nwe built streamingdataset to make training on large datasets from cloud storage as fast, cheap, and scalable as possible.\n\nit\u2019s specially designed for multi-node, distributed training for large models\u2014maximizing correctness guarantees, performance, and ease of use. now, you can efficiently train anywhere, independent of your training data location. just stream in the data you need, when you need it. to learn more about why we built streamingdataset, read our [announcement blog](https://www.mosaicml.com/blog/mosaicml-streamingdataset).\n\nstreamingdataset is compatible with any data type, including **images, text, video, and multimodal data**.\n\nwith support for major cloud storage providers ([aws](https://aws.amazon.com/s3/), [oci](https://www.oracle.com/cloud/storage/object-storage/), [gcs](https://cloud.google.com/storage), [azure](https://azure.microsoft.com/en-us/products/storage/blobs), [databricks](https://docs.databricks.com/en/storage/index.html), and any s3 compatible object store such as [cloudflare r2](https://www.cloudflare.com/products/r2/), [coreweave](https://docs.coreweave.com/storage/object-storage), [backblaze b2](https://www.backblaze.com/b2/cloud-storage.html), etc. ) and designed as a drop-in replacement for your pytorch\u00a0[iterabledataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.iterabledataset)\u00a0class, streamingdataset seamlessly integrates into your existing training workflows.\n\n![the flow of samples from shards in the cloud to devices in your cluster](docs/source/_static/images/flow.gif)\n\n# \ud83d\ude80 getting started\n\n## \ud83d\udcbe installation\n\nstreaming can be installed with `pip`:\n\n<!--pytest.mark.skip-->\n```bash\npip install mosaicml-streaming\n```\n\n## \ud83c\udfc1\u00a0quick start\n\n### 1. prepare your data\n\nconvert your raw dataset into one of our supported streaming formats:\n\n- mds (mosaic data shard) format which can encode and decode any python object\n- csv / tsv\n- jsonl\n\n<!--pytest.mark.skip-->\n```python\nimport numpy as np\nfrom pil import image\nfrom streaming import mdswriter\n\n# local or remote directory in which to store the compressed output files\ndata_dir = 'path-to-dataset'\n\n# a dictionary mapping input fields to their data types\ncolumns = {\n    'image': 'jpeg',\n    'class': 'int'\n}\n\n# shard compression, if any\ncompression = 'zstd'\n\n# save the samples as shards using mdswriter\nwith mdswriter(out=data_dir, columns=columns, compression=compression) as out:\n    for i in range(10000):\n        sample = {\n            'image': image.fromarray(np.random.randint(0, 256, (32, 32, 3), np.uint8)),\n            'class': np.random.randint(10),\n        }\n        out.write(sample)\n```\n\n### 2. upload your data to cloud storage\n\nupload your streaming dataset to the cloud storage of your choice ([aws](https://aws.amazon.com/s3/), [oci](https://www.oracle.com/cloud/storage/object-storage/), or [gcp](https://cloud.google.com/storage)). below is one example of uploading a directory to an s3 bucket using the [aws cli](https://aws.amazon.com/cli/).\n\n<!--pytest.mark.skip-->\n```bash\n$ aws s3 cp --recursive path-to-dataset s3://my-bucket/path-to-dataset\n```\n\n### 3. build a streamingdataset and dataloader\n\n<!--pytest.mark.skip-->\n```python\nfrom torch.utils.data import dataloader\nfrom streaming import streamingdataset\n\n# remote path where full dataset is persistently stored\nremote = 's3://my-bucket/path-to-dataset'\n\n# local working dir where dataset is cached during operation\nlocal = '/tmp/path-to-dataset'\n\n# create streaming dataset\ndataset = streamingdataset(local=local, remote=remote, shuffle=true)\n\n# let's see what is in sample #1337...\nsample = dataset[1337]\nimg = sample['image']\ncls = sample['class']\n\n# create pytorch dataloader\ndataloader = dataloader(dataset)\n```\n\n### \ud83d\udcda what next?\n\ngetting started guides, examples, api references, and other useful information can be found in our [docs](https://streaming.docs.mosaicml.com/).\n\nwe have end-to-end tutorials for training a model on:\n\n- [cifar-10](https://streaming.docs.mosaicml.com/en/stable/examples/cifar10.html)\n- [facesynthetics](https://streaming.docs.mosaicml.com/en/stable/examples/facesynthetics.html)\n- [syntheticnlp](https://streaming.docs.mosaicml.com/en/stable/examples/synthetic_nlp.html)\n\nwe also have starter code for the following popular datasets, which can be found in the `streaming` [directory](https://github.com/mosaicml/streaming/tree/main/streaming):\n\n| dataset | task | read | write |\n| --- | --- | --- | --- |\n| laion-400m | text and image | [read](https://github.com/mosaicml/diffusion-benchmark/blob/main/data.py) | [write](https://github.com/mosaicml/streaming/tree/main/streaming/multimodal/convert/laion/laion400m) |\n| webvid | text and video | [read](https://github.com/mosaicml/streaming/blob/main/streaming/multimodal/webvid.py) | [write](https://github.com/mosaicml/streaming/blob/main/streaming/multimodal/convert/webvid.py) |\n| c4 | text | [read](https://github.com/mosaicml/streaming/blob/main/streaming/text/c4.py) | [write](https://github.com/mosaicml/streaming/blob/main/streaming/text/convert/c4.py) |\n| enwiki | text | [read](https://github.com/mosaicml/streaming/blob/main/streaming/text/enwiki.py) | [write](https://github.com/mosaicml/streaming/tree/main/streaming/text/convert/enwiki) |\n| pile | text | [read](https://github.com/mosaicml/streaming/blob/main/streaming/text/pile.py) | [write](https://github.com/mosaicml/streaming/blob/main/streaming/text/convert/pile.py)\n| ade20k | image segmentation | [read](https://github.com/mosaicml/streaming/blob/main/streaming/vision/ade20k.py) | [write](https://github.com/mosaicml/streaming/blob/main/streaming/vision/convert/ade20k.py)\n| cifar10 | image classification | [read](https://github.com/mosaicml/streaming/blob/main/streaming/vision/cifar10.py) | [write](https://github.com/mosaicml/streaming/blob/main/streaming/vision/convert/cifar10.py) |\n| coco | image classification | [read](https://github.com/mosaicml/streaming/blob/main/streaming/vision/coco.py) | [write](https://github.com/mosaicml/streaming/blob/main/streaming/vision/convert/coco.py) |\n| imagenet | image classification | [read](https://github.com/mosaicml/streaming/blob/main/streaming/vision/imagenet.py) | [write](https://github.com/mosaicml/streaming/blob/main/streaming/vision/convert/imagenet.py) |\n\n**to start training on these datasets:**\n\n1. convert raw data into .mds format using the corresponding script from the `convert` directory.\n\nfor example:\n\n<!--pytest.mark.skip-->\n```bash\n$ python -m streaming.multimodal.convert.webvid --in <csv file> --out <mds output directory>\n```\n\n2. import dataset class to start training the model.\n\n<!--pytest.mark.skip-->\n```python\nfrom streaming.multimodal import streaminginsidewebvid\ndataset = streaminginsidewebvid(local=local, remote=remote, shuffle=true)\n```\n\n# **\ud83d\udd11**\u00a0key features\n\n---\n\n## seamless data mixing\n\neasily experiment with dataset mixtures with [`stream`](https://docs.mosaicml.com/projects/streaming/en/latest/api_reference/generated/streaming.stream.html#stream). dataset sampling can be controlled in relative (proportion) or absolute (repeat or samples terms). during streaming, the different datasets are streamed, shuffled, and mixed seamlessly just-in-time.\n\n```\n# mix c4, github code, and internal datasets\nstreams = [\n  stream(remote='s3://datasets/c4', proportion=0.4),\n  stream(remote='s3://datasets/github', proportion=0.1),\n  stream(remote='gcs://datasets/my_internal', proportion=0.5),\n]\n\ndataset = streamingdataset(\n  streams=streams,\n  samples_per_epoch=1e8,\n)\n```\n\n## true determinism\n\na unique feature of our solution: samples are in the same order regardless of the number of gpus, nodes, or cpu workers. this makes it easier to:\n\n- reproduce and debug training runs and loss spikes\n- load a checkpoint trained on 64 gpus and debug on 8 gpus with reproducibility\n\nsee the figure below \u2014 training a model on 1, 8, 16, 32, or 64 gpus yields the\u00a0**exact same loss curve** (up to the limitations of floating point math!)\n\n![plot of elastic determinism](docs/source/_static/images/determinism.png)\n\n## instant mid-epoch resumption\n\nit can be expensive \u2014 and annoying \u2014 to wait for your job to resume while your dataloader spins after a hardware failure or loss spike. thanks to our deterministic sample ordering, streamingdataset lets you resume training in seconds, not hours, in the middle of a long training run.\n\nminimizing resumption latency can save thousands of dollars in egress fees and idle gpu compute time compared to existing solutions.\n\n## high throughput\n\nour mds format cuts extraneous work to the bone, resulting in ultra-low sample latency and higher throughput compared to alternatives for workloads bottlenecked by the dataloader.\n\n| tool | throughput |\n| --- | --- |\n| streamingdataset | ~19000 img/sec |\n| imagefolder | ~18000 img/sec |\n| webdataset | ~16000 img/sec |\n\n*results shown are from imagenet + resnet-50 training, collected over 5 repetitions after the data is cached after the first epoch.*\n\n## equal convergence\n\nmodel convergence from using streamingdataset is just as good as using local disk, thanks to our shuffling algorithm.\n\n![plot of equal convergence](docs/source/_static/images/convergence.png)\n\nbelow are results from imagenet + resnet-50 training, collected over 5 repetitions.\n\n| tool | top-1 accuracy |\n| --- | --- |\n| streamingdataset | 76.51% +/- 0.09 |\n| imagefolder | 76.57% +/- 0.10 |\n| webdataset | 76.23% +/- 0.17 |\n\nstreamingdataset shuffles across all samples assigned to a node, whereas alternative solutions only shuffle samples in a smaller pool (within a single process). shuffling across a wider pool spreads out adjacent samples more. in addition, our shuffling algorithm minimizes dropped samples. we have found both of these shuffling features advantageous for model convergence.\n\n## random access\n\naccess the data you need when you need it.\n\neven if a sample isn\u2019t downloaded yet, you can access `dataset[i]` to get sample `i`. the download will kick off immediately and the result will be returned when it\u2019s done - similar to a map-style pytorch dataset with samples numbered sequentially and accessible in any order.\n\n<!--pytest.mark.skip-->\n```python\ndataset = streamingdataset(...)\nsample = dataset[19543]\n```\n\n## no divisibility requirements\n\nstreamingdataset will happily iterate over any number of samples. you do not have to forever delete samples so that the dataset is divisible over a baked-in number of devices. instead, each epoch a different selection of samples are repeated (none dropped) so that each device processes the same count.\n\n<!--pytest.mark.skip-->\n```python\ndataset = streamingdataset(...)\ndl = dataloader(dataset, num_workers=...)\n```\n\n## disk usage limits\n\ndynamically delete least recently used shards in order to keep disk usage under a specified limit. this is enabled by setting the streamingdataset argument `cache_limit`. see the [shuffling](./docs/source/fundamentals/shuffling.md) guide for more details.\n\n```\ndataset = streamingdataset(\n    cache_limit='100gb',\n    ...\n)\n```\n\n# \ud83c\udfc6\u00a0project showcase\n\nhere are some projects and experiments that used streamingdataset. got something to add?  email [community@mosaicml.com](mailto:community@mosaicml.com) or join our [community slack](https://mosaicml.me/slack).\n\n- [biomedlm](https://www.mosaicml.com/blog/introducing-pubmed-gpt): a domain specific large language model for biomedicine by mosaicml and stanford crfm\n- [mosaic diffusion models](https://www.mosaicml.com/blog/training-stable-diffusion-from-scratch-costs-160k): training stable diffusion from scratch costs <$160k\n- [mosaic llms](https://www.mosaicml.com/blog/gpt-3-quality-for-500k): gpt-3 quality for <$500k\n- [mosaic resnet](https://www.mosaicml.com/blog/mosaic-resnet): blazingly fast computer vision training with the mosaic resnet and composer\n- [mosaic deeplabv3](https://www.mosaicml.com/blog/mosaic-image-segmentation): 5x faster image segmentation training with mosaicml recipes\n- \u2026more to come! stay tuned!\n\n# \ud83d\udcab contributors\n\nwe welcome any contributions, pull requests, or issues.\n\nto start contributing, see our [contributing](https://github.com/mosaicml/streaming/blob/main/contributing.md) page.\n\np.s.: [we're hiring](https://mosaicml.com/jobs)!\n\nif you like this project, give us a star **\u2b50** and check out our other projects:\n\n- **[composer](https://github.com/mosaicml/composer) -** a modern pytorch library that makes scalable, efficient neural network training easy\n- **[mosaicml examples](https://github.com/mosaicml/examples)** - reference examples for training ml models quickly and to high accuracy - featuring starter code for gpt / large language models, stable diffusion, bert, resnet-50, and deeplabv3\n- **[mosaicml cloud](https://www.mosaicml.com/cloud)** - our training platform built to minimize training costs for llms, diffusion models, and other large models - featuring multi-cloud orchestration, effortless multi-node scaling, and under-the-hood optimizations for speeding up training time\n\n# \u270d\ufe0f citation\n\n```\n@misc{mosaicml2022streaming,\n    author = {the mosaic ml team},\n    title = {streaming},\n    year = {2022},\n    howpublished = {\\url{<https://github.com/mosaicml/streaming/>}},\n}\n```\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "mosaicml-streaming",
  "package_url": "https://pypi.org/project/mosaicml-streaming/",
  "project_url": "https://pypi.org/project/mosaicml-streaming/",
  "project_urls": {
    "Homepage": "https://github.com/mosaicml/streaming/"
  },
  "release_url": "https://pypi.org/project/mosaicml-streaming/0.7.2/",
  "requires_dist": [
    "boto3 <2,>=1.21.45",
    "Brotli >=1.0.9",
    "google-cloud-storage <2.11.0,>=2.9.0",
    "matplotlib <4,>=3.5.2",
    "paramiko <4,>=2.11.0",
    "python-snappy <1,>=0.6.1",
    "torch <3,>=1.10",
    "torchvision >=0.10",
    "tqdm <5,>=4.64.0",
    "transformers <5,>=4.21.3",
    "xxhash <4,>=3.0.0",
    "zstd <2,>=1.5.2.5",
    "oci <3,>=2.88",
    "azure-storage-blob <13,>=12.0.0",
    "azure-storage-file-datalake <13,>=12.11.0",
    "azure-identity >=1.13.0",
    "GitPython ==3.1.40 ; extra == 'all'",
    "PyYAML <7,>=6.0 ; extra == 'all'",
    "altair <6,>=5.1.1 ; extra == 'all'",
    "databricks-sdk ==0.14.0 ; extra == 'all'",
    "datasets <3,>=2.4.0 ; extra == 'all'",
    "docformatter >=1.4 ; extra == 'all'",
    "docutils ==0.18.1 ; extra == 'all'",
    "fastapi ==0.104.1 ; extra == 'all'",
    "furo ==2023.7.26 ; extra == 'all'",
    "humanize <5,>=4.7.0 ; extra == 'all'",
    "jupyter ==1.0.0 ; extra == 'all'",
    "moto <5,>=4.0 ; extra == 'all'",
    "myst-parser ==2.0.0 ; extra == 'all'",
    "nbsphinx ==0.9.2 ; extra == 'all'",
    "omegaconf <3,>=2.3.0 ; extra == 'all'",
    "pandas <3,>=2.0.3 ; extra == 'all'",
    "pandoc ==2.3 ; extra == 'all'",
    "pre-commit <4,>=2.18.1 ; extra == 'all'",
    "pyarrow >14.0.0 ; extra == 'all'",
    "pydantic ==2.5.2 ; extra == 'all'",
    "pypandoc ==1.12 ; extra == 'all'",
    "pyspark <4,>=3 ; extra == 'all'",
    "pytest-cov <5,>=4 ; extra == 'all'",
    "pytest-split ==0.8.1 ; extra == 'all'",
    "pytest ==7.4.3 ; extra == 'all'",
    "pytest-codeblocks ==0.17.0 ; extra == 'all'",
    "sortedcollections <3,>=2.1.0 ; extra == 'all'",
    "sphinx-argparse ==0.4.0 ; extra == 'all'",
    "sphinx-copybutton ==0.5.2 ; extra == 'all'",
    "sphinx-tabs ==3.4.4 ; extra == 'all'",
    "sphinx ==6.2.1 ; extra == 'all'",
    "streamlit <2,>=1.26.0 ; extra == 'all'",
    "toml ==0.10.2 ; extra == 'all'",
    "uvicorn ==0.24.0.post1 ; extra == 'all'",
    "wandb <1,>=0.15.5 ; extra == 'all'",
    "yamllint ==1.33.0 ; extra == 'all'",
    "databricks-sdk ==0.14.0 ; extra == 'databricks'",
    "datasets <3,>=2.4.0 ; extra == 'dev'",
    "pyarrow >14.0.0 ; extra == 'dev'",
    "docformatter >=1.4 ; extra == 'dev'",
    "jupyter ==1.0.0 ; extra == 'dev'",
    "pre-commit <4,>=2.18.1 ; extra == 'dev'",
    "pytest ==7.4.3 ; extra == 'dev'",
    "pytest-codeblocks ==0.17.0 ; extra == 'dev'",
    "pytest-cov <5,>=4 ; extra == 'dev'",
    "toml ==0.10.2 ; extra == 'dev'",
    "yamllint ==1.33.0 ; extra == 'dev'",
    "moto <5,>=4.0 ; extra == 'dev'",
    "fastapi ==0.104.1 ; extra == 'dev'",
    "pydantic ==2.5.2 ; extra == 'dev'",
    "uvicorn ==0.24.0.post1 ; extra == 'dev'",
    "pytest-split ==0.8.1 ; extra == 'dev'",
    "GitPython ==3.1.40 ; extra == 'docs'",
    "docutils ==0.18.1 ; extra == 'docs'",
    "furo ==2023.7.26 ; extra == 'docs'",
    "myst-parser ==2.0.0 ; extra == 'docs'",
    "nbsphinx ==0.9.2 ; extra == 'docs'",
    "pandoc ==2.3 ; extra == 'docs'",
    "pypandoc ==1.12 ; extra == 'docs'",
    "sphinx-argparse ==0.4.0 ; extra == 'docs'",
    "sphinx-copybutton ==0.5.2 ; extra == 'docs'",
    "sphinx ==6.2.1 ; extra == 'docs'",
    "sphinx-tabs ==3.4.4 ; extra == 'docs'",
    "sortedcollections <3,>=2.1.0 ; extra == 'simulator'",
    "streamlit <2,>=1.26.0 ; extra == 'simulator'",
    "altair <6,>=5.1.1 ; extra == 'simulator'",
    "omegaconf <3,>=2.3.0 ; extra == 'simulator'",
    "PyYAML <7,>=6.0 ; extra == 'simulator'",
    "pandas <3,>=2.0.3 ; extra == 'simulator'",
    "wandb <1,>=0.15.5 ; extra == 'simulator'",
    "humanize <5,>=4.7.0 ; extra == 'simulator'",
    "pyspark <4,>=3 ; extra == 'spark'"
  ],
  "requires_python": ">=3.8",
  "summary": "streaming lets users create pytorch compatible datasets that can be streamed from cloud-based object stores",
  "version": "0.7.2",
  "releases": [],
  "developers": [
    "mosaicml",
    "team@mosaicml.com"
  ],
  "kwds": "mosaicml mosaicml2022streaming png mosaic pypi",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_mosaicml_streaming",
  "homepage": "https://github.com/mosaicml/streaming/",
  "release_count": 22,
  "dependency_ids": [
    "pypi_altair",
    "pypi_azure_identity",
    "pypi_azure_storage_blob",
    "pypi_azure_storage_file_datalake",
    "pypi_boto3",
    "pypi_brotli",
    "pypi_databricks_sdk",
    "pypi_datasets",
    "pypi_docformatter",
    "pypi_docutils",
    "pypi_fastapi",
    "pypi_furo",
    "pypi_gitpython",
    "pypi_google_cloud_storage",
    "pypi_humanize",
    "pypi_jupyter",
    "pypi_matplotlib",
    "pypi_moto",
    "pypi_myst_parser",
    "pypi_nbsphinx",
    "pypi_oci",
    "pypi_omegaconf",
    "pypi_pandas",
    "pypi_pandoc",
    "pypi_paramiko",
    "pypi_pre_commit",
    "pypi_pyarrow",
    "pypi_pydantic",
    "pypi_pypandoc",
    "pypi_pyspark",
    "pypi_pytest",
    "pypi_pytest_codeblocks",
    "pypi_pytest_cov",
    "pypi_pytest_split",
    "pypi_python_snappy",
    "pypi_pyyaml",
    "pypi_sortedcollections",
    "pypi_sphinx",
    "pypi_sphinx_argparse",
    "pypi_sphinx_copybutton",
    "pypi_sphinx_tabs",
    "pypi_streamlit",
    "pypi_toml",
    "pypi_torch",
    "pypi_torchvision",
    "pypi_tqdm",
    "pypi_transformers",
    "pypi_uvicorn",
    "pypi_wandb",
    "pypi_xxhash",
    "pypi_yamllint",
    "pypi_zstd"
  ]
}