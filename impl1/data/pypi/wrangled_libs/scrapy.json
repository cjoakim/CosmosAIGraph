{
  "classifiers": [
    "development status :: 5 - production/stable",
    "environment :: console",
    "framework :: scrapy",
    "intended audience :: developers",
    "license :: osi approved :: bsd license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "programming language :: python :: implementation :: cpython",
    "programming language :: python :: implementation :: pypy",
    "topic :: internet :: www/http",
    "topic :: software development :: libraries :: application frameworks",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": ".. image:: https://scrapy.org/img/scrapylogo.png\n   :target: https://scrapy.org/\n   \n======\nscrapy\n======\n\n.. image:: https://img.shields.io/pypi/v/scrapy.svg\n   :target: https://pypi.python.org/pypi/scrapy\n   :alt: pypi version\n\n.. image:: https://img.shields.io/pypi/pyversions/scrapy.svg\n   :target: https://pypi.python.org/pypi/scrapy\n   :alt: supported python versions\n\n.. image:: https://github.com/scrapy/scrapy/workflows/ubuntu/badge.svg\n   :target: https://github.com/scrapy/scrapy/actions?query=workflow%3aubuntu\n   :alt: ubuntu\n\n.. image:: https://github.com/scrapy/scrapy/workflows/macos/badge.svg\n   :target: https://github.com/scrapy/scrapy/actions?query=workflow%3amacos\n   :alt: macos\n\n.. image:: https://github.com/scrapy/scrapy/workflows/windows/badge.svg\n   :target: https://github.com/scrapy/scrapy/actions?query=workflow%3awindows\n   :alt: windows\n\n.. image:: https://img.shields.io/badge/wheel-yes-brightgreen.svg\n   :target: https://pypi.python.org/pypi/scrapy\n   :alt: wheel status\n\n.. image:: https://img.shields.io/codecov/c/github/scrapy/scrapy/master.svg\n   :target: https://codecov.io/github/scrapy/scrapy?branch=master\n   :alt: coverage report\n\n.. image:: https://anaconda.org/conda-forge/scrapy/badges/version.svg\n   :target: https://anaconda.org/conda-forge/scrapy\n   :alt: conda version\n\n\noverview\n========\n\nscrapy is a fast high-level web crawling and web scraping framework, used to\ncrawl websites and extract structured data from their pages. it can be used for\na wide range of purposes, from data mining to monitoring and automated testing.\n\nscrapy is maintained by zyte_ (formerly scrapinghub) and `many other\ncontributors`_.\n\n.. _many other contributors: https://github.com/scrapy/scrapy/graphs/contributors\n.. _zyte: https://www.zyte.com/\n\ncheck the scrapy homepage at https://scrapy.org for more information,\nincluding a list of features.\n\n\nrequirements\n============\n\n* python 3.8+\n* works on linux, windows, macos, bsd\n\ninstall\n=======\n\nthe quick way:\n\n.. code:: bash\n\n    pip install scrapy\n\nsee the install section in the documentation at\nhttps://docs.scrapy.org/en/latest/intro/install.html for more details.\n\ndocumentation\n=============\n\ndocumentation is available online at https://docs.scrapy.org/ and in the ``docs``\ndirectory.\n\nreleases\n========\n\nyou can check https://docs.scrapy.org/en/latest/news.html for the release notes.\n\ncommunity (blog, twitter, mail list, irc)\n=========================================\n\nsee https://scrapy.org/community/ for details.\n\ncontributing\n============\n\nsee https://docs.scrapy.org/en/master/contributing.html for details.\n\ncode of conduct\n---------------\n\nplease note that this project is released with a contributor `code of conduct <https://github.com/scrapy/scrapy/blob/master/code_of_conduct.md>`_.\n\nby participating in this project you agree to abide by its terms.\nplease report unacceptable behavior to opensource@zyte.com.\n\ncompanies using scrapy\n======================\n\nsee https://scrapy.org/companies/ for a list.\n\ncommercial support\n==================\n\nsee https://scrapy.org/support/ for details.\n",
  "docs_url": null,
  "keywords": "",
  "license": "bsd",
  "name": "scrapy",
  "package_url": "https://pypi.org/project/Scrapy/",
  "project_url": "https://pypi.org/project/Scrapy/",
  "project_urls": {
    "Documentation": "https://docs.scrapy.org/",
    "Homepage": "https://scrapy.org",
    "Source": "https://github.com/scrapy/scrapy",
    "Tracker": "https://github.com/scrapy/scrapy/issues"
  },
  "release_url": "https://pypi.org/project/Scrapy/2.11.0/",
  "requires_dist": [
    "Twisted <23.8.0,>=18.9.0",
    "cryptography >=36.0.0",
    "cssselect >=0.9.1",
    "itemloaders >=1.0.1",
    "parsel >=1.5.0",
    "pyOpenSSL >=21.0.0",
    "queuelib >=1.4.2",
    "service-identity >=18.1.0",
    "w3lib >=1.17.0",
    "zope.interface >=5.1.0",
    "protego >=0.1.15",
    "itemadapter >=0.1.0",
    "setuptools",
    "packaging",
    "tldextract",
    "lxml >=4.4.1",
    "PyDispatcher >=2.0.5 ; platform_python_implementation == \"CPython\"",
    "PyPyDispatcher >=2.1.0 ; platform_python_implementation == \"PyPy\""
  ],
  "requires_python": ">=3.8",
  "summary": "a high-level web crawling and web scraping framework",
  "version": "2.11.0",
  "releases": [],
  "developers": [
    "pablo@pablohoffman.com",
    "pablo_hoffman",
    "scrapy_developers"
  ],
  "kwds": "scrapy scrapylogo pyversions scraping scrapinghub",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_scrapy",
  "homepage": "https://scrapy.org",
  "release_count": 96,
  "dependency_ids": [
    "pypi_cryptography",
    "pypi_cssselect",
    "pypi_itemadapter",
    "pypi_itemloaders",
    "pypi_lxml",
    "pypi_packaging",
    "pypi_parsel",
    "pypi_protego",
    "pypi_pydispatcher",
    "pypi_pyopenssl",
    "pypi_pypydispatcher",
    "pypi_queuelib",
    "pypi_service_identity",
    "pypi_setuptools",
    "pypi_tldextract",
    "pypi_twisted",
    "pypi_w3lib",
    "pypi_zope.interface"
  ]
}