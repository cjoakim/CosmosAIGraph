{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "intended audience :: education",
    "intended audience :: science/research",
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "topic :: scientific/engineering",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: scientific/engineering :: mathematics",
    "topic :: software development",
    "topic :: software development :: libraries",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "# dopamine\n[getting started](#getting-started) |\n[docs][docs] |\n[baseline results][baselines] |\n[changelist](https://google.github.io/dopamine/docs/changelist)\n\n<div align=\"center\">\n  <img src=\"https://google.github.io/dopamine/images/dopamine_logo.png\"><br><br>\n</div>\n\ndopamine is a research framework for fast prototyping of reinforcement learning\nalgorithms. it aims to fill the need for a small, easily grokked codebase in\nwhich users can freely experiment with wild ideas (speculative research).\n\nour design principles are:\n\n* _easy experimentation_: make it easy for new users to run benchmark\n                          experiments.\n* _flexible development_: make it easy for new users to try out research ideas.\n* _compact and reliable_: provide implementations for a few, battle-tested\n                          algorithms.\n* _reproducible_: facilitate reproducibility in results. in particular, our\n                  setup follows the recommendations given by\n                  [machado et al. (2018)][machado].\n\ndopamine supports the following agents, implemented with jax:\n\n* dqn ([mnih et al., 2015][dqn])\n* c51 ([bellemare et al., 2017][c51])\n* rainbow ([hessel et al., 2018][rainbow])\n* iqn ([dabney et al., 2018][iqn])\n* sac ([haarnoja et al., 2018][sac])\n\nfor more information on the available agents, see the [docs](https://google.github.io/dopamine/docs).\n\nmany of these agents also have a tensorflow (legacy) implementation, though\nnewly added agents are likely to be jax-only.\n\nthis is not an official google product.\n\n## getting started\n\n\nwe provide docker containers for using dopamine.\ninstructions can be found [here](https://google.github.io/dopamine/docker/).\n\nalternatively, dopamine can be installed from source (preferred) or installed\nwith pip. for either of these methods, continue reading at prerequisites.\n\n### prerequisites\n\ndopamine supports atari environments and mujoco environments. install the\nenvironments you intend to use before you install dopamine:\n\n**atari**\n\n1. install the atari roms following the instructions from\n[atari-py](https://github.com/openai/atari-py#roms).\n2. `pip install ale-py` (we recommend using a [virtual environment](virtualenv)):\n3. `unzip $rom_dir/roms.zip -d $rom_dir && ale-import-roms $rom_dir/roms`\n(replace $rom_dir with the directory you extracted the roms to).\n\n**mujoco**\n\n1. install mujoco and get a license\n[here](https://github.com/openai/mujoco-py#install-mujoco).\n2. run `pip install mujoco-py` (we recommend using a\n[virtual environment](virtualenv)).\n\n### installing from source\n\n\nthe most common way to use dopamine is to install it from source and modify\nthe source code directly:\n\n```\ngit clone https://github.com/google/dopamine\n```\n\nafter cloning, install dependencies:\n\n```\npip install -r dopamine/requirements.txt\n```\n\ndopamine supports tensorflow (legacy) and jax (actively maintained) agents.\nview the [tensorflow documentation](https://www.tensorflow.org/install) for\nmore information on installing tensorflow.\n\nnote: we recommend using a [virtual environment](virtualenv) when working with dopamine.\n\n### installing with pip\n\nnote: we strongly recommend installing from source for most users.\n\ninstalling with pip is simple, but dopamine is designed to be modified\ndirectly. we recommend installing from source for writing your own experiments.\n\n```\npip install dopamine-rl\n```\n\n### running tests\n\nyou can test whether the installation was successful by running the following\nfrom the dopamine root directory.\n\n```\nexport pythonpath=$pythonpath:$pwd\npython -m tests.dopamine.atari_init_test\n```\n\n## next steps\n\nview the [docs][docs] for more information on training agents.\n\nwe supply [baselines][baselines] for each dopamine agent.\n\nwe also provide a set of [colaboratory notebooks](https://github.com/google/dopamine/tree/master/dopamine/colab)\nwhich demonstrate how to use dopamine.\n\n## references\n\n[bellemare et al., *the arcade learning environment: an evaluation platform for\ngeneral agents*. journal of artificial intelligence research, 2013.][ale]\n\n[machado et al., *revisiting the arcade learning environment: evaluation\nprotocols and open problems for general agents*, journal of artificial\nintelligence research, 2018.][machado]\n\n[hessel et al., *rainbow: combining improvements in deep reinforcement learning*.\nproceedings of the aaai conference on artificial intelligence, 2018.][rainbow]\n\n[mnih et al., *human-level control through deep reinforcement learning*. nature,\n2015.][dqn]\n\n[schaul et al., *prioritized experience replay*. proceedings of the international\nconference on learning representations, 2016.][prioritized_replay]\n\n[haarnoja et al., *soft actor-critic algorithms and applications*,\narxiv preprint arxiv:1812.05905, 2018.][sac]\n\n## giving credit\n\nif you use dopamine in your work, we ask that you cite our\n[white paper][dopamine_paper]. here is an example bibtex entry:\n\n```\n@article{castro18dopamine,\n  author    = {pablo samuel castro and\n               subhodeep moitra and\n               carles gelada and\n               saurabh kumar and\n               marc g. bellemare},\n  title     = {dopamine: {a} {r}esearch {f}ramework for {d}eep {r}einforcement {l}earning},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1812.06110},\n  archiveprefix = {arxiv}\n}\n```\n\n\n\n[docs]: https://google.github.io/dopamine/docs/\n[baselines]: https://google.github.io/dopamine/baselines\n[machado]: https://jair.org/index.php/jair/article/view/11182\n[ale]: https://jair.org/index.php/jair/article/view/10819\n[dqn]: https://storage.googleapis.com/deepmind-media/dqn/dqnnaturepaper.pdf\n[a3c]: http://proceedings.mlr.press/v48/mniha16.html\n[prioritized_replay]: https://arxiv.org/abs/1511.05952\n[c51]: http://proceedings.mlr.press/v70/bellemare17a.html\n[rainbow]: https://www.aaai.org/ocs/index.php/aaai/aaai18/paper/download/17204/16680\n[iqn]: https://arxiv.org/abs/1806.06923\n[sac]: https://arxiv.org/abs/1812.05905\n[dopamine_paper]: https://arxiv.org/abs/1812.06110\n[vitualenv]: https://docs.python.org/3/library/venv.html#creating-virtual-environments\n\n\n",
  "docs_url": null,
  "keywords": "dopamine,reinforcement,machine,learning,research",
  "license": "apache 2.0",
  "name": "dopamine-rl",
  "package_url": "https://pypi.org/project/dopamine-rl/",
  "project_url": "https://pypi.org/project/dopamine-rl/",
  "project_urls": {
    "Bug Reports": "https://github.com/google/dopamine/issues",
    "Documentation": "https://github.com/google/dopamine",
    "Homepage": "https://github.com/google/dopamine",
    "Source": "https://github.com/google/dopamine"
  },
  "release_url": "https://pypi.org/project/dopamine-rl/4.0.6/",
  "requires_dist": [
    "tensorflow (>=2.2.0)",
    "gin-config (>=0.3.0)",
    "absl-py (>=0.9.0)",
    "opencv-python (>=3.4.8.29)",
    "gym (<=0.25.2)",
    "flax (>=0.2.0)",
    "jax (>=0.1.72)",
    "jaxlib (>=0.1.51)",
    "Pillow (>=7.0.0)",
    "numpy (>=1.16.4)",
    "pygame (>=1.9.2)",
    "pandas (>=0.24.2)",
    "tf-slim (>=1.0)",
    "tensorflow-probability (>=0.13.0)"
  ],
  "requires_python": ">=3.5,<4",
  "summary": "dopamine: a framework for flexible reinforcement learning research",
  "version": "4.0.6",
  "releases": [],
  "developers": [
    "the_dopamine_team"
  ],
  "kwds": "dopamine dopamine_logo dopamine_paper reinforcement deepmind",
  "license_kwds": "apache 2.0",
  "libtype": "pypi",
  "id": "pypi_dopamine_rl",
  "homepage": "https://github.com/google/dopamine",
  "release_count": 32,
  "dependency_ids": [
    "pypi_absl_py",
    "pypi_flax",
    "pypi_gin_config",
    "pypi_gym",
    "pypi_jax",
    "pypi_jaxlib",
    "pypi_numpy",
    "pypi_opencv_python",
    "pypi_pandas",
    "pypi_pillow",
    "pypi_pygame",
    "pypi_tensorflow",
    "pypi_tensorflow_probability",
    "pypi_tf_slim"
  ]
}