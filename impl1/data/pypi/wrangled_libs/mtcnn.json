{
  "classifiers": [
    "environment :: console",
    "intended audience :: developers",
    "intended audience :: education",
    "intended audience :: science/research",
    "natural language :: english",
    "programming language :: python :: 3.4",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7"
  ],
  "description": "mtcnn\n#####\n\n.. image:: https://badge.fury.io/py/mtcnn.svg\n    :target: https://badge.fury.io/py/mtcnn\n.. image:: https://travis-ci.org/ipazc/mtcnn.svg?branch=master\n    :target: https://travis-ci.org/ipazc/mtcnn\n\n\nimplementation of the mtcnn face detector for keras in python3.4+. it is written from scratch, using as a reference the implementation of\nmtcnn from david sandberg (`facenet's mtcnn <https://github.com/davidsandberg/facenet/tree/master/src/align>`_) in facenet. it is based on the paper *zhang, k et al. (2016)* [zhang2016]_.\n\n.. image:: https://github.com/ipazc/mtcnn/raw/master/result.jpg\n\n\ninstallation\n############\n\ncurrently it is only supported python3.4 onwards. it can be installed through pip:\n\n.. code:: bash\n\n    $ pip install mtcnn\n\nthis implementation requires opencv>=4.1 and keras>=2.0.0 (any tensorflow supported by keras will be supported by this mtcnn package).\nif this is the first time you use tensorflow, you will probably need to install it in your system:\n\n.. code:: bash\n\n    $ pip install tensorflow\n\nor with `conda`\n\n.. code:: bash\n\n    $ conda install tensorflow\n\nnote that `tensorflow-gpu` version can be used instead if a gpu device is available on the system, which will speedup the results.\n\nusage\n#####\n\nthe following example illustrates the ease of use of this package:\n\n\n.. code:: python\n\n    >>> from mtcnn import mtcnn\n    >>> import cv2\n    >>>\n    >>> img = cv2.cvtcolor(cv2.imread(\"ivan.jpg\"), cv2.color_bgr2rgb)\n    >>> detector = mtcnn()\n    >>> detector.detect_faces(img)\n    [\n        {\n            'box': [277, 90, 48, 63],\n            'keypoints':\n            {\n                'nose': (303, 131),\n                'mouth_right': (313, 141),\n                'right_eye': (314, 114),\n                'left_eye': (291, 117),\n                'mouth_left': (296, 143)\n            },\n            'confidence': 0.99851983785629272\n        }\n    ]\n\nthe detector returns a list of json objects. each json object contains three main keys: 'box', 'confidence' and 'keypoints':\n\n- the bounding box is formatted as [x, y, width, height] under the key 'box'.\n- the confidence is the probability for a bounding box to be matching a face.\n- the keypoints are formatted into a json object with the keys 'left_eye', 'right_eye', 'nose', 'mouth_left', 'mouth_right'. each keypoint is identified by a pixel position (x, y).\n\nanother good example of usage can be found in the file \"`example.py`_.\" located in the root of this repository. also, you can run the jupyter notebook \"`example.ipynb`_\" for another example of usage.\n\nbenchmark\n=========\n\nthe following tables shows the benchmark of this mtcnn implementation running on an `intel i7-3612qm cpu @ 2.10ghz <https://www.cpubenchmark.net/cpu.php?cpu=intel+core+i7-3612qm+%40+2.10ghz>`_, with a **cpu-based** tensorflow 1.4.1.\n\n - pictures containing a single frontal face:\n\n+------------+--------------+---------------+-----+\n| image size | total pixels | process time  | fps |\n+============+==============+===============+=====+\n| 460x259    | 119,140      | 0.118 seconds | 8.5 |\n+------------+--------------+---------------+-----+\n| 561x561    | 314,721      | 0.227 seconds | 4.5 |\n+------------+--------------+---------------+-----+\n| 667x1000   | 667,000      | 0.456 seconds | 2.2 |\n+------------+--------------+---------------+-----+\n| 1920x1200  | 2,304,000    | 1.093 seconds | 0.9 |\n+------------+--------------+---------------+-----+\n| 4799x3599  | 17,271,601   | 8.798 seconds | 0.1 |\n+------------+--------------+---------------+-----+\n\n - pictures containing 10 frontal faces:\n\n+------------+--------------+---------------+-----+\n| image size | total pixels | process time  | fps |\n+============+==============+===============+=====+\n| 474x224    | 106,176      | 0.185 seconds | 5.4 |\n+------------+--------------+---------------+-----+\n| 736x348    | 256,128      | 0.290 seconds | 3.4 |\n+------------+--------------+---------------+-----+\n| 2100x994   | 2,087,400    | 1.286 seconds | 0.7 |\n+------------+--------------+---------------+-----+\n\nmodel\n#####\n\nby default the mtcnn bundles a face detection weights model.\n\nthe model is adapted from the facenet's mtcnn implementation, merged in a single file located inside the folder 'data' relative\nto the module's path. it can be overriden by injecting it into the mtcnn() constructor during instantiation.\n\nthe model must be numpy-based containing the 3 main keys \"pnet\", \"rnet\" and \"onet\", having each of them the weights of each of the layers of the network.\n\nfor more reference about the network definition, take a close look at the paper from *zhang et al. (2016)* [zhang2016]_.\n\nlicense\n#######\n\n`mit license`_.\n\n\nreference\n=========\n\n.. [zhang2016] zhang, k., zhang, z., li, z., and qiao, y. (2016). joint face detection and alignment using multitask cascaded convolutional networks. ieee signal processing letters, 23(10):1499\u20131503.\n\n.. _example.py: example.py\n.. _example.ipynb: example.ipynb\n.. _mit license: license\n\n\n",
  "docs_url": null,
  "keywords": "mtcnn face detection tensorflow pip package",
  "license": "mit",
  "name": "mtcnn",
  "package_url": "https://pypi.org/project/mtcnn/",
  "project_url": "https://pypi.org/project/mtcnn/",
  "project_urls": {
    "Homepage": "http://github.com/ipazc/mtcnn"
  },
  "release_url": "https://pypi.org/project/mtcnn/0.1.1/",
  "requires_dist": [
    "keras (>=2.0.0)",
    "opencv-python (>=4.1.0)"
  ],
  "requires_python": "",
  "summary": "multi-task cascaded convolutional neural networks for face detection, based on tensorflow",
  "version": "0.1.1",
  "releases": [],
  "developers": [
    "ipazc@unileon.es"
  ],
  "kwds": "mtcnn facenet detect_faces tensorflow keras",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_mtcnn",
  "homepage": "http://github.com/ipazc/mtcnn",
  "release_count": 11,
  "dependency_ids": [
    "pypi_keras",
    "pypi_opencv_python"
  ]
}