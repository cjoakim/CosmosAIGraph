{
  "classifiers": [
    "development status :: 3 - alpha",
    "intended audience :: developers",
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: software development :: build tools"
  ],
  "description": "# pyspark-anonymizer\npython library which makes it possible to dynamically mask/anonymize data using json string or python dict rules in a pyspark environment.\n\n## installing\n\n```shell\npip install pyspark-anonymizer\n```\n\n## usage\n\n\n### before masking\n\n\n```python\nfrom pyspark.sql import sparksession\n\nspark = sparksession.builder.appname(\"your_app_name\").getorcreate()\ndf = spark.read.parquet(\"s3://amazon-reviews-pds/parquet/product_category=electronics/\")\ndf.limit(5).topandas()\n```\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>marketplace</th>\n      <th>customer_id</th>\n      <th>review_id</th>\n      <th>product_id</th>\n      <th>product_parent</th>\n      <th>product_title</th>\n      <th>star_rating</th>\n      <th>helpful_votes</th>\n      <th>total_votes</th>\n      <th>vine</th>\n      <th>verified_purchase</th>\n      <th>review_headline</th>\n      <th>review_body</th>\n      <th>review_date</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>us</td>\n      <td>51163966</td>\n      <td>r2rx7kloqq5vbg</td>\n      <td>b00000jbat</td>\n      <td>738692522</td>\n      <td>diamond rio digital player</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>n</td>\n      <td>n</td>\n      <td>why just 30 minutes?</td>\n      <td>rio is really great, but diamond should increa...</td>\n      <td>1999-06-22</td>\n      <td>1999</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>us</td>\n      <td>30050581</td>\n      <td>rphmrncgzf2hn</td>\n      <td>b001brplzu</td>\n      <td>197287809</td>\n      <td>ng 283220 ac adapter power supply for hp pavil...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>n</td>\n      <td>y</td>\n      <td>five stars</td>\n      <td>great quality for the price!!!!</td>\n      <td>2014-11-17</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>us</td>\n      <td>52246039</td>\n      <td>r3pd79h9cter8u</td>\n      <td>b00000jbat</td>\n      <td>738692522</td>\n      <td>diamond rio digital player</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>n</td>\n      <td>n</td>\n      <td>the digital audio &amp;quot;killer app&amp;quot;</td>\n      <td>one of several first-generation portable mp3 p...</td>\n      <td>1999-06-30</td>\n      <td>1999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>us</td>\n      <td>16186332</td>\n      <td>r3u6uvnh7hgdms</td>\n      <td>b009cy43dk</td>\n      <td>856142222</td>\n      <td>hde mini portable capsule travel mobile pocket...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>n</td>\n      <td>y</td>\n      <td>five stars</td>\n      <td>i like it, got some for the grandchilren</td>\n      <td>2014-11-17</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>us</td>\n      <td>53068431</td>\n      <td>r3sp31ln235gv3</td>\n      <td>b00000jbsn</td>\n      <td>670078724</td>\n      <td>jvc fs-7000 executive microsystem (discontinue...</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>n</td>\n      <td>n</td>\n      <td>design flaws ruined the better functions</td>\n      <td>i returned mine for a couple of reasons:  the ...</td>\n      <td>1999-07-13</td>\n      <td>1999</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n### after masking\n\nin this example we will add the following data anonymizers:\n\n- **drop_column** on column \"marketplace\"\n- **replace** all values to \"*\" of the \"customer_id\" column\n- **replace_with_regex** \"r\\d\" (r and any digit) to \"*\" on \"review_id\" column\n- **sha256** on \"product_id\" column\n- **filter_row** with condition \"product_parent != 738692522\"\n\n```python\nfrom pyspark.sql import sparksession\nimport pyspark.sql.functions as spark_functions\nimport pyspark_anonymizer\n\nspark = sparksession.builder.appname(\"your_app_name\").getorcreate()\ndf = spark.read.parquet(\"s3://amazon-reviews-pds/parquet/product_category=electronics/\")\n\ndataframe_anonymizers = [\n    {\n        \"method\": \"drop_column\",\n        \"parameters\": {\n            \"column_name\": \"marketplace\"\n        }\n    },\n    {\n        \"method\": \"replace\",\n        \"parameters\": {\n            \"column_name\": \"customer_id\",\n            \"replace_to\": \"*\"\n        }\n    },\n    {\n        \"method\": \"replace_with_regex\",\n        \"parameters\": {\n            \"column_name\": \"review_id\",\n            \"replace_from_regex\": \"r\\d\",\n            \"replace_to\": \"*\"\n        }\n    },\n    {\n        \"method\": \"sha256\",\n        \"parameters\": {\n            \"column_name\": \"product_id\"\n        }\n    },\n    {\n        \"method\": \"filter_row\",\n        \"parameters\": {\n            \"where\": \"product_parent != 738692522\"\n        }\n    }\n]\n\ndf_parsed = pyspark_anonymizer.parser(df, dataframe_anonymizers, spark_functions).parse()\ndf_parsed.limit(5).topandas()\n```\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>review_id</th>\n      <th>product_id</th>\n      <th>product_parent</th>\n      <th>product_title</th>\n      <th>star_rating</th>\n      <th>helpful_votes</th>\n      <th>total_votes</th>\n      <th>vine</th>\n      <th>verified_purchase</th>\n      <th>review_headline</th>\n      <th>review_body</th>\n      <th>review_date</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>*</td>\n      <td>rphmrncgzf2hn</td>\n      <td>69031b13080f90ae3bbbb505f5f80716cd11c4eadd8d86...</td>\n      <td>197287809</td>\n      <td>ng 283220 ac adapter power supply for hp pavil...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>n</td>\n      <td>y</td>\n      <td>five stars</td>\n      <td>great quality for the price!!!!</td>\n      <td>2014-11-17</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>*</td>\n      <td>*u6uvnh7hgdms</td>\n      <td>c99947c06f65c1398b39d092b50903986854c21fd1aeab...</td>\n      <td>856142222</td>\n      <td>hde mini portable capsule travel mobile pocket...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>n</td>\n      <td>y</td>\n      <td>five stars</td>\n      <td>i like it, got some for the grandchilren</td>\n      <td>2014-11-17</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>*</td>\n      <td>*sp31ln235gv3</td>\n      <td>eb6b489524a2fb1d2de5d2e869d600ee2663e952a4b252...</td>\n      <td>670078724</td>\n      <td>jvc fs-7000 executive microsystem (discontinue...</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>n</td>\n      <td>n</td>\n      <td>design flaws ruined the better functions</td>\n      <td>i returned mine for a couple of reasons:  the ...</td>\n      <td>1999-07-13</td>\n      <td>1999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>*</td>\n      <td>*iyazpptrjf7e</td>\n      <td>2a243d31915e78f260db520d9dcb9b16725191f55c54df...</td>\n      <td>503838146</td>\n      <td>bluerigger high speed hdmi cable with ethernet...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>n</td>\n      <td>y</td>\n      <td>never got around to returning the 1 out of 2 ...</td>\n      <td>never got around to returning the 1 out of 2 t...</td>\n      <td>2014-11-17</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>*</td>\n      <td>*rdd9filg1lsn</td>\n      <td>c1f5e54677bf48936fb1e9838869630e934d16ac653b15...</td>\n      <td>587294791</td>\n      <td>brookstone 2.4ghz wireless tv headphones</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>n</td>\n      <td>y</td>\n      <td>saved my. marriage, i swear to god.</td>\n      <td>saved my.marriage, i swear to god.</td>\n      <td>2014-11-17</td>\n      <td>2014</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n### anonymizers from dynamodb\n\nyou can store anonymizers on dynamodb too.\n\n#### creating dynamodb table\n\nto create the table follow the steps below.\n\nusing example script\n- run [examples/create_on_demand_table.py](examples/create_on_demand_table.py) script of examples directory. the table will be created\n\non aws console:\n- dynamodb > tables > create table\n- table name: \"pyspark_anonymizer\" (or any other of your own)\n- partition key: \"dataframe_name\"\n- customize the settings if you want\n- create table\n\n#### writing anonymizer on dynamodb\n\nyou can run the example script, then edit your settings from there.\n\n- run [examples/insert_anonymizer.py](examples/insert_anonymizer.py) script.\n- a new entry on dynamodb will be added, the example dataframe name is \"table_x\"\n\n#### parse from dynamodb\n\n```python\nfrom pyspark.sql import sparksession\nimport pyspark.sql.functions as spark_functions\nimport pyspark_anonymizer\nimport boto3\nfrom botocore.exceptions import clienterror as client_error\n\ndynamo_table = \"pyspark_anonymizer\"\ndataframe_name = \"table_x\"\n\ndynamo_table = boto3.resource('dynamodb').table(dynamo_table)\nspark = sparksession.builder.appname(\"your_app_name\").getorcreate()\ndf = spark.read.parquet(\"s3://amazon-reviews-pds/parquet/product_category=electronics/\")\n\ndf_parsed = pyspark_anonymizer.parserfromdynamodb(df, dataframe_name, dynamo_table, spark_functions, client_error).parse()\n\ndf_parsed.limit(5).topandas()\n```\n\n**the output will be same as the previous. the difference is that the anonymization settings will be in dynamodb**\n\n## currently supported data masking/anonymization methods\n- methods\n  - drop_column - drop a column.\n  - replace - replace all column to a string.\n  - replace_with_regex - replace column contents with regex.\n  - sha256 - apply sha256 hashing function.\n  - filter_row - apply a filter to the dataframe.\n\n\n",
  "docs_url": null,
  "keywords": "data anonymizer,anon,spark,data mask,mask,data masking,masking",
  "license": "apache-2.0",
  "name": "pyspark-anonymizer",
  "package_url": "https://pypi.org/project/pyspark-anonymizer/",
  "project_url": "https://pypi.org/project/pyspark-anonymizer/",
  "project_urls": {
    "Download": "https://github.com/wesleywilian/pyspark-anonymizer/archive/v0.5.tar.gz",
    "Homepage": "https://github.com/wesleywilian/pyspark-anonymizer"
  },
  "release_url": "https://pypi.org/project/pyspark-anonymizer/0.5/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "python library which makes it possible to dynamically mask/anonymize data using json string or python dict rules in a pyspark environment.",
  "version": "0.5",
  "releases": [],
  "developers": [
    "wesleywilian"
  ],
  "kwds": "pyspark_anonymizer dataframe_anonymizers pyspark anonymizer anonymizers",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_pyspark_anonymizer",
  "homepage": "https://github.com/wesleywilian/pyspark-anonymizer",
  "release_count": 4,
  "dependency_ids": []
}