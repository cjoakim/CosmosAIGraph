{
  "classifiers": [
    "development status :: 7 - inactive",
    "framework :: aws cdk",
    "framework :: aws cdk :: 1",
    "intended audience :: developers",
    "license :: osi approved",
    "operating system :: os independent",
    "programming language :: javascript",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "typing :: typed"
  ],
  "description": "# aws lambda construct library\n\n<!--begin stability banner-->---\n\n\n![end-of-support](https://img.shields.io/badge/end--of--support-critical.svg?style=for-the-badge)\n\n> aws cdk v1 has reached end-of-support on 2023-06-01.\n> this package is no longer being updated, and users should migrate to aws cdk v2.\n>\n> for more information on how to migrate, see the [*migrating to aws cdk v2* guide](https://docs.aws.amazon.com/cdk/v2/guide/migrating-v2.html).\n\n---\n<!--end stability banner-->\n\nthis construct library allows you to define aws lambda functions.\n\n```python\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\"))\n)\n```\n\n## handler code\n\nthe `lambda.code` class includes static convenience methods for various types of\nruntime code.\n\n* `lambda.code.frombucket(bucket, key[, objectversion])` - specify an s3 object\n  that contains the archive of your runtime code.\n* `lambda.code.frominline(code)` - inline the handle code as a string. this is\n  limited to supported runtimes and the code cannot exceed 4kib.\n* `lambda.code.fromasset(path)` - specify a directory or a .zip file in the local\n  filesystem which will be zipped and uploaded to s3 before deployment. see also\n  [bundling asset code](#bundling-asset-code).\n* `lambda.code.fromdockerbuild(path, options)` - use the result of a docker\n  build as code. the runtime code is expected to be located at `/asset` in the\n  image and will be zipped and uploaded to s3 as an asset.\n\nthe following example shows how to define a python function and deploy the code\nfrom the local directory `my-lambda-handler` to it:\n\n```python\nlambda_.function(self, \"mylambda\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"my-lambda-handler\")),\n    handler=\"index.main\",\n    runtime=lambda_.runtime.python_3_9\n)\n```\n\nwhen deploying a stack that contains this code, the directory will be zip\narchived and then uploaded to an s3 bucket, then the exact location of the s3\nobjects will be passed when the stack is deployed.\n\nduring synthesis, the cdk expects to find a directory on disk at the asset\ndirectory specified. note that we are referencing the asset directory relatively\nto our cdk project directory. this is especially important when we want to share\nthis construct through a library. different programming languages will have\ndifferent techniques for bundling resources into libraries.\n\n## docker images\n\nlambda functions allow specifying their handlers within docker images. the docker\nimage can be an image from ecr or a local asset that the cdk will package and load\ninto ecr.\n\nthe following `dockerimagefunction` construct uses a local folder with a\ndockerfile as the asset that will be used as the function handler.\n\n```python\nlambda_.dockerimagefunction(self, \"assetfunction\",\n    code=lambda_.dockerimagecode.from_image_asset(path.join(__dirname, \"docker-handler\"))\n)\n```\n\nyou can also specify an image that already exists in ecr as the function handler.\n\n```python\nimport aws_cdk.aws_ecr as ecr\n\nrepo = ecr.repository(self, \"repository\")\n\nlambda_.dockerimagefunction(self, \"ecrfunction\",\n    code=lambda_.dockerimagecode.from_ecr(repo)\n)\n```\n\nthe props for these docker image resources allow overriding the image's `cmd`, `entrypoint`, and `workdir`\nconfigurations as well as choosing a specific tag or digest. see their docs for more information.\n\n## execution role\n\nlambda functions assume an iam role during execution. in cdk by default, lambda\nfunctions will use an autogenerated role if one is not provided.\n\nthe autogenerated role is automatically given permissions to execute the lambda\nfunction. to reference the autogenerated role:\n\n```python\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\"))\n)\n\nrole = fn.role\n```\n\nyou can also provide your own iam role. provided iam roles will not automatically\nbe given permissions to execute the lambda function. to provide a role and grant\nit appropriate permissions:\n\n```python\nmy_role = iam.role(self, \"my role\",\n    assumed_by=iam.serviceprincipal(\"lambda.amazonaws.com\")\n)\n\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    role=my_role\n)\n\nmy_role.add_managed_policy(iam.managedpolicy.from_aws_managed_policy_name(\"service-role/awslambdabasicexecutionrole\"))\nmy_role.add_managed_policy(iam.managedpolicy.from_aws_managed_policy_name(\"service-role/awslambdavpcaccessexecutionrole\"))\n```\n\n## function timeout\n\naws lambda functions have a default timeout of 3 seconds, but this can be increased\nup to 15 minutes. the timeout is available as a property of `function` so that\nyou can reference it elsewhere in your stack. for instance, you could use it to create\na cloudwatch alarm to report when your function timed out:\n\n```python\nimport aws_cdk.core as cdk\nimport aws_cdk.aws_cloudwatch as cloudwatch\n\n\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    timeout=cdk.duration.minutes(5)\n)\n\nif fn.timeout:\n    cloudwatch.alarm(self, \"myalarm\",\n        metric=fn.metric_duration().with(\n            statistic=\"maximum\"\n        ),\n        evaluation_periods=1,\n        datapoints_to_alarm=1,\n        threshold=fn.timeout.to_milliseconds(),\n        treat_missing_data=cloudwatch.treatmissingdata.ignore,\n        alarm_name=\"my lambda timeout\"\n    )\n```\n\n## resource-based policies\n\naws lambda supports resource-based policies for controlling access to lambda\nfunctions and layers on a per-resource basis. in particular, this allows you to\ngive permission to aws services and other aws accounts to modify and invoke your\nfunctions. you can also restrict permissions given to aws services by providing\na source account or arn (representing the account and identifier of the resource\nthat accesses the function or layer).\n\n```python\n# fn: lambda.function\n\nprincipal = iam.serviceprincipal(\"my-service\")\n\nfn.grant_invoke(principal)\n\n# equivalent to:\nfn.add_permission(\"my-service invocation\",\n    principal=principal\n)\n```\n\nfor more information, see [resource-based\npolicies](https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html)\nin the aws lambda developer guide.\n\nproviding an unowned principal (such as account principals, generic arn\nprincipals, service principals, and principals in other accounts) to a call to\n`fn.grantinvoke` will result in a resource-based policy being created. if the\nprincipal in question has conditions limiting the source account or arn of the\noperation (see above), these conditions will be automatically added to the\nresource policy.\n\n```python\n# fn: lambda.function\n\nservice_principal = iam.serviceprincipal(\"my-service\")\nsource_arn = \"arn:aws:s3:::my-bucket\"\nsource_account = \"111122223333\"\nservice_principal_with_conditions = service_principal.with_conditions({\n    \"arnlike\": {\n        \"aws:sourcearn\": source_arn\n    },\n    \"stringequals\": {\n        \"aws:sourceaccount\": source_account\n    }\n})\n\nfn.grant_invoke(service_principal_with_conditions)\n\n# equivalent to:\nfn.add_permission(\"my-service invocation\",\n    principal=service_principal,\n    source_arn=source_arn,\n    source_account=source_account\n)\n```\n\n## versions\n\nyou can use\n[versions](https://docs.aws.amazon.com/lambda/latest/dg/configuration-versions.html)\nto manage the deployment of your aws lambda functions. for example, you can\npublish a new version of a function for beta testing without affecting users of\nthe stable production version.\n\nthe function version includes the following information:\n\n* the function code and all associated dependencies.\n* the lambda runtime that executes the function.\n* all of the function settings, including the environment variables.\n* a unique amazon resource name (arn) to identify this version of the function.\n\nyou could create a version to your lambda function using the `version` construct.\n\n```python\n# fn: lambda.function\n\nversion = lambda_.version(self, \"myversion\",\n    lambda_=fn\n)\n```\n\nthe major caveat to know here is that a function version must always point to a\nspecific 'version' of the function. when the function is modified, the version\nwill continue to point to the 'then version' of the function.\n\none way to ensure that the `lambda.version` always points to the latest version\nof your `lambda.function` is to set an environment variable which changes at\nleast as often as your code does. this makes sure the function always has the\nlatest code. for instance -\n\n```python\ncode_version = \"stringormethodtogetcodeversion\"\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    environment={\n        \"codeversionstring\": code_version\n    }\n)\n```\n\nthe `fn.latestversion` property returns a `lambda.iversion` which represents\nthe `$latest` pseudo-version.\n\nhowever, most aws services require a specific aws lambda version,\nand won't allow you to use `$latest`. therefore, you would normally want\nto use `lambda.currentversion`.\n\nthe `fn.currentversion` property can be used to obtain a `lambda.version`\nresource that represents the aws lambda function defined in your application.\nany change to your function's code or configuration will result in the creation\nof a new version resource. you can specify options for this version through the\n`currentversionoptions` property.\n\nnote: the `currentversion` property is only supported when your aws lambda function\nuses either `lambda.code.fromasset` or `lambda.code.frominline`. other types\nof code providers (such as `lambda.code.frombucket`) require that you define a\n`lambda.version` resource directly since the cdk is unable to determine if\ntheir contents had changed.\n\n### `currentversion`: updated hashing logic\n\nto produce a new lambda version each time the lambda function is modified, the\n`currentversion` property under the hood, computes a new logical id based on the\nproperties of the function. this informs cloudformation that a new\n`aws::lambda::version` resource should be created pointing to the updated lambda\nfunction.\n\nhowever, a bug was introduced in this calculation that caused the logical id to\nchange when it was not required (ex: when the function's `tags` property, or\nwhen the `dependson` clause was modified). this caused the deployment to fail\nsince the lambda service does not allow creating duplicate versions.\n\nthis has been fixed in the aws cdk but *existing* users need to opt-in via a\n[feature flag](https://docs.aws.amazon.com/cdk/latest/guide/featureflags.html). users who have run `cdk init` since this fix will be opted in,\nby default.\n\notherwise, you will need to enable the [feature flag](https://docs.aws.amazon.com/cdk/latest/guide/featureflags.html)\n`@aws-cdk/aws-lambda:recognizeversionprops`. since cloudformation does not\nallow duplicate versions, you will also need to make some modification to\nyour function so that a new version can be created. to efficiently and trivially\nmodify all your lambda functions at once, you can attach the\n`functionversionupgrade` aspect to the stack, which slightly alters the\nfunction description. this aspect is intended for one-time use to upgrade the\nversion of all your functions at the same time, and can safely be removed after\ndeploying once.\n\n```python\nstack = stack()\naspects.of(stack).add(lambda_.functionversionupgrade(lambda_recognize_version_props))\n```\n\nwhen the new logic is in effect, you may rarely come across the following error:\n`the following properties are not recognized as version properties`. this will\noccur, typically when [property overrides](https://docs.aws.amazon.com/cdk/latest/guide/cfn_layer.html#cfn_layer_raw) are used, when a new property\nintroduced in `aws::lambda::function` is used that cdk is still unaware of.\n\nto overcome this error, use the api `function.classifyversionproperty()` to\nrecord whether a new version should be generated when this property is changed.\nthis can be typically determined by checking whether the property can be\nmodified using the *[updatefunctionconfiguration](https://docs.aws.amazon.com/lambda/latest/dg/api_updatefunctionconfiguration.html)* api or not.\n\n### `currentversion`: updated hashing logic for layer versions\n\nan additional update to the hashing logic fixes two issues surrounding layers.\nprior to this change, updating the lambda layer version would have no effect on\nthe function version. also, the order of lambda layers provided to the function\nwas unnecessarily baked into the hash.\n\nthis has been fixed in the aws cdk starting with version 2.27. if you ran\n`cdk init` with an earlier version, you will need to opt-in via a [feature flag](https://docs.aws.amazon.com/cdk/latest/guide/featureflags.html).\nif you run `cdk init` with v2.27 or later, this fix will be opted in, by default.\n\nexisting users will need to enable the [feature flag](https://docs.aws.amazon.com/cdk/latest/guide/featureflags.html)\n`@aws-cdk/aws-lambda:recognizelayerversion`. since cloudformation does not\nallow duplicate versions, they will also need to make some modification to\ntheir function so that a new version can be created. to efficiently and trivially\nmodify all your lambda functions at once, users can attach the\n`functionversionupgrade` aspect to the stack, which slightly alters the\nfunction description. this aspect is intended for one-time use to upgrade the\nversion of all your functions at the same time, and can safely be removed after\ndeploying once.\n\n```python\nstack = stack()\naspects.of(stack).add(lambda_.functionversionupgrade(lambda_recognize_layer_version))\n```\n\n## aliases\n\nyou can define one or more\n[aliases](https://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html)\nfor your aws lambda function. a lambda alias is like a pointer to a specific\nlambda function version. users can access the function version using the alias\narn.\n\nthe `version.addalias()` method can be used to define an aws lambda alias that\npoints to a specific version.\n\nthe following example defines an alias named `live` which will always point to a\nversion that represents the function as defined in your cdk app. when you change\nyour lambda code or configuration, a new resource will be created. you can\nspecify options for the current version through the `currentversionoptions`\nproperty.\n\n```python\nfn = lambda_.function(self, \"myfunction\",\n    current_version_options=lambda.versionoptions(\n        removal_policy=removalpolicy.retain,  # retain old versions\n        retry_attempts=1\n    ),\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\"))\n)\n\nfn.add_alias(\"live\")\n```\n\n## function url\n\na function url is a dedicated http(s) endpoint for your lambda function. when you create a function url, lambda automatically generates a unique url endpoint for you. function urls can be created for the latest version lambda functions, or function aliases (but not for versions).\n\nfunction urls are dual stack-enabled, supporting ipv4 and ipv6, and cross-origin resource sharing (cors) configuration. after you configure a function url for your function, you can invoke your function through its http(s) endpoint via a web browser, curl, postman, or any http client. to invoke a function using iam authentication your http client must support sigv4 signing.\n\nsee the [invoking function urls](https://docs.aws.amazon.com/lambda/latest/dg/urls-invocation.html) section of the aws lambda developer guide\nfor more information on the input and output payloads of functions invoked in this way.\n\n### iam-authenticated function urls\n\nto create a function url which can be called by an iam identity, call `addfunctionurl()`, followed by `grantinvokefunctionurl()`:\n\n```python\n# can be a function or an alias\n# fn: lambda.function\n# my_role: iam.role\n\n\nfn_url = fn.add_function_url()\nfn_url.grant_invoke_url(my_role)\n\ncfnoutput(self, \"theurl\",\n    # the .url attributes will return the unique function url\n    value=fn_url.url\n)\n```\n\ncalls to this url need to be signed with sigv4.\n\n### anonymous function urls\n\nto create a function url which can be called anonymously, pass `authtype: functionurlauthtype.none` to `addfunctionurl()`:\n\n```python\n# can be a function or an alias\n# fn: lambda.function\n\n\nfn_url = fn.add_function_url(\n    auth_type=lambda_.functionurlauthtype.none\n)\n\ncfnoutput(self, \"theurl\",\n    value=fn_url.url\n)\n```\n\n### cors configuration for function urls\n\nif you want your function urls to be invokable from a web page in browser, you\nwill need to configure cross-origin resource sharing to allow the call (if you do\nnot do this, your browser will refuse to make the call):\n\n```python\n# fn: lambda.function\n\n\nfn.add_function_url(\n    auth_type=lambda_.functionurlauthtype.none,\n    cors=lambda.functionurlcorsoptions(\n        # allow this to be called from websites on https://example.com.\n        # can also be ['*'] to allow all domain.\n        allowed_origins=[\"https://example.com\"]\n    )\n)\n```\n\n## layers\n\nthe `lambda.layerversion` class can be used to define lambda layers and manage\ngranting permissions to other aws accounts or organizations.\n\n```python\nlayer = lambda_.layerversion(stack, \"mylayer\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"layer-code\")),\n    compatible_runtimes=[lambda_.runtime.nodejs_14_x],\n    license=\"apache-2.0\",\n    description=\"a layer to test the l2 construct\"\n)\n\n# to grant usage by other aws accounts\nlayer.add_permission(\"remote-account-grant\", account_id=aws_account_id)\n\n# to grant usage to all accounts in some aws ogranization\n# layer.grantusage({ accountid: '*', organizationid });\n\nlambda_.function(stack, \"mylayeredlambda\",\n    code=lambda_.inlinecode(\"foo\"),\n    handler=\"index.handler\",\n    runtime=lambda_.runtime.nodejs_14_x,\n    layers=[layer]\n)\n```\n\nby default, updating a layer creates a new layer version, and cloudformation will delete the old version as part of the stack update.\n\nalternatively, a removal policy can be used to retain the old version:\n\n```python\nlambda_.layerversion(self, \"mylayer\",\n    removal_policy=removalpolicy.retain,\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\"))\n)\n```\n\n## architecture\n\nlambda functions, by default, run on compute systems that have the 64 bit x86 architecture.\n\nthe aws lambda service also runs compute on the arm architecture, which can reduce cost\nfor some workloads.\n\na lambda function can be configured to be run on one of these platforms:\n\n```python\nlambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    architecture=lambda_.architecture.arm_64\n)\n```\n\nsimilarly, lambda layer versions can also be tagged with architectures it is compatible with.\n\n```python\nlambda_.layerversion(self, \"mylayer\",\n    removal_policy=removalpolicy.retain,\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    compatible_architectures=[lambda_.architecture.x86_64, lambda_.architecture.arm_64]\n)\n```\n\n## lambda insights\n\nlambda functions can be configured to use cloudwatch [lambda insights](https://docs.aws.amazon.com/amazoncloudwatch/latest/monitoring/lambda-insights.html)\nwhich provides low-level runtime metrics for a lambda functions.\n\n```python\nlambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    insights_version=lambda_.lambdainsightsversion.version_1_0_98_0\n)\n```\n\nif the version of insights is not yet available in the cdk, you can also provide the arn directly as so -\n\n```python\nlayer_arn = \"arn:aws:lambda:us-east-1:580247275435:layer:lambdainsightsextension:14\"\nlambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    insights_version=lambda_.lambdainsightsversion.from_insight_version_arn(layer_arn)\n)\n```\n\nif you are deploying an arm_64 lambda function, you must specify a\nlambda insights version >= `1_0_119_0`.\n\n```python\nlambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    architecture=lambda_.architecture.arm_64,\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    insights_version=lambda_.lambdainsightsversion.version_1_0_119_0\n)\n```\n\n## event rule target\n\nyou can use an aws lambda function as a target for an amazon cloudwatch event\nrule:\n\n```python\nimport aws_cdk.aws_events as events\nimport aws_cdk.aws_events_targets as targets\n\n# fn: lambda.function\n\nrule = events.rule(self, \"schedule rule\",\n    schedule=events.schedule.cron(minute=\"0\", hour=\"4\")\n)\nrule.add_target(targets.lambdafunction(fn))\n```\n\n## event sources\n\naws lambda supports a [variety of event sources](https://docs.aws.amazon.com/lambda/latest/dg/invoking-lambda-function.html).\n\nin most cases, it is possible to trigger a function as a result of an event by\nusing one of the `add<event>notification` methods on the source construct. for\nexample, the `s3.bucket` construct has an `onevent` method which can be used to\ntrigger a lambda when an event, such as putobject occurs on an s3 bucket.\n\nan alternative way to add event sources to a function is to use `function.addeventsource(source)`.\nthis method accepts an `ieventsource` object. the module **@aws-cdk/aws-lambda-event-sources**\nincludes classes for the various event sources supported by aws lambda.\n\nfor example, the following code adds an sqs queue as an event source for a function:\n\n```python\nimport aws_cdk.aws_lambda_event_sources as eventsources\nimport aws_cdk.aws_sqs as sqs\n\n# fn: lambda.function\n\nqueue = sqs.queue(self, \"queue\")\nfn.add_event_source(eventsources.sqseventsource(queue))\n```\n\nthe following code adds an s3 bucket notification as an event source:\n\n```python\nimport aws_cdk.aws_lambda_event_sources as eventsources\nimport aws_cdk.aws_s3 as s3\n\n# fn: lambda.function\n\nbucket = s3.bucket(self, \"bucket\")\nfn.add_event_source(eventsources.s3eventsource(bucket,\n    events=[s3.eventtype.object_created, s3.eventtype.object_removed],\n    filters=[s3.notificationkeyfilter(prefix=\"subdir/\")]\n))\n```\n\nsee the documentation for the **@aws-cdk/aws-lambda-event-sources** module for more details.\n\n## imported lambdas\n\nwhen referencing an imported lambda in the cdk, use `fromfunctionarn()` for most use cases:\n\n```python\nfn = lambda_.function.from_function_arn(self, \"function\", \"arn:aws:lambda:us-east-1:123456789012:function:myfn\")\n```\n\nthe `fromfunctionattributes()` api is available for more specific use cases:\n\n```python\nfn = lambda_.function.from_function_attributes(self, \"function\",\n    function_arn=\"arn:aws:lambda:us-east-1:123456789012:function:myfn\",\n    # the following are optional properties for specific use cases and should be used with caution:\n\n    # use case: imported function is in the same account as the stack. this tells the cdk that it\n    # can modify the function's permissions.\n    same_environment=true,\n\n    # use case: imported function is in a different account and user commits to ensuring that the\n    # imported function has the correct permissions outside the cdk.\n    skip_permissions=true\n)\n```\n\nif `fromfunctionarn()` causes an error related to having to provide an account and/or region in a different construct,\nand the lambda is in the same account and region as the stack you're importing it into,\nyou can use `function.fromfunctionname()` instead:\n\n```python\nfn = lambda_.function.from_function_name(self, \"function\", \"myfn\")\n```\n\n## lambda with dlq\n\na dead-letter queue can be automatically created for a lambda function by\nsetting the `deadletterqueueenabled: true` configuration. in such case cdk creates\na `sqs.queue` as `deadletterqueue`.\n\n```python\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_inline(\"exports.handler = function(event, ctx, cb) { return cb(null, \\\"hi\\\"); }\"),\n    dead_letter_queue_enabled=true\n)\n```\n\nit is also possible to provide a dead-letter queue instead of getting a new queue created:\n\n```python\nimport aws_cdk.aws_sqs as sqs\n\n\ndlq = sqs.queue(self, \"dlq\")\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_inline(\"exports.handler = function(event, ctx, cb) { return cb(null, \\\"hi\\\"); }\"),\n    dead_letter_queue=dlq\n)\n```\n\nyou can also use a `sns.topic` instead of an `sqs.queue` as dead-letter queue:\n\n```python\nimport aws_cdk.aws_sns as sns\n\n\ndlt = sns.topic(self, \"dlq\")\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_inline(\"// your code here\"),\n    dead_letter_topic=dlt\n)\n```\n\nsee [the aws documentation](https://docs.aws.amazon.com/lambda/latest/dg/dlq.html)\nto learn more about aws lambdas and dlqs.\n\n## lambda with x-ray tracing\n\n```python\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_inline(\"exports.handler = function(event, ctx, cb) { return cb(null, \\\"hi\\\"); }\"),\n    tracing=lambda_.tracing.active\n)\n```\n\nsee [the aws documentation](https://docs.aws.amazon.com/lambda/latest/dg/lambda-x-ray.html)\nto learn more about aws lambda's x-ray support.\n\n## lambda with profiling\n\nthe following code configures the lambda function with codeguru profiling. by default, this creates a new codeguru\nprofiling group -\n\n```python\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.python_3_9,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(\"lambda-handler\"),\n    profiling=true\n)\n```\n\nthe `profilinggroup` property can be used to configure an existing codeguru profiler group.\n\ncodeguru profiling is supported for all java runtimes and python3.6+ runtimes.\n\nsee [the aws documentation](https://docs.aws.amazon.com/codeguru/latest/profiler-ug/setting-up-lambda.html)\nto learn more about aws lambda's profiling support.\n\n## lambda with reserved concurrent executions\n\n```python\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_inline(\"exports.handler = function(event, ctx, cb) { return cb(null, \\\"hi\\\"); }\"),\n    reserved_concurrent_executions=100\n)\n```\n\nsee [the aws documentation](https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html)\nmanaging concurrency.\n\n## autoscaling\n\nyou can use application autoscaling to automatically configure the provisioned concurrency for your functions. autoscaling can be set to track utilization or be based on a schedule. to configure autoscaling on a function alias:\n\n```python\nimport aws_cdk.aws_autoscaling as autoscaling\n\n# fn: lambda.function\n\nalias = fn.add_alias(\"prod\")\n\n# create autoscaling target\nas = alias.add_auto_scaling(max_capacity=50)\n\n# configure target tracking\nas.scale_on_utilization(\n    utilization_target=0.5\n)\n\n# configure scheduled scaling\nas.scale_on_schedule(\"scaleupinthemorning\",\n    schedule=autoscaling.schedule.cron(hour=\"8\", minute=\"0\"),\n    min_capacity=20\n)\n```\n\n```python\nimport aws_cdk.aws_applicationautoscaling as appscaling\nimport aws_cdk.core as cdk\nfrom aws_cdk.cx_api import lambda_recognize_layer_version\nimport aws_cdk.aws_lambda as lambda_\n\n#\n# stack verification steps:\n# aws application-autoscaling describe-scalable-targets --service-namespace lambda --resource-ids function:<function name>:prod\n# has a mincapacity of 3 and maxcapacity of 50\n#\nclass teststack(cdk.stack):\n    def __init__(self, scope, id):\n        super().__init__(scope, id)\n\n        fn = lambda_.function(self, \"mylambda\",\n            code=lambda_.inlinecode(\"exports.handler = async () => { console.log('hello world'); };\"),\n            handler=\"index.handler\",\n            runtime=lambda_.runtime.nodejs_14_x\n        )\n\n        version = fn.current_version\n\n        alias = lambda_.alias(self, \"alias\",\n            alias_name=\"prod\",\n            version=version\n        )\n\n        scaling_target = alias.add_auto_scaling(min_capacity=3, max_capacity=50)\n\n        scaling_target.scale_on_utilization(\n            utilization_target=0.5\n        )\n\n        scaling_target.scale_on_schedule(\"scaleupinthemorning\",\n            schedule=appscaling.schedule.cron(hour=\"8\", minute=\"0\"),\n            min_capacity=20\n        )\n\n        scaling_target.scale_on_schedule(\"scaledownatnight\",\n            schedule=appscaling.schedule.cron(hour=\"20\", minute=\"0\"),\n            max_capacity=20\n        )\n\n        cdk.cfnoutput(self, \"functionname\",\n            value=fn.function_name\n        )\n\napp = cdk.app()\n\nstack = teststack(app, \"aws-lambda-autoscaling\")\n\n# changes the function description when the feature flag is present\n# to validate the changed function hash.\ncdk.aspects.of(stack).add(lambda_.functionversionupgrade(lambda_recognize_layer_version))\n\napp.synth()\n```\n\nsee [the aws documentation](https://docs.aws.amazon.com/lambda/latest/dg/invocation-scaling.html) on autoscaling lambda functions.\n\n## log group\n\nlambda functions automatically create a log group with the name `/aws/lambda/<function-name>` upon first execution with\nlog data set to never expire.\n\nthe `logretention` property can be used to set a different expiration period.\n\nit is possible to obtain the function's log group as a `logs.iloggroup` by calling the `loggroup` property of the\n`function` construct.\n\nby default, cdk uses the aws sdk retry options when creating a log group. the `logretentionretryoptions` property\nallows you to customize the maximum number of retries and base backoff duration.\n\n*note* that, if either `logretention` is set or `loggroup` property is called, a [cloudformation custom\nresource](https://docs.aws.amazon.com/awscloudformation/latest/userguide/aws-resource-cfn-customresource.html) is added\nto the stack that pre-creates the log group as part of the stack deployment, if it already doesn't exist, and sets the\ncorrect log retention period (never expire, by default).\n\n*further note* that, if the log group already exists and the `logretention` is not set, the custom resource will reset\nthe log retention to never expire even if it was configured with a different value.\n\n## filesystem access\n\nyou can configure a function to mount an amazon elastic file system (amazon efs) to a\ndirectory in your runtime environment with the `filesystem` property. to access amazon efs\nfrom lambda function, the amazon efs access point will be required.\n\nthe following sample allows the lambda function to mount the amazon efs access point to `/mnt/msg` in the runtime environment and access the filesystem with the posix identity defined in `posixuser`.\n\n```python\nimport aws_cdk.aws_ec2 as ec2\nimport aws_cdk.aws_efs as efs\n\n\n# create a new vpc\nvpc = ec2.vpc(self, \"vpc\")\n\n# create a new amazon efs filesystem\nfile_system = efs.filesystem(self, \"efs\", vpc=vpc)\n\n# create a new access point from the filesystem\naccess_point = file_system.add_access_point(\"accesspoint\",\n    # set /export/lambda as the root of the access point\n    path=\"/export/lambda\",\n    # as /export/lambda does not exist in a new efs filesystem, the efs will create the directory with the following createacl\n    create_acl=efs.acl(\n        owner_uid=\"1001\",\n        owner_gid=\"1001\",\n        permissions=\"750\"\n    ),\n    # enforce the posix identity so lambda function will access with this identity\n    posix_user=efs.posixuser(\n        uid=\"1001\",\n        gid=\"1001\"\n    )\n)\n\nfn = lambda_.function(self, \"mylambda\",\n    # mount the access point to /mnt/msg in the lambda runtime environment\n    filesystem=lambda_.filesystem.from_efs_access_point(access_point, \"/mnt/msg\"),\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    vpc=vpc\n)\n```\n\n## ephemeral storage\n\nyou can configure ephemeral storage on a function to control the amount of storage it gets for reading\nor writing data, allowing you to use aws lambda for etl jobs, ml inference, or other data-intensive workloads.\nthe ephemeral storage will be accessible in the functions' `/tmp` directory.\n\n```python\nfrom aws_cdk.core import size\n\n\nfn = lambda_.function(self, \"myfunction\",\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\")),\n    ephemeral_storage_size=size.mebibytes(1024)\n)\n```\n\nread more about using this feature in [this aws blog post](https://aws.amazon.com/blogs/aws/aws-lambda-now-supports-up-to-10-gb-ephemeral-storage/).\n\n## singleton function\n\nthe `singletonfunction` construct is a way to guarantee that a lambda function will be guaranteed to be part of the stack,\nonce and only once, irrespective of how many times the construct is declared to be part of the stack. this is guaranteed\nas long as the `uuid` property and the optional `lambdapurpose` property stay the same whenever they're declared into the\nstack.\n\na typical use case of this function is when a higher level construct needs to declare a lambda function as part of it but\nneeds to guarantee that the function is declared once. however, a user of this higher level construct can declare it any\nnumber of times and with different properties. using `singletonfunction` here with a fixed `uuid` will guarantee this.\n\nfor example, the `logretention` construct requires only one single lambda function for all different log groups whose\nretention it seeks to manage.\n\n## bundling asset code\n\nwhen using `lambda.code.fromasset(path)` it is possible to bundle the code by running a\ncommand in a docker container. the asset path will be mounted at `/asset-input`. the\ndocker container is responsible for putting content at `/asset-output`. the content at\n`/asset-output` will be zipped and used as lambda code.\n\nexample with python:\n\n```python\nlambda_.function(self, \"function\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"my-python-handler\"),\n        bundling=bundlingoptions(\n            image=lambda_.runtime.python_3_9.bundling_image,\n            command=[\"bash\", \"-c\", \"pip install -r requirements.txt -t /asset-output && cp -au . /asset-output\"\n            ]\n        )\n    ),\n    runtime=lambda_.runtime.python_3_9,\n    handler=\"index.handler\"\n)\n```\n\nruntimes expose a `bundlingimage` property that points to the [aws sam](https://github.com/awslabs/aws-sam-cli) build image.\n\nuse `cdk.dockerimage.fromregistry(image)` to use an existing image or\n`cdk.dockerimage.frombuild(path)` to build a specific image:\n\n```python\nlambda_.function(self, \"function\",\n    code=lambda_.code.from_asset(\"/path/to/handler\",\n        bundling=bundlingoptions(\n            image=dockerimage.from_build(\"/path/to/dir/with/dockerfile\",\n                build_args={\n                    \"arg1\": \"value1\"\n                }\n            ),\n            command=[\"my\", \"cool\", \"command\"]\n        )\n    ),\n    runtime=lambda_.runtime.python_3_9,\n    handler=\"index.handler\"\n)\n```\n\n## language-specific apis\n\nlanguage-specific higher level constructs are provided in separate modules:\n\n* `@aws-cdk/aws-lambda-nodejs`: [github](https://github.com/aws/aws-cdk/tree/master/packages/%40aws-cdk/aws-lambda-nodejs) & [cdk docs](https://docs.aws.amazon.com/cdk/api/latest/docs/aws-lambda-nodejs-readme.html)\n* `@aws-cdk/aws-lambda-python`: [github](https://github.com/aws/aws-cdk/tree/master/packages/%40aws-cdk/aws-lambda-python) & [cdk docs](https://docs.aws.amazon.com/cdk/api/latest/docs/aws-lambda-python-readme.html)\n\n## code signing\n\ncode signing for aws lambda helps to ensure that only trusted code runs in your lambda functions.\nwhen enabled, aws lambda checks every code deployment and verifies that the code package is signed by a trusted source.\nfor more information, see [configuring code signing for aws lambda](https://docs.aws.amazon.com/lambda/latest/dg/configuration-codesigning.html).\nthe following code configures a function with code signing.\n\n```python\nimport aws_cdk.aws_signer as signer\n\n\nsigning_profile = signer.signingprofile(self, \"signingprofile\",\n    platform=signer.platform.aws_lambda_sha384_ecdsa\n)\n\ncode_signing_config = lambda_.codesigningconfig(self, \"codesigningconfig\",\n    signing_profiles=[signing_profile]\n)\n\nlambda_.function(self, \"function\",\n    code_signing_config=code_signing_config,\n    runtime=lambda_.runtime.nodejs_16_x,\n    handler=\"index.handler\",\n    code=lambda_.code.from_asset(path.join(__dirname, \"lambda-handler\"))\n)\n```\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache-2.0",
  "name": "aws-cdk.aws-lambda",
  "package_url": "https://pypi.org/project/aws-cdk.aws-lambda/",
  "project_url": "https://pypi.org/project/aws-cdk.aws-lambda/",
  "project_urls": {
    "Homepage": "https://github.com/aws/aws-cdk",
    "Source": "https://github.com/aws/aws-cdk.git"
  },
  "release_url": "https://pypi.org/project/aws-cdk.aws-lambda/1.204.0/",
  "requires_dist": [
    "aws-cdk.aws-applicationautoscaling (==1.204.0)",
    "aws-cdk.aws-cloudwatch (==1.204.0)",
    "aws-cdk.aws-codeguruprofiler (==1.204.0)",
    "aws-cdk.aws-ec2 (==1.204.0)",
    "aws-cdk.aws-ecr-assets (==1.204.0)",
    "aws-cdk.aws-ecr (==1.204.0)",
    "aws-cdk.aws-efs (==1.204.0)",
    "aws-cdk.aws-events (==1.204.0)",
    "aws-cdk.aws-iam (==1.204.0)",
    "aws-cdk.aws-kms (==1.204.0)",
    "aws-cdk.aws-logs (==1.204.0)",
    "aws-cdk.aws-s3-assets (==1.204.0)",
    "aws-cdk.aws-s3 (==1.204.0)",
    "aws-cdk.aws-signer (==1.204.0)",
    "aws-cdk.aws-sns (==1.204.0)",
    "aws-cdk.aws-sqs (==1.204.0)",
    "aws-cdk.core (==1.204.0)",
    "aws-cdk.cx-api (==1.204.0)",
    "aws-cdk.region-info (==1.204.0)",
    "constructs (<4.0.0,>=3.3.69)",
    "jsii (<2.0.0,>=1.84.0)",
    "publication (>=0.0.3)",
    "typeguard (~=2.13.3)"
  ],
  "requires_python": "~=3.7",
  "summary": "the cdk construct library for aws::lambda",
  "version": "1.204.0",
  "releases": [],
  "developers": [
    "amazon_web_services"
  ],
  "kwds": "aws_lambda aws_cdk aws_lambda_event_sources aws_lambda_sha384_ecdsa aws_s3",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_aws_cdk.aws_lambda",
  "homepage": "https://github.com/aws/aws-cdk",
  "release_count": 258,
  "dependency_ids": [
    "pypi_aws_cdk.aws_applicationautoscaling",
    "pypi_aws_cdk.aws_cloudwatch",
    "pypi_aws_cdk.aws_codeguruprofiler",
    "pypi_aws_cdk.aws_ec2",
    "pypi_aws_cdk.aws_ecr",
    "pypi_aws_cdk.aws_ecr_assets",
    "pypi_aws_cdk.aws_efs",
    "pypi_aws_cdk.aws_events",
    "pypi_aws_cdk.aws_iam",
    "pypi_aws_cdk.aws_kms",
    "pypi_aws_cdk.aws_logs",
    "pypi_aws_cdk.aws_s3",
    "pypi_aws_cdk.aws_s3_assets",
    "pypi_aws_cdk.aws_signer",
    "pypi_aws_cdk.aws_sns",
    "pypi_aws_cdk.aws_sqs",
    "pypi_aws_cdk.core",
    "pypi_aws_cdk.cx_api",
    "pypi_aws_cdk.region_info",
    "pypi_constructs",
    "pypi_jsii",
    "pypi_publication",
    "pypi_typeguard"
  ]
}