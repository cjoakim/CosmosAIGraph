{
  "classifiers": [
    "license :: osi approved :: apache software license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# databricks sql connector for python\n\n[![pypi](https://img.shields.io/pypi/v/databricks-sql-connector?style=flat-square)](https://pypi.org/project/databricks-sql-connector/)\n[![downloads](https://pepy.tech/badge/databricks-sql-connector)](https://pepy.tech/project/databricks-sql-connector)\n\nthe databricks sql connector for python allows you to develop python applications that connect to databricks clusters and sql warehouses. it is a thrift-based client with no dependencies on odbc or jdbc. it conforms to the [python db api 2.0 specification](https://www.python.org/dev/peps/pep-0249/) and exposes a [sqlalchemy](https://www.sqlalchemy.org/) dialect for use with tools like `pandas` and `alembic` which use sqlalchemy to execute ddl. use `pip install databricks-sql-connector[sqlalchemy]` to install with sqlalchemy's dependencies. `pip install databricks-sql-connector[alembic]` will install alembic's dependencies.\n\nthis connector uses arrow as the data-exchange format, and supports apis to directly fetch arrow tables. arrow tables are wrapped in the `arrowqueue` class to provide a natural api to get several rows at a time.\n\nyou are welcome to file an issue here for general use cases. you can also contact databricks support [here](help.databricks.com).\n\n## requirements\n\npython 3.8 or above is required.\n\n## documentation\n\nfor the latest documentation, see\n\n- [databricks](https://docs.databricks.com/dev-tools/python-sql-connector.html)\n- [azure databricks](https://docs.microsoft.com/en-us/azure/databricks/dev-tools/python-sql-connector)\n\n## quickstart\n\ninstall the library with `pip install databricks-sql-connector`\n\nnote: don't hard-code authentication secrets into your python. use environment variables\n\n```bash\nexport databricks_host=********.databricks.com\nexport databricks_http_path=/sql/1.0/endpoints/****************\nexport databricks_token=dapi********************************\n```\n\nexample usage:\n```python\nimport os\nfrom databricks import sql\n\nhost = os.getenv(\"databricks_host\")\nhttp_path = os.getenv(\"databricks_http_path\")\naccess_token = os.getenv(\"databricks_token\")\n\nconnection = sql.connect(\n  server_hostname=host,\n  http_path=http_path,\n  access_token=access_token)\n\ncursor = connection.cursor()\ncursor.execute('select :param `p`, * from range(10)', {\"param\": \"foo\"})\nresult = cursor.fetchall()\nfor row in result:\n  print(row)\n\ncursor.close()\nconnection.close()\n```\n\nin the above example:\n- `server-hostname` is the databricks instance host name.\n- `http-path` is the http path either to a databricks sql endpoint (e.g. /sql/1.0/endpoints/1234567890abcdef),\nor to a databricks runtime interactive cluster (e.g. /sql/protocolv1/o/1234567890123456/1234-123456-slid123)\n- `personal-access-token` is the databricks personal access token for the account that will execute commands and queries\n\n\n## contributing\n\nsee [contributing.md](contributing.md)\n\n## license\n\n[apache license 2.0](license)\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache-2.0",
  "name": "databricks-sql-connector",
  "package_url": "https://pypi.org/project/databricks-sql-connector/",
  "project_url": "https://pypi.org/project/databricks-sql-connector/",
  "project_urls": {
    "Bug Tracker": "https://github.com/databricks/databricks-sql-python/issues",
    "Homepage": "https://github.com/databricks/databricks-sql-python"
  },
  "release_url": "https://pypi.org/project/databricks-sql-connector/3.0.1/",
  "requires_dist": [
    "thrift (>=0.16.0,<0.17.0)",
    "pandas (>=1.2.5,<3.0.0) ; python_version >= \"3.8\"",
    "pyarrow (>=14.0.1,<15.0.0)",
    "lz4 (>=4.0.2,<5.0.0)",
    "requests (>=2.18.1,<3.0.0)",
    "oauthlib (>=3.1.0,<4.0.0)",
    "numpy (>=1.16.6) ; python_version >= \"3.8\" and python_version < \"3.11\"",
    "numpy (>=1.23.4) ; python_version >= \"3.11\"",
    "sqlalchemy (>=2.0.21) ; extra == \"sqlalchemy\" or extra == \"alembic\"",
    "openpyxl (>=3.0.10,<4.0.0)",
    "alembic (>=1.0.11,<2.0.0) ; extra == \"alembic\"",
    "urllib3 (>=1.0)"
  ],
  "requires_python": ">=3.8.0,<4.0.0",
  "summary": "databricks sql connector for python",
  "version": "3.0.1",
  "releases": [],
  "developers": [
    "databricks",
    "databricks-sql-connector-maintainers@databricks.com"
  ],
  "kwds": "databricks databricks_host databricks_http_path databricks_token sqlalchemy",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_databricks_sql_connector",
  "homepage": "",
  "release_count": 52,
  "dependency_ids": [
    "pypi_alembic",
    "pypi_lz4",
    "pypi_numpy",
    "pypi_oauthlib",
    "pypi_openpyxl",
    "pypi_pandas",
    "pypi_pyarrow",
    "pypi_requests",
    "pypi_sqlalchemy",
    "pypi_thrift",
    "pypi_urllib3"
  ]
}