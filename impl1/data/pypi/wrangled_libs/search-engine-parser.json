{
  "classifiers": [
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3"
  ],
  "description": "# search engine parser\n\n<span><i>\"if it is a search engine, then it can be parsed\"</i> - some random guy</span>\n\n![demo](https://github.com/bisoncorps/search-engine-parser/raw/master/assets/animate.gif)\n\n[![python 3.6|3.7|3.8|3.9](https://img.shields.io/badge/python-3.5%7c3.6%7c3.7%7c3.8-blue)](https://www.python.org/downloads/)\n[![pypi version](https://img.shields.io/pypi/v/search-engine-parser)](https://pypi.org/project/search-engine-parser/)\n[![pypi - downloads](https://img.shields.io/pypi/dm/search-engine-parser)](https://pypi.org/project/search-engine-parser/)\n[![deploy to pypi](https://github.com/bisohns/search-engine-parser/actions/workflows/deploy.yml/badge.svg)](https://github.com/bisohns/search-engine-parser/actions/workflows/deploy.yml)\n[![test](https://github.com/bisohns/search-engine-parser/actions/workflows/test.yml/badge.svg)](https://github.com/bisohns/search-engine-parser/actions/workflows/test.yml)\n[![documentation status](https://readthedocs.org/projects/search-engine-parser/badge/?version=latest)](https://search-engine-parser.readthedocs.io/en/latest/?badge=latest)\n[![license: mit](https://img.shields.io/badge/license-mit-yellow.svg)](https://opensource.org/licenses/mit)\n[![all contributors](https://img.shields.io/badge/all_contributors-10-orange.svg)](#contributors)\n<hr/>\n\nsearch-engine-parser is a package that lets you query popular search engines and scrape for result titles, links, descriptions and more. it aims to scrape the widest range of search engines.\nview all supported engines [here.](https://github.com/bisoncorps/search-engine-parser/blob/master/docs/supported_engines.md)\n\n- [search engine parser](#search-engine-parser)\n  - [popular supported engines](#popular-supported-engines)\n  - [installation](#installation)\n  - [development](#development)\n  - [code documentation](#code-documentation)\n  - [running the tests](#running-the-tests)\n  - [usage](#usage)\n    - [code](#code)\n    - [command line](#command-line)\n  - [faq](docs/faq.md)\n  - [code of conduct](#code-of-conduct)\n  - [contribution](#contribution)\n  - [license (mit)](#license-mit)\n\n## popular supported engines\npopular search engines supported include:\n\n- google\n- duckduckgo\n- github\n- stackoverflow\n- baidu\n- youtube\n\nview all supported engines [here.](docs/supported_engines.md)\n\n## installation\ninstall from pypi:\n\n```bash\n    # install only package dependencies\n    pip install search-engine-parser\n    # installs `pysearch` cli  tool\n    pip install \"search-engine-parser[cli]\"\n```\n\nor from master:\n```bash\n  pip install git+https://github.com/bisoncorps/search-engine-parser\n```\n\n## development\nclone the repository:\n\n```bash\n    git clone git@github.com:bisoncorps/search-engine-parser.git\n```\n\nthen create a virtual environment and install the required packages:\n\n```bash\n    mkvirtualenv search_engine_parser\n    pip install -r requirements/dev.txt\n```\n\n\n## code documentation\ncode docs can be found on [read the docs](https://search-engine-parser.readthedocs.io/en/latest).\n\n## running the tests\n```bash\n    pytest\n```\n\n## usage\n\n### code\nquery results can be scraped from popular search engines, as shown in the example snippet below.\n\n```python\n  import pprint\n\n  from search_engine_parser.core.engines.bing import search as bingsearch\n  from search_engine_parser.core.engines.google import search as googlesearch\n  from search_engine_parser.core.engines.yahoo import search as yahoosearch\n\n  search_args = ('preaching to the choir', 1)\n  gsearch = googlesearch()\n  ysearch = yahoosearch()\n  bsearch = bingsearch()\n  gresults = gsearch.search(*search_args)\n  yresults = ysearch.search(*search_args)\n  bresults = bsearch.search(*search_args)\n  a = {\n      \"google\": gresults,\n      \"yahoo\": yresults,\n      \"bing\": bresults\n      }\n\n  # pretty print the result from each engine\n  for k, v in a.items():\n      print(f\"-------------{k}------------\")\n      for result in v:\n          pprint.pprint(result)\n\n  # print first title from google search\n  print(gresults[\"titles\"][0])\n  # print 10th link from yahoo search\n  print(yresults[\"links\"][9])\n  # print 6th description from bing search\n  print(bresults[\"descriptions\"][5])\n\n  # print first result containing links, descriptions and title\n  print(gresults[0])\n```\n\nfor localization, you can pass the `url` keyword and a localized url. this queries and parses the localized url using the same engine's parser:\n```python\n  # use google.de instead of google.com\n  results = gsearch.search(*search_args, url=\"google.de\")\n```\n\nif you need results in a specific language you can pass the 'hl' keyword and the 2-letter country abbreviation (here's a [handy list](https://en.wikipedia.org/wiki/list_of_iso_639-1_codes)):\n```python\n  # use 'it' to receive italian results\n  results = gsearch.search(*search_args, hl=\"it\")\n```\n\n#### cache\nthe results are automatically cached for engine searches. you can either bypass the cache by adding `cache=false` to the `search` or `async_search` method or clear the engine's cache\n```python\n    from search_engine_parser.core.engines.github import search as github\n    github = github()\n    # bypass the cache\n    github.search(\"search-engine-parser\", cache=false)\n\n    #or\n    # clear cache before search\n    github.clear_cache()\n    github.search(\"search-engine-parser\")\n```\n\n#### proxy\nadding a proxy entails sending details to the search function\n```python\n    from search_engine_parser.core.engines.github import search as github\n    github = github()\n    github.search(\"search-engine-parser\",\n        # http proxies supported only\n        proxy='http://123.12.1.0',\n        proxy_auth=('username', 'password'))\n```\n\n\n#### async\nsearch-engine-parser supports `async`:\n```python\n   results = await gsearch.async_search(*search_args)\n```\n\n#### results\nthe `searchresults` after searching:\n```python\n  >>> results = gsearch.search(\"preaching to the choir\", 1)\n  >>> results\n  <search_engine_parser.core.base.searchresult object at 0x7f907426a280>\n  # the object supports retrieving individual results by iteration of just by type (links, descriptions, titles)\n  >>> results[0] # returns the first <searchitem>\n  >>> results[0][\"description\"] # gets the description of the first item\n  >>> results[0][\"link\"] # gets the link of the first item\n  >>> results[\"descriptions\"] # returns a list of all descriptions from all results\n```\nit can be iterated like a normal list to return individual `searchitem`s.\n\n### command line\n\nsearch-engine-parser comes with a cli tool known as `pysearch`. you can use it as such:\n\n```bash\npysearch --engine bing  --type descriptions \"preaching to the choir\"\n```\n\nresult:\n\n```bash\n'preaching to the choir' originated in the usa in the 1970s. it is a variant of the earlier 'preaching to the converted', which dates from england in the late 1800s and has the same meaning. origin - the full story 'preaching to the choir' (also sometimes spelled quire) is of us origin.\n```\n\n![demo](https://github.com/bisoncorps/search-engine-parser/raw/master/assets/example.gif)\n\n```bash\nusage: pysearch [-h] [-v] [-e engine] [--show-summary] [-u url] [-p page]\n                [-t type] [-cc] [-r rank] [--proxy proxy]\n                [--proxy-user proxy_user] [--proxy-password proxy_password]\n                query\n\nsearchengineparser\n\npositional arguments:\n  query                 query string to search engine for\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  -e engine, --engine engine\n                        engine to use for parsing the query e.g google, yahoo,\n                        bing,duckduckgo (default: google)\n  --show-summary        shows the summary of an engine\n  -u url, --url url     a custom link to use as base url for search e.g\n                        google.de\n  -p page, --page page  page of the result to return details for (default: 1)\n  -t type, --type type  type of detail to return i.e full, links, desciptions\n                        or titles (default: full)\n  -cc, --clear-cache    clear cache of engine before searching\n  -r rank, --rank rank  id of detail to return e.g 5 (default: 0)\n  --proxy proxy         proxy address to make use of\n  --proxy-user proxy_user\n                        proxy user to make use of\n  --proxy-password proxy_password\n                        proxy password to make use of\n```\n\n\n\n## code of conduct\nmake sure to adhere to the [code of conduct](code_of_conduct.md) at all times.\n\n## contribution\nbefore making any contributions, please read the [contribution guide](contributing.md).\n\n## license (mit)\nthis project is licensed under the [mit 2.0 license](license) which allows very broad use for both academic and commercial purposes.\n\n## contributors \u2728\n\nthanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- all-contributors-list:start - do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/rexogamer\"><img src=\"https://avatars0.githubusercontent.com/u/42586271?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>ed luff</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=rexogamer\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"http://diretnandomnan.webnode.com\"><img src=\"https://avatars3.githubusercontent.com/u/23453888?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>diretnan domnan</b></sub></a><br /><a href=\"#infra-deven96\" title=\"infrastructure (hosting, build-tools, etc)\">\ud83d\ude87</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=deven96\" title=\"tests\">\u26a0\ufe0f</a> <a href=\"#tool-deven96\" title=\"tools\">\ud83d\udd27</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=deven96\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"http://mensaah.github.io\"><img src=\"https://avatars3.githubusercontent.com/u/24734308?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>mensaah</b></sub></a><br /><a href=\"#infra-mensaah\" title=\"infrastructure (hosting, build-tools, etc)\">\ud83d\ude87</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=mensaah\" title=\"tests\">\u26a0\ufe0f</a> <a href=\"#tool-mensaah\" title=\"tools\">\ud83d\udd27</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=mensaah\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/paladitya\"><img src=\"https://avatars2.githubusercontent.com/u/25523604?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>aditya pal</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=paladitya\" title=\"tests\">\u26a0\ufe0f</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=paladitya\" title=\"code\">\ud83d\udcbb</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=paladitya\" title=\"documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"http://energized.pro\"><img src=\"https://avatars1.githubusercontent.com/u/27774996?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>avinash reddy</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/issues?q=author%3aavinashreddy3108\" title=\"bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/iamdavidonuh\"><img src=\"https://avatars3.githubusercontent.com/u/37768509?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>david onuh</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=iamdavidonuh\" title=\"code\">\ud83d\udcbb</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=iamdavidonuh\" title=\"tests\">\u26a0\ufe0f</a></td>\n    <td align=\"center\"><a href=\"http://simakis.me\"><img src=\"https://avatars2.githubusercontent.com/u/8322266?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>panagiotis simakis</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=sp1thas\" title=\"code\">\ud83d\udcbb</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=sp1thas\" title=\"tests\">\u26a0\ufe0f</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/reiarthur\"><img src=\"https://avatars2.githubusercontent.com/u/20190646?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>reiarthur</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=reiarthur\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"http://ashokkumarta.blogspot.com/\"><img src=\"https://avatars0.githubusercontent.com/u/5450267?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>ashokkumar ta</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=ashokkumarta\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/ateuber\"><img src=\"https://avatars2.githubusercontent.com/u/44349054?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>andreas teuber</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=ateuber\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/mi096684\"><img src=\"https://avatars3.githubusercontent.com/u/22032932?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>mi096684</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/issues?q=author%3ami096684\" title=\"bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/devajithvs\"><img src=\"https://avatars1.githubusercontent.com/u/29475282?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>devajithvs</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=devajithvs\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/zakaryan2004\"><img src=\"https://avatars3.githubusercontent.com/u/29994884?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>geg zakaryan</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=zakaryan2004\" title=\"code\">\ud83d\udcbb</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/issues?q=author%3azakaryan2004\" title=\"bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://www.hakanbogan.com\"><img src=\"https://avatars1.githubusercontent.com/u/24498747?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>hakan bo\u011fan</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/issues?q=author%3aredrussianarmy\" title=\"bug reports\">\ud83d\udc1b</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/nickoehler\"><img src=\"https://avatars3.githubusercontent.com/u/53040044?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>nickoehler</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/issues?q=author%3anickoehler\" title=\"bug reports\">\ud83d\udc1b</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=nickoehler\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/chris4540\"><img src=\"https://avatars1.githubusercontent.com/u/12794588?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>chrislin</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/issues?q=author%3achris4540\" title=\"bug reports\">\ud83d\udc1b</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=chris4540\" title=\"code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"http://pete.world\"><img src=\"https://avatars.githubusercontent.com/u/10454135?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>pietro</b></sub></a><br /><a href=\"https://github.com/bisoncorps/search-engine-parser/commits?author=pgrandinetti\" title=\"code\">\ud83d\udcbb</a> <a href=\"https://github.com/bisoncorps/search-engine-parser/issues?q=author%3apgrandinetti\" title=\"bug reports\">\ud83d\udc1b</a></td>\n  </tr>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- all-contributors-list:end -->\n\nthis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. contributions of any kind welcome!\n",
  "docs_url": null,
  "keywords": "search-engine         search         parser         google         yahoo         bing         yandex         stackoverflow         github         baidu",
  "license": "mit",
  "name": "search-engine-parser",
  "package_url": "https://pypi.org/project/search-engine-parser/",
  "project_url": "https://pypi.org/project/search-engine-parser/",
  "project_urls": {
    "Documentation": "https://search-engine-parser.readthedocs.io/en/latest",
    "Homepage": "https://github.com/bisoncorps/search-engine-parser",
    "Source": "https://github.com/bisoncorps/search-engine-parser"
  },
  "release_url": "https://pypi.org/project/search-engine-parser/0.6.8/",
  "requires_dist": [
    "lxml (<5,>=4.6.5)",
    "aiohttp (<4,>=3.6.2)",
    "beautifulsoup4 (<5,>=4.9.1)",
    "fake-useragent (<0.2,>=0.1.11)",
    "blessed (<2,>=1.15.0) ; extra == 'cli'"
  ],
  "requires_python": ">=3.5",
  "summary": "scrapes search engine pages for query titles, descriptions and links",
  "version": "0.6.8",
  "releases": [],
  "developers": [
    "diretnandomnan@gmail.com",
    "domnan_diretnan"
  ],
  "kwds": "search_engine_parser bingsearch searchengineparser googlesearch searches",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_search_engine_parser",
  "homepage": "https://github.com/bisoncorps/search-engine-parser",
  "release_count": 22,
  "dependency_ids": [
    "pypi_aiohttp",
    "pypi_beautifulsoup4",
    "pypi_blessed",
    "pypi_fake_useragent",
    "pypi_lxml"
  ]
}