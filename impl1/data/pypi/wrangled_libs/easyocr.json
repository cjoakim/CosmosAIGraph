{
  "classifiers": [
    "development status :: 5 - production/stable"
  ],
  "description": "# easyocr\n\n[![pypi status](https://badge.fury.io/py/easyocr.svg)](https://badge.fury.io/py/easyocr)\n[![license](https://img.shields.io/badge/license-apache%202.0-blue.svg)](https://github.com/jaidedai/easyocr/blob/master/license)\n[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.to/easyocr)\n[![tweet](https://img.shields.io/twitter/url/https/github.com/jaidedai/easyocr.svg?style=social)](https://twitter.com/intent/tweet?text=check%20out%20this%20awesome%20library:%20easyocr%20https://github.com/jaidedai/easyocr)\n[![twitter](https://img.shields.io/badge/twitter-@jaidedai-blue.svg?style=flat)](https://twitter.com/jaidedai)\n\nready-to-use ocr with 80+ [supported languages](https://www.jaided.ai/easyocr) and all popular writing scripts including: latin, chinese, arabic, devanagari, cyrillic, etc.\n\n[try demo on our website](https://www.jaided.ai/easyocr)\n\nintegrated into [huggingface spaces \ud83e\udd17](https://huggingface.co/spaces) using [gradio](https://github.com/gradio-app/gradio). try out the web demo: [![hugging face spaces](https://img.shields.io/badge/%f0%9f%a4%97%20hugging%20face-spaces-blue)](https://huggingface.co/spaces/tomofi/easyocr)\n\n\n## what's new\n- 4 september 2023 - version 1.7.1\n    - fix several compatibilities\n- 25 may 2023 - version 1.7.0\n    - add apple silicon support (thanks[@rayeesoft](https://github.com/rayeesoft) and [@artembernatskyy](https://github.com/artembernatskyy), see [pr](https://github.com/jaidedai/easyocr/pull/1004))\n    - fix several compatibilities\n- 15 september 2022 - version 1.6.2\n    - add cpu support for dbnet\n    - dbnet will only be compiled when users initialize dbnet detector.  \n- 1 september 2022 - version 1.6.1\n    - fix dbnet path bug for windows\n    - add new built-in model `cyrillic_g2`. this model is a new default for cyrillic script.\n- 24 august 2022 - version 1.6.0\n    - restructure code to support alternative text detectors.\n    - add detector `dbnet`, see [paper](https://arxiv.org/abs/2202.10304v1). it can be used by initializing like this `reader = easyocr.reader(['en'], detect_network = 'dbnet18')`.\n- 2 june 2022 - version 1.5.0\n    - add trainer for craft detection model (thanks[@gmuffiness](https://github.com/gmuffiness), see [pr](https://github.com/jaidedai/easyocr/pull/739))\n\n- [read all release notes](https://github.com/jaidedai/easyocr/blob/master/releasenotes.md)\n\n## what's coming next\n- handwritten text support\n\n## examples\n\n![example](examples/example.png)\n\n![example2](examples/example2.png)\n\n![example3](examples/example3.png)\n\n\n## installation\n\ninstall using `pip`\n\nfor the latest stable release:\n\n``` bash\npip install easyocr\n```\n\nfor the latest development release:\n\n``` bash\npip install git+https://github.com/jaidedai/easyocr.git\n```\n\nnote 1: for windows, please install torch and torchvision first by following the official instructions here https://pytorch.org. on the pytorch website, be sure to select the right cuda version you have. if you intend to run on cpu mode only, select `cuda = none`.\n\nnote 2: we also provide a dockerfile [here](https://github.com/jaidedai/easyocr/blob/master/dockerfile).\n\n## usage\n\n``` python\nimport easyocr\nreader = easyocr.reader(['ch_sim','en']) # this needs to run only once to load the model into memory\nresult = reader.readtext('chinese.jpg')\n```\n\nthe output will be in a list format, each item represents a bounding box, the text detected and confident level, respectively.\n\n``` bash\n[([[189, 75], [469, 75], [469, 165], [189, 165]], '\u611a\u56ed\u8def', 0.3754989504814148),\n ([[86, 80], [134, 80], [134, 128], [86, 128]], '\u897f', 0.40452659130096436),\n ([[517, 81], [565, 81], [565, 123], [517, 123]], '\u4e1c', 0.9989598989486694),\n ([[78, 126], [136, 126], [136, 156], [78, 156]], '315', 0.8125889301300049),\n ([[514, 126], [574, 126], [574, 156], [514, 156]], '309', 0.4971577227115631),\n ([[226, 170], [414, 170], [414, 220], [226, 220]], 'yuyuan rd.', 0.8261902332305908),\n ([[79, 173], [125, 173], [125, 213], [79, 213]], 'w', 0.9848111271858215),\n ([[529, 173], [569, 173], [569, 213], [529, 213]], 'e', 0.8405593633651733)]\n```\nnote 1: `['ch_sim','en']` is the list of languages you want to read. you can pass\nseveral languages at once but not all languages can be used together.\nenglish is compatible with every language and languages that share common characters are usually compatible with each other.\n\nnote 2: instead of the filepath `chinese.jpg`, you can also pass an opencv image object (numpy array) or an image file as bytes. a url to a raw image is also acceptable.\n\nnote 3: the line `reader = easyocr.reader(['ch_sim','en'])` is for loading a model into memory. it takes some time but it needs to be run only once.\n\nyou can also set `detail=0` for simpler output.\n\n``` python\nreader.readtext('chinese.jpg', detail = 0)\n```\nresult:\n``` bash\n['\u611a\u56ed\u8def', '\u897f', '\u4e1c', '315', '309', 'yuyuan rd.', 'w', 'e']\n```\n\nmodel weights for the chosen language will be automatically downloaded or you can\ndownload them manually from the [model hub](https://www.jaided.ai/easyocr/modelhub) and put them in the '~/.easyocr/model' folder\n\nin case you do not have a gpu, or your gpu has low memory, you can run the model in cpu-only mode by adding `gpu=false`.\n\n``` python\nreader = easyocr.reader(['ch_sim','en'], gpu=false)\n```\n\nfor more information, read the [tutorial](https://www.jaided.ai/easyocr/tutorial) and [api documentation](https://www.jaided.ai/easyocr/documentation).\n\n#### run on command line\n\n```shell\n$ easyocr -l ch_sim en -f chinese.jpg --detail=1 --gpu=true\n```\n\n## train/use your own model\n\nfor recognition model, [read here](https://github.com/jaidedai/easyocr/blob/master/custom_model.md).\n\nfor detection model (craft), [read here](https://github.com/jaidedai/easyocr/blob/master/trainer/craft/readme.md).\n\n## implementation roadmap\n\n- handwritten support\n- restructure code to support swappable detection and recognition algorithms\nthe api should be as easy as\n``` python\nreader = easyocr.reader(['en'], detection='db', recognition = 'transformer')\n```\nthe idea is to be able to plug in any state-of-the-art model into easyocr. there are a lot of geniuses trying to make better detection/recognition models, but we are not trying to be geniuses here. we just want to make their works quickly accessible to the public ... for free. (well, we believe most geniuses want their work to create a positive impact as fast/big as possible) the pipeline should be something like the below diagram. grey slots are placeholders for changeable light blue modules.\n\n![plan](examples/easyocr_framework.jpeg)\n\n## acknowledgement and references\n\nthis project is based on research and code from several papers and open-source repositories.\n\nall deep learning execution is based on [pytorch](https://pytorch.org). :heart:\n\ndetection execution uses the craft algorithm from this [official repository](https://github.com/clovaai/craft-pytorch) and their [paper](https://arxiv.org/abs/1904.01941) (thanks @youngminbaek from [@clovaai](https://github.com/clovaai)). we also use their pretrained model. training script is provided by [@gmuffiness](https://github.com/gmuffiness).\n\nthe recognition model is a crnn ([paper](https://arxiv.org/abs/1507.05717)). it is composed of 3 main components: feature extraction (we are currently using [resnet](https://arxiv.org/abs/1512.03385)) and vgg, sequence labeling ([lstm](https://www.bioinf.jku.at/publications/older/2604.pdf)) and decoding ([ctc](https://www.cs.toronto.edu/~graves/icml_2006.pdf)). the training pipeline for recognition execution is a modified version of the [deep-text-recognition-benchmark](https://github.com/clovaai/deep-text-recognition-benchmark) framework. (thanks [@ku21fan](https://github.com/ku21fan) from [@clovaai](https://github.com/clovaai)) this repository is a gem that deserves more recognition.\n\nbeam search code is based on this [repository](https://github.com/githubharald/ctcdecoder) and his [blog](https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7). (thanks [@githubharald](https://github.com/githubharald))\n\ndata synthesis is based on [textrecognitiondatagenerator](https://github.com/belval/textrecognitiondatagenerator). (thanks [@belval](https://github.com/belval))\n\nand a good read about ctc from distill.pub [here](https://distill.pub/2017/ctc/).\n\n## want to contribute?\n\nlet's advance humanity together by making ai available to everyone!\n\n3 ways to contribute:\n\n**coder:** please send a pr for small bugs/improvements. for bigger ones, discuss with us by opening an issue first. there is a list of possible bug/improvement issues tagged with ['pr welcome'](https://github.com/jaidedai/easyocr/issues?q=is%3aissue+is%3aopen+label%3a%22pr+welcome%22).\n\n**user:** tell us how easyocr benefits you/your organization to encourage further development. also post failure cases in [issue  section](https://github.com/jaidedai/easyocr/issues) to help improve future models.\n\n**tech leader/guru:** if you found this library useful, please spread the word! (see [yann lecun's post](https://www.facebook.com/yann.lecun/posts/10157018122787143) about easyocr)\n\n## guideline for new language request\n\nto request a new language, we need you to send a pr with the 2 following files:\n\n1. in folder [easyocr/character](https://github.com/jaidedai/easyocr/tree/master/easyocr/character),\nwe need 'yourlanguagecode_char.txt' that contains list of all characters. please see format examples from other files in that folder.\n2. in folder [easyocr/dict](https://github.com/jaidedai/easyocr/tree/master/easyocr/dict),\nwe need 'yourlanguagecode.txt' that contains list of words in your language.\non average, we have ~30000 words per language with more than 50000 words for more popular ones.\nmore is better in this file.\n\nif your language has unique elements (such as 1. arabic: characters change form when attached to each other + write from right to left 2. thai: some characters need to be above the line and some below), please educate us to the best of your ability and/or give useful links. it is important to take care of the detail to achieve a system that really works.\n\nlastly, please understand that our priority will have to go to popular languages or sets of languages that share large portions of their characters with each other (also tell us if this is the case for your language). it takes us at least a week to develop a new model, so you may have to wait a while for the new model to be released.\n\nsee [list of languages in development](https://github.com/jaidedai/easyocr/issues/91)\n\n## github issues\n\ndue to limited resources, an issue older than 6 months will be automatically closed. please open an issue again if it is critical.\n\n## business inquiries\n\nfor enterprise support, [jaided ai](https://www.jaided.ai/) offers full service for custom ocr/ai systems from implementation, training/finetuning and deployment. click [here](https://www.jaided.ai/contactus?ref=github) to contact us.\n\n\n",
  "docs_url": null,
  "keywords": "ocr optical character recognition deep learning neural network",
  "license": "apache license 2.0",
  "name": "easyocr",
  "package_url": "https://pypi.org/project/easyocr/",
  "project_url": "https://pypi.org/project/easyocr/",
  "project_urls": {
    "Download": "https://github.com/jaidedai/easyocr.git",
    "Homepage": "https://github.com/jaidedai/easyocr"
  },
  "release_url": "https://pypi.org/project/easyocr/1.7.1/",
  "requires_dist": [
    "torch",
    "torchvision (>=0.5)",
    "opencv-python-headless",
    "scipy",
    "numpy",
    "Pillow",
    "scikit-image",
    "python-bidi",
    "PyYAML",
    "Shapely",
    "pyclipper",
    "ninja"
  ],
  "requires_python": "",
  "summary": "end-to-end multi-lingual optical character recognition (ocr) solution",
  "version": "1.7.1",
  "releases": [],
  "developers": [
    "r.kittinaradorn@gmail.com",
    "rakpong_kittinaradorn"
  ],
  "kwds": "ocr recognition handwritten decoding pytorch",
  "license_kwds": "apache license 2.0",
  "libtype": "pypi",
  "id": "pypi_easyocr",
  "homepage": "https://github.com/jaidedai/easyocr",
  "release_count": 32,
  "dependency_ids": [
    "pypi_ninja",
    "pypi_numpy",
    "pypi_opencv_python_headless",
    "pypi_pillow",
    "pypi_pyclipper",
    "pypi_python_bidi",
    "pypi_pyyaml",
    "pypi_scikit_image",
    "pypi_scipy",
    "pypi_shapely",
    "pypi_torch",
    "pypi_torchvision"
  ]
}