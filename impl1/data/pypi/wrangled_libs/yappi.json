{
  "classifiers": [
    "development status :: 5 - production/stable",
    "environment :: console",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "programming language :: python :: implementation :: cpython",
    "topic :: software development :: libraries",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/sumerc/yappi/master/misc/logo.png\" alt=\"yappi\">\n</p>\n\n<h1 align=\"center\">yappi</h1>\n<p align=\"center\">\n    a tracing profiler that is <b>multithreading, asyncio and gevent</b> aware.\n</p>\n\n[![freepalestine.dev](https://freepalestine.dev/header/1)](https://freepalestine.dev)\n\n<p align=\"center\">\n    <a href=\"https://github.com/sumerc/yappi/actions/workflows/main.yml\"><img src=\"https://github.com/sumerc/yappi/workflows/ci/badge.svg?branch=master\"></a>\n    <a href=\"https://pypi.org/project/yappi/\"><img src=\"https://img.shields.io/pypi/v/yappi.svg\"></a>\n    <a href=\"https://pypi.org/project/yappi/\"><img src=\"https://img.shields.io/pypi/dw/yappi.svg\"></a>\n    <a href=\"https://pypi.org/project/yappi/\"><img src=\"https://img.shields.io/pypi/pyversions/yappi.svg\"></a>\n    <a href=\"https://github.com/sumerc/yappi/commits/\"><img src=\"https://img.shields.io/github/last-commit/sumerc/yappi.svg\"></a>\n    <a href=\"https://github.com/sumerc/yappi/blob/master/license\"><img src=\"https://img.shields.io/github/license/sumerc/yappi.svg\"></a>\n    <a href=\"https://freepalestine.dev\"><img src=\"https://freepalestine.dev/badge?t=d&u=0&r=1\" alt=\"from the river to the sea, palestine will be free\" /></a>\n</p>\n\n## highlights\n\n- **fast**: yappi is fast. it is completely written in c and lots of love and care went into making it fast.\n- **unique**: yappi supports multithreaded, [asyncio](https://github.com/sumerc/yappi/blob/master/doc/coroutine-profiling.md) and [gevent](https://github.com/sumerc/yappi/blob/master/doc/greenlet-profiling.md) profiling. tagging/filtering multiple profiler results has interesting [use cases](https://github.com/sumerc/yappi/blob/master/doc/api.md#set_tag_callback).\n- **intuitive**: profiler can\u00a0be\u00a0started/stopped and results can be obtained from any time and any thread.\n- **standards compliant**: profiler\u00a0results\u00a0can\u00a0be\u00a0saved\u00a0in\u00a0[callgrind](http://valgrind.org/docs/manual/cl-format.html)\u00a0or\u00a0[pstat](http://docs.python.org/3.4/library/profile.html#pstats.stats)\u00a0formats.\n- **rich in feature set**: profiler results can show either [wall time](https://en.wikipedia.org/wiki/elapsed_real_time) or actual [cpu time](http://en.wikipedia.org/wiki/cpu_time) and can be aggregated\u00a0from\u00a0different\u00a0sessions. various flags are defined for filtering and sorting profiler results.\n- **robust**: yappi has been around for years.\n\n## motivation\n\ncpython standard distribution comes with three deterministic profilers. `cprofile`, `profile` and `hotshot`. `cprofile` is implemented as a c module based on `lsprof`, `profile` is in pure python and `hotshot` can be seen as a small subset of a cprofile. the major issue is that all of these profilers lack support for multi-threaded programs and cpu time.\n\nif you want to profile a  multi-threaded application, you must give an entry point to these profilers and then maybe merge the outputs. none of these profilers are designed to work on long-running multi-threaded applications. it is also not possible to profile an application that start/stop/retrieve traces on the fly with these profilers. \n\nnow fast forwarding to 2019: with the latest improvements on `asyncio` library and asynchronous frameworks, most of the current profilers lacks the ability to show correct wall/cpu time or even call count information per-coroutine. thus we need a different kind of approach to profile asynchronous code. yappi, with v1.2 introduces the concept of `coroutine profiling`. with `coroutine-profiling`, you should be able to profile correct wall/cpu time and call count of your coroutine. (including the time spent in context switches, too). you can see details [here](https://github.com/sumerc/yappi/blob/master/doc/coroutine-profiling.md).\n\n\n## installation\n\ncan be installed via pypi\n\n```\n$ pip install yappi\n```\n\nor from the source directly.\n\n```\n$ pip install git+https://github.com/sumerc/yappi#egg=yappi\n```\n\n## examples\n\n### a simple example:\n\n```python\nimport yappi\n\ndef a():\n    for _ in range(10000000):  # do something cpu heavy\n        pass\n\nyappi.set_clock_type(\"cpu\") # use set_clock_type(\"wall\") for wall time\nyappi.start()\na()\n\nyappi.get_func_stats().print_all()\nyappi.get_thread_stats().print_all()\n'''\n\nclock type: cpu\nordered by: totaltime, desc\n\nname                                  ncall  tsub      ttot      tavg      \ndoc.py:5 a                            1      0.117907  0.117907  0.117907\n\nname           id     tid              ttot      scnt        \n_mainthread    0      139867147315008  0.118297  1\n'''\n```\n\n### profile a multithreaded application:\n\nyou can profile a multithreaded application via yappi and can easily retrieve\nper-thread profile information by filtering on `ctx_id` with `get_func_stats` api.\n\n```python\nimport yappi\nimport time\nimport threading\n\n_nthread = 3\n\n\ndef _work(n):\n    time.sleep(n * 0.1)\n\n\nyappi.start()\n\nthreads = []\n# generate _nthread threads\nfor i in range(_nthread):\n    t = threading.thread(target=_work, args=(i + 1, ))\n    t.start()\n    threads.append(t)\n# wait all threads to finish\nfor t in threads:\n    t.join()\n\nyappi.stop()\n\n# retrieve thread stats by their thread id (given by yappi)\nthreads = yappi.get_thread_stats()\nfor thread in threads:\n    print(\n        \"function stats for (%s) (%d)\" % (thread.name, thread.id)\n    )  # it is the thread.__class__.__name__\n    yappi.get_func_stats(ctx_id=thread.id).print_all()\n'''\nfunction stats for (thread) (3)\n\nname                                  ncall  tsub      ttot      tavg\n..hon3.7/threading.py:859 thread.run  1      0.000017  0.000062  0.000062\ndoc3.py:8 _work                       1      0.000012  0.000045  0.000045\n\nfunction stats for (thread) (2)\n\nname                                  ncall  tsub      ttot      tavg\n..hon3.7/threading.py:859 thread.run  1      0.000017  0.000065  0.000065\ndoc3.py:8 _work                       1      0.000010  0.000048  0.000048\n\n\nfunction stats for (thread) (1)\n\nname                                  ncall  tsub      ttot      tavg\n..hon3.7/threading.py:859 thread.run  1      0.000010  0.000043  0.000043\ndoc3.py:8 _work                       1      0.000006  0.000033  0.000033\n'''\n```\n\n### different ways to filter/sort stats:\n\nyou can use `filter_callback` on `get_func_stats` api to filter on functions, modules\nor whatever available in `yfuncstat` object.\n\n```python\nimport package_a\nimport yappi\nimport sys\n\ndef a():\n    pass\n\ndef b():\n    pass\n\nyappi.start()\na()\nb()\npackage_a.a()\nyappi.stop()\n\n# filter by module object\ncurrent_module = sys.modules[__name__]\nstats = yappi.get_func_stats(\n    filter_callback=lambda x: yappi.module_matches(x, [current_module])\n)  # x is a yappi.yfuncstat object\nstats.sort(\"name\", \"desc\").print_all()\n'''\nclock type: cpu\nordered by: name, desc\n\nname                                  ncall  tsub      ttot      tavg\ndoc2.py:10 b                          1      0.000001  0.000001  0.000001\ndoc2.py:6 a                           1      0.000001  0.000001  0.000001\n'''\n\n# filter by function object\nstats = yappi.get_func_stats(\n    filter_callback=lambda x: yappi.func_matches(x, [a, b])\n).print_all()\n'''\nname                                  ncall  tsub      ttot      tavg\ndoc2.py:6 a                           1      0.000001  0.000001  0.000001\ndoc2.py:10 b                          1      0.000001  0.000001  0.000001\n'''\n\n# filter by module name\nstats = yappi.get_func_stats(filter_callback=lambda x: 'package_a' in x.module\n                             ).print_all()\n'''\nname                                  ncall  tsub      ttot      tavg\npackage_a/__init__.py:1 a             1      0.000001  0.000001  0.000001\n'''\n\n# filter by function name\nstats = yappi.get_func_stats(filter_callback=lambda x: 'a' in x.name\n                             ).print_all()\n'''\nname                                  ncall  tsub      ttot      tavg\ndoc2.py:6 a                           1      0.000001  0.000001  0.000001\npackage_a/__init__.py:1 a             1      0.000001  0.000001  0.000001\n'''\n```\n\n### profile an asyncio application:\n\nyou can see that coroutine wall-time's are correctly profiled.\n\n```python\nimport asyncio\nimport yappi\n\nasync def foo():\n    await asyncio.sleep(1.0)\n    await baz()\n    await asyncio.sleep(0.5)\n\nasync def bar():\n    await asyncio.sleep(2.0)\n\nasync def baz():\n    await asyncio.sleep(1.0)\n\nyappi.set_clock_type(\"wall\")\nwith yappi.run():\n    asyncio.run(foo())\n    asyncio.run(bar())\nyappi.get_func_stats().print_all()\n'''\nclock type: wall\nordered by: totaltime, desc\n\nname                                  ncall  tsub      ttot      tavg      \ndoc4.py:5 foo                         1      0.000030  2.503808  2.503808\ndoc4.py:11 bar                        1      0.000012  2.002492  2.002492\ndoc4.py:15 baz                        1      0.000013  1.001397  1.001397\n'''\n```\n\n### profile a gevent application:\n\nyou can use yappi to profile greenlet applications now!\n\n```python\nimport yappi\nfrom greenlet import greenlet\nimport time\n\nclass greenleta(greenlet):\n    def run(self):\n        time.sleep(1)\n\nyappi.set_context_backend(\"greenlet\")\nyappi.set_clock_type(\"wall\")\n\nyappi.start(builtins=true)\na = greenleta()\na.switch()\nyappi.stop()\n\nyappi.get_func_stats().print_all()\n'''\nname                                  ncall  tsub      ttot      tavg\ntests/test_random.py:6 greenleta.run  1      0.000007  1.000494  1.000494\ntime.sleep                            1      1.000487  1.000487  1.000487\n'''\n```\n\n## documentation\n\n- [introduction](https://github.com/sumerc/yappi/blob/master/doc/introduction.md)\n- [clock types](https://github.com/sumerc/yappi/blob/master/doc/clock_types.md)\n- [api](https://github.com/sumerc/yappi/blob/master/doc/api.md)\n- [coroutine profiling](https://github.com/sumerc/yappi/blob/master/doc/coroutine-profiling.md) _(new in 1.2)_\n- [greenlet profiling](https://github.com/sumerc/yappi/blob/master/doc/greenlet-profiling.md) _(new in 1.3)_\n\n  note: yes. i know i should be moving docs to readthedocs.io. stay tuned!\n\n\n## related talks\n\n  special thanks to a.jesse jiryu davis:\n- [python performance profiling: the guts and the glory (pycon 2015)](https://www.youtube.com/watch?v=4ujwwxyhxam)\n\n## pycharm integration\n\nyappi is the default profiler in `pycharm`. if you have yappi installed, `pycharm` will use it. see [the official](https://www.jetbrains.com/help/pycharm/profiler.html) documentation for more details.\n\n",
  "docs_url": null,
  "keywords": "python thread multithread asyncio gevent profiler",
  "license": "mit",
  "name": "yappi",
  "package_url": "https://pypi.org/project/yappi/",
  "project_url": "https://pypi.org/project/yappi/",
  "project_urls": {
    "Homepage": "https://github.com/sumerc/yappi"
  },
  "release_url": "https://pypi.org/project/yappi/1.6.0/",
  "requires_dist": [
    "gevent >=20.6.2 ; extra == 'test'"
  ],
  "requires_python": ">=3.6",
  "summary": "yet another python profiler",
  "version": "1.6.0",
  "releases": [],
  "developers": [
    "sumerc@gmail.com"
  ],
  "kwds": "multithread multithreaded yappi multithreading get_thread_stats",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_yappi",
  "homepage": "https://github.com/sumerc/yappi",
  "release_count": 22,
  "dependency_ids": [
    "pypi_gevent"
  ]
}