{
  "classifiers": [
    "development status :: 5 - production/stable",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "programming language :: python",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: software development :: libraries :: python modules",
    "topic :: text processing",
    "topic :: text processing :: markup :: html"
  ],
  "description": "urlextract\n----------\n\nurlextract is python class for collecting (extracting) urls from given\ntext based on locating tld.\n\n.. image:: https://img.shields.io/github/workflow/status/lipoja/urlextract/upload%20python%20package\n    :target: https://github.com/lipoja/urlextract/actions/workflows/python-publish.yml\n    :alt: build status\n.. image:: https://img.shields.io/github/tag/lipoja/urlextract.svg\n    :target: https://github.com/lipoja/urlextract/tags\n    :alt: git tag\n.. image:: https://img.shields.io/pypi/pyversions/urlextract.svg\n    :target: https://pypi.python.org/pypi/urlextract\n    :alt: python version compatibility\n\n\nhow does it work\n~~~~~~~~~~~~~~~~\n\nit tries to find any occurrence of tld in given text. if tld is found it\nstarts from that position to expand boundaries to both sides searching\nfor \"stop character\" (usually whitespace, comma, single or double\nquote).\n\na dns check option is available to also reject invalid domain names.\n\nnote: list of tlds is downloaded from iana.org to keep you up to date with new tlds.\n\ninstallation\n~~~~~~~~~~~~\n\npackage is available on pypi - you can install it via pip.\n\n.. image:: https://img.shields.io/pypi/v/urlextract.svg\n    :target: https://pypi.python.org/pypi/urlextract\n.. image:: https://img.shields.io/pypi/status/urlextract.svg\n    :target: https://pypi.python.org/pypi/urlextract\n\n::\n\n   pip install urlextract\n\ndocumentation\n~~~~~~~~~~~~~\n\nonline documentation is published at http://urlextract.readthedocs.io/\n\n\nrequirements\n~~~~~~~~~~~~\n\n- idna for converting links to idna format\n- uritools for domain name validation\n- platformdirs for determining user's cache directory\n- dnspython to cache dns results\n\n   ::\n\n       pip install idna\n       pip install uritools\n       pip install platformdirs\n       pip install dnspython\n\nor you can install the requirements with `requirements.txt`:\n\n   ::\n\n       pip install -r requirements.txt\n\n\nrun tox\n~~~~~~~\n\ninstall tox:\n\n   ::\n\n       pip install tox\n\nthen run it:\n\n   ::\n\n       tox\n\nexample\n~~~~~~~\n\nyou can look at command line program at the end of *urlextract.py*.\nbut everything you need to know is this:\n\n.. code:: python\n\n    from urlextract import urlextract\n\n    extractor = urlextract()\n    urls = extractor.find_urls(\"text with urls. let's have url janlipovsky.cz as an example.\")\n    print(urls) # prints: ['janlipovsky.cz']\n\nor you can get generator over urls in text by:\n\n.. code:: python\n\n    from urlextract import urlextract\n\n    extractor = urlextract()\n    example_text = \"text with urls. let's have url janlipovsky.cz as an example.\"\n\n    for url in extractor.gen_urls(example_text):\n        print(url) # prints: ['janlipovsky.cz']\n\nor if you want to just check if there is at least one url you can do:\n\n.. code:: python\n\n    from urlextract import urlextract\n\n    extractor = urlextract()\n    example_text = \"text with urls. let's have url janlipovsky.cz as an example.\"\n\n    if extractor.has_urls(example_text):\n        print(\"given text contains some url\")\n\nif you want to have up to date list of tlds you can use ``update()``:\n\n.. code:: python\n\n    from urlextract import urlextract\n\n    extractor = urlextract()\n    extractor.update()\n\nor ``update_when_older()`` method:\n\n.. code:: python\n\n    from urlextract import urlextract\n\n    extractor = urlextract()\n    extractor.update_when_older(7) # updates when list is older that 7 days\n\nknown issues\n~~~~~~~~~~~~\n\nsince tld can be not only shortcut but also some meaningful word we might see \"false matches\" when we are searching\nfor url in some html pages. the false match can occur for example in css or js when you are referring to html item\nusing its classes.\n\nexample html code:\n\n.. code-block:: html\n\n  <p class=\"bold name\">jan</p>\n  <style>\n    p.bold.name {\n      font-weight: bold;\n    }\n  </style>\n\nif this html snippet is on the input of ``urlextract.find_urls()`` it will return ``p.bold.name`` as an url.\nbehavior of urlextract is correct, because ``.name`` is valid tld and urlextract just see that there is ``bold.name``\nvalid domain name and ``p`` is valid sub-domain.\n\nlicense\n~~~~~~~\n\nthis piece of code is licensed under the mit license.\n",
  "docs_url": null,
  "keywords": "url,extract,find,finder,collect,link,tld,list",
  "license": "mit",
  "name": "urlextract",
  "package_url": "https://pypi.org/project/urlextract/",
  "project_url": "https://pypi.org/project/urlextract/",
  "project_urls": {
    "Documentation": "https://urlextract.readthedocs.io/en/latest/",
    "Homepage": "https://github.com/lipoja/URLExtract",
    "Source Code": "https://github.com/lipoja/URLExtract"
  },
  "release_url": "https://pypi.org/project/urlextract/1.8.0/",
  "requires_dist": [
    "idna",
    "uritools",
    "platformdirs",
    "filelock"
  ],
  "requires_python": "",
  "summary": "collects and extracts urls from given text.",
  "version": "1.8.0",
  "releases": [],
  "developers": [
    "janlipovsky@gmail.com"
  ],
  "kwds": "urlextract find_urls python extract extracting",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_urlextract",
  "homepage": "https://github.com/lipoja/urlextract",
  "release_count": 32,
  "dependency_ids": [
    "pypi_filelock",
    "pypi_idna",
    "pypi_platformdirs",
    "pypi_uritools"
  ]
}