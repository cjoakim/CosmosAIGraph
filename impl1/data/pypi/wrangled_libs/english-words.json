{
  "classifiers": [
    "development status :: 5 - production/stable",
    "license :: osi approved :: mit license",
    "natural language :: english",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.9"
  ],
  "description": "[![pypi](https://img.shields.io/pypi/v/english-words.svg)](https://pypi.org/project/english-words/)\n\n# english-words-py\n\nreturns sets of english words created by combining different words\nlists together. example usage: to get a set of english words from the\n\"web2\" word list, including only lower-case letters, you write the\nfollowing:\n\n```python3\n>>> from english_words import get_english_words_set\n>>> web2lowerset = get_english_words_set(['web2'], lower=true)\n```\n\n## usage\n\nfrom the main package, import `get_english_words_set` as demonstrated\nabove. this function takes a number of arguments; the first is a list of\nword list identifiers for the word lists to combine and the rest are\nflags. these arguments are described here (in the following order):\n\n- `sources` is an iterable containing strings\ncorresponding to word list identifiers (see \"word lists\" subsection\nbelow)\n- `alpha` (default `false`) is a flag specifying that all\n  non-alphanumeric characters (e.g.: `-`, `'`) should be stripped\n- `lower` (default `false` ) is a flag specifying that all upper-case\n  letters should be converted to lower-case\n\neach word list is pre-processed to handle the above flags, so using any\ncombination of options will not cause the function to run slower.\n\nnote that some care needs to be used when combining word lists. for\nexample, only proper nouns in the `web2` word list are capitalized, but\nmost words in the `gcide` word list are capitalized.\n\n### word lists\n\n| name/url | identifier | notes |\n| :--- | :--- | :--- |\n| [gcide 0.53 index](https://ftp.gnu.org/gnu/gcide/) | `gcide` | words found in gnu collaborative international dictionary of english 0.53. most words capitalized (not exactly sure what the capitalization convention is). contains some entries with multiple words (currently you must use the alpha option to exclude these).<br/><br/>unicode characters are currently unprocessed; for example `<ae/` is present in the dictionary instead of `\u00e6`. ideally, these should all be converted. |\n| [web2 revision 326913](https://svnweb.freebsd.org/base/head/share/dict/web2?view=markup&pathrev=326913) | `web2` | |\n\n## adding additional word lists\n\nto add a word list, say with identifier `x`, put the word list (one word\nper line), into a plain text file `x.txt` in the [`raw_data`](raw_data)\ndirectory at the root of the repository. then, to process the word list\n(and all others in the directory) run the script\n[`process_raw_data.py`](scripts/process_raw_data.py).\n\n## installation\n\ninstall this with pip with\n\n```\npip install english-words\n```\n\nthis package is unfortunately rather large (~20mb), and will run into\nscaling issues if more word lists or (especially) options are added.\nwhen that bridge is crossed, word lists should possibly be chosen by the\nuser instead of simply including all of them; word lists could also be\npreprocessed on the client side instead of being included in the\npackage.\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "english-words",
  "package_url": "https://pypi.org/project/english-words/",
  "project_url": "https://pypi.org/project/english-words/",
  "project_urls": {
    "Homepage": "https://github.com/mwiens91/english-words-py"
  },
  "release_url": "https://pypi.org/project/english-words/2.0.1/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "generate sets of english words by combining different word lists",
  "version": "2.0.1",
  "releases": [],
  "developers": [
    "matt_wiens",
    "mwiens91@gmail.com"
  ],
  "kwds": "get_english_words_set english_words dictionary words dict",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_english_words",
  "homepage": "https://github.com/mwiens91/english-words-py",
  "release_count": 8,
  "dependency_ids": []
}