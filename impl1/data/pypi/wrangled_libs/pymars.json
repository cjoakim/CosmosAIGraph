{
  "classifiers": [
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "programming language :: python :: implementation :: cpython",
    "topic :: software development :: libraries"
  ],
  "description": ".. image:: https://raw.githubusercontent.com/mars-project/mars/master/docs/source/images/mars-logo-title.png\r\n\r\n|pypi version| |docs| |build| |coverage| |quality| |license|\r\n\r\nmars is a tensor-based unified framework for large-scale data computation\r\nwhich scales numpy, pandas, scikit-learn and many other libraries.\r\n\r\n`documentation`_, `\u4e2d\u6587\u6587\u6863`_\r\n\r\ninstallation\r\n------------\r\n\r\nmars is easy to install by\r\n\r\n.. code-block:: bash\r\n\r\n    pip install pymars\r\n\r\n\r\ninstallation for developers\r\n```````````````````````````\r\n\r\nwhen you want to contribute code to mars, you can follow the instructions below to install mars\r\nfor development:\r\n\r\n.. code-block:: bash\r\n\r\n    git clone https://github.com/mars-project/mars.git\r\n    cd mars\r\n    pip install -e \".[dev]\"\r\n\r\nmore details about installing mars can be found at\r\n`installation <https://docs.pymars.org/en/latest/installation/index.html>`_ section in\r\nmars document.\r\n\r\n\r\narchitecture overview\r\n---------------------\r\n\r\n.. image:: https://raw.githubusercontent.com/mars-project/mars/master/docs/source/images/architecture.png\r\n\r\n\r\ngetting started\r\n---------------\r\n\r\nstarting a new runtime locally via:\r\n\r\n.. code-block:: python\r\n\r\n    >>> import mars\r\n    >>> mars.new_session()\r\n\r\nor connecting to a mars cluster which is already initialized.\r\n\r\n.. code-block:: python\r\n\r\n    >>> import mars\r\n    >>> mars.new_session('http://<web_ip>:<ui_port>')\r\n\r\n\r\nmars tensor\r\n-----------\r\n\r\nmars tensor provides a familiar interface like numpy.\r\n\r\n+-----------------------------------------------+-----------------------------------------------+\r\n| **numpy**                                     | **mars tensor**                               |\r\n+-----------------------------------------------+-----------------------------------------------+\r\n|.. code-block:: python                         |.. code-block:: python                         |\r\n|                                               |                                               |\r\n|    import numpy as np                         |    import mars.tensor as mt                   |\r\n|    n = 200_000_000                            |    n = 200_000_000                            |\r\n|    a = np.random.uniform(-1, 1, size=(n, 2))  |    a = mt.random.uniform(-1, 1, size=(n, 2))  |\r\n|    print((np.linalg.norm(a, axis=1) < 1)      |    print(((mt.linalg.norm(a, axis=1) < 1)     |\r\n|          .sum() * 4 / n)                      |            .sum() * 4 / n).execute())         |\r\n|                                               |                                               |\r\n+-----------------------------------------------+-----------------------------------------------+\r\n|.. code-block::                                |.. code-block::                                |\r\n|                                               |                                               |\r\n|    3.14174502                                 |     3.14161908                                |\r\n|    cpu times: user 11.6 s, sys: 8.22 s,       |     cpu times: user 966 ms, sys: 544 ms,      |\r\n|               total: 19.9 s                   |                total: 1.51 s                  |\r\n|    wall time: 22.5 s                          |     wall time: 3.77 s                         |\r\n|                                               |                                               |\r\n+-----------------------------------------------+-----------------------------------------------+\r\n\r\nmars can leverage multiple cores, even on a laptop, and could be even faster for a distributed setting.\r\n\r\n\r\nmars dataframe\r\n--------------\r\n\r\nmars dataframe provides a familiar interface like pandas.\r\n\r\n+-----------------------------------------+-----------------------------------------+\r\n| **pandas**                              | **mars dataframe**                      |\r\n+-----------------------------------------+-----------------------------------------+\r\n|.. code-block:: python                   |.. code-block:: python                   |\r\n|                                         |                                         |\r\n|    import numpy as np                   |    import mars.tensor as mt             |\r\n|    import pandas as pd                  |    import mars.dataframe as md          |\r\n|    df = pd.dataframe(                   |    df = md.dataframe(                   |\r\n|        np.random.rand(100000000, 4),    |        mt.random.rand(100000000, 4),    |\r\n|        columns=list('abcd'))            |        columns=list('abcd'))            |\r\n|    print(df.sum())                      |    print(df.sum().execute())            |\r\n|                                         |                                         |\r\n+-----------------------------------------+-----------------------------------------+\r\n|.. code-block::                          |.. code-block::                          |\r\n|                                         |                                         |\r\n|    cpu times: user 10.9 s, sys: 2.69 s, |    cpu times: user 1.21 s, sys: 212 ms, |\r\n|               total: 13.6 s             |               total: 1.42 s             |\r\n|    wall time: 11 s                      |    wall time: 2.75 s                    |\r\n+-----------------------------------------+-----------------------------------------+\r\n\r\n\r\nmars learn\r\n----------\r\n\r\nmars learn provides a familiar interface like scikit-learn.\r\n\r\n+---------------------------------------------+----------------------------------------------------+\r\n| **scikit-learn**                            | **mars learn**                                     |\r\n+---------------------------------------------+----------------------------------------------------+\r\n|.. code-block:: python                       |.. code-block:: python                              |\r\n|                                             |                                                    |\r\n|    from sklearn.datasets import make_blobs  |    from mars.learn.datasets import make_blobs      |\r\n|    from sklearn.decomposition import pca    |    from mars.learn.decomposition import pca        |\r\n|    x, y = make_blobs(                       |    x, y = make_blobs(                              |\r\n|        n_samples=100000000, n_features=3,   |        n_samples=100000000, n_features=3,          |\r\n|        centers=[[3, 3, 3], [0, 0, 0],       |        centers=[[3, 3, 3], [0, 0, 0],              |\r\n|                 [1, 1, 1], [2, 2, 2]],      |                  [1, 1, 1], [2, 2, 2]],            |\r\n|        cluster_std=[0.2, 0.1, 0.2, 0.2],    |        cluster_std=[0.2, 0.1, 0.2, 0.2],           |\r\n|        random_state=9)                      |        random_state=9)                             |\r\n|    pca = pca(n_components=3)                |    pca = pca(n_components=3)                       |\r\n|    pca.fit(x)                               |    pca.fit(x)                                      |\r\n|    print(pca.explained_variance_ratio_)     |    print(pca.explained_variance_ratio_)            |\r\n|    print(pca.explained_variance_)           |    print(pca.explained_variance_)                  |\r\n|                                             |                                                    |\r\n+---------------------------------------------+----------------------------------------------------+\r\n\r\nmars learn also integrates with many libraries:\r\n\r\n- `tensorflow <https://docs.pymars.org/en/latest/user_guide/learn/tensorflow.html>`_\r\n- `pytorch <https://docs.pymars.org/en/latest/user_guide/learn/pytorch.html>`_\r\n- `xgboost <https://docs.pymars.org/en/latest/user_guide/learn/xgboost.html>`_\r\n- `lightgbm <https://docs.pymars.org/en/latest/user_guide/learn/lightgbm.html>`_\r\n- `joblib <https://docs.pymars.org/en/latest/user_guide/learn/joblib.html>`_\r\n- `statsmodels <https://docs.pymars.org/en/latest/user_guide/learn/statsmodels.html>`_\r\n\r\nmars remote\r\n-----------\r\n\r\nmars remote allows users to execute functions in parallel.\r\n\r\n+-------------------------------------------+--------------------------------------------+\r\n| **vanilla function calls**                | **mars remote**                            |\r\n+-------------------------------------------+--------------------------------------------+\r\n|.. code-block:: python                     |.. code-block:: python                      |\r\n|                                           |                                            |\r\n|    import numpy as np                     |    import numpy as np                      |\r\n|                                           |    import mars.remote as mr                |\r\n|                                           |                                            |\r\n|    def calc_chunk(n, i):                  |    def calc_chunk(n, i):                   |\r\n|        rs = np.random.randomstate(i)      |        rs = np.random.randomstate(i)       |\r\n|        a = rs.uniform(-1, 1, size=(n, 2)) |        a = rs.uniform(-1, 1, size=(n, 2))  |\r\n|        d = np.linalg.norm(a, axis=1)      |        d = np.linalg.norm(a, axis=1)       |\r\n|        return (d < 1).sum()               |        return (d < 1).sum()                |\r\n|                                           |                                            |\r\n|    def calc_pi(fs, n):                    |    def calc_pi(fs, n):                     |\r\n|        return sum(fs) * 4 / n             |        return sum(fs) * 4 / n              |\r\n|                                           |                                            |\r\n|    n = 200_000_000                        |    n = 200_000_000                         |\r\n|    n = 10_000_000                         |    n = 10_000_000                          |\r\n|                                           |                                            |\r\n|    fs = [calc_chunk(n, i)                 |    fs = [mr.spawn(calc_chunk, args=(n, i)) |\r\n|          for i in range(n // n)]          |          for i in range(n // n)]           |\r\n|    pi = calc_pi(fs, n)                    |    pi = mr.spawn(calc_pi, args=(fs, n))    |\r\n|    print(pi)                              |    print(pi.execute().fetch())             |\r\n|                                           |                                            |\r\n+-------------------------------------------+--------------------------------------------+\r\n|.. code-block::                            |.. code-block::                             |\r\n|                                           |                                            |\r\n|    3.1416312                              |    3.1416312                               |\r\n|    cpu times: user 32.2 s, sys: 4.86 s,   |    cpu times: user 616 ms, sys: 307 ms,    |\r\n|               total: 37.1 s               |               total: 923 ms                |\r\n|    wall time: 12.4 s                      |    wall time: 3.99 s                       |\r\n|                                           |                                            |\r\n+-------------------------------------------+--------------------------------------------+\r\n\r\ndask on mars\r\n------------\r\n\r\nrefer to `dask on mars`_ for more information.\r\n\r\neager mode\r\n```````````\r\n\r\nmars supports eager mode which makes it friendly for developing and easy to debug.\r\n\r\nusers can enable the eager mode by options, set options at the beginning of the program or console session.\r\n\r\n.. code-block:: python\r\n\r\n    >>> from mars.config import options\r\n    >>> options.eager_mode = true\r\n\r\nor use a context.\r\n\r\n.. code-block:: python\r\n\r\n    >>> from mars.config import option_context\r\n    >>> with option_context() as options:\r\n    >>>     options.eager_mode = true\r\n    >>>     # the eager mode is on only for the with statement\r\n    >>>     ...\r\n\r\nif eager mode is on, tensor, dataframe etc will be executed immediately\r\nby default session once it is created.\r\n\r\n.. code-block:: python\r\n\r\n    >>> import mars.tensor as mt\r\n    >>> import mars.dataframe as md\r\n    >>> from mars.config import options\r\n    >>> options.eager_mode = true\r\n    >>> t = mt.arange(6).reshape((2, 3))\r\n    >>> t\r\n    array([[0, 1, 2],\r\n           [3, 4, 5]])\r\n    >>> df = md.dataframe(t)\r\n    >>> df.sum()\r\n    0    3\r\n    1    5\r\n    2    7\r\n    dtype: int64\r\n\r\n\r\nmars on ray\r\n------------\r\nmars also has deep integration with ray and can run on `ray <https://docs.ray.io/en/latest/>`_ efficiently and\r\ninteract with the large ecosystem of machine learning and distributed systems built on top of the core ray.\r\n\r\nstarting a new mars on ray runtime locally via:\r\n\r\n.. code-block:: python\r\n\r\n    import mars\r\n    mars.new_session(backend='ray')\r\n    # perform compute\r\n\r\ninteract with ray dataset:\r\n\r\n.. code-block:: python\r\n\r\n    import mars.tensor as mt\r\n    import mars.dataframe as md\r\n    df = md.dataframe(\r\n        mt.random.rand(1000_0000, 4),\r\n        columns=list('abcd'))\r\n    # convert mars dataframe to ray dataset\r\n    ds = md.to_ray_dataset(df)\r\n    print(ds.schema(), ds.count())\r\n    ds.filter(lambda row: row[\"a\"] > 0.5).show(5)\r\n    # convert ray dataset to mars dataframe\r\n    df2 = md.read_ray_dataset(ds)\r\n    print(df2.head(5).execute())\r\n\r\nrefer to `mars on ray`_ for more information.\r\n\r\n\r\neasy to scale in and scale out\r\n------------------------------\r\n\r\nmars can scale in to a single machine, and scale out to a cluster with thousands of machines.\r\nit's fairly simple to migrate from a single machine to a cluster to\r\nprocess more data or gain a better performance.\r\n\r\n\r\nbare metal deployment\r\n`````````````````````\r\n\r\nmars is easy to scale out to a cluster by starting different components of\r\nmars distributed runtime on different machines in the cluster.\r\n\r\na node can be selected as supervisor which integrated a web service,\r\nleaving other nodes as workers.  the supervisor can be started with the following command:\r\n\r\n.. code-block:: bash\r\n\r\n    mars-supervisor -h <host_name> -p <supervisor_port> -w <web_port>\r\n\r\nworkers can be started with the following command:\r\n\r\n.. code-block:: bash\r\n\r\n    mars-worker -h <host_name> -p <worker_port> -s <supervisor_endpoint>\r\n\r\nafter all mars processes are started, users can run\r\n\r\n.. code-block:: python\r\n\r\n    >>> sess = new_session('http://<web_ip>:<ui_port>')\r\n    >>> # perform computation\r\n\r\n\r\nkubernetes deployment\r\n`````````````````````\r\n\r\nrefer to `run on kubernetes`_ for more information.\r\n\r\n\r\nyarn deployment\r\n```````````````\r\n\r\nrefer to `run on yarn`_ for more information.\r\n\r\n\r\ngetting involved\r\n----------------\r\n\r\n- read `development guide <https://docs.pymars.org/en/latest/development/index.html>`_.\r\n- join our slack workgroup: `slack <https://join.slack.com/t/mars-computing/shared_invite/zt-17pw2cfua-nrb2h4vrg77pr9t4g3nqoq>`_.\r\n- join the mailing list: send an email to `mars-dev@googlegroups.com`_.\r\n- please report bugs by submitting a `github issue`_.\r\n- submit contributions using `pull requests`_.\r\n\r\nthank you in advance for your contributions!\r\n\r\n\r\n.. |build| image:: https://github.com/mars-project/mars/workflows/mars%20ci%20core/badge.svg\r\n   :target: https://github.com/mars-project/mars/actions\r\n.. |coverage| image:: https://codecov.io/gh/mars-project/mars/branch/master/graph/badge.svg\r\n   :target: https://codecov.io/gh/mars-project/mars\r\n.. |quality| image:: https://img.shields.io/codacy/grade/6a80bb4659ed410eb33795f580c8615e.svg\r\n   :target: https://app.codacy.com/project/mars-project/mars/dashboard\r\n.. |pypi version| image:: https://img.shields.io/pypi/v/pymars.svg\r\n   :target: https://pypi.python.org/pypi/pymars\r\n.. |docs| image:: https://img.shields.io/badge/docs-latest-brightgreen.svg\r\n   :target: `documentation`_\r\n.. |license| image:: https://img.shields.io/pypi/l/pymars.svg\r\n   :target: https://github.com/mars-project/mars/blob/master/license\r\n.. _`mars-dev@googlegroups.com`: https://groups.google.com/forum/#!forum/mars-dev\r\n.. _`github issue`: https://github.com/mars-project/mars/issues\r\n.. _`pull requests`: https://github.com/mars-project/mars/pulls\r\n.. _`documentation`: https://docs.pymars.org\r\n.. _`\u4e2d\u6587\u6587\u6863`: https://docs.pymars.org/zh_cn/latest/\r\n.. _`mars on ray`: https://docs.pymars.org/en/latest/installation/ray.html\r\n.. _`run on kubernetes`: https://docs.pymars.org/en/latest/installation/kubernetes.html\r\n.. _`run on yarn`: https://docs.pymars.org/en/latest/installation/yarn.html\r\n.. _`dask on mars`: https://docs.pymars.org/en/latest/user_guide/contrib/dask.html\r\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache license 2.0",
  "name": "pymars",
  "package_url": "https://pypi.org/project/pymars/",
  "project_url": "https://pypi.org/project/pymars/",
  "project_urls": {
    "Homepage": "http://github.com/mars-project/mars"
  },
  "release_url": "https://pypi.org/project/pymars/0.10.0/",
  "requires_dist": [
    "numpy (>=1.14.0)",
    "pandas (>=1.0.0)",
    "scipy (>=1.0.0)",
    "scikit-learn (>=0.20)",
    "numexpr (>=2.6.4)",
    "cloudpickle (>=1.5.0)",
    "pyyaml (>=5.1)",
    "psutil (>=5.9.0)",
    "tornado (>=6.0)",
    "sqlalchemy (>=1.2.0)",
    "defusedxml (>=0.5.0)",
    "tqdm (>=4.1.0)",
    "pickle5 ; python_version < \"3.8\"",
    "shared-memory38 (>=0.1.1) ; python_version < \"3.8\"",
    "uvloop (>=0.14.0) ; sys_platform != \"win32\"",
    "cython (>=0.29) ; extra == 'dev'",
    "pytest (>=3.5.0) ; extra == 'dev'",
    "pytest-cov (>=2.5.0) ; extra == 'dev'",
    "pytest-timeout (>=1.2.0) ; extra == 'dev'",
    "pytest-forked (>=1.0) ; extra == 'dev'",
    "pytest-asyncio (>=0.14.0) ; extra == 'dev'",
    "flake8 (>=3.8.0) ; extra == 'dev'",
    "black ; extra == 'dev'",
    "mock (>=4.0.0) ; (python_version < \"3.8\") and extra == 'dev'",
    "pillow (>=7.0.0) ; extra == 'extra'",
    "pyarrow (!=0.16.*,>=0.11.0) ; extra == 'extra'",
    "lz4 (>=1.0.0) ; extra == 'extra'",
    "fsspec (!=2022.8.0,>=2022.7.1) ; extra == 'extra'",
    "kubernetes (>=10.0.0) ; extra == 'kubernetes'",
    "ray (>=1.8.0) ; extra == 'ray'",
    "vineyard (>=0.11.1) ; (sys_platform != \"win32\") and extra == 'vineyard'"
  ],
  "requires_python": "",
  "summary": "mars: a tensor-based unified framework for large-scale data computation.",
  "version": "0.10.0",
  "releases": [],
  "developers": [
    "qin@qinxuye.me",
    "qin_xuye"
  ],
  "kwds": "mars pip python pymars scikit",
  "license_kwds": "apache license 2.0",
  "libtype": "pypi",
  "id": "pypi_pymars",
  "homepage": "http://github.com/mars-project/mars",
  "release_count": 117,
  "dependency_ids": [
    "pypi_black",
    "pypi_cloudpickle",
    "pypi_cython",
    "pypi_defusedxml",
    "pypi_flake8",
    "pypi_fsspec",
    "pypi_kubernetes",
    "pypi_lz4",
    "pypi_mock",
    "pypi_numexpr",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_pickle5",
    "pypi_pillow",
    "pypi_psutil",
    "pypi_pyarrow",
    "pypi_pytest",
    "pypi_pytest_asyncio",
    "pypi_pytest_cov",
    "pypi_pytest_forked",
    "pypi_pytest_timeout",
    "pypi_pyyaml",
    "pypi_ray",
    "pypi_scikit_learn",
    "pypi_scipy",
    "pypi_shared_memory38",
    "pypi_sqlalchemy",
    "pypi_tornado",
    "pypi_tqdm",
    "pypi_uvloop",
    "pypi_vineyard"
  ]
}