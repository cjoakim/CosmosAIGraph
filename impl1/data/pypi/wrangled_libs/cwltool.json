{
  "classifiers": [
    "development status :: 5 - production/stable",
    "environment :: console",
    "intended audience :: developers",
    "intended audience :: healthcare industry",
    "intended audience :: science/research",
    "license :: osi approved :: apache software license",
    "natural language :: english",
    "operating system :: macos :: macos x",
    "operating system :: posix",
    "operating system :: posix :: linux",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering",
    "topic :: scientific/engineering :: astronomy",
    "topic :: scientific/engineering :: atmospheric science",
    "topic :: scientific/engineering :: bio-informatics",
    "topic :: scientific/engineering :: information analysis",
    "topic :: scientific/engineering :: medical science apps.",
    "topic :: system :: distributed computing",
    "topic :: utilities"
  ],
  "description": "#############################################################################################\n``cwltool``: the reference reference implementation of the common workflow language standards\n#############################################################################################\n\n|linux status| |coverage status| |docs status|\n\npypi: |pypi version| |pypi downloads month| |total pypi downloads|\n\nconda: |conda version| |conda installs|\n\ndebian: |debian testing package| |debian stable package|\n\nquay.io (docker): |quay.io container|\n\n.. |linux status| image:: https://github.com/common-workflow-language/cwltool/actions/workflows/ci-tests.yml/badge.svg?branch=main\n   :target: https://github.com/common-workflow-language/cwltool/actions/workflows/ci-tests.yml\n\n.. |debian stable package| image:: https://badges.debian.net/badges/debian/stable/cwltool/version.svg\n   :target: https://packages.debian.org/stable/cwltool\n\n.. |debian testing package| image:: https://badges.debian.net/badges/debian/testing/cwltool/version.svg\n   :target: https://packages.debian.org/testing/cwltool\n\n.. |coverage status| image:: https://img.shields.io/codecov/c/github/common-workflow-language/cwltool.svg\n   :target: https://codecov.io/gh/common-workflow-language/cwltool\n\n.. |pypi version| image:: https://badge.fury.io/py/cwltool.svg\n   :target: https://badge.fury.io/py/cwltool\n\n.. |pypi downloads month| image:: https://pepy.tech/badge/cwltool/month\n   :target: https://pepy.tech/project/cwltool\n\n.. |total pypi downloads| image:: https://static.pepy.tech/personalized-badge/cwltool?period=total&units=international_system&left_color=black&right_color=orange&left_text=total%20pypi%20downloads\n   :target: https://pepy.tech/project/cwltool\n\n.. |conda version| image:: https://anaconda.org/conda-forge/cwltool/badges/version.svg\n   :target: https://anaconda.org/conda-forge/cwltool\n\n.. |conda installs| image:: https://anaconda.org/conda-forge/cwltool/badges/downloads.svg\n   :target: https://anaconda.org/conda-forge/cwltool\n\n.. |quay.io container| image:: https://quay.io/repository/commonwl/cwltool/status\n   :target: https://quay.io/repository/commonwl/cwltool\n\n.. |docs status| image:: https://readthedocs.org/projects/cwltool/badge/?version=latest\n   :target: https://cwltool.readthedocs.io/en/latest/?badge=latest\n   :alt: documentation status\n\nthis is the reference implementation of the `common workflow language open\nstandards <https://www.commonwl.org/>`_.  it is intended to be feature complete\nand provide comprehensive validation of cwl\nfiles as well as provide other tools related to working with cwl.\n\n``cwltool`` is written and tested for\n`python <https://www.python.org/>`_ ``3.x {x = 6, 8, 9, 10, 11}``\n\nthe reference implementation consists of two packages.  the ``cwltool`` package\nis the primary python module containing the reference implementation in the\n``cwltool`` module and console executable by the same name.\n\nthe ``cwlref-runner`` package is optional and provides an additional entry point\nunder the alias ``cwl-runner``, which is the implementation-agnostic name for the\ndefault cwl interpreter installed on a host.\n\n``cwltool`` is provided by the cwl project, `a member project of software freedom conservancy <https://sfconservancy.org/news/2018/apr/11/cwl-new-member-project/>`_\nand our `many contributors <https://github.com/common-workflow-language/cwltool/graphs/contributors>`_.\n\n.. contents:: table of contents\n\n*******\ninstall\n*******\n\n``cwltool`` packages\n====================\n\nyour operating system may offer cwltool directly. for `debian <https://tracker.debian.org/pkg/cwltool>`_, `ubuntu <https://launchpad.net/ubuntu/+source/cwltool>`_,\nand similar linux distribution try\n\n.. code:: bash\n\n   sudo apt-get install cwltool\n\nif you encounter an error, first try to update package information by using\n\n.. code:: bash\n\n   sudo apt-get update\n\nif you are running macos x or other unixes and you want to use packages prepared by the conda-forge project, then\nplease follow the install instructions for `conda-forge <https://conda-forge.org/#about>`_ (if you haven't already) and then\n\n.. code:: bash\n\n   conda install -c conda-forge cwltool\n\nall of the above methods of installing ``cwltool`` use packages that might contain bugs already fixed in newer versions or be missing desired features.\nif the packaged version of ``cwltool`` available to you is too old, then we recommend installing using ``pip`` and ``venv``\n\n.. code:: bash\n\n   python3 -m venv env      # create a virtual environment named 'env' in the current directory\n   source env/bin/activate  # activate environment before installing `cwltool`\n\nthen install the latest ``cwlref-runner`` package from pypi (which will install the latest ``cwltool`` package as\nwell)\n\n.. code:: bash\n\n  pip install cwlref-runner\n\nif installing alongside another cwl implementation (like ``toil-cwl-runner`` or ``arvados-cwl-runner``) then instead run\n\n.. code:: bash\n\n  pip install cwltool\n\nms windows users\n================\n\n1. `install windows subsystem for linux 2 and docker desktop <https://docs.docker.com/docker-for-windows/wsl/#prerequisites>`_. \n2. `install debian from the microsoft store <https://www.microsoft.com/en-us/p/debian/9msvkqc78pk6>`_.\n3. set debian as your default wsl 2 distro: ``wsl --set-default debian``.\n4. return to the docker desktop, choose ``settings`` \u2192 ``resources`` \u2192 ``wsl integration`` and under \"enable integration with additional distros\" select \"debian\",\n5. reboot if you have not yet already.\n6. launch debian and follow the linux instructions above (``apt-get install cwltool`` or use the ``venv`` method)\n\nnetwork problems from within wsl2? try `these instructions <https://github.com/microsoft/wsl/issues/4731#issuecomment-702176954>`_ followed by ``wsl --shutdown``.\n\n``cwltool`` development version\n===============================\n\nor you can skip the direct ``pip`` commands above and install the latest development version of ``cwltool``:\n\n.. code:: bash\n\n  git clone https://github.com/common-workflow-language/cwltool.git # clone (copy) the cwltool git repository\n  cd cwltool           # change to source directory that git clone just downloaded\n  pip install .[deps]  # installs ``cwltool`` from source\n  cwltool --version    # check if the installation works correctly\n\nremember, if co-installing multiple cwl implementations, then you need to\nmaintain which implementation ``cwl-runner`` points to via a symbolic file\nsystem link or `another facility <https://wiki.debian.org/debianalternatives>`_.\n\nrecommended software\n====================\n\nwe strongly suggested to have the following installed:\n\n* one of the following software container engines\n\n  * `podman <https://podman.io/getting-started/installation>`_\n  * `docker <https://docs.docker.com/engine/install/>`_\n  * singularity/apptainer: see `using singularity`_\n  * udocker: see `using udocker`_\n\n* `node.js <https://nodejs.org/en/download/>`_ for evaluating cwl expressions quickly\n  (required for `udocker` users, optional but recommended for the other container engines).\n\nwithout these, some examples in the cwl tutorials at http://www.commonwl.org/user_guide/ may not work.\n\n***********************\nrun on the command line\n***********************\n\nsimple command::\n\n  cwl-runner my_workflow.cwl my_inputs.yaml\n\nor if you have multiple cwl implementations installed and you want to override\nthe default cwl-runner then use::\n\n  cwltool my_workflow.cwl my_inputs.yml\n\nyou can set cwltool options in the environment with ``cwltool_options``,\nthese will be inserted at the beginning of the command line::\n\n  export cwltool_options=\"--debug\"\n\nuse with boot2docker on macos\n=============================\nboot2docker runs docker inside a virtual machine, and it only mounts ``users``\non it. the default behavior of cwl is to create temporary directories under e.g.\n``/var`` which is not accessible to docker containers.\n\nto run cwl successfully with boot2docker you need to set the ``--tmpdir-prefix``\nand ``--tmp-outdir-prefix`` to somewhere under ``/users``::\n\n    $ cwl-runner --tmp-outdir-prefix=/users/username/project --tmpdir-prefix=/users/username/project wc-tool.cwl wc-job.json\n\nusing udocker\n=============\n\nsome shared computing environments don't support docker software containers for technical or policy reasons.\nas a workaround, the cwl reference runner supports using the `udocker <https://github.com/indigo-dc/udocker>`_\nprogram on linux using ``--udocker``.\n\nudocker installation: https://indigo-dc.github.io/udocker/installation_manual.html\n\nrun `cwltool` just as you usually would, but with ``--udocker`` prior to the workflow path:\n\n.. code:: bash\n\n  cwltool --udocker https://github.com/common-workflow-language/common-workflow-language/raw/main/v1.0/v1.0/test-cwl-out2.cwl https://github.com/common-workflow-language/common-workflow-language/raw/main/v1.0/v1.0/empty.json\n\nas was mentioned in the `recommended software`_ section,\n\nusing singularity\n=================\n\n``cwltool`` can also use `singularity <https://github.com/hpcng/singularity/releases/>`_ version 2.6.1\nor later as a docker container runtime.\n``cwltool`` with singularity will run software containers specified in\n``dockerrequirement`` and therefore works with docker images only, native\nsingularity images are not supported. to use singularity as the docker container\nruntime, provide ``--singularity`` command line option to ``cwltool``.\nwith singularity, ``cwltool`` can pass all cwl v1.0 conformance tests, except\nthose involving docker container entrypoints.\n\nexample\n\n.. code:: bash\n\n  cwltool --singularity https://github.com/common-workflow-language/common-workflow-language/raw/main/v1.0/v1.0/cat3-tool-mediumcut.cwl https://github.com/common-workflow-language/common-workflow-language/raw/main/v1.0/v1.0/cat-job.json\n\nrunning a tool or workflow from remote or local locations\n=========================================================\n\n``cwltool`` can run tool and workflow descriptions on both local and remote\nsystems via its support for http[s] urls.\n\ninput job files and workflow steps (via the `run` directive) can reference cwl\ndocuments using absolute or relative local filesystem paths. if a relative path\nis referenced and that document isn't found in the current directory, then the\nfollowing locations will be searched:\nhttp://www.commonwl.org/v1.0/commandlinetool.html#discovering_cwl_documents_on_a_local_filesystem\n\nyou can also use `cwldep <https://github.com/common-workflow-language/cwldep>`_\nto manage dependencies on external tools and workflows.\n\noverriding workflow requirements at load time\n=============================================\n\nsometimes a workflow needs additional requirements to run in a particular\nenvironment or with a particular dataset.  to avoid the need to modify the\nunderlying workflow, cwltool supports requirement \"overrides\".\n\nthe format of the \"overrides\" object is a mapping of item identifier (workflow,\nworkflow step, or command line tool) to the process requirements that should be applied.\n\n.. code:: yaml\n\n  cwltool:overrides:\n    echo.cwl:\n      requirements:\n        envvarrequirement:\n          envdef:\n            message: override_value\n\noverrides can be specified either on the command line, or as part of the job\ninput document.  workflow steps are identified using the name of the workflow\nfile followed by the step name as a document fragment identifier \"#id\".\noverride identifiers are relative to the top-level workflow document.\n\n.. code:: bash\n\n  cwltool --overrides overrides.yml my-tool.cwl my-job.yml\n\n.. code:: yaml\n\n  input_parameter1: value1\n  input_parameter2: value2\n  cwltool:overrides:\n    workflow.cwl#step1:\n      requirements:\n        envvarrequirement:\n          envdef:\n            message: override_value\n\n.. code:: bash\n\n  cwltool my-tool.cwl my-job-with-overrides.yml\n\n\ncombining parts of a workflow into a single document\n====================================================\n\nuse ``--pack`` to combine a workflow made up of multiple files into a\nsingle compound document.  this operation takes all the cwl files\nreferenced by a workflow and builds a new cwl document with all\nprocess objects (commandlinetool and workflow) in a list in the\n``$graph`` field.  cross references (such as ``run:`` and ``source:``\nfields) are updated to internal references within the new packed\ndocument.  the top-level workflow is named ``#main``.\n\n.. code:: bash\n\n  cwltool --pack my-wf.cwl > my-packed-wf.cwl\n\n\nrunning only part of a workflow\n===============================\n\nyou can run a partial workflow with the ``--target`` (``-t``) option.  this\ntakes the name of an output parameter, workflow step, or input\nparameter in the top-level workflow.  you may provide multiple\ntargets.\n\n.. code:: bash\n\n  cwltool --target step3 my-wf.cwl\n\nif a target is an output parameter, it will only run only the steps\nthat contribute to that output.  if a target is a workflow step, it\nwill run the workflow starting from that step.  if a target is an\ninput parameter, it will only run the steps connected to\nthat input.\n\nuse ``--print-targets`` to get a listing of the targets of a workflow.\nto see which steps will run, use ``--print-subgraph`` with\n``--target`` to get a printout of the workflow subgraph for the\nselected targets.\n\n.. code:: bash\n\n  cwltool --print-targets my-wf.cwl\n\n  cwltool --target step3 --print-subgraph my-wf.cwl > my-wf-starting-from-step3.cwl\n\n\nvisualizing a cwl document\n==========================\n\nthe ``--print-dot`` option will print a file suitable for graphviz ``dot`` program.  here is a bash onliner to generate a scalable vector graphic (svg) file:\n\n.. code:: bash\n\n  cwltool --print-dot my-wf.cwl | dot -tsvg > my-wf.svg\n\nmodeling a cwl document as rdf\n==============================\n\ncwl documents can be expressed as rdf triple graphs.\n\n.. code:: bash\n\n  cwltool --print-rdf --rdf-serializer=turtle mywf.cwl\n\n\nenvironment variables in cwltool\n================================\n\nthis reference implementation supports several ways of setting\nenvironment variables for tools, in addition to the standard\n``envvarrequirement``. the sequence of steps applied to create the\nenvironment is:\n\n0. if the ``--preserve-entire-environment`` flag is present, then begin with the current\n   environment, else begin with an empty environment.\n\n1. add any variables specified by ``--preserve-environment`` option(s).\n\n2. set ``tmpdir`` and ``home`` per `the cwl v1.0+ commandlinetool specification <https://www.commonwl.org/v1.0/commandlinetool.html#runtime_environment>`_.\n\n3. apply any ``envvarrequirement`` from the ``commandlinetool`` description.\n\n4. apply any manipulations required by any ``cwltool:mpirequirement`` extensions.\n\n5. substitute any secrets required by ``secrets`` extension.\n\n6. modify the environment in response to ``softwarerequirement`` (see below).\n\n\nleveraging softwarerequirements (beta)\n--------------------------------------\n\ncwl tools may be decorated with ``softwarerequirement`` hints that cwltool\nmay in turn use to resolve to packages in various package managers or\ndependency management systems such as `environment modules\n<http://modules.sourceforge.net/>`__.\n\nutilizing ``softwarerequirement`` hints using cwltool requires an optional\ndependency, for this reason be sure to use specify the ``deps`` modifier when\ninstalling cwltool. for instance::\n\n  $ pip install 'cwltool[deps]'\n\ninstalling cwltool in this fashion enables several new command line options.\nthe most general of these options is ``--beta-dependency-resolvers-configuration``.\nthis option allows one to specify a dependency resolver's configuration file.\nthis file may be specified as either xml or yaml and very simply describes various\nplugins to enable to \"resolve\" ``softwarerequirement`` dependencies.\n\nusing these hints will allow cwltool to modify the environment in\nwhich your tool runs, for example by loading one or more environment\nmodules. the environment is constructed as above, then the environment\nmay modified by the selected tool resolver.  this currently means that\nyou cannot override any environment variables set by the selected tool\nresolver. note that the environment given to the configured dependency\nresolver has the variable `_cwltool` set to `1` to allow introspection.\n\nto discuss some of these plugins and how to configure them, first consider the\nfollowing ``hint`` definition for an example cwl tool.\n\n.. code:: yaml\n\n  softwarerequirement:\n    packages:\n    - package: seqtk\n      version:\n      - r93\n\nnow imagine deploying cwltool on a cluster with software modules installed\nand that a ``seqtk`` module is available at version ``r93``. this means cluster\nusers likely won't have the binary ``seqtk`` on their ``path`` by default, but after\nsourcing this module with the command ``modulecmd sh load seqtk/r93`` ``seqtk`` is\navailable on the ``path``. a simple dependency resolvers configuration file, called\n``dependency-resolvers-conf.yml`` for instance, that would enable cwltool to source\nthe correct module environment before executing the above tool would simply be:\n\n.. code:: yaml\n\n  - type: modules\n\nthe outer list indicates that one plugin is being enabled, the plugin parameters are\ndefined as a dictionary for this one list item. there is only one required parameter\nfor the plugin above, this is ``type`` and defines the plugin type. this parameter\nis required for all plugins. the available plugins and the parameters\navailable for each are documented (incompletely) `here\n<https://docs.galaxyproject.org/en/latest/admin/dependency_resolvers.html>`__.\nunfortunately, this documentation is in the context of galaxy tool\n``requirement`` s instead of cwl ``softwarerequirement`` s, but the concepts map fairly directly.\n\ncwltool is distributed with an example of such seqtk tool and sample corresponding\njob. it could executed from the cwltool root using a dependency resolvers\nconfiguration file such as the above one using the command::\n\n  cwltool --beta-dependency-resolvers-configuration /path/to/dependency-resolvers-conf.yml \\\n      tests/seqtk_seq.cwl \\\n      tests/seqtk_seq_job.json\n\nthis example demonstrates both that cwltool can leverage\nexisting software installations and also handle workflows with dependencies\non different versions of the same software and libraries. however the above\nexample does require an existing module setup so it is impossible to test this example\n\"out of the box\" with cwltool. for a more isolated test that demonstrates all\nthe same concepts - the resolver plugin type ``galaxy_packages`` can be used.\n\n\"galaxy packages\" are a lighter-weight alternative to environment modules that are\nreally just defined by a way to lay out directories into packages and versions\nto find little scripts that are sourced to modify the environment. they have\nbeen used for years in galaxy community to adapt galaxy tools to cluster\nenvironments but require neither knowledge of galaxy nor any special tools to\nsetup. these should work just fine for cwl tools.\n\nthe cwltool source code repository's test directory is setup with a very simple\ndirectory that defines a set of \"galaxy  packages\" (but really just defines one\npackage named ``random-lines``). the directory layout is simply::\n\n  tests/test_deps_env/\n    random-lines/\n      1.0/\n        env.sh\n\nif the ``galaxy_packages`` plugin is enabled and pointed at the\n``tests/test_deps_env`` directory in cwltool's root and a ``softwarerequirement``\nsuch as the following is encountered.\n\n.. code:: yaml\n\n  hints:\n    softwarerequirement:\n      packages:\n      - package: 'random-lines'\n        version:\n        - '1.0'\n\nthen cwltool will simply find that ``env.sh`` file and source it before executing\nthe corresponding tool. that ``env.sh`` script is only responsible for modifying\nthe job's ``path`` to add the required binaries.\n\nthis is a full example that works since resolving \"galaxy packages\" has no\nexternal requirements. try it out by executing the following command from cwltool's\nroot directory::\n\n  cwltool --beta-dependency-resolvers-configuration tests/test_deps_env_resolvers_conf.yml \\\n      tests/random_lines.cwl \\\n      tests/random_lines_job.json\n\nthe resolvers configuration file in the above example was simply:\n\n.. code:: yaml\n\n  - type: galaxy_packages\n    base_path: ./tests/test_deps_env\n\nit is possible that the ``softwarerequirement`` s in a given cwl tool will not\nmatch the module names for a given cluster. such requirements can be re-mapped\nto specific deployed packages or versions using another file specified using\nthe resolver plugin parameter `mapping_files`. we will\ndemonstrate this using `galaxy_packages,` but the concepts apply equally well\nto environment modules or conda packages (described below), for instance.\n\nso consider the resolvers configuration file.\n(`tests/test_deps_env_resolvers_conf_rewrite.yml`):\n\n.. code:: yaml\n\n  - type: galaxy_packages\n    base_path: ./tests/test_deps_env\n    mapping_files: ./tests/test_deps_mapping.yml\n\nand the corresponding mapping configuration file (`tests/test_deps_mapping.yml`):\n\n.. code:: yaml\n\n  - from:\n      name: randomlines\n      version: 1.0.0-rc1\n    to:\n      name: random-lines\n      version: '1.0'\n\nthis is saying if cwltool encounters a requirement of ``randomlines`` at version\n``1.0.0-rc1`` in a tool, to rewrite to our specific plugin as ``random-lines`` at\nversion ``1.0``. cwltool has such a test tool called ``random_lines_mapping.cwl``\nthat contains such a source ``softwarerequirement``. to try out this example with\nmapping, execute the following command from the cwltool root directory::\n\n  cwltool --beta-dependency-resolvers-configuration tests/test_deps_env_resolvers_conf_rewrite.yml \\\n      tests/random_lines_mapping.cwl \\\n      tests/random_lines_job.json\n\nthe previous examples demonstrated leveraging existing infrastructure to\nprovide requirements for cwl tools. if instead a real package manager is used\ncwltool has the opportunity to install requirements as needed. while initial\nsupport for homebrew/linuxbrew plugins is available, the most developed such\nplugin is for the `conda <https://conda.io/docs/#>`__ package manager. conda has the nice properties\nof allowing multiple versions of a package to be installed simultaneously,\nnot requiring evaluated permissions to install conda itself or packages using\nconda, and being cross-platform. for these reasons, cwltool may run as a normal\nuser, install its own conda environment and manage multiple versions of conda packages\non linux and mac os x.\n\nthe conda plugin can be endlessly configured, but a sensible set of defaults\nthat has proven a powerful stack for dependency management within the galaxy tool\ndevelopment ecosystem can be enabled by simply passing cwltool the\n``--beta-conda-dependencies`` flag.\n\nwith this, we can use the seqtk example above without docker or any externally managed services - cwltool should install everything it needs\nand create an environment for the tool. try it out with the following command::\n\n  cwltool --beta-conda-dependencies tests/seqtk_seq.cwl tests/seqtk_seq_job.json\n\nthe cwl specification allows uris to be attached to ``softwarerequirement`` s\nthat allow disambiguation of package names. if the mapping files described above\nallow deployers to adapt tools to their infrastructure, this mechanism allows\ntools to adapt their requirements to multiple package managers. to demonstrate\nthis within the context of the seqtk, we can simply break the package name we\nuse and then specify a specific conda package as follows:\n\n.. code:: yaml\n\n  hints:\n    softwarerequirement:\n      packages:\n      - package: seqtk_seq\n        version:\n        - '1.2'\n        specs:\n        - https://anaconda.org/bioconda/seqtk\n        - https://packages.debian.org/sid/seqtk\n\nthe example can be executed using the command::\n\n  cwltool --beta-conda-dependencies tests/seqtk_seq_wrong_name.cwl tests/seqtk_seq_job.json\n\nthe plugin framework for managing the resolution of these software requirements\nas maintained as part of `galaxy-tool-util <https://github.com/galaxyproject/galaxy/tree/dev/packages/tool_util>`__ - a small,\nportable subset of the galaxy project. more information on configuration and implementation can be found\nat the following links:\n\n- `dependency resolvers in galaxy <https://docs.galaxyproject.org/en/latest/admin/dependency_resolvers.html>`__\n- `conda for [galaxy] tool dependencies <https://docs.galaxyproject.org/en/latest/admin/conda_faq.html>`__\n- `mapping files - implementation <https://github.com/galaxyproject/galaxy/commit/495802d229967771df5b64a2f79b88a0eaf00edb>`__\n- `specifications - implementation <https://github.com/galaxyproject/galaxy/commit/81d71d2e740ee07754785306e4448f8425f890bc>`__\n- `initial cwltool integration pull request <https://github.com/common-workflow-language/cwltool/pull/214>`__\n\nuse with ga4gh tool registry api\n================================\n\ncwltool can launch tools directly from `ga4gh tool registry api`_ endpoints.\n\nby default, cwltool searches https://dockstore.org/ .  use ``--add-tool-registry`` to add other registries to the search path.\n\nfor example ::\n\n  cwltool quay.io/collaboratory/dockstore-tool-bamstats:develop test.json\n\nand (defaults to latest when a version is not specified) ::\n\n  cwltool quay.io/collaboratory/dockstore-tool-bamstats test.json\n\nfor this example, grab the test.json (and input file) from https://github.com/cancercollaboratory/dockstore-tool-bamstats ::\n\n  wget https://dockstore.org/api/api/ga4gh/v2/tools/quay.io%2fbriandoconnor%2fdockstore-tool-bamstats/versions/develop/plain-cwl/descriptor/test.json\n  wget https://github.com/cancercollaboratory/dockstore-tool-bamstats/raw/develop/rna.srr948778.bam\n\n\n.. _`ga4gh tool registry api`: https://github.com/ga4gh/tool-registry-schemas\n\nrunning mpi-based tools that need to be launched\n================================================\n\ncwltool supports an extension to the cwl spec\n``http://commonwl.org/cwltool#mpirequirement``. when the tool\ndefinition has this in its ``requirements``/``hints`` section, and\ncwltool has been run with ``--enable-ext``, then the tool's command\nline will be extended with the commands needed to launch it with\n``mpirun`` or similar. you can specify the number of processes to\nstart as either a literal integer or an expression (that will result\nin an integer). for example::\n\n  #!/usr/bin/env cwl-runner\n  cwlversion: v1.1\n  class: commandlinetool\n  $namespaces:\n    cwltool: \"http://commonwl.org/cwltool#\"\n  requirements:\n    cwltool:mpirequirement:\n      processes: $(inputs.nproc)\n  inputs:\n    nproc:\n      type: int\n\ninteraction with containers: the mpirequirement currently prepends its\ncommands to the front of the command line that is constructed. if you\nwish to run a containerized application in parallel, for simple use\ncases, this does work with singularity, depending upon the platform\nsetup. however, this combination should be considered \"alpha\" -- please\ndo report any issues you have! this does not work with docker at the\nmoment. (more precisely, you get `n` copies of the same single process\nimage run at the same time that cannot communicate with each other.)\n\nthe host-specific parameters are configured in a simple yaml file\n(specified with the ``--mpi-config-file`` flag). the allowed keys are\ngiven in the following table; all are optional.\n\n+----------------+------------------+----------+------------------------------+\n| key            | type             | default  | description                  |\n+================+==================+==========+==============================+\n| runner         | str              | \"mpirun\" | the primary command to use.  |\n+----------------+------------------+----------+------------------------------+\n| nproc_flag     | str              | \"-n\"     | flag to set number of        |\n|                |                  |          | processes to start.          |\n+----------------+------------------+----------+------------------------------+\n| default_nproc  | int              | 1        | default number of processes. |\n+----------------+------------------+----------+------------------------------+\n| extra_flags    | list[str]        | []       | a list of any other flags to |\n|                |                  |          | be added to the runner's     |\n|                |                  |          | command line before          |\n|                |                  |          | the ``basecommand``.         |\n+----------------+------------------+----------+------------------------------+\n| env_pass       | list[str]        | []       | a list of environment        |\n|                |                  |          | variables that should be     |\n|                |                  |          | passed from the host         |\n|                |                  |          | environment through to the   |\n|                |                  |          | tool (e.g., giving the       |\n|                |                  |          | node list as set by your     |\n|                |                  |          | scheduler).                  |\n+----------------+------------------+----------+------------------------------+\n| env_pass_regex | list[str]        | []       | a list of python regular     |\n|                |                  |          | expressions that will be     |\n|                |                  |          | matched against the host's   |\n|                |                  |          | environment. those that match|\n|                |                  |          | will be passed through.      |\n+----------------+------------------+----------+------------------------------+\n| env_set        | mapping[str,str] | {}       | a dictionary whose keys are  |\n|                |                  |          | the environment variables set|\n|                |                  |          | and the values being the     |\n|                |                  |          | values.                      |\n+----------------+------------------+----------+------------------------------+\n\n\nenabling fast parser (experimental)\n===================================\n\nfor very large workflows, `cwltool` can spend a lot of time in\ninitialization, before the first step runs.  there is an experimental\nflag ``--fast-parser`` which can dramatically reduce the\ninitialization overhead, however as of this writing it has several limitations:\n\n- error reporting in general is worse than the standard parser, you will want to use it with workflows that you know are already correct.\n\n- it does not check for dangling links (these will become runtime errors instead of loading errors)\n\n- several other cases fail, as documented in https://github.com/common-workflow-language/cwltool/pull/1720\n\n***********\ndevelopment\n***********\n\nrunning tests locally\n=====================\n\n-  running basic tests ``(/tests)``:\n\nto run the basic tests after installing `cwltool` execute the following:\n\n.. code:: bash\n\n  pip install -rtest-requirements.txt\n  pytest   ## n.b. this requires node.js or docker to be available\n\nto run various tests in all supported python environments, we use `tox <https://github.com/common-workflow-language/cwltool/tree/main/tox.ini>`_. to run the test suite in all supported python environments\nfirst clone the complete code repository (see the ``git clone`` instructions above) and then run\nthe following in the terminal:\n``pip install \"tox<4\"; tox -p``\n\nlist of all environment can be seen using:\n``tox --listenvs``\nand running a specific test env using:\n``tox -e <env name>``\nand additionally run a specific test using this format:\n``tox -e py310-unit -- -v tests/test_examples.py::test_scandeps``\n\n-  running the entire suite of cwl conformance tests:\n\nthe github repository for the cwl specifications contains a script that tests a cwl\nimplementation against a wide array of valid cwl files using the `cwltest <https://github.com/common-workflow-language/cwltest>`_\nprogram\n\ninstructions for running these tests can be found in the common workflow language specification repository at https://github.com/common-workflow-language/common-workflow-language/blob/main/conformance_tests.md .\n\nimport as a module\n==================\n\nadd\n\n.. code:: python\n\n  import cwltool\n\nto your script.\n\nthe easiest way to use cwltool to run a tool or workflow from python is to use a factory\n\n.. code:: python\n\n  import cwltool.factory\n  fac = cwltool.factory.factory()\n\n  echo = fac.make(\"echo.cwl\")\n  result = echo(inp=\"foo\")\n\n  # result[\"out\"] == \"foo\"\n\n\ncwl tool control flow\n=====================\n\ntechnical outline of how cwltool works internally, for maintainers.\n\n#. use cwl ``load_tool()`` to load document.\n\n   #. fetches the document from file or url\n   #. applies preprocessing (syntax/identifier expansion and normalization)\n   #. validates the document based on cwlversion\n   #. if necessary, updates the document to the latest spec\n   #. constructs a process object using ``make_tool()``` callback.  this yields a\n      commandlinetool, workflow, or expressiontool.  for workflows, this\n      recursively constructs each workflow step.\n   #. to construct custom types for commandlinetool, workflow, or\n      expressiontool, provide a custom ``make_tool()``\n\n#. iterate on the ``job()`` method of the process object to get back runnable jobs.\n\n   #. ``job()`` is a generator method (uses the python iterator protocol)\n   #. each time the ``job()`` method is invoked in an iteration, it returns one\n      of: a runnable item (an object with a ``run()`` method), ``none`` (indicating\n      there is currently no work ready to run) or end of iteration (indicating\n      the process is complete.)\n   #. invoke the runnable item by calling ``run()``.  this runs the tool and gets output.\n   #. an output callback reports the output of a process.\n   #. ``job()`` may be iterated over multiple times.  it will yield all the work\n      that is currently ready to run and then yield none.\n\n#. ``workflow`` objects create a corresponding ``workflowjob`` and ``workflowjobstep`` objects to hold the workflow state for the duration of the job invocation.\n\n   #. the workflowjob iterates over each workflowjobstep and determines if the\n      inputs the step are ready.\n   #. when a step is ready, it constructs an input object for that step and\n      iterates on the ``job()`` method of the workflow job step.\n   #. each runnable item is yielded back up to top-level run loop\n   #. when a step job completes and receives an output callback, the\n      job outputs are assigned to the output of the workflow step.\n   #. when all steps are complete, the intermediate files are moved to a final\n      workflow output, intermediate directories are deleted, and the workflow's output callback is called.\n\n#. ``commandlinetool`` job() objects yield a single runnable object.\n\n   #. the commandlinetool ``job()`` method calls ``make_job_runner()`` to create a\n      ``commandlinejob`` object\n   #. the job method configures the commandlinejob object by setting public\n      attributes\n   #. the job method iterates over file and directories inputs to the\n      commandlinetool and creates a \"path map\".\n   #. files are mapped from their \"resolved\" location to a \"target\" path where\n      they will appear at tool invocation (for example, a location inside a\n      docker container.)  the target paths are used on the command line.\n   #. files are staged to targets paths using either docker volume binds (when\n      using containers) or symlinks (if not).  this staging step enables files\n      to be logically rearranged or renamed independent of their source layout.\n   #. the ``run()`` method of commandlinejob executes the command line tool or\n      docker container, waits for it to complete, collects output, and makes\n      the output callback.\n\nextension points\n================\n\nthe following functions can be passed to main() to override or augment\nthe listed behaviors.\n\nexecutor\n  ::\n\n    executor(tool, job_order_object, runtimecontext, logger)\n      (process, dict[text, any], runtimecontext) -> tuple[dict[text, any], text]\n\n  an implementation of the top-level workflow execution loop should\n  synchronously run a process object to completion and return the\n  output object.\n\nversionfunc\n  ::\n\n    ()\n      () -> text\n\n  return version string.\n\nlogger_handler\n  ::\n\n    logger_handler\n      logging.handler\n\n  handler object for logging.\n\nthe following functions can be set in loadingcontext to override or\naugment the listed behaviors.\n\nfetcher_constructor\n  ::\n\n    fetcher_constructor(cache, session)\n      (dict[unicode, unicode], requests.sessions.session) -> fetcher\n\n  construct a fetcher object with the supplied cache and http session.\n\nresolver\n  ::\n\n    resolver(document_loader, document)\n      (loader, union[text, dict[text, any]]) -> text\n\n  resolve a relative document identifier to an absolute one that can be fetched.\n\nthe following functions can be set in runtimecontext to override or\naugment the listed behaviors.\n\nconstruct_tool_object\n  ::\n\n    construct_tool_object(toolpath_object, loadingcontext)\n      (mutablemapping[text, any], loadingcontext) -> process\n\n  hook to construct a process object (eg commandlinetool) object from a document.\n\nselect_resources\n  ::\n\n    selectresources(request)\n      (dict[str, int], runtimecontext) -> dict[text, int]\n\n  take a resource request and turn it into a concrete resource assignment.\n\nmake_fs_access\n  ::\n\n    make_fs_access(basedir)\n      (text) -> stdfsaccess\n\n  return a file system access object.\n\nin addition, when providing custom subclasses of process objects, you can override the following methods:\n\ncommandlinetool.make_job_runner\n  ::\n\n    make_job_runner(runtimecontext)\n      (runtimecontext) -> type[jobbase]\n\n  create and return a job runner object (this implements concrete execution of a command line tool).\n\nworkflow.make_workflow_step\n  ::\n\n    make_workflow_step(toolpath_object, pos, loadingcontext, parentworkflowprov)\n      (dict[text, any], int, loadingcontext, optional[provenanceprofile]) -> workflowstep\n\n  create and return a workflow step object.\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "cwltool",
  "package_url": "https://pypi.org/project/cwltool/",
  "project_url": "https://pypi.org/project/cwltool/",
  "project_urls": {
    "Download": "https://github.com/common-workflow-language/cwltool",
    "Homepage": "https://github.com/common-workflow-language/cwltool"
  },
  "release_url": "https://pypi.org/project/cwltool/3.1.20231207110929/",
  "requires_dist": [
    "setuptools",
    "requests >=2.6.1",
    "ruamel.yaml <0.19,>=0.16",
    "rdflib <7.1.0,>=4.2.2",
    "shellescape <3.9,>=3.4.1",
    "schema-salad <9,>=8.4.20230426093816",
    "prov ==1.5.1",
    "mypy-extensions",
    "psutil >=5.6.6",
    "coloredlogs",
    "pydot >=1.4.1",
    "argcomplete",
    "pyparsing !=3.0.2",
    "cwl-utils >=0.32",
    "spython >=0.3.0",
    "importlib-resources >=1.4 ; python_version < \"3.9\"",
    "galaxy-tool-util !=23.0.1,!=23.0.2,!=23.0.3,!=23.0.4,!=23.0.5,<23.2,>=22.1.2 ; extra == 'deps'",
    "galaxy-util <23.2 ; extra == 'deps'"
  ],
  "requires_python": ">=3.8, <4",
  "summary": "common workflow language reference implementation",
  "version": "3.1.20231207110929",
  "releases": [],
  "developers": [
    "common-workflow-language@googlegroups.com",
    "common_workflow_language_working_group"
  ],
  "kwds": "make_workflow_step my_workflow workflowstep workflow workflows",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_cwltool",
  "homepage": "https://github.com/common-workflow-language/cwltool",
  "release_count": 425,
  "dependency_ids": [
    "pypi_argcomplete",
    "pypi_coloredlogs",
    "pypi_cwl_utils",
    "pypi_galaxy_tool_util",
    "pypi_galaxy_util",
    "pypi_importlib_resources",
    "pypi_mypy_extensions",
    "pypi_prov",
    "pypi_psutil",
    "pypi_pydot",
    "pypi_pyparsing",
    "pypi_rdflib",
    "pypi_requests",
    "pypi_ruamel.yaml",
    "pypi_schema_salad",
    "pypi_setuptools",
    "pypi_shellescape",
    "pypi_spython"
  ]
}