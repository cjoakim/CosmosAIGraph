{
  "classifiers": [
    "development status :: 5 - production/stable",
    "environment :: plugins",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "programming language :: python",
    "topic :: scientific/engineering :: human machine interfaces"
  ],
  "description": "# textdistance\n\n![textdistance logo](logo.png)\n\n[![build status](https://travis-ci.org/life4/textdistance.svg?branch=master)](https://travis-ci.org/life4/textdistance) [![pypi version](https://img.shields.io/pypi/v/textdistance.svg)](https://pypi.python.org/pypi/textdistance) [![status](https://img.shields.io/pypi/status/textdistance.svg)](https://pypi.python.org/pypi/textdistance) [![license](https://img.shields.io/pypi/l/textdistance.svg)](license)\n\n**textdistance** -- python library for comparing distance between two or more sequences by many algorithms.\n\nfeatures:\n\n- 30+ algorithms\n- pure python implementation\n- simple usage\n- more than two sequences comparing\n- some algorithms have more than one implementation in one class.\n- optional numpy usage for maximum speed.\n\n## algorithms\n\n### edit based\n\n| algorithm                                                                                 | class                | functions              |\n|-------------------------------------------------------------------------------------------|----------------------|------------------------|\n| [hamming](https://en.wikipedia.org/wiki/hamming_distance)                                 | `hamming`            | `hamming`              |\n| [mlipns](http://www.sial.iias.spb.su/files/386-386-1-pb.pdf)                              | `mlipns`             | `mlipns`               |\n| [levenshtein](https://en.wikipedia.org/wiki/levenshtein_distance)                         | `levenshtein`        | `levenshtein`          |\n| [damerau-levenshtein](https://en.wikipedia.org/wiki/damerau%e2%80%93levenshtein_distance) | `dameraulevenshtein` | `damerau_levenshtein`  |\n| [jaro-winkler](https://en.wikipedia.org/wiki/jaro%e2%80%93winkler_distance)               | `jarowinkler`        | `jaro_winkler`, `jaro` |\n| [strcmp95](http://cpansearch.perl.org/src/scw/text-jarowinkler-0.1/strcmp95.c)            | `strcmp95`           | `strcmp95`             |\n| [needleman-wunsch](https://en.wikipedia.org/wiki/needleman%e2%80%93wunsch_algorithm)      | `needlemanwunsch`    | `needleman_wunsch`     |\n| [gotoh](http://bioinfo.ict.ac.cn/~dbu/algorithmcourses/lectures/loa/lec6-sequence-alignment-affine-gaps-gotoh1982.pdf) | `gotoh`              | `gotoh`                |\n| [smith-waterman](https://en.wikipedia.org/wiki/smith%e2%80%93waterman_algorithm)          | `smithwaterman`      | `smith_waterman`       |\n\n### token based\n\n| algorithm                                                                                 | class                | functions     |\n|-------------------------------------------------------------------------------------------|----------------------|---------------|\n| [jaccard index](https://en.wikipedia.org/wiki/jaccard_index)                              | `jaccard`            | `jaccard`     |\n| [s\u00f8rensen\u2013dice coefficient](https://en.wikipedia.org/wiki/s%c3%b8rensen%e2%80%93dice_coefficient) | `sorensen`   | `sorensen`, `sorensen_dice`, `dice` |\n| [tversky index](https://en.wikipedia.org/wiki/tversky_index)                              | `tversky`            | `tversky`    |\n| [overlap coefficient](https://en.wikipedia.org/wiki/overlap_coefficient)                  | `overlap`            | `overlap`    |\n| [tanimoto distance](https://en.wikipedia.org/wiki/jaccard_index#tanimoto_similarity_and_distance) | `tanimoto`   | `tanimoto`   |\n| [cosine similarity](https://en.wikipedia.org/wiki/cosine_similarity)                      | `cosine`             | `cosine`     |\n| [monge-elkan](https://www.academia.edu/200314/generalized_monge-elkan_method_for_approximate_text_string_comparison) | `mongeelkan` | `monge_elkan` |\n| [bag distance](https://github.com/yomguithereal/talisman/blob/master/src/metrics/bag.js) | `bag`        | `bag`        |\n\n### sequence based\n\n| algorithm | class | functions |\n|-----------|-------|-----------|\n| [longest common subsequence similarity](https://en.wikipedia.org/wiki/longest_common_subsequence_problem)          | `lcsseq` | `lcsseq` |\n| [longest common substring similarity](https://docs.python.org/2/library/difflib.html#difflib.sequencematcher)      | `lcsstr` | `lcsstr` |\n| [ratcliff-obershelp similarity](https://en.wikipedia.org/wiki/gestalt_pattern_matching) | `ratcliffobershelp` | `ratcliff_obershelp` |\n\n### compression based\n\n[normalized compression distance](https://en.wikipedia.org/wiki/normalized_compression_distance#normalized_compression_distance) with different compression algorithms.\n\nclassic compression algorithms:\n\n| algorithm                                                                  | class       | function     |\n|----------------------------------------------------------------------------|-------------|--------------|\n| [arithmetic coding](https://en.wikipedia.org/wiki/arithmetic_coding)       | `arithncd`  | `arith_ncd`  |\n| [rle](https://en.wikipedia.org/wiki/run-length_encoding)                   | `rlencd`    | `rle_ncd`    |\n| [bwt rle](https://en.wikipedia.org/wiki/burrows%e2%80%93wheeler_transform) | `bwtrlencd` | `bwtrle_ncd` |\n\nnormal compression algorithms:\n\n| algorithm                                                                  | class        | function      |\n|----------------------------------------------------------------------------|--------------|---------------|\n| square root                                                                | `sqrtncd`    | `sqrt_ncd`    |\n| [entropy](https://en.wikipedia.org/wiki/entropy_(information_theory))      | `entropyncd` | `entropy_ncd` |\n\nwork in progress algorithms that compare two strings as array of bits:\n\n| algorithm                                  | class     | function   |\n|--------------------------------------------|-----------|------------|\n| [bz2](https://en.wikipedia.org/wiki/bzip2) | `bz2ncd`  | `bz2_ncd`  |\n| [lzma](https://en.wikipedia.org/wiki/lzma) | `lzmancd` | `lzma_ncd` |\n| [zlib](https://en.wikipedia.org/wiki/zlib) | `zlibncd` | `zlib_ncd` |\n\nsee [blog post](https://articles.life4web.ru/other/ncd/) for more details about ncd.\n\n### phonetic\n\n| algorithm                                                                    | class    | functions |\n|------------------------------------------------------------------------------|----------|-----------|\n| [mra](https://en.wikipedia.org/wiki/match_rating_approach)                   | `mra`    | `mra`     |\n| [editex](https://anhaidgroup.github.io/py_stringmatching/v0.3.x/editex.html) | `editex` | `editex`  |\n\n### simple\n\n| algorithm           | class      | functions  |\n|---------------------|------------|------------|\n| prefix similarity   | `prefix`   | `prefix`   |\n| postfix similarity  | `postfix`  | `postfix`  |\n| length distance     | `length`   | `length`   |\n| identity similarity | `identity` | `identity` |\n| matrix similarity   | `matrix`   | `matrix`   |\n\n## installation\n\n### stable\n\nonly pure python implementation:\n\n```bash\npip install textdistance\n```\n\nwith extra libraries for maximum speed:\n\n```bash\npip install \"textdistance[extras]\"\n```\n\nwith all libraries (required for [benchmarking](#benchmarks) and [testing](#running-tests)):\n\n```bash\npip install \"textdistance[benchmark]\"\n```\n\nwith algorithm specific extras:\n\n```bash\npip install \"textdistance[hamming]\"\n```\n\nalgorithms with available extras: `dameraulevenshtein`, `hamming`, `jaro`, `jarowinkler`, `levenshtein`.\n\n### dev\n\nvia pip:\n\n```bash\npip install -e git+https://github.com/life4/textdistance.git#egg=textdistance\n```\n\nor clone repo and install with some extras:\n\n```bash\ngit clone https://github.com/life4/textdistance.git\npip install -e \".[benchmark]\"\n```\n\n## usage\n\nall algorithms have 2 interfaces:\n\n1. class with algorithm-specific params for customizing.\n1. class instance with default params for quick and simple usage.\n\nall algorithms have some common methods:\n\n1. `.distance(*sequences)` -- calculate distance between sequences.\n1. `.similarity(*sequences)` -- calculate similarity for sequences.\n1. `.maximum(*sequences)` -- maximum possible value for distance and similarity. for any sequence: `distance + similarity == maximum`.\n1. `.normalized_distance(*sequences)` -- normalized distance between sequences. the return value is a float between 0 and 1, where 0 means equal, and 1 totally different.\n1. `.normalized_similarity(*sequences)` -- normalized similarity for sequences. the return value is a float between 0 and 1, where 0 means totally different, and 1 equal.\n\nmost common init arguments:\n\n1. `qval` -- q-value for split sequences into q-grams. possible values:\n    - 1 (default) -- compare sequences by chars.\n    - 2 or more -- transform sequences to q-grams.\n    - none -- split sequences by words.\n1. `as_set` -- for token-based algorithms:\n    - true -- `t` and `ttt` is equal.\n    - false (default) -- `t` and `ttt` is different.\n\n## examples\n\nfor example, [hamming distance](https://en.wikipedia.org/wiki/hamming_distance):\n\n```python\nimport textdistance\n\ntextdistance.hamming('test', 'text')\n# 1\n\ntextdistance.hamming.distance('test', 'text')\n# 1\n\ntextdistance.hamming.similarity('test', 'text')\n# 3\n\ntextdistance.hamming.normalized_distance('test', 'text')\n# 0.25\n\ntextdistance.hamming.normalized_similarity('test', 'text')\n# 0.75\n\ntextdistance.hamming(qval=2).distance('test', 'text')\n# 2\n\n```\n\nany other algorithms have same interface.\n\n## articles\n\na few articles with examples how to use textdistance in the real world:\n\n- [guide to fuzzy matching with python](http://theautomatic.net/2019/11/13/guide-to-fuzzy-matching-with-python/)\n- [string similarity \u2014 the basic know your algorithms guide!](https://itnext.io/string-similarity-the-basic-know-your-algorithms-guide-3de3d7346227)\n- [normalized compression distance](https://articles.life4web.ru/other/ncd/)\n\n## extra libraries\n\nfor main algorithms textdistance try to call known external libraries (fastest first) if available (installed in your system) and possible (this implementation can compare this type of sequences). [install](#installation) textdistance with extras for this feature.\n\nyou can disable this by passing `external=false` argument on init:\n\n```python3\nimport textdistance\nhamming = textdistance.hamming(external=false)\nhamming('text', 'testit')\n# 3\n```\n\nsupported libraries:\n\n1. [distance](https://github.com/doukremt/distance)\n1. [jellyfish](https://github.com/jamesturk/jellyfish)\n1. [py_stringmatching](https://github.com/anhaidgroup/py_stringmatching)\n1. [pylev](https://github.com/toastdriven/pylev)\n1. [levenshtein](https://github.com/maxbachmann/levenshtein)\n1. [pyxdameraulevenshtein](https://github.com/gfairchild/pyxdameraulevenshtein)\n\nalgorithms:\n\n1. dameraulevenshtein\n1. hamming\n1. jaro\n1. jarowinkler\n1. levenshtein\n\n## benchmarks\n\nwithout extras installation:\n\n| algorithm          | library               |    time |\n|--------------------|-----------------------|---------|\n| dameraulevenshtein | rapidfuzz             | 0.00312 |\n| dameraulevenshtein | jellyfish             | 0.00591 |\n| dameraulevenshtein | pyxdameraulevenshtein | 0.03335 |\n| dameraulevenshtein | **textdistance**      | 0.83524 |\n| hamming            | levenshtein           | 0.00038 |\n| hamming            | rapidfuzz             | 0.00044 |\n| hamming            | jellyfish             | 0.00091 |\n| hamming            | distance              | 0.00812 |\n| hamming            | **textdistance**      | 0.03531 |\n| jaro               | rapidfuzz             | 0.00092 |\n| jaro               | jellyfish             | 0.00191 |\n| jaro               | **textdistance**      | 0.07365 |\n| jarowinkler        | rapidfuzz             | 0.00094 |\n| jarowinkler        | jellyfish             | 0.00195 |\n| jarowinkler        | **textdistance**      | 0.07501 |\n| levenshtein        | rapidfuzz             | 0.00099 |\n| levenshtein        | levenshtein           | 0.00122 |\n| levenshtein        | jellyfish             | 0.00254 |\n| levenshtein        | pylev                 | 0.15688 |\n| levenshtein        | distance              | 0.28669 |\n| levenshtein        | **textdistance**      | 0.53902 |\n\ntotal: 24 libs.\n\nyeah, so slow. use textdistance on production only with extras.\n\ntextdistance use benchmark's results for algorithm's optimization and try to call fastest external lib first (if possible).\n\nyou can run benchmark manually on your system:\n\n```bash\npip install textdistance[benchmark]\npython3 -m textdistance.benchmark\n```\n\ntextdistance show benchmarks results table for your system and save libraries priorities into `libraries.json` file in textdistance's folder. this file will be used by textdistance for calling fastest algorithm implementation. default [libraries.json](textdistance/libraries.json) already included in package.\n\n## running tests\n\nall you need is [task](https://taskfile.dev/). see [taskfile.yml](./taskfile.yml) for the list of available commands. for example, to run tests including third-party libraries usage, execute `task pytest-external:run`.\n\n## contributing\n\nprs are welcome!\n\n- found a bug? fix it!\n- want to add more algorithms? sure! just make it with the same interface as other algorithms in the lib and add some tests.\n- can make something faster? great! just avoid external dependencies and remember that everything should work not only with strings.\n- something else that do you think is good? do it! just make sure that ci passes and everything from the readme is still applicable (interface, features, and so on).\n- have no time to code? tell your friends and subscribers about `textdistance`. more users, more contributions, more amazing features.\n\nthank you :heart:\n",
  "docs_url": null,
  "keywords": "distance between text strings sequences iterators",
  "license": "mit",
  "name": "textdistance",
  "package_url": "https://pypi.org/project/textdistance/",
  "project_url": "https://pypi.org/project/textdistance/",
  "project_urls": {
    "Download": "https://github.com/orsinium/textdistance/tarball/master",
    "Homepage": "https://github.com/orsinium/textdistance"
  },
  "release_url": "https://pypi.org/project/textdistance/4.6.0/",
  "requires_dist": [
    "rapidfuzz >=2.6.0 ; extra == 'dameraulevenshtein'",
    "jellyfish ; extra == 'dameraulevenshtein'",
    "pyxDamerauLevenshtein ; extra == 'dameraulevenshtein'",
    "Levenshtein ; extra == 'hamming'",
    "rapidfuzz >=2.6.0 ; extra == 'hamming'",
    "jellyfish ; extra == 'hamming'",
    "distance ; extra == 'hamming'",
    "rapidfuzz >=2.6.0 ; extra == 'jaro'",
    "Levenshtein ; extra == 'jaro'",
    "rapidfuzz >=2.6.0 ; extra == 'jarowinkler'",
    "jellyfish ; extra == 'jarowinkler'",
    "rapidfuzz >=2.6.0 ; extra == 'levenshtein'",
    "Levenshtein ; extra == 'levenshtein'",
    "jellyfish ; extra == 'all'",
    "numpy ; extra == 'all'",
    "Levenshtein ; extra == 'all'",
    "pyxDamerauLevenshtein ; extra == 'all'",
    "rapidfuzz >=2.6.0 ; extra == 'all'",
    "distance ; extra == 'all'",
    "pylev ; extra == 'all'",
    "py-stringmatching ; extra == 'all'",
    "tabulate ; extra == 'all'",
    "jellyfish ; extra == 'benchmark'",
    "numpy ; extra == 'benchmark'",
    "Levenshtein ; extra == 'benchmark'",
    "pyxDamerauLevenshtein ; extra == 'benchmark'",
    "rapidfuzz >=2.6.0 ; extra == 'benchmark'",
    "distance ; extra == 'benchmark'",
    "pylev ; extra == 'benchmark'",
    "py-stringmatching ; extra == 'benchmark'",
    "tabulate ; extra == 'benchmark'",
    "jellyfish ; extra == 'benchmarks'",
    "numpy ; extra == 'benchmarks'",
    "Levenshtein ; extra == 'benchmarks'",
    "pyxDamerauLevenshtein ; extra == 'benchmarks'",
    "rapidfuzz >=2.6.0 ; extra == 'benchmarks'",
    "distance ; extra == 'benchmarks'",
    "pylev ; extra == 'benchmarks'",
    "py-stringmatching ; extra == 'benchmarks'",
    "tabulate ; extra == 'benchmarks'",
    "jellyfish ; extra == 'common'",
    "numpy ; extra == 'common'",
    "Levenshtein ; extra == 'common'",
    "pyxDamerauLevenshtein ; extra == 'common'",
    "rapidfuzz >=2.6.0 ; extra == 'common'",
    "jellyfish ; extra == 'extra'",
    "numpy ; extra == 'extra'",
    "Levenshtein ; extra == 'extra'",
    "pyxDamerauLevenshtein ; extra == 'extra'",
    "rapidfuzz >=2.6.0 ; extra == 'extra'",
    "jellyfish ; extra == 'extras'",
    "numpy ; extra == 'extras'",
    "Levenshtein ; extra == 'extras'",
    "pyxDamerauLevenshtein ; extra == 'extras'",
    "rapidfuzz >=2.6.0 ; extra == 'extras'",
    "twine ; extra == 'lint'",
    "mypy ; extra == 'lint'",
    "isort ; extra == 'lint'",
    "flake8 ; extra == 'lint'",
    "types-tabulate ; extra == 'lint'",
    "flake8-blind-except ; extra == 'lint'",
    "flake8-bugbear ; extra == 'lint'",
    "flake8-commas ; extra == 'lint'",
    "flake8-logging-format ; extra == 'lint'",
    "flake8-mutable ; extra == 'lint'",
    "flake8-pep3101 ; extra == 'lint'",
    "flake8-quotes ; extra == 'lint'",
    "flake8-string-format ; extra == 'lint'",
    "flake8-tidy-imports ; extra == 'lint'",
    "pep8-naming ; extra == 'lint'",
    "hypothesis ; extra == 'test'",
    "isort ; extra == 'test'",
    "numpy ; extra == 'test'",
    "pytest ; extra == 'test'"
  ],
  "requires_python": ">=3.5",
  "summary": "compute distance between the two texts.",
  "version": "4.6.0",
  "releases": [],
  "developers": [
    "gram@orsinium.dev",
    "orsinium"
  ],
  "kwds": "textdistance elkan_method_for_approximate_text_string_comparison distance hamming_distance levenshtein_distance",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_textdistance",
  "homepage": "https://github.com/orsinium/textdistance",
  "release_count": 25,
  "dependency_ids": [
    "pypi_distance",
    "pypi_flake8",
    "pypi_flake8_blind_except",
    "pypi_flake8_bugbear",
    "pypi_flake8_commas",
    "pypi_flake8_logging_format",
    "pypi_flake8_mutable",
    "pypi_flake8_pep3101",
    "pypi_flake8_quotes",
    "pypi_flake8_string_format",
    "pypi_flake8_tidy_imports",
    "pypi_hypothesis",
    "pypi_isort",
    "pypi_jellyfish",
    "pypi_levenshtein",
    "pypi_mypy",
    "pypi_numpy",
    "pypi_pep8_naming",
    "pypi_py_stringmatching",
    "pypi_pylev",
    "pypi_pytest",
    "pypi_pyxdameraulevenshtein",
    "pypi_rapidfuzz",
    "pypi_tabulate",
    "pypi_twine",
    "pypi_types_tabulate"
  ]
}