{
  "classifiers": [],
  "description": "# pythena\n\nthis is a simple python module that will allow you to query athena the same way the aws athena console would. it only requires a database name and query string.\n\n## install\n\n```bash\npip install pythena\n```\n\n## setup\n\nbe sure to set up your aws authentication credentials. you can do so by using the aws cli and running\n\n```bash\npip install awscli\naws configure\n```\n\nmore help on configuring the aws cli here https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html\n\n## simple usage\n\n```python\nimport pythena\n\nathena_client = pythena.athena(\"mydatabase\") \n\n# returns results as a pandas dataframe\ndf = athena_client.execute(\"select * from mytable\")\n\nprint(df.sample(n=2)) # prints 2 rows from your dataframe\n```\n\n## connect to database\n\n```python\nimport boto3\nimport pythena\n\n# connect to a database\nathena_client = pythena.athena(database=\"mydatabase\")\n# connect to a database and override default aws region in your aws configuration\nathena_client = pythena.athena(database=\"mydatabase\", region='us-east-1')\n# connect to a database and override default profile in your aws configuration\nathena_client = pythena.athena(database=\"mydatabase\", session=boto3.session.session())\n\n```\n\n## athena_client.execute()\n\n```\nexecute(\n  query='sql_query',                   # required\n  s3_output_url='full_s3_path',        # optional (format example: 's3://mybucket/mydir'\n  save_results=true | false            # optional. defaults to true only when 's3_output_url' is provided. if true, the s3 results will not be deleted and an tuple is returned with the execution_id.\n  run_async=true | false               # optional. if true, allows you to run the query asynchronously. returns execution_id, use get_result(execution_id) to fetch it when finished\n  workgroup='primary'                  # optional. defaults to 'primary' workgroup\n)\n```\n\nnote: `execute()` returns a tuple (dataframe, execution_id) unless `run_async=true`, then it only returns the execution_id.\n\n## full usage examples\n\n```python\nimport boto3\nimport pythena\n\n# prints out all databases listed in the glue catalog\npythena.print_databases()\npythena.print_databases(region='us-east-1') # overrides default region\npythena.print_databases(session=boto3.session.session()) # overrides default profile\n\n# gets all databases and returns as a list\npythena.get_databases()\npythena.get_databases(region='us-east-1') # overrides default region\npythena.get_databases(session=boto3.session.session()) # overrides default profile\n\n# connect to a database\nathena_client = pythena.athena(database=\"mydatabase\")\nathena_client = pythena.athena(database=\"mydatabase\", region='us-east-1') # overrides default region\nathena_client = pythena.athena(database=\"mydatabase\", session=boto3.session.session()) # overrides default profile\n\n# prints out all tables in a database\nathena_client.print_tables()\n\n# gets all tables in the database you are connected to and returns as a list\nathena_client.get_tables()\n\n# execute a query, returns tuple with dataframe and athena execution_id\ndataframe, _ = athena_client.execute(query=\"select * from my_table\") # results are  returned as a dataframe\n\n# execute a query and save results to s3\ndataframe, execution_id = athena_client.execute(query=\"select * from my_table\", s3_output_url=\"s3://mybucket/mydir\") # results are  returned as a dataframe\n\n# get execution id and save results\ndataframe, execution_id = athena_client.execute(query=\"select * from my_table\", save_results=true)\n\n# get execution id and save results\ndataframe, execution_id = athena_client.execute(query=\"select * from my_table\", save_results=true)\n\n# execute a query asynchronously\nexecution_id = athena_client.execute(query=\"select * from my_table\", run_async=true) # returns just the execution id\ndataframe = athena_client.get_result(execution_id) # will report errors if query failed or let you know if it is still running\n\n# with asynchronous queries, can check status, get error, or cancel\npythena.get_query_status(execution_id)\npythena.get_query_error(execution_id)\npythena.cancel_query(execution_id)\n\n```\n\n## note\n\nby default, when executing athena queries, via boto3 or the aws athena console, the results are saved in an s3 bucket. this module by default, assuming a successful execution, will delete the s3 result file to keep s3 clean. if an s3_output_url is provided, then the results will be saved to that location and will not be deleted.\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "mozilla public license version 2.0",
  "name": "pythena",
  "package_url": "https://pypi.org/project/pythena/",
  "project_url": "https://pypi.org/project/pythena/",
  "project_urls": {
    "Homepage": "https://github.com/chrispruitt/pythena"
  },
  "release_url": "https://pypi.org/project/pythena/1.6.0/",
  "requires_dist": [
    "pandas (>=0.22.0)",
    "boto3 (>=1.9.90)",
    "botocore (>=1.12.90)",
    "retrying (>=1.3.3)"
  ],
  "requires_python": "",
  "summary": "a simple athena wrapper leveraging boto3 to execute queries and return results while only requiring a database and a query string.",
  "version": "1.6.0",
  "releases": [],
  "developers": [
    "chris",
    "chris.pruitt15@gmail.com"
  ],
  "kwds": "athena_client athena aws get_databases print_databases",
  "license_kwds": "mozilla public license version 2.0",
  "libtype": "pypi",
  "id": "pypi_pythena",
  "homepage": "https://github.com/chrispruitt/pythena",
  "release_count": 17,
  "dependency_ids": [
    "pypi_boto3",
    "pypi_botocore",
    "pypi_pandas",
    "pypi_retrying"
  ]
}