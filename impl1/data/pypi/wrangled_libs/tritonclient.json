{
  "classifiers": [
    "development status :: 5 - production/stable",
    "environment :: console",
    "intended audience :: developers",
    "intended audience :: information technology",
    "intended audience :: science/research",
    "license :: osi approved :: bsd license",
    "natural language :: english",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "topic :: scientific/engineering",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: scientific/engineering :: image recognition",
    "topic :: software development :: libraries",
    "topic :: utilities"
  ],
  "description": "see [download-using-python-package-installer-pip](https://github.com/triton-inference-server/client/tree/main#download-using-python-package-installer-pip) for package details.\n\nthe [client examples](https://github.com/triton-inference-server/client/tree/main/src/python/examples) demonstrate how to use the package to issue request to [triton inference server](https://github.com/triton-inference-server/server).\n",
  "docs_url": null,
  "keywords": "grpc,http,triton,tensorrt,inference,server,service,client,nvidia",
  "license": "bsd",
  "name": "tritonclient",
  "package_url": "https://pypi.org/project/tritonclient/",
  "project_url": "https://pypi.org/project/tritonclient/",
  "project_urls": {
    "Homepage": "https://developer.nvidia.com/nvidia-triton-inference-server"
  },
  "release_url": "https://pypi.org/project/tritonclient/2.41.0/",
  "requires_dist": [
    "numpy >=1.19.1",
    "python-rapidjson >=0.9.1",
    "grpcio >=1.41.0 ; extra == 'all'",
    "numpy >=1.19.1 ; extra == 'all'",
    "packaging >=14.1 ; extra == 'all'",
    "python-rapidjson >=0.9.1 ; extra == 'all'",
    "aiohttp <4.0.0,>=3.8.1 ; extra == 'all'",
    "geventhttpclient <=2.0.2,>=1.4.4 ; extra == 'all'",
    "cuda-python ; extra == 'all'",
    "cuda-python ; extra == 'cuda'",
    "grpcio >=1.41.0 ; extra == 'grpc'",
    "numpy >=1.19.1 ; extra == 'grpc'",
    "packaging >=14.1 ; extra == 'grpc'",
    "python-rapidjson >=0.9.1 ; extra == 'grpc'",
    "aiohttp <4.0.0,>=3.8.1 ; extra == 'http'",
    "geventhttpclient <=2.0.2,>=1.4.4 ; extra == 'http'",
    "numpy >=1.19.1 ; extra == 'http'",
    "python-rapidjson >=0.9.1 ; extra == 'http'"
  ],
  "requires_python": "",
  "summary": "python client library and utilities for communicating with triton inference server",
  "version": "2.41.0",
  "releases": [],
  "developers": [
    "nvidia_inc",
    "sw-dl-triton@nvidia.com"
  ],
  "kwds": "triton grpc pip client package",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_tritonclient",
  "homepage": "https://developer.nvidia.com/nvidia-triton-inference-server",
  "release_count": 44,
  "dependency_ids": [
    "pypi_aiohttp",
    "pypi_cuda_python",
    "pypi_geventhttpclient",
    "pypi_grpcio",
    "pypi_numpy",
    "pypi_packaging",
    "pypi_python_rapidjson"
  ]
}