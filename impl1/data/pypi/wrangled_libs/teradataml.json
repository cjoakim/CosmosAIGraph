{
  "classifiers": [
    "license :: other/proprietary license",
    "operating system :: macos :: macos x",
    "operating system :: microsoft :: windows",
    "operating system :: posix :: linux",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "topic :: database :: front-ends"
  ],
  "description": "## teradata python package for advanced analytics.\n\nteradataml makes available to python users a collection of analytic functions that reside on teradata vantage. this allows users to perform analytics on teradata vantage with no sql coding. in addition, the teradataml library provides functions for scaling data manipulation and transformation, data filtering and sub-setting, and can be used in conjunction with other open-source python libraries.\n\nfor community support, please visit the [teradata community](https://support.teradata.com/community?id=community_forum&sys_id=14fe131e1bf7f304682ca8233a4bcb1d).\n\nfor teradata customer support, please visit [teradata support](https://support.teradata.com/csm).\n\ncopyright 2023, teradata. all rights reserved.\n\n### table of contents\n* [release notes](#release-notes)\n* [installation and requirements](#installation-and-requirements)\n* [using the teradata python package](#using-the-teradata-python-package)\n* [documentation](#documentation)\n* [license](#license)\n\n## release notes:\n#### teradataml 17.20.00.06\n* ##### new features/functionality\n* ###### teradataml dataframecolumn a.k.a. columnexpression\n    * `columnexpression.nulls_first()` - displays null values at first.\n    * `columnexpression.nulls_last()` - displays null values at last.\n    * _bit byte manipulation functions_\n      * `dataframecolumn.bit_and()` - returns the logical and operation on the bits from\n         the column and corresponding bits from the argument.\n      * `dataframecolumn.bit_get()` - returns the bit specified by input argument from the column and \n         returns either 0 or 1 to indicate the value of that bit.\n      * `dataframecolumn.bit_or()` - returns the logical or operation on the bits from the column and \n         corresponding bits from the argument.\n      * `dataframecolumn.bit_xor()` - returns the bitwise xor operation on the binary representation of the\n         column and corresponding bits from the argument.\n      * `dataframecolumn.bitand()` - it is an alias for `dataframecolumn.bit_and()` function.\n      * `dataframecolumn.bitnot()` - returns a bitwise complement on the binary representation of the column.\n      * `dataframecolumn.bitor()` - it is an alias for `dataframecolumn.bit_or()` function.\n      * `dataframecolumn.bitwise_not()` - it is an alias for `dataframecolumn.bitnot()` function.\n      * `dataframecolumn.bitwisenot()` - it is an alias for `dataframecolumn.bitnot()` function.\n      * `dataframecolumn.bitxor()` - it is an alias for `dataframecolumn.bit_xor()` function.\n      * `dataframecolumn.countset()` - returns the count of the binary bits within the column that are either set to 1 \n         or set to 0, depending on the input argument value.\n      * `dataframecolumn.getbit()` - it is an alias for `dataframecolumn.bit_get()` function.\n      * `dataframecolumn.rotateleft()` - returns an expression rotated to the left by the specified number of bits,\n         with the most significant bits wrapping around to the right.\n      * `dataframecolumn.rotateright()` - returns an expression rotated to the right by the specified number of bits,\n         with the least significant bits wrapping around to the left.\n      * `dataframecolumn.setbit()` - sets the value of the bit specified by input argument to the value\n         of column.\n      * `dataframecolumn.shiftleft()` - returns the expression when value in column is shifted by the specified\n         number of bits to the left.\n      * `dataframecolumn.shiftright()` - returns the expression when column expression is shifted by the specified\n         number of bits to the right.\n      * `dataframecolumn.subbitstr()` - extracts a bit substring from the column expression based on the specified \n         bit position.\n      * `dataframecolumn.to_byte()` - converts a numeric data type to the vantage byte representation\n        (byte value) of the column expression value.\n\n    * _regular expression functions_\n      * `dataframecolumn.regexp_instr()` - searches string value in column for a match to value specified in argument.\n      * `dataframecolumn.regexp_replace()` - replaces the portions of string value in a column that matches the value \n         specified regex string and replaces with the replace string.\n      * `dataframecolumn.regexp_similar()` - compares value in column to value in argument and returns integer value.\n      * `dataframecolumn.regexp_substr()` - extracts a substring from column that matches a regular expression \n         specified in the input argument.\n\n* ###### open analytics framework (openaf) apis:\n    * manage all user environments.\n      * `create_env()`:\n        * user can create one or more user environments using newly added argument `template` by providing specifications in template json file. new feature allows user to create complete user environment, including file and library installation, in just single function call.\n    * userenv class \u2013 manage individual user environment.\n      * properties:\n        * `models` - supports listing of models in user environment.\n      * methods:\n        * `install_model()` - install a model in user environment.\n        * `uninstall_model()` - uninstall a model from user environment.\n        * `snapshot()`- take the snapshot of the user environment.\n\n* ###### teradataml: bring your own model\n    * _new functions_\n      * `datarobotpredict()` - score the data in vantage using the model trained externally in datarobot and stored \n                               in vantage.\n\n* ##### updates\n  * `dataframe.describe()`\n    * method now accepts an argument `statistics`, which specifies the aggregate operation to be performed. \n  * `dataframe.sort()` \n    * method now accepts columnexpressions as well.\n    * enables sorting using nulls first and nulls last.\n  * `view_log()` downloads the apply query logs based on query id.\n  * arguments which accepts floating numbers will accept integers also for `analytics database analytic functions`.\n  * argument `ignore_nulls` added to `dataframe.plot()` to ignore the null values while plotting the data.\n  * `dataframe.sample()` \n    * method supports column stratification. \n\n* ##### bug fixes\n  * `dataframecolumn.cast()` accepts all teradatasqlalchemy types.\n  * minor bug fix related to `dataframe.merge()`.\n\n#### teradataml 17.20.00.05\n* ##### new features/functionality\n  * ###### teradataml: hyperparameter-tuning - technique to identify best model parameters.\n    hyperparameter tuning is an\u00a0optimization method to determine the optimal\u00a0set of \n    hyperparameters\u00a0for the given\u00a0dataset and learning model. teradataml hyperparameter tuning feature\n    offers best model identification, parallel execution, early stopping feature, best data identification, \n    model evaluation, model prediction, live logging, input data hyper-parameterization, input data sampling, \n    numerous scoring functions, hyper-parameterization for non-model trainer functions.  \n    * `gridsearch`\n      gridsearch is an exhaustive search algorithm that covers all possible\n      parameter values to identify optimal hyperparameters.\n      * methods of gridsearch\n        * `__init__()` - instantiate an object of gridsearch for given model function and parameters.\n        * `evaluate()` - function to perform evaluation on the given teradataml dataframe using default model.\n        * `fit()` - function to perform hyperparameter-tuning for given hyperparameters and model on teradataml dataframe.\n        * `get_error_log()` - useful to get the error log if model execution failed, using the model identifier.\n        * `get_input_data()` - useful to get the input data using the data identifier, when input data is also parameterized.\n        * `get_model()` - returns the trained model for the given model identifier.\n        * `get_parameter_grid()` - returns the hyperparameter space used for hyperparameter optimization.\n        * `is_running()` - returns the execution status of hyperaparameter tuning.\n        * `predict()` - function to perform prediction on the given teradataml dataframe using default model.\n        * `set_model()` -  function to update the default model.\n      * properties of gridsearch\n        * `best_data_id` - returns the best data identifier used for model training.\n        * `best_model` - returns the best trained model.\n        * `best_model_id` - returns the identifier for best model.\n        * `best_params_` - returns the best set of hyperparameter.\n        * `best_sampled_data_` - returns the best sampled data used to train the best model.\n        * `best_score_` - returns the best trained model score.\n        * `model_stats` - returns the model evaluation reports.\n        * `models` - returns the metadata of all the models.\n    * `randomsearch`\n      randomsearch algorithm performs random sampling on hyperparameter \n      space to identify optimal hyperparameters.\n      * methods of randomsearch\n        * `__init__()` - instantiate an object of randomsearch for given model function and parameters.\n        * `evaluate()` - function to perform evaluation on the given teradataml dataframe using default model.\n        * `fit()` - function to perform hyperparameter-tuning for given hyperparameters and model on teradataml dataframe.\n        * `get_error_log()` - useful to get the error log if model execution failed, using the model identifier.\n        * `get_input_data()` - useful to get the input data using the data identifier, when input data is also parameterized.\n        * `get_model()` - returns the trained model for the given model identifier.\n        * `get_parameter_grid()` - returns the hyperparameter space used for hyperparameter optimization.\n        * `is_running()` - returns the execution status of hyperaparameter tuning.\n        * `predict()` - function to perform prediction on the given teradataml dataframe using default model.\n        * `set_model()` - function to update the default model.\n      * properties of gridsearch    \n        * `best_data_id` - returns the best data identifier used for model training.\n        * `best_model` - returns the best trained model.\n        * `best_model_id` - returns the identifier for best model.\n        * `best_params_` - returns the best set of hyperparameter.\n        * `best_sampled_data_` - returns the best sampled data used to train the best model.\n        * `best_score_` - returns the best trained model score.\n        * `model_stats` - returns the model evaluation reports.\n        * `models` - returns the metadata of all the models.\n\n  * ###### teradataml: analytic functions\n    teradataml currently has different functions to generate a model, predict, transform and evaluate. all these functions are needed to be invoked individually, i.e., predict(), evaluate(), transform() cannot be invoked using the model trainer function output. enhancement done to this feature now enables user to invoke these functions as methods of the model trainer function. below is the list of functions, updated with this enhancement:\n    * analytics database analytic functions\n      *  `bincodefit()` - supports `transform()` method.\n      *  `decisionforest()` - supports `predict()`, `evaluate()` methods.\n      *  `fit()` - supports `transform()` method. \n      *  `glm()` - supports `predict()`, `evaluate()` methods. \n      *  `glmpersegment()` - supports `predict()`, `evaluate()` methods. \n      *  `kmeans()` - supports `predict()` method.\n      *  `knn()` - supports `predict()`, `evaluate()` methods. \n      *  `naivebayestextclassifiertrainer()` - supports `predict()`, `evaluate()` methods. \n      *  `nonlinearcombinefit()` - supports `transform()` method. \n      *  `oneclasssvm()` - supports `predict()` method.\n      *  `onehotencodingfit()` - supports `transform()` method. \n      *  `ordinalencodingfit()` - supports `transform()` method. \n      *  `outlierfilterfit()` - supports `transform()` method. \n      *  `polynomialfeaturesfit()` - supports `transform()` method. \n      *  `randomprojectionfit()` - supports `transform()` method. \n      *  `rownormalizefit()` - supports `transform()` method. \n      *  `scalefit()` - supports `transform()` method. \n      *  `simpleimputefit()` - supports `transform()` method. \n      *  `svm()` - supports `predict()`, `evaluate()` methods. \n      *  `targetencodingfit()` - supports `transform()` method. \n      *  `xgboost()` - supports `predict()`, `evaluate()` methods. \n    * time series analytic (uaf) functions\n      *  `arimaestimate()` - supports `forecast()`, `validate()` methods.\n      *  `dfft()` - supports `convolve()`, `inverse()` methods. \n      *  `idfft()` - supports `inverse()` method. \n      *  `dfft2()` - supports `convolve()`, `inverse()` methods. \n      *  `idfft2()` - supports `inverse()` method. \n      *  `diff()` - supports `inverse()` method. \n      *  `undiff()` - supports `inverse()` method. \n      *  `seasonalnormalize()` - supports `inverse()` method.\n\n  * ###### teradataml: dataframe\n    * new functions\n      * `dataframe.plot()` - generates the below type of plots on teradataml dataframe.\n        * line - generates line plot.\n        * bar - generates bar plot.\n        * scatter - generates scatter plot.\n        * corr - generates correlation plot.\n        * wiggle - generates a wiggle plot.\n        * mesh - generates a mesh plot.\n      * `dataframe.itertuples()` - iterate over teradataml dataframe rows as namedtuples or list.\n  * ###### teradataml: geodataframe\n    * new functions\n      * `geodataframe.plot()` - generate the below type of plots on teradataml geodataframe.\n        * line - generates line plot.\n        * bar - generates bar plot.\n        * scatter - generates scatter plot.\n        * corr - generates correlation plot.\n        * wiggle - generates a wiggle plot.\n        * mesh - generates a mesh plot.\n        * geometry - generates plot on geospatial data. \n  * plot:\n    * `axis` - genertes the axis for plot.\n    * `figure` - generates the figure for plot.\n    * `subplots` - helps in generating multiple plots on a single `figure`.    \n  * bring your own model (byom) function:\n    * `dataikupredict` - score the data in vantage using the model trained externally in dataiku ui and stored in vantage.\n  * `async_run_status()` - function to check the status of asynchronous run(s) using unique run id(s).\n\n  * ###### teradataml dataframecolumn a.k.a. columnexpression\n    * _regular arithmetic functions_\n      * `dataframecolumn.abs()` - computes the absolute value.\n      * `dataframecolumn.ceil()` - returns the ceiling value of the column.\n      * `dataframecolumn.ceiling()` - it is an alias for `dataframecolumn.ceil()` function.\n      * `dataframecolumn.degrees()` - converts radians value from the column to degrees.\n      * `dataframecolumn.exp()` - raises e (the base of natural logarithms) to the power of the value in the column, where e = 2.71828182845905.\n      * `dataframecolumn.floor()` - returns the largest integer equal to or less than the value in the column.\n      * `dataframecolumn.ln()` - computes the natural logarithm of values in column.\n      * `dataframecolumn.log10()` - computes the base 10 logarithm.\n      * `dataframecolumn.mod()` - returns the modulus of the column.\n      * `dataframecolumn.pmod()` - it is an alias for `dataframecolumn.mod()` function.\n      * `dataframecolumn.nullifzero()` - converts data from zero to null to avoid problems with division by zero.\n      * `dataframecolumn.pow()` - computes the power of the column raised to expression or constant.\n      * `dataframecolumn.power()` - it is an alias for `dataframecolumn.pow()` function.\n      * `dataframecolumn.radians()` - converts degree value from the column to radians.\n      * `dataframecolumn.round()` - returns the rounded off value.\n      * `dataframecolumn.sign()` - returns the sign.\n      * `dataframecolumn.signum()` - it is an alias for `dataframecolumn.sign()` function.\n      * `dataframecolumn.sqrt()` - computes the square root of values in the column.\n      * `dataframecolumn.trunc()` - provides the truncated value of columns.\n      * `dataframecolumn.width_bucket()` - returns the number of the partition to which column is assigned.\n      * `dataframecolumn.zeroifnull()` - converts data from null to zero to avoid problems with null.\n    * _trigonometric functions_\n      * `dataframecolumn.acos()` - returns the arc-cosine value.\n      * `dataframecolumn.asin()` - returns the arc-sine value.\n      * `dataframecolumn.atan()` - returns the arc-tangent value.\n      * `dataframecolumn.atan2()` - returns the arc-tangent value based on x and y coordinates.\n      * `dataframecolumn.cos()` - returns the cosine value.\n      * `dataframecolumn.sin()` - returns the sine value.\n      * `dataframecolumn.tan()` - returns the tangent value.\n    * _hyperbolic functions_\n      * `dataframecolumn.acosh()` - returns the inverse hyperbolic cosine value. \n      * `dataframecolumn.asinh()` - returns the inverse hyperbolic sine value.\n      * `dataframecolumn.atanh()` - returns the inverse hyperbolic tangent value.\n      * `dataframecolumn.cosh()` - returns the hyperbolic cosine value.\n      * `dataframecolumn.sinh()` - returns the hyperbolic sine value\n      * `dataframecolumn.tanh()` - returns the hyperbolic tangent value.\n    * _string functions_\n      * `dataframecolumn.ascii()` - returns the decimal representation of the first character in column.\n      * `dataframecolumn.char2hexint()` - returns the hexadecimal representation for a character string in a column.\n      * `dataframecolumn.chr()` - returns the latin ascii character of a given a numeric code value in column.\n      * `dataframecolumn.char()` - it is an alias for `dataframecolumn.chr()` function.\n      * `dataframecolumn.character_length()` - returns the number of characters in the column.\n      * `dataframecolumn.char_length()` - it is an alias for `dataframecolumn.character_length()` function.\n      * `dataframecolumn.edit_distance()` - returns the minimum number of edit operations required to \n         transform string in a column into string specified in argument.\n      * `dataframecolumn.index()` - returns the position of a string in a column where string specified in argument starts.\n      * `dataframecolumn.initcap()` - modifies a string column and returns the string with the first character\n         of each word in uppercase.\n      * `dataframecolumn.instr()` - searches the string in a column for occurrences of search string passed as argument.\n      * `dataframecolumn.lcase()` - returns a character string identical to string values in column,\n         with all uppercase letters replaced with their lowercase equivalents.\n      * `dataframecolumn.left()` - truncates string in a column to a specified number of characters desired from\n         the left side of the string.\n      * `dataframecolumn.length()` - it is an alias for `dataframecolumn.character_length()` function.\n      * `dataframecolumn.levenshtein()` - it is an alias for `dataframecolumn.edit_distance()` function.\n      * `dataframecolumn.locate()` - returns the position of the first occurrence of a string in a column within \n         string in argument. \n      * `dataframecolumn.lower()` - it is an alias for `dataframecolumn.character_lcase()` function.\n      * `dataframecolumn.lpad()` - returns the string in a column padded to the left with the characters specified \n         in argument so that the resulting string has length specified in argument.\n      * `dataframecolumn.ltrim()` - returns the string in a column, with its left-most characters removed up\n        to the first character that is not in the string specified in argument.\n      * `dataframecolumn.ngram()` - returns the number of n-gram matches between string in a column,\n        and string specified in argument.\n      * `dataframecolumn.nvp()` - extracts the value of a name-value pair where the name in the pair matches\n        the name and the number of the occurrence specified.\n      * `dataframecolumn.oreplace()` - replaces every occurrence of search string in the column.\n      * `dataframecolumn.otranslate()` - returns string in a column with every occurrence of each character in\n         string in argument replaced with the corresponding character in another argument.\n      * `dataframecolumn.replace()` - it is an alias for `dataframecolumn.oreplace()` function.\n      * `dataframecolumn.reverse()` - returns the reverse of string in column.\n      * `dataframecolumn.right()` - truncates input string to a specified number of characters desired from\n         the right side of the string.\n      * `dataframecolumn.rpad()` - returns the string in a column padded to the right with the characters specified \n         in argument so the resulting string has length specified in argument.\n      * `dataframecolumn.rtrim()` - returns the string in column, with its right-most characters removed up\n         to the first character that is not in the string specified in argument.\n      * `dataframecolumn.soundex()` - returns a character string that represents the soundex code for\n         string in a column.\n      * `dataframecolumn.string_cs()` - returns a heuristically derived integer value that can be used to determine\n         which kanji1-compatible client character set was used to encode string in a column.\n      * `dataframecolumn.translate()` - it is an alias for `dataframecolumn.otranslate()` function.\n      * `dataframecolumn.upper()` - returns a character string with all lowercase letters in a column replaced \n         with their uppercase equivalents.\n\n  * ##### teradataml options\n    * configuration options\n      * `configure.indb_install_location`\n        specifies the installation location of in-db python package.\n\n* ##### updates\n  * open analytics framework (openaf) apis:\n    * `set_auth_token()`\n      * `set_auth_token()` does not accept username and password anymore. instead, function opens up a browser session and user should authenticate in browser.\n      * after token expiry, teradataml will open a browser and user needs to authenticate again.\n      * if client machine does not have browser, then user should copy the url posted by teradataml and authenticate themselves.\n    * security fixes - `auth_token` is not set or retrieved from the `configure` option anymore.\n    * manage all user environments.\n      * `create_env()` - supports creation of r environment.\n      * `remove_env()` - supports removal of remote r environment.\n      * `remove_all_envs()` - supports removal of all remote r environments.\n      * `remove_env()` and `remove_all_envs()` supports asynchronous call.\n    * userenv class \u2013 supports managing of r remote environments.\n      * properties:\n        * `libs` - supports listing of libraries in r remote environment.\n      * methods:\n        * `install_lib()` - supports installing of libraries in remote r environment.\n        * `uninstall_lib()` - supports uninstalling of libraries in remote r environment.\n        * `update_lib()` - supports updating of libraries in remote r environment.\n  * unbounded array framework (uaf) functions:\n    * `arimaestimate()`\n        * added support for `css` algorithm via `algorithm` argument.\n\n* ##### bug fixes\n    * installation location of in-db 2.0.0 package is changed. script() will now work with both 2.0.0 and previous version.  \n\n## release notes:\n#### teradataml 17.20.00.04\n* ##### new features/functionality\n  * teradataml is now compatible with sqlalchemy 2.0.x\n    * **important notes** when user has sqlalchemy version >= 2.0: \n      * users will not be able to run the `execute()` method on sqlalchemy engine object returned by \n        `get_context()` and `create_context()` teradataml functions. this is due to the sqlalchemy has\n        removed the support for `execute()` method on the engine object. thus, user scripts where \n        `get_context().execute()` and `create_context().execute()`, is used, teradata recommends to\n        replace those with either `execute_sql()` function exposed by teradataml or `exec_driver_sql()` \n        method on the `connection` object returned by `get_connection()` function in teradataml.\n      * now `get_connection().execute()` accepts only executable sqlalchemy object. refer to \n        `sqlalchemy.engine.base.execute()` for more details.\n      * teradata recommends to use either `execute_sql()` function exposed by teradataml or \n        `exec_driver_sql()` method on the `connection` object returned by `get_connection()` \n        function in teradataml, in such cases.\n  * new utility function `execute_sql()` is added to execute the sql.  \n  * extending compatibility for mac with arm processors.\n  * added support for floor division (//) between two teradataml dataframe columns.\n  * analytics database analytic functions:\n    * `glmpersegment()`\n    * `glmpredictpersegment()`\n    * `oneclasssvm()`\n    * `oneclasssvmpredict()`\n    * `svm()`\n    * `svmpredict()`\n    * `targetencodingfit()`\n    * `targetencodingtransform()`\n    * `traintestsplit()`\n    * `wordembeddings()`\n    * `xgboost()`\n    * `xgboostpredict()`\n\n  * ###### teradataml options\n    * display options\n      * `display.geometry_column_length`\n        option to display the default length of geometry column in geodataframe.\n\n  * ##### updates\n    * `set_auth_token()` function can generate the client id automatically based on org_id when user do not specify it.\n    * analytics database analytic functions:\n      * `columntransformer()` \n          * does not allow list values for arguments - `onehotencoding_fit_data` and `ordinalencoding_fit_data`.\n      * `ordidnalencodingfit()`\n          * new arguments added - `category_data`, `target_column_names`, `categories_column`, `ordinal_values_column`.\n          * allows the list of values for arguments - `target_column`, `start_value`, `default_value`.\n      * `onehotencodingfit()`\n          * new arguments added - `category_data`, `approach`, `target_columns`, `categories_column`, `category_counts`.\n          * allows the list of values for arguments - `target_column`, `other_column`.\n\n  * ##### bug fixes\n    * `dataframe.sample()` method output is now deterministic.\n    * `copy_to_sql()` now preserves the rows of the table even when the view content is copied to the same table name.\n    * `list_user_envs()` does not raise warning when no user environments found.\n\n## release notes:\n#### teradataml 17.20.00.03\n\n  * ##### updates\n    * dataframe.join \n      * new arguments `lprefix` and `rprefix` added.\n      * behavior of arguments `lsuffix` and `rsuffix` will be changed in future, use new arguments instead.\n      * new and old affix arguments can now be used independently.\n    * analytic functions can be imported regardless of context creation. \n      import after create context constraint is now removed.\n    * `readnos` and `writenos` now accept dictionary value for `authorization` and `row_format` arguments.\n    * `writenos` supports writing csv files to external store.\n    * following model cataloging apis will be deprecated in future:\n       * describe_model\n       * delete_model\n       * list_models\n       * publish_model\n       * retrieve_model\n       * save_model\n\n  * ##### bug fixes\n    * `copy_to_sql()` bug related to nat value has been fixed.\n    * tooltip on pycharm ide now points to sqle.\n    * `value` argument of `fillna()`, a vantage analytic library function supports special characters.\n    * `case` function accepts dataframe column as value in `whens` argument.\n\n## release notes:\n#### teradataml 17.20.00.02\n* ##### new features/functionality\n  * ###### teradataml: open analytics\n    * new functions\n      * `set_auth_token()` - sets the jwt token automatically for using open af api's.\n\n  * ###### teradataml options\n    * display options\n      * `display.suppress_vantage_runtime_warnings`\n        suppresses the vantageruntimewarning raised by teradataml, when set to true.\n\n  * ##### updates\n    * simpleimputefit function arguments `stats_columns` and `stats` are made to be optional.\n    * new argument `table_format` is added to readnos().\n    * argument `full_scan` is changed to `scan_pct` in readnos(). \n\n  * ##### bug fixes\n    * minor bug fix related to read_csv.\n    * apply and `dataframe.apply()` supports hash by and local order by.\n    * output column names are changed for dataframe.dtypes and dataframe.tdtypes.\n\n## release notes:\n#### teradataml 17.20.00.01\n* ##### new features/functionality\n  * ###### teradataml: dataframe\n    * new functions\n      * `dataframe.pivot()` - rotate data from rows into columns to create easy-to-read dataframes.\n      * `dataframe.unpivot()` - rotate data from columns into rows to create easy-to-read dataframes.\n      * `dataframe.drop_duplicate()` - drop duplicate rows from teradataml dataframe.\n    * new properties \n      * `dataframe.is_art` - check whether teradataml dataframe is created on an analytic result table, i.e., art table or not.\n\n  * ###### teradataml:  unbounded array framework (uaf) functions:\n    * new functions\n      * new functions supported on database versions: 17.20.x.x\n        * model preparation and parameter estimation functions:\n\t\t\t 1. `acf()`\n\t\t\t 2. `arimaestimate()`\n\t\t\t 3. `arimavalidate()`\n\t\t\t 4. `diff()`\n\t\t\t 5. `linearregr()`\n\t\t\t 6. `multivarregr()`\n\t\t\t 7. `pacf()`\n\t\t\t 8. `powertransform()`\n\t\t\t 9. `seasonalnormalize()`\n\t\t\t 10. `smoothma()`\n\t\t\t 11. `undiff()`\n\t\t\t 12. `unnormalize()`\n\t\t* series forecasting functions:\n\t\t\t 1. `arimaforecast()`\n\t\t\t 2. `dtw()`\n\t\t\t 3. `holtwintersforecaster()`\n\t\t\t 4. `mamean()`\n\t\t\t 5. `simpleexp()`\n\t\t* data preparation functions:\n\t\t\t 1. `binarymatrixop()`\n\t\t\t 2. `binaryseriesop()`\n\t\t\t 3. `genseriesformula()`\n\t\t\t 4. `matrixmultiply()`\n\t\t\t 5. `resample()`\n\t\t* diagnostic statistical test functions:\n\t\t\t 1. `breuschgodfrey()`\n\t\t\t 2. `breuschpagangodfrey()`\n\t\t\t 3. `cumulperiodogram()`\n\t\t\t 4. `dickeyfuller()`\n\t\t\t 5. `durbinwatson()`\n\t\t\t 6. `fitmetrics()`\n\t\t\t 7. `goldfeldquandt()`\n\t\t\t 8. `portman()`\n\t\t\t 9. `selectioncriteria()`\n\t\t\t 10. `signifperiodicities()`\n\t\t\t 11. `signifresidmean()`\n\t\t\t 12. `whitesgeneral()`\n\t\t* temporal and spatial functions:\n\t\t\t 1. `convolve()`\n\t\t\t 2. `convolve2()`\n\t\t\t 3. `dfft()`\n\t\t\t 4. `dfft2()`\n\t\t\t 5. `dfft2conv()`\n\t\t\t 6. `dfftconv()`\n\t\t\t 7. `genseriessinusoids()`\n\t\t\t 8. `idfft()`\n\t\t\t 9. `idfft2()`\n\t\t\t 10. `linespec()`\n\t\t\t 11. `powerspec()`\n\t\t* general utility functions:\n\t\t\t 1. `extractresults()`\n\t\t\t 2. `inputvalidator()`\n\t\t\t 3. `minfo()`\n\t\t\t 4. `sinfo()`\n\t\t\t 5. `trackingop()`\n\n    * new features: inputs to unbounded array framework (uaf) functions\n      * `tdanalyticresult()` - allows to prepare function output generated by uaf functions to be passed.\n      * `tdgenseries()` - allows to generate a series, that can be passed to a uaf function.\n      * `tdmatrix()` - represents a matrix in time series, that can be created from a teradataml dataframe.\n      * `tdseries()` - represents a series in time series, that can be created from a teradataml dataframe.\n\n  * ##### updates \n    * native object store (nos) functions support authorization by specifying authorization object.\n    * `display_analytic_functions()` categorizes the analytic functions based on function type.\n    * columntransformer accepts multiple values for arguments nonlinearcombine_fit_data, \n      onehotencoding_fit_data, ordinalencoding_fit_data.\n\n  * ##### bug fixes\n    * redundant warnings thrown by teradataml are suppressed.\n    * openaf supports when context is created with jwt token.\n    * new argument \"match_column_order\" added to copy_to_sql, that allows dataframe loading with any column order.\n    * `copy_to_sql` updated to map data type timezone(tzinfo) to timestamp(timezone=true), instead of varchar.\n    * improved performance for dataframe.sum and dataframecolumn.sum functions.\n\n## release notes:\n#### teradataml 17.20.00.00\n* ##### new features/functionality\n  * ###### teradataml: analytics database analytic functions\n    * _new functions_ \n      * ###### new functions supported on database versions: 17.20.x.x\n        * `anova()`\u200b\n        * `classificationevaluator()`\u200b\n        * `columntransformer()`\u200b\n        * `decisionforest()`\n        * `glm\u200b()`\n        * `getfutilecolumns()`\n        * `kmeans()`\u200b\n        * `kmeanspredict()`\u200b\u200b\n        * `naivebayestextclassifiertrainer()`\u200b\n        * `nonlinearcombinefit()`\u200b\n        * `nonlinearcombinetransform()`\u200b\n        * `ordinalencodingfit\u200b()`\n        * `ordinalencodingtransform()`\u200b\n        * `randomprojectioncomponents\u200b()`\n        * `randomprojectionfit\u200b()`\n        * `randomprojectiontransform()`\u200b\n        * `regressionevaluator\u200b()`\n        * `roc\u200b()`\n        * `sentimentextractor()`\u200b\n        * `silhouette\u200b()`\n        * `tdglmpredict\u200b()`\n        * `textparser\u200b()`\n        * `vectordistance()`\n    * _updates_\n      * `display_analytic_functions()` categorizes the analytic functions based on function type.\n      * users can provide range value for columns argument.\n\n  * ###### teradataml: open analytics\n    * manage all user environments.\n      * `list_base_envs()` - list the available python base versions.\u200b\n      * `create_env()` - create a new user environment. \u200b\n      * `get_env()` - get existing user environment.\n      * `list_user_envs()` - list the available user environments.\u200b\n      * `remove_env()` - delete user environment.\u200b\n      * `remove_all_envs()` - delete all the user environments.\n    * userenv class \u2013 manage individual user environment.      \n      * properties\n        * `files` - get files in user environment. \n        * `libs` - get libraries in user environment.\n      * methods\n        * `install_file()` - install a file in user environment.\u200b\n        * `remove_file()` - remove a file in user environment.\u200b\n        * `install_lib()` - install a library in user environment.\u200b\n        * `update_lib()` - update a library in user environment.\u200b\n        * `uninstall_lib()` - uninstall a library in user environment.\u200b\n        * `status()` - check the status of\u200b\n          * file installation\u200b\n          * library installation\u200b\n          * library update\u200b\n          * library uninstallation\u200b\n        * `refresh()` - refresh the environment details in local client.\n    * apply class \u2013 execute a user script on vantagecloud lake.\u200b\n      * `__init__()` - instantiate an object of apply for script execution.\u200b\n      * `install_file()` - install a file in user environment.\u200b\n      * `remove_file()` - remove a file in user environment.\u200b\n      * `set_data()` \u2013 reset data and related arguments.\u200b\n      * `execute_script()` \u2013 executes python script.\n\n  * ###### teradataml: dataframe\n    * _new functions_\n      * `dataframe.apply()` - execute a user defined python function on vantagelake cloud.\n\n  * ###### teradataml: bring your own model\n    * _new functions_\n      * `onnxpredict()` - score using model trained externally on onnx and stored in vantage.\n\n  * ###### teradataml: options\n    * _new functions_\n      * set_config_params() new api to set all config params in one go.\n    * _new configuration options_\n      * for open analytics support.\u200b\n        * ues_url \u2013 user environment service url for vantagecloud lake.\u200b\n        * auth_token \u2013 authentication token to connect to vantagecloud lake.\n        * certificate_file \u2013 path to a ca_bundle file or directory with certificates of trusted cas.\n\n  * ##### updates\n    * `accumulate` argument is working for `scaletransform()`.\n    * following functions have `accumulate` argument added on database versions: 17.20.x.x\n      * `convertto()`\n      * `getrowswithoutmissingvalues()`\n      * `getrowswithoutmissingvalues()`\n    * `outlierfilterfit()` supports multiple output.\n    * for `outlierfilterfit()` function below arguments are optional in teradataml 17.20.x.x\n      * `lower_percentile`\n      * `upper_percentile`\n      * `outlier_method`\n      * `replacement_value`\n      * `percentile_method`\n    * analytics database analytic functions \u2013 in line help, i.e., help() for the functions\n    is available.\u200b\n\n  * ##### bug fixes\n    * vantage analytic library fillna() function: now `columns` argument is required.\n    * `output_responses` argument in mle function `decisiontreepredict()`, does not allow empty string.\n    * teradataml closes docker sandbox environment properly.\n    * users can create context using jwt token.\n\n#### teradataml 17.10.00.02\n* ##### new features/functionality\n  * ###### database utility\n      * `list_td_reserved_keywords()` - validates if the specified string is teradata reserved\n        keyword or not, else lists down all the teradata reserved keywords.\n\n* ##### updates\n    * ###### dataframe\n      * _updates_\n        * multiple columns can be selected using slice operator ([]).\n\n    * ###### script\n      * _updates_\n        * a warning will be raised, when teradata reserved keyword is used in script local mode.\n\n* ##### bug fixes\n  * numeric overflow issue observed for describe(), sum(), csum(), and mean() has been fixed.\n  * error messages are updated for sqle function arguments accepting multiple datatypes.\n  * error messages are updated for sqle function arguments volatile and persist arguments when \n    non-boolean value is provided.\n  * dataframe sample() method can handle column names with special characters like space, hyphen, \n    period etc.\n  * in-db sqle functions can be loaded for any locale setting.\n  * `create_context()` - password containing special characters requires url encoding as per\n    https://docs.microfocus.com/omi/10.62/content/omi/extguide/extapps/url_encoding.html. \n    teradataml has added a fix to take care of the url encoding of the password while creating a context. \n    also, a new argument is added to give a more control over the url encoding to be done at the time of context creation.\n\n#### teradataml 17.10.00.01\n* ##### new features/functionality\n  * ###### geospatial\n    the geospatial feature in teradataml enables data manipulation, exploration and analysis on tables, views, and queries on teradata vantage that contains geospatial data.\n    * ###### geomtery types\n      * point\n      * linestring\n      * polygon\n      * multipoint\n      * multilinestring\n      * multipolygon\n      * geometrycollection\n      * geosequence\n    * ###### teradataml geodataframe\n      * properties\n        * columns\n        * dtypes\n        * geometry\n        * iloc\n        * index\n        * loc\n        * shape\n        * size\n        * tdtypes\n        * geospatial specific properties\n          * ###### properties for all types of geometries\n            * boundary\n            * centroid\n            * convex_hell\n            * coord_dim\n            * dimension\n            * geom_type\n            * is_3d\n            * is_empty\n            * is_simple\n            * is_valid\n            * max_x\n            * max_y\n            * max_z\n            * min_x\n            * min_y\n            * min_z\n            * srid\n          * ###### properties for point geometry\n            * x\n            * y\n            * z\n          * ###### properties for linestring geometry\n            * is_closed_3d\n            * is_closed\n            * is_ring\n          * ###### properties for polygon geometry\n            * area\n            * exterior\n            * perimeter\n      * methods\n        * `__getattr__()`\n        * `__getitem__()`\n        * `__init__()`\n        * `__repr__()`\n        * `assign()`\n        * `concat()`\n        * `count()`\n        * `drop()`\n        * `dropna()`\n        * `filter()`\n        * `from_query()`\n        * `from_table()`\n        * `get()`\n        * `get_values()`\n        * `groupby()`\n        * `head()`\n        * `info()`\n        * `join()`\n        * `keys()`\n        * `merge()`\n        * `sample()`\n        * `select()`\n        * `set_index()`\n        * `show_query()`\n        * `sort()`\n        * `sort_index()`\n        * `squeeze()`\n        * `tail()`\n        * `to_csv()`\n        * `to_pandas()`\n        * `to_sql()` \n        * geospatial specific methods\n          * ###### methods for all type of geometry\n            * `buffer()`\n            * `contains()`\n            * `crosses()`\n            * `difference()`\n            * `disjoint()`\n            * `distance()`\n            * `distance_3d()`\n            * `envelope()`\n            * `geom_equals()`\n            * `intersection()`\n            * `intersects()`\n            * `make_2d()`\n            * `mbb()`\n            * `mbr()`\n            * `overlaps()`\n            * `relates()`\n            * `set_exterior()`\n            * `set_srid()`\n            * `simplify()`\n            * `sym_difference()`\n            * `to_binary()`\n            * `to_text()`\n            * `touches()`\n            * `transform()`\n            * `union()`\n            * `within()`\n            * `wkb_geom_to_sql()`\n            * `wkt_geom_to_sql()`\n          * ###### methods for point geometry\n            * `spherical_buffer()`\n            * `spherical_distance()`\n            * `spheriodal_buffer()`\n            * `spheriodal_distance()`\n            * `set_x()`\n            * `set_y()`\n            * `set_z()`\n          * ###### methods for linestring geometry\n            * `end_point()`\n            * `length()`\n            * `length_3d()`\n            * `line_interpolate_point()`\n            * `num_points()`\n            * `point()`\n            * `start_point()`\n          * ###### methods for polygon geometry\n            * `interiors()`\n            * `num_interior_ring()`\n            * `point_on_surface()`\n          * ###### methods for geometrycollection geometry\n            * `geom_component()`\n            * `num_geometry()`\n          * ###### methods for geosequence geometry\n            * `clip()`\n            * `get_final_timestamp()`\n            * `get_init_timestamp()`\n            * `get_link()`\n            * `get_user_field()`\n            * `get_user_field_count()`\n            * `point_heading()`\n            * `set_link()`\n            * `speed()`\n          * ###### filtering functions and methods\n            * `intersects_mbb()`\n            * `mbb_filter()`\n            * `mbr_filter()`\n            * `within_mbb()`\n    * ###### teradataml geodataframecolumn\n      * geospatial specific properties\n        * ###### properties for all types of geometries\n          * boundary\n          * centroid\n          * convex_hell\n          * coord_dim\n          * dimension\n          * geom_type\n          * is_3d\n          * is_empty\n          * is_simple\n          * is_valid\n          * max_x\n          * max_y\n          * max_z\n          * min_x\n          * min_y\n          * min_z\n          * srid\n        * ###### properties for point geometry\n          * x\n          * y\n          * z\n        * ###### properties for linestring geometry\n          * is_closed_3d\n          * is_closed\n          * is_ring\n        * ###### properties for polygon geometry\n          * area\n          * exterior\n          * perimeter\n      * geospatial specific methods\n        * ###### methods for all type of geometry\n          * `buffer()`\n          * `contains()`\n          * `crosses()`\n          * `difference()`\n          * `disjoint()`\n          * `distance()`\n          * `distance_3d()`\n          * `envelope()`\n          * `geom_equals()`\n          * `intersection()`\n          * `intersects()`\n          * `make_2d()`\n          * `mbb()`\n          * `mbr()`\n          * `overlaps()`\n          * `relates()`\n          * `set_exterior()`\n          * `set_srid()`\n          * `simplify()`\n          * `sym_difference()`\n          * `to_binary()`\n          * `to_text()`\n          * `touches()`\n          * `transform()`\n          * `union()`\n          * `within()`\n          * `wkb_geom_to_sql()`\n          * `wkt_geom_to_sql()`\n        * ###### methods for point geometry\n          * `spherical_buffer()`\n          * `spherical_distance()`\n          * `spheriodal_buffer()`\n          * `spheriodal_distance()`\n          * `set_x()`\n          * `set_y()`\n          * `set_z()`\n        * ###### methods for linestring geometry\n          * `endpoint()`\n          * `length()`\n          * `length_3d()`\n          * `line_interpolate_point()`\n          * `num_points()`\n          * `point()`\n          * `start_point()`\n        * ###### methods for polygon geometry\n          * `interiors()`\n          * `num_interior_ring()`\n          * `point_on_surface()`\n        * ###### methods for geometrycollection geometry\n          * `geom_component()`\n          * `num_geometry()`\n        * ###### methods for geosequence geometry\n          * `clip()`\n          * `get_final_timestamp()`\n          * `get_init_timestamp()`\n          * `get_link()`\n          * `get_user_field()`\n          * `get_user_field_count()`\n          * `point_heading()`\n          * `set_link()`\n          * `speed()`\n        * ###### filtering functions and methods\n          * `intersects_mbb()`\n          * `mbb_filter()`\n          * `mbr_filter()`\n          * `within_mbb()`\n\n  * ###### teradataml dataframe\n    * _new functions_\n      * `to_csv()`\n\n  * ###### teradataml: sqle engine analytic functions\n    * _new functions_\n      *  newly added sqle functions are accessible only after establishing the connection to vantage.\n      * `display_analytic_functions()` api displays all the available sqle analytic functions based on database version. \n      * ###### functions supported on databaseversions: 16.20.x.x, 17.10.x.x, 17.05.x.x\n        * `antiselect()`\n        * `attribution()`\n        * `decisionforestpredict()`\n        * `decisiontreepredict()`\n        * `glmpredict()`\n        * `movingaverage()`\n        * `naivebayespredict()`\n        * `naivebayestextclassifierpredict()`\n        * `ngramsplitter()`\n        * `npath()`\n        * `pack()`\n        * `sessionize()`\n        * `stringsimilarity()`\n        * `svmparsepredict()`\n        * `unpack()`\n      * ###### functions supported on databaseversions: 17.10.x.x\n        * `antiselect()`\n        * `attribution()`\n        * `bincoodefit()`\n        * `bncodetransform()`\n        * `categoricalsummary()`\n        * `chisq()`\n        * `columnsummary()`\n        * `convertto()`\n        * `decisionforestpredict()`\n        * `decisiontreepredict()`\n        * `glmpredict()`\n        * `fillrowid()`\n        * `ftest()`\n        * `fit()`\n        * `transform()`\n        * `getrowswithmissingvalues()`\n        * `getrowswithoutmissingvalues()`\n        * `movingaverage()`\n        * `histogram()`\n        * `naivebayespredict()`      \n        * `naivebayestextclassifierpredict()`\n        * `ngramsplitter()`\n        * `npath()`\n        * `numapply()`\n        * `onehotencodingfit()`\n        * `onehotencodingtransform()`\n        * `outlierfilterfit()`\n        * `outlierfiltertransform()`\n        * `pack()`\n        * `polynomialfeatuesfit()`\n        * `polynomialfeatuestransform()`\n        * `qqnorm()`\n        * `roundcolumns()`\n        * `rownormalizefit()`\n        * `rownormalizetransform()`\n        * `scalefit()`\n        * `scaletransform()`  \n        * `sessionize()`\n        * `simpleimputefit()`\n        * `simpleimputetransform()`\n        * `strapply()`\n        * `stringsimilarity()`\n        * `svmparsepredict()`\n        * `univariatestatistics()`\n        * `unpack()`\n        * `whichmax()`\n        * `whichmin()`\n        * `ztest()`\n\n  * ###### teradataml: general functions\n    * _new functions_\n      * data transfer utility\n        * `read_csv()`\n\n  * ###### operators\n    * _new functions_\n      * table operators\n        * `read_nos()`\n        * `write_nos()`\n\n  * ###### teradataml: bring your own model\n    * _new functions_\n      * model cataloging\n        * `get_license()`\n        * `set_byom_catalog()`\n        * `set_license()`\n\n* ##### updates\n    * ###### teradataml: general functions\n      * data transfer utility\n        * `copy_to_sql()` - new argument \"chunksize\" added to load data in chunks.\n        * following data transfer utility functions updated to specify the number of teradata sessions to open for data transfer using \"open_session\" argument:\n          * `fastexport()`\n          * `fastload()`\n          * `to_pandas()`\n\n    * ###### operators\n      * following set operator functions updated to work with geospatial data:\n        * `concat()`\n        * `td_intersect()`\n        * `td_expect()`\n        * `td_minus()`\n\n    * ###### teradataml: bring your own model\n      * model cataloging apis mentioned below are updated to use session level parameters set by `set_byom_catalog()` and `set_license()` such as table name, schema name and license details respectively.\n        * `delete_byom()`\n        * `list_byom()`\n        * `retrieve_byom()`\n        * `save_byom()`\n      * `view_log()` - allows user to view byom logs.\n\n* ##### bug fixes\n  * cs0733758 - `db_python_package_details()` function is fixed to support latest sto release for pip and python aliases used.\n  * dataframe `print()` issue related to `response row size is greater than the 1mb allowed maximum.` has been fixed to print the data with lot of columns.\n  * new parameter \"chunksize\" is added to `dataframe.to_sql()` and `copy_to_sql()` to fix the issue where the function was failing with error - \"request requires too many spool files.\". reducing the chunksize than the default one will result in successful operation.\n  * `remove_context()` is fixed to remove the active connection from database.\n  * support added to specify the number of teradata data transfer sessions to open for data transfer using `fastexport()` and `fastload()` functions.\n  * `dataframe.to_sql()` is fixed to support temporary table when default database differs from the username. \n  * `dataframe.to_pandas()` now by default support data transfer using regular method. change is carried out for user to allow the data transfer if utility throttles are configured, i.e., tasm configuration does not support data export using fastexport.\n  * `save_byom()` now notifies if varchar column is trimmed out if data passed to the api is greater than the length of the varchar column.\n  * standard error can now be captured for `dataframe.map_row()` and `dataframe.map_parition()` when executed in local mode.\n  * vantage analytic library - underlying sql can be retrieved using newly added arguments \"gen_sql\"/\"gen_sql_only\" for the functions. query can be viewed with the help `show_query()`.\n  * documentation example has been fixed for `fastexport()` to show the correct import statement.\n\n\n#### teradataml 17.00.00.05\nfixed [cs0733758] db_python_package_details() fails on recent sto release due to changes in pip and python aliases.\n\n\n#### teradataml 17.00.00.04\n* ##### new features/functionality\n  * ###### analytic functions\n    * bring your own analytics functions\n      the byom feature in vantage provides flexibility to score the data in vantage using external models using following byom functions:\n      * `h2opredict()` - score using model trained externally in h2o and stored in vantage.\n      * `pmmlpredict()` - score using model trained externally in pmml and stored in vantage.\n      * byom model catalog apis\n        * `save_byom()` - save externally trained models in teradata vantage.\n        * `delete_byom()` - delete a model from the user specified table in teradata vantage.\n        * `list_byom()` - list models.\n        * `retrieve_byom()` - function to retrieve a saved model.\n    * vantage analytic library functions\n      * _new functions_\n        * `xmltohtmlreport()` - transforms xml output of val functions to html.\n  * ###### teradataml dataframe\n    * `dataframe.window()` - generates window object on a teradataml dataframe to run window aggregate functions.\n    * `dataframe.csum()` - returns column-wise cumulative sum for rows in the partition of the dataframe.\n    * `dataframe.mavg()` - returns moving average for the current row and the preceding rows.\n    * `dataframe.mdiff()` - returns moving difference for the current row and the preceding rows.\n    * `dataframe.mlinreg()` - returns moving linear regression for the current row and the preceding rows.\n    * `dataframe.msum()` - returns moving sum for the current row and the preceding rows.\n    * _regular aggregate functions_\n      * `dataframe.corr()` - returns the sample pearson product moment correlation coefficient.\n      * `dataframe.covar_pop()` - returns the population covariance.\n      * `dataframe.covar_samp()` - returns the sample covariance.\n      * `dataframe.regr_avgx()` - returns the mean of the independent variable.\n      * `dataframe.regr_avgy()` - returns the mean of the dependent variable.\n      * `dataframe.regr_count()` - returns the count of the dependent and independent variable arguments.\n      * `dataframe.rege_intercept()` - returns the intercept of the univariate linear regression line.\n      * `dataframe.regr_r2()` - returns the coefficient of determination.\n      * `dataframe.regr_slope()` - returns the slope of the univariate linear regression line through.\n      * `dataframe.regr_sxx()` - returns the sum of the squares of the independent variable expression.\n      * `dataframe.regr_sxy()` - returns the sum of the products of the independent variable and the dependent variable.\n      * `dataframe.regr_syy()` - returns the sum of the squares of the dependent variable expression.\n  * ###### teradataml dataframecolumn a.k.a. columnexpression\n    * `columnexpression.window()` - generates window object on a teradataml dataframecolumn to run window aggregate functions.\n    * `columnexpression.desc()` - sorts columnexpression in descending order.\n    * `columnexpression.asc()` - sorts columnexpression in ascending order.\n    * `columnexpression.distinct()` - removes duplicate value from columnexpression.\n    * _regular aggregate functions_\n      * `columnexpression.corr()` - returns the sample pearson product moment correlation coefficient.\n      * `columnexpression.count()` - returns the column-wise count.\n      * `columnexpression.covar_pop()` - returns the population covariance.\n      * `columnexpression.covar_samp()` - returns the sample covariance.\n      * `columnexpression.kurtosis()` - returns kurtosis value for a column.\n      * `columnexpression.median()` - returns column-wise median value.\n      * `columnexpression.max()` - returns the column-wise max value.\n      * `columnexpression.mean()` - returns the column-wise average value.\n      * `columnexpression.min()` - returns the column-wise min value.\n      * `columnexpression.regr_avgx()` - returns the mean of the independent variable.\n      * `columnexpression.regr_avgy()` - returns the mean of the dependent variable.\n      * `columnexpression.regr_count()` - returns the count of the dependent and independent variable arguments.\n      * `columnexpression.rege_intercept()` - returns the intercept of the univariate linear regression line.\n      * `columnexpression.regr_r2()` - returns the coefficient of determination arguments.\n      * `columnexpression.regr_slope()` - returns the slope of the univariate linear regression line.\n      * `columnexpression.regr_sxx()` - returns the sum of the squares of the independent variable expression.\n      * `columnexpression.regr_sxy()` - returns the sum of the products of the independent variable and the dependent variable.\n      * `columnexpression.regr_syy()` - returns the sum of the squares of the dependent variable expression.\n      * `columnexpression.skew()` - returns skew value for a column.\n      * `columnexpression.std()` - returns the column-wise population/sample standard deviation.\n      * `columnexpression.sum()` - returns the column-wise sum.\n      * `columnexpression.var()` - returns the column-wise population/sample variance.\n      * `columnexpression.percentile()` - returns the column-wise percentile.\n  * ###### teradataml window - window aggregate functions\n    following set of _window aggregate functions_ return the results over a specified window which can be of any type:\n      * cumulative/expanding window\n      * moving/rolling window\n      * contracting/remaining window\n      * grouping window\n    _window aggregate functions_\n    * `window.corr()` - returns the sample pearson product moment correlation coefficient.\n    * `window.count()` - returns the count.\n    * `window.covar_pop()` - returns the population covariance.\n    * `window.covar_samp()` - returns the sample covariance.\n    * `window.cume_dist()` - returns the cumulative distribution of values.\n    * `window.dense_rank()` - returns the ordered ranking of all the rows.\n    * `window.first_value()` - returns the first value of an ordered set of values.\n    * `window.lag()` - returns data from the row preceding the current row at a specified offset value.\n    * `window.last_value()` - returns the last value of an ordered set of values.\n    * `window.lead()` - returns data from the row following the current row at a specified offset value.\n    * `window.max()` - returns the column-wise max value.\n    * `window.mean()` - returns the column-wise average value.\n    * `window.min()` - returns the column-wise min value.\n    * `window.percent_rank()` - returns the relative rank of all the rows.\n    * `window.rank()` - returns the rank (1 \u2026 n) of all the rows.\n    * `window.regr_avgx()` - returns the mean of the independent variable arguments.\n    * `window.regr_avgy()` - returns the mean of the dependent variable arguments.\n    * `window.regr_count()` - returns the count of the dependent and independent variable arguments.\n    * `window.rege_intercept()` - returns the intercept of the univariate linear regression line arguments.\n    * `window.regr_r2()` - returns the coefficient of determination arguments.\n    * `window.regr_slope()` - returns the slope of the univariate linear regression line.\n    * `window.regr_sxx()` - returns the sum of the squares of the independent variable expression.\n    * `window.regr_sxy()` - returns the sum of the products of the independent variable and the dependent variable.\n    * `window.regr_syy()` - returns the sum of the squares of the dependent variable expression.\n    * `window.row_number()` - returns the sequential row number.\n    * `window.std()` - returns the column-wise population/sample standard deviation.\n    * `window.sum()` - returns the column-wise sum.\n    * `window.var()` - returns the column-wise population/sample variance.\n  * ###### general functions\n    * _new functions_\n      * `fastexport()` - exports teradataml dataframe to pandas dataframe using fastexport data transfer protocol.\n  * ###### teradataml options\n    * display options\n      * `display.blob_length`\n        specifies default display length of blob column in teradataml dataframe.\n    * configuration options\n      * `configure.temp_table_database`\n        specifies database name for storing the tables created internally.\n      * `configure.temp_view_database`\n        specifies database name for storing the views created internally.\n      * `configure.byom_install_location`\n        specifies the install location for the byom functions.\n      * `configure.val_install_location`\n        specifies the install location for the vantage analytic library functions.\n* ##### updates\n  * ###### teradataml dataframe\n    * `to_pandas()` - \n      * support added to transfer data to pandas dataframe using fastexport protocol improving the performance.\n      * support added for other arguments similar to pandas `read_sql()`:\n        * `coerce_float`\n        * `parse_dates`\n  * ###### analytic functions\n    * vantage analytic library functions\n      * support added to accept datetime.date object for literals/values in \n        following transformation functions:\n        * `fillna()`\n        * `binning()`\n        * `onehotencoder()`\n        * `labelencoder()`\n      * all transformation functions now supports accepting \n        teradatasqlalchemy datatypes as input to \"datatype\" argument for \n        casting the result.\n* ##### bug fixes.\n  * cs0249633 - support added for teradataml to work with user/database/tablename\n    containing period (.).\n  * cs0086594 - use of dbc.tablesvx versus dbc.tablesvx in teradatasqlalchemy.\n  * ipython integration to print the teradataml dataframes in pretty format.\n  * teradataml dataframe apis now support column names same as that of teradata \n    reserved keywords.\n  * issue has been fixed for duplicate rows being loaded via teradataml \n    fastload() api.\n  * val - empty string now can be passed as input for recoding values using \n    labelencoder.\n  * teradataml extension with sqlalchemy functions:\n    * mod() function is fixed to return correct datatype.\n    * sum() function is fixed to return correct datatype.\n\n\n#### teradataml 17.00.00.03\n- new release of sqlalchemy1.4.x introduced backward compatibility issue. a fix has been carried out so that teradataml can support latest sqlalchemy changes.\n- other minor bug fixes.\n\n#### teradataml 17.00.00.02\nfixed the internal library load issue related to the gcc version discrepancies on centos platform.\n\n#### teradataml 17.00.00.01\n* ##### new features/functionality\n  * ###### analytic functions\n    * vantage analytic library\n      teradataml now supports executing analytic functions offered by vantage analytic library.\n      these functions are available via new 'valib' sub-package of teradataml.\n      following functions are added as part of this:\n      * association rules:\n        * `association()`\n      * descriptive statistics:\n        * `adaptivehistogram()`\n        * `explore()`\n        * `frequency()`\n        * `histogram()`\n        * `overlaps()`\n        * `statistics()`\n        * `textanalyzer()`\n        * `values()`\n      * decision tree:\n        * `decisiontree()`\n        * `decisiontreepredict()`\n        * `decisiontreeevaluator()`\n      * fast k-means clustering:\n        * `kmeans()`\n        * `kmeanspredict()`\n      * linear regression:\n        * `linreg()`\n        * `linregpredict()`\n      * logistic regression:\n        * `logreg()`\n        * `logregpredict()`\n        * `logregevaluator()`\n      * factor analysis:\n        * `pca()`\n        * `pcapredict()`\n        * `pcaevaluator()`\n      * matrix building:\n        * `matrix()`\n      * statistical tests:\n        * `binomialtest()`\n        * `chisquaretest()`\n        * `kstest()`\n        * `parametrictest()`\n        * `ranktest()`\n      * variable transformation:\n        * `transform()`\n        * transformation techniques supported for variable transformation:\n          * `binning()` - perform bin coding to replaces continuous numeric column with a\n                          categorical one to produce ordinal values.\n          * `derive()` - perform free-form transformation done using arithmetic formula.\n          * `fillna()` - perform missing value/null replacement transformations.\n          * `labelencoder()` - re-express categorical column values into a new coding scheme.\n          * `minmaxscalar()` - rescale data limiting the upper and lower boundaries.\n          * `onehotencoder()` - re-express a categorical data element as one or more\n                                numeric data elements, creating a binary numeric field for each\n                                categorical data value.\n          * `retain()` - copy one or more columns into the final analytic data set.\n          * `sigmoid()` - rescale data using sigmoid or s-shaped functions.\n          * `zscore()` - rescale data using z-score values.\n    * ml engine functions (mle)\n      * correlation2\n      * naivebayestextclassifier2\n  * ###### dataframe\n    * _new functions_\n      * `dataframe.map_row()` - function to apply a user defined function to each row in the\n                                teradataml dataframe.\n      * `dataframe.map_partition()` - function to apply a user defined function to a group or\n                                      partition of rows in the teradataml dataframe.\n    * _new property_\n      * `dataframe.tdtypes` - get the teradataml dataframe metadata containing column names and\n                              corresponding teradatasqlalchemy types.\n  * ###### general functions\n    * _new functions_\n      * database utility functions\n        * `db_python_package_details()` - lists the details of python packages installed on vantage.\n      * general utility functions\n        * `print_options()`\n        * `view_log()`\n        * `setup_sandbox_env()`\n        * `copy_files_from_container()`\n        * `cleanup_sandbox_env()`\n* ##### updates\n  * ###### `create_context()`\n    * supports all connection parameters supported by teradatasql.connect().\n  * ###### script\n    * `test_script()` can now be executed in 'local' mode, i.e., outside of the sandbox.\n    * `script.setup_sto_env()` is deprecated. use `setup_sandbox_env()` function instead.\n    * added support for using \"quotechar\" argument.\n  * ###### analytic functions\n    * _updates_\n      * visit teradataml user guide to know more about the updates done to ml engine analytic\n        functions. following type of updates are done to several functions:\n        * new arguments are added, which are supported only on vantage version 1.3.\n        * default value has been updated for few function arguments.\n        * few arguments were required, but now they are optional.\n* ##### minor bug fixes.\n\n#### teradataml 17.00.00.00\n* ##### new features/functionality\n  * ###### model cataloging - functionality to catalog model metadata and related information in the model catalog.\n    * `save_model()` - save a teradataml analytic function model.\n    * `retrieve_model()` - retrieve a saved model.\n    * `list_model()` - list accessible models.\n    * `describe_model()` - list the details of a model.\n    * `delete_model()` - remove a model from model catalog.\n    * `publish_model()` - share a model.\n  * ###### script - an interface to the script table operator object in the advanced sql engine.\n    interface offers execution in two modes:\n    * test/debug - to test user scripts locally in a containerized environment.\n      supporting methods:\n      * `setup_sto_env()` - set up test environment.\n      * `test_script()` - test user script in containerized environment.\n      * `set_data()` - set test data parameters.\n    * in-database script execution - to execute user scripts in database.\n      supporting methods:\n      * `execute_script()` - execute user script in vantage.\n      * `install_file()` - install or replace file in database.\n      * `remove_file()` - remove installed file from database.\n      * `set_data()` - set test data parameters.\n  * ###### dataframe\n    * `dataframe.show_query()` - show underlying query for dataframe.\n    * regular aggregates\n      * _new functions_\n        * `kurtosis()` - calculate the kurtosis value.\n        * `skew()` - calculate the skewness of the distribution.\n      * _updates_\\\n        new argument `distinct` is added to following aggregates to exclude duplicate values.\n        * `count()`\n        * `max()`\n        * `mean()`\n        * `min()`\n        * `sum()`\n        * `std()`\n          * new argument `population` is added to calculate the population standard deviation.\n        * `var()`\n          * new argument `population` is added to calculate the population variance.\n    * time series aggregates\n      * _new functions_\n        * `kurtosis()` - calculate the kurtosis value.\n        * `count()` - get the total number of values.\n        * `max()` - calculate the maximum value.\n        * `mean()` - calculate the average value.\n        * `min()` - calculate the minimum value.\n        * `percentile()` - calculate the desired percentile.\n        * `skew()` - calculate the skewness of the distribution.\n        * `sum()` - calculate the column-wise sum value.\n        * `std()` - calculate the sample and population standard deviation.\n        * `var()` - calculate the sample and population standard variance.\n  * ###### general functions\n    * _new functions_\n      * database utility functions\n        * `db_drop_table()`\n        * `db_drop_view()`\n        * `db_list_tables()`\n      * vantage file management functions\n        * `install_file()` - install a file in database.\n        * `remove_file()` - remove an installed file from database.\n    * _updates_\n      * `create_context()`\n        * support added for stored password protection feature.\n        * kerberos authentication bug fix.\n        * new argument `database` added to `create_context()` api, that allows user to specify connecting database.\n  * ###### analytic functions\n    * _new functions_\n      * `betweenness`\n      * `closeness`\n      * `fmeasure`\n      * `frequentpaths`\n      * `identitymatch`\n      * `interpolator`\n      * `roc`\n    * _updates_\n      * new methods are added to all analytic functions\n        * `show_query()`\n        * `get_build_time()`\n        * `get_prediction_type()`\n        * `get_target_column()`\n      * new properties are added to analytic function's formula argument\n        * `response_column`\n        * `numeric_columns`\n        * `categorical_columns`\n        * `all_columns`\n\n#### teradataml 16.20.00.06\nfixed the dataframe data display corruption issue observed with certain analytic functions.\n\n#### teradataml 16.20.00.05\ncompatible with vantage 1.1.1.\\\nthe following ml engine (`teradataml.analytics.mle`) functions have new and/or updated arguments to support the vantage version:\n* `adaboostpredict`\n* `decisionforestpredict`\n* `decisiontreepredict`\n* `glmpredict`\n* `lda`\n* `naivebayespredict`\n* `naivebayestextclassifierpredict`\n* `svmdensepredict`\n* `svmsparse`\n* `svmsparsepredict`\n* `xgboostpredict`\n\n#### teradataml 16.20.00.04\n* ##### improvements\n  * dataframe creation is now quicker, impacting many apis and analytic functions.\n  * improved performance by reducing the number of intermediate queries issued to teradata vantage when not required.\n    * the number of queries reduced by combining multiple operations into a single step whenever possible and unless the user expects or demands to see the intermediate results.\n    * the performance improvement is almost proportional to the number of chained and unexecuted operations on a teradataml dataframe.\n  * reduced number of intermediate internal objects created on vantage.\n* ##### new features/functionality\n  * ###### general functions\n    * _new functions_\n      * `show_versions()` - to list the version of teradataml and dependencies installed.\n      * `fastload()` - for high performance data loading of large amounts of data into a table on vantage. requires `teradatasql` version `16.20.0.48` or above.\n      * set operators:\n        * `concat`\n        * `td_intersect`\n        * `td_except`\n        * `td_minus`\n      * `case()` - to help construct sql case based expressions.\n    * _updates_\n      * `copy_to_sql`\n        * added support to `copy_to_sql` to save multi-level index.\n        * corrected the type mapping for index when being saved.\n      * `create_context()` updated to support 'jwt' logon mechanism.\n  * ###### analytic functions\n    * _new functions_\n      * `nertrainer`\n      * `nerextractor`\n      * `nerevaluator`\n      * `glml1l2`\n      * `glml1l2predict`\n    * _updates_\n      * added support to categorize numeric columns as categorical while using formula - `as_categorical()` in the `teradataml.common.formula` module.\n  * ###### dataframe\n    * added support to create dataframe from volatile and primary time index tables.\n    * `dataframe.sample()` - to sample data.\n    * `dataframe.index` - property to access `index_label` of dataframe.\n    * functionality to process time series data\n      * grouping/resampling time series data:\n        * `groupby_time()`\n        * `resample()`\n      * time series aggregates:\n        * `bottom()`\n        * `count()`\n        * `describe()`\n        * `delta_t()`\n        * `mad()`\n        * `median()`\n        * `mode()`\n        * `first()`\n        * `last()`\n        * `top()`\n    * dataframe api and method argument validation added.\n    * `dataframe.info()` - default value for `null_counts` argument updated from `none` to `false`.\n    * `dataframe.merge()` updated to accept columns expressions along with column names to `on`, `left_on`, `right_on` arguments.\n  * ###### dataframe column/columnexpression methods\n    * `cast()` - to help cast the column to a specified type.\n    * `isin()` and `~isin()` - to check the presence of values in a column.\n* ##### removed deprecated analytic functions\n  * all the deprecated analytic functions under the `teradataml.analytics module` have been removed.\n    newer versions of the functions are available under the `teradataml.analytics.mle` and the `teradataml.analytics.sqle` modules.\n    the modules removed are:\n    * `teradataml.analytics.antiselect`\n    * `teradataml.analytics.arima`\n    * `teradataml.analytics.arimapredictor`\n    * `teradataml.analytics.attribution`\n    * `teradataml.analytics.confusionmatrix`\n    * `teradataml.analytics.coxhazardratio`\n    * `teradataml.analytics.coxph`\n    * `teradataml.analytics.coxsurvival`\n    * `teradataml.analytics.decisionforest`\n    * `teradataml.analytics.decisionforestevaluator`\n    * `teradataml.analytics.decisionforestpredict`\n    * `teradataml.analytics.decisiontree`\n    * `teradataml.analytics.decisiontreepredict`\n    * `teradataml.analytics.glm`\n    * `teradataml.analytics.glmpredict`\n    * `teradataml.analytics.kmeans`\n    * `teradataml.analytics.ngrams`\n    * `teradataml.analytics.npath`\n    * `teradataml.analytics.naivebayes`\n    * `teradataml.analytics.naivebayespredict`\n    * `teradataml.analytics.naivebayestextclassifier`\n    * `teradataml.analytics.naivebayestextclassifierpredict`\n    * `teradataml.analytics.pack`\n    * `teradataml.analytics.svmsparse`\n    * `teradataml.analytics.svmsparsepredict`\n    * `teradataml.analytics.sentenceextractor`\n    * `teradataml.analytics.sessionize`\n    * `teradataml.analytics.tf`\n    * `teradataml.analytics.tfidf`\n    * `teradataml.analytics.texttagger`\n    * `teradataml.analytics.texttokenizer`\n    * `teradataml.analytics.unpack`\n    * `teradataml.analytics.varmax`\n\n#### teradataml 16.20.00.03\n* fixed the garbage collection issue observed with `remove_context()` when context is created using a sqlalchemy engine.\n* added 4 new advanced sql engine (was newsql engine) analytic functions supported only on vantage 1.1:\n    * `antiselect`, `pack`, `stringsimilarity`, and `unpack`.\n* updated the machine learning engine `ngrams` function to work with vantage 1.1.\n\n#### teradataml 16.20.00.02\n* python version 3.4.x will no longer be supported. the python versions supported are 3.5.x, 3.6.x, and 3.7.x.\n* major issue with the usage of formula argument in analytic functions with python3.7 has been fixed, allowing this package to be used with python3.7 or later.\n* configurable alias name support for analytic functions has been added.\n* support added to create_context (connect to teradata vantage) with different logon mechanisms.\n    logon mechanisms supported are: 'td2', 'tdnego', 'ldap' & 'krb5'.\n* copy_to_sql function and dataframe 'to_sql' methods now provide following additional functionality:\n    * create primary time index tables.\n    * create set/multiset tables.\n* new dataframe methods are added: 'median', 'var', 'squeeze', 'sort_index', 'concat'.\n* dataframe method 'join' is now updated to make use of columnexpressions (df.column_name) for the 'on' clause as opposed to strings.\n* series is supported as a first class object by calling squeeze on dataframe.\n    * methods supported by teradataml series are: 'head', 'unique', 'name', '\\_\\_repr__'.\n    * binary operations with teradataml series is not yet supported. try using columns from teradataml.dataframes.\n* sample datasets and commands to load the same have been provided in the function examples.\n* new configuration property has been added 'column_casesenitive_handler'. useful when one needs to play with case sensitive columns.\n\n#### teradataml 16.20.00.01\n* new support has been added for linux distributions: red hat 7+, ubuntu 16.04+, centos 7+, sles12+.\n* 16.20.00.01 now has over 100 analytic functions. these functions have been organized into their own packages for better control over which engine to execute the analytic function on. due to these namespace changes, the old analytic functions have been deprecated and will be removed in a future release. see the deprecations section in the teradata python package user guide for more information.\n* new dataframe methods `shape`, `iloc`, `describe`, `get_values`, `merge`, and `tail`.\n* new series methods for na checking (`isnull`, `notnull`) and string processing (`lower`, `strip`, `contains`).\n\n#### teradataml 16.20.00.00\n* `teradataml 16.20.00.00` is the first release version. please refer to the _teradata python package user guide_ for a list of limitations and usage considerations.\n\n## installation and requirements\n\n### package requirements:\n* python 3.5 or later\n\nnote: 32-bit python is not supported.\n\n### minimum system requirements:\n* windows 7 (64bit) or later\n* macos 10.9 (64bit) or later\n* red hat 7 or later versions\n* ubuntu 16.04 or later versions\n* centos 7 or later versions\n* sles 12 or later versions\n* teradata vantage advanced sql engine:\n    * advanced sql engine 16.20 feature update 1 or later\n* for a teradata vantage system with the ml engine:\n    * teradata machine learning engine 08.00.03.01 or later\n\n### installation\n\nuse pip to install the teradata python package for advanced analytics.\n\nplatform       | command\n-------------- | ---\nmacos/linux    | `pip install teradataml`\nwindows        | `py -3 -m pip install teradataml`\n\nwhen upgrading to a new version of the teradata python package, you may need to use pip install's `--no-cache-dir` option to force the download of the new version.\n\nplatform       | command\n-------------- | ---\nmacos/linux    | `pip install --no-cache-dir -u teradataml`\nwindows        | `py -3 -m pip install --no-cache-dir -u teradataml`\n\n## using the teradata python package\n\nyour python script must import the `teradataml` package in order to use the teradata python package:\n\n```\n>>> import teradataml as tdml\n>>> from teradataml import create_context, remove_context\n>>> create_context(host = 'hostname', username = 'user', password = 'password')\n>>> df = tdml.dataframe('iris')\n>>> df\n\n   sepallength  sepalwidth  petallength  petalwidth             name\n0          5.1         3.8          1.5         0.3      iris-setosa\n1          6.9         3.1          5.1         2.3   iris-virginica\n2          5.1         3.5          1.4         0.3      iris-setosa\n3          5.9         3.0          4.2         1.5  iris-versicolor\n4          6.0         2.9          4.5         1.5  iris-versicolor\n5          5.0         3.5          1.3         0.3      iris-setosa\n6          5.5         2.4          3.8         1.1  iris-versicolor\n7          6.9         3.2          5.7         2.3   iris-virginica\n8          4.4         3.0          1.3         0.2      iris-setosa\n9          5.8         2.7          5.1         1.9   iris-virginica\n\n>>> df = df.select(['name', 'sepallength', 'petallength'])\n>>> df\n\n              name  sepallength  petallength\n0  iris-versicolor          6.0          4.5\n1  iris-versicolor          5.5          3.8\n2   iris-virginica          6.9          5.7\n3      iris-setosa          5.1          1.4\n4      iris-setosa          5.1          1.5\n5   iris-virginica          5.8          5.1\n6   iris-virginica          6.9          5.1\n7      iris-setosa          5.1          1.4\n8   iris-virginica          7.7          6.7\n9      iris-setosa          5.0          1.3\n\n>>> df = df[(df.name == 'iris-setosa') & (df.petallength > 1.5)]\n>>> df\n\n          name  sepallength  petallength\n0  iris-setosa          4.8          1.9\n1  iris-setosa          5.4          1.7\n2  iris-setosa          5.7          1.7\n3  iris-setosa          5.0          1.6\n4  iris-setosa          5.1          1.9\n5  iris-setosa          4.8          1.6\n6  iris-setosa          4.7          1.6\n7  iris-setosa          5.1          1.6\n8  iris-setosa          5.1          1.7\n9  iris-setosa          4.8          1.6\n```\n\n## documentation\n\ngeneral product information, including installation instructions, is available in the [teradata documentation website](https://docs.teradata.com/search/documents?query=package+python+-lake&filters=category~%2522programming+reference%2522_%2522user+guide%2522*prodname~%2522teradata+package+for+python%2522_%2522teradata+python+package%2522&sort=last_update&virtual-field=title_only&content-lang=)\n\n## license\n\nuse of the teradata python package is governed by the *license agreement for the teradata python package for advanced analytics*. \nafter installation, the `license` and `license-3rd-party` files are located in the `teradataml` directory of the python installation directory.\n\n\n",
  "docs_url": null,
  "keywords": "teradata",
  "license": "teradata license agreement",
  "name": "teradataml",
  "package_url": "https://pypi.org/project/teradataml/",
  "project_url": "https://pypi.org/project/teradataml/",
  "project_urls": {
    "Homepage": "http://www.teradata.com/"
  },
  "release_url": "https://pypi.org/project/teradataml/17.20.0.6/",
  "requires_dist": [
    "teradatasql (>=17.10.0.11)",
    "teradatasqlalchemy (>=17.20.0.0)",
    "pandas (>=0.22)",
    "psutil",
    "requests (>=2.25.1)"
  ],
  "requires_python": ">=3.5",
  "summary": "teradata vantage python package for advanced analytics",
  "version": "17.20.0.6",
  "releases": [],
  "developers": [
    "teradata_corporation"
  ],
  "kwds": "teradatasql teradata _teradata teradataml teradatasqlalchemy",
  "license_kwds": "teradata license agreement",
  "libtype": "pypi",
  "id": "pypi_teradataml",
  "homepage": "http://www.teradata.com/",
  "release_count": 22,
  "dependency_ids": [
    "pypi_pandas",
    "pypi_psutil",
    "pypi_requests",
    "pypi_teradatasql",
    "pypi_teradatasqlalchemy"
  ]
}