{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "intended audience :: education",
    "intended audience :: science/research",
    "license :: osi approved :: apache software license",
    "operating system :: macos",
    "operating system :: microsoft :: windows",
    "operating system :: posix :: linux",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.12",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: utilities"
  ],
  "description": "<!-- markdownlint-disable html -->\n\n# optree\n\n![python 3.7+](https://img.shields.io/badge/python-3.7%2b-brightgreen)\n[![pypi](https://img.shields.io/pypi/v/optree?logo=pypi)](https://pypi.org/project/optree)\n![github workflow status](https://img.shields.io/github/actions/workflow/status/metaopt/optree/build.yml?label=build&logo=github)\n![github workflow status](https://img.shields.io/github/actions/workflow/status/metaopt/optree/tests.yml?label=tests&logo=github)\n[![codecov](https://img.shields.io/codecov/c/github/metaopt/optree/main?logo=codecov)](https://codecov.io/gh/metaopt/optree)\n[![documentation status](https://img.shields.io/readthedocs/optree?logo=readthedocs)](https://optree.readthedocs.io)\n[![downloads](https://static.pepy.tech/personalized-badge/optree?period=total&left_color=grey&right_color=blue&left_text=downloads)](https://pepy.tech/project/optree)\n[![github repo stars](https://img.shields.io/github/stars/metaopt/optree?color=brightgreen&logo=github)](https://github.com/metaopt/optree/stargazers)\n\noptimized pytree utilities.\n\n--------------------------------------------------------------------------------\n\n### table of contents  <!-- omit in toc --> <!-- markdownlint-disable heading-increment -->\n\n- [installation](#installation)\n- [pytrees](#pytrees)\n  - [tree nodes and leaves](#tree-nodes-and-leaves)\n    - [built-in pytree node types](#built-in-pytree-node-types)\n    - [registering a container-like custom type as non-leaf nodes](#registering-a-container-like-custom-type-as-non-leaf-nodes)\n    - [notes about the pytree type registry](#notes-about-the-pytree-type-registry)\n  - [`none` is non-leaf node vs. `none` is leaf](#none-is-non-leaf-node-vs-none-is-leaf)\n  - [key ordering for dictionaries](#key-ordering-for-dictionaries)\n- [benchmark](#benchmark)\n  - [tree flatten](#tree-flatten)\n  - [tree unflatten](#tree-unflatten)\n  - [tree flatten with path](#tree-flatten-with-path)\n  - [tree copy](#tree-copy)\n  - [tree map](#tree-map)\n  - [tree map (nargs)](#tree-map-nargs)\n  - [tree map with path](#tree-map-with-path)\n  - [tree map with path (nargs)](#tree-map-with-path-nargs)\n- [changelog](#changelog)\n- [license](#license)\n\n--------------------------------------------------------------------------------\n\n## installation\n\ninstall from pypi ([![pypi](https://img.shields.io/pypi/v/optree?logo=pypi)](https://pypi.org/project/optree) / ![status](https://img.shields.io/pypi/status/optree)):\n\n```bash\npip3 install --upgrade optree\n```\n\ninstall from conda-forge ([![conda-forge](https://img.shields.io/conda/v/conda-forge/optree?logo=condaforge)](https://anaconda.org/conda-forge/optree)):\n\n```bash\nconda install -c conda-forge optree\n```\n\ninstall the latest version from github:\n\n```bash\npip3 install git+https://github.com/metaopt/optree.git#egg=optree\n```\n\nor, clone this repo and install manually:\n\n```bash\ngit clone --depth=1 https://github.com/metaopt/optree.git\ncd optree\npip3 install .\n```\n\ncompiling from the source requires python 3.7+, a compiler (`gcc` / `clang` / `icc` / `cl.exe`) that supports c++20 and a `cmake` installation.\n\n--------------------------------------------------------------------------------\n\n## pytrees\n\na pytree is a recursive structure that can be an arbitrarily nested python container (e.g., `tuple`, `list`, `dict`, `ordereddict`, `namedtuple`, etc.) or an opaque python object.\nthe key concepts of tree operations are tree flattening and its inverse (tree unflattening).\nadditional tree operations can be performed based on these two basic functions (e.g., `tree_map = tree_unflatten \u2218 map \u2218 tree_flatten`).\n\ntree flattening is traversing the entire tree in a left-to-right depth-first manner and returning the leaves of the tree in a deterministic order.\n\n```python\n>>> tree = {'b': (2, [3, 4]), 'a': 1, 'c': 5, 'd': 6}\n>>> optree.tree_flatten(tree)\n([1, 2, 3, 4, 5, 6], pytreespec({'a': *, 'b': (*, [*, *]), 'c': *, 'd': *}))\n>>> optree.tree_flatten(1)\n([1], pytreespec(*))\n>>> optree.tree_flatten(none)\n([], pytreespec(none))\n```\n\nthis usually implies that the equal pytrees return equal lists of leaves and the same tree structure.\nsee also section [key ordering for dictionaries](#key-ordering-for-dictionaries).\n\n```python\n>>> {'a': [1, 2], 'b': [3]} == {'b': [3], 'a': [1, 2]}\ntrue\n>>> optree.tree_leaves({'a': [1, 2], 'b': [3]}) == optree.tree_leaves({'b': [3], 'a': [1, 2]})\ntrue\n>>> optree.tree_structure({'a': [1, 2], 'b': [3]}) == optree.tree_structure({'b': [3], 'a': [1, 2]})\ntrue\n```\n\n### tree nodes and leaves\n\na tree is a collection of non-leaf nodes and leaf nodes, where the leaf nodes have no children to flatten.\n`optree.tree_flatten(...)` will flatten the tree and return a list of leaf nodes while the non-leaf nodes will store in the tree specification.\n\n#### built-in pytree node types\n\noptree out-of-box supports the following python container types in the registry:\n\n- [`tuple`](https://docs.python.org/3/library/stdtypes.html#tuple)\n- [`list`](https://docs.python.org/3/library/stdtypes.html#list)\n- [`dict`](https://docs.python.org/3/library/stdtypes.html#dict)\n- [`collections.namedtuple`](https://docs.python.org/3/library/collections.html#collections.namedtuple) and its subclasses\n- [`collections.ordereddict`](https://docs.python.org/3/library/collections.html#collections.ordereddict)\n- [`collections.defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict)\n- [`collections.deque`](https://docs.python.org/3/library/collections.html#collections.deque)\n- [`pystructsequence`](https://docs.python.org/3/c-api/tuple.html#struct-sequence-objects) types created by c api [`pystructsequence_newtype`](https://docs.python.org/3/c-api/tuple.html#c.pystructsequence_newtype)\n\nwhich are considered non-leaf nodes in the tree.\npython objects that the type is not registered will be treated as leaf nodes.\nthe registration lookup uses the `is` operator to determine whether the type is matched.\nso subclasses will need to explicitly register in the registry, otherwise, an object of that type will be considered a leaf.\nthe [`nonetype`](https://docs.python.org/3/library/constants.html#none) is a special case discussed in section [`none` is non-leaf node vs. `none` is leaf](#none-is-non-leaf-node-vs-none-is-leaf).\n\n#### registering a container-like custom type as non-leaf nodes\n\na container-like python type can be registered in the type registry with a pair of functions that specify:\n\n- `flatten_func(container) -> (children, metadata, entries)`: convert an instance of the container type to a `(children, metadata, entries)` triple, where `children` is an iterable of subtrees and `entries` is an iterable of path entries of the container (e.g., indices or keys).\n- `unflatten_func(metadata, children) -> container`: convert such a pair back to an instance of the container type.\n\nthe `metadata` is some necessary data apart from the children to reconstruct the container, e.g., the keys of the dictionary (the children are values).\n\nthe `entries` can be omitted (only returns a pair) or is optional to implement (returns `none`). if so, use `range(len(children))` (i.e., flat indices) as path entries of the current node. the function signature can be `flatten_func(container) -> (children, metadata)` or `flatten_func(container) -> (children, metadata, none)`.\n\nthe following examples show how to register custom types and utilize them for `tree_flatten` and `tree_map`. please refer to section [notes about the pytree type registry](#notes-about-the-pytree-type-registry) for more information.\n\n```python\n# registry a python type with lambda functions\noptree.register_pytree_node(\n    set,\n    # (set) -> (children, metadata, none)\n    lambda s: (sorted(s), none, none),\n    # (metadata, children) -> (set)\n    lambda _, children: set(children),\n    namespace='set',\n)\n\n# register a python type into a namespace\nimport torch\n\noptree.register_pytree_node(\n    torch.tensor,\n    # (tensor) -> (children, metadata)\n    flatten_func=lambda tensor: (\n        (tensor.cpu().detach().numpy(),),\n        {'dtype': tensor.dtype, 'device': tensor.device, 'requires_grad': tensor.requires_grad},\n    ),\n    # (metadata, children) -> tensor\n    unflatten_func=lambda metadata, children: torch.tensor(children[0], **metadata),\n    namespace='torch2numpy',\n)\n```\n\n```python\n>>> tree = {'weight': torch.ones(size=(1, 2)).cuda(), 'bias': torch.zeros(size=(2,))}\n>>> tree\n{'weight': tensor([[1., 1.]], device='cuda:0'), 'bias': tensor([0., 0.])}\n\n# flatten without specifying the namespace\n>>> optree.tree_flatten(tree)  # `torch.tensor`s are leaf nodes\n([tensor([0., 0.]), tensor([[1., 1.]], device='cuda:0')], pytreespec({'bias': *, 'weight': *}))\n\n# flatten with the namespace\n>>> leaves, treespec = optree.tree_flatten(tree, namespace='torch2numpy')\n>>> leaves, treespec\n(\n    [array([0., 0.], dtype=float32), array([[1., 1.]], dtype=float32)],\n    pytreespec(\n        {\n            'bias': customtreenode(tensor[{'dtype': torch.float32, 'device': device(type='cpu'), 'requires_grad': false}], [*]),\n            'weight': customtreenode(tensor[{'dtype': torch.float32, 'device': device(type='cuda', index=0), 'requires_grad': false}], [*])\n        },\n        namespace='torch2numpy'\n    )\n)\n\n# `entries` are not defined and use `range(len(children))`\n>>> optree.tree_paths(tree, namespace='torch2numpy')\n[('bias', 0), ('weight', 0)]\n\n# unflatten back to a copy of the original object\n>>> optree.tree_unflatten(treespec, leaves)\n{'bias': tensor([0., 0.]), 'weight': tensor([[1., 1.]], device='cuda:0')}\n```\n\nusers can also extend the pytree registry by decorating the custom class and defining an instance method `tree_flatten` and a class method `tree_unflatten`.\n\n```python\nfrom collections import userdict\n\n@optree.register_pytree_node_class(namespace='mydict')\nclass mydict(userdict):\n    def tree_flatten(self):  # -> (children, metadata, entries)\n        reversed_keys = sorted(self.keys(), reverse=true)\n        return (\n            [self[key] for key in reversed_keys],  # children\n            reversed_keys,  # metadata\n            reversed_keys,  # entries\n        )\n\n    @classmethod\n    def tree_unflatten(cls, metadata, children):\n        return cls(zip(metadata, children))\n```\n\n```python\n>>> tree = mydict(b=4, a=(2, 3), c=mydict({'d': 5, 'f': 6}))\n\n# flatten without specifying the namespace\n>>> optree.tree_flatten_with_path(tree)  # `mydict`s are leaf nodes\n(\n    [()],\n    [mydict(b=4, a=(2, 3), c=mydict({'d': 5, 'f': 6}))],\n    pytreespec(*)\n)\n\n# flatten with the namespace\n>>> optree.tree_flatten_with_path(tree, namespace='mydict')\n(\n    [('c', 'f'), ('c', 'd'), ('b',), ('a', 0), ('a', 1)],\n    [6, 5, 4, 2, 3],\n    pytreespec(\n        customtreenode(mydict[['c', 'b', 'a']], [customtreenode(mydict[['f', 'd']], [*, *]), *, (*, *)]),\n        namespace='mydict'\n    )\n)\n```\n\n#### notes about the pytree type registry\n\nthere are several key attributes of the pytree type registry:\n\n1. **the type registry is per-interpreter-dependent.** this means registering a custom type in the registry affects all modules that use optree.\n\n    ```diff\n    - !!! warning !!!\n      for safety reasons, a `namespace` must be specified while registering a custom type. it is\n      used to isolate the behavior of flattening and unflattening a pytree node type. this is to\n      prevent accidental collisions between different libraries that may register the same type.\n    ```\n\n2. **the elements in the type registry are immutable.** users can neither register the same type twice in the same namespace (i.e., update the type registry), nor remove a type from the type registry. to update the behavior of an already registered type, simply register it again with another `namespace`.\n\n3. **users cannot modify the behavior of already registered built-in types** listed in [built-in pytree node types](#built-in-pytree-node-types), such as key order sorting for `dict` and `collections.defaultdict`.\n\n4. **inherited subclasses are not implicitly registered.** the registration lookup uses `type(obj) is registered_type` rather than `isinstance(obj, registered_type)`. users need to register the subclasses explicitly. to register all subclasses, it is easy to implement with [`metaclass`](https://docs.python.org/3/reference/datamodel.html#metaclasses) or [`__init_subclass__`](https://docs.python.org/3/reference/datamodel.html#customizing-class-creation), for example:\n\n    ```python\n    from collections import userdict\n\n    @optree.register_pytree_node_class(namespace='mydict')\n    class mydict(userdict):\n        def __init_subclass__(cls):  # define this in the base class\n            super().__init_subclass__()\n            # register a subclass to namespace 'mydict'\n            optree.register_pytree_node_class(cls, namespace='mydict')\n\n        def tree_flatten(self):  # -> (children, metadata, entries)\n            reversed_keys = sorted(self.keys(), reverse=true)\n            return (\n                [self[key] for key in reversed_keys],  # children\n                reversed_keys,  # metadata\n                reversed_keys,  # entries\n            )\n\n        @classmethod\n        def tree_unflatten(cls, metadata, children):\n            return cls(zip(metadata, children))\n\n    # subclasses will be automatically registered in namespace 'mydict'\n    class myanotherdict(mydict):\n        pass\n    ```\n\n    ```python\n    >>> tree = mydict(b=4, a=(2, 3), c=myanotherdict({'d': 5, 'f': 6}))\n    >>> optree.tree_flatten_with_path(tree, namespace='mydict')\n    (\n        [('c', 'f'), ('c', 'd'), ('b',), ('a', 0), ('a', 1)],\n        [6, 5, 4, 2, 3],\n        pytreespec(\n            customtreenode(mydict[['c', 'b', 'a']], [customtreenode(myanotherdict[['f', 'd']], [*, *]), *, (*, *)]),\n            namespace='mydict'\n        )\n    )\n    ```\n\n5. **be careful about the potential infinite recursion of the custom flatten function.** the returned `children` from the custom flatten function are considered subtrees. they will be further flattened recursively. the `children` can have the same type as the current node. users must design their termination condition carefully.\n\n    ```python\n    import numpy as np\n    import torch\n\n    optree.register_pytree_node(\n        np.ndarray,\n        # children are nest lists of python objects\n        lambda array: (np.atleast_1d(array).tolist(), array.ndim == 0),\n        lambda scalar, rows: np.asarray(rows) if not scalar else np.asarray(rows[0]),\n        namespace='numpy1',\n    )\n\n    optree.register_pytree_node(\n        np.ndarray,\n        # children are python objects\n        lambda array: (\n            list(array.ravel()),  # list(1darray[t]) -> list[t]\n            dict(shape=array.shape, dtype=array.dtype)\n        ),\n        lambda metadata, children: np.asarray(children, dtype=metadata['dtype']).reshape(metadata['shape']),\n        namespace='numpy2',\n    )\n\n    optree.register_pytree_node(\n        np.ndarray,\n        # returns a list of `np.ndarray`s without termination condition\n        lambda array: ([array.ravel()], array.dtype),\n        lambda shape, children: children[0].reshape(shape),\n        namespace='numpy3',\n    )\n\n    optree.register_pytree_node(\n        torch.tensor,\n        # children are nest lists of python objects\n        lambda tensor: (torch.atleast_1d(tensor).tolist(), tensor.ndim == 0),\n        lambda scalar, rows: torch.tensor(rows) if not scalar else torch.tensor(rows[0])),\n        namespace='torch1',\n    )\n\n    optree.register_pytree_node(\n        torch.tensor,\n        # returns a list of `torch.tensor`s without termination condition\n        lambda tensor: (\n            list(tensor.view(-1)),  # list(1dtensor[t]) -> list[0dtensor[t]] (still tensors!)\n            tensor.shape\n        ),\n        lambda shape, children: torch.stack(children).reshape(shape),\n        namespace='torch2',\n    )\n    ```\n\n    ```python\n    >>> optree.tree_flatten(np.arange(9).reshape(3, 3), namespace='numpy1')\n    (\n        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n        pytreespec(\n            customtreenode(ndarray[false], [[*, *, *], [*, *, *], [*, *, *]]),\n            namespace='numpy1'\n        )\n    )\n    # implicitly casts `float`s to `np.float64`\n    >>> optree.tree_map(lambda x: x + 1.5, np.arange(9).reshape(3, 3), namespace='numpy1')\n    array([[1.5, 2.5, 3.5],\n           [4.5, 5.5, 6.5],\n           [7.5, 8.5, 9.5]])\n\n    >>> optree.tree_flatten(np.arange(9).reshape(3, 3), namespace='numpy2')\n    (\n        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n        pytreespec(\n            customtreenode(ndarray[{'shape': (3, 3), 'dtype': dtype('int64')}], [*, *, *, *, *, *, *, *, *]),\n            namespace='numpy2'\n        )\n    )\n    # explicitly casts `float`s to `np.int64`\n    >>> optree.tree_map(lambda x: x + 1.5, np.arange(9).reshape(3, 3), namespace='numpy2')\n    array([[1, 2, 3],\n           [4, 5, 6],\n           [7, 8, 9]])\n\n    # children are also `np.ndarray`s, recurse without termination condition.\n    >>> optree.tree_flatten(np.arange(9).reshape(3, 3), namespace='numpy3')\n    traceback (most recent call last):\n        ...\n    recursionerror: maximum recursion depth exceeded during flattening the tree.\n\n    >>> optree.tree_flatten(torch.arange(9).reshape(3, 3), namespace='torch1')\n    (\n        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n        pytreespec(\n            customtreenode(tensor[false], [[*, *, *], [*, *, *], [*, *, *]]),\n            namespace='torch1'\n        )\n    )\n    # implicitly casts `float`s to `torch.float32`\n    >>> optree.tree_map(lambda x: x + 1.5, torch.arange(9).reshape(3, 3), namespace='torch1')\n    tensor([[1.5000, 2.5000, 3.5000],\n            [4.5000, 5.5000, 6.5000],\n            [7.5000, 8.5000, 9.5000]])\n\n    # children are also `torch.tensor`s, recurse without termination condition.\n    >>> optree.tree_flatten(torch.arange(9).reshape(3, 3), namespace='torch2')\n    traceback (most recent call last):\n        ...\n    recursionerror: maximum recursion depth exceeded during flattening the tree.\n    ```\n\n### `none` is non-leaf node vs. `none` is leaf\n\nthe [`none`](https://docs.python.org/3/library/constants.html#none) object is a special object in the python language.\nit serves some of the same purposes as `null` (a pointer does not point to anything) in other programming languages, which denotes a variable is empty or marks default parameters.\nhowever, the `none` object is a singleton object rather than a pointer.\nit may also serve as a sentinel value.\nin addition, if a function has returned without any return value or the return statement is omitted, the function will also implicitly return the `none` object.\n\nby default, the `none` object is considered a non-leaf node in the tree with arity 0, i.e., _**a non-leaf node that has no children**_.\nthis is like the behavior of an empty tuple.\nwhile flattening a tree, it will remain in the tree structure definitions rather than in the leaves list.\n\n```python\n>>> tree = {'b': (2, [3, 4]), 'a': 1, 'c': none, 'd': 5}\n>>> optree.tree_flatten(tree)\n([1, 2, 3, 4, 5], pytreespec({'a': *, 'b': (*, [*, *]), 'c': none, 'd': *}))\n>>> optree.tree_flatten(tree, none_is_leaf=true)\n([1, 2, 3, 4, none, 5], pytreespec({'a': *, 'b': (*, [*, *]), 'c': *, 'd': *}, noneisleaf))\n>>> optree.tree_flatten(1)\n([1], pytreespec(*))\n>>> optree.tree_flatten(none)\n([], pytreespec(none))\n>>> optree.tree_flatten(none, none_is_leaf=true)\n([none], pytreespec(*, noneisleaf))\n```\n\noptree provides a keyword argument `none_is_leaf` to determine whether to consider the `none` object as a leaf, like other opaque objects.\nif `none_is_leaf=true`, the `none` object will place in the leaves list.\notherwise, the `none` object will remain in the tree specification (structure).\n\n```python\n>>> import torch\n\n>>> linear = torch.nn.linear(in_features=3, out_features=2, bias=false)\n>>> linear._parameters  # a container has none\nordereddict([\n    ('weight', parameter containing:\n               tensor([[-0.6677,  0.5209,  0.3295],\n                       [-0.4876, -0.3142,  0.1785]], requires_grad=true)),\n    ('bias', none)\n])\n\n>>> optree.tree_map(torch.zeros_like, linear._parameters)\nordereddict([\n    ('weight', tensor([[0., 0., 0.],\n                       [0., 0., 0.]])),\n    ('bias', none)\n])\n\n>>> optree.tree_map(torch.zeros_like, linear._parameters, none_is_leaf=true)\ntraceback (most recent call last):\n    ...\ntypeerror: zeros_like(): argument 'input' (position 1) must be tensor, not nonetype\n\n>>> optree.tree_map(lambda t: torch.zeros_like(t) if t is not none else 0, linear._parameters, none_is_leaf=true)\nordereddict([\n    ('weight', tensor([[0., 0., 0.],\n                       [0., 0., 0.]])),\n    ('bias', 0)\n])\n```\n\n### key ordering for dictionaries\n\nthe built-in python dictionary (i.e., [`builtins.dict`](https://docs.python.org/3/library/stdtypes.html#dict)) is an unordered mapping that holds the keys and values.\nthe leaves of a dictionary are the values. although since python 3.6, the built-in dictionary is insertion ordered ([pep 468](https://peps.python.org/pep-0468)).\nthe dictionary equality operator (`==`) does not check for key ordering.\nto ensure [referential transparency](https://en.wikipedia.org/wiki/referential_transparency) that \"equal `dict`\" implies \"equal ordering of leaves\", the order of values of the dictionary is sorted by the keys.\nthis behavior is also applied to [`collections.defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict).\n\n```python\n>>> optree.tree_flatten({'a': [1, 2], 'b': [3]})\n([1, 2, 3], pytreespec({'a': [*, *], 'b': [*]}))\n>>> optree.tree_flatten({'b': [3], 'a': [1, 2]})\n([1, 2, 3], pytreespec({'a': [*, *], 'b': [*]}))\n```\n\nif users want to keep the values in the insertion order in pytree traversal, they should use [`collections.ordereddict`](https://docs.python.org/3/library/collections.html#collections.ordereddict), which will take the order of keys under consideration:\n\n```python\n>>> ordereddict([('a', [1, 2]), ('b', [3])]) == ordereddict([('b', [3]), ('a', [1, 2])])\nfalse\n>>> optree.tree_flatten(ordereddict([('a', [1, 2]), ('b', [3])]))\n([1, 2, 3], pytreespec(ordereddict([('a', [*, *]), ('b', [*])])))\n>>> optree.tree_flatten(ordereddict([('b', [3]), ('a', [1, 2])]))\n([3, 1, 2], pytreespec(ordereddict([('b', [*]), ('a', [*, *])])))\n```\n\n**since optree v0.9.0, the key order of the reconstructed output dictionaries from `tree_unflatten` is guaranteed to be consistent with the key order of the input dictionaries in `tree_flatten`.**\n\n```python\n>>> leaves, treespec = optree.tree_flatten({'b': [3], 'a': [1, 2]})\n>>> leaves, treespec\n([1, 2, 3], pytreespec({'a': [*, *], 'b': [*]}))\n>>> optree.tree_unflatten(treespec, leaves)\n{'b': [3], 'a': [1, 2]}\n>>> optree.tree_map(lambda x: x, {'b': [3], 'a': [1, 2]})\n{'b': [3], 'a': [1, 2]}\n>>> optree.tree_map(lambda x: x + 1, {'b': [3], 'a': [1, 2]})\n{'b': [4], 'a': [2, 3]}\n```\n\nthis property is also preserved during serialization/deserialization.\n\n```python\n>>> leaves, treespec = optree.tree_flatten({'b': [3], 'a': [1, 2]})\n>>> leaves, treespec\n([1, 2, 3], pytreespec({'a': [*, *], 'b': [*]}))\n>>> restored_treespec = pickle.loads(pickle.dumps(treespec))\n>>> optree.tree_unflatten(treespec, leaves)\n{'b': [3], 'a': [1, 2]}\n>>> optree.tree_unflatten(restored_treespec, leaves)\n{'b': [3], 'a': [1, 2]}\n```\n\n> note that there are no restrictions on the `dict` to require the keys to be comparable (sortable).\n> there can be multiple types of keys in the dictionary.\n> the keys are sorted in ascending order by `key=lambda k: k` first if capable otherwise fallback to `key=lambda k: (f'{k.__class__.__module__}.{k.__class__.__qualname__}', k)`. this handles most cases.\n>\n> ```python\n> >>> sorted({1: 2, 1.5: 1}.keys())\n> [1, 1.5]\n> >>> sorted({'a': 3, 1: 2, 1.5: 1}.keys())\n> traceback (most recent call last):\n>     ...\n> typeerror: '<' not supported between instances of 'int' and 'str'\n> >>> sorted({'a': 3, 1: 2, 1.5: 1}.keys(), key=lambda k: (f'{k.__class__.__module__}.{k.__class__.__qualname__}', k))\n> [1.5, 1, 'a']\n> ```\n\n--------------------------------------------------------------------------------\n\n## benchmark\n\nwe benchmark the performance of:\n\n- tree flatten\n- tree unflatten\n- tree copy (i.e., `unflatten(flatten(...))`)\n- tree map\n\ncompared with the following libraries:\n\n- optree ([`@v0.9.0`](https://github.com/metaopt/optree/tree/v0.9.0))\n- jax xla ([`jax[cpu] == 0.4.6`](https://pypi.org/project/jax/0.4.6))\n- pytorch ([`torch == 2.0.0`](https://pypi.org/project/torch/2.0.0))\n- dm-tree ([`dm-tree == 0.1.8`](https://pypi.org/project/dm-tree/0.1.8))\n\n| average time cost (\u2193)      | optree (v0.9.0) | jax xla (v0.4.6) | pytorch (v2.0.0) | dm-tree (v0.1.8) |\n| :------------------------- | --------------: | ---------------: | ---------------: | ---------------: |\n| tree flatten               |           x1.00 |             2.33 |            22.05 |             1.12 |\n| tree unflatten             |           x1.00 |             2.69 |             4.28 |            16.23 |\n| tree flatten with path     |           x1.00 |            16.16 |    not supported |            27.59 |\n| tree copy                  |           x1.00 |             2.56 |             9.97 |            11.02 |\n| tree map                   |           x1.00 |             2.56 |             9.58 |            10.62 |\n| tree map (nargs)           |           x1.00 |             2.89 |    not supported |            31.33 |\n| tree map with path         |           x1.00 |             7.23 |    not supported |            19.66 |\n| tree map with path (nargs) |           x1.00 |             6.56 |    not supported |            29.61 |\n\nall results are reported on a workstation with an amd ryzen 9 5950x cpu @ 4.45ghz in an isolated virtual environment with python 3.10.9.\nrun with the following commands:\n\n```bash\nconda create --name optree-benchmark anaconda::python=3.10 --yes --no-default-packages\nconda activate optree-benchmark\npython3 -m pip install --editable '.[benchmark]' --extra-index-url https://download.pytorch.org/whl/cpu\npython3 benchmark.py --number=10000 --repeat=5\n```\n\nthe test inputs are nested containers (i.e., pytrees) extracted from `torch.nn.module` objects.\nthey are:\n\n```python\ntiny_mlp = nn.sequential(\n    nn.linear(1, 1, bias=true),\n    nn.batchnorm1d(1, affine=true, track_running_stats=true),\n    nn.relu(),\n    nn.linear(1, 1, bias=false),\n    nn.sigmoid(),\n)\n```\n\nand alexnet, resnet18, resnet34, resnet50, resnet101, resnet152, visiontransformerh14 (vit-h/14), and swintransformerb (swin-b) from [`torchvsion`](https://github.com/pytorch/vision).\nplease refer to [`benchmark.py`](https://github.com/metaopt/optree/blob/head/benchmark.py) for more details.\n\n### tree flatten\n\n| module    | nodes | optree (\u03bcs) | jax xla (\u03bcs) | pytorch (\u03bcs) | dm-tree (\u03bcs) | speedup (j / o) | speedup (p / o) | speedup (d / o) |\n| :-------- | ----: | ----------: | -----------: | -----------: | -----------: | --------------: | --------------: | --------------: |\n| tinymlp   |    53 |       29.70 |        71.06 |       583.66 |        31.32 |            2.39 |           19.65 |            1.05 |\n| alexnet   |   188 |      103.92 |       262.56 |      2304.36 |       119.61 |            2.53 |           22.17 |            1.15 |\n| resnet18  |   698 |      368.06 |       852.69 |      8440.31 |       420.43 |            2.32 |           22.93 |            1.14 |\n| resnet34  |  1242 |      644.96 |      1461.55 |     14498.81 |       712.81 |            2.27 |           22.48 |            1.11 |\n| resnet50  |  1702 |      919.95 |      2080.58 |     20995.96 |      1006.42 |            2.26 |           22.82 |            1.09 |\n| resnet101 |  3317 |     1806.36 |      3996.90 |     40314.12 |      1955.48 |            2.21 |           22.32 |            1.08 |\n| resnet152 |  4932 |     2656.92 |      5812.38 |     57775.53 |      2826.92 |            2.19 |           21.75 |            1.06 |\n| vit-h/14  |  3420 |     1863.50 |      4418.24 |     41334.64 |      2128.71 |            2.37 |           22.18 |            1.14 |\n| swin-b    |  2881 |     1631.06 |      3944.13 |     36131.54 |      2032.77 |            2.42 |           22.15 |            1.25 |\n|           |       |             |              |              |  **average** |        **2.33** |       **22.05** |        **1.12** |\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/16078332/227140610-dce44f1b-3a91-43e6-85b5-7566ae4c8769.png\" width=\"90%\" />\n</div>\n\n### tree unflatten\n\n| module    | nodes | optree (\u03bcs) | jax xla (\u03bcs) | pytorch (\u03bcs) | dm-tree (\u03bcs) | speedup (j / o) | speedup (p / o) | speedup (d / o) |\n| :-------- | ----: | ----------: | -----------: | -----------: | -----------: | --------------: | --------------: | --------------: |\n| tinymlp   |    53 |       55.13 |       152.07 |       231.94 |       940.11 |            2.76 |            4.21 |           17.05 |\n| alexnet   |   188 |      226.29 |       678.29 |       972.90 |      4195.04 |            3.00 |            4.30 |           18.54 |\n| resnet18  |   698 |      766.54 |      1953.26 |      3137.86 |     12049.88 |            2.55 |            4.09 |           15.72 |\n| resnet34  |  1242 |     1309.22 |      3526.12 |      5759.16 |     20966.75 |            2.69 |            4.40 |           16.01 |\n| resnet50  |  1702 |     1914.96 |      5002.83 |      8369.43 |     29597.10 |            2.61 |            4.37 |           15.46 |\n| resnet101 |  3317 |     3672.61 |      9633.29 |     15683.16 |     57240.20 |            2.62 |            4.27 |           15.59 |\n| resnet152 |  4932 |     5407.58 |     13970.88 |     23074.68 |     82072.54 |            2.58 |            4.27 |           15.18 |\n| vit-h/14  |  3420 |     4013.18 |     11146.31 |     17633.07 |     66723.58 |            2.78 |            4.39 |           16.63 |\n| swin-b    |  2881 |     3595.34 |      9505.31 |     15054.88 |     57310.03 |            2.64 |            4.19 |           15.94 |\n|           |       |             |              |              |  **average** |        **2.69** |        **4.28** |       **16.23** |\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/16078332/227140674-1edc9fc5-f8db-481a-817d-a40b93c12b32.png\" width=\"90%\" />\n</div>\n\n### tree flatten with path\n\n| module    | nodes | optree (\u03bcs) | jax xla (\u03bcs) | pytorch (\u03bcs) | dm-tree (\u03bcs) | speedup (j / o) | speedup (p / o) | speedup (d / o) |\n| :-------- | ----: | ----------: | -----------: | -----------: | -----------: | --------------: | --------------: | --------------: |\n| tinymlp   |    53 |       36.49 |       543.67 |          n/a |       919.13 |           14.90 |             n/a |           25.19 |\n| alexnet   |   188 |      115.44 |      2185.21 |          n/a |      3752.11 |           18.93 |             n/a |           32.50 |\n| resnet18  |   698 |      431.84 |      7106.55 |          n/a |     12286.70 |           16.46 |             n/a |           28.45 |\n| resnet34  |  1242 |      845.61 |     13431.99 |          n/a |     22860.48 |           15.88 |             n/a |           27.03 |\n| resnet50  |  1702 |     1166.27 |     18426.52 |          n/a |     31225.05 |           15.80 |             n/a |           26.77 |\n| resnet101 |  3317 |     2312.77 |     34770.49 |          n/a |     59346.86 |           15.03 |             n/a |           25.66 |\n| resnet152 |  4932 |     3304.74 |     50557.25 |          n/a |     85847.91 |           15.30 |             n/a |           25.98 |\n| vit-h/14  |  3420 |     2235.25 |     37473.53 |          n/a |     64105.24 |           16.76 |             n/a |           28.68 |\n| swin-b    |  2881 |     1970.25 |     32205.83 |          n/a |     55177.50 |           16.35 |             n/a |           28.01 |\n|           |       |             |              |              |  **average** |       **16.16** |             n/a |       **27.59** |\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/16078332/227140719-d0040671-57f8-4dee-a0b8-02ee6d008723.png\" width=\"90%\" />\n</div>\n\n### tree copy\n\n| module    | nodes | optree (\u03bcs) | jax xla (\u03bcs) | pytorch (\u03bcs) | dm-tree (\u03bcs) | speedup (j / o) | speedup (p / o) | speedup (d / o) |\n| :-------- | ----: | ----------: | -----------: | -----------: | -----------: | --------------: | --------------: | --------------: |\n| tinymlp   |    53 |       89.81 |       232.26 |       845.20 |       981.48 |            2.59 |            9.41 |           10.93 |\n| alexnet   |   188 |      334.58 |       959.32 |      3360.46 |      4316.05 |            2.87 |           10.04 |           12.90 |\n| resnet18  |   698 |     1128.11 |      2840.71 |     11471.07 |     12297.07 |            2.52 |           10.17 |           10.90 |\n| resnet34  |  1242 |     2160.57 |      5333.10 |     20563.06 |     21901.91 |            2.47 |            9.52 |           10.14 |\n| resnet50  |  1702 |     2746.84 |      6823.88 |     29705.99 |     28927.88 |            2.48 |           10.81 |           10.53 |\n| resnet101 |  3317 |     5762.05 |     13481.45 |     56968.78 |     60115.93 |            2.34 |            9.89 |           10.43 |\n| resnet152 |  4932 |     8151.21 |     20805.61 |     81024.06 |     84079.57 |            2.55 |            9.94 |           10.31 |\n| vit-h/14  |  3420 |     5963.61 |     15665.91 |     59813.52 |     68377.82 |            2.63 |           10.03 |           11.47 |\n| swin-b    |  2881 |     5401.59 |     14255.33 |     53361.77 |     62317.07 |            2.64 |            9.88 |           11.54 |\n|           |       |             |              |              |  **average** |        **2.56** |        **9.97** |       **11.02** |\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/16078332/227140744-d87eedf8-6fa8-44ad-9bac-7475a5a73f5e.png\" width=\"90%\" />\n</div>\n\n### tree map\n\n| module    | nodes | optree (\u03bcs) | jax xla (\u03bcs) | pytorch (\u03bcs) | dm-tree (\u03bcs) | speedup (j / o) | speedup (p / o) | speedup (d / o) |\n| :-------- | ----: | ----------: | -----------: | -----------: | -----------: | --------------: | --------------: | --------------: |\n| tinymlp   |    53 |       95.13 |       243.86 |       867.34 |      1026.99 |            2.56 |            9.12 |           10.80 |\n| alexnet   |   188 |      348.44 |       987.57 |      3398.32 |      4354.81 |            2.83 |            9.75 |           12.50 |\n| resnet18  |   698 |     1190.62 |      2982.66 |     11719.94 |     12559.01 |            2.51 |            9.84 |           10.55 |\n| resnet34  |  1242 |     2205.87 |      5417.60 |     20935.72 |     22308.51 |            2.46 |            9.49 |           10.11 |\n| resnet50  |  1702 |     3128.48 |      7579.55 |     30372.71 |     31638.67 |            2.42 |            9.71 |           10.11 |\n| resnet101 |  3317 |     6173.05 |     14846.57 |     59167.85 |     60245.42 |            2.41 |            9.58 |            9.76 |\n| resnet152 |  4932 |     8641.22 |     22000.74 |     84018.65 |     86182.21 |            2.55 |            9.72 |            9.97 |\n| vit-h/14  |  3420 |     6211.79 |     17077.49 |     59790.25 |     69763.86 |            2.75 |            9.63 |           11.23 |\n| swin-b    |  2881 |     5673.66 |     14339.69 |     53309.17 |     59764.61 |            2.53 |            9.40 |           10.53 |\n|           |       |             |              |              |  **average** |        **2.56** |        **9.58** |       **10.62** |\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/16078332/227140788-6bb37706-f441-46c8-8897-a778e8679e05.png\" width=\"90%\" />\n</div>\n\n### tree map (nargs)\n\n| module    | nodes | optree (\u03bcs) | jax xla (\u03bcs) | pytorch (\u03bcs) | dm-tree (\u03bcs) | speedup (j / o) | speedup (p / o) | speedup (d / o) |\n| :-------- | ----: | ----------: | -----------: | -----------: | -----------: | --------------: | --------------: | --------------: |\n| tinymlp   |    53 |      137.06 |       389.96 |          n/a |      3908.77 |            2.85 |             n/a |           28.52 |\n| alexnet   |   188 |      467.24 |      1496.96 |          n/a |     15395.13 |            3.20 |             n/a |           32.95 |\n| resnet18  |   698 |     1603.79 |      4534.01 |          n/a |     50323.76 |            2.83 |             n/a |           31.38 |\n| resnet34  |  1242 |     2907.64 |      8435.33 |          n/a |     90389.23 |            2.90 |             n/a |           31.09 |\n| resnet50  |  1702 |     4183.77 |     11382.51 |          n/a |    121777.01 |            2.72 |             n/a |           29.11 |\n| resnet101 |  3317 |     7721.13 |     22247.85 |          n/a |    238755.17 |            2.88 |             n/a |           30.92 |\n| resnet152 |  4932 |    11508.05 |     31429.39 |          n/a |    360257.74 |            2.73 |             n/a |           31.30 |\n| vit-h/14  |  3420 |     8294.20 |     24524.86 |          n/a |    270514.87 |            2.96 |             n/a |           32.61 |\n| swin-b    |  2881 |     7074.62 |     20854.80 |          n/a |    241120.41 |            2.95 |             n/a |           34.08 |\n|           |       |             |              |              |  **average** |        **2.89** |             n/a |       **31.33** |\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/16078332/227140815-754fd476-0dee-42df-a809-40c953d7aff5.png\" width=\"90%\" />\n</div>\n\n### tree map with path\n\n| module    | nodes | optree (\u03bcs) | jax xla (\u03bcs) | pytorch (\u03bcs) | dm-tree (\u03bcs) | speedup (j / o) | speedup (p / o) | speedup (d / o) |\n| :-------- | ----: | ----------: | -----------: | -----------: | -----------: | --------------: | --------------: | --------------: |\n| tinymlp   |    53 |      109.82 |       778.30 |          n/a |      2186.40 |            7.09 |             n/a |           19.91 |\n| alexnet   |   188 |      365.16 |      2939.36 |          n/a |      8355.37 |            8.05 |             n/a |           22.88 |\n| resnet18  |   698 |     1308.26 |      9529.58 |          n/a |     25758.24 |            7.28 |             n/a |           19.69 |\n| resnet34  |  1242 |     2527.21 |     18084.89 |          n/a |     45942.32 |            7.16 |             n/a |           18.18 |\n| resnet50  |  1702 |     3226.03 |     22935.53 |          n/a |     61275.34 |            7.11 |             n/a |           18.99 |\n| resnet101 |  3317 |     6663.52 |     46878.89 |          n/a |    126642.14 |            7.04 |             n/a |           19.01 |\n| resnet152 |  4932 |     9378.19 |     66136.44 |          n/a |    176981.01 |            7.05 |             n/a |           18.87 |\n| vit-h/14  |  3420 |     7033.69 |     50418.37 |          n/a |    142508.11 |            7.17 |             n/a |           20.26 |\n| swin-b    |  2881 |     6078.15 |     43173.22 |          n/a |    116612.71 |            7.10 |             n/a |           19.19 |\n|           |       |             |              |              |  **average** |        **7.23** |             n/a |       **19.66** |\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/16078332/227140830-ab8dfb6e-ea59-449e-af86-ae89897258be.png\" width=\"90%\" />\n</div>\n\n### tree map with path (nargs)\n\n| module    | nodes | optree (\u03bcs) | jax xla (\u03bcs) | pytorch (\u03bcs) | dm-tree (\u03bcs) | speedup (j / o) | speedup (p / o) | speedup (d / o) |\n| :-------- | ----: | ----------: | -----------: | -----------: | -----------: | --------------: | --------------: | --------------: |\n| tinymlp   |    53 |      146.05 |       917.00 |          n/a |      3940.61 |            6.28 |             n/a |           26.98 |\n| alexnet   |   188 |      489.27 |      3560.76 |          n/a |     15434.71 |            7.28 |             n/a |           31.55 |\n| resnet18  |   698 |     1712.79 |     11171.44 |          n/a |     50219.86 |            6.52 |             n/a |           29.32 |\n| resnet34  |  1242 |     3112.83 |     21024.58 |          n/a |     95505.71 |            6.75 |             n/a |           30.68 |\n| resnet50  |  1702 |     4220.70 |     26600.82 |          n/a |    121897.57 |            6.30 |             n/a |           28.88 |\n| resnet101 |  3317 |     8631.34 |     54372.37 |          n/a |    236555.54 |            6.30 |             n/a |           27.41 |\n| resnet152 |  4932 |    12710.49 |     77643.13 |          n/a |    353600.32 |            6.11 |             n/a |           27.82 |\n| vit-h/14  |  3420 |     8753.09 |     58712.71 |          n/a |    286365.36 |            6.71 |             n/a |           32.72 |\n| swin-b    |  2881 |     7359.29 |     50112.23 |          n/a |    228866.66 |            6.81 |             n/a |           31.10 |\n|           |       |             |              |              |  **average** |        **6.56** |             n/a |       **29.61** |\n\n<div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/16078332/227140850-bd3744aa-363d-46a7-9e92-4279d14d9be6.png\" width=\"90%\" />\n</div>\n\n--------------------------------------------------------------------------------\n\n## changelog\n\nsee [changelog.md](https://github.com/metaopt/optree/blob/head/changelog.md).\n\n--------------------------------------------------------------------------------\n\n## license\n\noptree is released under the apache license 2.0.\n\noptree is heavily based on jax's implementation of the pytree utility, with deep refactoring and several improvements.\nthe original licenses can be found at [jax's apache license 2.0](https://github.com/google/jax/blob/head/license) and [tensorflow's apache license 2.0](https://github.com/tensorflow/tensorflow/blob/head/license).\n",
  "docs_url": null,
  "keywords": "pytree,tree manipulation,tree traversal,functional programming",
  "license": "apache license, version 2.0",
  "name": "optree",
  "package_url": "https://pypi.org/project/optree/",
  "project_url": "https://pypi.org/project/optree/",
  "project_urls": {
    "Bug Report": "https://github.com/metaopt/optree/issues",
    "Documentation": "https://optree.readthedocs.io",
    "Homepage": "https://github.com/metaopt/optree",
    "Repository": "https://github.com/metaopt/optree"
  },
  "release_url": "https://pypi.org/project/optree/0.10.0/",
  "requires_dist": [
    "typing-extensions >=4.0.0",
    "jax[cpu] <0.5.0a0,>=0.4.6 ; extra == 'benchmark'",
    "torch <2.1.0a0,>=2.0 ; extra == 'benchmark'",
    "torchvision ; extra == 'benchmark'",
    "dm-tree <0.2.0a0,>=0.1 ; extra == 'benchmark'",
    "pandas ; extra == 'benchmark'",
    "tabulate ; extra == 'benchmark'",
    "termcolor ; extra == 'benchmark'",
    "sphinx >=5.2.1 ; extra == 'docs'",
    "sphinx-autoapi ; extra == 'docs'",
    "sphinx-autobuild ; extra == 'docs'",
    "sphinx-copybutton ; extra == 'docs'",
    "sphinx-rtd-theme ; extra == 'docs'",
    "sphinxcontrib-bibtex ; extra == 'docs'",
    "sphinx-autodoc-typehints >=1.19.2 ; extra == 'docs'",
    "docutils ; extra == 'docs'",
    "jax[cpu] ; extra == 'docs'",
    "numpy ; extra == 'docs'",
    "torch ; extra == 'docs'",
    "jax ; extra == 'jax'",
    "isort >=5.11.0 ; extra == 'lint'",
    "black >=22.6.0 ; extra == 'lint'",
    "pylint[spelling] >=2.15.0 ; extra == 'lint'",
    "mypy >=0.990 ; extra == 'lint'",
    "flake8 ; extra == 'lint'",
    "flake8-bugbear ; extra == 'lint'",
    "flake8-comprehensions ; extra == 'lint'",
    "flake8-docstrings ; extra == 'lint'",
    "flake8-pyi ; extra == 'lint'",
    "flake8-simplify ; extra == 'lint'",
    "ruff ; extra == 'lint'",
    "doc8 <1.0.0a0 ; extra == 'lint'",
    "pydocstyle ; extra == 'lint'",
    "pyenchant ; extra == 'lint'",
    "xdoctest ; extra == 'lint'",
    "cpplint ; extra == 'lint'",
    "pre-commit ; extra == 'lint'",
    "numpy ; extra == 'numpy'",
    "pytest ; extra == 'test'",
    "pytest-cov ; extra == 'test'",
    "pytest-xdist ; extra == 'test'",
    "torch ; extra == 'torch'"
  ],
  "requires_python": ">=3.7",
  "summary": "optimized pytree utilities.",
  "version": "0.10.0",
  "releases": [],
  "developers": [
    "jieren9806@gmail.com",
    "optree_contributors",
    "xuehaipan@pku.edu.cn"
  ],
  "kwds": "optree pytreespec pytree pytrees tree_structure",
  "license_kwds": "apache license, version 2.0",
  "libtype": "pypi",
  "id": "pypi_optree",
  "homepage": "",
  "release_count": 15,
  "dependency_ids": [
    "pypi_black",
    "pypi_cpplint",
    "pypi_dm_tree",
    "pypi_doc8",
    "pypi_docutils",
    "pypi_flake8",
    "pypi_flake8_bugbear",
    "pypi_flake8_comprehensions",
    "pypi_flake8_docstrings",
    "pypi_flake8_pyi",
    "pypi_flake8_simplify",
    "pypi_isort",
    "pypi_jax",
    "pypi_mypy",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_pre_commit",
    "pypi_pydocstyle",
    "pypi_pyenchant",
    "pypi_pylint",
    "pypi_pytest",
    "pypi_pytest_cov",
    "pypi_pytest_xdist",
    "pypi_ruff",
    "pypi_sphinx",
    "pypi_sphinx_autoapi",
    "pypi_sphinx_autobuild",
    "pypi_sphinx_autodoc_typehints",
    "pypi_sphinx_copybutton",
    "pypi_sphinx_rtd_theme",
    "pypi_sphinxcontrib_bibtex",
    "pypi_tabulate",
    "pypi_termcolor",
    "pypi_torch",
    "pypi_torchvision",
    "pypi_typing_extensions",
    "pypi_xdoctest"
  ]
}