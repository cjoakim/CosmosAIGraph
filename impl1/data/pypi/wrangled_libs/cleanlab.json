{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "intended audience :: education",
    "intended audience :: information technology",
    "intended audience :: science/research",
    "license :: osi approved :: gnu affero general public license v3 or later (agplv3+)",
    "natural language :: english",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: scientific/engineering :: mathematics",
    "topic :: software development",
    "topic :: software development :: libraries",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_open_source_transparent_optimized_size.png\" width=60% height=60%>\n</p>\n\n\ncleanlab helps you **clean** data and **lab**els by automatically detecting issues in a ml dataset. to facilitate **machine learning with messy, real-world data**, this data-centric ai package uses your *existing* models to estimate dataset problems that can be fixed to train even *better* models.\n\n```python\n\n# cleanlab works with **any classifier**. yup, you can use pytorch/tensorflow/openai/xgboost/etc.\ncl = cleanlab.classification.cleanlearning(sklearn.yourfavoriteclassifier())\n\n# cleanlab finds data and label issues in **any dataset**... in one line of code!\nlabel_issues = cl.find_label_issues(data, labels)\n\n# cleanlab trains a robust version of your model that works more reliably with noisy data.\ncl.fit(data, labels)\n\n# cleanlab estimates the predictions you would have gotten if you had trained with *no* label issues.\ncl.predict(test_data)\n\n# a universal data-centric ai tool, cleanlab quantifies class-level issues and overall data quality, for any dataset.\ncleanlab.dataset.health_summary(labels, confident_joint=cl.confident_joint)\n```\n\nget started with: [tutorials](https://docs.cleanlab.ai/stable/tutorials/image.html), [documentation](https://docs.cleanlab.ai/), [examples](https://github.com/cleanlab/examples), and [blogs](https://cleanlab.ai/blog/).\n\n - learn to run cleanlab on your data in 5 minutes for: [image](https://docs.cleanlab.ai/stable/tutorials/datalab/image.html), [text](https://docs.cleanlab.ai/stable/tutorials/datalab/text.html), [audio](https://docs.cleanlab.ai/stable/tutorials/audio.html), or [tabular](https://docs.cleanlab.ai/stable/tutorials/datalab/tabular.html) data.\n- use cleanlab to automatically: [detect data issues (outliers, duplicates, label errors, etc)](https://docs.cleanlab.ai/stable/tutorials/datalab/datalab_quickstart.html), [train robust models](https://docs.cleanlab.ai/stable/tutorials/indepth_overview.html), [infer consensus + annotator-quality for multi-annotator data](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html), [suggest data to (re)label next (active learning)](https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb). \n\n\n[![pypi](https://img.shields.io/pypi/v/cleanlab.svg)](https://pypi.org/pypi/cleanlab/)\n[![os](https://img.shields.io/badge/platform-noarch-lightgrey)](https://pypi.org/pypi/cleanlab/)\n[![py\\_versions](https://img.shields.io/badge/python-3.7%2b-blue)](https://pypi.org/pypi/cleanlab/)\n[![build\\_status](https://github.com/cleanlab/cleanlab/workflows/ci/badge.svg)](https://github.com/cleanlab/cleanlab/actions?query=workflow%3aci)\n[![coverage](https://codecov.io/gh/cleanlab/cleanlab/branch/master/graph/badge.svg)](https://app.codecov.io/gh/cleanlab/cleanlab)\n[![docs](https://img.shields.io/static/v1?logo=github&style=flat&color=pink&label=docs&message=cleanlab)](https://docs.cleanlab.ai/)\n[![slack community](https://img.shields.io/static/v1?logo=slack&style=flat&color=white&label=slack&message=community)](https://cleanlab.ai/slack)\n[![twitter](https://img.shields.io/twitter/follow/cleanlabai?style=social)](https://twitter.com/cleanlabai)\n[![cleanlab studio](https://raw.githubusercontent.com/cleanlab/assets/master/shields/cl-studio-shield.svg)](https://cleanlab.ai/studio/?utm_source=github&utm_medium=readme&utm_campaign=clostostudio)\n\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/datalab_issues.png\" width=74% height=74%>\n</p>\n<p align=\"center\">\n    examples of various issues in cat/dog dataset <b>automatically detected</b> by cleanlab via this code:    \n</p>\n\n```python\n        lab = cleanlab.datalab(data=dataset, label=\"column_name_for_labels\")\n        # fit any ml model, get its feature_embeddings & pred_probs for your data\n        lab.find_issues(features=feature_embeddings, pred_probs=pred_probs)\n        lab.report()\n```\n\n## so fresh, so cleanlab\n\ncleanlab **clean**s your data's **lab**els via state-of-the-art *confident learning* algorithms, published in this [paper](https://jair.org/index.php/jair/article/view/12125) and [blog](https://l7.curtisnorthcutt.com/confident-learning). see some of the datasets cleaned with cleanlab at [labelerrors.com](https://labelerrors.com). this data-centric ai tool helps you find data and label issues, so you can train reliable ml models.\n\ncleanlab is:\n\n1. **backed by theory** -- with [provable guarantees](https://arxiv.org/abs/1911.00068) of exact label noise estimation, even with imperfect models.\n2. **fast** -- code is parallelized and scalable.\n4. **easy to use** -- one line of code to find mislabeled data, bad annotators, outliers, or train noise-robust models.\n6. **general** -- works with **[any dataset](https://labelerrors.com/)** (text, image, tabular, audio,...) + **any model** (pytorch, openai, xgboost,...)\n<br/>\n\n![](https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/label-errors-examples.png)\n<p align=\"center\">\nexamples of incorrect given labels in various image datasets <a href=\"https://l7.curtisnorthcutt.com/label-errors\">found and corrected</a> using cleanlab.\n</p>\n\n## run cleanlab\n\ncleanlab supports linux, macos, and windows and runs on python 3.7+.\n\n- get started [here](https://docs.cleanlab.ai/)! install via `pip` or `conda` as described [here](https://docs.cleanlab.ai/).\n- developers who install the bleeding-edge from source should refer to [this master branch documentation](https://docs.cleanlab.ai/master/index.html).\n- for help, check out our detailed [faq](https://docs.cleanlab.ai/stable/tutorials/faq.html), [github issues](https://github.com/cleanlab/cleanlab/issues?q=is%3aissue), or [slack](https://cleanlab.ai/slack). we welcome any questions!\n\n**practicing data-centric ai can look like this:**\n1. train initial ml model on original dataset.\n2. utilize this model to diagnose data issues (via cleanlab methods) and improve the dataset.\n3. train the same model on the improved dataset. \n4. try various modeling techniques to further improve performance.\n\nmost folks jump from step 1 \u2192 4, but you may achieve big gains without *any* change to your modeling code by using cleanlab!\ncontinuously boost performance by iterating steps 2 \u2192 4 (and try to evaluate\u00a0with *cleaned* data).\n\n![](https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/dcai_flowchart.png)\n\n\n## use cleanlab with any model for most ml tasks\n\nall features of cleanlab work with **any dataset** and **any model**. yes, any model: pytorch, tensorflow, keras, jax, huggingface, openai, xgboost, scikit-learn, etc.\nif you use a sklearn-compatible classifier, all cleanlab methods work out-of-the-box.\n\n<details><summary>\nit\u2019s also easy to use your favorite non-sklearn-compatible model (<b>click to learn more</b>)\n</summary>\n<br/>\n\ncleanlab can find label issues from any model's predicted class probabilities if you can produce them yourself.\n\nsome cleanlab functionality may require your model to be sklearn-compatible.\nthere's nothing you need to do if your model already has `.fit()`, `.predict()`, and `.predict_proba()` methods.\notherwise, just wrap your custom model into a python class that inherits the `sklearn.base.baseestimator`:\n\n``` python\nfrom sklearn.base import baseestimator\nclass yourfavoritemodel(baseestimator): # inherits sklearn base classifier\n    def __init__(self, ):\n        pass  # ensure this re-initializes parameters for neural net models\n    def fit(self, x, y, sample_weight=none):\n        pass\n    def predict(self, x):\n        pass\n    def predict_proba(self, x):\n        pass\n    def score(self, x, y, sample_weight=none):\n        pass\n```\n\nthis inheritance allows to apply a wide range of sklearn functionality like hyperparameter-optimization to your custom model.\nnow you can use your model with every method in cleanlab. here's one example:\n\n``` python\nfrom cleanlab.classification import cleanlearning\ncl = cleanlearning(clf=yourfavoritemodel())  # has all the same methods of yourfavoritemodel\ncl.fit(train_data, train_labels_with_errors)\ncl.predict(test_data)\n```\n\n#### want to see a working example? [here\u2019s a compliant pytorch mnist cnn class](https://github.com/cleanlab/cleanlab/blob/master/cleanlab/experimental/mnist_pytorch.py)\n\nmore details are provided in documentation of [cleanlab.classification.cleanlearning](https://docs.cleanlab.ai/stable/cleanlab/classification.html).\n\nnote, some libraries exist to give you sklearn-compatibility for free. for pytorch, check out the [skorch](https://skorch.readthedocs.io/) python library which will wrap your pytorch model into a sklearn-compatible model ([example](https://docs.cleanlab.ai/stable/tutorials/image.html)). for tensorflow/keras, check out our [keras wrapper](https://docs.cleanlab.ai/stable/cleanlab/models/keras.html). many libraries also already offer a special scikit-learn api, for example: [xgboost](https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.sklearn) or [lightgbm](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.lgbmclassifier.html).\n\n<br/>\n</details>\n\ncleanlab is useful across a wide variety of machine learning tasks. specific tasks this data-centric ai solution offers dedicated functionality for include:\n1. [binary and multi-class classification](https://docs.cleanlab.ai/stable/tutorials/indepth_overview.html)\n2. [multi-label classification](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html) (e.g. image/document tagging)\n3. [token classification](https://docs.cleanlab.ai/stable/tutorials/token_classification.html) (e.g. entity recognition in text)\n4. [regression](https://docs.cleanlab.ai/stable/tutorials/regression.html) (predicting numerical column in a dataset)\n5. [image segmentation](https://docs.cleanlab.ai/stable/tutorials/segmentation.html) (images with per-pixel annotations)\n6. [object detection](https://docs.cleanlab.ai/stable/tutorials/object_detection.html) (images with bounding box annotations)\n7. [classification with data labeled by multiple annotators](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html)\n8. [active learning with multiple annotators](https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb) (suggest which data to label or re-label to improve model most)\n9. [outlier detection](https://docs.cleanlab.ai/stable/tutorials/outliers.html) (identify atypical data that appears out of distribution)\n\nfor other ml tasks, cleanlab can still help you improve your dataset if appropriately applied.\nmany practical applications are demonstrated in our [example notebooks](https://github.com/cleanlab/examples).\n\n\n## citation and related publications\n\ncleanlab is based on peer-reviewed research. here are relevant papers to cite if you use this package:\n\n<details><summary><a href=\"https://arxiv.org/abs/1911.00068\">confident learning (jair '21)</a> (<b>click to show bibtex</b>) </summary>\n\n    @article{northcutt2021confidentlearning,\n        title={confident learning: estimating uncertainty in dataset labels},\n        author={curtis g. northcutt and lu jiang and isaac l. chuang},\n        journal={journal of artificial intelligence research (jair)},\n        volume={70},\n        pages={1373--1411},\n        year={2021}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/1705.01936\">rank pruning (uai '17)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{northcutt2017rankpruning,\n        author={northcutt, curtis g. and wu, tailin and chuang, isaac l.},\n        title={learning with confident examples: rank pruning for robust classification with noisy labels},\n        booktitle = {proceedings of the thirty-third conference on uncertainty in artificial intelligence},\n        series = {uai'17},\n        year = {2017},\n        location = {sydney, australia},\n        numpages = {10},\n        url = {http://auai.org/uai2017/proceedings/papers/35.pdf},\n        publisher = {auai press},\n    }\n\n</details>\n\n<details><summary><a href=\"https://people.csail.mit.edu/jonasmueller/info/labelquality_icml.pdf\"> label quality scoring (icml '22)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{kuan2022labelquality,\n        title={model-agnostic label quality scoring to detect real-world label errors},\n        author={kuan, johnson and mueller, jonas},\n        booktitle={icml dataperf workshop},\n        year={2022}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2207.03061\"> out-of-distribution detection (icml '22)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{kuan2022ood,\n        title={back to the basics: revisiting out-of-distribution detection baselines},\n        author={kuan, johnson and mueller, jonas},\n        booktitle={icml workshop on principles of distribution shift},\n        year={2022}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2210.03920\"> token classification label errors (neurips '22)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{wang2022tokenerrors,\n        title={detecting label errors in token classification data},\n        author={wang, wei-chen and mueller, jonas},\n        booktitle={neurips workshop on interactive learning for natural language processing (internlp)},\n        year={2022}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2210.06812\"> crowdlab for data with multiple annotators (neurips '22)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{goh2022crowdlab,\n        title={crowdlab: supervised learning to infer consensus labels and quality scores for data with multiple annotators},\n        author={goh, hui wen and tkachenko, ulyana and mueller, jonas},\n        booktitle={neurips human in the loop learning workshop},\n        year={2022}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2301.11856\"> activelab: active learning with data re-labeling (iclr '23)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{goh2023activelab,\n        title={activelab: active learning with re-labeling by multiple annotators},\n        author={goh, hui wen and mueller, jonas},\n        booktitle={iclr workshop on trustworthy ml},\n        year={2023}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2211.13895\"> incorrect annotations in multi-label classification (iclr '23)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{thyagarajan2023multilabel,\n        title={identifying incorrect annotations in multi-label classification data},\n        author={thyagarajan, aditya and snorrason, el\u00edas and northcutt, curtis and mueller, jonas},\n        booktitle={iclr workshop on trustworthy ml},\n        year={2023}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2305.15696\"> detecting dataset drift and non-iid sampling (icml '23)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{cummings2023drift,\n        title={detecting dataset drift and non-iid sampling via k-nearest neighbors},\n        author={cummings, jesse and snorrason, el\u00edas and mueller, jonas},\n        booktitle={icml workshop on data-centric machine learning research},\n        year={2023}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2305.16583\"> detecting errors in numerical data (icml '23)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{zhou2023errors,\n        title={detecting errors in numerical data via any regression model},\n        author={zhou, hang and mueller, jonas and kumar, mayank and wang, jane-ling and lei, jing},\n        booktitle={icml workshop on data-centric machine learning research},\n        year={2023}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2309.00832\"> objectlab: mislabeled images in object detection data (icml '23)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{tkachenko2023objectlab,\n        title={objectlab: automated diagnosis of mislabeled images in object detection data},\n        author={tkachenko, ulyana and thyagarajan, aditya and mueller, jonas},\n        booktitle={icml workshop on data-centric machine learning research},\n        year={2023}\n    }\n\n</details>\n\n<details><summary><a href=\"https://arxiv.org/abs/2307.05080\"> label errors in segmentation data (icml '23)</a> (<b>click to show bibtex</b>) </summary>\n\n    @inproceedings{lad2023segmentation,\n        title={estimating label quality and errors in semantic segmentation data via any model},\n        author={lad, vedang and mueller, jonas},\n        booktitle={icml workshop on data-centric machine learning research},\n        year={2023}\n    }\n\n</details>\n\nto understand/cite other cleanlab functionality not described above, check out our [additional publications](https://cleanlab.ai/research/).\n\n\n## other resources\n\n- [example notebooks demonstrating practical applications of this package](https://github.com/cleanlab/examples)\n\n- [cleanlab blog](https://cleanlab.ai/blog/)\n\n- [blog post: introduction to confident learning](https://l7.curtisnorthcutt.com/confident-learning)\n\n- [neurips 2021 paper: pervasive label errors in test sets destabilize machine learning benchmarks](https://arxiv.org/abs/2103.14749)\n\n- [introduction to data-centric ai (mit iap course 2023)](https://dcai.csail.mit.edu/)\n\n- [release notes for past versions](https://github.com/cleanlab/cleanlab/releases)\n\n- [cleanlab studio](https://cleanlab.ai/studio/?utm_source=github&utm_medium=readme&utm_campaign=clostostudio): *no-code data improvement*\n\nwhile this open-source library **finds** data issues, its utility depends on you having a decent existing ml model and an interface to efficiently **fix** these issues in your dataset. providing all these pieces, [cleanlab studio](https://cleanlab.ai/studio/?utm_source=github&utm_medium=readme&utm_campaign=clostostudio) is a no-code platform to **find and fix** problems in real-world ml datasets. cleanlab studio [automatically runs](https://cleanlab.ai/blog/data-centric-ai/) optimized versions of the algorithms from this open-source library on top of automl & foundation models fit to your data, and presents detected issues in a smart data editing interface. it's a data cleaning assistant to quickly turn unreliable data into reliable models/insights (via ai/automation + streamlined ux). [try it for free!](https://cleanlab.ai/signup)\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/studio.png\" width=80% height=80% alt=\"cleanlab studio logo\">\n</p>\n\n## join our community\n\n* the best place to learn is [our slack community](https://cleanlab.ai/slack).\n\n* have ideas for the future of cleanlab? how are you using cleanlab? [join the discussion](https://github.com/cleanlab/cleanlab/discussions) and check out [our active/planned projects and what we could use your help with](https://github.com/cleanlab/cleanlab/projects).\n\n* interested in contributing? see the [contributing guide](contributing.md) and [ideas on useful contributions](https://github.com/cleanlab/cleanlab/wiki#ideas-for-contributing-to-cleanlab). we welcome your help building a standard open-source platform for data-centric ai!\n\n* have code improvements for cleanlab? see the [development guide](development.md).\n\n* have an issue with cleanlab? search [our faq](https://docs.cleanlab.ai/stable/tutorials/faq.html) and [existing issues](https://github.com/cleanlab/cleanlab/issues?q=is%3aissue), or [submit a new issue](https://github.com/cleanlab/cleanlab/issues/new).\n\n* need professional help with cleanlab?\njoin our [\\#help slack channel](https://cleanlab.ai/slack) and message us there, or reach out via email: team@cleanlab.ai\n\n## license\n\ncopyright (c) 2017 cleanlab inc.\n\ncleanlab is free software: you can redistribute it and/or modify it under the terms of the gnu affero general public license as published by the free software foundation, either version 3 of the license, or (at your option) any later version.\n\ncleanlab is distributed in the hope that it will be useful, but without any warranty; without even the implied warranty of merchantability or fitness for a particular purpose.\n\nsee [gnu affero general public license](https://github.com/cleanlab/cleanlab/blob/master/license) for details.\nyou can email us to discuss licensing: team@cleanlab.ai\n\n### commercial licensing\n\ncommercial licensing is available for teams and enterprises that want to use cleanlab in production workflows, but are unable to open-source their code [as is required by the current license](https://github.com/cleanlab/cleanlab/blob/master/license). please email us: team@cleanlab.ai\n",
  "docs_url": null,
  "keywords": "machine_learning data_cleaning confident_learning classification weak_supervision learning_with_noisy_labels unsupervised_learning datacentric_ai,datacentric",
  "license": "agplv3+",
  "name": "cleanlab",
  "package_url": "https://pypi.org/project/cleanlab/",
  "project_url": "https://pypi.org/project/cleanlab/",
  "project_urls": {
    "Bug Tracker": "https://github.com/cleanlab/cleanlab/issues",
    "Documentation": "https://docs.cleanlab.ai",
    "Homepage": "https://cleanlab.ai",
    "Source Code": "https://github.com/cleanlab/cleanlab"
  },
  "release_url": "https://pypi.org/project/cleanlab/2.5.0/",
  "requires_dist": [
    "numpy >=1.20.0",
    "scikit-learn >=1.0",
    "tqdm >=4.53.0",
    "pandas >=1.1.5",
    "termcolor >=2.0.0",
    "matplotlib >=3.5.1 ; extra == 'all'",
    "datasets >=2.7.0 ; extra == 'all'",
    "cleanvision >=0.3.2 ; extra == 'all'",
    "datasets >=2.7.0 ; extra == 'datalab'",
    "datasets >=2.7.0 ; extra == 'image'",
    "cleanvision >=0.3.2 ; extra == 'image'"
  ],
  "requires_python": ">=3.7",
  "summary": "the standard package for data-centric ai, machine learning with label errors, and automatically finding and fixing dataset issues in python.",
  "version": "2.5.0",
  "releases": [],
  "developers": [
    "cleanlab_inc",
    "team@cleanlab.ai"
  ],
  "kwds": "cleanlearning cleanlab learning_with_noisy_labels datacentric_ai cleanlabai",
  "license_kwds": "agplv3+",
  "libtype": "pypi",
  "id": "pypi_cleanlab",
  "homepage": "https://cleanlab.ai",
  "release_count": 24,
  "dependency_ids": [
    "pypi_cleanvision",
    "pypi_datasets",
    "pypi_matplotlib",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_scikit_learn",
    "pypi_termcolor",
    "pypi_tqdm"
  ]
}