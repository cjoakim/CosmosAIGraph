{
  "classifiers": [
    "development status :: 4 - beta",
    "environment :: console",
    "intended audience :: developers",
    "intended audience :: science/research",
    "license :: osi approved :: apache software license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "# optax\n\n![ci status](https://github.com/deepmind/optax/workflows/tests/badge.svg)\n[![documentation status](https://readthedocs.org/projects/optax/badge/?version=latest)](http://optax.readthedocs.io)\n![pypi](https://img.shields.io/pypi/v/optax)\n\n## introduction\n\noptax is a gradient processing and optimization library for jax.\n\noptax is designed to facilitate research by providing building blocks\nthat can be easily recombined in custom ways.\n\nour goals are to\n\n*   provide simple, well-tested, efficient implementations of core components.\n*   improve research productivity by enabling to easily combine low level\n    ingredients into custom optimisers (or other gradient processing components).\n*   accelerate adoption of new ideas by making it easy for anyone to contribute.\n\nwe favour focusing on small composable building blocks that can be effectively\ncombined into custom solutions. others may build upon these basic components\nmore complicated abstractions. whenever reasonable, implementations prioritise\nreadability and structuring code to match standard equations, over code reuse.\n\nan initial prototype of this library was made available in jax's experimental\nfolder as `jax.experimental.optix`. given the wide adoption across deepmind\nof `optix`, and after a few iterations on the api, `optix` was eventually moved\nout of `experimental` as a standalone open-source library, renamed `optax`.\n\ndocumentation on optax can be found at [optax.readthedocs.io](https://optax.readthedocs.io/).\n\n## installation\n\nyou can install the latest released version of optax from pypi via:\n\n```sh\npip install optax\n```\n\nor you can install the latest development version from github:\n\n```sh\npip install git+https://github.com/deepmind/optax.git\n```\n\n## quickstart\n\noptax contains implementations of [many popular optimizers](https://optax.readthedocs.io/en/latest/api.html#common-optimizers) and\n[loss functions](https://optax.readthedocs.io/en/latest/api.html#common-losses).\nfor example the following code snippet uses the adam optimizer from `optax.adam`\nand the mean squared error from `optax.l2_loss`. we initialize the optimizer\nstate using the `init` function and `params` of the model.\n\n```python\noptimizer = optax.adam(learning_rate)\n# obtain the `opt_state` that contains statistics for the optimizer.\nparams = {'w': jnp.ones((num_weights,))}\nopt_state = optimizer.init(params)\n```\n\nto write the update loop we need a loss function that can be differentiated by\njax (with `jax.grad` in this\nexample) to obtain the gradients.\n\n```python\ncompute_loss = lambda params, x, y: optax.l2_loss(params['w'].dot(x), y)\ngrads = jax.grad(compute_loss)(params, xs, ys)\n```\n\nthe gradients are then converted via `optimizer.update` to obtain the updates\nthat should be applied to the current params to obtain the new ones.\n`optax.apply_updates` is a convinience utility to do this.\n\n```python\nupdates, opt_state = optimizer.update(grads, opt_state)\nparams = optax.apply_updates(params, updates)\n```\n\nyou can continue the quick start in [the optax quickstart notebook.](https://github.com/deepmind/optax/blob/master/examples/quick_start.ipynb)\n\n\n## components\n\nwe refer to the [docs](https://optax.readthedocs.io/en/latest/index.html)\nfor a detailed list of available optax components. here, we highlight\nthe main categories of building blocks provided by optax.\n\n### gradient transformations ([transform.py](https://github.com/deepmind/optax/blob/master/optax/_src/transform.py))\n\none of the key building blocks of `optax` is a `gradienttransformation`.\n\neach transformation is defined two functions:\n\n*   `state = init(params)`\n*   `grads, state = update(grads, state, params=none)`\n\nthe `init` function initializes a (possibly empty) set of statistics (aka state)\nand the `update` function transforms a candidate gradient given some statistics,\nand (optionally) the current value of the parameters.\n\nfor example:\n\n```python\ntx = scale_by_rms()\nstate = tx.init(params)  # init stats\ngrads, state = tx.update(grads, state, params)  # transform & update stats.\n```\n\n### composing gradient transformations ([combine.py](https://github.com/deepmind/optax/blob/master/optax/_src/combine.py))\n\nthe fact that transformations take candidate gradients as input and return\nprocessed gradients as output (in contrast to returning the updated parameters)\nis critical to allow to combine arbitrary transformations into a custom\noptimiser / gradient processor, and also allows to combine transformations for\ndifferent gradients that operate on a shared set of variables.\n\nfor instance, `chain` combines them sequentially, and returns a\nnew `gradienttransformation` that applies several transformations in sequence.\n\nfor example:\n\n```python\nmy_optimiser = chain(\n    clip_by_global_norm(max_norm),\n    scale_by_adam(eps=1e-4),\n    scale(-learning_rate))\n```\n\n### wrapping gradient transformations ([wrappers.py](https://github.com/deepmind/optax/blob/master/optax/_src/wrappers.py))\n\noptax also provides several wrappers that take a `gradienttransformation` as\ninput and return a new `gradienttransformation` that modifies the behaviour\nof the inner transformation in a specific way.\n\nfor instance the `flatten` wrapper flattens gradients into a single large vector\nbefore applying the inner gradienttransformation. the transformed updated are\nthen unflattened before being returned to the user. this can be used to reduce\nthe overhead of performing many calculations on lots of small variables,\nat the cost of increasing memory usage.\n\nfor example:\n```python\nmy_optimiser = flatten(adam(learning_rate))\n```\n\nother examples of wrappers include accumulating gradients over multiple steps,\nor applying the inner transformation only to specific parameters or at\nspecific steps.\n\n### schedules ([schedule.py](https://github.com/deepmind/optax/blob/master/optax/_src/schedule.py))\n\nmany popular transformations use time dependent components, e.g. to anneal\nsome hyper-parameter (e.g. the learning rate). optax provides for this purpose\n`schedules` that can be used to decay scalars as a function of a `step` count.\n\nfor example you may use a polynomial schedule (with `power=1`) to decay\na hyper-parameter linearly over a number of steps:\n\n```python\nschedule_fn = polynomial_schedule(\n    init_value=1., end_value=0., power=1, transition_steps=5)\n\nfor step_count in range(6):\n  print(schedule_fn(step_count))  # [1., 0.8, 0.6, 0.4, 0.2, 0.]\n```\n\nschedules are used by certain gradient transformation, for instance:\n\n```python\nschedule_fn = polynomial_schedule(\n    init_value=-learning_rate, end_value=0., power=1, transition_steps=5)\noptimiser = chain(\n    clip_by_global_norm(max_norm),\n    scale_by_adam(eps=1e-4),\n    scale_by_schedule(schedule_fn))\n```\n\n### popular optimisers ([alias.py](https://github.com/deepmind/optax/blob/master/optax/_src/alias.py))\n\nin addition to the low level building blocks we also provide aliases for popular\noptimisers built using these components (e.g. rmsprop, adam, adamw, etc, ...).\nthese are all still instances of a `gradienttransformation`, and can therefore\nbe further combined with any of the individual building blocks.\n\nfor example:\n\n```python\ndef adamw(learning_rate, b1, b2, eps, weight_decay):\n  return chain(\n      scale_by_adam(b1=b1, b2=b2, eps=eps),\n      scale_and_decay(-learning_rate, weight_decay=weight_decay))\n```\n\n### applying updates ([update.py](https://github.com/deepmind/optax/blob/master/optax/_src/update.py))\n\nafter transforming an update using a `gradienttransformation` or any custom\nmanipulation of the update, you will typically apply the update to a set\nof parameters. this can be done trivially using `tree_map`. \n\nfor convenience, we expose an `apply_updates` function to apply updates to\nparameters. the function just adds the updates and the parameters together,\ni.e. `tree_map(lambda p, u: p + u, params, updates)`.\n\n```python\nupdates, state = tx.update(grads, state, params)  # transform & update stats.\nnew_params = optax.apply_updates(params, updates)  # update the parameters.\n```\n\nnote that separating gradient transformations from the parameter update is\ncritical to support composing sequence of transformations (e.g. `chain`), as\nwell as combine multiple updates to the same parameters (e.g. in multi-task\nsettings where different tasks need different sets of gradient transformations).\n\n### losses ([loss.py](https://github.com/deepmind/optax/blob/master/optax/_src/loss.py))\n\noptax provides a number of standard losses used in deep learning, such as\n`l2_loss`, `softmax_cross_entropy`, `cosine_distance`, etc.\n\n```python\nloss = huber_loss(predictions, targets)\n```\n\nthe losses accept batches as inputs, however they perform no reduction across\nthe batch dimension(s). this is trivial to do in jax, for example:\n\n```python\navg_loss = jnp.mean(huber_loss(predictions, targets))\nsum_loss = jnp.sum(huber_loss(predictions, targets))\n```\n\n### second order ([second_order.py](https://github.com/deepmind/optax/blob/master/optax/_src/second_order.py))\n\ncomputing the hessian or fisher information matrices for neural networks is\ntypically intractable due to the quadratic memory requirements. solving for the\ndiagonals of these matrices is often a better solution. the library offers\nfunctions for computing these diagonals with sub-quadratic memory requirements.\n\n### stochastic gradient estimators ([stochastic_gradient_estimators.py](https://github.com/deepmind/optax/blob/master/optax/_src/stochastic_gradient_estimators.py))\n\nstochastic gradient estimators compute monte carlo estimates of gradients of\nthe expectation of a function under a distribution with respect to the\ndistribution's parameters.\n\nunbiased estimators, such as the score function estimator (reinforce),\npathwise estimator (reparameterization trick) or measure valued estimator,\nare implemented: `score_function_jacobians`, `pathwise_jacobians` and `\nmeasure_valued_jacobians`. their applicability (both in terms of functions and\ndistributions) is discussed in their respective documentation.\n\nstochastic gradient estimators can be combined with common control variates for\nvariance reduction via `control_variates_jacobians`. for provided control\nvariates see `delta` and `moving_avg_baseline`.\n\nthe result of a gradient estimator or `control_variates_jacobians` contains the\njacobians of the function with respect to the samples from the input\ndistribution. these can then be used to update distributional parameters, or\nto assess gradient variance.\n\nexample of how to use the `pathwise_jacobians` estimator:\n\n```python\ndist_params = [mean, log_scale]\nfunction = lambda x: jnp.sum(x * weights)\njacobians = pathwise_jacobians(\n      function, dist_params,\n      utils.multi_normal, rng, num_samples)\n\nmean_grads = jnp.mean(jacobians[0], axis=0)\nlog_scale_grads = jnp.mean(jacobians[1], axis=0)\ngrads = [mean_grads, log_scale_grads]\noptim_update, optim_state = optim.update(grads, optim_state)\nupdated_dist_params = optax.apply_updates(dist_params, optim_update)\n```\n\nwhere `optim` is an optax optimizer.\n\n## citing optax\n\noptax is part of the [deepmind jax ecosystem], to cite optax please use\nthe [deepmind jax ecosystem citation].\n\n[deepmind jax ecosystem]: https://deepmind.com/blog/article/using-jax-to-accelerate-our-research \"deepmind jax ecosystem\"\n[deepmind jax ecosystem citation]: https://github.com/deepmind/jax/blob/main/deepmind2020jax.txt \"citation\"\n\n",
  "docs_url": null,
  "keywords": "python,machine learning,reinforcement-learning",
  "license": "",
  "name": "optax",
  "package_url": "https://pypi.org/project/optax/",
  "project_url": "https://pypi.org/project/optax/",
  "project_urls": {
    "documentation": "https://optax.readthedocs.io/",
    "homepage": "https://github.com/deepmind/optax",
    "repository": "https://github.com/deepmind/optax"
  },
  "release_url": "https://pypi.org/project/optax/0.1.7/",
  "requires_dist": [
    "absl-py>=0.7.1",
    "chex>=0.1.5",
    "jax>=0.1.55",
    "jaxlib>=0.1.37",
    "numpy>=1.18.0",
    "sphinx==4.5.0 ; extra == \"docs\"",
    "sphinx-book-theme==0.3.3 ; extra == \"docs\"",
    "sphinxcontrib-katex==0.9.0 ; extra == \"docs\"",
    "sphinxcontrib-bibtex==2.4.2 ; extra == \"docs\"",
    "sphinx-autodoc-typehints==1.11.1 ; extra == \"docs\"",
    "IPython==7.16.3 ; extra == \"docs\"",
    "ipykernel==5.3.4 ; extra == \"docs\"",
    "pandoc==1.0.2 ; extra == \"docs\"",
    "myst_nb==0.13.1 ; extra == \"docs\"",
    "docutils==0.16 ; extra == \"docs\"",
    "matplotlib==3.5.0 ; extra == \"docs\"",
    "dm-haiku==0.0.8 ; extra == \"docs\"",
    "absl-py>=1.0.0 ; extra == \"dp-accounting\"",
    "attrs>=21.4.0 ; extra == \"dp-accounting\"",
    "mpmath>=1.2.1 ; extra == \"dp-accounting\"",
    "numpy>=1.21.4 ; extra == \"dp-accounting\"",
    "scipy>=1.7.1 ; extra == \"dp-accounting\"",
    "dm-haiku>=0.0.3 ; extra == \"examples\"",
    "tensorflow-datasets>=4.2.0 ; extra == \"examples\"",
    "tensorflow>=2.4.0 ; extra == \"examples\"",
    "dm-haiku>=0.0.3 ; extra == \"test\"",
    "dm-tree>=0.1.7 ; extra == \"test\"",
    "flax==0.5.3 ; extra == \"test\""
  ],
  "requires_python": ">=3.8",
  "summary": "a gradient processing and optimisation library in jax.",
  "version": "0.1.7",
  "releases": [],
  "developers": [
    "optax-dev@google.com"
  ],
  "kwds": "optimizers optimisers optimiser optimisation optimizer",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_optax",
  "homepage": "",
  "release_count": 15,
  "dependency_ids": [
    "pypi_absl_py",
    "pypi_attrs",
    "pypi_chex",
    "pypi_dm_haiku",
    "pypi_dm_tree",
    "pypi_docutils",
    "pypi_flax",
    "pypi_ipykernel",
    "pypi_ipython",
    "pypi_jax",
    "pypi_jaxlib",
    "pypi_matplotlib",
    "pypi_mpmath",
    "pypi_myst_nb",
    "pypi_numpy",
    "pypi_pandoc",
    "pypi_scipy",
    "pypi_sphinx",
    "pypi_sphinx_autodoc_typehints",
    "pypi_sphinx_book_theme",
    "pypi_sphinxcontrib_bibtex",
    "pypi_sphinxcontrib_katex",
    "pypi_tensorflow",
    "pypi_tensorflow_datasets"
  ]
}