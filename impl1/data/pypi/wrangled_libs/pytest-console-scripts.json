{
  "classifiers": [
    "development status :: 4 - beta",
    "framework :: pytest",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "programming language :: python :: implementation :: cpython",
    "programming language :: python :: implementation :: pypy",
    "topic :: software development :: testing"
  ],
  "description": "pytest-console-scripts\n======================\n\n[![pypi](https://img.shields.io/pypi/v/pytest-console-scripts)](https://pypi.org/project/pytest-console-scripts/)\n[![pypi - license](https://img.shields.io/pypi/l/pytest-console-scripts)](https://github.com/kvas-it/pytest-console-scripts/blob/master/license)\n[![github workflow status](https://img.shields.io/github/actions/workflow/status/kvas-it/pytest-console-scripts/test.yml)](https://github.com/kvas-it/pytest-console-scripts/actions)\n[![codecov](https://codecov.io/gh/kvas-it/pytest-console-scripts/branch/master/graph/badge.svg?token=rfelxcqvpf)](https://codecov.io/gh/kvas-it/pytest-console-scripts)\n\n[![github issues](https://img.shields.io/github/issues/kvas-it/pytest-console-scripts)](https://github.com/kvas-it/pytest-console-scripts/issues)\n[![github pull requests](https://img.shields.io/github/issues-pr/kvas-it/pytest-console-scripts)](https://github.com/kvas-it/pytest-console-scripts/pulls)\n[![github commits since latest release (by date)](https://img.shields.io/github/commits-since/kvas-it/pytest-console-scripts/latest)](https://github.com/kvas-it/pytest-console-scripts/blob/master/changelog.md)\n\npytest-console-scripts is a [pytest][1] plugin for running python scripts from\nwithin tests. it's quite similar to `subprocess.run()`, but it also has an\nin-process mode, where the scripts are executed by the interpreter that's\nrunning `pytest` (using some amount of sandboxing).\n\nin-process mode significantly reduces the run time of the test suites that\nrun many external scripts. this is speeds up development. in the ci environment\nsubprocess mode can be used to make sure the scripts also work (and behave the\nsame) when run by a fresh interpreter.\n\nrequirements\n------------\n\n- python 3.8+, or pypy3,\n- pytest 4.0 or newer.\n\ninstallation\n------------\n\nyou can install \"pytest-console-scripts\" via [pip][2] from [pypi][3]:\n\n```sh\n$ pip install pytest-console-scripts\n```\n\nnormally you would add it as a test dependency in `tox.ini` (see [tox\ndocumentation][9]).\n\nusage\n-----\n\nthis plugin will run scripts that are installed via `console_scripts` entry\npoint in `setup.py`, python files in current directory (or anywhere else, if\ngiven the path), and python scripts anywhere else in the path. it will also run\nexecutables that are not python scripts, but only in subprocess mode (there's\nno benefit in using `pytest-console-scripts` for this, you should just use\n`subprocess.run`).\n\nhere's an example with `console_scripts` entry point. imagine we have a python\npackage `foo` with the following `setup.py`:\n\n```py\nsetup(\n    name='foo',\n    version='0.0.1',\n    py_modules=['foo'],\n    entry_points={\n        'console_scripts': ['foobar=foo:bar']\n    },\n)\n```\n\nwe could use pytest-console-scripts to test the `foobar` script:\n\n```py\ndef test_foo_bar(script_runner):\n    result = script_runner.run(['foobar', '--version'])\n    assert result.returncode == 0\n    assert result.stdout == '3.2.1\\n'\n    assert result.stderr == ''\n\n    script_runner.run('foobar --version', shell=true, check=true)\n```\n\nthis would use the `script_runner` fixture provided by the plugin to\nrun the script and capture its output.\n\nthe arguments of `script_runner.run` are the command name of the script and\nany command line arguments that should be passed to it. additionally the\nfollowing keyword arguments can be used:\n\n- `cwd` - set the working directory of the script under test.\n- `env` - a dictionary with environment variables to use instead of the current\n  environment.\n- `stdin` - a file-like object that will be piped to standard input of the\n  script.\n- `check` - raises an exception if `returncode != 0`, defaults to false.\n- `shell` - mimic shell execution, this should work well for simple cases,\n  defaults to false.\n\ntype-hinting is also supported.\nyou may type-hint the fixture with the following code:\n\n```py\nfrom pytest_console_scripts import scriptrunner\n\ndef test_foo_bar(script_runner: scriptrunner) -> none:\n    ...\n```\n\nconfiguring script execution mode\n---------------------------------\n\nin the example above the `foobar` script would run in in-process mode (which is\nthe default). this is fast and good for quick iteration during development.\nafter we're happy with the functionality, it's time to run the script in\nsubprocess mode to simulate real invocation more closely. there are several\nways to do this. we can configure it via pytest configuration (for example in\n`tox.ini`):\n\n```ini\n[pytest]\nscript_launch_mode = subprocess\n```\n\nwe can give a command line option to pytest (this will override the\nconfiguration file):\n\n```sh\n$ pytest --script-launch-mode=subprocess test_foobar.py\n```\n\nwe can also mark individual tests to run in a specific mode:\n\n```py\n@pytest.mark.script_launch_mode('subprocess')\ndef test_foobar(script_runner):\n    ...\n```\n\nbetween these three methods the marking of the tests has priority before the\ncommand line option that in turn overrides the configuration setting. all three\ncan take three possible values: \"inprocess\", \"subprocess\", and \"both\" (which\nwill cause the test to be run twice: in in-process and in subprocess modes).\n\ninteraction with mocking\n------------------------\n\nit is possible to mock objects and functions inside of console scripts when\nthey are run using `pytest-console-scripts` but only in inprocess mode. when\nthe script is run in subprocess mode, it is executed by a separate python\ninterpreter and the test can't mock anything inside of it.\n\nanother limitation of mocking is that with simple python scripts that are not\ninstalled via [`console_scripts` entry point][14] mocking of objects inside of\nthe main script will not work. the reason for that is that when we run\n`myscript.py` with `$ python myscript.py` the script gets imported into\n`__main__` namespace instead of `myscript` namespace. our patching of\n`myscript.myfunction` will have no effect on what the code in `__main__`\nnamespace sees when it's calling `myfunction` defined in the same file.\n\nsee [this stackoverflow answer](https://stackoverflow.com/a/66693954/1595738)\nfor some ideas of how to get around this.\n\nsuppressing the printing of script run results\n----------------------------------------------\n\nwhen tests involving `pytest-console-scripts` fail, it tends to be quite\nuseful to see the output of the scripts that were executed in them. we try\nto be helpful and print it out just before returning the result from\n`script_runner.run()`. normally pytest [captures][12] all the output during a\ntest run and it's not shown to the user unless some tests fail. this is exactly\nwhat we want.\n\nhowever, in some cases it might be useful to disable the output capturing and\npytest provides [ways to do it][13]. when capturing is disabled, all test run\nresults will be printed out and this might make it harder to inspect the other\noutput of the tests. to deal with this, `pytest-console-scripts` has an option\nto disable the printing of script run results:\n\n```sh\n$ pytest --hide-run-results test_foobar.py\n```\n\nit's also possible to disable it just for one script run:\n\n```py\nresult = script_runner.run('foobar', print_result=false)\n```\n\nwhen printing of script run results is disabled, script output won't be\nvisible even when the test fails. unfortunately there's no automatic way to\nprint it only if the test fails because by the time a script run completes we\ndon't know whether the test will fail or not. it's possible to do it manually\nfrom the test by using:\n\n```py\nresult.print()\n```\n\nthis, combined with `--hide-run-results` or `print_result=false` can be used to\nonly print interesting run results when capturing is off.\n\npackage installation and testing during development\n---------------------------------------------------\n\nsince `pytest-console-scripts` relies on the scripts being located in the path,\nit can only run the console scripts from packages that have been installed (if\nyou are interested in working on removing this limitation, take a look at [this\nticket](https://github.com/kvas-it/pytest-console-scripts/issues/34) and in\nparticular [this comment](https://github.com/kvas-it/pytest-console-scripts/issues/34#issuecomment-649497564)).\nif you want to run the tests quickly during development, the additional\ninstallation step would add a significant overhead and slow you down.\n\nthere's a way around this: install your package in [development mode][10] using\n`pip install -e .`. if you use [tox][9], you can take one of its\nexisting virtualenvs (they live in `.tox/`). otherwise create a\n[virtualenv][11] just for development, activate it and run `python setup.py\ndevelop` to install your package in development mode. you will need to\nre-install every time you add a new console script, but otherwise all the\nchanges to your code will be immediately picked up by the tests.\n\ncontributing\n------------\n\ncontributions are very welcome. tests can be run with `tox`, please ensure\nthe coverage at least stays the same before you submit a pull request.\n\nlicense\n-------\n\ndistributed under the terms of the [mit][8] license, \"pytest-console-scripts\"\nis free and open source software.\n\nissues\n------\n\nif you encounter any problems, please [file an issue][7] along with a detailed\ndescription.\n\n----\n\npytest-console-scripts was initially generated with [cookiecutter][4] along\nwith [@hackebrot][5]'s [cookiecutter-pytest-plugin][6] template.\n\n[1]: https://github.com/pytest-dev/pytest\n[2]: https://pypi.python.org/pypi/pip/\n[3]: https://pypi.python.org/pypi\n[4]: https://github.com/audreyr/cookiecutter\n[5]: https://github.com/hackebrot\n[6]: https://github.com/pytest-dev/cookiecutter-pytest-plugin\n[7]: https://github.com/kvas-it/pytest-console-scripts/issues\n[8]: http://opensource.org/licenses/mit\n[9]: https://tox.readthedocs.org/en/latest/\n[10]: https://setuptools.pypa.io/en/latest/userguide/development_mode.html\n[11]: https://docs.python.org/3/library/venv.html\n[12]: https://docs.pytest.org/en/stable/capture.html\n[13]: https://docs.pytest.org/en/stable/capture.html#setting-capturing-methods-or-disabling-capturing\n[14]: https://python-packaging.readthedocs.io/en/latest/command-line-scripts.html#the-console-scripts-entry-point\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "pytest-console-scripts",
  "package_url": "https://pypi.org/project/pytest-console-scripts/",
  "project_url": "https://pypi.org/project/pytest-console-scripts/",
  "project_urls": {
    "Homepage": "https://github.com/kvas-it/pytest-console-scripts"
  },
  "release_url": "https://pypi.org/project/pytest-console-scripts/1.4.1/",
  "requires_dist": [
    "pytest (>=4.0.0)",
    "importlib-metadata (>=3.6) ; python_version < \"3.10\""
  ],
  "requires_python": ">=3.8",
  "summary": "pytest plugin for testing console scripts",
  "version": "1.4.1",
  "releases": [],
  "developers": [
    "4b796c65+github@gmail.com",
    "kvas.it@gmail.com",
    "vasily_kuznetsov"
  ],
  "kwds": "pytest_console_scripts pytest pypy3 pypi pypa",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_pytest_console_scripts",
  "homepage": "https://github.com/kvas-it/pytest-console-scripts",
  "release_count": 21,
  "dependency_ids": [
    "pypi_importlib_metadata",
    "pypi_pytest"
  ]
}