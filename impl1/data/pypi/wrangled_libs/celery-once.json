{
  "classifiers": [
    "intended audience :: developers",
    "license :: osi approved :: bsd license",
    "natural language :: english",
    "programming language :: python :: 2",
    "programming language :: python :: 2.6",
    "programming language :: python :: 2.7",
    "programming language :: python :: 3",
    "programming language :: python :: 3.3",
    "programming language :: python :: 3.4",
    "topic :: system :: distributed computing"
  ],
  "description": "celery once\n===========\n\n|build status| |coverage status|\n\ncelery once allows you to prevent multiple execution and queuing of `celery <http://www.celeryproject.org/>`_ tasks.\n\ninstallation\n============\n\ninstalling ``celery_once`` is simple with pip, just run:\n\n::\n\n    pip install -u celery_once\n\n\nrequirements\n============\n\n* `celery <http://www.celeryproject.org/>`__. built to run with celery 4.0. older versions may work, but are not officially supported.\n\nusage\n=====\n\nto use ``celery_once``, your tasks need to inherit from an `abstract <http://celery.readthedocs.org/en/latest/userguide/tasks.html#abstract-classes>`_ base task called ``queueonce``.\n\nonce installed, you'll need to configure a few options a ``once`` key in celery's conf.\n\n.. code:: python\n\n    from celery import celery\n    from celery_once import queueonce\n    from time import sleep\n\n    celery = celery('tasks', broker='amqp://guest@localhost//')\n    celery.conf.once = {\n      'backend': 'celery_once.backends.redis',\n      'settings': {\n        'url': 'redis://localhost:6379/0',\n        'default_timeout': 60 * 60\n      }\n    }\n\n    @celery.task(base=queueonce)\n    def slow_task():\n        sleep(30)\n        return \"done!\"\n\n\nthe exact configuration, depends on which locking backend you want to use. see `backends`_.\n\n\nbehind the scenes, this overrides ``apply_async`` and ``delay``. it does not affect calling the tasks directly.\n\nwhen running the task, ``celery_once`` checks that no lock is in place (against a redis key).\nif it isn't, the task will run as normal. once the task completes (or ends due to an exception) the lock will clear.\nif an attempt is made to run the task again before it completes an ``alreadyqueued`` exception will be raised.\n\n.. code-block:: python\n\n    example.delay(10)\n    example.delay(10)\n    traceback (most recent call last):\n        ..\n    alreadyqueued()\n\n.. code-block:: python\n\n    result = example.apply_async(args=(10))\n    result = example.apply_async(args=(10))\n    traceback (most recent call last):\n        ..\n    alreadyqueued()\n\n\n``graceful``\n------------\n\noptionally, instead of raising an ``alreadyqueued`` exception, the task can return ``none`` if ``once={'graceful': true}`` is set in the task's `options <http://celery.readthedocs.org/en/latest/userguide/tasks.html#list-of-options>`__ or when run through ``apply_async``.\n\n.. code:: python\n\n    from celery_once import alreadyqueued\n    # either catch the exception,\n    try:\n        example.delay(10)\n    except alreadyqueued:\n        pass\n    # or, handle it gracefully at run time.\n    result = example.apply(args=(10), once={'graceful': true})\n    # or by default.\n    @celery.task(base=queueonce, once={'graceful': true})\n    def slow_task():\n        sleep(30)\n        return \"done!\"\n\n\n``keys``\n--------\n\nby default ``celery_once`` creates a lock based on the task's name and its arguments and values.\ntake for example, the following task below...\n\n.. code:: python\n\n    @celery.task(base=queueonce)\n    def slow_add(a, b):\n        sleep(30)\n        return a + b\n\nrunning the task with different arguments will default to checking against different locks.\n\n.. code:: python\n\n    slow_add(1, 1)\n    slow_add(1, 2)\n\nif you want to specify locking based on a subset, or no arguments you can adjust the keys ``celery_once`` looks at in the task's `options <http://celery.readthedocs.org/en/latest/userguide/tasks.html#list-of-options>`_ with ``once={'keys': [..]}``\n\n.. code:: python\n\n    @celery.task(base=queueonce, once={'keys': ['a']})\n    def slow_add(a, b):\n        sleep(30)\n        return a + b\n\n    example.delay(1, 1)\n    # checks if any tasks are running with the `a=1`\n    example.delay(1, 2)\n    traceback (most recent call last):\n        ..\n    alreadyqueued()\n    example.delay(2, 2)\n\n.. code:: python\n\n    @celery.task(base=queueonce, once={'keys': []})\n    def slow_add(a, b):\n        sleep(30)\n        return a + b\n\n    # will enforce only one task can run, no matter what arguments.\n    example.delay(1, 1)\n    example.delay(2, 2)\n    traceback (most recent call last):\n        ..\n    alreadyqueued()\n\n\n``timeout``\n-----------\nas a fall back, ``celery_once`` will clear a lock after 60 minutes.\nthis is set globally in celery's configuration with ``once_default_timeout`` but can be set for individual tasks using...\n\n.. code:: python\n\n    @celery.task(base=queueonce, once={'timeout': 60 * 60 * 10})\n    def long_running_task():\n        sleep(60 * 60 * 3)\n\n\n``unlock_before_run``\n---------------------\nby default, the lock is removed after the task has executed (using celery's `after_return <https://celery.readthedocs.org/en/latest/reference/celery.app.task.html#celery.app.task.task.after_return>`_). this behaviour can be changed setting the task's option ``unlock_before_run``. when set to ``true``, the lock will be removed just before executing the task.\n\n**caveats**:\n  * any retry of the task won't re-enable the lock!\n  * this can only be set when defining the task, it cannot be passed dynamically to ``apply_async``\n\n.. code:: python\n\n    @celery.task(base=queueonce, once={'unlock_before_run': true})\n    def slow_task():\n        sleep(30)\n        return \"done!\"\n\n\n\n\nbackends\n========\n\nredis backend\n-------------\n\nrequires:\n\n* `redis <http://redis.io/>`_ is used as a distributed locking mechanism. behind the scenes, it use redis-py's `shared, distributed lock <https://github.com/andymccurdy/redis-py/blob/31519e4ccef49fb59254ee5524007c81faa7e850/redis/lock.py#l8>`_.\n\nconfiguration:\n\n-  ``backend`` - ``celery_once.backends.redis``\n\n-  ``settings``\n\n  - ``default_timeout`` - how many seconds after a lock has been set before it should automatically timeout (defaults to 3600 seconds, or 1 hour).\n\n  - ``url`` - should point towards a running redis instance (defaults to ``redis://localhost:6379/0``). see below for the format options supported\n\n  - ``blocking`` (boolean value: default ``false``) - if set to ``true``, scheduling a task (by ``.delay/.apply_async``) will block for x seconds to acquire the lock (see: ``blocking_timeout`` below). if no lock could be acquired after x seconds, will raise an ``alreadyqueued`` exception. this is a very specific use-case scenario and by default is disabled.\n\n  - ``blocking_timeout`` (int or float value: default ``1``) - how many seconds the task will block trying to aquire the lock, if ``blocking`` is set to ``true``. setting this to ``none`` set's no timeout (equivalent to infinite seconds).\n\n\n\nthe url parser supports three patterns of urls:\n\n* ``redis://host:port[/db][?options]``: redis over tcp\n\n* ``rediss://host:port[/db][?options]``: redis over tcp with ssl enabled.\n\n* ``redis+socket:///path/to/redis.sock[?options]``: redis over a unix socket\n\n  the ``options`` query args are mapped to the `strictredis <https://redis-py.readthedocs.org/en/latest/index.html#redis.strictredis>`_ keyword args.\n  examples:\n  * ``redis://localhost:6379/1``\n  \n  * ``redis://localhost:6379/1?ssl=true``\n\n  * ``rediss://localhost:6379/1``\n\n  * ``redis+socket:///var/run/redis/redis.sock?db=1``\n\n\nexample configuration:\n\nminimal:\n\n.. code:: python\n\n    celery.conf.once = {\n      'backend': 'celery_once.backends.redis',\n      'settings': {\n        'url': 'redis://localhost:6379/0',\n        'default_timeout': 60 * 60\n      }\n    }\n\n\nadvanced:\nscheduling tasks blocks up to 30 seconds trying to acquire a lock before raising an exception.\n\n    .. code:: python\n\n        celery.conf.once = {\n          'backend': 'celery_once.backends.redis',\n          'settings': {\n            'url': 'redis://localhost:6379/0',\n            'default_timeout': 60 * 60,\n            'blocking': true,\n            'blocking_timeout': 30\n          }\n        }\n\nfile backend\n-------------\n\nconfiguration:\n\n-  ``backend`` - ``celery_once.backends.file``\n\n-  ``settings``\n\n  - ``location`` - directory where lock files will be located. default is temporary directory.\n\n  - ``default_timeout`` - how many seconds after a lock has been set before it should automatically timeout (defaults to 3600 seconds, or 1 hour).\n\n\nexample configuration:\n\n.. code:: python\n\n    celery.conf.once = {\n        'backend': 'celery_once.backends.file',\n        'settings': {\n            'location': '/tmp/celery_once',\n            'default_timeout': 60 * 60\n        }\n    }\n\n\nflask intergration\n------------------\nto avoid ``runtimeerror: working outside of application context`` errors when using ``celery_once`` with `flask <http://flask.pocoo.org/docs/1.0/>`_, you need to make the ``queueonce`` task base class application context aware.\nif you've implemented celery following the flask `documentation <http://flask.pocoo.org/docs/1.0/patterns/celery/#configure>`_ you can extend it like so.\n\n    .. code:: python\n\n        def make_celery(app):\n            celery = celery(\n                app.import_name,\n                backend=app.config['celery_result_backend'],\n                broker=app.config['celery_broker_url']\n            )\n            celery.conf.update(app.config)\n\n            class contexttask(celery.task):\n                def __call__(self, *args, **kwargs):\n                    with app.app_context():\n                        return self.run(*args, **kwargs)\n            celery.task = contexttask\n\n            # make queueonce app context aware.\n            class contextqueueonce(queueonce):\n                def __call__(self, *args, **kwargs):\n                    with app.app_context():\n                        return super(contextqueueonce, self).__call__(*args, **kwargs)\n\n            # attach to celery object for easy access.\n            celery.queueonce = contextqueueonce\n            return celery\n\n\nnow, when instead of importing the ``queueonce`` base, you can use the context aware base on the ``celery`` object.\n\n    .. code:: python\n\n        celery = make_celery(app)\n\n        @celery.task(base=celery.queueonce)\n        def example_task(value):\n            return\n\n\ncustom backend\n--------------\n\nif you want to implement a custom locking backend, see `backend\\_guide.rst`_.\n\n.. _backend\\_guide.rst: backend_guide.rst\n\nsupport\n=======\n\n* tests are run against python 2.7, 3.4 and 3.5. other versions may work, but are not officially supported.\n\ncontributing\n============\n\ncontributions are welcome, and they are greatly appreciated! see `contributing\nguide <contributing.rst>`_ for more details.\n\n\n.. |build status| image:: https://travis-ci.org/cameronmaske/celery-once.svg\n   :target: https://travis-ci.org/cameronmaske/celery-once\n.. |coverage status| image:: https://coveralls.io/repos/cameronmaske/celery-once/badge.svg\n   :target: https://coveralls.io/r/cameronmaske/celery-once\n",
  "docs_url": null,
  "keywords": "celery",
  "license": "bsd",
  "name": "celery_once",
  "package_url": "https://pypi.org/project/celery_once/",
  "project_url": "https://pypi.org/project/celery_once/",
  "project_urls": {
    "Homepage": "https://github.com/cameronmaske/celery-once"
  },
  "release_url": "https://pypi.org/project/celery_once/3.0.1/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "allows you to prevent multiple execution and queuing of celery tasks.",
  "version": "3.0.1",
  "releases": [],
  "developers": [
    "cameron_maske",
    "cameronmaske@gmail.com"
  ],
  "kwds": "celery_result_backend make_celery celery celery_once celery_broker_url",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_celery_once",
  "homepage": "https://github.com/cameronmaske/celery-once",
  "release_count": 18,
  "dependency_ids": []
}