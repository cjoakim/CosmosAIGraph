{
  "classifiers": [
    "license :: osi approved :: apache software license",
    "operating system :: os independent",
    "programming language :: python :: 3",
    "programming language :: python :: 3 :: only"
  ],
  "description": "# schemachange\n<img src=\"images/schemachange-logo-title.png\" alt=\"schemachange\" title=\"schemachange logo\" width=\"600\" />\n\n*looking for snowchange? you've found the right spot. snowchange has been renamed to schemachange.*\n\n[![pytest](https://github.com/snowflake-labs/schemachange/actions/workflows/pytest.yml/badge.svg)](https://github.com/snowflake-labs/schemachange/actions/workflows/pytest.yml)\n[![pypi](https://img.shields.io/pypi/v/schemachange.svg)](https://pypi.org/project/schemachange)\n## overview\n\nschemachange is a simple python based tool to manage all of your [snowflake](https://www.snowflake.com/) objects. it follows an imperative-style approach to database change management (dcm) and was inspired by the [flyway database migration tool](https://flywaydb.org). when combined with a version control system and a ci/cd tool, database changes can be approved and deployed through a pipeline using modern software delivery practices. as such schemachange plays a critical role in enabling database (or data) devops.\n\ndcm tools (also known as database migration, schema change management, or schema migration tools) follow one of two approaches: declarative or imperative. for a background on database devops, including a discussion on the differences between the declarative and imperative approaches, please read the [embracing agile software delivery and devops with snowflake](https://www.snowflake.com/blog/embracing-agile-software-delivery-and-devops-with-snowflake/) blog post.\n\nfor the complete list of changes made to schemachange check out the [changelog](changelog.md).\n\n**please note** that schemachange is a community-developed tool, not an official snowflake offering. it comes with no support or warranty.\n\n## table of contents\n\n1. [overview](#overview)\n1. [project structure](#project-structure)\n   1. [folder structure](#folder-structure)\n1. [change scripts](#change-scripts)\n   1. [versioned script naming](#versioned-script-naming)\n   1. [repeatable script naming](#repeatable-script-naming)\n   1. [always script naming](#always-script-naming)\n   1. [script requirements](#script-requirements)\n   1. [using variables in scripts](#using-variables-in-scripts)\n      1. [secrets filtering](#secrets-filtering)\n   1. [jinja templating engine](#jinja-templating-engine)\n   1. [gotchas](#gotchas)\n1. [change history table](#change-history-table)\n1. [authentication](#authentication)\n   1. [password authentication](#password-authentication)\n   1. [private key authentication](#private-key-authentication)\n   1. [oauth authentication](#oauth-authentication)\n   1. [external browser authentication](#external-browser-authentication)\n   1. [okta authentication](#okta-authentication)\n1. [configuration](#configuration)\n   1. [yaml config file](#yaml-config-file)\n      1. [yaml jinja support](#yaml-jinja-support)\n   1. [command line arguments](#command-line-arguments)\n1. [running schemachange](#running-schemachange)\n   1. [prerequisites](#prerequisites)\n   1. [running the script](#running-the-script)\n1. [getting started with schemachange](#getting-started-with-schemachange)\n1. [integrating with devops](#integrating-with-devops)\n   1. [sample devops process flow](#sample-devops-process-flow)\n   1. [using in a ci/cd pipeline](#using-in-a-cicd-pipeline)\n1. [maintainers](#maintainers)\n1. [third party packages](#third-party-packages)\n1. [legal](#legal)\n\n\n## project structure\n\n### folder structure\n\nschemachange expects a directory structure like the following to exist:\n```\n(project_root)\n|\n|-- folder_1\n    |-- v1.1.1__first_change.sql\n    |-- v1.1.2__second_change.sql\n    |-- r__sp_add_sales.sql\n    |-- r__fn_get_timezone.sql\n|-- folder_2\n    |-- folder_3\n        |-- v1.1.3__third_change.sql\n        |-- r__fn_sort_ascii.sql\n```\n\nthe schemachange folder structure is very flexible. the `project_root` folder is specified with the `-f` or `--root-folder` argument. schemachange only pays attention to the filenames, not the paths. therefore, under the `project_root` folder you are free to arrange the change scripts any way you see fit. you can have as many subfolders (and nested subfolders) as you would like.\n\n## change scripts\n\n### versioned script naming\n\nversioned change scripts follow a similar naming convention to that used by [flyway versioned migrations](https://flywaydb.org/documentation/migrations#versioned-migrations). the script name must follow this pattern (image taken from [flyway docs](https://flywaydb.org/documentation/migrations#versioned-migrations)):\n\n<img src=\"images/flyway-naming-convention.png\" alt=\"flyway naming conventions\" title=\"flyway naming conventions\" width=\"300\" />\n\nwith the following rules for each part of the filename:\n\n* **prefix**: the letter 'v' for versioned change\n* **version**: a unique version number with dots or underscores separating as many number parts as you like\n* **separator**: __ (two underscores)\n* **description**: an arbitrary description with words separated by underscores or spaces (can not include two underscores)\n* **suffix**: .sql or .sql.jinja\n\nfor example, a script name that follows this convention is: `v1.1.1__first_change.sql`. as with flyway, the unique version string is very flexible. you just need to be consistent and always use the same convention, like 3 sets of numbers separated by periods. here are a few valid version strings:\n\n* 1.1\n* 1_1\n* 1.2.3\n* 1_2_3\n\nevery script within a database folder must have a unique version number. schemachange will check for duplicate version numbers and throw an error if it finds any. this helps to ensure that developers who are working in parallel don't accidently (re-)use the same version number.\n\n### repeatable script naming\n\nrepeatable change scripts follow a similar naming convention to that used by [flyway versioned migrations](https://flywaydb.org/documentation/concepts/migrations.html#repeatable-migrations). the script name must follow this pattern (image taken from [flyway docs](https://flywaydb.org/documentation/concepts/migrations.html#repeatable-migrations):\n\n<img src=\"images/flyway-repeatable-naming-convention.png\" alt=\"flyway naming conventions\" title=\"flyway naming conventions\" width=\"300\" />\n\ne.g:\n\n* r__sp_add_sales.sql\n* r__fn_get_timezone.sql\n* r__fn_sort_ascii.sql\n\nall repeatable change scripts are applied each time the utility is run, if there is a change in the file.\nrepeatable scripts could be used for maintaining code that always needs to be applied in its entirety. e.g. stores procedures, functions and view definitions etc.\n\njust like flyway, within a single migration run, repeatable scripts are always applied after all pending versioned scripts have been executed. repeatable scripts are applied in alphabetical order of their description.\n\n### always script naming\n\nalways change scripts are executed with every run of schemachange. this is an addition to the implementation of [flyway versioned migrations](https://flywaydb.org/documentation/concepts/migrations.html#repeatable-migrations).\nthe script name must following pattern:\n\n`a__some_description.sql`\n\ne.g.\n\n* a__add_user.sql\n* a__assign_roles.sql\n\nthis type of change script is useful for an environment set up after cloning. always scripts are applied always last.\n\n### script requirements\n\nschemachange is designed to be very lightweight and not impose to many limitations. each change script can have any number of sql statements within it and must supply the necessary context, like database and schema names. the context can be supplied by using an explicit `use <database>` command or by naming all objects with a three-part name (`<database name>.<schema name>.<object name>`). schemachange will simply run the contents of each script against the target snowflake account, in the correct order.\n\n### using variables in scripts\nschemachange supports the jinja engine for a variable replacement strategy. one important use of variables is to support multiple environments (dev, test, prod) in a single snowflake account by dynamically changing the database name during deployment. to use a variable in a change script, use this syntax anywhere in the script: `{{ variable1 }}`.\n\nto pass variables to schemachange, check out the [configuration](#configuration) section below. you can either use the `--vars` command line parameter or the yaml config file `schemachange-config.yml`. for the command line version you can pass variables like this: `--vars '{\"variable1\": \"value\", \"variable2\": \"value2\"}'`. this parameter accepts a flat json object formatted as a string. nested objects and arrays don't make sense at this point and aren't supported.\n\nschemachange will replace any variable placeholders before running your change script code and will throw an error if it finds any variable placeholders that haven't been replaced.\n\n#### secrets filtering\nwhile many ci/cd tools already have the capability to filter secrets, it is best that any tool also does not output secrets to the console or logs. schemachange implements secrets filtering in a number of areas to ensure secrets are not writen to the console or logs. the only exception is the `render` command which will display secrets.\n\na secret is just a standard variable that has been tagged as a secret. this is determined using a naming convention and either of the following will tag a variable as a secret:\n1. the variable name has the word secret in it.\n   ```yaml\n      config-version: 1\n      vars:\n         bucket_name: s3://......  # not a secret\n         secret_key: 567576d8e  # a secret\n   ```\n2. the variable is a child of a key named secrets.\n   ```yaml\n      config-version: 1\n      vars:\n      secrets:\n         my_key: 567576d8e # a secret\n      aws:\n         bucket_name: s3://......  # not a secret\n         secrets:\n            encryption_key: fgdsuuehdhjk # a secret\n            us_east_1:\n               encryption_key: sdsdsd # a secret\n   ```\n\n### jinja templating engine\nschemachange uses the jinja templating engine internally and supports: [expressions](https://jinja.palletsprojects.com/en/3.0.x/templates/#expressions), [macros](https://jinja.palletsprojects.com/en/3.0.x/templates/#macros), [includes](https://jinja.palletsprojects.com/en/3.0.x/templates/#include) and [template inheritance](https://jinja.palletsprojects.com/en/3.0.x/templates/#template-inheritance).\n\nthese files can be stored in the root-folder but schemachange also provides a separate modules folder `--modules-folder`. this allows common logic to be stored outside of the main changes scripts. the [demo/citibike_jinja](demo/citibike_jinja) has a simple example that demonstrates this.\n\nthe jinja autoescaping feature is disabled in schemachange, this feature in jinja is currently designed for where the output language is html/xml. so if you are using schemachange with untrusted inputs you will need to handle this within your change scripts.\n\n### gotchas\n\nwithin change scripts:\n- [snowflake scripting blocks need delimiters](https://docs.snowflake.com/en/developer-guide/snowflake-scripting/running-examples#introduction)\n- [the last line can't be a comment](https://github.com/snowflake-labs/schemachange/issues/130)\n\n## change history table\n\nschemachange records all applied changes scripts to the change history table. by default schemachange will attempt to log all activities to the `metadata.schemachange.change_history` table. the name and location of the change history table can be overriden by using the `-c` (or `--change-history-table`) parameter. the value passed to the parameter can have a one, two, or three part name (e.g. \"table_name\", or \"schema_name.table_name\", or \"database_name.schema_name.table_name\"). this can be used to support multiple environments (dev, test, prod) or multiple subject areas within the same snowflake account. by default schemachange will not try to create the change history table, and will fail if the table does not exist.\n\nadditionally, if the `--create-change-history-table` parameter is given, then schemachange will attempt to create the schema and table associated with the change history table. schemachange will not attempt to create the database for the change history table, so that must be created ahead of time, even when using the `--create-change-history-table` parameter.\n\nthe structure of the `change_history` table is as follows:\n\ncolumn name | type |  example\n--- | --- | ---\nversion | varchar | 1.1.1\ndescription | varchar | first change\nscript | varchar | v1.1.1__first_change.sql\nscript_type | varchar | v\nchecksum | varchar | 38e5ba03b1a6d2...\nexecution_time | number | 4\nstatus | varchar | success\ninstalled_by | varchar | snowflake_user\ninstalled_on | timestamp_ltz | 2020-03-17 12:54:33.056 -0700\n\na new row will be added to this table every time a change script has been applied to the database. schemachange will use this table to identify which changes have been applied to the database and will not apply the same version more than once.\n\nhere is the current schema ddl for the change history table (found in the [schemachange/cli.py](schemachange/cli.py) script), in case you choose to create it manually and not use the `--create-change-history-table` parameter:\n\n```sql\ncreate table if not exists schemachange.change_history\n(\n    version varchar\n   ,description varchar\n   ,script varchar\n   ,script_type varchar\n   ,checksum varchar\n   ,execution_time number\n   ,status varchar\n   ,installed_by varchar\n   ,installed_on timestamp_ltz\n)\n```\n\n## authentication\nschemachange supports snowflake's default authenticator, external oauth, browswer based sso and programmatic sso options supported by the [snowflake python connector](https://docs.snowflake.com/en/user-guide/python-connector-example.html#connecting-to-snowflake). set the environment variable `snowflake_authenticator` to one of the following\nauthentication option | expected value\n--- | ---\ndefault [password](https://docs.snowflake.com/en/user-guide/python-connector-example.html#connecting-using-the-default-authenticator) authenticator | `snowflake`\n[key pair](https://docs.snowflake.com/en/user-guide/python-connector-example.html#using-key-pair-authentication) authenticator| `snowflake`\n[external oauth](https://docs.snowflake.com/en/user-guide/oauth-external.html) | `oauth`\n[browser based sso](https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-use.html#setting-up-browser-based-sso) | `externalbrowser`\n[programmatic sso](https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-use.html#native-sso-okta-only) (okta only) | okta url endpoing for your okta account typically in the form `https://<okta_account_name>.okta.com` or `https://<okta_account_name>.oktapreview.com`\n\nif an authenticator is unsupported, then schemachange will default to `snowflake`. if the authenticator is `snowflake`, and both password and key pair values are provided then schemachange will use the password over the key pair values.\n\n### password authentication\nthe snowflake user password for `snowflake_user` is required to be set in the environment variable `snowflake_password` prior to calling the script. schemachange will fail if the `snowflake_password` environment variable is not set. the environment variable `snowflake_authenticator` will be set to `snowflake` if it not explicitly set.\n\n_**deprecation notice**: the `snowsql_pwd` environment variable is deprecated but currently still supported. support for it will be removed in a later version of schemachange. please use `snowflake_password` instead._\n\n### private key authentication\nthe snowflake user encrypted private key for `snowflake_user` is required to be in a file with the file path set in the environment variable `snowflake_private_key_path`. additionally, the password for the encrypted private key file is required to be set in the environment variable `snowflake_private_key_passphrase`. if the variable is not set, schemachange will assume the private key is not encrypted. these two environment variables must be set prior to calling the script. schemachange will fail if the `snowflake_private_key_path` is not set.\n\n### oauth authentication\na oauth configuration can be made in the [yaml config file](#yaml-config-file) or passing an equivalent json dictionary to the switch `--oauth-config`. invoke this method by setting the environment variable `snowflake_authenticator` to the value `oauth` prior to calling schemachange.  since different oauth providers may require different information the oauth configuration uses four named variables that are fed into a post request to obtain a token. azure is shown in the example yaml but other providers should use a similar pattern and request payload contents.\n* token-provider-url\nthe url of the authenticator resource that will be receive the post request.\n* token-response-name\nthe expected name of the json element containing the token in the return response from the authenticator resource.\n* token-request-payload\nthe set of variables passed as a dictionary to the `data` element of the request.\n* token-request-headers\nthe set of variables passed as a dictionary to the `headers` element of the request.\n\nit is recomended to use the yaml file and pass oauth secrets into the configuration using the templating engine instead of the command line option.\n\n\n### external browser authentication\nexternal browser authentication can be used for local development by setting the environment variable `snowflake_authenticator` to the value `externalbrowser` prior to calling schemachange.\nthe client will be prompted to authenticate in a browser that pops up. refer to the [documentation](https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-use.html#setting-up-browser-based-sso) to cache the token to minimize the number of times the browser pops up to authenticate the user.\n\n### okta authentication\nfor clients that do not have a browser, can use the popular saas idp option to connect via okta. this will require the okta url that you utilize for sso.\nokta authentication can be used setting the environment variable `snowflake_authenticator` to the value of your okta endpoint as a fully formed url ( e.g. `https://<org_name>.okta.com`) prior to calling schemachange.\n\n_** note**: please disable okta mfa for the user who uses native sso authentication with client drivers. please consult your okta administrator for more information._\n\n## configuration\n\nparameters to schemachange can be supplied in two different ways:\n1. through a yaml config file\n2. via command line arguments\n\nif supplied by both the command line and the yaml file, the command line overides the yaml values.\n\nadditionally, regardless of the approach taken, the following paramaters are required to run schemachange:\n* snowflake-account\n* snowflake-user\n* snowflake-role\n* snowflake-warehouse\n\nplese see [usage notes for the account parameter (for the connect method)](https://docs.snowflake.com/en/user-guide/python-connector-api.html#label-account-format-info) for more details on how to structure the account name.\n\n### yaml config file\n\nschemachange expects the yaml config file to be named `schemachange-config.yml` and looks for it by default in the current folder. the folder can be overridden by using the `--config-folder` command line argument (see [command line arguments](#command-line-arguments) below for more details).\n\nhere is the list of available configurations in the `schemachange-config.yml` file:\n\n```yaml\nconfig-version: 1\n\n# the root folder for the database change scripts\nroot-folder: '/path/to/folder'\n\n# the modules folder for jinja macros and templates to be used across multiple scripts.\nmodules-folder: null\n\n# the name of the snowflake account (e.g. xy12345.east-us-2.azure)\nsnowflake-account: 'xy12345.east-us-2.azure'\n\n# the name of the snowflake user\nsnowflake-user: 'user'\n\n# the name of the default role to use. can be overrideen in the change scripts.\nsnowflake-role: 'role'\n\n# the name of the default warehouse to use. can be overridden in the change scripts.\nsnowflake-warehouse: 'warehouse'\n\n# the name of the default database to use. can be overridden in the change scripts.\nsnowflake-database: null\n\n# the name of the default schema to use. can be overridden in the change scripts.\nsnowflake-schema: null\n\n# used to override the default name of the change history table (the default is metadata.schemachange.change_history)\nchange-history-table: null\n\n# define values for the variables to replaced in change scripts\nvars:\n  var1: 'value1'\n  var2: 'value2'\n  secrets:\n    var3: 'value3' # this is considered a secret and will not be displayed in any output\n\n# create the change history schema and table, if they do not exist (the default is false)\ncreate-change-history-table: false\n\n# enable autocommit feature for dml commands (the default is false)\nautocommit: false\n\n# display verbose debugging details during execution (the default is false)\nverbose: false\n\n# run schemachange in dry run mode (the default is false)\ndry-run: false\n\n# a string to include in the query_tag that is attached to every sql statement executed\nquery-tag: 'query_tag'\n\n# information for oauth token requests\noauthconfig:\n  # url where token request are posted to\n  token-provider-url: 'https://login.microsoftonline.com/{{ env_var('azure_org_guid', 'default') }}/oauth2/v2.0/token'\n  # name of json entity returned by request\n  token-response-name: 'access_token'\n  # headers needed for successful post or other security markings ( multiple labeled items permitted\n  token-request-headers:\n    content-type: \"application/x-www-form-urlencoded\"\n    user-agent: \"python/schemachange\"\n  # request payload for token (it is recommended pass\n  token-request-payload:\n    client_id: '{{ env_var('client_id', 'default') }}'\n    username: '{{ env_var('user_id', 'default') }}'\n    password: '{{ env_var('user_password', 'default') }}'\n    grant_type: 'password'\n    scope: '{{ env_var('session_scope', 'default') }}'\n```\n\n#### yaml jinja support\nthe yaml config file supports the jinja templating language and has a custom function \"env_var\" to access environmental variables.  jinja variables are unavailible and not yet loaded since they are supplied by the yaml file. customisation of the yaml file can only happen through values passed via environment variables.\n\n##### env_var\nprovides access to environmental variables. the function can be used two different ways.\n\nreturn the value of the environmental variable if it exists, otherwise return the default value.\n``` jinja\n{{ env_var('<environmental_variable>', 'default') }}\n```\n\nreturn the value of the environmental variable if it exists, otherwise raise an error.\n``` jinja\n{{ env_var('<environmental_variable>') }}\n```\n\n### command line arguments\n\nschemachange supports a number of subcommands, it the subcommand is not provided it is defaulted to deploy. this behaviour keeps compatibility with versions prior to 3.2.\n\n#### deploy\nthis is the main command that runs the deployment process.\n\n`usage: schemachange deploy [-h] [--config-folder config_folder] [-f root_folder] [-m modules_folder] [-a snowflake_account] [-u snowflake_user] [-r snowflake_role] [-w snowflake_warehouse] [-d snowflake_database] [-s snowflake_schema] [-c change_history_table] [--vars vars] [--create-change-history-table] [-ac] [-v] [--dry-run] [--query-tag query_tag]`\n\nparameter | description\n--- | ---\n-h, --help | show the help message and exit\n--config-folder config_folder | the folder to look in for the schemachange-config.yml file (the default is the current working directory)\n-f root_folder, --root-folder root_folder | the root folder for the database change scripts. the default is the current directory.\n-m modules_folder, --modules-folder modules_folder | the modules folder for jinja macros and templates to be used across mutliple scripts\n-a snowflake_account, --snowflake-account snowflake_account | the name of the snowflake account (e.g. xy12345.east-us-2.azure).\n-u snowflake_user, --snowflake-user snowflake_user | the name of the snowflake user\n-r snowflake_role, --snowflake-role snowflake_role | the name of the role to use\n-w snowflake_warehouse, --snowflake-warehouse snowflake_warehouse | the name of the default warehouse to use. can be overridden in the change scripts.\n-d snowflake_database, --snowflake-database snowflake_database | the name of the default database to use. can be overridden in the change scripts.\n-s snowflake_schema, --snowflake-schema snowflake_schema | the name of the default schema to use. can be overridden in the change scripts.\n-c change_history_table, --change-history-table change_history_table | used to override the default name of the change history table (which is metadata.schemachange.change_history)\n--vars vars | define values for the variables to replaced in change scripts, given in json format (e.g. '{\"variable1\": \"value1\", \"variable2\": \"value2\"}')\n--create-change-history-table | create the change history table if it does not exist. the default is 'false'.\n-ac, --autocommit | enable autocommit feature for dml commands. the default is 'false'.\n-v, --verbose | display verbose debugging details during execution. the default is 'false'.\n--dry-run | run schemachange in dry run mode. the default is 'false'.\n--query-tag | a string to include in the query_tag that is attached to every sql statement executed.\n--oauth-config | define values for the variables to make oauth token requests  (e.g. {\"token-provider-url\": \"https//...\", \"token-request-payload\": {\"client_id\": \"guid_xyz\",...},... })'\n\n#### render\nthis subcommand is used to render a single script to the console. it is intended to support the development and troubleshooting of script that use features from the jinja template engine.\n\n`usage: schemachange render [-h] [--config-folder config_folder] [-f root_folder] [-m modules_folder] [--vars vars] [-v] script`\n\nparameter | description\n--- | ---\n--config-folder config_folder | the folder to look in for the schemachange-config.yml file (the default is the current working directory)\n-f root_folder, --root-folder root_folder | the root folder for the database change scripts\n-m modules_folder, --modules-folder modules_folder | the modules folder for jinja macros and templates to be used across multiple scripts\n--vars vars | define values for the variables to replaced in change scripts, given in json format (e.g. {\"variable1\": \"value1\", \"variable2\": \"value2\"})\n-v, --verbose | display verbose debugging details during execution (the default is false)\n\n\n## running schemachange\n\n### prerequisites\n\nin order to run schemachange you must have the following:\n\n* you will need to have a recent version of python 3 installed\n* you will need to have the latest [snowflake python driver installed](https://docs.snowflake.com/en/user-guide/python-connector-install.html)\n* you will need to create the change history table used by schemachange in snowflake (see [change history table](#change-history-table) above for more details)\n    * first, you will need to create a database to store your change history table (schemachange will not help you with this)\n    * second, you will need to create the change history schema and table. you can do this manually (see [change history table](#change-history-table) above for the ddl) or have schemachange create them by running it with the `--create-change-history-table` parameter (just make sure the snowflake user you're running schemachange with has privileges to create a schema and table in that database)\n* you will need to create (or choose) a user account that has privileges to apply the changes in your change script\n    * don't forget that this user also needs the select and insert privileges on the change history table\n\n### running the script\n\nschemachange is a single python script located at [schemachange/cli.py](schemachange/cli.py). it can be executed as follows:\n\n```\npython schemachange/cli.py [-h] [--config-folder config_folder] [-f root_folder] [-a snowflake_account] [-u snowflake_user] [-r snowflake_role] [-w snowflake_warehouse] [-d snowflake_database] [-s snowflake_schema] [-c change_history_table] [--vars vars] [--create-change-history-table] [-ac] [-v] [--dry-run] [--query-tag query_tag] [--oauth-config ouath_config]\n```\n\nor if installed via `pip`, it can be executed as follows:\n\n```\nschemachange [-h] [--config-folder config_folder] [-f root_folder] [-a snowflake_account] [-u snowflake_user] [-r snowflake_role] [-w snowflake_warehouse] [-d snowflake_database] [-s snowflake_schema] [-c change_history_table] [--vars vars] [--create-change-history-table] [-ac] [-v] [--dry-run] [--query-tag query_tag] [--oauth-config ouath_config]\n```\n\n## getting started with schemachange\n\nthe [demo](demo) folder in this project repository contains a schemachange demo project for you to try out. this demo is based on the standard snowflake citibike demo which can be found in [the snowflake hands-on lab](https://docs.snowflake.net/manuals/other-resources.html#hands-on-lab). it contains the following database change scripts:\n\nchange script | description\n--- | ---\nv1.1__initial_database_objects.sql | create the initial citibike demo objects including file formats, stages, and tables.\nv1.2__load_tables_from_s3.sql | load the citibike and weather data from the snowlake lab s3 bucket.\n\nthe [citibike data](https://www.citibikenyc.com/system-data) for this demo comes from the nyc citi bike bike share program.\n\nto get started with schemachange and these demo citibike scripts follow these steps:\n1. make sure you've completed the [prerequisites](#prerequisites) steps above\n1. get a copy of this schemachange repository (either via a clone or download)\n1. open a shell and change directory to your copy of the schemachange repository\n1. run schemachange (see [running the script](#running-the-script) above) with your snowflake account details and the `demo/citibike` folder as the root folder (make sure you use the full path)\n\n## integrating with devops\n\n### sample devops process flow\n\nhere is a sample devops development lifecycle with schemachange:\n\n<img src=\"images/diagram.png\" alt=\"schemachange devops process\" title=\"schemachange devops process\" />\n\n### using in a ci/cd pipeline\n\nif your build agent has a recent version of python 3 installed, the script can be ran like so:\n```\npip install schemachange --upgrade\nschemachange [-h] [-f root_folder] -a snowflake_account -u snowflake_user -r snowflake_role -w snowflake_warehouse [-d snowflake_database] [-s snowflake_schema] [-c change_history_table] [--vars vars] [--create-change-history-table] [-ac] [-v] [--dry-run] [--query-tag query_tag] [--oauth-config ouath_config]\n```\n\nor if you prefer docker, set the environment variables and run like so:\n```\ndocker run -it --rm \\\n  --name schemachange-script \\\n  -v \"$pwd\":/usr/src/schemachange \\\n  -w /usr/src/schemachange \\\n  -e root_folder \\\n  -e snowflake_account \\\n  -e snowflake_user \\\n  -e snowflake_role \\\n  -e snowflake_warehouse \\\n  -e snowflake_password \\\n  python:3 /bin/bash -c \"pip install schemachange --upgrade && schemachange -f $root_folder -a $snowflake_account -u $snowflake_user -r $snowflake_role -w $snowflake_warehouse\"\n```\n\neither way, don't forget to set the `snowflake_password` environment variable if using password authentication!\n\n## maintainers\n\n- james weakley (@jamesweakley)\n- jeremiah hansen (@jeremiahhansen)\n\nthis is a community-developed tool, not an official snowflake offering. it comes with no support or warranty. however, feel free to raise a github issue if you find a bug or would like a new feature.\n\n## third party packages\nthe current functionality in schemachange would not be possible without the following third party packages and all those that maintain and have contributed.\n\n name | license | author | url\n ---|---|---|---\n jinja2 | bsd license | armin ronacher | https://palletsprojects.com/p/jinja/\n pyyaml | mit license | kirill simonov | https://pyyaml.org/\n pandas | bsd license | the pandas development team | https://pandas.pydata.org\n pytest | mit license | holger krekel, bruno oliveira, ronny pfannschmidt, floris bruynooghe, brianna laugher, florian bruhin and others | https://docs.pytest.org/en/latest/\n snowflake-connector-python | apache software license | snowflake, inc | https://www.snowflake.com/\n\n## legal\n\nlicensed under the apache license, version 2.0 (the \"license\"); you may not use this tool except in compliance with the license. you may obtain a copy of the license at: [http://www.apache.org/licenses/license-2.0](http://www.apache.org/licenses/license-2.0)\n\nunless required by applicable law or agreed to in writing, software distributed under the license is distributed on an \"as is\" basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license.\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache-2.0",
  "name": "schemachange",
  "package_url": "https://pypi.org/project/schemachange/",
  "project_url": "https://pypi.org/project/schemachange/",
  "project_urls": {
    "Homepage": "https://github.com/Snowflake-Labs/schemachange"
  },
  "release_url": "https://pypi.org/project/schemachange/3.6.1/",
  "requires_dist": [
    "jinja2 ~=3.0",
    "pandas ~=1.3",
    "pyyaml ~=6.0",
    "snowflake-connector-python <4.0,>=2.8",
    "pytest ; extra == 'dev'"
  ],
  "requires_python": ">=3.8",
  "summary": "a database change management tool for snowflake",
  "version": "3.6.1",
  "releases": [],
  "developers": [
    "jamesweakley"
  ],
  "kwds": "snowflake_schema snowflake_authenticator snowflake_password pytest snowflake_warehouse",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_schemachange",
  "homepage": "https://github.com/snowflake-labs/schemachange",
  "release_count": 22,
  "dependency_ids": [
    "pypi_jinja2",
    "pypi_pandas",
    "pypi_pytest",
    "pypi_pyyaml",
    "pypi_snowflake_connector_python"
  ]
}