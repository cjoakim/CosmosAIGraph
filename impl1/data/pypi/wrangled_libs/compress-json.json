{
  "classifiers": [
    "development status :: 3 - alpha",
    "license :: osi approved :: mit license",
    "programming language :: python :: 3"
  ],
  "description": "compress_json\n=========================================================================================\n|pip| |downloads|\n\nthe missing python utility to read and write large compressed jsons.\n\nthe library is loosely based on the `compress_pickle <https://github.com/lucianopaz/compress_pickle>`_ library.\n\nhow do i install this package?\n----------------------------------------------\nas usual, just download it using pip:\n\n.. code:: shell\n\n    pip install compress_json\n\navailable compression modes\n----------------------------------------------\nthe compression modes, detected automatically by the file name, are **gzip**, **bz2** and **lzma**,\nwith the notable exception of **zip** which seems difficult to integrate in the json pipeline.\n\nusage example\n----------------------------------------------\nthe library is extremely easy to use:\n\n.. code:: python\n\n    import compress_json\n    \n    d = {\n        \"a\":{\n            \"b\":\"c\"\n        }\n    }\n    compress_json.dump(d, \"filepath.json.gz\") # for a gzip file\n    compress_json.dump(d, \"filepath.json.bz\") # for a bz2 file\n    compress_json.dump(d, \"filepath.json.lzma\") # for a lzma file\n\n    d1 = compress_json.load(\"filepath.json.gz\") # for loading a gzip file\n    d2 = compress_json.load(\"filepath.json.bz\") # for loading a bz2 file\n    d3 = compress_json.load(\"filepath.json.lzma\") # for loading a lzma file\n\n\nsome extra perks: local loading and dumping\n----------------------------------------------\nthe library makes available, other than the usual load and dump from the json library, the methods local_load and local_dump, which let you load and dump file in the same directory of wherever you are calling them, by using the call stack.\n\nthis can get useful, especially when loading files within packages.\n\n.. code:: python\n\n    import compress_json\n    \n    d = {\n        \"a\": {\n            \"b\": \"c\"\n        }\n    }\n    compress_json.local_dump(d, \"filepath.json.gz\") # for a gzip file\n    compress_json.local_dump(d, \"filepath.json.bz\") # for a bz2 file\n    compress_json.local_dump(d, \"filepath.json.lzma\") # for a lzma file\n\n    d1 = compress_json.local_load(\"filepath.json.gz\") # for loading a gzip file\n    d2 = compress_json.local_load(\"filepath.json.bz\") # for loading a bz2 file\n    d3 = compress_json.local_load(\"filepath.json.lzma\") # for loading a lzma file\n\nloading with ram cache\n----------------------------------------------\nsometimes you need to load a compressed json file a lot of times, and you may want to\nput this document in a cache or something of the sorts. fortunately, we already provide\nthis option for you:\n\n.. code:: python\n\n    import compress_json\n    \n    d1 = compress_json.load(\n        \"filepath.json.gz\",\n        use_cache=true\n    )\n\n    d1 = compress_json.local_load(\n        \"filepath.json.gz\",\n        use_cache=true\n    )\n\nadvanced usage\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nyou can pass parameters to either the chosen compression mode or the json library.\n\nwith the :code:`json_kwargs` parameter you can specify any of the kwargs that should\nbe forwarded to the json library method, which you can obtain for your python version\nby running :code:`help(json.dump)` and :code:`help(json.load)`, depending whether you are\ndumping or loading the json object.\n\nanalogously, with the :code:`compression_kwargs` parameter you can specify any parameter that\nhas to be forwarded to the compression library that you intend to use, whether that is\n`lzma`, :code:`gzip` or :code:`bz2`, and as per json will depend on which version you have installed.\n\nwhether you are dumping or loading a compressed json object, you can get the list of parameters you\nhave available to forward to the compression method by running :code:`help(lzma.open)`, :code:`help(gzip.open)`\nor :code:`help(bz2.open)`, respectively.\n\n.. code:: python\n\n    import compress_json\n    \n    d = {\n        \"a\": {\n            \"b\": \"c\"\n        }\n    }\n    compress_json.dump(\n        d, \"filepath.json.gz\",\n        compression_kwargs = {kwargs go here},\n        json_kwargs = {kwargs go here}\n    )\n\n    d4 = compress_json.load(\n        \"filepath.json.gz\",\n        compression_kwargs = {kwargs go here},\n        json_kwargs = {kwargs go here}\n    )\n\n\n.. |pip| image:: https://badge.fury.io/py/compress-json.svg\n    :target: https://badge.fury.io/py/compress-json\n    :alt: pypi project\n\n.. |downloads| image:: https://pepy.tech/badge/compress-json\n    :target: https://pepy.tech/badge/compress-json\n    :alt: pypi total project downloads \n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "compress-json",
  "package_url": "https://pypi.org/project/compress-json/",
  "project_url": "https://pypi.org/project/compress-json/",
  "project_urls": {
    "Homepage": "https://github.com/LucaCappelletti94/compress_json"
  },
  "release_url": "https://pypi.org/project/compress-json/1.0.10/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "the missing python utility to read and write large compressed jsons.",
  "version": "1.0.10",
  "releases": [],
  "developers": [
    "cappelletti.luca94@gmail.com",
    "luca_cappelletti"
  ],
  "kwds": "compress_pickle compress_json compression_kwargs gzip compressed",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_compress_json",
  "homepage": "https://github.com/lucacappelletti94/compress_json",
  "release_count": 11,
  "dependency_ids": []
}