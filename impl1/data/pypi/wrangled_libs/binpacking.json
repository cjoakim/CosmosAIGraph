{
  "classifiers": [
    "license :: osi approved :: mit license",
    "programming language :: python :: 2.7",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "binpacking\n==========\n\nthis package contains greedy algorithms to solve two typical bin packing\nproblems, (i) sorting items into a constant number of bins, (ii) sorting\nitems into a low number of bins of constant size. here's a usage example\n\n.. code:: python\n\n    >>> import binpacking\n    >>>\n    >>> b = { 'a': 10, 'b': 10, 'c':11, 'd':1, 'e': 2,'f':7 }\n    >>> bins = binpacking.to_constant_bin_number(b,4) # 4 being the number of bins\n    >>> print(\"===== dict\\n\",b,\"\\n\",bins)\n    ===== dict\n     {'a': 10, 'b': 10, 'c': 11, 'd': 1, 'e': 2, 'f': 7}\n     [{'c': 11}, {'b': 10}, {'a': 10}, {'f': 7, 'e': 2, 'd': 1}]\n    >>>\n    >>> b = list(b.values())\n    >>> bins = binpacking.to_constant_volume(b,11) # 11 being the bin volume\n    >>> print(\"===== list\\n\",b,\"\\n\",bins)\n    ===== list\n     [10, 10, 11, 1, 2, 7]\n     [[11], [10], [10], [7, 2, 1]]\n\nconsider you have a list of items, each carrying a weight *w\\_i*.\ntypical questions are\n\n#. how can we distribute the items to a minimum number of bins *n* of\n   equal volume *v*?\n#. how can we distribute the items to exactly *n* bins where each\n   carries items that sum up to approximately equal weight?\n\nproblems like this can easily occur in modern computing. assume you have\nto run computations where a lot of files of different sizes have to be\nloaded into the memory. however, you only have a machine with 8gb of\nram. how should you bind the files such that you have to run your\nprogram a minimum amount of times? this is equivalent to solving problem\n1.\n\nwhat about problem 2? say you have to run a large number of\ncomputations. for each of the jobs you know the time it will probably\ntake to finish. however, you only have a cpu with 4 cores. how should\nyou distribute the jobs to the 4 cores such that they will all finish at\napproximately the same time?\n\nthe package provides the command line tool \"binpacking\" using which one\ncan easily bin pack csv-files containing a column that can be identified\nwith a weight. to see the usage enter\n\n.. code:: bash\n\n    $ binpacking -h\n    usage: binpacking [options]\n\n    options:\n      -h, --help            show this help message and exit\n      -f filepath, --filepath=filepath\n                            path to the csv-file to be bin-packed\n      -v v_max, --volume=v_max\n                            maximum volume per bin (constant volume algorithm will\n                            be used)\n      -n n_bin, --n-bin=n_bin\n                            number of bins (constant bin number algorithm will be\n                            used)\n      -c weight_column, --weight-column=weight_column\n                            integer (or string) giving the column number (or\n                        column name in header) where the weight is stored\n      -h, --has-header      parse this option if there is a header in the csv-file\n      -d delim, --delimiter=delim\n                            delimiter in the csv-file (use \"tab\" for tabs)\n      -q quotechar, --quotechar=quotechar\n                            quotecharacter in the csv-file\n      -l lower_bound, --lower-bound=lower_bound\n                            weights below this bound will not be considered\n      -u upper_bound, --upper-bound=upper_bound\n                            weights exceeding this bound will not be considered\n\ninstall\n-------\n\n.. code:: bash\n\n    $ pip install binpacking\n\nexamples\n--------\n\nin the repository's directory\n\n.. code:: bash\n\n    cd examples/\n    binpacking -f hamlet_word_count.csv -v 2000 -h -c count -l 10 -u 1000\n    binpacking -f hamlet_word_count.csv -n 4 -h -c count \n\nin python\n\n.. code:: python\n\n    import binpacking\n\n    b = { 'a': 10, 'b': 10, 'c':11, 'd':1, 'e': 2,'f':7 }\n    bins = binpacking.to_constant_bin_number(b,4)\n    print(\"===== dict\\n\",b,\"\\n\",bins)\n\n    b = list(b.values())\n    bins = binpacking.to_constant_volume(b,11)\n    print(\"===== list\\n\",b,\"\\n\",bins)",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "binpacking",
  "package_url": "https://pypi.org/project/binpacking/",
  "project_url": "https://pypi.org/project/binpacking/",
  "project_urls": {
    "Homepage": "https://www.github.com/benmaier/binpacking"
  },
  "release_url": "https://pypi.org/project/binpacking/1.5.2/",
  "requires_dist": [],
  "requires_python": "",
  "summary": "heuristic distribution of weighted items to bins (either a fixed number of bins or a fixed number of volume per bin). data may be in form of list, dictionary, list of tuples or csv-file.",
  "version": "1.5.2",
  "releases": [],
  "developers": [
    "benjamin_f",
    "bfmaier@physik.hu-berlin.de"
  ],
  "kwds": "binpacking bins bin packing to_constant_bin_number",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_binpacking",
  "homepage": "https://www.github.com/benmaier/binpacking",
  "release_count": 12,
  "dependency_ids": []
}