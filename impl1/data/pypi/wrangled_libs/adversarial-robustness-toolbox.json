{
  "classifiers": [
    "development status :: 3 - alpha",
    "intended audience :: developers",
    "intended audience :: education",
    "intended audience :: science/research",
    "license :: osi approved :: mit license",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering :: artificial intelligence",
    "topic :: security",
    "topic :: software development :: libraries",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "# adversarial robustness toolbox (art) v1.16\n<p align=\"center\">\n  <img src=\"docs/images/art_lfai.png?raw=true\" width=\"467\" title=\"art logo\">\n</p>\n<br />\n\n![codeql](https://github.com/trusted-ai/adversarial-robustness-toolbox/workflows/codeql/badge.svg)\n[![documentation status](https://readthedocs.org/projects/adversarial-robustness-toolbox/badge/?version=latest)](http://adversarial-robustness-toolbox.readthedocs.io/en/latest/?badge=latest)\n[![pypi](https://badge.fury.io/py/adversarial-robustness-toolbox.svg)](https://badge.fury.io/py/adversarial-robustness-toolbox)\n[![codecov](https://codecov.io/gh/trusted-ai/adversarial-robustness-toolbox/branch/main/graph/badge.svg)](https://codecov.io/gh/trusted-ai/adversarial-robustness-toolbox)\n[![code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![license: mit](https://img.shields.io/badge/license-mit-yellow.svg)](https://opensource.org/licenses/mit)\n[![pypi - python version](https://img.shields.io/pypi/pyversions/adversarial-robustness-toolbox)](https://pypi.org/project/adversarial-robustness-toolbox/)\n[![slack-img](https://img.shields.io/badge/chat-on%20slack-yellow.svg)](https://ibm-art.slack.com/)\n[![downloads](https://static.pepy.tech/badge/adversarial-robustness-toolbox)](https://pepy.tech/project/adversarial-robustness-toolbox)\n[![downloads](https://static.pepy.tech/badge/adversarial-robustness-toolbox/month)](https://pepy.tech/project/adversarial-robustness-toolbox)\n[![cii best practices](https://bestpractices.coreinfrastructure.org/projects/5090/badge)](https://bestpractices.coreinfrastructure.org/projects/5090)\n\n[\u4e2d\u6587readme\u8bf7\u6309\u6b64\u5904](readme-cn.md)\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/lfai/artwork/master/lfaidata-assets/lfaidata-project-badge/graduate/color/lfaidata-project-badge-graduate-color.png\" alt=\"lf ai & data\" width=\"300\"/>\n</p>\n\nadversarial robustness toolbox (art) is a python library for machine learning security. art is hosted by the \n[linux foundation ai & data foundation](https://lfaidata.foundation) (lf ai & data). art provides tools that enable\ndevelopers and researchers to defend and evaluate machine learning models and applications against the\nadversarial threats of evasion, poisoning, extraction, and inference. art supports all popular machine learning frameworks\n(tensorflow, keras, pytorch, mxnet, scikit-learn, xgboost, lightgbm, catboost, gpy, etc.), all data types\n(images, tables, audio, video, etc.) and machine learning tasks (classification, object detection, speech recognition,\ngeneration, certification, etc.).\n\n## adversarial threats\n\n<p align=\"center\">\n  <img src=\"docs/images/adversarial_threats_attacker.png?raw=true\" width=\"400\" title=\"art logo\">\n  <img src=\"docs/images/adversarial_threats_art.png?raw=true\" width=\"400\" title=\"art logo\">\n</p>\n<br />\n\n## art for red and blue teams (selection)\n\n<p align=\"center\">\n  <img src=\"docs/images/white_hat_blue_red.png?raw=true\" width=\"800\" title=\"art red and blue teams\">\n</p>\n<br />\n\n## learn more\n\n| **[get started][get-started]**     | **[documentation][documentation]**     | **[contributing][contributing]**           |\n|-------------------------------------|-------------------------------|-----------------------------------|\n| - [installation][installation]<br>- [examples](examples/readme.md)<br>- [notebooks](notebooks/readme.md) | - [attacks][attacks]<br>- [defences][defences]<br>- [estimators][estimators]<br>- [metrics][metrics]<br>- [technical documentation](https://adversarial-robustness-toolbox.readthedocs.io) | - [slack](https://ibm-art.slack.com), [invitation](https://join.slack.com/t/ibm-art/shared_invite/enqtmzkyotkyode4nzm4lta4ngq1otmxmzfmy2q1mze1nwi2mmezn2fjngnjogvlodvkzde0mja1nta4ogvkmjvknmq4mty1nmmyogm5ytg)<br>- [contributing](contributing.md)<br>- [roadmap][roadmap]<br>- [citing][citing] |\n\n[get-started]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/get-started\n[attacks]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/art-attacks\n[defences]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/art-defences\n[estimators]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/art-estimators\n[metrics]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/art-metrics\n[contributing]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/contributing\n[documentation]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/documentation\n[installation]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/get-started#setup\n[roadmap]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/roadmap\n[citing]: https://github.com/trusted-ai/adversarial-robustness-toolbox/wiki/contributing#citing-art\n\nthe library is under continuous development. feedback, bug reports and contributions are very welcome!\n\n# acknowledgment\nthis material is partially based upon work supported by the defense advanced research projects agency (darpa) under\ncontract no. hr001120c0013. any opinions, findings and conclusions or recommendations expressed in this material are\nthose of the author(s) and do not necessarily reflect the views of the defense advanced research projects agency (darpa).\n",
  "docs_url": null,
  "keywords": "",
  "license": "mit",
  "name": "adversarial-robustness-toolbox",
  "package_url": "https://pypi.org/project/adversarial-robustness-toolbox/",
  "project_url": "https://pypi.org/project/adversarial-robustness-toolbox/",
  "project_urls": {
    "Homepage": "https://github.com/Trusted-AI/adversarial-robustness-toolbox"
  },
  "release_url": "https://pypi.org/project/adversarial-robustness-toolbox/1.16.0/",
  "requires_dist": [
    "numpy (>=1.18.0)",
    "scipy (>=1.4.1)",
    "scikit-learn (<1.2.0,>=0.22.2)",
    "six",
    "setuptools",
    "tqdm",
    "mxnet ; extra == 'all'",
    "catboost ; extra == 'all'",
    "lightgbm ; extra == 'all'",
    "tensorflow ; extra == 'all'",
    "tensorflow-addons ; extra == 'all'",
    "h5py ; extra == 'all'",
    "torch ; extra == 'all'",
    "torchvision ; extra == 'all'",
    "xgboost ; extra == 'all'",
    "pandas ; extra == 'all'",
    "kornia ; extra == 'all'",
    "matplotlib ; extra == 'all'",
    "Pillow ; extra == 'all'",
    "statsmodels ; extra == 'all'",
    "pydub ; extra == 'all'",
    "resampy ; extra == 'all'",
    "ffmpeg-python ; extra == 'all'",
    "cma ; extra == 'all'",
    "librosa ; extra == 'all'",
    "opencv-python ; extra == 'all'",
    "numba ; extra == 'all'",
    "catboost ; extra == 'catboost'",
    "sphinx (>=1.4) ; extra == 'docs'",
    "sphinx-rtd-theme ; extra == 'docs'",
    "sphinx-autodoc-annotation ; extra == 'docs'",
    "sphinx-autodoc-typehints ; extra == 'docs'",
    "matplotlib ; extra == 'docs'",
    "numpy (>=1.18.0) ; extra == 'docs'",
    "scipy (>=1.4.1) ; extra == 'docs'",
    "six (>=1.13.0) ; extra == 'docs'",
    "scikit-learn (<1.2.0,>=0.22.2) ; extra == 'docs'",
    "Pillow (>=6.0.0) ; extra == 'docs'",
    "GPy ; extra == 'gpy'",
    "keras ; extra == 'keras'",
    "h5py ; extra == 'keras'",
    "lightgbm ; extra == 'lightgbm'",
    "tensorflow-gpu (==2.1.0) ; extra == 'lingvo_asr'",
    "lingvo (==0.6.4) ; extra == 'lingvo_asr'",
    "pydub ; extra == 'lingvo_asr'",
    "resampy ; extra == 'lingvo_asr'",
    "librosa ; extra == 'lingvo_asr'",
    "mxnet ; extra == 'mxnet'",
    "matplotlib ; extra == 'non_framework'",
    "Pillow ; extra == 'non_framework'",
    "statsmodels ; extra == 'non_framework'",
    "pydub ; extra == 'non_framework'",
    "resampy ; extra == 'non_framework'",
    "ffmpeg-python ; extra == 'non_framework'",
    "cma ; extra == 'non_framework'",
    "pandas ; extra == 'non_framework'",
    "librosa ; extra == 'non_framework'",
    "opencv-python ; extra == 'non_framework'",
    "pytest ; extra == 'non_framework'",
    "pytest-flake8 ; extra == 'non_framework'",
    "pytest-mock ; extra == 'non_framework'",
    "pytest-cov ; extra == 'non_framework'",
    "requests ; extra == 'non_framework'",
    "sortedcontainers ; extra == 'non_framework'",
    "numba ; extra == 'non_framework'",
    "timm ; extra == 'non_framework'",
    "multiprocess ; extra == 'non_framework'",
    "torch ; extra == 'pytorch'",
    "torchvision ; extra == 'pytorch'",
    "torch ; extra == 'pytorch_audio'",
    "torchvision ; extra == 'pytorch_audio'",
    "torchaudio ; extra == 'pytorch_audio'",
    "pydub ; extra == 'pytorch_audio'",
    "resampy ; extra == 'pytorch_audio'",
    "librosa ; extra == 'pytorch_audio'",
    "torch ; extra == 'pytorch_image'",
    "torchvision ; extra == 'pytorch_image'",
    "kornia ; extra == 'pytorch_image'",
    "Pillow ; extra == 'pytorch_image'",
    "ffmpeg-python ; extra == 'pytorch_image'",
    "opencv-python ; extra == 'pytorch_image'",
    "tensorflow ; extra == 'tensorflow'",
    "tensorflow-addons ; extra == 'tensorflow'",
    "h5py ; extra == 'tensorflow'",
    "tensorflow ; extra == 'tensorflow_audio'",
    "tensorflow-addons ; extra == 'tensorflow_audio'",
    "h5py ; extra == 'tensorflow_audio'",
    "pydub ; extra == 'tensorflow_audio'",
    "resampy ; extra == 'tensorflow_audio'",
    "librosa ; extra == 'tensorflow_audio'",
    "tensorflow ; extra == 'tensorflow_image'",
    "tensorflow-addons ; extra == 'tensorflow_image'",
    "h5py ; extra == 'tensorflow_image'",
    "Pillow ; extra == 'tensorflow_image'",
    "ffmpeg-python ; extra == 'tensorflow_image'",
    "opencv-python ; extra == 'tensorflow_image'",
    "xgboost ; extra == 'xgboost'"
  ],
  "requires_python": "",
  "summary": "toolbox for adversarial machine learning.",
  "version": "1.16.0",
  "releases": [],
  "developers": [
    "beat.buesser@ie.ibm.com",
    "beat_buesser",
    "irina_nicolae",
    "irinutza.n@gmail.com"
  ],
  "kwds": "adversarial_threats_art adversarial adversarial_threats_attacker robustness badge",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_adversarial_robustness_toolbox",
  "homepage": "https://github.com/trusted-ai/adversarial-robustness-toolbox",
  "release_count": 56,
  "dependency_ids": [
    "pypi_catboost",
    "pypi_cma",
    "pypi_ffmpeg_python",
    "pypi_gpy",
    "pypi_h5py",
    "pypi_keras",
    "pypi_kornia",
    "pypi_librosa",
    "pypi_lightgbm",
    "pypi_lingvo",
    "pypi_matplotlib",
    "pypi_multiprocess",
    "pypi_mxnet",
    "pypi_numba",
    "pypi_numpy",
    "pypi_opencv_python",
    "pypi_pandas",
    "pypi_pillow",
    "pypi_pydub",
    "pypi_pytest",
    "pypi_pytest_cov",
    "pypi_pytest_flake8",
    "pypi_pytest_mock",
    "pypi_requests",
    "pypi_resampy",
    "pypi_scikit_learn",
    "pypi_scipy",
    "pypi_setuptools",
    "pypi_six",
    "pypi_sortedcontainers",
    "pypi_sphinx",
    "pypi_sphinx_autodoc_annotation",
    "pypi_sphinx_autodoc_typehints",
    "pypi_sphinx_rtd_theme",
    "pypi_statsmodels",
    "pypi_tensorflow",
    "pypi_tensorflow_addons",
    "pypi_tensorflow_gpu",
    "pypi_timm",
    "pypi_torch",
    "pypi_torchaudio",
    "pypi_torchvision",
    "pypi_tqdm",
    "pypi_xgboost"
  ]
}