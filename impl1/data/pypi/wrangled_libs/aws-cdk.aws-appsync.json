{
  "classifiers": [
    "development status :: 7 - inactive",
    "framework :: aws cdk",
    "framework :: aws cdk :: 1",
    "intended audience :: developers",
    "license :: osi approved",
    "operating system :: os independent",
    "programming language :: javascript",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "typing :: typed"
  ],
  "description": "# aws appsync construct library\n\n<!--begin stability banner-->---\n\n\n![end-of-support](https://img.shields.io/badge/end--of--support-critical.svg?style=for-the-badge)\n\n> aws cdk v1 has reached end-of-support on 2023-06-01.\n> this package is no longer being updated, and users should migrate to aws cdk v2.\n>\n> for more information on how to migrate, see the [*migrating to aws cdk v2* guide](https://docs.aws.amazon.com/cdk/v2/guide/migrating-v2.html).\n\n---\n<!--end stability banner-->\n\nthe `@aws-cdk/aws-appsync` package contains constructs for building flexible\napis that use graphql.\n\n```python\nimport aws_cdk.aws_appsync as appsync\n```\n\n## example\n\n### dynamodb\n\nexample of a graphql api with `aws_iam` [authorization](#authorization) resolving into a dynamodb\nbackend data source.\n\ngraphql schema file `schema.graphql`:\n\n```gql\ntype demo {\n  id: string!\n  version: string!\n}\ntype query {\n  getdemos: [ demo! ]\n}\ninput demoinput {\n  version: string!\n}\ntype mutation {\n  adddemo(input: demoinput!): demo\n}\n```\n\ncdk stack file `app-stack.ts`:\n\n```python\napi = appsync.graphqlapi(self, \"api\",\n    name=\"demo\",\n    schema=appsync.schema.from_asset(path.join(__dirname, \"schema.graphql\")),\n    authorization_config=appsync.authorizationconfig(\n        default_authorization=appsync.authorizationmode(\n            authorization_type=appsync.authorizationtype.iam\n        )\n    ),\n    xray_enabled=true\n)\n\ndemo_table = dynamodb.table(self, \"demotable\",\n    partition_key=dynamodb.attribute(\n        name=\"id\",\n        type=dynamodb.attributetype.string\n    )\n)\n\ndemo_ds = api.add_dynamo_db_data_source(\"demodatasource\", demo_table)\n\n# resolver for the query \"getdemos\" that scans the dynamodb table and returns the entire list.\ndemo_ds.create_resolver(\n    type_name=\"query\",\n    field_name=\"getdemos\",\n    request_mapping_template=appsync.mappingtemplate.dynamo_db_scan_table(),\n    response_mapping_template=appsync.mappingtemplate.dynamo_db_result_list()\n)\n\n# resolver for the mutation \"adddemo\" that puts the item into the dynamodb table.\ndemo_ds.create_resolver(\n    type_name=\"mutation\",\n    field_name=\"adddemo\",\n    request_mapping_template=appsync.mappingtemplate.dynamo_db_put_item(\n        appsync.primarykey.partition(\"id\").auto(),\n        appsync.values.projecting(\"input\")),\n    response_mapping_template=appsync.mappingtemplate.dynamo_db_result_item()\n)\n```\n\n### aurora serverless\n\nappsync provides a data source for executing sql commands against amazon aurora\nserverless clusters. you can use appsync resolvers to execute sql statements\nagainst the data api with graphql queries, mutations, and subscriptions.\n\n```python\n# build a data source for appsync to access the database.\n# api: appsync.graphqlapi\n# create username and password secret for db cluster\nsecret = rds.databasesecret(self, \"aurorasecret\",\n    username=\"clusteradmin\"\n)\n\n# the vpc to place the cluster in\nvpc = ec2.vpc(self, \"auroravpc\")\n\n# create the serverless cluster, provide all values needed to customise the database.\ncluster = rds.serverlesscluster(self, \"auroracluster\",\n    engine=rds.databaseclusterengine.aurora_mysql,\n    vpc=vpc,\n    credentials={\"username\": \"clusteradmin\"},\n    cluster_identifier=\"db-endpoint-test\",\n    default_database_name=\"demos\"\n)\nrds_ds = api.add_rds_data_source(\"rds\", cluster, secret, \"demos\")\n\n# set up a resolver for an rds query.\nrds_ds.create_resolver(\n    type_name=\"query\",\n    field_name=\"getdemosrds\",\n    request_mapping_template=appsync.mappingtemplate.from_string(\"\"\"\n          {\n            \"version\": \"2018-05-29\",\n            \"statements\": [\n              \"select * from demos\"\n            ]\n          }\n          \"\"\"),\n    response_mapping_template=appsync.mappingtemplate.from_string(\"\"\"\n            $utils.tojson($utils.rds.tojsonobject($ctx.result)[0])\n          \"\"\")\n)\n\n# set up a resolver for an rds mutation.\nrds_ds.create_resolver(\n    type_name=\"mutation\",\n    field_name=\"adddemords\",\n    request_mapping_template=appsync.mappingtemplate.from_string(\"\"\"\n          {\n            \"version\": \"2018-05-29\",\n            \"statements\": [\n              \"insert into demos values (:id, :version)\",\n              \"select * where id = :id\"\n            ],\n            \"variablemap\": {\n              \":id\": $util.tojson($util.autoid()),\n              \":version\": $util.tojson($ctx.args.version)\n            }\n          }\n          \"\"\"),\n    response_mapping_template=appsync.mappingtemplate.from_string(\"\"\"\n            $utils.tojson($utils.rds.tojsonobject($ctx.result)[1][0])\n          \"\"\")\n)\n```\n\n### http endpoints\n\ngraphql schema file `schema.graphql`:\n\n```gql\ntype job {\n  id: string!\n  version: string!\n}\n\ninput demoinput {\n  version: string!\n}\n\ntype mutation {\n  callstepfunction(input: demoinput!): job\n}\n```\n\ngraphql request mapping template `request.vtl`:\n\n```json\n{\n  \"version\": \"2018-05-29\",\n  \"method\": \"post\",\n  \"resourcepath\": \"/\",\n  \"params\": {\n    \"headers\": {\n      \"content-type\": \"application/x-amz-json-1.0\",\n      \"x-amz-target\":\"awsstepfunctions.startexecution\"\n    },\n    \"body\": {\n      \"statemachinearn\": \"<your step functions arn>\",\n      \"input\": \"{ \\\"id\\\": \\\"$context.arguments.id\\\" }\"\n    }\n  }\n}\n```\n\ngraphql response mapping template `response.vtl`:\n\n```json\n{\n  \"id\": \"${context.result.id}\"\n}\n```\n\ncdk stack file `app-stack.ts`:\n\n```python\napi = appsync.graphqlapi(self, \"api\",\n    name=\"api\",\n    schema=appsync.schema.from_asset(path.join(__dirname, \"schema.graphql\"))\n)\n\nhttp_ds = api.add_http_data_source(\"ds\", \"https://states.amazonaws.com\",\n    name=\"httpdswithstepf\",\n    description=\"from appsync to stepfunctions workflow\",\n    authorization_config=appsync.awsiamconfig(\n        signing_region=\"us-east-1\",\n        signing_service_name=\"states\"\n    )\n)\n\nhttp_ds.create_resolver(\n    type_name=\"mutation\",\n    field_name=\"callstepfunction\",\n    request_mapping_template=appsync.mappingtemplate.from_file(\"request.vtl\"),\n    response_mapping_template=appsync.mappingtemplate.from_file(\"response.vtl\")\n)\n```\n\n### amazon opensearch service\n\nappsync has builtin support for amazon opensearch service (successor to amazon\nelasticsearch service) from domains that are provisioned through your aws account. you can\nuse appsync resolvers to perform graphql operations such as queries, mutations, and\nsubscriptions.\n\n```python\nimport aws_cdk.aws_opensearchservice as opensearch\n\n# api: appsync.graphqlapi\n\n\nuser = iam.user(self, \"user\")\ndomain = opensearch.domain(self, \"domain\",\n    version=opensearch.engineversion.opensearch_1_2,\n    removal_policy=removalpolicy.destroy,\n    fine_grained_access_control=opensearch.advancedsecurityoptions(master_user_arn=user.user_arn),\n    encryption_at_rest=opensearch.encryptionatrestoptions(enabled=true),\n    node_to_node_encryption=true,\n    enforce_https=true\n)\nds = api.add_open_search_data_source(\"ds\", domain)\n\nds.create_resolver(\n    type_name=\"query\",\n    field_name=\"gettests\",\n    request_mapping_template=appsync.mappingtemplate.from_string(json.stringify({\n        \"version\": \"2017-02-28\",\n        \"operation\": \"get\",\n        \"path\": \"/id/post/_search\",\n        \"params\": {\n            \"headers\": {},\n            \"query_string\": {},\n            \"body\": {\"from\": 0, \"size\": 50}\n        }\n    })),\n    response_mapping_template=appsync.mappingtemplate.from_string(\"\"\"[\n            #foreach($entry in $context.result.hits.hits)\n            #if( $velocitycount > 1 ) , #end\n            $utils.tojson($entry.get(\"_source\"))\n            #end\n          ]\"\"\")\n)\n```\n\n## custom domain names\n\nfor many use cases you may want to associate a custom domain name with your\ngraphql api. this can be done during the api creation.\n\n```python\nimport aws_cdk.aws_certificatemanager as acm\nimport aws_cdk.aws_route53 as route53\n\n# hosted zone and route53 features\n# hosted_zone_id: str\nzone_name = \"example.com\"\n\n\nmy_domain_name = \"api.example.com\"\ncertificate = acm.certificate(self, \"cert\", domain_name=my_domain_name)\napi = appsync.graphqlapi(self, \"api\",\n    name=\"myapi\",\n    domain_name=appsync.domainoptions(\n        certificate=certificate,\n        domain_name=my_domain_name\n    )\n)\n\n# hosted zone for adding appsync domain\nzone = route53.hostedzone.from_hosted_zone_attributes(self, \"hostedzone\",\n    hosted_zone_id=hosted_zone_id,\n    zone_name=zone_name\n)\n\n# create a cname to the appsync domain. will map to something like xxxx.cloudfront.net\nroute53.cnamerecord(self, \"cnameapirecord\",\n    record_name=\"api\",\n    zone=zone,\n    domain_name=my_domain_name\n)\n```\n\n## schema\n\nevery graphql api needs a schema to define the api. cdk offers `appsync.schema`\nfor static convenience methods for various types of schema declaration: code-first\nor schema-first.\n\n### code-first\n\nwhen declaring your graphql api, cdk defaults to a code-first approach if the\n`schema` property is not configured.\n\n```python\napi = appsync.graphqlapi(self, \"api\", name=\"myapi\")\n```\n\ncdk will declare a `schema` class that will give your api access functions to\ndefine your schema code-first: `addtype`, `addtoschema`, etc.\n\nyou can also declare your `schema` class outside of your cdk stack, to define\nyour schema externally.\n\n```python\nschema = appsync.schema()\nschema.add_type(appsync.objecttype(\"demo\",\n    definition={\"id\": appsync.graphqltype.id()}\n))\napi = appsync.graphqlapi(self, \"api\",\n    name=\"myapi\",\n    schema=schema\n)\n```\n\nsee the [code-first schema](#code-first-schema) section for more details.\n\n### schema-first\n\nyou can define your graphql schema from a file on disk. for convenience, use\nthe `appsync.schema.fromasset` to specify the file representing your schema.\n\n```python\napi = appsync.graphqlapi(self, \"api\",\n    name=\"myapi\",\n    schema=appsync.schema.from_asset(path.join(__dirname, \"schema.graphl\"))\n)\n```\n\n## imports\n\nany graphql api that has been created outside the stack can be imported from\nanother stack into your cdk app. utilizing the `fromxxx` function, you have\nthe ability to add data sources and resolvers through a `igraphqlapi` interface.\n\n```python\n# api: appsync.graphqlapi\n# table: dynamodb.table\n\nimported_api = appsync.graphqlapi.from_graphql_api_attributes(self, \"iapi\",\n    graphql_api_id=api.api_id,\n    graphql_api_arn=api.arn\n)\nimported_api.add_dynamo_db_data_source(\"tabledatasource\", table)\n```\n\nif you don't specify `graphqlarn` in `fromxxxattributes`, cdk will autogenerate\nthe expected `arn` for the imported api, given the `apiid`. for creating data\nsources and resolvers, an `apiid` is sufficient.\n\n## authorization\n\nthere are multiple authorization types available for graphql api to cater to different\naccess use cases. they are:\n\n* api keys (`authorizationtype.api_key`)\n* amazon cognito user pools (`authorizationtype.user_pool`)\n* openid connect (`authorizationtype.openid_connect`)\n* aws identity and access management (`authorizationtype.aws_iam`)\n* aws lambda (`authorizationtype.aws_lambda`)\n\nthese types can be used simultaneously in a single api, allowing different types of clients to\naccess data. when you specify an authorization type, you can also specify the corresponding\nauthorization mode to finish defining your authorization. for example, this is a graphql api\nwith aws lambda authorization.\n\n```python\nimport aws_cdk.aws_lambda as lambda_\n# auth_function: lambda.function\n\n\nappsync.graphqlapi(self, \"api\",\n    name=\"api\",\n    schema=appsync.schema.from_asset(path.join(__dirname, \"appsync.test.graphql\")),\n    authorization_config=appsync.authorizationconfig(\n        default_authorization=appsync.authorizationmode(\n            authorization_type=appsync.authorizationtype.lambda,\n            lambda_authorizer_config=appsync.lambdaauthorizerconfig(\n                handler=auth_function\n            )\n        )\n    )\n)\n```\n\n## permissions\n\nwhen using `aws_iam` as the authorization type for graphql api, an iam role\nwith correct permissions must be used for access to api.\n\nwhen configuring permissions, you can specify specific resources to only be\naccessible by `iam` authorization. for example, if you want to only allow mutability\nfor `iam` authorized access you would configure the following.\n\nin `schema.graphql`:\n\n```gql\ntype mutation {\n  updateexample(...): ...\n    @aws_iam\n}\n```\n\nin `iam`:\n\n```json\n{\n  \"version\": \"2012-10-17\",\n  \"statement\": [\n    {\n      \"effect\": \"allow\",\n      \"action\": [\n        \"appsync:graphql\"\n      ],\n      \"resource\": [\n        \"arn:aws:appsync:region:account_id:apis/graphql_id/types/mutation/fields/updateexample\"\n      ]\n    }\n  ]\n}\n```\n\nsee [documentation](https://docs.aws.amazon.com/appsync/latest/devguide/security.html#aws-iam-authorization) for more details.\n\nto make this easier, cdk provides `grant` api.\n\nuse the `grant` function for more granular authorization.\n\n```python\n# api: appsync.graphqlapi\nrole = iam.role(self, \"role\",\n    assumed_by=iam.serviceprincipal(\"lambda.amazonaws.com\")\n)\n\napi.grant(role, appsync.iamresource.custom(\"types/mutation/fields/updateexample\"), \"appsync:graphql\")\n```\n\n### iamresource\n\nin order to use the `grant` functions, you need to use the class `iamresource`.\n\n* `iamresource.custom(...arns)` permits custom arns and requires an argument.\n* `iamresouce.oftype(type, ...fields)` permits arns for types and their fields.\n* `iamresource.all()` permits all resources.\n\n### generic permissions\n\nalternatively, you can use more generic `grant` functions to accomplish the same usage.\n\nthese include:\n\n* grantmutation (use to grant access to mutation fields)\n* grantquery (use to grant access to query fields)\n* grantsubscription (use to grant access to subscription fields)\n\n```python\n# api: appsync.graphqlapi\n# role: iam.role\n\n\n# for generic types\napi.grant_mutation(role, \"updateexample\")\n\n# for custom types and granular design\napi.grant(role, appsync.iamresource.of_type(\"mutation\", \"updateexample\"), \"appsync:graphql\")\n```\n\n## pipeline resolvers and appsync functions\n\nappsync functions are local functions that perform certain operations onto a\nbackend data source. developers can compose operations (functions) and execute\nthem in sequence with pipeline resolvers.\n\n```python\n# api: appsync.graphqlapi\n\n\nappsync_function = appsync.appsyncfunction(self, \"function\",\n    name=\"appsync_function\",\n    api=api,\n    data_source=api.add_none_data_source(\"none\"),\n    request_mapping_template=appsync.mappingtemplate.from_file(\"request.vtl\"),\n    response_mapping_template=appsync.mappingtemplate.from_file(\"response.vtl\")\n)\n```\n\nappsync functions are used in tandem with pipeline resolvers to compose multiple\noperations.\n\n```python\n# api: appsync.graphqlapi\n# appsync_function: appsync.appsyncfunction\n\n\npipeline_resolver = appsync.resolver(self, \"pipeline\",\n    api=api,\n    data_source=api.add_none_data_source(\"none\"),\n    type_name=\"typename\",\n    field_name=\"fieldname\",\n    request_mapping_template=appsync.mappingtemplate.from_file(\"beforerequest.vtl\"),\n    pipeline_config=[appsync_function],\n    response_mapping_template=appsync.mappingtemplate.from_file(\"afterresponse.vtl\")\n)\n```\n\nlearn more about pipeline resolvers and appsync functions [here](https://docs.aws.amazon.com/appsync/latest/devguide/pipeline-resolvers.html).\n\n## code-first schema\n\ncdk offers the ability to generate your schema in a code-first approach.\na code-first approach offers a developer workflow with:\n\n* **modularity**: organizing schema type definitions into different files\n* **reusability**: simplifying down boilerplate/repetitive code\n* **consistency**: resolvers and schema definition will always be synced\n\nthe code-first approach allows for **dynamic** schema generation. you can generate your schema based on variables and templates to reduce code duplication.\n\n### code-first example\n\nto showcase the code-first approach. let's try to model the following schema segment.\n\n```gql\ninterface node {\n  id: string\n}\n\ntype query {\n  allfilms(after: string, first: int, before: string, last: int): filmconnection\n}\n\ntype filmnode implements node {\n  filmname: string\n}\n\ntype filmconnection {\n  edges: [filmedge]\n  films: [film]\n  totalcount: int\n}\n\ntype filmedge {\n  node: film\n  cursor: string\n}\n```\n\nabove we see a schema that allows for generating paginated responses. for example,\nwe can query `allfilms(first: 100)` since `filmconnection` acts as an intermediary\nfor holding `filmedges` we can write a resolver to return the first 100 films.\n\nin a separate file, we can declare our object types and related functions.\nwe will call this file `object-types.ts` and we will have created it in a way that\nallows us to generate other `xxxconnection` and `xxxedges` in the future.\n\n```python\nimport aws_cdk.aws_appsync as appsync\npluralize = require(\"pluralize\")\n\nargs = {\n    \"after\": appsync.graphqltype.string(),\n    \"first\": appsync.graphqltype.int(),\n    \"before\": appsync.graphqltype.string(),\n    \"last\": appsync.graphqltype.int()\n}\n\nnode = appsync.interfacetype(\"node\",\n    definition={\"id\": appsync.graphqltype.string()}\n)\nfilmnode = appsync.objecttype(\"filmnode\",\n    interface_types=[node],\n    definition={\"film_name\": appsync.graphqltype.string()}\n)\n\ndef generate_edge_and_connection(base):\n    edge = appsync.objecttype(f\"{base.name}edge\",\n        definition={\"node\": base.attribute(), \"cursor\": appsync.graphqltype.string()}\n    )\n    connection = appsync.objecttype(f\"{base.name}connection\",\n        definition={\n            \"edges\": edge.attribute(is_list=true),\n            \"pluralize(base.name)\": base.attribute(is_list=true),\n            \"total_count\": appsync.graphqltype.int()\n        }\n    )\n    return {\"edge\": edge, \"connection\": connection}\n```\n\nfinally, we will go to our `cdk-stack` and combine everything together\nto generate our schema.\n\n```python\n# dummy_request: appsync.mappingtemplate\n# dummy_response: appsync.mappingtemplate\n\n\napi = appsync.graphqlapi(self, \"api\",\n    name=\"demo\"\n)\n\nobject_types = [node, filmnode]\n\nfilm_connections = generate_edge_and_connection(filmnode)\n\napi.add_query(\"allfilms\", appsync.resolvablefield(\n    return_type=film_connections.connection.attribute(),\n    args=args,\n    data_source=api.add_none_data_source(\"none\"),\n    request_mapping_template=dummy_request,\n    response_mapping_template=dummy_response\n))\n\napi.add_type(node)\napi.add_type(filmnode)\napi.add_type(film_connections.edge)\napi.add_type(film_connections.connection)\n```\n\nnotice how we can utilize the `generateedgeandconnection` function to generate\nobject types. in the future, if we wanted to create more object types, we can simply\ncreate the base object type (i.e. film) and from there we can generate its respective\n`connections` and `edges`.\n\ncheck out a more in-depth example [here](https://github.com/bryanpan342/starwars-code-first).\n\n## graphql types\n\none of the benefits of graphql is its strongly typed nature. we define the\ntypes within an object, query, mutation, interface, etc. as **graphql types**.\n\ngraphql types are the building blocks of types, whether they are scalar, objects,\ninterfaces, etc. graphql types can be:\n\n* [**scalar types**](https://docs.aws.amazon.com/appsync/latest/devguide/scalars.html): id, int, string, awsdate, etc.\n* [**object types**](#object-types): types that you generate (i.e. `demo` from the example above)\n* [**interface types**](#interface-types): abstract types that define the base implementation of other\n  intermediate types\n\nmore concretely, graphql types are simply the types appended to variables.\nreferencing the object type `demo` in the previous example, the graphql types\nis `string!` and is applied to both the names `id` and `version`.\n\n### directives\n\n`directives` are attached to a field or type and affect the execution of queries,\nmutations, and types. with appsync, we use `directives` to configure authorization.\ncdk provides static functions to add directives to your schema.\n\n* `directive.iam()` sets a type or field's authorization to be validated through `iam`\n* `directive.apikey()` sets a type or field's authorization to be validated through a `api key`\n* `directive.oidc()` sets a type or field's authorization to be validated through `openid connect`\n* `directive.cognito(...groups: string[])` sets a type or field's authorization to be validated\n  through `cognito user pools`\n\n  * `groups` the name of the cognito groups to give access\n\nto learn more about authorization and directives, read these docs [here](https://docs.aws.amazon.com/appsync/latest/devguide/security.html).\n\n### field and resolvable fields\n\nwhile `graphqltype` is a base implementation for graphql fields, we have abstractions\non top of `graphqltype` that provide finer grain support.\n\n### field\n\n`field` extends `graphqltype` and will allow you to define arguments. [**interface types**](#interface-types) are not resolvable and this class will allow you to define arguments,\nbut not its resolvers.\n\nfor example, if we want to create the following type:\n\n```gql\ntype node {\n  test(argument: string): string\n}\n```\n\nthe cdk code required would be:\n\n```python\nfield = appsync.field(\n    return_type=appsync.graphqltype.string(),\n    args={\n        \"argument\": appsync.graphqltype.string()\n    }\n)\ntype = appsync.interfacetype(\"node\",\n    definition={\"test\": field}\n)\n```\n\n### resolvable fields\n\n`resolvablefield` extends `field` and will allow you to define arguments and its resolvers.\n[**object types**](#object-types) can have fields that resolve and perform operations on\nyour backend.\n\nyou can also create resolvable fields for object types.\n\n```gql\ntype info {\n  node(id: string): string\n}\n```\n\nthe cdk code required would be:\n\n```python\n# api: appsync.graphqlapi\n# dummy_request: appsync.mappingtemplate\n# dummy_response: appsync.mappingtemplate\n\ninfo = appsync.objecttype(\"info\",\n    definition={\n        \"node\": appsync.resolvablefield(\n            return_type=appsync.graphqltype.string(),\n            args={\n                \"id\": appsync.graphqltype.string()\n            },\n            data_source=api.add_none_data_source(\"none\"),\n            request_mapping_template=dummy_request,\n            response_mapping_template=dummy_response\n        )\n    }\n)\n```\n\nto nest resolvers, we can also create top level query types that call upon\nother types. building off the previous example, if we want the following graphql\ntype definition:\n\n```gql\ntype query {\n  get(argument: string): info\n}\n```\n\nthe cdk code required would be:\n\n```python\n# api: appsync.graphqlapi\n# dummy_request: appsync.mappingtemplate\n# dummy_response: appsync.mappingtemplate\n\nquery = appsync.objecttype(\"query\",\n    definition={\n        \"get\": appsync.resolvablefield(\n            return_type=appsync.graphqltype.string(),\n            args={\n                \"argument\": appsync.graphqltype.string()\n            },\n            data_source=api.add_none_data_source(\"none\"),\n            request_mapping_template=dummy_request,\n            response_mapping_template=dummy_response\n        )\n    }\n)\n```\n\nlearn more about fields and resolvers [here](https://docs.aws.amazon.com/appsync/latest/devguide/resolver-mapping-template-reference-overview.html).\n\n### intermediate types\n\nintermediate types are defined by graphql types and fields. they have a set of defined\nfields, where each field corresponds to another type in the system. intermediate\ntypes will be the meat of your graphql schema as they are the types defined by you.\n\nintermediate types include:\n\n* [**interface types**](#interface-types)\n* [**object types**](#object-types)\n* [**enum types**](#enum-types)\n* [**input types**](#input-types)\n* [**union types**](#union-types)\n\n#### interface types\n\n**interface types** are abstract types that define the implementation of other\nintermediate types. they are useful for eliminating duplication and can be used\nto generate object types with less work.\n\nyou can create interface types ***externally***.\n\n```python\nnode = appsync.interfacetype(\"node\",\n    definition={\n        \"id\": appsync.graphqltype.string(is_required=true)\n    }\n)\n```\n\nto learn more about **interface types**, read the docs [here](https://graphql.org/learn/schema/#interfaces).\n\n#### object types\n\n**object types** are types that you declare. for example, in the [code-first example](#code-first-example)\nthe `demo` variable is an **object type**. **object types** are defined by\ngraphql types and are only usable when linked to a graphql api.\n\nyou can create object types in two ways:\n\n1. object types can be created ***externally***.\n\n   ```python\n   api = appsync.graphqlapi(self, \"api\",\n       name=\"demo\"\n   )\n   demo = appsync.objecttype(\"demo\",\n       definition={\n           \"id\": appsync.graphqltype.string(is_required=true),\n           \"version\": appsync.graphqltype.string(is_required=true)\n       }\n   )\n\n   api.add_type(demo)\n   ```\n\n   > this method allows for reusability and modularity, ideal for larger projects.\n   > for example, imagine moving all object type definition outside the stack.\n\n   `object-types.ts` - a file for object type definitions\n\n   ```python\n   import aws_cdk.aws_appsync as appsync\n   demo = appsync.objecttype(\"demo\",\n       definition={\n           \"id\": appsync.graphqltype.string(is_required=true),\n           \"version\": appsync.graphqltype.string(is_required=true)\n       }\n   )\n   ```\n\n   `cdk-stack.ts` - a file containing our cdk stack\n\n   ```python\n   # api: appsync.graphqlapi\n\n   api.add_type(demo)\n   ```\n2. object types can be created ***externally*** from an interface type.\n\n   ```python\n   node = appsync.interfacetype(\"node\",\n       definition={\n           \"id\": appsync.graphqltype.string(is_required=true)\n       }\n   )\n   demo = appsync.objecttype(\"demo\",\n       interface_types=[node],\n       definition={\n           \"version\": appsync.graphqltype.string(is_required=true)\n       }\n   )\n   ```\n\n   > this method allows for reusability and modularity, ideal for reducing code duplication.\n\nto learn more about **object types**, read the docs [here](https://graphql.org/learn/schema/#object-types-and-fields).\n\n#### enum types\n\n**enum types** are a special type of intermediate type. they restrict a particular\nset of allowed values for other intermediate types.\n\n```gql\nenum episode {\n  newhope\n  empire\n  jedi\n}\n```\n\n> this means that wherever we use the type episode in our schema, we expect it to\n> be exactly one of newhope, empire, or jedi.\n\nthe above graphql enumeration type can be expressed in cdk as the following:\n\n```python\n# api: appsync.graphqlapi\n\nepisode = appsync.enumtype(\"episode\",\n    definition=[\"newhope\", \"empire\", \"jedi\"\n    ]\n)\napi.add_type(episode)\n```\n\nto learn more about **enum types**, read the docs [here](https://graphql.org/learn/schema/#enumeration-types).\n\n#### input types\n\n**input types** are special types of intermediate types. they give users an\neasy way to pass complex objects for top level mutation and queries.\n\n```gql\ninput review {\n  stars: int!\n  commentary: string\n}\n```\n\nthe above graphql input type can be expressed in cdk as the following:\n\n```python\n# api: appsync.graphqlapi\n\nreview = appsync.inputtype(\"review\",\n    definition={\n        \"stars\": appsync.graphqltype.int(is_required=true),\n        \"commentary\": appsync.graphqltype.string()\n    }\n)\napi.add_type(review)\n```\n\nto learn more about **input types**, read the docs [here](https://graphql.org/learn/schema/#input-types).\n\n#### union types\n\n**union types** are a special type of intermediate type. they are similar to\ninterface types, but they cannot specify any common fields between types.\n\n**note:** the fields of a union type need to be `object types`. in other words, you\ncan't create a union type out of interfaces, other unions, or inputs.\n\n```gql\nunion search = human | droid | starship\n```\n\nthe above graphql union type encompasses the object types of human, droid and starship. it\ncan be expressed in cdk as the following:\n\n```python\n# api: appsync.graphqlapi\n\nstring = appsync.graphqltype.string()\nhuman = appsync.objecttype(\"human\", definition={\"name\": string})\ndroid = appsync.objecttype(\"droid\", definition={\"name\": string})\nstarship = appsync.objecttype(\"starship\", definition={\"name\": string})\nsearch = appsync.uniontype(\"search\",\n    definition=[human, droid, starship]\n)\napi.add_type(search)\n```\n\nto learn more about **union types**, read the docs [here](https://graphql.org/learn/schema/#union-types).\n\n### query\n\nevery schema requires a top level query type. by default, the schema will look\nfor the `object type` named `query`. the top level `query` is the **only** exposed\ntype that users can access to perform `get` operations on your api.\n\nto add fields for these queries, we can simply run the `addquery` function to add\nto the schema's `query` type.\n\n```python\n# api: appsync.graphqlapi\n# film_connection: appsync.interfacetype\n# dummy_request: appsync.mappingtemplate\n# dummy_response: appsync.mappingtemplate\n\n\nstring = appsync.graphqltype.string()\nint = appsync.graphqltype.int()\napi.add_query(\"allfilms\", appsync.resolvablefield(\n    return_type=film_connection.attribute(),\n    args={\"after\": string, \"first\": int, \"before\": string, \"last\": int},\n    data_source=api.add_none_data_source(\"none\"),\n    request_mapping_template=dummy_request,\n    response_mapping_template=dummy_response\n))\n```\n\nto learn more about top level operations, check out the docs [here](https://docs.aws.amazon.com/appsync/latest/devguide/graphql-overview.html).\n\n### mutation\n\nevery schema **can** have a top level mutation type. by default, the schema will look\nfor the `objecttype` named `mutation`. the top level `mutation` type is the only exposed\ntype that users can access to perform `mutable` operations on your api.\n\nto add fields for these mutations, we can simply run the `addmutation` function to add\nto the schema's `mutation` type.\n\n```python\n# api: appsync.graphqlapi\n# film_node: appsync.objecttype\n# dummy_request: appsync.mappingtemplate\n# dummy_response: appsync.mappingtemplate\n\n\nstring = appsync.graphqltype.string()\nint = appsync.graphqltype.int()\napi.add_mutation(\"addfilm\", appsync.resolvablefield(\n    return_type=film_node.attribute(),\n    args={\"name\": string, \"film_number\": int},\n    data_source=api.add_none_data_source(\"none\"),\n    request_mapping_template=dummy_request,\n    response_mapping_template=dummy_response\n))\n```\n\nto learn more about top level operations, check out the docs [here](https://docs.aws.amazon.com/appsync/latest/devguide/graphql-overview.html).\n\n### subscription\n\nevery schema **can** have a top level subscription type. the top level `subscription` type\nis the only exposed type that users can access to invoke a response to a mutation. `subscriptions`\nnotify users when a mutation specific mutation is called. this means you can make any data source\nreal time by specify a graphql schema directive on a mutation.\n\n**note**: the aws appsync client sdk automatically handles subscription connection management.\n\nto add fields for these subscriptions, we can simply run the `addsubscription` function to add\nto the schema's `subscription` type.\n\n```python\n# api: appsync.graphqlapi\n# film: appsync.interfacetype\n\n\napi.add_subscription(\"addedfilm\", appsync.field(\n    return_type=film.attribute(),\n    args={\"id\": appsync.graphqltype.id(is_required=true)},\n    directives=[appsync.directive.subscribe(\"addfilm\")]\n))\n```\n\nto learn more about top level operations, check out the docs [here](https://docs.aws.amazon.com/appsync/latest/devguide/real-time-data.html).\n",
  "docs_url": null,
  "keywords": "",
  "license": "apache-2.0",
  "name": "aws-cdk.aws-appsync",
  "package_url": "https://pypi.org/project/aws-cdk.aws-appsync/",
  "project_url": "https://pypi.org/project/aws-cdk.aws-appsync/",
  "project_urls": {
    "Homepage": "https://github.com/aws/aws-cdk",
    "Source": "https://github.com/aws/aws-cdk.git"
  },
  "release_url": "https://pypi.org/project/aws-cdk.aws-appsync/1.204.0/",
  "requires_dist": [
    "aws-cdk.aws-certificatemanager (==1.204.0)",
    "aws-cdk.aws-cognito (==1.204.0)",
    "aws-cdk.aws-dynamodb (==1.204.0)",
    "aws-cdk.aws-ec2 (==1.204.0)",
    "aws-cdk.aws-elasticsearch (==1.204.0)",
    "aws-cdk.aws-iam (==1.204.0)",
    "aws-cdk.aws-lambda (==1.204.0)",
    "aws-cdk.aws-opensearchservice (==1.204.0)",
    "aws-cdk.aws-rds (==1.204.0)",
    "aws-cdk.aws-s3-assets (==1.204.0)",
    "aws-cdk.aws-secretsmanager (==1.204.0)",
    "aws-cdk.core (==1.204.0)",
    "constructs (<4.0.0,>=3.3.69)",
    "jsii (<2.0.0,>=1.84.0)",
    "publication (>=0.0.3)",
    "typeguard (~=2.13.3)"
  ],
  "requires_python": "~=3.7",
  "summary": "the cdk construct library for aws::appsync",
  "version": "1.204.0",
  "releases": [],
  "developers": [
    "amazon_web_services"
  ],
  "kwds": "aws_appsync aws_cdk from_graphql_api_attributes aws_lambda graphql_api_arn",
  "license_kwds": "apache-2.0",
  "libtype": "pypi",
  "id": "pypi_aws_cdk.aws_appsync",
  "homepage": "https://github.com/aws/aws-cdk",
  "release_count": 258,
  "dependency_ids": [
    "pypi_aws_cdk.aws_certificatemanager",
    "pypi_aws_cdk.aws_cognito",
    "pypi_aws_cdk.aws_dynamodb",
    "pypi_aws_cdk.aws_ec2",
    "pypi_aws_cdk.aws_elasticsearch",
    "pypi_aws_cdk.aws_iam",
    "pypi_aws_cdk.aws_lambda",
    "pypi_aws_cdk.aws_opensearchservice",
    "pypi_aws_cdk.aws_rds",
    "pypi_aws_cdk.aws_s3_assets",
    "pypi_aws_cdk.aws_secretsmanager",
    "pypi_aws_cdk.core",
    "pypi_constructs",
    "pypi_jsii",
    "pypi_publication",
    "pypi_typeguard"
  ]
}