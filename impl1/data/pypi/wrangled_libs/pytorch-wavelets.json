{
  "classifiers": [
    "development status :: 3 - alpha",
    "license :: free to use but restricted",
    "programming language :: python :: 3"
  ],
  "description": "2d wavelet transforms in pytorch\r\n================================\r\n\r\n|build-status| |docs| |doi|\r\n\r\n.. |build-status| image:: https://travis-ci.org/fbcotter/pytorch_wavelets.png?branch=master\r\n    :alt: build status\r\n    :scale: 100%\r\n    :target: https://travis-ci.org/fbcotter/pytorch_wavelets\r\n\r\n.. |docs| image:: https://readthedocs.org/projects/pytorch-wavelets/badge/?version=latest\r\n    :target: https://pytorch-wavelets.readthedocs.io/en/latest/?badge=latest\r\n    :alt: documentation status\r\n\r\n.. |doi| image:: https://zenodo.org/badge/146817005.svg\r\n   :target: https://zenodo.org/badge/latestdoi/146817005\r\n   \r\nthe full documentation is also available `here`__.\r\n\r\n__ http://pytorch-wavelets.readthedocs.io/\r\n\r\nthis package provides support for computing the 2d discrete wavelet and \r\nthe 2d dual-tree complex wavelet transforms, their inverses, and passing \r\ngradients through both using pytorch.\r\n\r\nthe implementation is designed to be used with batches of multichannel images.\r\nwe use the standard pytorch implementation of having 'nchw' data format.\r\n\r\nwe also have added layers to do the 2-d dtcwt based scatternet. this is similar\r\nto the morlet based scatternet in `kymatio`__, but is roughly 10 times faster.\r\n\r\nif you use this repo, please cite my phd thesis, chapter 3: https://doi.org/10.17863/cam.53748.\r\n\r\n__ https://github.com/kymatio/kymatio\r\n\r\nnew in version 1.3.0\r\n~~~~~~~~~~~~~~~~~~~~\r\n\r\n- added 1d dwt support\r\n\r\n.. code:: python\r\n\r\n    import torch\r\n    from pytorch_wavelets import dwt1dforward, dwt1dinverse  # or simply dwt1d, idwt1d\r\n    dwt = dwt1dforward(wave='db6', j=3)\r\n    x = torch.randn(10, 5, 100)\r\n    yl, yh = dwt(x)\r\n    print(yl.shape)\r\n    >>> torch.size([10, 5, 22])\r\n    print(yh[0].shape)\r\n    >>> torch.size([10, 5, 55])\r\n    print(yh[1].shape)\r\n    >>> torch.size([10, 5, 33])\r\n    print(yh[2].shape)\r\n    >>> torch.size([10, 5, 22])\r\n    idwt = dwt1dinverse(wave='db6')\r\n    x = idwt((yl, yh))\r\n\r\nnew in version 1.2.0\r\n~~~~~~~~~~~~~~~~~~~~\r\n\r\n- added a dtcwt based scatternet\r\n\r\n.. code:: python\r\n\r\n    import torch\r\n    from pytorch_wavelets import scatlayer\r\n    scat = scatlayer()\r\n    x = torch.randn(10,5,64,64)\r\n    # a first order scatternet with 6 orientations and one lowpass channels\r\n    # gives 7 times the input channel dimension\r\n    z = scat(x)\r\n    print(z.shape)\r\n    >>> torch.size([10, 35, 32, 32])\r\n    # a second order scatternet with 6 orientations and one lowpass channels\r\n    # gives 7^2 times the input channel dimension\r\n    scat2 = torch.nn.sequential(scatlayer(), scatlayer())\r\n    z = scat2(x)\r\n    print(z.shape)\r\n    >>> torch.size([10, 245, 16, 16])\r\n    # we also have a slightly more specialized, but slower, second order scatternet\r\n    from pytorch_wavelets import scatlayerj2\r\n    scat2a = scatlayerj2()\r\n    z = scat2a(x)\r\n    print(z.shape)\r\n    >>> torch.size([10, 245, 16, 16])\r\n    # these all of course work with cuda\r\n    scat2a.cuda()\r\n    z = scat2a(x.cuda())\r\n\r\nnew in version 1.1.0\r\n~~~~~~~~~~~~~~~~~~~~\r\n\r\n- fixed memory problem with dwt \r\n- fixed the backend code for the dtcwt calculation - much cleaner now but similar performance\r\n- both dtcwt and dwt should be more memory efficient/aware now. \r\n- removed need to specify number of scales for dtcwtinverse\r\n\r\nnew in version 1.0.0\r\n~~~~~~~~~~~~~~~~~~~~\r\nversion 1.0.0 has now added support for separable dwt calculation, and more\r\npadding schemes, such as symmetric, zero and periodization.\r\n\r\nalso, no longer need to specify the number of channels when creating the wavelet\r\ntransform classes.\r\n\r\nspeed tests\r\n~~~~~~~~~~~\r\nwe compare doing the dtcwt with the python package and doing the dwt with\r\npywavelets to doing both in pytorch_wavelets, using a gtx1080. the numpy methods\r\nwere run on a 14 core xeon phi machine using intel's parallel python. for the\r\ndtwcwt we use the `near_sym_a` filters for the first scale and the `qshift_a`\r\nfilters for subsequent scales. for the dwt we use the `db4` filters.\r\n\r\nfor a fixed input size, but varying the number of scales (from 1 to 4) we have\r\nthe following speeds (averaged over 5 runs):\r\n\r\n.. image:: docs/scale.png\r\n\r\nfor an input size with height and width 512 by 512, we also vary the batch size\r\nfor a 3 scale transform. the resulting speeds were:\r\n\r\n.. image:: docs/batchsize.png\r\n\r\ninstallation\r\n````````````\r\nthe easiest way to install ``pytorch_wavelets`` is to clone the repo and pip install\r\nit. later versions will be released on pypi but the docs need to updated first::\r\n\r\n    $ git clone https://github.com/fbcotter/pytorch_wavelets\r\n    $ cd pytorch_wavelets\r\n    $ pip install .\r\n\r\n(although the `develop` command may be more useful if you intend to perform any\r\nsignificant modification to the library.) a test suite is provided so that you\r\nmay verify the code works on your system::\r\n\r\n    $ pip install -r tests/requirements.txt\r\n    $ pytest tests/\r\n\r\nexample use\r\n```````````\r\nfor the dwt - note that the highpass output has an extra dimension, in which we\r\nstack the (lh, hl, hh) coefficients.  also note that the yh output has the\r\nfinest detail coefficients first, and the coarsest last (the opposite to\r\npywavelets).\r\n\r\n.. code:: python\r\n\r\n    import torch\r\n    from pytorch_wavelets import dwtforward, dwtinverse\r\n    xfm = dwtforward(j=3, wave='db3', mode='zero')\r\n    x = torch.randn(10,5,64,64)\r\n    yl, yh = xfm(x) \r\n    print(yl.shape)\r\n    >>> torch.size([10, 5, 12, 12])\r\n    print(yh[0].shape) \r\n    >>> torch.size([10, 5, 3, 34, 34])\r\n    print(yh[1].shape)\r\n    >>> torch.size([10, 5, 3, 19, 19])\r\n    print(yh[2].shape)\r\n    >>> torch.size([10, 5, 3, 12, 12])\r\n    ifm = dwtinverse(wave='db3', mode='zero')\r\n    y = ifm((yl, yh))\r\n\r\nfor the dtcwt:\r\n\r\n.. code:: python\r\n\r\n    import torch\r\n    from pytorch_wavelets import dtcwtforward, dtcwtinverse\r\n    xfm = dtcwtforward(j=3, biort='near_sym_b', qshift='qshift_b')\r\n    x = torch.randn(10,5,64,64)\r\n    yl, yh = xfm(x) \r\n    print(yl.shape)\r\n    >>> torch.size([10, 5, 16, 16])\r\n    print(yh[0].shape) \r\n    >>> torch.size([10, 5, 6, 32, 32, 2])\r\n    print(yh[1].shape)\r\n    >>> torch.size([10, 5, 6, 16, 16, 2])\r\n    print(yh[2].shape)\r\n    >>> torch.size([10, 5, 6, 8, 8, 2])\r\n    ifm = dtcwtinverse(biort='near_sym_b', qshift='qshift_b')\r\n    y = ifm((yl, yh))\r\n\r\nsome initial notes:\r\n\r\n- yh returned is a tuple. there are 2 extra dimensions - the first comes between\r\n  the channel dimension of the input and the row dimension. this is the\r\n  6 orientations of the dtcwt. the second is the final dimension, which is the\r\n  real an imaginary parts (complex numbers are not native to pytorch)\r\n\r\nrunning on the gpu\r\n~~~~~~~~~~~~~~~~~~\r\nthis should come as no surprise to pytorch users. the dwt and dtcwt transforms support\r\ncuda calling:\r\n\r\n.. code:: python\r\n\r\n    import torch\r\n    from pytorch_wavelets import dtcwtforward, dtcwtinverse\r\n    xfm = dtcwtforward(j=3, biort='near_sym_b', qshift='qshift_b').cuda()\r\n    x = torch.randn(10,5,64,64).cuda()\r\n    yl, yh = xfm(x) \r\n    ifm = dtcwtinverse(biort='near_sym_b', qshift='qshift_b').cuda()\r\n    y = ifm((yl, yh))\r\n\r\nthe automated tests cannot test the gpu functionality, but do check cpu running.\r\nto test whether the repo is working on your gpu, you can download the repo,\r\nensure you have pytorch with cuda enabled (the tests will check to see if\r\n:code:`torch.cuda.is_available()` returns true), and run:\r\n\r\n.. code:: \r\n\r\n    pip install -r tests/requirements.txt\r\n    pytest tests/\r\n\r\nfrom the base of the repo.\r\n\r\nbackpropagation\r\n~~~~~~~~~~~~~~~\r\nit is possible to pass gradients through the forward and backward transforms.\r\nall you need to do is ensure that the input to each has the required_grad\r\nattribute set to true.\r\n\r\n\r\n\r\nprovenance\r\n~~~~~~~~~~\r\nbased on the dual-tree complex wavelet transform pack for matlab by nick\r\nkingsbury, cambridge university. the original readme can be found in\r\noriginal_readme.txt.  this file outlines the conditions of use of the original\r\nmatlab toolbox.\r\n\r\nfurther information on the dt cwt can be obtained from papers\r\ndownloadable from my website (given below). the best tutorial is in\r\nthe 1999 royal society paper. in particular this explains the conversion\r\nbetween 'real' quad-number subimages and pairs of complex subimages. \r\nthe q-shift filters are explained in the icip 2000 paper and in more detail\r\nin the may 2001 paper for the journal on applied and computational \r\nharmonic analysis.\r\n\r\nthis code is copyright and is supplied free of charge for research\r\npurposes only. in return for supplying the code, all i ask is that, if\r\nyou use the algorithms, you give due reference to this work in any\r\npapers that you write and that you let me know if you find any good\r\napplications for the dt cwt. if the applications are good, i would be\r\nvery interested in collaboration. i accept no liability arising from use\r\nof these algorithms.\r\n\r\nnick kingsbury, \r\ncambridge university, june 2003.\r\n\r\ndr n g kingsbury,\r\ndept. of engineering, university of cambridge,\r\ntrumpington st., cambridge cb2 1pz, uk., or\r\ntrinity college, cambridge cb2 1tq, uk.\r\nphone: (0 or +44) 1223 338514 / 332647;  home: 1954 211152;\r\nfax: 1223 338564 / 332662;  e-mail: ngk@eng.cam.ac.uk\r\nweb home page: http://www.eng.cam.ac.uk/~ngk/\r\n\r\n.. vim:sw=4:sts=4:et\r\n",
  "docs_url": null,
  "keywords": "pytorch,dwt,dtcwt,wavelet,complex wavelet",
  "license": "free to use",
  "name": "pytorch-wavelets",
  "package_url": "https://pypi.org/project/pytorch-wavelets/",
  "project_url": "https://pypi.org/project/pytorch-wavelets/",
  "project_urls": {
    "Homepage": "https://github.com/fbcotter/pytorch_wavelets"
  },
  "release_url": "https://pypi.org/project/pytorch-wavelets/1.3.0/",
  "requires_dist": [
    "numpy",
    "six",
    "torch",
    "sphinx ; extra == 'docs'",
    "docutils ; extra == 'docs'",
    "matplotlib ; extra == 'docs'",
    "ipython ; extra == 'docs'"
  ],
  "requires_python": "",
  "summary": "a port of the dtcwt toolbox to run on pytorch",
  "version": "1.3.0",
  "releases": [],
  "developers": [
    "fbc23@cam.ac.uk",
    "fergal_cotter"
  ],
  "kwds": "pytorch_wavelets wavelets wavelet pywavelets dtcwt",
  "license_kwds": "free to use",
  "libtype": "pypi",
  "id": "pypi_pytorch_wavelets",
  "homepage": "https://github.com/fbcotter/pytorch_wavelets",
  "release_count": 1,
  "dependency_ids": [
    "pypi_docutils",
    "pypi_ipython",
    "pypi_matplotlib",
    "pypi_numpy",
    "pypi_six",
    "pypi_sphinx",
    "pypi_torch"
  ]
}