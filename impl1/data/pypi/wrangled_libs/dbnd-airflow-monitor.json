{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "license :: osi approved :: apache software license",
    "natural language :: english",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "programming language :: python :: implementation :: cpython",
    "programming language :: python :: implementation :: pypy",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "# databand airflow monitor\n\ndataband airflow monitor is a stand-alone module for databand system, enables you to load data from airflow server and import it into databand system.\nthis databand side module is one of two components allows you to sync your airflow data into databand system.\n\n## installation with setup tools\n\n```bash\ncd modules/dbnd-airflow-monitor\npip install -e .\n```\n\n## usage\n\n`dbnd airflow-monitor`\n\n### important flags\n\n`--sync-history`: by default, airflow monitor's `since` value will be determined by last time it was running. use this flag to enable syncning from beginning\n\n### configuration\n\nyou can configure your syncing variables inside databand configuration system\n\n```cfg\n[airflow_monitor]\ninterval = 10 ; time in seconds to wait between each fetching cycle\ninclude_logs = true ; whether or not to include logs (might be heavy)\ninclude_task_args = true ; whether or not to include task arguments\nfetch_quantity = 100 ; max number of tasks or dag runs to retrieve at each fetch\nfetch_period = 60 ; time in minutes for window fetching size (start: since, end: since + period)\ndag_ids = ['ingest_data_dag', 'simple_dag'] ; limit fetching to these specific dag ids\n\n## db fetcher\n### pay attention, when using this system airflow version must be equal to databand's airflow version\nsql_alchemy_conn = sqlite:////usr/local/airflow/airflow.db ; when using fetcher=db, use this sql connection string\nlocal_dag_folder =  /usr/local/airflow/dags ; when using fetcher=db, this is the dag folder location\n```\n\n## steps for google composer\n\n\u200b\nafter spinning new google composer, under pypi packages add dbnd, and add `dbnd__core__databand_url` env pointing to dnbd instance, copy plugin file to pluings folder (go to dags folder, one level up, and then plugins)\n\u200b\n\u200b\nfor monitor to work you will need to setup service account (add relevant binding):\n(taken from here: https://medium.com/google-cloud/using-airflow-experimental-rest-api-on-google-cloud-platform-cloud-composer-and-iap-9bd0260f095a\nsee create a service account for post trigger section)\n\u200b\nexample with creating new sa:\n\n```bash\nexport project=prefab-root-227507\nexport service_account_name=dbnd-airflow-monitor\ngcloud iam service-accounts create $service_account_name --project $project\n# give service account permissions to create tokens for iap requests.\ngcloud projects add-iam-policy-binding $project --member serviceaccount:$service_account_name@$project.iam.gserviceaccount.com --role roles/iam.serviceaccounttokencreator\ngcloud projects add-iam-policy-binding $project --member serviceaccount:$service_account_name@$project.iam.gserviceaccount.com --role roles/iam.serviceaccountactor\n# service account also needs to be authorized to use composer.\ngcloud projects add-iam-policy-binding $project --member serviceaccount:$service_account_name@$project.iam.gserviceaccount.com --role roles/composer.user\n# we need a service account key to trigger the dag.\ngcloud iam service-accounts keys create ~/$project-$service_account_name-key.json --iam-account=$service_account_name@$project.iam.gserviceaccount.com\nexport google_application_credentials=~/$project-$service_account_name-key.json\n```\n\n\u200b\nconfigure airflow monitor with composer fetcher, with url pointing to composer airflow instance and client id (same article, getting airflow client id section):\nvisit the airflow url https://your_unique_id.appspot.com (which you noted in the last step) in an incognito window, don\u2019t login. at this first landing page for iap auth has client id in the url in the address bar:\n\n```\nhttps://accounts.google.com/signin/oauth/identifier?client_id=00000000000-xxxx0x0xx0xx00xxxx0x00xxx0xxxxx.apps.googleusercontent.com&...\n```\n\n## integration tests\n\nwe have 2 tests:\n\n-   databand/integration-tests/airflow_monitor\n-   databand/integration-tests/airflow_monitor_stress\n\nto run them, go to the right dir and run inttest container:\n\n```\ncd databand/integration-tests/airflow_monitor\ndocker-compose up inttest\n```\n",
  "docs_url": null,
  "keywords": "orchestration,data,machinelearning",
  "license": "",
  "name": "dbnd-airflow-monitor",
  "package_url": "https://pypi.org/project/dbnd-airflow-monitor/",
  "project_url": "https://pypi.org/project/dbnd-airflow-monitor/",
  "project_urls": {
    "Bug-Tracker": "https://github.com/databand-ai/dbnd/issues",
    "Documentation": "https://dbnd.readme.io/",
    "Homepage": "https://github.com/databand-ai/dbnd",
    "Source-Code": "https://github.com/databand-ai/dbnd"
  },
  "release_url": "https://pypi.org/project/dbnd-airflow-monitor/1.0.20.3/",
  "requires_dist": [
    "dbnd (==1.0.20.3)",
    "setuptools",
    "prometheus-client",
    "PyJWT (==2.4.0) ; extra == 'composer'",
    "cryptography (==37.0.2) ; extra == 'composer'",
    "google-auth (==1.10.0) ; extra == 'composer'",
    "requests (==2.22.0) ; extra == 'composer'",
    "requests-toolbelt (==0.9.1) ; extra == 'composer'",
    "tzlocal (>=1.5.1) ; extra == 'composer'",
    "pytest ; extra == 'tests'",
    "mock ; extra == 'tests'",
    "sh ; extra == 'tests'"
  ],
  "requires_python": "",
  "summary": "machine learning orchestration",
  "version": "1.0.20.3",
  "releases": [],
  "developers": [
    "evgeny.shulman@databand.ai",
    "evgeny_shulman"
  ],
  "kwds": "airflow_monitor airflow_monitor_stress airflow databand syncning",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_dbnd_airflow_monitor",
  "homepage": "https://github.com/databand-ai/dbnd",
  "release_count": 421,
  "dependency_ids": [
    "pypi_cryptography",
    "pypi_dbnd",
    "pypi_google_auth",
    "pypi_mock",
    "pypi_prometheus_client",
    "pypi_pyjwt",
    "pypi_pytest",
    "pypi_requests",
    "pypi_requests_toolbelt",
    "pypi_setuptools",
    "pypi_sh",
    "pypi_tzlocal"
  ]
}