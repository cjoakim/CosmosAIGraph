{
  "classifiers": [],
  "description": "[![pypi version](https://badge.fury.io/py/numcompress.svg)](https://badge.fury.io/py/numcompress) [![build status](https://travis-ci.org/amit1rrr/numcompress.svg?branch=master)](https://travis-ci.org/amit1rrr/numcompress)  [![coverage status](https://coveralls.io/repos/github/amit1rrr/numcompress/badge.svg)](https://coveralls.io/github/amit1rrr/numcompress)\n\n# numcompress\nsimple way to compress and decompress numerical series & numpy arrays.\n- easily gets you above 80% compression ratio\n- you can specify the precision you need for floating points (up to 10 decimal points)\n- useful to store or transmit stock prices, monitoring data & other time series data in compressed string format\n\ncompression algorithm is based on [google encoded polyline format](https://developers.google.com/maps/documentation/utilities/polylinealgorithm). i modified it to preserve arbitrary precision and apply it to any numerical series. the work is motivated by usefulness of [time aware polyline](https://www.hypertrack.com/blog/2016/09/01/the-missing-dimension-in-geospatial-data-formats/) built by [arjun attam](https://github.com/arjun27) at [hypertrack](https://github.com/hypertrack/time-aware-polyline-py).\nafter building this i came across [arrays](https://docs.python.org/3/library/array.html) that are much efficient than lists in terms memory footprint. you might consider using that over numcompress if you don't care about conversion to string for transmitting or storing purpose.\n\n# installation\n```\npip install numcompress\n```\n\n# usage\n```python\nfrom numcompress import compress, decompress\n\n# integers\n>>> compress([14578, 12759, 13525])\n'b_twxznv_nb_bwm@'\n\n>>> decompress('b_twxznv_nb_bwm@')\n[14578.0, 12759.0, 13525.0]\n```\n\n```python\n# floats - lossless compression\n# precision argument specifies how many decimal points to preserve, defaults to 3\n>>> compress([145.7834, 127.5989, 135.2569], precision=4)\n'csi~wahdbjgqtc'\n\n>>> decompress('csi~wahdbjgqtc')\n[145.7834, 127.5989, 135.2569]\n```\n```python\n# floats - lossy compression\n>>> compress([145.7834, 127.5989, 135.2569], precision=2)\n'acn[rpb{n@'\n\n>>> decompress('acn[rpb{n@')\n[145.78, 127.6, 135.26]\n```\n```python\n# compressing and decompressing numpy arrays\n>>> from numcompress import compress_ndarray, decompress_ndarray\n>>> import numpy as np\n\n>>> series = np.random.randint(1, 100, 25).reshape(5, 5)\n>>> compressed_series = compress_ndarray(series)\n>>> decompressed_series = decompress_ndarray(compressed_series)\n\n>>> series\narray([[29, 95, 10, 48, 20],\n       [60, 98, 73, 96, 71],\n       [95, 59,  8,  6, 17],\n       [ 5, 12, 69, 65, 52],\n       [84,  6, 83, 20, 50]])\n\n>>> compressed_series\n'5*5,bosw@_|_cn_ed_fia~tu@_cma_fianyo@o|k@nyo@_{m@~heanrbb~{bont~lvotloinb~xfnkx_o}@~iwcokucn`zb_ry@'\n\n>>> decompressed_series\narray([[29., 95., 10., 48., 20.],\n       [60., 98., 73., 96., 71.],\n       [95., 59.,  8.,  6., 17.],\n       [ 5., 12., 69., 65., 52.],\n       [84.,  6., 83., 20., 50.]])\n\n>>> (series == decompressed_series).all()\ntrue\n```\n\n\n# compression ratio\n\n| test          | # of numbers          | compression ratio |\n| ------------- |-------------- |---------------------------|\n| [integers](https://github.com/amit1rrr/numcompress/blob/master/test/test_numcompress.py#l29)    | 10k | **91.14%** |\n| [floats](https://github.com/amit1rrr/numcompress/blob/master/test/test_numcompress.py#l49)      | 10k | **81.35%** |\n\nyou can run the test suite with -s switch to see the compression ratio. you can even modify the tests to see what kind of compression ratio you will get for your own input.\n```\npytest -s\n```\n\nhere's a quick example showing compression ratio:\n\n```python\n>>> series = random.sample(range(1, 100000), 50000)  # generate 50k random numbers between 1 and 100k\n>>> text = compress(series)  # apply compression\n\n>>> original_size = sum(sys.getsizeof(i) for i in series)\n>>> original_size\n1200000\n\n>>> compressed_size = sys.getsizeof(text)\n>>> compressed_size\n284092\n\n>>> compression_ratio = ((original_size - compressed_size) * 100.0) / original_size\n>>> compression_ratio\n76.32566666666666\n```\n\nwe get ~76% compression for 50k random numbers between 1 & 100k. this ratio increases for real world numerical series as the difference between consecutive numbers tends to be lower. think of stock prices, monitoring & other time series data.\n\n\n# contribute\nif you see any problem, open an issue or send a pull request. you can write to [me](https://blog.amirathi.com/about/) at [amit.juschill@gmail.com](mailto:amit.juschill@gmail.com)\n\n\n",
  "docs_url": null,
  "keywords": "compression,numerical,numbers into text",
  "license": "mit",
  "name": "numcompress",
  "package_url": "https://pypi.org/project/numcompress/",
  "project_url": "https://pypi.org/project/numcompress/",
  "project_urls": {
    "Homepage": "https://github.com/amit1rrr/numcompress"
  },
  "release_url": "https://pypi.org/project/numcompress/0.1.2/",
  "requires_dist": [
    "numpy"
  ],
  "requires_python": "",
  "summary": "python package to convert numerical series & numpy arrays into compressed strings",
  "version": "0.1.2",
  "releases": [],
  "developers": [
    "amit.juschill@gmail.com",
    "amit_rathi"
  ],
  "kwds": "compress_ndarray compressed_series compression_ratio compressed compression",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_numcompress",
  "homepage": "https://github.com/amit1rrr/numcompress",
  "release_count": 2,
  "dependency_ids": [
    "pypi_numpy"
  ]
}