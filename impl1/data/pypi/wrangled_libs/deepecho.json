{
  "classifiers": [
    "development status :: 2 - pre-alpha",
    "intended audience :: developers",
    "license :: free for non-commercial use",
    "natural language :: english",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: scientific/engineering :: artificial intelligence"
  ],
  "description": "<div align=\"center\">\n<br/>\n<p align=\"center\">\n    <i>this repository is part of <a href=\"https://sdv.dev\">the synthetic data vault project</a>, a project from <a href=\"https://datacebo.com\">datacebo</a>.</i>\n</p>\n\n[![development status](https://img.shields.io/badge/development%20status-2%20--%20pre--alpha-yellow)](https://pypi.org/search/?c=development+status+%3a%3a+2+-+pre-alpha)\n[![pypi shield](https://img.shields.io/pypi/v/deepecho.svg)](https://pypi.python.org/pypi/deepecho)\n[![tests](https://github.com/sdv-dev/deepecho/workflows/run%20tests/badge.svg)](https://github.com/sdv-dev/deepecho/actions?query=workflow%3a%22run+tests%22+branch%3amain)\n[![downloads](https://pepy.tech/badge/deepecho)](https://pepy.tech/project/deepecho)\n[![coverage status](https://codecov.io/gh/sdv-dev/deepecho/branch/main/graph/badge.svg)](https://codecov.io/gh/sdv-dev/deepecho)\n[![binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sdv-dev/deepecho/main?filepath=tutorials/timeseries_data)\n[![slack](https://img.shields.io/badge/slack%20workspace-join%20now!-36c5f0?logo=slack)](https://bit.ly/sdv-slack-invite)\n\n<div align=\"left\">\n<br/>\n<p align=\"center\">\n<a href=\"https://github.com/sdv-dev/deepecho\">\n<img align=\"center\" width=40% src=\"https://github.com/sdv-dev/sdv/blob/stable/docs/images/deepecho-datacebo.png\"></img>\n</a>\n</p>\n</div>\n\n</div>\n\n# overview\n\n**deepecho** is a **synthetic data generation** python library for **mixed-type**, **multivariate\ntime series**. it provides:\n\n1. multiple models based both on **classical statistical modeling** of time series and the latest\n   in **deep learning** techniques.\n2. a robust [benchmarking framework](https://github.com/sdv-dev/sdgym) for evaluating these methods\n   on multiple datasets and with multiple metrics.\n3. ability for **machine learning researchers** to submit new methods following our `model` and\n   `sample` api and get evaluated.\n\n| important links                               |                                                                      |\n| --------------------------------------------- | -------------------------------------------------------------------- |\n| :computer: **[website]**                      | check out the sdv website for more information about the project.    |\n| :orange_book: **[sdv blog]**                  | regular publshing of useful content about synthetic data generation. |\n| :book: **[documentation]**                    | quickstarts, user and development guides, and api reference.         |\n| :octocat: **[repository]**                    | the link to the github repository of this library.                   |\n| :keyboard: **[development status]**           | this software is in its pre-alpha stage.                             |\n| [![][slack logo] **community**][community]    | join our slack workspace for announcements and discussions.          |\n| [![][mybinder logo] **tutorials**][tutorials] | run the sdv tutorials in a binder environment.                       |\n\n[website]: https://sdv.dev\n[sdv blog]: https://sdv.dev/blog\n[documentation]: https://sdv.dev/sdv\n[repository]: https://github.com/sdv-dev/deepecho\n[license]: https://github.com/sdv-dev/deepecho/blob/main/license\n[development status]: https://pypi.org/search/?c=development+status+%3a%3a+2+-+pre-alpha\n[slack logo]: https://github.com/sdv-dev/sdv/blob/stable/docs/images/slack.png\n[community]: https://bit.ly/sdv-slack-invite\n[mybinder logo]: https://github.com/sdv-dev/sdv/blob/stable/docs/images/mybinder.png\n[tutorials]: https://mybinder.org/v2/gh/sdv-dev/deepecho/main?filepath=tutorials\n\n# install\n\n**deepecho** is part of the **sdv** project and is automatically installed alongside it. for\ndetails about this process please visit the [sdv installation guide](\nhttps://sdv.dev/sdv/getting_started/install.html)\n\noptionally, **deepecho** can also be installed as a standalone library using the following commands:\n\n**using `pip`:**\n\n```bash\npip install deepecho\n```\n\n**using `conda`:**\n\n```bash\nconda install -c pytorch -c conda-forge deepecho\n```\n\nfor more installation options please visit the [deepecho installation guide](install.md)\n\n# quickstart\n\n**deepecho** is included as part of [sdv](https://sdv.dev/sdv) to model and sample synthetic\ntime series. in most cases, usage through sdv is recommeded, since it provides additional\nfunctionalities which are not available here. for more details about how to use deepecho\nwhithin sdv, please visit the corresponding user guide:\n\n* [sdv timeseries user guide](https://sdv.dev/sdv/user_guides/timeseries/par.html)\n\n## standalone usage\n\n**deepecho** can also be used as a standalone library.\n\nin this short quickstart, we show how to learn a mixed-type multivariate time series\ndataset and then generate synthetic data that resembles it.\n\nwe will start by loading the data and preparing the instance of our model.\n\n```python3\nfrom deepecho import parmodel\nfrom deepecho.demo import load_demo\n\n# load demo data\ndata = load_demo()\n\n# define data types for all the columns\ndata_types = {\n    'region': 'categorical',\n    'day_of_week': 'categorical',\n    'total_sales': 'continuous',\n    'nb_customers': 'count',\n}\n\nmodel = parmodel(cuda=false)\n```\n\nif we want to use different settings for our model, like increasing the number\nof epochs or enabling cuda, we can pass the arguments when creating the model:\n\n```python  # keep this as python (without the 3) to avoid using it in test-readme\nmodel = parmodel(epochs=1024, cuda=true)\n```\n\nnotice that for smaller datasets like the one used on this demo, cuda usage introduces\nmore overhead than the gains it obtains from parallelization, so the process in this\ncase is more efficient without cuda, even if it is available.\n\nonce we have created our instance, we are ready to learn the data and generate\nnew synthetic data that resembles it:\n\n```python3\n# learn a model from the data\nmodel.fit(\n    data=data,\n    entity_columns=['store_id'],\n    context_columns=['region'],\n    data_types=data_types,\n    sequence_index='date'\n)\n\n# sample new data\nmodel.sample(num_entities=5)\n```\n\nthe output will be a table with synthetic time series data with the same properties to\nthe demo data that we used as input.\n\n# what's next?\n\nfor more details about **deepecho** and all its possibilities and features, please check and\nrun the [tutorials](tutorials).\n\nif you want to see how we evaluate the performance and quality of our models, please have a\nlook at the [sdgym benchmarking framework](https://github.com/sdv-dev/sdgym).\n\nalso, please feel welcome to visit [our contributing guide](contributing.rst) in order to help\nus developing new features or cool ideas!\n\n---\n\n\n<div align=\"center\">\n<a href=\"https://datacebo.com\"><img align=\"center\" width=40% src=\"https://github.com/sdv-dev/sdv/blob/stable/docs/images/datacebo.png\"></img></a>\n</div>\n<br/>\n<br/>\n\n[the synthetic data vault project](https://sdv.dev) was first created at mit's [data to ai lab](\nhttps://dai.lids.mit.edu/) in 2016. after 4 years of research and traction with enterprise, we\ncreated [datacebo](https://datacebo.com) in 2020 with the goal of growing the project.\ntoday, datacebo is the proud developer of sdv, the largest ecosystem for\nsynthetic data generation & evaluation. it is home to multiple libraries that support synthetic\ndata, including:\n\n* \ud83d\udd04 data discovery & transformation. reverse the transforms to reproduce realistic data.\n* \ud83e\udde0 multiple machine learning models -- ranging from copulas to deep learning -- to create tabular,\n  multi table and time series data.\n* \ud83d\udcca measuring quality and privacy of synthetic data, and comparing different synthetic data\n  generation models.\n\n[get started using the sdv package](https://sdv.dev/sdv/getting_started/install.html) -- a fully\nintegrated solution and your one-stop shop for synthetic data. or, use the standalone libraries\nfor specific needs.\n\n\n# history\n\n## 0.5.0 - 2023-11-13\n\nthis release updates the par's model progress bar to show loss values and time elapsed (verbose option).\n\n### new features\n* update progress bar for par fitting - issue [#80](https://github.com/sdv-dev/deepecho/issues/80) by @frances-h\n\n\n## 0.4.2 - 2023-07-25\n\nthis release drops support for python 3.7 and adds support for python 3.11.\n\n### maintenance\n\n* add support for python 3.11 - issue [#74](https://github.com/sdv-dev/deepecho/issues/74) by @fealho\n* drop support for python 3.7 - issue [#75](https://github.com/sdv-dev/deepecho/issues/75) by @r-palazzo\n\n## 0.4.1 - 2023-05-02\n\nthis release adds support for pandas 2.0 and pytorch 2.0!\n\n### maintenance\n\n* remove upper bound for pandas - issue [#69](https://github.com/sdv-dev/deepecho/issues/69) by @frances-h\n* upgrade to torch 2.0 - issue [#70](https://github.com/sdv-dev/deepecho/issues/70) by @frances-h\n\n## 0.4.0 - 2023-01-10\n\nthis release adds support for python 3.10 and 3.11. it also drops support for python 3.6.\n\n### maintenance\n\n* support python 3.10 and 3.11 - issue [#63](https://github.com/sdv-dev/deepecho/issues/63) by @pvk-developer\n* deepecho package maintenance updates - issue [#62](https://github.com/sdv-dev/deepecho/issues/62) by @pvk-developer\n\n## 0.3.0 - 2021-11-15\n\nthis release adds support for python 3.9 and updates dependencies to ensure compatibility with the rest\nof the sdv ecosystem.\n\n* add support for python 3.9 - issue [#41](https://github.com/sdv-dev/deepecho/issues/41) by @fealho\n* add pip check to ci workflows internal improvements - issue [#39](https://github.com/sdv-dev/deepecho/issues/39) by @pvk-developer\n* add support for pylint>2.7.2 housekeeping - issue [#33](https://github.com/sdv-dev/deepecho/issues/33) by @fealho\n* add support for torch>=1.8 housekeeping - issue [#32](https://github.com/sdv-dev/deepecho/issues/32) by @fealho\n\n## 0.2.1 - 2021-10-12\n\nthis release fixes a bug with how deepecho handles nan values.\n\n* handling nan's bug - issue [#35](https://github.com/sdv-dev/deepecho/issues/35) by @fealho\n\n## 0.2.0 - 2021-02-24\n\nmaintenance release to update dependencies and ensure compatibility with the rest\nof the sdv ecosystem libraries.\n\n## 0.1.4 - 2020-10-16\n\nminor maintenance version to update dependencies and documentation, and\nalso make the demo data loading function parse dates properly.\n\n## 0.1.3 - 2020-10-16\n\nthis version includes several minor improvements to the par model and the\nway the sequences are generated:\n\n* sequences can now be generated without dropping the sequence index.\n* the par model learns the min and max length of the sequence from the input data.\n* nan values are properly supported for both categorical and numerical columns.\n* nan values are generated for numerical columns only if there were nans in the input data.\n* constant columns can now be modeled.\n\n## 0.1.2 - 2020-09-15\n\nadd basicgan model and additional benchmarking results.\n\n## 0.1.1 - 2020-08-15\n\nthis release includes a few new features to make deepecho work on more types of datasets\nas well as to making it easier to add new datasets to the benchmarking framework.\n\n* add `segment_size` and `sequence_index` arguments to `fit` method.\n* add `sequence_length` as an optional argument to `sample` and `sample_sequence` methods.\n* update the dataset storage format to add `sequence_index` and versioning.\n* separate the sequence assembling process in its own `deepecho.sequences` module.\n* add function `make_dataset` to create a dataset from a dataframe and just a few column names.\n* add notebook tutorial to show how to create a datasets and use them.\n\n## 0.1.0 - 2020-08-11\n\nfirst release.\n\nincluded features:\n\n* parmodel\n* demo dataset and tutorials\n* benchmarking framework\n* support and instructions for benchmarking on a kubernetes cluster.\n\n\n",
  "docs_url": null,
  "keywords": "deepecho deepecho deepecho",
  "license": "bsl-1.1",
  "name": "deepecho",
  "package_url": "https://pypi.org/project/deepecho/",
  "project_url": "https://pypi.org/project/deepecho/",
  "project_urls": {
    "Homepage": "https://github.com/sdv-dev/DeepEcho"
  },
  "release_url": "https://pypi.org/project/deepecho/0.5.0/",
  "requires_dist": [
    "tqdm <5,>=4.15",
    "numpy <2,>=1.20.0 ; python_version < \"3.10\"",
    "pandas >=1.1.3 ; python_version < \"3.10\"",
    "torch >=1.8.0 ; python_version < \"3.10\"",
    "numpy <2,>=1.23.3 ; python_version >= \"3.10\"",
    "pandas >=1.3.4 ; python_version >= \"3.10\" and python_version < \"3.11\"",
    "torch >=1.11.0 ; python_version >= \"3.10\" and python_version < \"3.11\"",
    "pandas >=1.5.0 ; python_version >= \"3.11\"",
    "torch >=2.0.0 ; python_version >= \"3.11\"",
    "setuptools <49.2 ; extra == 'dev'",
    "bumpversion <0.6,>=0.5.3 ; extra == 'dev'",
    "pip >=9.0.1 ; extra == 'dev'",
    "watchdog <0.11,>=0.8.3 ; extra == 'dev'",
    "flake8 <4,>=3.7.7 ; extra == 'dev'",
    "flake8-absolute-import <2,>=1.0 ; extra == 'dev'",
    "flake8-docstrings <2,>=1.5.0 ; extra == 'dev'",
    "flake8-sfs <0.1,>=0.0.3 ; extra == 'dev'",
    "isort <5,>=4.3.4 ; extra == 'dev'",
    "pylint <3,>=2.5.3 ; extra == 'dev'",
    "flake8-builtins <1.6,>=1.5.3 ; extra == 'dev'",
    "flake8-debugger <4.1,>=4.0.0 ; extra == 'dev'",
    "flake8-mock <0.4,>=0.3 ; extra == 'dev'",
    "dlint <0.12,>=0.11.0 ; extra == 'dev'",
    "flake8-eradicate <1.2,>=1.1.0 ; extra == 'dev'",
    "flake8-mutable <1.3,>=1.2.0 ; extra == 'dev'",
    "flake8-fixme <1.2,>=1.1.1 ; extra == 'dev'",
    "flake8-multiline-containers <0.1,>=0.0.18 ; extra == 'dev'",
    "flake8-quotes <4,>=3.3.0 ; extra == 'dev'",
    "flake8-variables-names <0.1,>=0.0.4 ; extra == 'dev'",
    "pep8-naming <0.13,>=0.12.1 ; extra == 'dev'",
    "flake8-expression-complexity <0.1,>=0.0.9 ; extra == 'dev'",
    "flake8-print <4.1,>=4.0.0 ; extra == 'dev'",
    "autoflake <2,>=1.1 ; extra == 'dev'",
    "autopep8 <1.6,>=1.4.3 ; extra == 'dev'",
    "twine <4,>=1.10.0 ; extra == 'dev'",
    "wheel >=0.30.0 ; extra == 'dev'",
    "coverage <6,>=4.5.1 ; extra == 'dev'",
    "tox <4,>=2.9.1 ; extra == 'dev'",
    "invoke ; extra == 'dev'",
    "pytest >=3.4.2 ; extra == 'dev'",
    "pytest-cov >=2.6.0 ; extra == 'dev'",
    "pytest-rerunfailures <10,>=9.0.0 ; extra == 'dev'",
    "jupyter <2,>=1.0.0 ; extra == 'dev'",
    "rundoc <0.5,>=0.4.3 ; extra == 'dev'",
    "pytest >=3.4.2 ; extra == 'test'",
    "pytest-cov >=2.6.0 ; extra == 'test'",
    "pytest-rerunfailures <10,>=9.0.0 ; extra == 'test'",
    "jupyter <2,>=1.0.0 ; extra == 'test'",
    "rundoc <0.5,>=0.4.3 ; extra == 'test'"
  ],
  "requires_python": ">=3.8,<3.12",
  "summary": "create sequential synthetic data of mixed types using a gan.",
  "version": "0.5.0",
  "releases": [],
  "developers": [
    "datacebo",
    "info@sdv.dev"
  ],
  "kwds": "vault deepecho links pypi pytorch",
  "license_kwds": "bsl-1.1",
  "libtype": "pypi",
  "id": "pypi_deepecho",
  "homepage": "https://github.com/sdv-dev/deepecho",
  "release_count": 22,
  "dependency_ids": [
    "pypi_autoflake",
    "pypi_autopep8",
    "pypi_bumpversion",
    "pypi_coverage",
    "pypi_dlint",
    "pypi_flake8",
    "pypi_flake8_absolute_import",
    "pypi_flake8_builtins",
    "pypi_flake8_debugger",
    "pypi_flake8_docstrings",
    "pypi_flake8_eradicate",
    "pypi_flake8_expression_complexity",
    "pypi_flake8_fixme",
    "pypi_flake8_mock",
    "pypi_flake8_multiline_containers",
    "pypi_flake8_mutable",
    "pypi_flake8_print",
    "pypi_flake8_quotes",
    "pypi_flake8_sfs",
    "pypi_flake8_variables_names",
    "pypi_invoke",
    "pypi_isort",
    "pypi_jupyter",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_pep8_naming",
    "pypi_pip",
    "pypi_pylint",
    "pypi_pytest",
    "pypi_pytest_cov",
    "pypi_pytest_rerunfailures",
    "pypi_rundoc",
    "pypi_setuptools",
    "pypi_torch",
    "pypi_tox",
    "pypi_tqdm",
    "pypi_twine",
    "pypi_watchdog",
    "pypi_wheel"
  ]
}