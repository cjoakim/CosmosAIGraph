{
  "classifiers": [
    "development status :: 4 - beta",
    "environment :: console",
    "framework :: pytest",
    "framework :: sphinx",
    "framework :: tox",
    "intended audience :: developers",
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "<!--\n<p align=\"center\">\n  <img src=\"docs/source/logo.png\" height=\"150\">\n</p>\n-->\n\n<h1 align=\"center\">\n  class resolver\n</h1>\n\n<p align=\"center\">\n    <a href=\"https://github.com/cthoyt/class-resolver/actions?query=workflow%3atests\">\n        <img alt=\"tests\" src=\"https://github.com/cthoyt/class-resolver/workflows/tests/badge.svg\" />\n    </a>\n    <a href=\"https://github.com/cthoyt/cookiecutter-python-package\">\n        <img alt=\"cookiecutter template from @cthoyt\" src=\"https://img.shields.io/badge/cookiecutter-snekpack-blue\" /> \n    </a>\n    <a href=\"https://pypi.org/project/class_resolver\">\n        <img alt=\"pypi\" src=\"https://img.shields.io/pypi/v/class_resolver\" />\n    </a>\n    <a href=\"https://pypi.org/project/class_resolver\">\n        <img alt=\"pypi - python version\" src=\"https://img.shields.io/pypi/pyversions/class_resolver\" />\n    </a>\n    <a href=\"https://github.com/cthoyt/class-resolver/blob/main/license\">\n        <img alt=\"pypi - license\" src=\"https://img.shields.io/pypi/l/class-resolver\" />\n    </a>\n    <a href='https://class_resolver.readthedocs.io/en/latest/?badge=latest'>\n        <img src='https://readthedocs.org/projects/class_resolver/badge/?version=latest' alt='documentation status' />\n    </a>\n    <a href=\"https://codecov.io/gh/cthoyt/class-resolver/branch/main\">\n        <img src=\"https://codecov.io/gh/cthoyt/class-resolver/branch/main/graph/badge.svg\" alt=\"codecov status\" />\n    </a>  \n    <a href=\"https://zenodo.org/badge/latestdoi/343741010\">\n        <img src=\"https://zenodo.org/badge/343741010.svg\" alt=\"doi\">\n    </a>\n    <a href=\"https://github.com/psf/black\">\n        <img src=\"https://img.shields.io/badge/code%20style-black-000000.svg\" alt=\"code style: black\" />\n    </a>\n</p>\n\nlookup and instantiate classes with style.\n\n## \ud83d\udcaa getting started\n\n```python\nfrom class_resolver import classresolver\nfrom dataclasses import dataclass\n\nclass base: pass\n\n@dataclass\nclass a(base):\n   name: str\n\n@dataclass\nclass b(base):\n   name: str\n\n# index\nresolver = classresolver([a, b], base=base)\n\n# lookup\nassert a == resolver.lookup('a')\n\n# instantiate with a dictionary\nassert a(name='hi') == resolver.make('a', {'name': 'hi'})\n\n# instantiate with kwargs\nassert a(name='hi') == resolver.make('a', name='hi')\n\n# a pre-instantiated class will simply be passed through\nassert a(name='hi') == resolver.make(a(name='hi'))\n```\n\n## \ud83e\udd16 writing extensible machine learning models with `class-resolver`\n\nassume you've implemented a simple multi-layer perceptron in pytorch:\n\n```python\nfrom itertools import chain\n\nfrom more_itertools import pairwise\nfrom torch import nn\n\nclass mlp(nn.sequential):\n    def __init__(self, dims: list[int]):\n        super().__init__(chain.from_iterable(\n            (\n                nn.linear(in_features, out_features),\n                nn.relu(),\n            )\n            for in_features, out_features in pairwise(dims)\n        ))\n```\n\nthis mlp uses a hard-coded rectified linear unit as the non-linear activation\nfunction between layers. we can generalize this mlp to use a variety of\nnon-linear activation functions by adding an argument to its\n`__init__()` function like in:\n\n```python\nfrom itertools import chain\n\nfrom more_itertools import pairwise\nfrom torch import nn\n\nclass mlp(nn.sequential):\n    def __init__(self, dims: list[int], activation: str = \"relu\"):\n        if activation == \"relu\":\n            activation = nn.relu()\n        elif activation == \"tanh\":\n            activation = nn.tanh()\n        elif activation == \"hardtanh\":\n            activation = nn.hardtanh()\n        else:\n            raise keyerror(f\"unsupported activation: {activation}\")\n        super().__init__(chain.from_iterable(\n            (\n                nn.linear(in_features, out_features),\n                activation,\n            )\n            for in_features, out_features in pairwise(dims)\n        ))\n```\n\nthe first issue with this implementation is it relies on a hard-coded set of\nconditional statements and is therefore hard to extend. it can be improved\nby using a dictionary lookup:\n\n```python\nfrom itertools import chain\n\nfrom more_itertools import pairwise\nfrom torch import nn\n\nactivation_lookup: dict[str, nn.module] = {\n   \"relu\": nn.relu(),\n   \"tanh\": nn.tanh(),\n   \"hardtanh\": nn.hardtanh(),\n}\n\nclass mlp(nn.sequential):\n    def __init__(self, dims: list[int], activation: str = \"relu\"):\n        activation = activation_lookup[activation]\n        super().__init__(chain.from_iterable(\n            (\n                nn.linear(in_features, out_features),\n                activation,\n            )\n            for in_features, out_features in pairwise(dims)\n        ))\n```\n\nthis approach is rigid because it requires pre-instantiation of the activations.\nif we needed to vary the arguments to the `nn.hardtanh` class, the previous\napproach wouldn't work. we can change the implementation to lookup on the \nclass *before instantiation* then optionally pass some arguments:\n\n```python\nfrom itertools import chain\n\nfrom more_itertools import pairwise\nfrom torch import nn\n\nactivation_lookup: dict[str, type[nn.module]] = {\n   \"relu\": nn.relu,\n   \"tanh\": nn.tanh,\n   \"hardtanh\": nn.hardtanh,\n}\n\nclass mlp(nn.sequential):\n    def __init__(\n        self, \n        dims: list[int], \n        activation: str = \"relu\", \n        activation_kwargs: none | dict[str, any] = none,\n    ):\n        activation_cls = activation_lookup[activation]\n        activation = activation_cls(**(activation_kwargs or {}))\n        super().__init__(chain.from_iterable(\n            (\n                nn.linear(in_features, out_features),\n                activation,\n            )\n            for in_features, out_features in pairwise(dims)\n        ))\n```\n\nthis is pretty good, but it still has a few issues:\n1. you have to manually maintain the `activation_lookup` dictionary,\n2. you can't pass an instance or class through the `activation` keyword\n3. you have to get the casing just right\n4. the default is hard-coded as a string, which means this has to get copied\n   (error-prone) in any place that creates an mlp\n5. you have to re-write this logic for all of your classes\n\nenter the `class_resolver` package, which takes care of all of these\nthings using the following:\n\n```python\nfrom itertools import chain\n\nfrom class_resolver import classresolver, hint\nfrom more_itertools import pairwise\nfrom torch import nn\n\nactivation_resolver = classresolver(\n    [nn.relu, nn.tanh, nn.hardtanh],\n    base=nn.module,\n    default=nn.relu,\n)\n\nclass mlp(nn.sequential):\n    def __init__(\n        self, \n        dims: list[int], \n        activation: hint[nn.module] = none,  # hint = union[none, str, nn.module, type[nn.module]]\n        activation_kwargs: none | dict[str, any] = none,\n    ):\n        super().__init__(chain.from_iterable(\n            (\n                nn.linear(in_features, out_features),\n                activation_resolver.make(activation, activation_kwargs),\n            )\n            for in_features, out_features in pairwise(dims)\n        ))\n```\n\nbecause this is such a common pattern, we've made it available through contrib\nmodule in `class_resolver.contrib.torch`:\n\n```python\nfrom itertools import chain\n\nfrom class_resolver import hint\nfrom class_resolver.contrib.torch import activation_resolver\nfrom more_itertools import pairwise\nfrom torch import nn\n\nclass mlp(nn.sequential):\n    def __init__(\n        self, \n        dims: list[int], \n        activation: hint[nn.module] = none,\n        activation_kwargs: none | dict[str, any] = none,\n    ):\n        super().__init__(chain.from_iterable(\n            (\n                nn.linear(in_features, out_features),\n                activation_resolver.make(activation, activation_kwargs),\n            )\n            for in_features, out_features in pairwise(dims)\n        ))\n```\n\nnow, you can instantiate the mlp with any of the following:\n\n```python\nmlp(dims=[10, 200, 40])  # uses default, which is relu\nmlp(dims=[10, 200, 40], activation=\"relu\")  # uses lowercase\nmlp(dims=[10, 200, 40], activation=\"relu\")  # uses stylized\nmlp(dims=[10, 200, 40], activation=nn.relu)  # uses class\nmlp(dims=[10, 200, 40], activation=nn.relu())  # uses instance\n\nmlp(dims=[10, 200, 40], activation=\"hardtanh\", activation_kwargs={\"min_val\": 0.0, \"max_value\": 6.0})  # uses kwargs\nmlp(dims=[10, 200, 40], activation=nn.hardtanh, activation_kwargs={\"min_val\": 0.0, \"max_value\": 6.0})  # uses kwargs\nmlp(dims=[10, 200, 40], activation=nn.hardtanh(0.0, 6.0))  # uses instance\n```\n\nin practice, it makes sense to stick to using the strings in combination with\nhyper-parameter optimization libraries like [optuna](https://optuna.org/).\n\n## \u2b07\ufe0f installation\n\nthe most recent release can be installed from\n[pypi](https://pypi.org/project/class_resolver/) with:\n\n```bash\n$ pip install class_resolver\n```\n\nthe most recent code and data can be installed directly from github with:\n\n```bash\n$ pip install git+https://github.com/cthoyt/class-resolver.git\n```\n\nto install in development mode, use the following:\n\n```bash\n$ git clone git+https://github.com/cthoyt/class-resolver.git\n$ cd class-resolver\n$ pip install -e .\n```\n\n## \ud83d\ude4f contributing\n\ncontributions, whether filing an issue, making a pull request, or forking, are appreciated. see\n[contributing.rst](https://github.com/cthoyt/class-resolver/blob/master/contributing.rst) for more\ninformation on getting involved.\n\n## \ud83d\udc4b attribution\n\n### \u2696\ufe0f license\n\nthe code in this package is licensed under the mit license.\n\n### \ud83c\udf6a cookiecutter\n\nthis package was created with [@audreyfeldroy](https://github.com/audreyfeldroy)'s\n[cookiecutter](https://github.com/cookiecutter/cookiecutter) package using [@cthoyt](https://github.com/cthoyt)'s\n[cookiecutter-snekpack](https://github.com/cthoyt/cookiecutter-snekpack) template.\n\n## \ud83d\udee0\ufe0f for developers\n\n<details>\n  <summary>see developer instructions</summary>\n\n\nthe final section of the readme is for if you want to get involved by making a code contribution.\n\n### \u2753 testing\n\nafter cloning the repository and installing `tox` with `pip install tox`, the unit tests in the `tests/` folder can be\nrun reproducibly with:\n\n```shell\n$ tox\n```\n\nadditionally, these tests are automatically re-run with each commit in a [github action](https://github.com/{{cookiecutter.github_organization_name}}/{{cookiecutter.github_repository_name}}/actions?query=workflow%3atests).\n\n### \ud83d\udce6 making a release\n\nafter installing the package in development mode and installing\n`tox` with `pip install tox`, the commands for making a new release are contained within the `finish` environment\nin `tox.ini`. run the following from the shell:\n\n```shell\n$ tox -e finish\n```\n\nthis script does the following:\n\n1. uses bumpversion to switch the version number in the `setup.cfg` and\n   `src/{{cookiecutter.package_name}}/version.py` to not have the `-dev` suffix\n2. packages the code in both a tar archive and a wheel\n3. uploads to pypi using `twine`. be sure to have a `.pypirc` file configured to avoid the need for manual input at this\n   step\n4. push to github. you'll need to make a release going with the commit where the version was bumped.\n5. bump the version to the next patch. if you made big changes and want to bump the version by minor, you can\n   use `tox -e bumpversion minor` after.\n</details>\n",
  "docs_url": null,
  "keywords": "development tool,configurability",
  "license": "mit",
  "name": "class-resolver",
  "package_url": "https://pypi.org/project/class-resolver/",
  "project_url": "https://pypi.org/project/class-resolver/",
  "project_urls": {
    "Bug Tracker": "https://github.com/cthoyt/class-resolver/issues",
    "Download": "https://github.com/cthoyt/class-resolver/releases",
    "Homepage": "https://github.com/cthoyt/class-resolver",
    "Source Code": "https://github.com/cthoyt/class-resolver"
  },
  "release_url": "https://pypi.org/project/class-resolver/0.4.2/",
  "requires_dist": [
    "importlib-metadata (>3.6) ; python_version < \"3.10\"",
    "click ; extra == 'click'",
    "docdata ; extra == 'docdata'",
    "sphinx ; extra == 'docs'",
    "sphinx-rtd-theme ; extra == 'docs'",
    "sphinx-autodoc-typehints ; extra == 'docs'",
    "sphinx-automodapi ; extra == 'docs'",
    "numpy ; extra == 'numpy'",
    "optuna ; extra == 'optuna'",
    "ray[tune] (<2.0.0) ; (python_version < \"3.9\") and extra == 'ray'",
    "scikit-learn ; extra == 'sklearn'",
    "docdata ; extra == 'tests'",
    "coverage ; extra == 'tests'",
    "pytest ; extra == 'tests'",
    "torch ; extra == 'torch'",
    "torch ; extra == 'torch-geometric'",
    "torch-sparse ; extra == 'torch-geometric'",
    "torch-geometric ; extra == 'torch-geometric'"
  ],
  "requires_python": ">=3.7",
  "summary": "lookup and instantiate classes with style.",
  "version": "0.4.2",
  "releases": [],
  "developers": [
    "charles_tapley_hoyt",
    "cthoyt@gmail.com"
  ],
  "kwds": "cookiecutter class_resolver badge activation_resolver resolver",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_class_resolver",
  "homepage": "https://github.com/cthoyt/class-resolver",
  "release_count": 36,
  "dependency_ids": [
    "pypi_click",
    "pypi_coverage",
    "pypi_docdata",
    "pypi_importlib_metadata",
    "pypi_numpy",
    "pypi_optuna",
    "pypi_pytest",
    "pypi_ray",
    "pypi_scikit_learn",
    "pypi_sphinx",
    "pypi_sphinx_autodoc_typehints",
    "pypi_sphinx_automodapi",
    "pypi_sphinx_rtd_theme",
    "pypi_torch",
    "pypi_torch_geometric",
    "pypi_torch_sparse"
  ]
}