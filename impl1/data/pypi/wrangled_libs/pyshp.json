{
  "classifiers": [
    "development status :: 5 - production/stable",
    "programming language :: python",
    "programming language :: python :: 2.7",
    "programming language :: python :: 3",
    "topic :: scientific/engineering :: gis",
    "topic :: software development :: libraries",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "# pyshp\n\nthe python shapefile library (pyshp) reads and writes esri shapefiles in pure python.\n\n![pyshp logo](http://4.bp.blogspot.com/_sbi37qescvg/tpquohlhqxi/aaaaaaaaae0/qjflwfmx0tq/s350/gsp_logo.png \"pyshp\")\n\n![build status](https://github.com/geospatialpython/pyshp/actions/workflows/build.yml/badge.svg)\n\n- **author**: [joel lawhead](https://github.com/geospatialpython)\n- **maintainers**: [karim bahgat](https://github.com/karimbahgat)\n- **version**: 2.3.0\n- **date**: 30 april, 2022\n- **license**: [mit](https://github.com/geospatialpython/pyshp/blob/master/license.txt)\n\n## contents\n\n- [overview](#overview)\n- [version changes](#version-changes)\n- [the basics](#the-basics)\n\t- [reading shapefiles](#reading-shapefiles)\n\t\t- [the reader class](#the-reader-class)\n\t\t\t- [reading shapefiles from local files](#reading-shapefiles-from-local-files)\n\t\t\t- [reading shapefiles from zip files](#reading-shapefiles-from-zip-files)\n\t\t\t- [reading shapefiles from urls](#reading-shapefiles-from-urls)\n\t\t\t- [reading shapefiles from file-like objects](#reading-shapefiles-from-file-like-objects)\n\t\t\t- [reading shapefiles using the context manager](#reading-shapefiles-using-the-context-manager)\n\t\t\t- [reading shapefile meta-data](#reading-shapefile-meta-data)\n\t\t- [reading geometry](#reading-geometry)\n\t\t- [reading records](#reading-records)\n\t\t- [reading geometry and records simultaneously](#reading-geometry-and-records-simultaneously)\n\t- [writing shapefiles](#writing-shapefiles)\n\t\t- [the writer class](#the-writer-class)\n\t\t\t- [writing shapefiles to local files](#writing-shapefiles-to-local-files)\n\t\t\t- [writing shapefiles to file-like objects](#writing-shapefiles-to-file-like-objects)\n\t\t\t- [writing shapefiles using the context manager](#writing-shapefiles-using-the-context-manager)\n\t\t\t- [setting the shape type](#setting-the-shape-type)\n\t\t- [adding records](#adding-records)\n\t\t- [adding geometry](#adding-geometry)\n\t\t- [geometry and record balancing](#geometry-and-record-balancing)\n- [advanced use](#advanced-use)\n    - [common errors and fixes](#common-errors-and-fixes)\n        - [warnings and logging](#warnings-and-logging)\n        - [shapefile encoding errors](#shapefile-encoding-errors)\n\t- [reading large shapefiles](#reading-large-shapefiles)\n\t\t- [iterating through a shapefile](#iterating-through-a-shapefile)\n\t\t- [limiting which fields to read](#limiting-which-fields-to-read)\n\t\t- [attribute filtering](#attribute-filtering)\n\t\t- [spatial filtering](#spatial-filtering)\n\t- [writing large shapefiles](#writing-large-shapefiles)\n\t\t- [merging multiple shapefiles](#merging-multiple-shapefiles)\n\t\t- [editing shapefiles](#editing-shapefiles)\n\t- [3d and other geometry types](#3d-and-other-geometry-types)\n    \t- [shapefiles with measurement (m) values](#shapefiles-with-measurement-m-values)\n\t\t- [shapefiles with elevation (z) values](#shapefiles-with-elevation-z-values)\n\t\t- [3d multipatch shapefiles](#3d-multipatch-shapefiles)\n- [testing](#testing)\n- [contributors](#contributors)\n\n\n# overview\n\nthe python shapefile library (pyshp) provides read and write support for the\nesri shapefile format. the shapefile format is a popular geographic\ninformation system vector data format created by esri. for more information\nabout this format please read the well-written \"esri shapefile technical\ndescription - july 1998\" located at [http://www.esri.com/library/whitepapers/p\ndfs/shapefile.pdf](http://www.esri.com/library/whitepapers/pdfs/shapefile.pdf)\n. the esri document describes the shp and shx file formats. however a third\nfile format called dbf is also required. this format is documented on the web\nas the \"xbase file format description\" and is a simple file-based database\nformat created in the 1960's. for more on this specification see: [http://www.clicketyclick.dk/databases/xbase/format/index.html](http://www.clicketyclick.dk/databases/xbase/format/index.html)\n\nboth the esri and xbase file-formats are very simple in design and memory\nefficient which is part of the reason the shapefile format remains popular\ndespite the numerous ways to store and exchange gis data available today.\n\npyshp is compatible with python 2.7-3.x.\n\nthis document provides examples for using pyshp to read and write shapefiles. however \nmany more examples are continually added to the blog [http://geospatialpython.com](http://geospatialpython.com),\nand by searching for pyshp on [https://gis.stackexchange.com](https://gis.stackexchange.com). \n\ncurrently the sample census blockgroup shapefile referenced in the examples is available on the github project site at\n[https://github.com/geospatialpython/pyshp](https://github.com/geospatialpython/pyshp). these\nexamples are straight-forward and you can also easily run them against your\nown shapefiles with minimal modification. \n\nimportant: if you are new to gis you should read about map projections.\nplease visit: [https://github.com/geospatialpython/pyshp/wiki/map-projections](https://github.com/geospatialpython/pyshp/wiki/map-projections)\n\ni sincerely hope this library eliminates the mundane distraction of simply\nreading and writing data, and allows you to focus on the challenging and fun\npart of your geospatial project.\n\n\n# version changes\n\n## 2.3.1\n\n### bug fixes:\n\n- fix recently introduced issue where reader/writer closes file-like objects provided by user (#244)\n\n## 2.3.0\n\n### new features:\n\n- added support for pathlib and path-like shapefile filepaths (@mwtoews). \n- allow reading individual file extensions via filepaths.\n\n### improvements:\n\n- simplified setup and deployment (@mwtoews)\n- faster shape access when missing shx file\n- switch to named logger (see #240)\n\n### bug fixes:\n\n- more robust handling of corrupt shapefiles (fixes #235)\n- fix errors when writing to individual file-handles (fixes #237)\n- revert previous decision to enforce geojson output ring orientation (detailed explanation at https://github.com/scitools/cartopy/issues/2012)\n- fix test issues in environments without network access (@sebastic, @musicinmybrain). \n\n## 2.2.0\n\n### new features:\n\n- read shapefiles directly from zipfiles.\n- read shapefiles directly from urls.\n- allow fast extraction of only a subset of dbf fields through a `fields` arg.\n- allow fast filtering which shapes to read from the file through a `bbox` arg.\n\n### improvements:\n\n- more examples and restructuring of readme. \n- more informative shape to geojson warnings (see #219).\n- add shapefile.verbose flag to control warnings verbosity (default true).\n- shape object information when calling repr().\n- faster ring orientation checks, enforce geojson output ring orientation.\n\n### bug fixes:\n\n- remove null-padding at end of some record character fields.\n- fix dbf writing error when the number of record list or dict entries didn't match the number of fields.\n- handle rare garbage collection issue after deepcopy (https://github.com/mattijn/topojson/issues/120)\n- fix bug where records and shapes would be assigned incorrect record number (@karanrn)\n- fix typos in docs (@timgates)\n\n## 2.1.3\n\n### bug fixes:\n\n- fix recent bug in geojson hole-in-polygon checking (see #205)\n- misc fixes to allow geo interface dump to json (eg dates as strings)\n- handle additional dbf date null values, and return faulty dates as unicode (see #187)\n- add writer target typecheck\n- fix bugs to allow reading shp/shx/dbf separately\n- allow delayed shapefile loading by passing no args\n- fix error with writing empty z/m shapefile (@mcuprjak)\n- fix signed_area() so ignores z/m coords\n- enforce writing the 11th field name character as null-terminator (only first 10 are used)\n- minor readme fixes\n- added more tests\n\n## 2.1.2\n\n### bug fixes:\n\n- fix issue where warnings.simplefilter('always') changes global warning behavior [see #203]\n\n## 2.1.1\n\n### improvements:\n\n- handle shapes with no coords and represent as geojson with no coords (geojson null-equivalent)\n- expand testing to python 3.6, 3.7, 3.8 and pypy; drop 3.3 and 3.4 [@mwtoews]\n- added pytest testing [@jmoujaes]\n\n### bug fixes:\n\n- fix incorrect geo interface handling of multipolygons with complex exterior-hole relations [see #202]\n- enforce shapefile requirement of at least one field, to avoid writing invalid shapefiles [@jonty]\n- fix reader geo interface including deletionflag field in feature properties [@nnseva]\n- fix polygons not being auto closed, which was accidentally dropped\n- fix error for null geometries in feature geojson\n- misc docstring cleanup [@fiveham]\n\n## 2.1.0\n\n### new features:\n\n- added back read/write support for unicode field names. \n- improved record representation\n- more support for geojson on reader, shaperecord, shaperecords, and shapes()\n\n### bug fixes:\n\n- fixed error when reading optional m-values\n- fixed record attribute autocomplete in python 3\n- misc readme cleanup\n\n## 2.0.0\n\nthe newest version of pyshp, version 2.0 introduced some major new improvements. \na great thanks to all who have contributed code and raised issues, and for everyone's\npatience and understanding during the transition period. \nsome of the new changes are incompatible with previous versions. \nusers of the previous version 1.x should therefore take note of the following changes\n(note: some contributor attributions may be missing): \n\n### major changes:\n\n- full support for unicode text, with custom encoding, and exception handling. \n  - means that the reader returns unicode, and the writer accepts unicode. \n- pyshp has been simplified to a pure input-output library using the reader and writer classes, dropping the editor class. \n- switched to a new streaming approach when writing files, keeping memory-usage at a minimum:\n  - specify filepath/destination and text encoding when creating the writer. \n  - the file is written incrementally with each call to shape/record. \n  - adding shapes is now done using dedicated methods for each shapetype. \n- reading shapefiles is now more convenient:\n  - shapefiles can be opened using the context manager, and files are properly closed. \n  - shapefiles can be iterated, have a length, and supports the geo interface. \n  - new ways of inspecting shapefile metadata by printing. [@megies]\n  - more convenient accessing of record values as attributes. [@philippkraft]\n  - more convenient shape type name checking. [@megies] \n- add more support and documentation for multipatch 3d shapes. \n- the reader \"elevation\" and \"measure\" attributes now renamed \"zbox\" and \"mbox\", to make it clear they refer to the min/max values. \n- better documentation of previously unclear aspects, such as field types. \n\n### important fixes:\n\n- more reliable/robust:\n  - fixed shapefile bbox error for empty or point type shapefiles. [@mcuprjak]\n  - reading and writing z and m type shapes is now more robust, fixing many errors, and has been added to the documentation. [@shinnonoir]\n  - improved parsing of field value types, fixed errors and made more flexible. \n  - fixed bug when writing shapefiles with datefield and date values earlier than 1900 [@megies]\n- fix some geo interface errors, including checking polygon directions.\n- bug fixes for reading from case sensitive file names, individual files separately, and from file-like objects. [@gastoneb, @kb003308, @erickskb]\n- enforce maximum field limit. [@mwtoews]\n\n\n# the basics\n\nbefore doing anything you must import the library.\n\n\n\t>>> import shapefile\n\nthe examples below will use a shapefile created from the u.s. census bureau\nblockgroups data set near san francisco, ca and available in the git\nrepository of the pyshp github site.\n\n## reading shapefiles\n\n### the reader class\n\n#### reading shapefiles from local files\n\nto read a shapefile create a new \"reader\" object and pass it the name of an\nexisting shapefile. the shapefile format is actually a collection of three\nfiles. you specify the base filename of the shapefile or the complete filename\nof any of the shapefile component files.\n\n\n\t>>> sf = shapefile.reader(\"shapefiles/blockgroups\")\n\nor\n\n\n\t>>> sf = shapefile.reader(\"shapefiles/blockgroups.shp\")\n\nor\n\n\n\t>>> sf = shapefile.reader(\"shapefiles/blockgroups.dbf\")\n\nor any of the other 5+ formats which are potentially part of a shapefile. the\nlibrary does not care about file extensions. you can also specify that you only \nwant to read some of the file extensions through the use of keyword arguments:\n\n\n\t>>> sf = shapefile.reader(dbf=\"shapefiles/blockgroups.dbf\")\n\n#### reading shapefiles from zip files\n\nif your shapefile is wrapped inside a zip file, the library is able to handle that too, meaning you don't have to worry about unzipping the contents: \n\n\n\t>>> sf = shapefile.reader(\"shapefiles/blockgroups.zip\")\n\nif the zip file contains multiple shapefiles, just specify which shapefile to read by additionally specifying the relative path after the \".zip\" part:\n\n\n\t>>> sf = shapefile.reader(\"shapefiles/blockgroups_multishapefile.zip/blockgroups2.shp\")\n\n#### reading shapefiles from urls\n\nfinally, you can use all of the above methods to read shapefiles directly from the internet, by giving a url instead of a local path, e.g.: \n\n\n\t>>> # from a zipped shapefile on website\n\t>>> sf = shapefile.reader(\"https://biogeo.ucdavis.edu/data/diva/rrd/nic_rrd.zip\")\n\n\t>>> # from a shapefile collection of files in a github repository\n\t>>> sf = shapefile.reader(\"https://github.com/nvkelso/natural-earth-vector/blob/master/110m_cultural/ne_110m_admin_0_tiny_countries.shp?raw=true\")\n\nthis will automatically download the file(s) to a temporary location before reading, saving you a lot of time and repetitive boilerplate code when you just want quick access to some external data.\n\n#### reading shapefiles from file-like objects\n\nyou can also load shapefiles from any python file-like object using keyword\narguments to specify any of the three files. this feature is very powerful and\nallows you to custom load shapefiles from arbitrary storage formats, such as a protected url or zip file, a serialized object, or in some cases a database.\n\n\n\t>>> myshp = open(\"shapefiles/blockgroups.shp\", \"rb\")\n\t>>> mydbf = open(\"shapefiles/blockgroups.dbf\", \"rb\")\n\t>>> r = shapefile.reader(shp=myshp, dbf=mydbf)\n\nnotice in the examples above the shx file is never used. the shx file is a\nvery simple fixed-record index for the variable-length records in the shp\nfile. this file is optional for reading. if it's available pyshp will use the\nshx file to access shape records a little faster but will do just fine without\nit.\n\n#### reading shapefiles using the context manager\n\nthe \"reader\" class can be used as a context manager, to ensure open file\nobjects are properly closed when done reading the data:\n\n    >>> with shapefile.reader(\"shapefiles/blockgroups.shp\") as shp:\n    ...     print(shp)\n    shapefile reader\n        663 shapes (type 'polygon')\n        663 records (44 fields)\n\n#### reading shapefile meta-data\n\nshapefiles have a number of attributes for inspecting the file contents.\na shapefile is a container for a specific type of geometry, and this can be checked using the \nshapetype attribute. \n\n\n\t>>> sf = shapefile.reader(\"shapefiles/blockgroups.dbf\")\n\t>>> sf.shapetype\n\t5\n\nshape types are represented by numbers between 0 and 31 as defined by the\nshapefile specification and listed below. it is important to note that the numbering system has\nseveral reserved numbers that have not been used yet, therefore the numbers of\nthe existing shape types are not sequential:\n\n- null = 0\n- point = 1\n- polyline = 3\n- polygon = 5\n- multipoint = 8\n- pointz = 11\n- polylinez = 13\n- polygonz = 15\n- multipointz = 18\n- pointm = 21\n- polylinem = 23\n- polygonm = 25\n- multipointm = 28\n- multipatch = 31\n\t\nbased on this we can see that our blockgroups shapefile contains\npolygon type shapes. the shape types are also defined as constants in\nthe shapefile module, so that we can compare types more intuitively:\n\n\n\t>>> sf.shapetype == shapefile.polygon\n\ttrue\n\nfor convenience, you can also get the name of the shape type as a string:\n\n\n\t>>> sf.shapetypename == 'polygon'\n\ttrue\n\t\nother pieces of meta-data that we can check include the number of features \nand the bounding box area the shapefile covers:\n\n\n\t>>> len(sf)\n\t663\n\t>>> sf.bbox\n\t[-122.515048, 37.652916, -122.327622, 37.863433]\n\t\nfinally, if you would prefer to work with the entire shapefile in a different\nformat, you can convert all of it to a geojson dictionary, although you may lose\nsome information in the process, such as z- and m-values: \n\n\n\t>>> sf.__geo_interface__['type']\n\t'featurecollection'\n\n### reading geometry\n\na shapefile's geometry is the collection of points or shapes made from\nvertices and implied arcs representing physical locations. all types of\nshapefiles just store points. the metadata about the points determine how they\nare handled by software.\n\nyou can get a list of the shapefile's geometry by calling the shapes()\nmethod.\n\n\n\t>>> shapes = sf.shapes()\n\nthe shapes method returns a list of shape objects describing the geometry of\neach shape record.\n\n\n\t>>> len(shapes)\n\t663\n\t\nto read a single shape by calling its index use the shape() method. the index\nis the shape's count from 0. so to read the 8th shape record you would use its\nindex which is 7.\n\n\n\t>>> s = sf.shape(7)\n\t>>> s\n\tshape #7: polygon\n\n\t>>> # read the bbox of the 8th shape to verify\n\t>>> # round coordinates to 3 decimal places\n\t>>> ['%.3f' % coord for coord in s.bbox]\n\t['-122.450', '37.801', '-122.442', '37.808']\n\neach shape record (except points) contains the following attributes. records of\nshapetype point do not have a bounding box 'bbox'.\n\n\n\t>>> for name in dir(shapes[3]):\n\t...     if not name.startswith('_'):\n\t...         name\n\t'bbox'\n\t'oid'\n\t'parts'\n\t'points'\n\t'shapetype'\n\t'shapetypename'\n\n  * `oid`: the shape's index position in the original shapefile.\n\n\n\t\t>>> shapes[3].oid\n\t\t3\n\n  * `shapetype`: an integer representing the type of shape as defined by the\n\t  shapefile specification.\n\n\n\t\t>>> shapes[3].shapetype\n\t\t5\n\n  * `shapetypename`: a string representation of the type of shape as defined by shapetype. read-only. \n\n\n\t\t>>> shapes[3].shapetypename\n\t\t'polygon'\n\t\t\n  * `bbox`: if the shape type contains multiple points this tuple describes the\n\t  lower left (x,y) coordinate and upper right corner coordinate creating a\n\t  complete box around the points. if the shapetype is a\n\t  null (shapetype == 0) then an attributeerror is raised.\n\n\n\t\t>>> # get the bounding box of the 4th shape.\n\t\t>>> # round coordinates to 3 decimal places\n\t\t>>> bbox = shapes[3].bbox\n\t\t>>> ['%.3f' % coord for coord in bbox]\n\t\t['-122.486', '37.787', '-122.446', '37.811']\n\n  * `parts`: parts simply group collections of points into shapes. if the shape\n\t  record has multiple parts this attribute contains the index of the first\n\t  point of each part. if there is only one part then a list containing 0 is\n\t  returned.\n\n\n\t\t>>> shapes[3].parts\n\t\t[0]\n\n  * `points`: the points attribute contains a list of tuples containing an\n\t  (x,y) coordinate for each point in the shape.\n\n\n\t\t>>> len(shapes[3].points)\n\t\t173\n\t\t>>> # get the 8th point of the fourth shape\n\t\t>>> # truncate coordinates to 3 decimal places\n\t\t>>> shape = shapes[3].points[7]\n\t\t>>> ['%.3f' % coord for coord in shape]\n\t\t['-122.471', '37.787']\n\nin most cases, however, if you need to do more than just type or bounds checking, you may want \nto convert the geometry to the more human-readable [geojson format](http://geojson.org),\nwhere lines and polygons are grouped for you:\n\n\n\t>>> s = sf.shape(0)\n\t>>> geoj = s.__geo_interface__\n\t>>> geoj[\"type\"]\n\t'multipolygon'\n\t\nthe results from the shapes() method similarly supports converting to geojson:\n\n\n\t>>> shapes.__geo_interface__['type']\n\t'geometrycollection'\n\nnote: in some cases, if the conversion from shapefile geometry to geojson encountered any problems\nor potential issues, a warning message will be displayed with information about the affected\ngeometry. to ignore or suppress these warnings, you can disable this behavior by setting the \nmodule constant verbose to false: \n\n\n\t>>> shapefile.verbose = false\n\t\n\n### reading records\n\na record in a shapefile contains the attributes for each shape in the\ncollection of geometries. records are stored in the dbf file. the link between\ngeometry and attributes is the foundation of all geographic information systems.\nthis critical link is implied by the order of shapes and corresponding records\nin the shp geometry file and the dbf attribute file.\n\nthe field names of a shapefile are available as soon as you read a shapefile.\nyou can call the \"fields\" attribute of the shapefile as a python list. each\nfield is a python list with the following information:\n\n  * field name: the name describing the data at this column index.\n  * field type: the type of data at this column index. types can be: \n       * \"c\": characters, text.\n\t   * \"n\": numbers, with or without decimals.\n\t   * \"f\": floats (same as \"n\").\n\t   * \"l\": logical, for boolean true/false values. \n\t   * \"d\": dates. \n\t   * \"m\": memo, has no meaning within a gis and is part of the xbase spec instead.\n  * field length: the length of the data found at this column index. older gis\n\t   software may truncate this length to 8 or 11 characters for \"character\"\n\t   fields.\n  * decimal length: the number of decimal places found in \"number\" fields.\n\nto see the fields for the reader object above (sf) call the \"fields\"\nattribute:\n\n\n\t>>> fields = sf.fields\n\n\t>>> assert fields == [(\"deletionflag\", \"c\", 1, 0), [\"area\", \"n\", 18, 5],\n\t... [\"bkg_key\", \"c\", 12, 0], [\"pop1990\", \"n\", 9, 0], [\"pop90_sqmi\", \"n\", 10, 1],\n\t... [\"households\", \"n\", 9, 0],\n\t... [\"males\", \"n\", 9, 0], [\"females\", \"n\", 9, 0], [\"white\", \"n\", 9, 0],\n\t... [\"black\", \"n\", 8, 0], [\"ameri_es\", \"n\", 7, 0], [\"asian_pi\", \"n\", 8, 0],\n\t... [\"other\", \"n\", 8, 0], [\"hispanic\", \"n\", 8, 0], [\"age_under5\", \"n\", 8, 0],\n\t... [\"age_5_17\", \"n\", 8, 0], [\"age_18_29\", \"n\", 8, 0], [\"age_30_49\", \"n\", 8, 0],\n\t... [\"age_50_64\", \"n\", 8, 0], [\"age_65_up\", \"n\", 8, 0],\n\t... [\"nevermarry\", \"n\", 8, 0], [\"married\", \"n\", 9, 0], [\"separated\", \"n\", 7, 0],\n\t... [\"widowed\", \"n\", 8, 0], [\"divorced\", \"n\", 8, 0], [\"hsehld_1_m\", \"n\", 8, 0],\n\t... [\"hsehld_1_f\", \"n\", 8, 0], [\"marhh_chd\", \"n\", 8, 0],\n\t... [\"marhh_no_c\", \"n\", 8, 0], [\"mhh_child\", \"n\", 7, 0],\n\t... [\"fhh_child\", \"n\", 7, 0], [\"hse_units\", \"n\", 9, 0], [\"vacant\", \"n\", 7, 0],\n\t... [\"owner_occ\", \"n\", 8, 0], [\"renter_occ\", \"n\", 8, 0],\n\t... [\"median_val\", \"n\", 7, 0], [\"medianrent\", \"n\", 4, 0],\n\t... [\"units_1det\", \"n\", 8, 0], [\"units_1att\", \"n\", 7, 0], [\"units2\", \"n\", 7, 0],\n\t... [\"units3_9\", \"n\", 8, 0], [\"units10_49\", \"n\", 8, 0],\n\t... [\"units50_up\", \"n\", 8, 0], [\"mobilehome\", \"n\", 7, 0]]\n\nthe first field of a dbf file is always a 1-byte field called \"deletionflag\", \nwhich indicates records that have been deleted but not removed. however, \nsince this flag is very rarely used, pyshp currently will return all records  \nregardless of their deletion flag, and the flag is also not included in the list of \nrecord values. in other words, the deletionflag field has no real purpose, and \nshould in most cases be ignored. for instance, to get a list of all fieldnames:\n\n\n\t>>> fieldnames = [f[0] for f in sf.fields[1:]]\n\nyou can get a list of the shapefile's records by calling the records() method:\n\n\n\t>>> records = sf.records()\n\n\t>>> len(records)\n\t663\n\nto read a single record call the record() method with the record's index:\n\n\n\t>>> rec = sf.record(3)\n\t\neach record is a list-like record object containing the values corresponding to each field in\nthe field list (except the deletionflag). a record's values can be accessed by positional indexing or slicing.\nfor example in the blockgroups shapefile the 2nd and 3rd fields are the blockgroup id \nand the 1990 population count of that san francisco blockgroup:\n\n\n\t>>> rec[1:3]\n\t['060750601001', 4715]\n\nfor simpler access, the fields of a record can also accessed via the name of the field,\neither as a key or as an attribute name. the blockgroup id (bkg_key) of the blockgroups shapefile \ncan also be retrieved as:\n\n\n    >>> rec['bkg_key']\n    '060750601001'\n\n    >>> rec.bkg_key\n    '060750601001'\n\t\nthe record values can be easily integrated with other programs by converting it to a field-value dictionary:\n\n\n\t>>> dct = rec.as_dict()\n\t>>> sorted(dct.items())\n\t[('age_18_29', 1467), ('age_30_49', 1681), ('age_50_64', 92), ('age_5_17', 848), ('age_65_up', 30), ('age_under5', 597), ('ameri_es', 6), ('area', 2.34385), ('asian_pi', 452), ('bkg_key', '060750601001'), ('black', 1007), ('divorced', 149), ('females', 2095), ('fhh_child', 16), ('hispanic', 416), ('households', 1195), ('hsehld_1_f', 40), ('hsehld_1_m', 22), ('hse_units', 1258), ('males', 2620), ('marhh_chd', 79), ('marhh_no_c', 958), ('married', 2021), ('medianrent', 739), ('median_val', 337500), ('mhh_child', 0), ('mobilehome', 0), ('nevermarry', 703), ('other', 288), ('owner_occ', 66), ('pop1990', 4715), ('pop90_sqmi', 2011.6), ('renter_occ', 3733), ('separated', 49), ('units10_49', 49), ('units2', 160), ('units3_9', 672), ('units50_up', 0), ('units_1att', 302), ('units_1det', 43), ('vacant', 93), ('white', 2962), ('widowed', 37)]\n\nif at a later point you need to check the record's index position in the original \nshapefile, you can do this through the \"oid\" attribute:\n\n\n\t>>> rec.oid\n\t3\n\t\n### reading geometry and records simultaneously\n\nyou may want to examine both the geometry and the attributes for a record at\nthe same time. the shaperecord() and shaperecords() method let you do just\nthat.\n\ncalling the shaperecords() method will return the geometry and attributes for\nall shapes as a list of shaperecord objects. each shaperecord instance has a\n\"shape\" and \"record\" attribute. the shape attribute is a shape object as\ndiscussed in the first section \"reading geometry\". the record attribute is a\nlist-like object containing field values as demonstrated in the \"reading records\" section.\n\n\n\t>>> shaperecs = sf.shaperecords()\n\nlet's read the blockgroup key and the population for the 4th blockgroup:\n\n\n\t>>> shaperecs[3].record[1:3]\n\t['060750601001', 4715]\n\nthe results from the shaperecords() method is a list-like object that can be easily converted\nto geojson through the _\\_geo_interface\\_\\_:\n\n\n\t>>> shaperecs.__geo_interface__['type']\n\t'featurecollection'\n\nthe shaperecord() method reads a single shape/record pair at the specified index.\nto get the 4th shape record from the blockgroups shapefile use the third index:\n\n\n\t>>> shaperec = sf.shaperecord(3)\n\t>>> shaperec.record[1:3]\n\t['060750601001', 4715]\n\t\neach individual shape record also supports the _\\_geo_interface\\_\\_ to convert it to a geojson feature:\n\n\n\t>>> shaperec.__geo_interface__['type']\n\t'feature'\n\t\n\n## writing shapefiles\n\n### the writer class\n\npyshp tries to be as flexible as possible when writing shapefiles while\nmaintaining some degree of automatic validation to make sure you don't\naccidentally write an invalid file.\n\npyshp can write just one of the component files such as the shp or dbf file\nwithout writing the others. so in addition to being a complete shapefile\nlibrary, it can also be used as a basic dbf (xbase) library. dbf files are a\ncommon database format which are often useful as a standalone simple database\nformat. and even shp files occasionally have uses as a standalone format. some\nweb-based gis systems use an user-uploaded shp file to specify an area of\ninterest. many precision agriculture chemical field sprayers also use the shp\nformat as a control file for the sprayer system (usually in combination with\ncustom database file formats).\n\n#### writing shapefiles to local files\n\nto create a shapefile you begin by initiating a new writer instance, passing it\nthe file path and name to save to:\n\n\n\t>>> w = shapefile.writer('shapefiles/test/testfile')\n\t>>> w.field('field1', 'c')\n\t\nfile extensions are optional when reading or writing shapefiles. if you specify\nthem pyshp ignores them anyway. when you save files you can specify a base\nfile name that is used for all three file types. or you can specify a name for\none or more file types:\n\n\n\t>>> w = shapefile.writer(dbf='shapefiles/test/onlydbf.dbf')\n\t>>> w.field('field1', 'c')\n\t\nin that case, any file types not assigned will not\nsave and only file types with file names will be saved. \n\n#### writing shapefiles to file-like objects\n\njust as you can read shapefiles from python file-like objects you can also\nwrite to them:\n\n\n\t>>> try:\n\t...     from stringio import stringio\n\t... except importerror:\n\t...     from io import bytesio as stringio\n\t>>> shp = stringio()\n\t>>> shx = stringio()\n\t>>> dbf = stringio()\n\t>>> w = shapefile.writer(shp=shp, shx=shx, dbf=dbf)\n\t>>> w.field('field1', 'c')\n\t>>> w.record()\n\t>>> w.null()\n\t>>> w.close()\n\n\t>>> # to read back the files you could call the \"stringio.getvalue()\" method later.\n\t>>> assert shp.getvalue()\n\t>>> assert shx.getvalue()\n\t>>> assert dbf.getvalue()\n\n\t>>> # in fact, you can read directly from them using the reader\n\t>>> r = shapefile.reader(shp=shp, shx=shx, dbf=dbf)\n\t>>> len(r)\n\t1\n\t\n\t\n\n#### writing shapefiles using the context manager\n\nthe \"writer\" class automatically closes the open files and writes the final headers once it is garbage collected.\nin case of a crash and to make the code more readable, it is nevertheless recommended \nyou do this manually by calling the \"close()\" method: \n\n\n\t>>> w.close()\n\nalternatively, you can also use the \"writer\" class as a context manager, to ensure open file\nobjects are properly closed and final headers written once you exit the with-clause:\n\n\n\t>>> with shapefile.writer(\"shapefiles/test/contextwriter\") as w:\n\t... \tw.field('field1', 'c')\n\t... \tpass\n\t\n#### setting the shape type\n\nthe shape type defines the type of geometry contained in the shapefile. all of\nthe shapes must match the shape type setting.\n\nthere are three ways to set the shape type: \n  * set it when creating the class instance. \n  * set it by assigning a value to an existing class instance. \n  * set it automatically to the type of the first non-null shape by saving the shapefile.\n\nto manually set the shape type for a writer object when creating the writer:\n\n\n\t>>> w = shapefile.writer('shapefiles/test/shapetype', shapetype=3)\n\t>>> w.field('field1', 'c')\n\n\t>>> w.shapetype\n\t3\n\nor you can set it after the writer is created:\n\n\n\t>>> w.shapetype = 1\n\n\t>>> w.shapetype\n\t1\n\t\n\n### adding records\n\nbefore you can add records you must first create the fields that define what types of \nvalues will go into each attribute. \n\nthere are several different field types, all of which support storing none values as null. \n\ntext fields are created using the 'c' type, and the third 'size' argument can be customized to the expected\nlength of text values to save space:\n\n\n\t>>> w = shapefile.writer('shapefiles/test/dtype')\n\t>>> w.field('text', 'c')\n\t>>> w.field('short_text', 'c', size=5)\n\t>>> w.field('long_text', 'c', size=250)\n\t>>> w.null()\n\t>>> w.record('hello', 'world', 'world'*50)\n\t>>> w.close()\n\t\n\t>>> r = shapefile.reader('shapefiles/test/dtype')\n\t>>> assert r.record(0) == ['hello', 'world', 'world'*50]\n\ndate fields are created using the 'd' type, and can be created using either \ndate objects, lists, or a yyyymmdd formatted string. \nfield length or decimal have no impact on this type:\n\n\n\t>>> from datetime import date\n\t>>> w = shapefile.writer('shapefiles/test/dtype')\n\t>>> w.field('date', 'd')\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.record(date(1898,1,30))\n\t>>> w.record([1998,1,30])\n\t>>> w.record('19980130')\n\t>>> w.record(none)\n\t>>> w.close()\n\t\n\t>>> r = shapefile.reader('shapefiles/test/dtype')\n\t>>> assert r.record(0) == [date(1898,1,30)]\n\t>>> assert r.record(1) == [date(1998,1,30)]\n\t>>> assert r.record(2) == [date(1998,1,30)]\n\t>>> assert r.record(3) == [none]\n\nnumeric fields are created using the 'n' type (or the 'f' type, which is exactly the same). \nby default the fourth decimal argument is set to zero, essentially creating an integer field. \nto store floats you must set the decimal argument to the precision of your choice. \nto store very large numbers you must increase the field length size to the total number of digits \n(including comma and minus). \n\n\n\t>>> w = shapefile.writer('shapefiles/test/dtype')\n\t>>> w.field('int', 'n')\n\t>>> w.field('lowprec', 'n', decimal=2)\n\t>>> w.field('medprec', 'n', decimal=10)\n\t>>> w.field('highprec', 'n', decimal=30)\n\t>>> w.field('ftype', 'f', decimal=10)\n\t>>> w.field('largenr', 'n', 101)\n\t>>> nr = 1.3217328\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.record(int=nr, lowprec=nr, medprec=nr, highprec=-3.2302e-25, ftype=nr, largenr=int(nr)*10**100)\n\t>>> w.record(none, none, none, none, none, none)\n\t>>> w.close()\n\t\n\t>>> r = shapefile.reader('shapefiles/test/dtype')\n\t>>> assert r.record(0) == [1, 1.32, 1.3217328, -3.2302e-25, 1.3217328, 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000]\n\t>>> assert r.record(1) == [none, none, none, none, none, none]\n\n\t\nfinally, we can create boolean fields by setting the type to 'l'. \nthis field can take true or false values, or 1 (true) or 0 (false). \nnone is interpreted as missing. \n\n\n\t>>> w = shapefile.writer('shapefiles/test/dtype')\n\t>>> w.field('boolean', 'l')\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.record(true)\n\t>>> w.record(1)\n\t>>> w.record(false)\n\t>>> w.record(0)\n\t>>> w.record(none)\n\t>>> w.record(\"nonesense\")\n\t>>> w.close()\n\t\n\t>>> r = shapefile.reader('shapefiles/test/dtype')\n\t>>> r.record(0)\n\trecord #0: [true]\n\t>>> r.record(1)\n\trecord #1: [true]\n\t>>> r.record(2)\n\trecord #2: [false]\n\t>>> r.record(3)\n\trecord #3: [false]\n\t>>> r.record(4)\n\trecord #4: [none]\n\t>>> r.record(5)\n\trecord #5: [none]\n\t\nyou can also add attributes using keyword arguments where the keys are field names.\n\n\n\t>>> w = shapefile.writer('shapefiles/test/dtype')\n\t>>> w.field('first_fld','c','40')\n\t>>> w.field('second_fld','c','40')\n\t>>> w.null()\n\t>>> w.null()\n\t>>> w.record('first', 'line')\n\t>>> w.record(first_fld='first', second_fld='line')\n\t>>> w.close()\n\n### adding geometry\n\ngeometry is added using one of several convenience methods. the \"null\" method is used\nfor null shapes, \"point\" is used for point shapes, \"multipoint\" is used for multipoint shapes, \"line\" for lines,\n\"poly\" for polygons. \n\n**adding a null shape**\n\na shapefile may contain some records for which geometry is not available, and may be set using the \"null\" method. \nbecause null shape types (shape type 0) have no geometry the \"null\" method is called without any arguments. \n\n\n\t>>> w = shapefile.writer('shapefiles/test/null')\n\t>>> w.field('name', 'c')\n\n\t>>> w.null()\n\t>>> w.record('nullgeom')\n\n\t>>> w.close()\n\n**adding a point shape**\n\npoint shapes are added using the \"point\" method. a point is specified by an x and\ny value. \n\n\n\t>>> w = shapefile.writer('shapefiles/test/point')\n\t>>> w.field('name', 'c')\n\t\n\t>>> w.point(122, 37) \n\t>>> w.record('point1')\n\t\n\t>>> w.close()\n\n**adding a multipoint shape**\n\nif your point data allows for the possibility of multiple points per feature, use \"multipoint\" instead. \nthese are specified as a list of xy point coordinates. \n\n\n\t>>> w = shapefile.writer('shapefiles/test/multipoint')\n\t>>> w.field('name', 'c')\n\t\n\t>>> w.multipoint([[122,37], [124,32]]) \n\t>>> w.record('multipoint1')\n\t\n\t>>> w.close()\n\t\n**adding a linestring shape**\n\nfor linestring shapefiles, each shape is given as a list of one or more linear features. \neach of the linear features must have at least two points. \n\t\n\t\n\t>>> w = shapefile.writer('shapefiles/test/line')\n\t>>> w.field('name', 'c')\n\t\n\t>>> w.line([\n\t...\t\t\t[[1,5],[5,5],[5,1],[3,3],[1,1]], # line 1\n\t...\t\t\t[[3,2],[2,6]] # line 2\n\t...\t\t\t])\n\t\n\t>>> w.record('linestring1')\n\t\n\t>>> w.close()\n\t\n**adding a polygon shape**\n\nsimilarly to linestring, polygon shapes consist of multiple polygons, and must be given as a list of polygons.\nthe main difference is that polygons must have at least 4 points and the last point must be the same as the first. \nit's also okay if you forget to repeat the first point at the end; pyshp automatically checks and closes the polygons\nif you don't.\n\nit's important to note that for polygon shapefiles, your polygon coordinates must be ordered in a clockwise direction.\nif any of the polygons have holes, then the hole polygon coordinates must be ordered in a counterclockwise direction.\nthe direction of your polygons determines how shapefile readers will distinguish between polygon outlines and holes. \n\n\n\t>>> w = shapefile.writer('shapefiles/test/polygon')\n\t>>> w.field('name', 'c')\n\n\t>>> w.poly([\n\t...\t        [[113,24], [112,32], [117,36], [122,37], [118,20]], # poly 1\n\t...\t        [[116,29],[116,26],[119,29],[119,32]], # hole 1\n\t...         [[15,2], [17,6], [22,7]]  # poly 2\n\t...        ])\n\t>>> w.record('polygon1')\n\t\n\t>>> w.close()\n\t\t\n**adding from an existing shape object**\n\nfinally, geometry can be added by passing an existing \"shape\" object to the \"shape\" method.\nyou can also pass it any geojson dictionary or _\\_geo_interface\\_\\_ compatible object. \nthis can be particularly useful for copying from one file to another:\n\n\n\t>>> r = shapefile.reader('shapefiles/test/polygon')\n\n\t>>> w = shapefile.writer('shapefiles/test/copy')\n\t>>> w.fields = r.fields[1:] # skip first deletion field\n\n\t>>> # adding existing shape objects\n\t>>> for shaperec in r.itershaperecords():\n\t...     w.record(*shaperec.record)\n\t...     w.shape(shaperec.shape)\n\t\n\t>>> # or geojson dicts\n\t>>> for shaperec in r.itershaperecords():\n\t...     w.record(*shaperec.record)\n\t...     w.shape(shaperec.shape.__geo_interface__)\n\t\n\t>>> w.close()\t\n\t\n\n### geometry and record balancing\n\nbecause every shape must have a corresponding record it is critical that the\nnumber of records equals the number of shapes to create a valid shapefile. you\nmust take care to add records and shapes in the same order so that the record\ndata lines up with the geometry data. for example:\n\n\t\n\t>>> w = shapefile.writer('shapefiles/test/balancing', shapetype=shapefile.point)\n\t>>> w.field(\"field1\", \"c\")\n\t>>> w.field(\"field2\", \"c\")\n\t\n\t>>> w.record(\"row\", \"one\")\n\t>>> w.point(1, 1)\n\t\n\t>>> w.record(\"row\", \"two\")\n\t>>> w.point(2, 2)\n\t\nto help prevent accidental misalignment pyshp has an \"auto balance\" feature to\nmake sure when you add either a shape or a record the two sides of the\nequation line up. this way if you forget to update an entry the\nshapefile will still be valid and handled correctly by most shapefile\nsoftware. autobalancing is not turned on by default. to activate it set\nthe attribute autobalance to 1 or true:\n\n\n    >>> w.autobalance = 1\n\t>>> w.record(\"row\", \"three\")\n\t>>> w.record(\"row\", \"four\")\n\t>>> w.point(4, 4)\n\t\n\t>>> w.recnum == w.shpnum\n\ttrue\n\nyou also have the option of manually calling the balance() method at any time\nto ensure the other side is up to date. when balancing is used\nnull shapes are created on the geometry side or records\nwith a value of \"null\" for each field is created on the attribute side.\nthis gives you flexibility in how you build the shapefile.\nyou can create all of the shapes and then create all of the records or vice versa. \n\n\n    >>> w.autobalance = 0\n\t>>> w.record(\"row\", \"five\")\n\t>>> w.record(\"row\", \"six\")\n\t>>> w.record(\"row\", \"seven\")\n\t>>> w.point(5, 5)\n\t>>> w.point(6, 6)\n\t>>> w.balance()\n\t\n\t>>> w.recnum == w.shpnum\n\ttrue\n\nif you do not use the autobalance() or balance() method and forget to manually\nbalance the geometry and attributes the shapefile will be viewed as corrupt by\nmost shapefile software.\n\t\n\n\n# advanced use\n\n## common errors and fixes\n\nbelow we list some commonly encountered errors and ways to fix them. \n\n### warnings and logging\n\nby default, pyshp chooses to be transparent and provide the user with logging information and warnings about non-critical issues when reading or writing shapefiles. this behavior is controlled by the module constant `verbose` (which defaults to true). if you would rather suppress this information, you can simply set this to false: \n\n\n\t>>> shapefile.verbose = false\n\nall logging happens under the namespace `shapefile`. so another way to suppress all pyshp warnings would be to alter the logging behavior for that namespace:\n\n\n\t>>> import logging\n\t>>> logging.getlogger('shapefile').setlevel(logging.error)\n\n### shapefile encoding errors\n\npyshp supports reading and writing shapefiles in any language or character encoding, and provides several options for decoding and encoding text. \nmost shapefiles are written in utf-8 encoding, pyshp's default encoding, so in most cases you don't have to specify the encoding. \nif you encounter an encoding error when reading a shapefile, this means the shapefile was likely written in a non-utf8 encoding. \nfor instance, when working with english language shapefiles, a common reason for encoding errors is that the shapefile was written in latin-1 encoding.\nfor reading shapefiles in any non-utf8 encoding, such as latin-1, just \nsupply the encoding option when creating the reader class. \n\n\n\t>>> r = shapefile.reader(\"shapefiles/test/latin1.shp\", encoding=\"latin1\")\n\t>>> r.record(0) == [2, u'\u00f1and\u00fa']\n\ttrue\n\t\nonce you have loaded the shapefile, you may choose to save it using another more supportive encoding such \nas utf-8. assuming the new encoding supports the characters you are trying to write, reading it back in \nshould give you the same unicode string you started with. \n\n\n\t>>> w = shapefile.writer(\"shapefiles/test/latin_as_utf8.shp\", encoding=\"utf8\")\n\t>>> w.fields = r.fields[1:]\n\t>>> w.record(*r.record(0))\n\t>>> w.null()\n\t>>> w.close()\n\t\n\t>>> r = shapefile.reader(\"shapefiles/test/latin_as_utf8.shp\", encoding=\"utf8\")\n\t>>> r.record(0) == [2, u'\u00f1and\u00fa']\n\ttrue\n\t\nif you supply the wrong encoding and the string is unable to be decoded, pyshp will by default raise an\nexception. if however, on rare occasion, you are unable to find the correct encoding and want to ignore\nor replace encoding errors, you can specify the \"encodingerrors\" to be used by the decode method. this\napplies to both reading and writing. \n\n\n\t>>> r = shapefile.reader(\"shapefiles/test/latin1.shp\", encoding=\"ascii\", encodingerrors=\"replace\")\n\t>>> r.record(0) == [2, u'\ufffdand\ufffd']\n\ttrue\n\n\n\n## reading large shapefiles\n\ndespite being a lightweight library, pyshp is designed to be able to read shapefiles of any size, allowing you to work with hundreds of thousands or even millions \nof records and complex geometries. \n\n### iterating through a shapefile\n\nas an example, let's load this natural earth shapefile of more than 4000 global administrative boundary polygons:\n\n\n\t>>> sf = shapefile.reader(\"https://github.com/nvkelso/natural-earth-vector/blob/master/10m_cultural/ne_10m_admin_1_states_provinces?raw=true\")\n\nwhen first creating the reader class, the library only reads the header information\nand leaves the rest of the file contents alone. once you call the records() and shapes() \nmethods however, it will attempt to read the entire file into memory at once. \nfor very large files this can result in memoryerror. so when working with large files\nit is recommended to use instead the itershapes(), iterrecords(), or itershaperecords()\nmethods instead. these iterate through the file contents one at a time, enabling you to loop \nthrough them while keeping memory usage at a minimum. \n\n\n\t>>> for shape in sf.itershapes():\n\t...     # do something here\n\t...     pass\n\t\n\t>>> for rec in sf.iterrecords():\n\t...     # do something here\n\t...     pass\n\t\n\t>>> for shaperec in sf.itershaperecords():\n\t...     # do something here\n\t...     pass\n\n\t>>> for shaperec in sf: # same as itershaperecords()\n\t...     # do something here\n\t...     pass\n\n### limiting which fields to read\n\nby default when reading the attribute records of a shapefile, pyshp unpacks and returns the data for all of the dbf fields, regardless of whether you actually need that data or not. to limit which field data is unpacked when reading each record and speed up processing time, you can specify the `fields` argument to any of the methods involving record data. note that the order of the specified fields does not matter, the resulting records will list the specified field values in the order that they appear in the original dbf file. for instance, if we are only interested in the country and name of each admin unit, the following is a more efficient way of iterating through the file:\n\n\n\t>>> fields = [\"geonunit\", \"name\"]\n\t>>> for rec in sf.iterrecords(fields=fields):\n\t... \t# do something\n\t... \tpass\n\t>>> rec\n\trecord #4595: ['birgu', 'malta']\n\t\n### attribute filtering\n\nin many cases, we aren't interested in all entries of a shapefile, but rather only want to retrieve a small subset of records by filtering on some attribute. to avoid wasting time reading records and shapes that we don't need, we can start by iterating only the records and fields of interest, check if the record matches some condition as a way to filter the data, and finally load the full record and shape geometry for those that meet the condition:\n\n\n\t>>> filter_field = \"geonunit\"\n\t>>> filter_value = \"eritrea\"\n\t>>> for rec in sf.iterrecords(fields=[filter_field]):\n\t...     if rec[filter_field] == filter_value:\n\t... \t\t# load full record and shape\n\t... \t\tshaperec = sf.shaperecord(rec.oid)\n\t... \t\tshaperec.record[\"name\"]\n\t'debubawi keyih bahri'\n\t'debub'\n\t'semenawi keyih bahri'\n\t'gash barka'\n\t'maekel'\n\t'anseba'\n\nselectively reading only the necessary data in this way is particularly useful for efficiently processing a limited subset of data from very large files or when looping through a large number of files, especially if they contain large attribute tables or complex shape geometries. \n\n### spatial filtering\n\nanother common use-case is that we only want to read those records that are located in some region of interest. because the shapefile stores the bounding box of each shape separately from the geometry data, it's possible to quickly retrieve all shapes that might overlap a given bounding box region without having to load the full shape geometry data for every shape. this can be done by specifying the `bbox` argument to any of the record or shape methods:\n\n\n\t>>> bbox = [36.423, 12.360, 43.123, 18.004] # ca bbox of eritrea\n\t>>> fields = [\"geonunit\",\"name\"]\n\t>>> for shaperec in sf.itershaperecords(bbox=bbox, fields=fields):\n\t... \tshaperec.record\n\trecord #368: ['afar', 'ethiopia']\n\trecord #369: ['tadjourah', 'djibouti']\n\trecord #375: ['obock', 'djibouti']\n\trecord #376: ['debubawi keyih bahri', 'eritrea']\n\trecord #1106: ['amhara', 'ethiopia']\n\trecord #1107: ['gedarif', 'sudan']\n\trecord #1108: ['tigray', 'ethiopia']\n\trecord #1414: ['sa`dah', 'yemen']\n\trecord #1415: ['`asir', 'saudi arabia']\n\trecord #1416: ['hajjah', 'yemen']\n\trecord #1417: ['jizan', 'saudi arabia']\n\trecord #1598: ['debub', 'eritrea']\n\trecord #1599: ['red sea', 'sudan']\n\trecord #1600: ['semenawi keyih bahri', 'eritrea']\n\trecord #1601: ['gash barka', 'eritrea']\n\trecord #1602: ['kassala', 'sudan']\n\trecord #1603: ['maekel', 'eritrea']\n\trecord #2037: ['al hudaydah', 'yemen']\n\trecord #3741: ['anseba', 'eritrea']\n\nthis functionality means that shapefiles can be used as a bare-bones spatially indexed database, with very fast bounding box queries for even the largest of shapefiles. note that, as with all spatial indexing, this method does not guarantee that the *geometries* of the resulting matches overlap the queried region, only that their *bounding boxes* overlap. \n\n\n\n## writing large shapefiles\n\nsimilar to the reader class, the shapefile writer class uses a streaming approach to keep memory \nusage at a minimum and allow writing shapefiles of arbitrarily large sizes. the library takes care of this under-the-hood by immediately \nwriting each geometry and record to disk the moment they \nare added using shape() or record(). once the writer is closed, exited, or garbage \ncollected, the final header information is calculated and written to the beginning of \nthe file. \n\n### merging multiple shapefiles\n\nthis means that it's possible to merge hundreds or thousands of shapefiles, as \nlong as you iterate through the source files to avoid loading everything into \nmemory. the following example copies the contents of a shapefile to a new file 10 times:\n\n\t>>> # create writer\n\t>>> w = shapefile.writer('shapefiles/test/merge')\n\n\t>>> # copy over fields from the reader\n\t>>> r = shapefile.reader(\"shapefiles/blockgroups\")\n\t>>> for field in r.fields[1:]:\n\t...     w.field(*field)\n\n\t>>> # copy the shapefile to writer 10 times\n\t>>> repeat = 10\n\t>>> for i in range(repeat):\n\t...     r = shapefile.reader(\"shapefiles/blockgroups\")\n\t...     for shaperec in r.itershaperecords():\n\t...         w.record(*shaperec.record)\n\t...         w.shape(shaperec.shape)\n\n\t>>> # check that the written file is 10 times longer\n\t>>> len(w) == len(r) * 10\n\ttrue\n\n\t>>> # close the writer\n\t>>> w.close()\n\nin this trivial example, we knew that all files had the exact same field names, ordering, and types. in other scenarios, you will have to additionally make sure that all shapefiles have the exact same fields in the same order, and that they all contain the same geometry type. \n\n### editing shapefiles\n\nif you need to edit a shapefile you would have to read the \nfile one record at a time, modify or filter the contents, and write it back out. for instance, to create a copy of a shapefile that only keeps a subset of relevant fields: \n\n\t>>> # create writer\n\t>>> w = shapefile.writer('shapefiles/test/edit')\n\n\t>>> # define which fields to keep\n\t>>> keep_fields = ['bkg_key', 'medianrent']\n\n\t>>> # copy over the relevant fields from the reader\n\t>>> r = shapefile.reader(\"shapefiles/blockgroups\")\n\t>>> for field in r.fields[1:]:\n\t...     if field[0] in keep_fields:\n\t...         w.field(*field)\n\n\t>>> # write only the relevant attribute values\n\t>>> for shaperec in r.itershaperecords(fields=keep_fields):\n\t...     w.record(*shaperec.record)\n\t...     w.shape(shaperec.shape)\n\n\t>>> # close writer\n\t>>> w.close()\n\n## 3d and other geometry types\n\nmost shapefiles store conventional 2d points, lines, or polygons. but the shapefile format is also capable\nof storing various other types of geometries as well, including complex 3d surfaces and objects. \n\n### shapefiles with measurement (m) values\n\nmeasured shape types are shapes that include a measurement value at each vertex, for instance\nspeed measurements from a gps device. shapes with measurement (m) values are added with the following\nmethods: \"pointm\", \"multipointm\", \"linem\", and \"polygonm\". the m-values are specified by adding a\nthird m value to each xy coordinate. missing or unobserved m-values are specified with a none value,\nor by simply omitting the third m-coordinate.\n\n\n\t>>> w = shapefile.writer('shapefiles/test/linem')\n\t>>> w.field('name', 'c')\n\t\n\t>>> w.linem([\n\t...\t\t\t[[1,5,0],[5,5],[5,1,3],[3,3,none],[1,1,0]], # line with one omitted and one missing m-value\n\t...\t\t\t[[3,2],[2,6]] # line without any m-values\n\t...\t\t\t])\n\t\n\t>>> w.record('linem1')\n\t\n\t>>> w.close()\n\t\nshapefiles containing m-values can be examined in several ways:\n\n\t>>> r = shapefile.reader('shapefiles/test/linem')\n\t\n\t>>> r.mbox # the lower and upper bound of m-values in the shapefile\n\t[0.0, 3.0]\n\t\n\t>>> r.shape(0).m # flat list of m-values\n\t[0.0, none, 3.0, none, 0.0, none, none]\n\n\t\n### shapefiles with elevation (z) values\n\nelevation shape types are shapes that include an elevation value at each vertex, for instance elevation from a gps device. \nshapes with elevation (z) values are added with the following methods: \"pointz\", \"multipointz\", \"linez\", and \"polyz\". \nthe z-values are specified by adding a third z value to each xy coordinate. z-values do not support the concept of missing data,\nbut if you omit the third z-coordinate it will default to 0. note that z-type shapes also support measurement (m) values added\nas a fourth m-coordinate. this too is optional. \n\t\n\t\n\t>>> w = shapefile.writer('shapefiles/test/linez')\n\t>>> w.field('name', 'c')\n\t\n\t>>> w.linez([\n\t...\t\t\t[[1,5,18],[5,5,20],[5,1,22],[3,3],[1,1]], # line with some omitted z-values\n\t...\t\t\t[[3,2],[2,6]], # line without any z-values\n\t...\t\t\t[[3,2,15,0],[2,6,13,3],[1,9,14,2]] # line with both z- and m-values\n\t...\t\t\t])\n\t\n\t>>> w.record('linez1')\n\t\n\t>>> w.close()\n\t\nto examine a z-type shapefile you can do:\n\n\t>>> r = shapefile.reader('shapefiles/test/linez')\n\t\n\t>>> r.zbox # the lower and upper bound of z-values in the shapefile\n\t[0.0, 22.0]\n\t\n\t>>> r.shape(0).z # flat list of z-values\n\t[18.0, 20.0, 22.0, 0.0, 0.0, 0.0, 0.0, 15.0, 13.0, 14.0]\n\n### 3d multipatch shapefiles\n\nmultipatch shapes are useful for storing composite 3-dimensional objects. \na multipatch shape represents a 3d object made up of one or more surface parts.\neach surface in \"parts\" is defined by a list of xyzm values (z and m values optional), and its corresponding type is\ngiven in the \"parttypes\" argument. the part type decides how the coordinate sequence is to be interpreted, and can be one \nof the following module constants: triangle_strip, triangle_fan, outer_ring, inner_ring, first_ring, or ring.\nfor instance, a triangle_strip may be used to represent the walls of a building, combined with a triangle_fan to represent \nits roof: \n\n\t>>> from shapefile import triangle_strip, triangle_fan\n\t\n\t>>> w = shapefile.writer('shapefiles/test/multipatch')\n\t>>> w.field('name', 'c')\n\t\n\t>>> w.multipatch([\n\t...\t\t\t\t [[0,0,0],[0,0,3],[5,0,0],[5,0,3],[5,5,0],[5,5,3],[0,5,0],[0,5,3],[0,0,0],[0,0,3]], # triangle_strip for house walls\n\t...\t\t\t\t [[2.5,2.5,5],[0,0,3],[5,0,3],[5,5,3],[0,5,3],[0,0,3]], # triangle_fan for pointed house roof\n\t...\t\t\t\t ],\n\t...\t\t\t\t parttypes=[triangle_strip, triangle_fan]) # one type for each part\n\t\n\t>>> w.record('house1')\n\t\n\t>>> w.close()\n\t\nfor an introduction to the various multipatch part types and examples of how to create 3d multipatch objects see [this\nesri white paper](http://downloads.esri.com/support/whitepapers/ao_/j9749_multipatch_geometry_type.pdf). \n\n\n\t\n# testing\n\nthe testing framework is pytest, and the tests are located in test_shapefile.py. \nthis includes an extensive set of unit tests of the various pyshp features, \nand tests against various input data. some of the tests that require \ninternet connectivity will be skipped in offline testing environments. \nin the same folder as readme.md and shapefile.py, from the command line run \n```\n$ python -m pytest\n``` \n\nadditionally, all the code and examples located in this file, readme.md, \nis tested and verified with the builtin doctest framework.\na special routine for invoking the doctest is run when calling directly on shapefile.py.\nin the same folder as readme.md and shapefile.py, from the command line run \n```\n$ python shapefile.py\n``` \n\nlinux/mac and similar platforms will need to run `$ dos2unix readme.md` in order\nto correct line endings in readme.md.\n\n# contributors\n\n```\natle frenvik sveen\nbas couwenberg\nben beasley\ncasey meisenzahl\ncharles arnold\ndavid a. riggs\ndavidh-ssec\nevan heidtmann\nezcitron\nfiveham\ngeospatialpython\nhannes\nignacio martinez vazquez\njason moujaes\njonty wareing\nkarim bahgat\nkaranrn\nkyle kelley\nlouis tiao\nmarcin cuprjak\nmcuprjak\nmicah cochran\nmichael davis\nmichal \u010diha\u0159\nmike toews\nmiroslav \u0161ediv\u00fd\nnilo\npakoun\npaulo ernesto\nraynor vliegendhart\nrazzi abuissa\nrosber97\nross rogers\nryan brideau\ntim gates\ntobias megies\ntommi penttinen\nuli k\u00f6hler\nvsevolod novikov\nzac miller\n```\n",
  "docs_url": null,
  "keywords": "gis,geospatial,geographic,shapefile,shapefiles",
  "license": "mit",
  "name": "pyshp",
  "package_url": "https://pypi.org/project/pyshp/",
  "project_url": "https://pypi.org/project/pyshp/",
  "project_urls": {
    "Download": "https://pypi.org/project/pyshp/",
    "Homepage": "https://github.com/GeospatialPython/pyshp"
  },
  "release_url": "https://pypi.org/project/pyshp/2.3.1/",
  "requires_dist": [],
  "requires_python": ">=2.7",
  "summary": "pure python read/write support for esri shapefile format",
  "version": "2.3.1",
  "releases": [],
  "developers": [
    "jlawhead@geospatialpython.com",
    "joel_lawhead",
    "karim.bahgat.norway@gmail.com",
    "karim_bahgat"
  ],
  "kwds": "pyshp geospatialpython shapefiles shapefile pytest",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_pyshp",
  "homepage": "https://github.com/geospatialpython/pyshp",
  "release_count": 25,
  "dependency_ids": []
}