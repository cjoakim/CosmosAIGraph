{
  "classifiers": [
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3"
  ],
  "description": "# sacremoses\n\n# license\n\n[mit license](license).\n\n# install\n\n```\npip install -u sacremoses\n```\n\nnote: sacremoses only supports python 3 now (`sacremoses>=0.0.41`). if you're using python 2, the last possible version is `sacremoses==0.0.40`.\n\n# usage (python)\n\n## tokenizer and detokenizer\n\n```python\n>>> from sacremoses import mosestokenizer, mosesdetokenizer\n>>> mt = mosestokenizer(lang='en')\n>>> text = 'this, is a sentence with weird\\xbb symbols\\u2026 appearing everywhere\\xbf'\n>>> expected_tokenized = 'this , is a sentence with weird \\xbb symbols \\u2026 appearing everywhere \\xbf'\n>>> tokenized_text = mt.tokenize(text, return_str=true)\n>>> tokenized_text == expected_tokenized\ntrue\n\n\n>>> mt, md = mosestokenizer(lang='en'), mosesdetokenizer(lang='en')\n>>> sent = \"this ain't funny. it's actually hillarious, yet double ls. | [] < > [ ] & you're gonna shake it off? don't?\"\n>>> expected_tokens = ['this', 'ain', '&apos;t', 'funny', '.', 'it', '&apos;s', 'actually', 'hillarious', ',', 'yet', 'double', 'ls', '.', '&#124;', '&#91;', '&#93;', '&lt;', '&gt;', '&#91;', '&#93;', '&amp;', 'you', '&apos;re', 'gonna', 'shake', 'it', 'off', '?', 'don', '&apos;t', '?']\n>>> expected_detokens = \"this ain't funny. it's actually hillarious, yet double ls. | [] < > [] & you're gonna shake it off? don't?\"\n>>> mt.tokenize(sent) == expected_tokens\ntrue\n>>> md.detokenize(tokens) == expected_detokens\ntrue\n```\n\n\n## truecaser\n\n```python\n>>> from sacremoses import mosestruecaser, mosestokenizer\n\n# train a new truecaser from a 'big.txt' file.\n>>> mtr = mosestruecaser()\n>>> mtok = mosestokenizer(lang='en')\n\n# save the truecase model to 'big.truecasemodel' using `save_to`\n>> tokenized_docs = [mtok.tokenize(line) for line in open('big.txt')]\n>>> mtr.train(tokenized_docs, save_to='big.truecasemodel')\n\n# save the truecase model to 'big.truecasemodel' after training\n# (just in case you forgot to use `save_to`)\n>>> mtr = mosestruecaser()\n>>> mtr.train('big.txt')\n>>> mtr.save_model('big.truecasemodel')\n\n# truecase a string after training a model.\n>>> mtr = mosestruecaser()\n>>> mtr.train('big.txt')\n>>> mtr.truecase(\"the adventures of sherlock holmes\")\n['the', 'adventures', 'of', 'sherlock', 'holmes']\n\n# loads a model and truecase a string using trained model.\n>>> mtr = mosestruecaser('big.truecasemodel')\n>>> mtr.truecase(\"the adventures of sherlock holmes\")\n['the', 'adventures', 'of', 'sherlock', 'holmes']\n>>> mtr.truecase(\"the adventures of sherlock holmes\", use_known=true)\n['the', 'adventures', 'of', 'sherlock', 'holmes']\n>>> mtr.truecase(\"the adventures of sherlock holmes\", return_str=true)\n'the adventures of sherlock holmes'\n```\n\n## normalizer\n\n```python\n>>> from sacremoses import mosespunctnormalizer\n>>> mpn = mosespunctnormalizer()\n>>> mpn.normalize('this ebook is otherwise provided to you \"as-is.\"')\n'this ebook is otherwise provided to you \"as-is.\"'\n```\n\n# usage (cli)\n\nsince version `0.0.42`, the pipeline feature for cli is introduced, thus there\nare global options that should be set first before calling the commands:\n\n - language\n - processes\n - encoding\n - quiet\n\n```shell\n$ pip install -u sacremoses>=0.1\n\n$ sacremoses --help\nusage: sacremoses [options] command1 [args]... [command2 [args]...]...\n\noptions:\n  -l, --language text      use language specific rules when tokenizing\n  -j, --processes integer  no. of processes.\n  -e, --encoding text      specify encoding of file.\n  -q, --quiet              disable progress bar.\n  --version                show the version and exit.\n  -h, --help               show this message and exit.\n\ncommands:\n  detokenize\n  detruecase\n  normalize\n  tokenize\n  train-truecase\n  truecase\n```\n\n## pipeline\n\nexample to chain the following commands:\n\n - `normalize` with `-c` option to remove control characters.\n - `tokenize` with `-a` option for aggressive dash split rules.\n - `truecase` with `-a` option to indicate that model is for asr \n   - if `big.truemodel` exists, load the model with `-m` option,\n   - otherwise train a model and save it with `-m` option to `big.truemodel` file.\n - save the output to console to the `big.txt.norm.tok.true` file.\n\n```shell\ncat big.txt | sacremoses -l en -j 4 \\\n    normalize -c tokenize -a truecase -a -m big.truemodel \\\n    > big.txt.norm.tok.true\n```\n\n## tokenizer\n\n```shell\n$ sacremoses tokenize --help\nusage: sacremoses tokenize [options]\n\noptions:\n  -a, --aggressive-dash-splits   triggers dash split rules.\n  -x, --xml-escape               escape special characters for xml.\n  -p, --protected-patterns text  specify file with patters to be protected in\n                                 tokenisation.\n  -c, --custom-nb-prefixes text  specify a custom non-breaking prefixes file,\n                                 add prefixes to the default ones from the\n                                 specified language.\n  -h, --help                     show this message and exit.\n\n\n $ sacremoses -l en -j 4 tokenize  < big.txt > big.txt.tok\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128457/128457 [00:05<00:00, 24363.39it/s\n\n $ wget https://raw.githubusercontent.com/moses-smt/mosesdecoder/master/scripts/tokenizer/basic-protected-patterns\n $ sacremoses -l en -j 4 tokenize -p basic-protected-patterns < big.txt > big.txt.tok\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128457/128457 [00:05<00:00, 22183.94it/s\n```\n\n## detokenizer\n\n```shell\n$ sacremoses detokenize --help\nusage: sacremoses detokenize [options]\n\noptions:\n  -x, --xml-unescape  unescape special characters for xml.\n  -h, --help          show this message and exit.\n\n $ sacremoses -l en -j 4 detokenize < big.txt.tok > big.txt.tok.detok\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128457/128457 [00:16<00:00, 7931.26it/s]\n```\n\n## truecase\n\n```shell\n$ sacremoses truecase --help\nusage: sacremoses truecase [options]\n\noptions:\n  -m, --modelfile text            filename to save/load the modelfile.\n                                  [required]\n  -a, --is-asr                    a flag to indicate that model is for asr.\n  -p, --possibly-use-first-token  use the first token as part of truecase\n                                  training.\n  -h, --help                      show this message and exit.\n\n$ sacremoses -j 4 truecase -m big.model < big.txt.tok > big.txt.tok.true\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128457/128457 [00:09<00:00, 14257.27it/s]\n```\n\n## detruecase\n\n```shell\n$ sacremoses detruecase --help\nusage: sacremoses detruecase [options]\n\noptions:\n  -j, --processes integer  no. of processes.\n  -a, --is-headline        whether the file are headlines.\n  -e, --encoding text      specify encoding of file.\n  -h, --help               show this message and exit.\n\n$ sacremoses -j 4 detruecase  < big.txt.tok.true > big.txt.tok.true.detrue\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128457/128457 [00:04<00:00, 26945.16it/s]\n```\n\n## normalize\n\n```shell\n$ sacremoses normalize --help\nusage: sacremoses normalize [options]\n\noptions:\n  -q, --normalize-quote-commas  normalize quotations and commas.\n  -d, --normalize-numbers       normalize number.\n  -p, --replace-unicode-puncts  replace unicode punctuations before\n                                normalization.\n  -c, --remove-control-chars    remove control characters after normalization.\n  -h, --help                    show this message and exit.\n\n$ sacremoses -j 4 normalize < big.txt > big.txt.norm\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128457/128457 [00:09<00:00, 13096.23it/s]\n```\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "sacremoses",
  "package_url": "https://pypi.org/project/sacremoses/",
  "project_url": "https://pypi.org/project/sacremoses/",
  "project_urls": {
    "Homepage": "https://github.com/hplt-project/sacremoses"
  },
  "release_url": "https://pypi.org/project/sacremoses/0.1.1/",
  "requires_dist": [
    "regex",
    "click",
    "joblib",
    "tqdm"
  ],
  "requires_python": ">=3.8",
  "summary": "sacremoses",
  "version": "0.1.1",
  "releases": [],
  "developers": [],
  "kwds": "tokenized_text tokenizer tokenisation tokenizing sacremoses",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_sacremoses",
  "homepage": "https://github.com/hplt-project/sacremoses",
  "release_count": 52,
  "dependency_ids": [
    "pypi_click",
    "pypi_joblib",
    "pypi_regex",
    "pypi_tqdm"
  ]
}