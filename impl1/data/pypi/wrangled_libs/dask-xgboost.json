{
  "classifiers": [],
  "description": "dask-xgboost\n============\n\n.. warning::\n\n   dask-xgboost has been deprecated and is no longer maintained. the functionality\n   of this project has been included directly in xgboost. to use dask and xgboost\n   together, please use ``xgboost.dask`` instead\n   https://xgboost.readthedocs.io/en/latest/tutorials/dask.html.\n\ndistributed training with xgboost and dask.distributed\n\nthis repository offers a legacy option to perform distributed training\nwith xgboost on dask.array and dask.dataframe collections.\n\n::\n\n   pip install dask-xgboost\n\nplease note that xgboost now includes a dask api as part of its official python package.\nthat api is independent of `dask-xgboost` and is now the recommended way to use dask\nadn xgboost together. see\n`the xgb.dask documentation here https://xgboost.readthedocs.io/en/latest/tutorials/dask.html`\nfor more details on the new api.\n\n\n\nexample\n-------\n\n.. code-block:: python\n\n   from dask.distributed import client\n   client = client('scheduler-address:8786')  # connect to cluster\n\n   import dask.dataframe as dd\n   df = dd.read_csv('...')  # use dask.dataframe to load and\n   df_train = ...           # preprocess data\n   labels_train = ...\n\n   import dask_xgboost as dxgb\n   params = {'objective': 'binary:logistic', ...}  # use normal xgboost params\n   bst = dxgb.train(client, params, df_train, labels_train)\n\n   >>> bst  # get back normal xgboost result\n   <xgboost.core.booster at ... >\n\n   predictions = dxgb.predict(client, bst, data_test)\n\n\nhow this works\n--------------\n\nfor more information on using dask.dataframe for preprocessing see the\n`dask.dataframe documentation <http://dask.pydata.org/en/latest/dataframe.html>`_.\n\nonce you have created suitable data and labels we are ready for distributed\ntraining with xgboost.  every dask worker sets up an xgboost slave and gives\nthem enough information to find each other.  then dask workers hand their\nin-memory pandas dataframes to xgboost (one dask dataframe is just many pandas\ndataframes spread around the memory of many machines).  xgboost handles\ndistributed training on its own without dask interference.  xgboost then hands\nback a single ``xgboost.booster`` result object.\n\n\nlarger example\n--------------\n\nfor a more serious example see\n\n-  `this blogpost <http://matthewrocklin.com/blog/work/2017/03/28/dask-xgboost>`_\n-  `this notebook <https://gist.github.com/mrocklin/19c89d78e34437e061876a9872f4d2df>`_\n-  `this screencast <https://youtu.be/cc4e-pddsro>`_\n\nhistory\n-------\n\nconversation during development happened at `dmlc/xgboost #2032\n<https://github.com/dmlc/xgboost/issues/2032>`_\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "bsd",
  "name": "dask-xgboost",
  "package_url": "https://pypi.org/project/dask-xgboost/",
  "project_url": "https://pypi.org/project/dask-xgboost/",
  "project_urls": {
    "Homepage": "https://github.com/dask/dask-xgboost"
  },
  "release_url": "https://pypi.org/project/dask-xgboost/0.2.0/",
  "requires_dist": [
    "xgboost (<=0.90)",
    "dask",
    "distributed (>=1.15.2)",
    "sparse ; extra == 'sparse'",
    "scipy ; extra == 'sparse'"
  ],
  "requires_python": "",
  "summary": "interactions between dask and xgboost",
  "version": "0.2.0",
  "releases": [],
  "developers": [
    "matthew_rocklin",
    "mrocklin@continuum.io"
  ],
  "kwds": "dask_xgboost dask xgboost xgb pandas",
  "license_kwds": "bsd",
  "libtype": "pypi",
  "id": "pypi_dask_xgboost",
  "homepage": "https://github.com/dask/dask-xgboost",
  "release_count": 9,
  "dependency_ids": [
    "pypi_dask",
    "pypi_distributed",
    "pypi_scipy",
    "pypi_sparse",
    "pypi_xgboost"
  ]
}