{
  "classifiers": [],
  "description": "<p align=\"center\">\n    <br>\n    <img src=\"https://github.com/makcedward/nlpaug/blob/master/res/logo_small.png\"/>\n    <br>\n<p>\n<p align=\"center\">\n    <a href=\"https://travis-ci.org/makcedward/nlpaug\">\n        <img alt=\"build\" src=\"https://travis-ci.org/makcedward/nlpaug.svg?branch=master\">\n    </a>\n    <a href=\"https://www.codacy.com/app/makcedward/nlpaug?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=makcedward/nlpaug&amp;utm_campaign=badge_grade\">\n        <img alt=\"code quality\" src=\"https://api.codacy.com/project/badge/grade/2d6d1d08016a4f78818161a89a2dfbfb\">\n    </a>\n    <a href=\"https://pepy.tech/badge/nlpaug\">\n        <img alt=\"downloads\" src=\"https://pepy.tech/badge/nlpaug\">\n    </a>\n</p>\n\n# nlpaug\n\nthis python library helps you with augmenting nlp for your machine learning projects. visit this introduction to understand about [data augmentation in nlp](https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28). `augmenter` is the basic element of augmentation while `flow` is a pipeline to orchestra multi augmenter together.\n\n## features\n*   generate synthetic data for improving model performance without manual effort\n*   simple, easy-to-use and lightweight library. augment data in 3 lines of code\n*   plug and play to any machine leanring/ neural network frameworks (e.g. scikit-learn, pytorch, tensorflow)\n*   support textual and audio input\n\n<h3 align=\"center\">textual data augmentation example</h3>\n<br><p align=\"center\"><img src=\"https://github.com/makcedward/nlpaug/blob/master/res/textual_example.png\"/></p>\n<h3 align=\"center\">acoustic data augmentation example</h3>\n<br><p align=\"center\"><img src=\"https://github.com/makcedward/nlpaug/blob/master/res/audio_example.png\"/></p>\n\n| section | description |\n|:---:|:---:|\n| [quick demo](https://github.com/makcedward/nlpaug#quick-demo) | how to use this library |\n| [augmenter](https://github.com/makcedward/nlpaug#augmenter) | introduce all available augmentation methods |\n| [installation](https://github.com/makcedward/nlpaug#installation) | how to install this library |\n| [recent changes](https://github.com/makcedward/nlpaug#recent-changes) | latest enhancement |\n| [extension reading](https://github.com/makcedward/nlpaug#extension-reading) | more real life examples or researchs |\n| [reference](https://github.com/makcedward/nlpaug#reference) | reference of external resources such as data or model |\n\n## quick demo\n*   [quick example](https://github.com/makcedward/nlpaug/blob/master/example/quick_example.ipynb)\n*   [example of augmentation for textual inputs](https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb)\n*   [example of augmentation for multilingual textual inputs ](https://github.com/makcedward/nlpaug/blob/master/example/textual_language_augmenter.ipynb)\n*   [example of augmentation for spectrogram inputs](https://github.com/makcedward/nlpaug/blob/master/example/spectrogram_augmenter.ipynb)\n*   [example of augmentation for audio inputs](https://github.com/makcedward/nlpaug/blob/master/example/audio_augmenter.ipynb)\n*   [example of orchestra multiple augmenters](https://github.com/makcedward/nlpaug/blob/master/example/flow.ipynb)\n*   [example of showing augmentation history](https://github.com/makcedward/nlpaug/blob/master/example/change_log.ipynb)\n*   how to train [tf-idf model](https://github.com/makcedward/nlpaug/blob/master/example/tfidf-train_model.ipynb)\n*   how to train [lambada model](https://github.com/makcedward/nlpaug/blob/master/example/lambada-train_model.ipynb)\n*   how to create [custom augmentation](https://github.com/makcedward/nlpaug/blob/master/example/custom_augmenter.ipynb)\n*   [api documentation](https://nlpaug.readthedocs.io/en/latest/)\n\n## augmenter\n| augmenter | target | augmenter | action | description |\n|:---:|:---:|:---:|:---:|:---:|\n|textual| character | keyboardaug | substitute | simulate keyboard distance error |\n|textual| | ocraug | substitute | simulate ocr engine error |\n|textual| | [randomaug](https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c) | insert, substitute, swap, delete | apply augmentation randomly |\n|textual| word | antonymaug | substitute | substitute opposite meaning word according to wordnet antonym|\n|textual| | contextualwordembsaug | insert, substitute | feeding surroundings word to [bert](https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb), distilbert, [roberta](https://medium.com/towards-artificial-intelligence/a-robustly-optimized-bert-pretraining-approach-f6b6e537e6a6) or [xlnet](https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b) language model to find out the most suitlabe word for augmentation|\n|textual| | randomwordaug | swap, crop, delete | apply augmentation randomly |\n|textual| | spellingaug | substitute | substitute word according to spelling mistake dictionary |\n|textual| | splitaug | split | split one word to two words randomly|\n|textual| | synonymaug | substitute | substitute similar word according to wordnet/ ppdb synonym |\n|textual| | [tfidfaug](https://medium.com/towards-artificial-intelligence/unsupervised-data-augmentation-6760456db143) | insert, substitute | use tf-idf to find out how word should be augmented |\n|textual| | wordembsaug | insert, substitute | leverage  [word2vec](https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a), [glove](https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a) or [fasttext](https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a) embeddings to apply augmentation|\n|textual| | [backtranslationaug](https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28) | substitute | leverage two translation models for augmentation |\n|textual| | reservedaug | substitute | replace reserved words |\n|textual| sentence | contextualwordembsforsentenceaug | insert | insert sentence according to [xlnet](https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b), [gpt2](https://towardsdatascience.com/too-powerful-nlp-model-generative-pre-training-2-4cc6afb6655) or distilgpt2 prediction |\n|textual| | abstsummaug | substitute | summarize article by abstractive summarization method |\n|textual| | lambadaaug | substitute | using language model to generate text and then using classification model to retain high quality results |\n|signal| audio | cropaug | delete | delete audio's segment |\n|signal| | loudnessaug|substitute | adjust audio's volume |\n|signal| | maskaug | substitute | mask audio's segment |\n|signal| | noiseaug | substitute | inject noise |\n|signal| | pitchaug | substitute | adjust audio's pitch |\n|signal| | shiftaug | substitute | shift time dimension forward/ backward |\n|signal| | speedaug | substitute | adjust audio's speed |\n|signal| | vtlpaug | substitute | change vocal tract |\n|signal| | normalizeaug | substitute | normalize audio |\n|signal| | polarityinverseaug | substitute | swap positive and negative for audio |\n|signal| spectrogram | frequencymaskingaug | substitute | set block of values to zero according to frequency dimension |\n|signal| | timemaskingaug | substitute | set block of values to zero according to time dimension |\n|signal| | loudnessaug | substitute | adjust volume |\n\n## flow\n| augmenter | augmenter | description |\n|:---:|:---:|:---:|\n|pipeline| sequential | apply list of augmentation functions sequentially |\n|pipeline| sometimes | apply some augmentation functions randomly |\n\n## installation\nthe library supports python 3.5+ in linux and window platform.\n\nto install the library:\n```bash\npip install numpy requests nlpaug\n```\nor install the latest version (include beta features) from github directly\n```bash\npip install numpy git+https://github.com/makcedward/nlpaug.git\n```\nor install over conda\n```bash\nconda install -c makcedward nlpaug\n```\n\nif you use backtranslationaug, contextualwordembsaug, contextualwordembsforsentenceaug and abstsummaug, installing the following dependencies as well\n```bash\npip install torch>=1.6.0 transformers>=4.11.3 sentencepiece\n```\n\nif you use lambadaaug, installing the following dependencies as well\n```bash\npip install simpletransformers>=0.61.10\n```\n\nif you use antonymaug, synonymaug, installing the following dependencies as well\n```bash\npip install nltk>=3.4.5\n```\n\nif you use wordembsaug (word2vec, glove or fasttext), downloading pre-trained model first and installing the following dependencies as well\n```bash\nfrom nlpaug.util.file.download import downloadutil\ndownloadutil.download_word2vec(dest_dir='.') # download word2vec model\ndownloadutil.download_glove(model_name='glove.6b', dest_dir='.') # download glove model\ndownloadutil.download_fasttext(model_name='wiki-news-300d-1m', dest_dir='.') # download fasttext model\n\npip install gensim>=4.1.2\n```\n\nif you use synonymaug (ppdb), downloading file from the following uri. you may not able to run the augmenter if you get ppdb file from other website\n```bash\nhttp://paraphrase.org/#/download\n```\n\nif you use pitchaug, speedaug and vtlpaug, installing the following dependencies as well\n```bash\npip install librosa>=0.9.1 matplotlib\n```\n\n## recent changes\n\n### 1.1.11 jul 6, 2022\n*   [return list of output](https://github.com/makcedward/nlpaug/issues/302)\n*   [fix download util](https://github.com/makcedward/nlpaug/issues/301)\n*   [fix lambda label misalignment](https://github.com/makcedward/nlpaug/issues/295)\n*   [add language pack reference link for synonymaug](https://github.com/makcedward/nlpaug/issues/289)\n\n\nsee [changelog](https://github.com/makcedward/nlpaug/blob/master/change.md) for more details.\n\n## extension reading\n*   [data augmentation library for text](https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff)\n*   [does your nlp model able to prevent adversarial attack?](https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c)\n*   [how does data noising help to improve your nlp model?](https://medium.com/towards-artificial-intelligence/how-does-data-noising-help-to-improve-your-nlp-model-480619f9fb10)\n*   [data augmentation library for speech recognition](https://towardsdatascience.com/data-augmentation-for-speech-recognition-e7c607482e78)\n*   [data augmentation library for audio](https://towardsdatascience.com/data-augmentation-for-audio-76912b01fdf6)\n*   [unsupervied data augmentation](https://medium.com/towards-artificial-intelligence/unsupervised-data-augmentation-6760456db143)\n*   [a visual survey of data augmentation in nlp](https://amitness.com/2020/05/data-augmentation-for-nlp/)\n\n## reference\nthis library uses data (e.g. capturing from internet), research (e.g. following augmenter idea), model (e.g. using pre-trained model) see [data source](https://github.com/makcedward/nlpaug/blob/master/source.md) for more details.\n\n## citation\n\n```latex\n@misc{ma2019nlpaug,\n  title={nlp augmentation},\n  author={edward ma},\n  howpublished={https://github.com/makcedward/nlpaug},\n  year={2019}\n}\n```\n\nthis package is cited by many books, workshop and academic research papers (70+). here are some of examples and you may visit [here](https://github.com/makcedward/nlpaug/blob/master/cited.md) to get the full list.\n\n### workshops cited nlpaug\n*   s. vajjala. [nlp without a readymade labeled dataset](https://rpubs.com/vbsowmya/tmls2021) at [toronto machine learning summit, 2021](https://www.torontomachinelearning.com/). 2021\n\n### book cited nlpaug\n*   s. vajjala, b. majumder, a. gupta and h. surana. [practical natural language processing: a comprehensive guide to building real-world nlp systems](https://www.amazon.com/practical-natural-language-processing-pragmatic/dp/1492054054). 2020\n*   a. bartoli and a. fusiello. [computer vision\u2013eccv 2020 workshops](https://books.google.com/books?hl=en&lr=lang_en&id=0ryreaaaqbaj&oi=fnd&pg=pr7&dq=nlpaug&ots=88bpp5rhny&sig=c2ue8xxbu09l59namocvxwyvvwm#v=onepage&q=nlpaug&f=false). 2020\n*   l. werra, l. tunstall, and t. wolf [natural language processing with transformers](https://www.amazon.com/natural-language-processing-transformers-applications/dp/1098103246/ref=sr_1_3?crid=2cwbpa8qg0tru&keywords=natural+language+processing+with+transformers&qid=1645646312&sprefix=natural+language+processing+with+transformers%2caps%2c111&sr=8-3). 2022\n\n### research paper cited nlpaug\n*   google: m. raghu and  e. schmidt. [a survey of deep learning for scientific discovery](https://arxiv.org/pdf/2003.11755.pdf). 2020\n*   sirius xm: e. jing, k. schneck, d. egan and s. a. waterman. [identifying introductions in podcast episodes from automatically generated transcripts](https://arxiv.org/pdf/2110.07096.pdf). 2021\n*   salesforce research: b. newman, p. k. choubey and n. rajani. [p-adapters: robustly extracting factual information from language modesl with diverse prompts](https://arxiv.org/pdf/2110.07280.pdf). 2021\n*   salesforce research: l. xue, m. gao, z. chen, c. xiong and r. xu. [robustness evaluation of transformer-based form field extractors via form attacks](https://arxiv.org/pdf/2110.04413.pdf). 2021\n\n\n## contributions\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/sakares\"><img src=\"https://avatars.githubusercontent.com/u/1306031\" width=\"100px;\" alt=\"\"/><br /><sub><b>sakares saengkaew</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/bdalal\"><img src=\"https://avatars.githubusercontent.com/u/3478378?s=400&v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>binoy dalal</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/emrecncelik\"><img src=\"https://avatars.githubusercontent.com/u/20845117?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>emrecan \u00e7elik</b></sub></a><br /></td>\n  </tr>\n</table>\n",
  "docs_url": null,
  "keywords": "deep learning,neural network,machine learning,nlp,natural language processing,text,audio,spectrogram,augmentation,adversarial attack,ai,ml",
  "license": "mit",
  "name": "nlpaug",
  "package_url": "https://pypi.org/project/nlpaug/",
  "project_url": "https://pypi.org/project/nlpaug/",
  "project_urls": {
    "Homepage": "https://github.com/makcedward/nlpaug"
  },
  "release_url": "https://pypi.org/project/nlpaug/1.1.11/",
  "requires_dist": [
    "numpy (>=1.16.2)",
    "pandas (>=1.2.0)",
    "requests (>=2.22.0)",
    "gdown (>=4.0.0)"
  ],
  "requires_python": ">=3.7",
  "summary": "natural language processing augmentation library for deep neural networks",
  "version": "1.1.11",
  "releases": [],
  "developers": [
    "edward_ma",
    "makcedward@gmail.com"
  ],
  "kwds": "nlpaug nltk wordnet networks nlp",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_nlpaug",
  "homepage": "https://github.com/makcedward/nlpaug",
  "release_count": 37,
  "dependency_ids": [
    "pypi_gdown",
    "pypi_numpy",
    "pypi_pandas",
    "pypi_requests"
  ]
}