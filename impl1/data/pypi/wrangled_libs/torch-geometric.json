{
  "classifiers": [
    "development status :: 5 - production/stable",
    "license :: osi approved :: mit license",
    "programming language :: python",
    "programming language :: python :: 3 :: only",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "graph neural network library for pytorch\n[pypi-image]: https://badge.fury.io/py/torch-geometric.svg\n[pypi-url]: https://pypi.python.org/pypi/torch-geometric\n[testing-image]: https://github.com/pyg-team/pytorch_geometric/actions/workflows/testing.yml/badge.svg\n[testing-url]: https://github.com/pyg-team/pytorch_geometric/actions/workflows/testing.yml\n[linting-image]: https://github.com/pyg-team/pytorch_geometric/actions/workflows/linting.yml/badge.svg\n[linting-url]: https://github.com/pyg-team/pytorch_geometric/actions/workflows/linting.yml\n[docs-image]: https://readthedocs.org/projects/pytorch-geometric/badge/?version=latest\n[docs-url]: https://pytorch-geometric.readthedocs.io/en/latest\n[coverage-image]: https://codecov.io/gh/pyg-team/pytorch_geometric/branch/master/graph/badge.svg\n[coverage-url]: https://codecov.io/github/pyg-team/pytorch_geometric?branch=master\n[contributing-image]: https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\n[contributing-url]: https://github.com/pyg-team/pytorch_geometric/blob/master/.github/contributing.md\n[slack-image]: https://img.shields.io/badge/slack-pyg-brightgreen\n[slack-url]: https://data.pyg.org/slack.html\n\n<p align=\"center\">\n  <img height=\"150\" src=\"https://raw.githubusercontent.com/pyg-team/pyg_sphinx_theme/master/pyg_sphinx_theme/static/img/pyg_logo_text.svg?sanitize=true\" />\n</p>\n\n--------------------------------------------------------------------------------\n\n[![pypi version][pypi-image]][pypi-url]\n[![testing status][testing-image]][testing-url]\n[![linting status][linting-image]][linting-url]\n[![docs status][docs-image]][docs-url]\n[![contributing][contributing-image]][contributing-url]\n[![slack][slack-image]][slack-url]\n\n**[documentation](https://pytorch-geometric.readthedocs.io)** | **[paper](https://arxiv.org/abs/1903.02428)** | **[colab notebooks and video tutorials](https://pytorch-geometric.readthedocs.io/en/latest/get_started/colabs.html)** | **[external resources](https://pytorch-geometric.readthedocs.io/en/latest/external/resources.html)** | **[ogb examples](https://github.com/snap-stanford/ogb/tree/master/examples)**\n\n**pyg** *(pytorch geometric)* is a library built upon [pytorch](https://pytorch.org/) to easily write and train graph neural networks (gnns) for a wide range of applications related to structured data.\n\nit consists of various methods for deep learning on graphs and other irregular structures, also known as *[geometric deep learning](http://geometricdeeplearning.com/)*, from a variety of published papers.\nin addition, it consists of easy-to-use mini-batch loaders for operating on many small and single giant graphs, [multi gpu-support](https://github.com/pyg-team/pytorch_geometric/tree/master/examples/multi_gpu), [`torch.compile`](https://pytorch-geometric.readthedocs.io/en/latest/advanced/compile.html) support, [`datapipe`](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/datapipe.py) support, a large number of common benchmark datasets (based on simple interfaces to create your own), the [graphgym](https://pytorch-geometric.readthedocs.io/en/latest/advanced/graphgym.html) experiment manager, and helpful transforms, both for learning on arbitrary graphs as well as on 3d meshes or point clouds.\n\n**[click here to join our slack community!][slack-url]**\n\n<p align=\"center\">\n  <a href=\"https://medium.com/stanford-cs224w\"><img style=\"max-width=: 941px\" src=\"https://data.pyg.org/img/cs224w_tutorials.png\" /></a>\n</p>\n\n--------------------------------------------------------------------------------\n\n* [library highlights](#library-highlights)\n* [quick tour for new users](#quick-tour-for-new-users)\n* [architecture overview](#architecture-overview)\n* [implemented gnn models](#implemented-gnn-models)\n* [installation](#installation)\n\n## library highlights\n\nwhether you are a machine learning researcher or first-time user of machine learning toolkits, here are some reasons to try out pyg for machine learning on graph-structured data.\n\n* **easy-to-use and unified api**:\n  all it takes is 10-20 lines of code to get started with training a gnn model (see the next section for a [quick tour](#quick-tour-for-new-users)).\n  pyg is *pytorch-on-the-rocks*: it utilizes a tensor-centric api and keeps design principles close to vanilla pytorch.\n  if you are already familiar with pytorch, utilizing pyg is straightforward.\n* **comprehensive and well-maintained gnn models**:\n  most of the state-of-the-art graph neural network architectures have been implemented by library developers or authors of research papers and are ready to be applied.\n* **great flexibility**:\n  existing pyg models can easily be extended for conducting your own research with gnns.\n  making modifications to existing models or creating new architectures is simple, thanks to its easy-to-use message passing api, and a variety of operators and utility functions.\n* **large-scale real-world gnn models**:\n  we focus on the need of gnn applications in challenging real-world scenarios, and support learning on diverse types of graphs, including but not limited to: scalable gnns for graphs with millions of nodes; dynamic gnns for node predictions over time; heterogeneous gnns with multiple node types and edge types.\n* **graphgym integration**: graphgym lets users easily reproduce gnn experiments, is able to launch and analyze thousands of different gnn configurations, and is customizable by registering new modules to a gnn learning pipeline.\n\n## quick tour for new users\n\nin this quick tour, we highlight the ease of creating and training a gnn model with only a few lines of code.\n\n### train your own gnn model\n\nin the first glimpse of pyg, we implement the training of a gnn for classifying papers in a citation graph.\nfor this, we load the [cora](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.planetoid.html) dataset, and create a simple 2-layer gcn model using the pre-defined [`gcnconv`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gcnconv.html):\n\n```python\nimport torch\nfrom torch import tensor\nfrom torch_geometric.nn import gcnconv\nfrom torch_geometric.datasets import planetoid\n\ndataset = planetoid(root='.', name='cora')\n\nclass gcn(torch.nn.module):\n    def __init__(self, in_channels, hidden_channels, out_channels):\n        super().__init__()\n        self.conv1 = gcnconv(in_channels, hidden_channels)\n        self.conv2 = gcnconv(hidden_channels, out_channels)\n\n    def forward(self, x: tensor, edge_index: tensor) -> tensor:\n        # x: node feature matrix of shape [num_nodes, in_channels]\n        # edge_index: graph connectivity matrix of shape [2, num_edges]\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index)\n        return x\n\nmodel = gcn(dataset.num_features, 16, dataset.num_classes)\n```\n\n<details>\n<summary>we can now optimize the model in a training loop, similar to the <a href=\"https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation\">standard pytorch training procedure</a>.</summary>\n\n```python\nimport torch.nn.functional as f\n\ndata = dataset[0]\noptimizer = torch.optim.adam(model.parameters(), lr=0.01)\n\nfor epoch in range(200):\n    pred = model(data.x, data.edge_index)\n    loss = f.cross_entropy(pred[data.train_mask], data.y[data.train_mask])\n\n    # backpropagation\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n```\n</details>\n\nmore information about evaluating final model performance can be found in the corresponding [example](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py).\n\n### create your own gnn layer\n\nin addition to the easy application of existing gnns, pyg makes it simple to implement custom graph neural networks (see [here](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html) for the accompanying tutorial).\nfor example, this is all it takes to implement the [edge convolutional layer](https://arxiv.org/abs/1801.07829) from wang *et al.*:\n\n$$x_i^{\\prime} ~ = ~ \\max_{j \\in \\mathcal{n}(i)} ~ \\textrm{mlp}_{\\theta} \\left( [ ~ x_i, ~ x_j - x_i ~ ] \\right)$$\n\n```python\nimport torch\nfrom torch import tensor\nfrom torch.nn import sequential, linear, relu\nfrom torch_geometric.nn import messagepassing\n\nclass edgeconv(messagepassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr=\"max\")  # \"max\" aggregation.\n        self.mlp = sequential(\n            linear(2 * in_channels, out_channels),\n            relu(),\n            linear(out_channels, out_channels),\n        )\n\n    def forward(self, x: tensor, edge_index: tensor) -> tensor:\n        # x: node feature matrix of shape [num_nodes, in_channels]\n        # edge_index: graph connectivity matrix of shape [2, num_edges]\n        return self.propagate(edge_index, x=x)  # shape [num_nodes, out_channels]\n\n    def message(self, x_j: tensor, x_i: tensor) -> tensor:\n        # x_j: source node features of shape [num_edges, in_channels]\n        # x_i: target node features of shape [num_edges, in_channels]\n        edge_features = torch.cat([x_i, x_j - x_i], dim=-1)\n        return self.mlp(edge_features)  # shape [num_edges, out_channels]\n```\n\n### manage experiments with graphgym\n\ngraphgym allows you to manage and launch gnn experiments, using a highly modularized pipeline (see [here](https://pytorch-geometric.readthedocs.io/en/latest/advanced/graphgym.html) for the accompanying tutorial).\n\n```\ngit clone https://github.com/pyg-team/pytorch_geometric.git\ncd pytorch_geometric/graphgym\nbash run_single.sh  # run a single gnn experiment (node/edge/graph-level)\nbash run_batch.sh   # run a batch of gnn experiments, using differnt gnn designs/datasets/tasks\n```\n\nusers are highly encouraged to check out the [documentation](https://pytorch-geometric.readthedocs.io/en/latest), which contains additional tutorials on the essential functionalities of pyg, including data handling, creation of datasets and a full list of implemented methods, transforms, and datasets.\nfor a quick start, check out our [examples](https://github.com/pyg-team/pytorch_geometric/tree/master/examples) in `examples/`.\n\n## architecture overview\n\npyg provides a multi-layer framework that enables users to build graph neural network solutions on both low and high levels.\nit comprises of the following components:\n\n* the pyg **engine** utilizes the powerful pytorch deep learning framework with full [`torch.compile`](https://pytorch-geometric.readthedocs.io/en/latest/advanced/compile.html) and [torchscript](https://pytorch-geometric.readthedocs.io/en/latest/advanced/jit.html) support, as well as additions of efficient cpu/cuda libraries for operating on sparse data, *e.g.*, [`pyg-lib`](https://github.com/pyg-team/pyg-lib).\n* the pyg **storage** handles data processing, transformation and loading pipelines. it is capable of handling and processing large-scale graph datasets, and provides effective solutions for heterogeneous graphs. it further provides a variety of sampling solutions, which enable training of gnns on large-scale graphs.\n* the pyg **operators** bundle essential functionalities for implementing graph neural networks. pyg supports important gnn building blocks that can be combined and applied to various parts of a gnn model, ensuring rich flexibility of gnn design.\n* finally, pyg provides an abundant set of gnn **models**, and examples that showcase gnn models on standard graph benchmarks. thanks to its flexibility, users can easily build and modify custom gnn models to fit their specific needs.\n\n<p align=\"center\">\n  <img width=\"100%\" src=\"https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/docs/source/_figures/architecture.svg?sanitize=true\" />\n</p>\n\n## implemented gnn models\n\nwe list currently supported pyg models, layers and operators according to category:\n\n**gnn layers:**\nall graph neural network layers are implemented via the **[`nn.messagepassing`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.messagepassing.html)** interface.\na gnn layer specifies how to perform message passing, *i.e.* by designing different message, aggregation and update functions as defined [here](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html).\nthese gnn layers can be stacked together to create graph neural network models.\n\n* **[gcnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gcnconv.html)** from kipf and welling: [semi-supervised classification with graph convolutional networks](https://arxiv.org/abs/1609.02907) (iclr 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py)]\n* **[chebconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.chebconv.html)** from defferrard *et al.*: [convolutional neural networks on graphs with fast localized spectral filtering](https://arxiv.org/abs/1606.09375) (nips 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py#l36-l37)]\n* **[gatconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gatconv.html)** from veli\u010dkovi\u0107 *et al.*: [graph attention networks](https://arxiv.org/abs/1710.10903) (iclr 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py)]\n\n<details>\n<summary><b>expand to see all implemented gnn layers...</b></summary>\n\n* **[gcn2conv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gcn2conv.html)** from chen *et al.*: [simple and deep graph convolutional networks](https://arxiv.org/abs/2007.02133) (icml 2020) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn2_cora.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn2_ppi.py)]\n* **[splineconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.splineconv.html)** from fey *et al.*: [splinecnn: fast geometric deep learning with continuous b-spline kernels](https://arxiv.org/abs/1711.08920) (cvpr 2018) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cora.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/faust.py)]\n* **[nnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.nnconv.html)** from gilmer *et al.*: [neural message passing for quantum chemistry](https://arxiv.org/abs/1704.01212) (icml 2017) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/qm9_nn_conv.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mnist_nn_conv.py)]\n* **[cgconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.cgconv.html)** from xie and grossman: [crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties](https://journals.aps.org/prl/abstract/10.1103/physrevlett.120.145301) (physical review letters 120, 2018)\n* **[ecconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ecconv.html)** from simonovsky and komodakis: [edge-conditioned convolution on graphs](https://arxiv.org/abs/1704.02901) (cvpr 2017)\n* **[egconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.egconv.html)** from tailor *et al.*: [adaptive filters and aggregator fusion for efficient graph convolutions](https://arxiv.org/abs/2104.01481) (gnnsys 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/egc.py)]\n* **[gatv2conv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gatv2conv.html)** from brody *et al.*: [how attentive are graph attention networks?](https://arxiv.org/abs/2105.14491) (iclr 2022)\n* **[transformerconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.transformerconv.html)** from shi *et al.*: [masked label prediction: unified message passing model for semi-supervised classification](https://arxiv.org/abs/2009.03509) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/unimp_arxiv.py)]\n* **[sageconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.sageconv.html)** from hamilton *et al.*: [inductive representation learning on large graphs](https://arxiv.org/abs/1706.02216) (nips 2017) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/reddit.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py), [**example3**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py), [**example4**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup_ppi.py)]\n* **[graphconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.graphconv.html)** from, *e.g.*, morris *et al.*: [weisfeiler and leman go neural: higher-order graph neural networks](https://arxiv.org/abs/1810.02244) (aaai 2019)\n* **[gatedgraphconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gatedgraphconv.html)** from li *et al.*: [gated graph sequence neural networks](https://arxiv.org/abs/1511.05493) (iclr 2016)\n* **[resgatedgraphconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.resgatedgraphconv.html)** from bresson and laurent: [residual gated graph convnets](https://arxiv.org/abs/1711.07553) (corr 2017)\n* **[ginconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ginconv.html)** from xu *et al.*: [how powerful are graph neural networks?](https://arxiv.org/abs/1810.00826) (iclr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mutag_gin.py)]\n* **[gineconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gineconv.html)** from hu *et al.*: [strategies for pre-training graph neural networks](https://arxiv.org/abs/1905.12265) (iclr 2020)\n* **[armaconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.armaconv.html)** from bianchi *et al.*: [graph neural networks with convolutional arma filters](https://arxiv.org/abs/1901.01343) (corr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/arma.py)]\n* **[sgconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.sgconv.html)** from wu *et al.*: [simplifying graph convolutional networks](https://arxiv.org/abs/1902.07153) (corr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/sgc.py)]\n* **[appnp](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.appnp.html)** from klicpera *et al.*: [predict then propagate: graph neural networks meet personalized pagerank](https://arxiv.org/abs/1810.05997) (iclr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/citation/appnp.py)]\n* **[mfconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.mfconv.html)** from duvenaud *et al.*: [convolutional networks on graphs for learning molecular fingerprints](https://arxiv.org/abs/1509.09292) (nips 2015)\n* **[agnnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.agnnconv.html)** from thekumparampil *et al.*: [attention-based graph neural network for semi-supervised learning](https://arxiv.org/abs/1803.03735) (corr 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/agnn.py)]\n* **[tagconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.tagconv.html)** from du *et al.*: [topology adaptive graph convolutional networks](https://arxiv.org/abs/1710.10370) (corr 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/tagcn.py)]\n* **[pnaconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.pnaconv.html)** from corso *et al.*: [principal neighbourhood aggregation for graph nets](https://arxiv.org/abs/2004.05718) (corr 2020) [**[example](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pna.py)**]\n* **[faconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.faconv.html)** from bo *et al.*: [beyond low-frequency information in graph convolutional networks](https://arxiv.org/abs/2101.00797) (aaai 2021)\n* **[pdnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.nn.conv.pdnconv.html)** from rozemberczki *et al.*: [pathfinder discovery networks for neural message passing](https://arxiv.org/abs/2010.12878) (www 2021)\n* **[rgcnconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.rgcnconv.html)** from schlichtkrull *et al.*: [modeling relational data with graph convolutional networks](https://arxiv.org/abs/1703.06103) (eswc 2018) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgcn.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgcn_link_pred.py)]\n* **[rgatconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.rgatconv.html)** from busbridge *et al.*: [relational graph attention networks](https://arxiv.org/abs/1904.05811) (corr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgat.py)]\n* **[filmconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.filmconv.html)** from brockschmidt: [gnn-film: graph neural networks with feature-wise linear modulation](https://arxiv.org/abs/1906.12192) (icml 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/film.py)]\n* **[signedconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.signedconv.html)** from derr *et al.*: [signed graph convolutional network](https://arxiv.org/abs/1808.06354) (icdm 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/signed_gcn.py)]\n* **[dnaconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.dnaconv.html)** from fey: [just jump: dynamic neighborhood aggregation in graph neural networks](https://arxiv.org/abs/1904.04849) (iclr-w 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/dna.py)]\n* **[panconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.panconv.html)** from ma *et al.*: [path integral based convolution and pooling for graph neural networks](https://arxiv.org/abs/2006.16811) (neurips 2020)\n* **[pointnetconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.pointnetconv.html)** (including **[iterative farthest point sampling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.fps.html)**, dynamic graph generation based on **[nearest neighbor](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.knn_graph.html)** or **[maximum distance](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.radius_graph.html)**, and **[k-nn interpolation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.unpool.knn_interpolate.html)** for upsampling) from qi *et al.*: [pointnet: deep learning on point sets for 3d classification and segmentation](https://arxiv.org/abs/1612.00593) (cvpr 2017) and [pointnet++: deep hierarchical feature learning on point sets in a metric space](https://arxiv.org/abs/1706.02413) (nips 2017) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pointnet2_classification.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pointnet2_segmentation.py)]\n* **[edgeconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.edgeconv.html)** from wang *et al.*: [dynamic graph cnn for learning on point clouds](https://arxiv.org/abs/1801.07829) (corr, 2018) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/dgcnn_classification.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/dgcnn_segmentation.py)]\n* **[xconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.xconv.html)** from li *et al.*: [pointcnn: convolution on x-transformed points](https://arxiv.org/abs/1801.07791) (neurips 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/points/point_cnn.py)]\n* **[ppfconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ppfconv.html)** from deng *et al.*: [ppfnet: global context aware local features for robust 3d point matching](https://arxiv.org/abs/1802.02669) (cvpr 2018)\n* **[gmmconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gmmconv.html)** from monti *et al.*: [geometric deep learning on graphs and manifolds using mixture model cnns](https://arxiv.org/abs/1611.08402) (cvpr 2017)\n* **[feastconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.feastconv.html)** from verma *et al.*: [feastnet: feature-steered graph convolutions for 3d shape analysis](https://arxiv.org/abs/1706.05206) (cvpr 2018)\n* **[pointtransformerconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.pointtransformerconv.html)** from zhao *et al.*: [point transformer](https://arxiv.org/abs/2012.09164) (2020)\n* **[hypergraphconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.hypergraphconv.html)** from bai *et al.*: [hypergraph convolution and hypergraph attention](https://arxiv.org/abs/1901.08150) (corr 2019)\n* **[gravnetconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gravnetconv.html)** from qasim *et al.*: [learning representations of irregular particle-detector geometry with distance-weighted graph networks](https://arxiv.org/abs/1902.07987) (european physics journal c, 2019)\n* **[supergat](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.supergatconv.html)** from kim and oh: [how to find your friendly neighborhood: graph attention design with self-supervision](https://openreview.net/forum?id=wi5kunlqwty) (iclr 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/super_gat.py)]\n* **[hgtconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.hgtconv.html)** from hu *et al.*: [heterogeneous graph transformer](https://arxiv.org/abs/2003.01332) (www 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hgt_dblp.py)]\n* **[heatconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.heatonv.html)** from mo *et al.*: [heterogeneous edge-enhanced graph attention network for multi-agent trajectory prediction](https://arxiv.org/abs/2106.07161) (corr 2021)\n* **[ssgconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ssgconv.html)** from zhu *et al.*: [simple spectral graph convolution](https://openreview.net/forum?id=cyo5t-yjwzv) (iclr 2021)\n* **[fusedgatconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.fusedgatconv.html)** from zhang *et al.*: [understanding gnn computational graph: a coordinated computation, io, and memory perspective](https://proceedings.mlsys.org/paper/2022/file/9a1158154dfa42caddbd0694a4e9bdc8-paper.pdf) (mlsys 2022)\n* **[gpsconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.gpsconv.html)** from ramp\u00e1\u0161ek *et al.*: [recipe for a general, powerful, scalable graph transformer](https://arxiv.org/abs/2205.12454) (neurips 2022) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_gps.py)]\n</details>\n\n**pooling layers:**\ngraph pooling layers combine the vectorial representations of a set of nodes in a graph (or a subgraph) into a single vector representation that summarizes its properties of nodes.\nit is commonly applied to graph-level tasks, which require combining node features into a single graph representation.\n\n* **[top-k pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.topkpooling.html)** from gao and ji: [graph u-nets](https://arxiv.org/abs/1905.05178) (icml 2019), cangea *et al.*: [towards sparse hierarchical graph classifiers](https://arxiv.org/abs/1811.01287) (neurips-w 2018) and knyazev *et al.*: [understanding attention and generalization in graph neural networks](https://arxiv.org/abs/1905.02850) (iclr-w 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_topk_pool.py)]\n* **[diffpool](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dense_diff_pool.html)** from ying *et al.*: [hierarchical graph representation learning with differentiable pooling](https://arxiv.org/abs/1806.08804) (neurips 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_diff_pool.py)]\n\n<details>\n<summary><b>expand to see all implemented pooling layers...</b></summary>\n\n* **[attentional aggregation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.attentionalaggregation.html)** from li *et al.*: [graph matching networks for learning the similarity of graph structured objects](https://arxiv.org/abs/1904.12787) (icml 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/global_attention.py)]\n* **[set2set](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.set2set.html)** from vinyals *et al.*: [order matters: sequence to sequence for sets](https://arxiv.org/abs/1511.06391) (iclr 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/set2set.py)]\n* **[sort aggregation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.sortaggregation.html)** from zhang *et al.*: [an end-to-end deep learning architecture for graph classification](https://www.cse.wustl.edu/~muhan/papers/aaai_2018_dgcnn.pdf) (aaai 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/sort_pool.py)]\n* **[mincut pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dense_mincut_pool.html)** from bianchi *et al.*: [spectral clustering with graph neural networks for graph pooling](https://arxiv.org/abs/1907.00481) (icml 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_mincut_pool.py)]\n* **[dmon pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dmonpooling.html)** from tsitsulin *et al.*: [graph clustering with graph neural networks](https://arxiv.org/abs/2006.16904) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_dmon_pool.py)]\n* **[graclus pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.graclus.html)** from dhillon *et al.*: [weighted graph cuts without eigenvectors: a multilevel approach](http://www.cs.utexas.edu/users/inderjit/public_papers/multilevel_pami.pdf) (pami 2007) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mnist_graclus.py)]\n* **[voxel grid pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.voxel_grid.html)** from, *e.g.*, simonovsky and komodakis: [dynamic edge-conditioned filters in convolutional neural networks on graphs](https://arxiv.org/abs/1704.02901) (cvpr 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mnist_voxel_grid.py)]\n* **[sag pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.sagpooling.html)** from lee *et al.*: [self-attention graph pooling](https://arxiv.org/abs/1904.08082) (icml 2019) and knyazev *et al.*: [understanding attention and generalization in graph neural networks](https://arxiv.org/abs/1905.02850) (iclr-w 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/sag_pool.py)]\n* **[edge pooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.edgepooling.html)** from diehl *et al.*: [towards graph pooling by edge contraction](https://graphreason.github.io/papers/17.pdf) (icml-w 2019) and diehl: [edge contraction pooling for graph neural networks](https://arxiv.org/abs/1905.10990) (corr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/edge_pool.py)]\n* **[asapooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.asapooling.html)** from ranjan *et al.*: [asap: adaptive structure aware pooling for learning hierarchical graph representations](https://arxiv.org/abs/1911.07979) (aaai 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/asap.py)]\n* **[panpooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.panpooling.html)** from ma *et al.*: [path integral based convolution and pooling for graph neural networks](https://arxiv.org/abs/2006.16811) (neurips 2020)\n* **[mempooling](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.mempooling.html)** from khasahmadi *et al.*: [memory-based graph networks](https://arxiv.org/abs/2002.09518) (iclr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/mem_pool.py)]\n* **[graph multiset transformer](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.graphmultisettransformer.html)** from baek *et al.*: [accurate learning of graph representations with graph multiset pooling](https://arxiv.org/abs/2102.11533) (iclr 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/proteins_gmt.py)]\n* **[equilibrium aggregation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.equilibriumaggregation.html)** from bartunov *et al.*: [](https://arxiv.org/abs/2202.12795) (uai 2022) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/equilibrium_median.py)]\n</details>\n\n**gnn models:**\nour supported gnn models incorporate multiple message passing layers, and users can directly use these pre-defined models to make predictions on graphs.\nunlike simple stacking of gnn layers, these models could involve pre-processing, additional learnable parameters, skip connections, graph coarsening, etc.\n\n* **[schnet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.schnet.html)** from sch\u00fctt *et al.*: [schnet: a continuous-filter convolutional neural network for modeling quantum interactions](https://arxiv.org/abs/1706.08566) (nips 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/qm9_pretrained_schnet.py)]\n* **[dimenet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.dimenet.html)** and **[dimenetplusplus](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.dimenetplusplus.html)** from klicpera *et al.*: [directional message passing for molecular graphs](https://arxiv.org/abs/2003.03123) (iclr 2020) and [fast and uncertainty-aware directional message passing for non-equilibrium molecules](https://arxiv.org/abs/2011.14115) (neurips-w 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/qm9_pretrained_dimenet.py)]\n* **[node2vec](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.node2vec.html)** from grover and leskovec: [node2vec: scalable feature learning for networks](https://arxiv.org/abs/1607.00653) (kdd 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/node2vec.py)]\n* **[deep graph infomax](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.deepgraphinfomax.html)** from veli\u010dkovi\u0107 *et al.*: [deep graph infomax](https://arxiv.org/abs/1809.10341) (iclr 2019) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/infomax_transductive.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/infomax_inductive.py)]\n* **deep multiplex graph infomax** from park *et al.*: [unsupervised attributed multiplex network embedding](https://arxiv.org/abs/1911.06750) (aaai 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/dmgi_unsup.py)]\n* **[masked label prediction](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.masklabel.html)** from shi *et al.*: [masked label prediction: unified message passing model for semi-supervised classification](https://arxiv.org/abs/2009.03509) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/unimp_arxiv.py)]\n* **[pmlp](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.pmlp.html)** from yang *et al.*: [graph neural networks are inherently good generalizers: insights by bridging gnns and mlps](https://arxiv.org/abs/2212.09034) (iclr 2023)\n\n<details>\n<summary><b>expand to see all implemented gnn models...</b></summary>\n\n* **[jumping knowledge](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.jumpingknowledge.html)** from xu *et al.*: [representation learning on graphs with jumping knowledge networks](https://arxiv.org/abs/1806.03536) (icml 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/gin.py#l54-l106)]\n* a **[metalayer](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.metalayer.html)** for building any kind of graph network similar to the [tensorflow graph nets library](https://github.com/deepmind/graph_nets) from battaglia *et al.*: [relational inductive biases, deep learning, and graph networks](https://arxiv.org/abs/1806.01261) (corr 2018)\n* **[metapath2vec](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.metapath2vec.html)** from dong *et al.*: [metapath2vec: scalable representation learning for heterogeneous networks](https://ericdongyx.github.io/papers/kdd17-dong-chawla-swami-metapath2vec.pdf) (kdd 2017) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/metapath2vec.py)]\n* all variants of **[graph autoencoders](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.gae.html)** and **[variational autoencoders](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.vgae.html)** from:\n    * [variational graph auto-encoders](https://arxiv.org/abs/1611.07308) from kipf and welling (nips-w 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/autoencoder.py)]\n    * [adversarially regularized graph autoencoder for graph embedding](https://arxiv.org/abs/1802.04407) from pan *et al.* (ijcai 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/argva_node_clustering.py)]\n    * [simple and effective graph autoencoders with one-hop linear models](https://arxiv.org/abs/2001.07614) from salha *et al.* (ecml 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/autoencoder.py)]\n* **[seal](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/seal_link_pred.py)** from zhang and chen: [link prediction based on graph neural networks](https://arxiv.org/pdf/1802.09691.pdf) (neurips 2018) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/seal_link_pred.py)]\n* **[renet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.renet.html)** from jin *et al.*: [recurrent event network for reasoning over temporal knowledge graphs](https://arxiv.org/abs/1904.05530) (iclr-w 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/renet.py)]\n* **[graphunet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.graphunet.html)** from gao and ji: [graph u-nets](https://arxiv.org/abs/1905.05178) (icml 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_unet.py)]\n* **[attentivefp](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.attentivefp.html)** from xiong *et al.*: [pushing the boundaries of molecular representation for drug discovery with the graph attention mechanism](https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959) (j. med. chem. 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/attentive_fp.py)]\n* **[deepgcn](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.deepgcnlayer.html)** and the **[genconv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.genconv.html)** from li *et al.*: [deepgcns: can gcns go as deep as cnns?](https://arxiv.org/abs/1904.03751) (iccv 2019) and [deepergcn: all you need to train deeper gcns](https://arxiv.org/abs/2006.07739) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_proteins_deepgcn.py)]\n* **[rect](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.rect_l.html)** from wang *et al.*: [network embedding with completely-imbalanced labels](https://ieeexplore.ieee.org/document/8979355) (tkde 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rect.py)]\n* **[gnnexplainer](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.explain.algorithm.gnnexplainer.html)** from ying *et al.*: [gnnexplainer: generating explanations for graph neural networks](https://arxiv.org/abs/1903.03894) (neurips 2019) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/gnn_explainer.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/gnn_explainer_ba_shapes.py), [**example3**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/gnn_explainer_link_pred.py)]\n* **graph-less neural networks** from zhang *et al.*: [graph-less neural networks: teaching old mlps new tricks via distillation](https://arxiv.org/abs/2110.08727) (corr 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/glnn.py)]\n* **[linkx](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.linkx.html)** from lim *et al.*: [large scale learning on non-homophilous graphs:\nnew benchmarks and strong simple methods](https://arxiv.org/abs/2110.14446) (neurips 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/linkx.py)]\n* **[revgnn](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.groupaddrev.html)** from li *et al.*: [training graph neural with 1000 layers](https://arxiv.org/abs/2106.07476) (icml 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rev_gnn.py)]\n* **[transe](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.transe.html)** from bordes *et al.*: [translating embeddings for modeling multi-relational data](https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-paper.pdf) (nips 2013) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kge_fb15k_237.py)]\n* **[complex](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.complex.html)** from trouillon *et al.*: [complex embeddings for simple link prediction](https://arxiv.org/abs/1606.06357) (icml 2016) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kge_fb15k_237.py)]\n* **[distmult](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.distmult.html)** from yang *et al.*: [embedding entities and relations for learning and inference in knowledge bases](https://arxiv.org/abs/1412.6575) (iclr 2015) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kge_fb15k_237.py)]\n* **[rotate](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.rotate.html)** from sun *et al.*: [rotate: knowledge graph embedding by relational rotation in complex space](https://arxiv.org/abs/1902.10197) (iclr 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kge_fb15k_237.py)]\n</details>\n\n**gnn operators and utilities:**\npyg comes with a rich set of neural network operators that are commonly used in many gnn models.\nthey follow an extensible design: it is easy to apply these operators and graph utilities to existing gnn layers and models to further enhance model performance.\n\n* **[dropedge](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_edge)** from rong *et al.*: [dropedge: towards deep graph convolutional networks on node classification](https://openreview.net/forum?id=hkx1qkrkpr) (iclr 2020)\n* **[dropnode](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_node)**, **[maskfeature](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.mask_feature)** and **[addrandomedge](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.add_random_edge)** from you *et al.*: [graph contrastive learning with augmentations](https://arxiv.org/abs/2010.13902) (neurips 2020)\n* **[droppath](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_path)** from li *et al.*: [maskgae: masked graph modeling meets graph autoencoders](https://arxiv.org/abs/2205.10053) (arxiv 2022)\n* **[shufflenode](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.shuffle_node)** from veli\u010dkovi\u0107 *et al.*: [deep graph infomax](https://arxiv.org/abs/1809.10341) (iclr 2019)\n* **[graphnorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.graphnorm.html)** from cai *et al.*: [graphnorm: a principled approach to accelerating graph neural network training](https://proceedings.mlr.press/v139/cai21e.html) (icml 2021)\n* **[gdc](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.gdc.html)** from klicpera *et al.*: [diffusion improves graph learning](https://arxiv.org/abs/1911.05485) (neurips 2019) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn.py)]\n\n<details>\n<summary><b>expand to see all implemented gnn operators and utilities...</b></summary>\n\n* **[graphsizenorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.graphsizenorm.html)** from dwivedi *et al.*: [benchmarking graph neural networks](https://arxiv.org/abs/2003.00982) (corr 2020)\n* **[pairnorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.pairnorm.html)** from zhao and akoglu: [pairnorm: tackling oversmoothing in gnns](https://arxiv.org/abs/1909.12223) (iclr 2020)\n* **[meansubtractionnorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.meansubtractionnorm.html)** from yang *et al.*: [revisiting \"over-smoothing\" in deep gcns](https://arxiv.org/abs/2003.13663) (corr 2020)\n* **[diffgroupnorm](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.diffgroupnorm.html)** from zhou *et al.*: [towards deeper graph neural networks with differentiable group normalization](https://arxiv.org/abs/2006.06972) (neurips 2020)\n* **[tree decomposition](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.tree_decomposition)** from jin *et al.*: [junction tree variational autoencoder for molecular graph generation](https://arxiv.org/abs/1802.04364) (icml 2018)\n* **[tgn](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.tgnmemory.html)** from rossi *et al.*: [temporal graph networks for deep learning on dynamic graphs](https://arxiv.org/abs/2006.10637) (grl+ 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/tgn.py)]\n* **[weisfeiler lehman operator](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.wlconv.html)** from weisfeiler and lehman: [a reduction of a graph to a canonical form and an algebra arising during this reduction](https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf) (nauchno-technicheskaya informatsia 1968) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/wl_kernel.py)]\n* **[continuous weisfeiler lehman operator](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.wlconvcontinuous.html)** from togninalli *et al.*: [wasserstein weisfeiler-lehman graph kernels](https://arxiv.org/abs/1906.01277) (neurips 2019)\n* **[label propagation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.labelpropagation.html)** from zhu and ghahramani: [learning from labeled and unlabeled data with label propagation](http://mlg.eng.cam.ac.uk/zoubin/papers/cmu-cald-02-107.pdf) (cmu-cald 2002) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/label_prop.py)]\n* **[local degree profile](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.localdegreeprofile)** from cai and wang: [a simple yet effective baseline for non-attribute graph classification](https://arxiv.org/abs/1811.03508) (corr 2018)\n* **[correctandsmooth](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.correctandsmooth.html)** from huang *et al.*: [combining label propagation and simple models out-performs graph neural networks](https://arxiv.org/abs/2010.13993) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/correct_and_smooth.py)]\n* **[gini](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.functional.gini.html)** and **[bro](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.functional.bro.html)** regularization from henderson *et al.*: [improving molecular graph neural network explainability with orthonormalization and induced sparsity](https://arxiv.org/abs/2105.04854) (icml 2021)\n* **[rootedegonets](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.rootedegonets)** and **[rootedrwsubgraph](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.rootedrwsubgraph)** from zhao *et al.*: [from stars to subgraphs: uplifting any gnn with local structure awareness](https://arxiv.org/abs/2110.03753) (iclr 2022)\n* **[featurepropagation](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.featurepropagation)** from rossi *et al.*: [on the unreasonable effectiveness of feature propagation in learning on graphs with missing node features](https://arxiv.org/abs/2111.12128) (corr 2021)\n</details>\n\n**scalable gnns:**\npyg supports the implementation of graph neural networks that can scale to large-scale graphs.\nsuch application is challenging since the entire graph, its associated features and the gnn parameters cannot fit into gpu memory.\nmany state-of-the-art scalability approaches tackle this challenge by sampling neighborhoods for mini-batch training, graph clustering and partitioning, or by using simplified gnn models.\nthese approaches have been implemented in pyg, and can benefit from the above gnn layers, operators and models.\n\n* **[neighborloader](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.neighborloader)** from hamilton *et al.*: [inductive representation learning on large graphs](https://arxiv.org/abs/1706.02216) (nips 2017) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/reddit.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py), [**example3**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_gat.py), [**example4**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py)]\n* **[clustergcn](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.clusterloader)** from chiang *et al.*: [cluster-gcn: an efficient algorithm for training deep and large graph convolutional networks](https://arxiv.org/abs/1905.07953) (kdd 2019) [[**example1**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cluster_gcn_reddit.py), [**example2**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cluster_gcn_ppi.py)]\n* **[graphsaint](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.graphsaintsampler)** from zeng *et al.*: [graphsaint: graph sampling based inductive learning method](https://arxiv.org/abs/1907.04931) (iclr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_saint.py)]\n\n<details>\n<summary><b>expand to see all implemented scalable gnns...</b></summary>\n\n* **[shadow](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.shadowkhopsampler)** from zeng *et al.*: [decoupling the depth and scope of graph neural networks](https://arxiv.org/abs/2201.07858) (neurips 2021) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/shadow.py)]\n* **[sign](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.sign.html)** from rossi *et al.*: [sign: scalable inception graph neural networks](https://arxiv.org/abs/2004.11198) (corr 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/sign.py)]\n* **[hgtloader](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.loader.hgtloader.html)** from hu *et al.*: [heterogeneous graph transformer](https://arxiv.org/abs/2003.01332) (www 2020) [[**example**](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py)]\n</details>\n\n## installation\n\npyg is available for python 3.8 to python 3.11.\n\n### anaconda\n\nyou can now install pyg via [anaconda](https://anaconda.org/pyg/pyg) for all major os/pytorch/cuda combinations \ud83e\udd17\nif you have not yet installed pytorch, install it via `conda` as described in the [official pytorch documentation](https://pytorch.org/get-started/locally/).\ngiven that you have pytorch installed (`>=1.8.0`), simply run\n\n```\nconda install pyg -c pyg\n```\n\n### pypi\n\nfrom **pyg 2.3** onwards, you can install and use pyg **without any external library** required except for pytorch.\nfor this, simply run\n\n```\npip install torch_geometric\n```\n\npyg 2.3 requires that at least pytorch 1.11 is installed.\n\n### additional libraries\n\nif you want to utilize the full set of features from pyg, there exists several additional libraries you may want to install:\n\n* **[`pyg-lib`](https://github.com/pyg-team/pyg-lib)**: heterogeneous gnn operators and graph sampling routines\n* **[`torch-scatter`](https://github.com/rusty1s/pytorch_scatter)**: accelerated and efficient sparse reductions\n* **[`torch-sparse`](https://github.com/rusty1s/pytorch_sparse)**: [`sparsetensor`](https://pytorch-geometric.readthedocs.io/en/latest/advanced/sparse_tensor.html) support\n* **[`torch-cluster`](https://github.com/rusty1s/pytorch_cluster)**: graph clustering routines\n* **[`torch-spline-conv`](https://github.com/rusty1s/pytorch_spline_conv)**: [`splineconv`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.splineconv.html) support\n\nthese packages come with their own cpu and gpu kernel implementations based on the [pytorch c++/cuda/hip(rocm) extension interface](https://github.com/pytorch/extension-cpp).\nfor a basic usage of pyg, these dependencies are **fully optional**.\nwe recommend to start with a minimal installation, and install additional dependencies once you start to actually need them.\n\nfor ease of installation of these extensions, we provide `pip` wheels for all major os/pytorch/cuda combinations, see [here](https://data.pyg.org/whl).\n\n#### pytorch 2.1\n\nto install the binaries for pytorch 2.1.0, simply run\n\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+${cuda}.html\n```\n\nwhere `${cuda}` should be replaced by either `cpu`, `cu118`, or `cu121` depending on your pytorch installation.\n\n|             | `cpu` | `cu118` | `cu121` |\n|-------------|-------|---------|---------|\n| **linux**   | \u2705    | \u2705      | \u2705      |\n| **windows** | \u2705    | \u2705      | \u2705      |\n| **macos**   | \u2705    |         |         |\n\n#### pytorch 2.0\n\nto install the binaries for pytorch 2.0.0, simply run\n\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+${cuda}.html\n```\n\nwhere `${cuda}` should be replaced by either `cpu`, `cu117`, or `cu118` depending on your pytorch installation.\n\n|             | `cpu` | `cu117` | `cu118` |\n|-------------|-------|---------|---------|\n| **linux**   | \u2705    | \u2705      | \u2705      |\n| **windows** | \u2705    | \u2705      | \u2705      |\n| **macos**   | \u2705    |         |         |\n\n**note:** binaries of older versions are also provided for pytorch 1.4.0, pytorch 1.5.0, pytorch 1.6.0, pytorch 1.7.0/1.7.1, pytorch 1.8.0/1.8.1, pytorch 1.9.0, pytorch 1.10.0/1.10.1/1.10.2, pytorch 1.11.0, pytorch 1.12.0/1.12.1 and pytorch 1.13.0/1.13.1 (following the same procedure).\n**for older versions, you might need to explicitly specify the latest supported version number** or install via `pip install --no-index` in order to prevent a manual installation from source.\nyou can look up the latest supported version number [here](https://data.pyg.org/whl).\n\n### nightly and master\n\nin case you want to experiment with the latest pyg features which are not fully released yet, either install the **nightly version** of pyg via\n\n```\npip install pyg-nightly\n```\n\nor install pyg **from master** via\n\n```\npip install git+https://github.com/pyg-team/pytorch_geometric.git\n```\n\n### rocm wheels\n\nthe external [`pyg-rocm-build` repository](https://github.com/looong01/pyg-rocm-build) provides wheels and detailed instructions on how to install pyg for rocm.\nif you have any questions about it, please open an issue [here](https://github.com/looong01/pyg-rocm-build/issues).\n\n## cite\n\nplease cite [our paper](https://arxiv.org/abs/1903.02428) (and the respective papers of the methods used) if you use this code in your own work:\n\n```\n@inproceedings{fey/lenssen/2019,\n  title={fast graph representation learning with {pytorch geometric}},\n  author={fey, matthias and lenssen, jan e.},\n  booktitle={iclr workshop on representation learning on graphs and manifolds},\n  year={2019},\n}\n```\n\nfeel free to [email us](mailto:matthias.fey@tu-dortmund.de) if you wish your work to be listed in the [external resources](https://pytorch-geometric.readthedocs.io/en/latest/external/resources.html).\nif you notice anything unexpected, please open an [issue](https://github.com/pyg-team/pytorch_geometric/issues) and let us know.\nif you have any questions or are missing a specific feature, feel free [to discuss them with us](https://github.com/pyg-team/pytorch_geometric/discussions).\nwe are motivated to constantly make pyg even better.\n\n",
  "docs_url": null,
  "keywords": "deep-learning,pytorch,geometric-deep-learning,graph-neural-networks,graph-convolutional-networks",
  "license": "",
  "name": "torch-geometric",
  "package_url": "https://pypi.org/project/torch-geometric/",
  "project_url": "https://pypi.org/project/torch-geometric/",
  "project_urls": {
    "changelog": "https://github.com/pyg-team/pytorch_geometric/blob/master/CHANGELOG.md",
    "documentation": "https://pytorch-geometric.readthedocs.io",
    "homepage": "https://pyg.org",
    "repository": "https://github.com/pyg-team/pytorch_geometric.git"
  },
  "release_url": "https://pypi.org/project/torch-geometric/2.4.0/",
  "requires_dist": [
    "tqdm",
    "numpy",
    "scipy",
    "jinja2",
    "requests",
    "pyparsing",
    "scikit-learn",
    "psutil>=5.8.0",
    "protobuf<4.21 ; extra == \"benchmark\"",
    "wandb ; extra == \"benchmark\"",
    "pandas ; extra == \"benchmark\"",
    "networkx ; extra == \"benchmark\"",
    "matplotlib ; extra == \"benchmark\"",
    "torch_geometric[test] ; extra == \"dev\"",
    "pre-commit ; extra == \"dev\"",
    "torch_geometric[graphgym, modelhub] ; extra == \"full\"",
    "ase ; extra == \"full\"",
    "h5py ; extra == \"full\"",
    "numba ; extra == \"full\"",
    "sympy ; extra == \"full\"",
    "pandas ; extra == \"full\"",
    "captum ; extra == \"full\"",
    "rdflib ; extra == \"full\"",
    "trimesh ; extra == \"full\"",
    "networkx ; extra == \"full\"",
    "graphviz ; extra == \"full\"",
    "tabulate ; extra == \"full\"",
    "matplotlib ; extra == \"full\"",
    "pynndescent ; extra == \"full\"",
    "torchmetrics ; extra == \"full\"",
    "scikit-image ; extra == \"full\"",
    "pytorch-memlab ; extra == \"full\"",
    "pgmpy ; extra == \"full\"",
    "opt_einsum ; extra == \"full\"",
    "statsmodels ; extra == \"full\"",
    "rdkit ; extra == \"full\"",
    "yacs ; extra == \"graphgym\"",
    "hydra-core ; extra == \"graphgym\"",
    "protobuf<4.21 ; extra == \"graphgym\"",
    "pytorch-lightning ; extra == \"graphgym\"",
    "huggingface_hub ; extra == \"modelhub\"",
    "pytest ; extra == \"test\"",
    "pytest-cov ; extra == \"test\"",
    "onnx ; extra == \"test\"",
    "onnxruntime ; extra == \"test\""
  ],
  "requires_python": ">=3.8",
  "summary": "graph neural network library for pytorch",
  "version": "2.4.0",
  "releases": [],
  "developers": [
    "matthias@pyg.org"
  ],
  "kwds": "torch_geometric pytorch edge_features hypergraphconv svg",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_torch_geometric",
  "homepage": "",
  "release_count": 38,
  "dependency_ids": [
    "pypi_ase",
    "pypi_captum",
    "pypi_graphviz",
    "pypi_h5py",
    "pypi_huggingface_hub",
    "pypi_hydra_core",
    "pypi_jinja2",
    "pypi_matplotlib",
    "pypi_networkx",
    "pypi_numba",
    "pypi_numpy",
    "pypi_onnx",
    "pypi_onnxruntime",
    "pypi_opt_einsum",
    "pypi_pandas",
    "pypi_pgmpy",
    "pypi_pre_commit",
    "pypi_protobuf",
    "pypi_psutil",
    "pypi_pynndescent",
    "pypi_pyparsing",
    "pypi_pytest",
    "pypi_pytest_cov",
    "pypi_pytorch_lightning",
    "pypi_pytorch_memlab",
    "pypi_rdflib",
    "pypi_rdkit",
    "pypi_requests",
    "pypi_scikit_image",
    "pypi_scikit_learn",
    "pypi_scipy",
    "pypi_statsmodels",
    "pypi_sympy",
    "pypi_tabulate",
    "pypi_torch_geometric",
    "pypi_torchmetrics",
    "pypi_tqdm",
    "pypi_trimesh",
    "pypi_wandb",
    "pypi_yacs"
  ],
  "documentation_summary": "PyTorch Geometric (PyG) version 2.5.0, released on February 16, 2024, is a comprehensive library for Graph Neural Network (GNN) development in PyTorch. It facilitates easy writing and training of GNNs for structured data applications, offering methods for deep learning on graphs and other irregular structures. PyG includes mini-batch loaders, multi-GPU support, and a variety of benchmark datasets. It supports Python versions 3.8 to 3.12 and is licensed under the MIT License. The library is designed for both machine learning researchers and first-time users, providing a unified API, comprehensive GNN models, and great flexibility for custom research. PyG also integrates GraphGym for managing GNN experiments and offers extensive documentation, tutorials, and examples for users.",
  "embedding": [
    -0.029017897322773933,
    0.007996776141226292,
    0.0061212992295622826,
    -0.0340239517390728,
    0.023165548220276833,
    0.018288591876626015,
    -0.002169528976082802,
    -0.020052902400493622,
    -0.016165681183338165,
    -0.03608948737382889,
    0.02111435867846012,
    0.019479142501950264,
    -0.010757994838058949,
    0.017987366765737534,
    0.009309251792728901,
    0.00993321556597948,
    0.016653375700116158,
    0.0007467841496691108,
    0.0012748223962262273,
    0.030696146190166473,
    0.03715094178915024,
    -4.488100967137143e-05,
    -0.01118114311248064,
    -0.0481097549200058,
    0.0009601510246284306,
    0.018216870725154877,
    0.013626793399453163,
    -0.025661403313279152,
    0.010284642688930035,
    0.01488906517624855,
    0.018661534413695335,
    -0.03370838239789009,
    -0.0022304910235106945,
    -0.02267785370349884,
    -0.020268062129616737,
    -0.006236051209270954,
    0.02150164544582367,
    -0.009961903095245361,
    0.02224753424525261,
    0.022147124633193016,
    0.020483221858739853,
    0.003022996475920081,
    -0.003403112292289734,
    -0.0059635150246322155,
    4.4824977521784604e-05,
    0.014100145548582077,
    0.0031162325758486986,
    -0.013985393568873405,
    -0.020884854719042778,
    0.019579550251364708,
    0.0011421404778957367,
    0.040105804800987244,
    -0.007652520202100277,
    -0.023724963888525963,
    -0.0050849453546106815,
    0.003250707406550646,
    0.0231225173920393,
    0.03382313624024391,
    -0.0031951244454830885,
    -0.02074141427874565,
    0.010198579169809818,
    -0.006261153146624565,
    -0.03147071972489357,
    -0.005389755591750145,
    -0.0010390429524704814,
    -0.010528490878641605,
    -0.015548888593912125,
    0.014946441166102886,
    -0.009330767206847668,
    -0.017557047307491302,
    0.02280694991350174,
    0.05731859803199768,
    -0.00812587235122919,
    -0.03347887843847275,
    0.027583498507738113,
    -0.02761218696832657,
    -0.018475063145160675,
    0.00978260301053524,
    -0.02548927627503872,
    -0.008176076225936413,
    -0.007236544508486986,
    -0.024714700877666473,
    0.013390117324888706,
    0.013698513619601727,
    0.005802145227789879,
    0.002169528976082802,
    -0.016050929203629494,
    0.012142189778387547,
    0.0014729488175362349,
    -0.014121660962700844,
    0.016481248661875725,
    0.006877944804728031,
    0.027956442907452583,
    0.006203777156770229,
    -0.013253849931061268,
    0.03999105468392372,
    -0.027741283178329468,
    -0.004801651928573847,
    0.0004782825126312673,
    -0.0037617122288793325,
    -0.021214766427874565,
    0.031442031264305115,
    0.009983419440686703,
    -0.010499803349375725,
    -0.01906316727399826,
    -0.03964679688215256,
    -0.019364390522241592,
    -0.00834820419549942,
    0.01744229532778263,
    0.028444139286875725,
    -0.0013671618653461337,
    0.03158547356724739,
    -0.01202743873000145,
    -0.018518095836043358,
    -0.0016208712477236986,
    0.008462956175208092,
    0.04472457244992256,
    0.013655481860041618,
    0.012974142096936703,
    -0.015548888593912125,
    0.009667851030826569,
    -0.0020458120852708817,
    0.01943610981106758,
    0.00543637340888381,
    0.021329518407583237,
    0.004145414102822542,
    0.005217627622187138,
    -0.01818818412721157,
    0.005361067596822977,
    -0.012242598459124565,
    -0.007631004322320223,
    0.002537093823775649,
    0.015878800302743912,
    0.007552112452685833,
    -0.016682064160704613,
    -0.01080819871276617,
    0.0007772651151753962,
    -0.020856166258454323,
    -0.029892882332205772,
    -0.016653375700116158,
    0.010363535024225712,
    0.011267206631600857,
    -0.011891170404851437,
    -0.010915778577327728,
    -0.014150349423289299,
    0.048568759113550186,
    0.0006795466761104763,
    0.004457395989447832,
    0.012529478408396244,
    -0.011905514635145664,
    0.020884854719042778,
    -0.007501908577978611,
    -0.03078220970928669,
    0.015778392553329468,
    -0.0024922688025981188,
    -0.004356987774372101,
    0.0017159001436084509,
    0.011819450184702873,
    -0.041913148015737534,
    -0.0017517601372674108,
    -0.012285630218684673,
    0.018432030454277992,
    -0.022390972822904587,
    -0.013318398036062717,
    0.004600835964083672,
    0.041913148015737534,
    0.006132056936621666,
    -0.007132550701498985,
    -0.013827609829604626,
    -0.007451704237610102,
    0.00400556018576026,
    0.027081459760665894,
    -0.03795420750975609,
    -0.01956520602107048,
    0.009976247325539589,
    0.004729931708425283,
    0.010657587088644505,
    0.009180155582726002,
    -0.010815370827913284,
    0.02653638646006584,
    0.016065271571278572,
    0.010277471505105495,
    -0.003973286133259535,
    0.038155023008584976,
    -0.009244703687727451,
    -0.016093960031867027,
    0.017098039388656616,
    0.02267785370349884,
    -0.0049845376051962376,
    -0.009825635701417923,
    0.007544940337538719,
    0.008835899643599987,
    0.0008745353552512825,
    -0.0013492318103089929,
    -0.58890700340271,
    0.0008256760775111616,
    -5.101642818772234e-05,
    -0.04400737211108208,
    -0.011166798882186413,
    -0.005540367215871811,
    0.003168229479342699,
    0.005751941353082657,
    -0.01732754334807396,
    0.03870009258389473,
    -0.020511910319328308,
    0.013626793399453163,
    -0.0008480885880999267,
    -0.008391235955059528,
    -0.012156534008681774,
    -0.022419661283493042,
    -0.017040664330124855,
    -0.0374951995909214,
    0.015850111842155457,
    0.03313462436199188,
    -0.01600789651274681,
    0.018776286393404007,
    -0.0030678214970976114,
    0.012988485395908356,
    0.011109422892332077,
    0.032675616443157196,
    -0.01111659500747919,
    -0.005145907402038574,
    0.033249374479055405,
    0.013512041419744492,
    -0.02873101830482483,
    0.030122386291623116,
    0.014559153467416763,
    -0.017313199117779732,
    0.038728781044483185,
    0.0005544850137084723,
    -0.03121252916753292,
    0.046015530824661255,
    0.004647453781217337,
    0.03700750321149826,
    -0.02636425942182541,
    0.0029207956977188587,
    -0.012178050354123116,
    0.016839848831295967,
    -0.02348111756145954,
    0.01158994622528553,
    0.01906316727399826,
    0.0047765495255589485,
    0.012787669897079468,
    -0.02854454703629017,
    0.00966067984700203,
    -0.03339281678199768,
    0.008075668476521969,
    -0.00013974186731502414,
    0.008592051453888416,
    0.006601823028177023,
    0.01100184302777052,
    0.0032542934641242027,
    0.009359455667436123,
    -0.022276220843195915,
    0.003614686196669936,
    -0.0012721328530460596,
    0.00026020899531431496,
    -0.011102250777184963,
    -0.021903278306126595,
    -0.011661666445434093,
    -0.01214936189353466,
    -0.001390470890328288,
    -0.002669775625690818,
    -0.02223319001495838,
    0.02992156893014908,
    0.0018082396127283573,
    0.008520332165062428,
    0.002148012863472104,
    0.0403926856815815,
    0.028644954785704613,
    0.03887221962213516,
    0.006257567089051008,
    -0.005253487266600132,
    0.02485813945531845,
    0.016180023550987244,
    0.008541847579181194,
    -0.004149000160396099,
    -0.009969075210392475,
    0.03244611248373985,
    -0.015534544363617897,
    -0.014293788932263851,
    -0.0005011432804167271,
    0.014673905447125435,
    -0.008943479508161545,
    0.0009843565057963133,
    0.02049756608903408,
    -0.01181227806955576,
    -0.043892618268728256,
    0.016366496682167053,
    0.020095935091376305,
    -0.009890182875096798,
    0.002151598921045661,
    -0.007035728543996811,
    -0.03276168182492256,
    -0.0159505195915699,
    -0.03250348940491676,
    0.01837465539574623,
    0.004030662123113871,
    0.00046797277173027396,
    0.027067115530371666,
    -0.022333597764372826,
    0.000969116052147001,
    0.030696146190166473,
    -0.007286748383194208,
    -0.017212791368365288,
    -0.010621726512908936,
    -0.009388143196702003,
    -0.0013286123285070062,
    0.001821687095798552,
    -0.02972075343132019,
    -0.0007006144151091576,
    0.003109060460701585,
    0.0001611457992112264,
    -0.014666733331978321,
    -0.004977365490049124,
    -0.011919857934117317,
    0.021831557154655457,
    0.006157158873975277,
    0.014229240827262402,
    0.007559284567832947,
    -0.0008642256143502891,
    -0.01801605522632599,
    -0.05915462598204613,
    0.0037294381763786077,
    0.016983287408947945,
    0.012536649592220783,
    0.012974142096936703,
    -0.003200503531843424,
    0.04529833048582077,
    0.02690933085978031,
    0.023638900369405746,
    0.015677984803915024,
    0.009201671928167343,
    -0.029548626393079758,
    0.0029781716875731945,
    0.011704698204994202,
    0.019106198102235794,
    0.0018683051457628608,
    0.005902552977204323,
    0.014975128695368767,
    0.0019256811356171966,
    0.010134031064808369,
    0.004934333730489016,
    0.002264557871967554,
    -0.02056928537786007,
    -0.012206737883388996,
    -0.0162087120115757,
    0.01805908791720867,
    -0.013712857849895954,
    -0.017929991707205772,
    -0.03445427119731903,
    -0.03126990422606468,
    0.0015518408035859466,
    -0.026579419150948524,
    0.021530333906412125,
    0.002624950837343931,
    -0.008254967629909515,
    -0.01988077536225319,
    -0.028071194887161255,
    -0.0068922885693609715,
    -0.04679010435938835,
    0.021974997594952583,
    -0.0030427195597440004,
    -0.019651271402835846,
    -0.005576227325946093,
    -0.028386762365698814,
    -0.005845176987349987,
    0.004152586217969656,
    0.021587708964943886,
    0.023007765412330627,
    0.022419661283493042,
    -0.008943479508161545,
    -0.01093729492276907,
    -0.013433150015771389,
    -0.015577576123178005,
    0.010851230472326279,
    -0.0353722870349884,
    -0.011776418425142765,
    0.03600342199206352,
    0.031757600605487823,
    0.01950783096253872,
    0.004755033645778894,
    -0.022132782265543938,
    -0.013633965514600277,
    -0.005751941353082657,
    0.04036399722099304,
    -0.038355838507413864,
    0.00928773544728756,
    -0.018417688086628914,
    -0.01560626458376646,
    0.011683182790875435,
    -0.007082346826791763,
    0.002739702584221959,
    0.04575733840465546,
    0.009108435362577438,
    0.00545071717351675,
    0.019421767443418503,
    -0.00046214551548473537,
    0.013024345971643925,
    -0.004780135583132505,
    0.014300961047410965,
    -0.014343992806971073,
    0.0026626037433743477,
    -0.014508948661386967,
    0.013755889609456062,
    -0.007297506555914879,
    -0.04093775525689125,
    -0.028759706765413284,
    0.004529115743935108,
    0.026077380403876305,
    -0.004819581750780344,
    0.009804119355976582,
    -0.018231214955449104,
    -0.006956836674362421,
    0.024384789168834686,
    0.011209830641746521,
    0.005970687139779329,
    0.0015921832527965307,
    -0.016180023550987244,
    0.019479142501950264,
    -0.005712495185434818,
    0.0281716026365757,
    -0.012737466022372246,
    -0.03528622165322304,
    -0.011790762655436993,
    0.029634689912199974,
    -0.013017173856496811,
    -0.011855310760438442,
    -0.010148375295102596,
    0.004339057952165604,
    0.029806816950440407,
    -0.03319200128316879,
    0.03167153522372246,
    -0.013124753721058369,
    -0.0025209567975252867,
    0.006038821302354336,
    0.00981846358627081,
    -0.023208580911159515,
    0.010585866868495941,
    0.023251613602042198,
    0.016309119760990143,
    -0.00527858966961503,
    -0.023036453872919083,
    0.004747861530631781,
    -0.010478287003934383,
    0.02211843803524971,
    -0.026306884363293648,
    0.010614555329084396,
    0.03316331282258034,
    0.0016665926668792963,
    0.0171410720795393,
    0.0180734321475029,
    0.003523243358358741,
    0.011597118340432644,
    -0.0023542079143226147,
    0.0036308232229202986,
    0.020483221858739853,
    0.004496841691434383,
    0.019292671233415604,
    -0.020583629608154297,
    0.027009738609194756,
    -0.023136861622333527,
    -0.015778392553329468,
    -0.0004863510257564485,
    0.022075405344367027,
    -0.027009738609194756,
    -0.010162719525396824,
    -0.021573366597294807,
    0.012328661978244781,
    -0.012916766107082367,
    0.012314317747950554,
    0.01863284781575203,
    -0.001437088823877275,
    0.024413475766777992,
    -0.0065587908029556274,
    -0.05014659836888313,
    0.008082840591669083,
    0.029692064970731735,
    -0.008025464601814747,
    -0.02362455613911152,
    -0.01712672784924507,
    0.013225161470472813,
    -0.014451572671532631,
    0.003259672550484538,
    0.02498723566532135,
    0.00030570634407922626,
    -0.010234438814222813,
    0.01913488656282425,
    -0.020411502569913864,
    -0.01569232903420925,
    0.0018790630856528878,
    0.0030983025208115578,
    -0.011582774110138416,
    -0.00716482475399971,
    0.004622351843863726,
    0.013698513619601727,
    -0.020153310149908066,
    -0.009216015227138996,
    0.04306066781282425,
    0.011295894160866737,
    -0.011597118340432644,
    -0.008298000320792198,
    -0.008341032080352306,
    -0.02735399454832077,
    0.011159626767039299,
    0.001527635264210403,
    -0.0025783327873796225,
    -0.02673720382153988,
    -0.012099158018827438,
    -0.006214534863829613,
    0.003973286133259535,
    -0.0058882092125713825,
    0.028315043076872826,
    -0.017786551266908646,
    -0.00826213974505663,
    -0.02779865823686123,
    -0.023825373500585556,
    -0.010169890709221363,
    0.04911383241415024,
    0.03129859268665314,
    0.005644361488521099,
    0.0019041651394218206,
    -0.0219319649040699,
    0.008298000320792198,
    -0.030380576848983765,
    -0.009237531572580338,
    -0.015305040404200554,
    0.0028831425588577986,
    -0.01156125869601965,
    0.009216015227138996,
    0.006013719365000725,
    0.007068002596497536,
    0.011805105954408646,
    0.025317147374153137,
    -0.0033762173261493444,
    -0.006644854787737131,
    -0.008434267714619637,
    0.00576269906014204,
    0.005920483265072107,
    0.003256086492910981,
    0.005465061403810978,
    -0.004615179728716612,
    0.005798559170216322,
    -0.008498815819621086,
    0.02137254923582077,
    0.008921964094042778,
    0.005640775430947542,
    0.0006212742300704122,
    -0.03195841610431671,
    -0.016036584973335266,
    -0.005167423747479916,
    0.013454665429890156,
    -0.008936307393014431,
    0.03726569563150406,
    0.0324174240231514,
    -0.00912995170801878,
    -0.006587478797882795,
    0.006329286843538284,
    0.02293604426085949,
    0.0036792343016713858,
    -0.020052902400493622,
    -0.0006208259728737175,
    0.00841275230050087,
    -0.006899460684508085,
    0.005163837689906359,
    0.005881037097424269,
    0.003661304246634245,
    0.02373930811882019,
    0.004536287859082222,
    0.013856297358870506,
    -0.03973286226391792,
    -0.014788656495511532,
    0.007186340633779764,
    -0.00193106010556221,
    0.005264245439320803,
    -0.02094222977757454,
    0.007272404618561268,
    -0.03416739031672478,
    -0.0031628503929823637,
    -0.011360442265868187,
    -0.015190288424491882,
    -0.022477038204669952,
    0.010801026597619057,
    -0.027124490588903427,
    0.009302079677581787,
    0.006368733011186123,
    -0.014932096935808659,
    -0.009574615396559238,
    -0.029806816950440407,
    -0.041913148015737534,
    -0.014078629203140736,
    -0.012328661978244781,
    0.009789775125682354,
    0.015132912434637547,
    0.011776418425142765,
    0.009883011691272259,
    -0.017585735768079758,
    0.00866377167403698,
    -0.00810435600578785,
    -0.027526123449206352,
    -0.03003632090985775,
    -0.018518095836043358,
    0.028515858575701714,
    -0.00450042774900794,
    -0.0013626792933791876,
    0.004708415828645229,
    0.013834781013429165,
    0.034110017120838165,
    0.020411502569913864,
    -0.02355283685028553,
    0.003157471539452672,
    -0.01831727847456932,
    -0.0005903449491597712,
    0.011905514635145664,
    -0.0009915285045281053,
    0.002721772762015462,
    0.00984715111553669,
    -0.0070249708369374275,
    0.009402487426996231,
    -0.0038119161035865545,
    0.02137254923582077,
    -0.03433952108025551,
    -0.0065587908029556274,
    0.02860192209482193,
    0.012974142096936703,
    0.020038558170199394,
    -0.01202743873000145,
    0.011934202164411545,
    0.02006724663078785,
    -0.03752388432621956,
    0.008950651623308659,
    0.00912995170801878,
    0.004055764060467482,
    0.01084405928850174,
    0.006164330989122391,
    0.016165681183338165,
    -0.006167917046695948,
    -0.0499744713306427,
    0.015391104854643345,
    0.005945585202425718,
    0.004608007613569498,
    0.005744769237935543,
    -0.014817344956099987,
    0.016596000641584396,
    -0.02243400551378727,
    -0.025460587814450264,
    -0.021602053195238113,
    0.000969116052147001,
    0.02886011451482773,
    0.020210687071084976,
    -0.003573447233065963,
    0.0085059879347682,
    0.0014998437836766243,
    -0.004919989500194788,
    -0.029060930013656616,
    -0.010019279085099697,
    -0.009581787511706352,
    -0.0028759706765413284,
    -0.010750822722911835,
    -0.003991215955466032,
    -0.004371332004666328,
    -0.002791699720546603,
    -0.012486445717513561,
    -0.023940125480294228,
    -0.02891748957335949,
    -0.0036792343016713858,
    0.023524148389697075,
    0.02036846987903118,
    -0.004539873916655779,
    0.01507553644478321,
    -0.02467166818678379,
    -0.02474338747560978,
    -0.025345835834741592,
    -0.002083464991301298,
    -0.006114127114415169,
    0.01788695901632309,
    0.00966067984700203,
    0.037237007170915604,
    0.04730648919939995,
    0.008649427443742752,
    0.019393078982830048,
    0.027640875428915024,
    -0.009388143196702003,
    0.011073562316596508,
    0.017600079998373985,
    -0.0007118206704035401,
    -0.05083511024713516,
    -0.02878839336335659,
    -0.002130083041265607,
    0.0053467233665287495,
    0.01844637468457222,
    -0.0009753915364854038,
    -0.003661304246634245,
    -0.011876826174557209,
    0.010578694753348827,
    -0.007760100532323122,
    -0.013296881690621376,
    -0.05092117562890053,
    -0.020899198949337006,
    0.03709356486797333,
    0.007430188357830048,
    0.01520463265478611,
    -0.019923806190490723,
    -0.01801605522632599,
    0.02092788554728031,
    -0.0036200652830302715,
    0.01336860191076994,
    0.006860014516860247,
    0.00981846358627081,
    0.0010246989550068974,
    -0.008341032080352306,
    0.012378865852952003,
    0.027425715699791908,
    -0.00559415714815259,
    -0.004496841691434383,
    -0.035429663956165314,
    -0.037409134209156036,
    -0.013540729880332947,
    -0.003218433354049921,
    0.031069088727235794,
    -0.003930253908038139,
    0.012048954144120216,
    0.006243222858756781,
    0.0049845376051962376,
    0.01156125869601965,
    0.013483353890478611,
    0.011381958611309528,
    -0.03167153522372246,
    -0.019407423213124275,
    -0.00780313229188323,
    -0.02548927627503872,
    0.004041420295834541,
    0.0049881236627697945,
    -0.007207856513559818,
    -0.014946441166102886,
    0.018661534413695335,
    -0.014759968966245651,
    -0.011862481944262981,
    0.0180734321475029,
    0.010865574702620506,
    0.046646665781736374,
    0.008484471589326859,
    0.017298854887485504,
    0.013476181775331497,
    0.005970687139779329,
    0.003490969305858016,
    -0.0018001710996031761,
    0.007774444296956062,
    5.300553675624542e-05,
    0.011927030049264431,
    -0.003573447233065963,
    -0.01392801757901907,
    -0.020167654380202293,
    -0.005730425473302603,
    0.009359455667436123,
    -0.024657323956489563,
    -0.015376760624349117,
    0.02454257197678089,
    0.012192394584417343,
    0.007379984483122826,
    -0.02163074165582657,
    -0.007523424457758665,
    -0.026220818981528282,
    0.02280694991350174,
    -0.014702592976391315,
    0.008627912029623985,
    -0.001385988318361342,
    0.00027903547743335366,
    -0.016466904431581497,
    0.025833532214164734,
    0.009431175887584686,
    0.03525753691792488,
    0.0005616569542326033,
    -0.004113140050321817,
    0.01663903146982193,
    -0.000553588499315083,
    -0.015534544363617897,
    0.024944204837083817,
    -0.009280563332140446,
    0.03967548534274101,
    -9.082661563297734e-05,
    -0.007968088611960411,
    0.03706488013267517,
    0.0005042810225859284,
    -0.005626431200653315,
    0.0006145504303276539,
    -0.006730918772518635,
    0.03858534246683121,
    -0.04162626713514328,
    -0.007953744381666183,
    -0.012873733416199684,
    -0.008549019694328308,
    0.030810898169875145,
    0.003912324085831642,
    -0.012235426343977451,
    -0.013856297358870506,
    0.004902059677988291,
    0.00654086098074913,
    0.005332379601895809,
    -0.019048823043704033,
    -0.022032372653484344,
    0.003987629897892475,
    0.002615985693410039,
    -0.01111659500747919,
    -0.029433874413371086,
    0.001516877324320376,
    0.030810898169875145,
    -0.018231214955449104,
    0.0020798789337277412,
    -0.014716937206685543,
    -0.017772207036614418,
    0.02025371789932251,
    0.015534544363617897,
    -0.013232333585619926,
    -0.00423865020275116,
    0.04280247539281845,
    -0.010105343535542488,
    0.006472726818174124,
    0.017098039388656616,
    0.005769871175289154,
    -0.022477038204669952,
    -0.0038334322161972523,
    -0.011389130726456642,
    -0.010033623315393925,
    0.023638900369405746,
    -0.02835807390511036,
    -0.03396657481789589,
    -0.031011713668704033,
    -0.002370344940572977,
    0.03304855898022652,
    0.013232333585619926,
    -0.03752388432621956,
    0.007774444296956062,
    0.0027630117256194353,
    0.019766023382544518,
    -0.006361560896039009,
    -0.01757139153778553,
    0.017212791368365288,
    0.005228385329246521,
    0.010908606462180614,
    0.008957823738455772,
    -0.004590077791363001,
    0.01589314453303814,
    -0.012665745802223682,
    -0.0012389624025672674,
    -0.004561389796435833,
    -0.030696146190166473,
    -0.00440719211474061,
    -0.009567443281412125,
    -0.014716937206685543,
    -0.0011663459008559585,
    0.04248690605163574,
    -0.00566946342587471,
    -0.0020099519751966,
    -0.023524148389697075,
    0.038097646087408066,
    0.011353270150721073,
    -0.018862351775169373,
    0.01749967224895954,
    0.015247664414346218,
    -0.0066054086200892925,
    0.011934202164411545,
    0.0015554267447441816,
    -0.0401344932615757,
    0.00012842356227338314,
    0.006379491183906794,
    -0.05086379870772362,
    -0.013978221453726292,
    0.002800664631649852,
    0.04369180276989937,
    0.019852086901664734,
    -0.018489407375454903,
    -0.023409396409988403,
    -0.03052401728928089,
    -0.00984715111553669,
    -0.0038441901560872793,
    -0.013562245294451714,
    0.01762876845896244,
    0.0027450816705822945,
    0.023638900369405746,
    0.021888934075832367,
    0.02381102927029133,
    0.013576589524745941,
    0.017872614786028862,
    0.00040857968269847333,
    0.024341756477952003,
    0.018116462975740433,
    -0.010435255244374275,
    -0.009230359457433224,
    -0.026278195902705193,
    -0.04088038206100464,
    -0.020167654380202293,
    0.011303066276013851,
    0.00417410209774971,
    -0.0002931553462985903,
    0.020784446969628334,
    0.002626743633300066,
    0.01047111488878727,
    -0.02722489833831787,
    -0.011260034516453743,
    0.019479142501950264,
    -0.0025066128000617027,
    0.03476984053850174,
    -0.022821292281150818,
    -0.023696277290582657,
    -0.005382583476603031,
    0.0036164792254567146,
    0.007566456217318773,
    -0.021587708964943886,
    0.013311225920915604,
    -0.03606079891324043,
    0.03715094178915024,
    -0.013017173856496811,
    -0.0009059128351509571,
    -0.006135642994195223,
    0.017843928188085556,
    0.011805105954408646,
    0.020454533398151398,
    0.019952494651079178,
    0.034425582736730576,
    -0.0017867236165329814,
    0.019550861790776253,
    -0.0228643249720335,
    0.01663903146982193,
    -0.034368205815553665,
    -0.002508405828848481,
    0.014372681267559528,
    -0.009703711606562138,
    0.008319515734910965,
    -0.02198934182524681,
    0.03752388432621956,
    -0.02200368605554104,
    -0.0062217069789767265,
    -0.006727332714945078,
    -0.014143177308142185,
    -0.026249507442116737,
    0.014989472925662994,
    -0.004360573831945658,
    -0.003851362271234393,
    -0.010614555329084396,
    -0.003374424297362566,
    0.016122648492455482,
    -0.0006306874565780163,
    -0.016653375700116158,
    -0.002122910926118493,
    -0.03431083261966705,
    -0.002271729987114668,
    0.003919496200978756,
    0.006573135033249855,
    -0.02811422571539879,
    -0.002888521645218134,
    0.009789775125682354,
    -0.006239636801183224,
    -0.0026715686544775963,
    0.18268509209156036,
    0.015505856834352016,
    0.030610080808401108,
    0.035802606493234634,
    -0.019966838881373405,
    0.006103368941694498,
    0.011805105954408646,
    -0.005977859254926443,
    -0.0042673381976783276,
    0.0240548774600029,
    -0.002626743633300066,
    -0.008713975548744202,
    -0.021200422197580338,
    -0.002580125816166401,
    0.0014057112857699394,
    -0.041023820638656616,
    -0.03494196757674217,
    -0.03172891214489937,
    -0.02293604426085949,
    -0.00264108763076365,
    0.0006755124195478857,
    0.013820437714457512,
    -0.004127483814954758,
    -0.03672062233090401,
    -0.002174908062443137,
    -0.002018917119130492,
    -0.005206869449466467,
    -0.005023983772844076,
    0.023337677121162415,
    0.013497697189450264,
    0.0059133111499249935,
    0.03743782266974449,
    0.0038155021611601114,
    -0.04816712811589241,
    -0.01945045404136181,
    -0.0034891762770712376,
    0.036605872213840485,
    0.0007723344024270773,
    0.0028580406215041876,
    0.04070825129747391,
    -0.01650993525981903,
    -0.018618503585457802,
    0.006956836674362421,
    -0.028558891266584396,
    0.018604159355163574,
    -0.0377533882856369,
    -0.02729661948978901,
    0.03345019370317459,
    -0.024628635495901108,
    0.018087774515151978,
    -0.031069088727235794,
    -0.0113676143810153,
    0.009875839576125145,
    0.015434136614203453,
    -0.005181767512112856,
    -0.02044019103050232,
    0.0016916947206482291,
    0.004762205760926008,
    0.028515858575701714,
    0.005726839415729046,
    -0.03198710456490517,
    0.017399264499545097,
    -0.0006450314540416002,
    0.028960522264242172,
    -0.016036584973335266,
    -0.004998881835490465,
    -0.015677984803915024,
    0.025690091773867607,
    -0.0023452427703887224,
    -0.003132369602099061,
    -0.03540097549557686,
    -0.004819581750780344,
    -0.01820252649486065,
    0.00036263407673686743,
    -0.04710567370057106,
    -0.036290302872657776,
    0.041913148015737534,
    -0.010772339068353176,
    0.0168828796595335,
    0.020583629608154297,
    -0.000695235445164144,
    0.03540097549557686,
    -0.0005428305012173951,
    0.002072707051411271,
    -0.02821463532745838,
    -0.0015850112540647388,
    0.02672285959124565,
    -0.022634821012616158,
    -0.0228643249720335,
    -0.00535748153924942,
    0.006967594847083092,
    -0.008921964094042778,
    0.007544940337538719,
    -0.00772424042224884,
    -0.005214041564613581,
    0.0170119758695364,
    -0.009452691301703453,
    0.016065271571278572,
    -0.015333728864789009,
    0.0237966850399971,
    -0.03606079891324043,
    0.05892512574791908,
    0.009094092063605785,
    0.02230490930378437,
    0.003725852118805051,
    0.009825635701417923,
    -0.014659561216831207,
    0.027440058067440987,
    0.005339551251381636,
    -0.0027450816705822945,
    -0.0179443359375,
    -0.019952494651079178,
    0.0066054086200892925,
    0.0067416769452393055,
    -0.014006908982992172,
    -0.007731412537395954,
    0.0031664364505559206,
    -0.0018898211419582367,
    0.01694025658071041,
    -0.005171009339392185,
    -0.025589684024453163,
    -0.008735491894185543,
    -0.0035698614083230495,
    0.001353714382275939,
    -0.02461429312825203,
    -0.011876826174557209,
    -0.010621726512908936,
    -0.0010533869499340653,
    -0.010442427359521389,
    -0.0231225173920393,
    0.0014801208162680268,
    -0.0382697731256485,
    0.03439689427614212,
    -0.012787669897079468,
    0.008864588104188442,
    -0.00984715111553669,
    -0.005375411361455917,
    -0.0010444220388308167,
    -0.006390248890966177,
    0.008405580185353756,
    -0.025632714852690697,
    0.0031915383879095316,
    0.009474207647144794,
    -0.011733386665582657,
    0.0171410720795393,
    -0.0062217069789767265,
    -0.002728944644331932,
    -0.003912324085831642,
    0.004557803738862276,
    -0.012192394584417343,
    -0.007107448764145374,
    -0.009954730980098248,
    0.004285268019884825,
    -0.007989604026079178,
    0.01969430223107338,
    -0.027755627408623695,
    -0.018804974853992462,
    -0.028128569945693016,
    0.02062666229903698,
    0.009710883721709251,
    -0.025776155292987823,
    -0.028616266325116158,
    0.010621726512908936,
    -0.014257929287850857,
    -0.032245296984910965,
    -0.00479806587100029,
    -0.18383261561393738,
    0.021544678136706352,
    0.01986643113195896,
    -0.025933939963579178,
    -0.004772963933646679,
    -0.006784708704799414,
    0.01118114311248064,
    -0.016495592892169952,
    -0.025159364566206932,
    -0.001074006431736052,
    0.02137254923582077,
    0.005716081243008375,
    -0.0028723846189677715,
    -0.03170022368431091,
    -0.0010049759875983,
    0.002927967580035329,
    -0.0031234044581651688,
    0.016725096851587296,
    0.029132649302482605,
    0.028458481654524803,
    0.017413606867194176,
    -0.024499541148543358,
    -0.008871760219335556,
    0.029247401282191277,
    -0.004532701801508665,
    -0.02137254923582077,
    -0.014286616817116737,
    0.016466904431581497,
    -0.0007423016359098256,
    -0.02310817316174507,
    -0.009646335616707802,
    -0.00859922356903553,
    0.035544414073228836,
    0.012601197697222233,
    0.007415844593197107,
    0.019364390522241592,
    0.024843795225024223,
    -0.0006176882307045162,
    -0.04242953285574913,
    0.0074086724780499935,
    0.04139676317572594,
    0.020411502569913864,
    0.010851230472326279,
    -0.006845670752227306,
    -0.01658165641129017,
    0.0008911205804906785,
    -0.003564482321962714,
    -0.026321226730942726,
    0.022821292281150818,
    -0.016725096851587296,
    0.02972075343132019,
    -0.009431175887584686,
    0.030983025208115578,
    -0.002253799932077527,
    0.027267931029200554,
    0.01323950570076704,
    0.010012106969952583,
    0.010212923400104046,
    0.015290697105228901,
    -0.014501777477562428,
    -0.028272010385990143,
    -0.019909461960196495,
    0.017973022535443306,
    -0.003603928256779909,
    -0.011632978916168213,
    -0.017112383618950844,
    -0.02000986970961094,
    -0.01199157815426588,
    -0.022276220843195915,
    -0.0014361923094838858,
    0.005031155422329903,
    -0.00637231906875968,
    0.005576227325946093,
    -0.006160744931548834,
    0.03792551904916763,
    0.02754046767950058,
    -0.02292170189321041,
    -0.01062889862805605,
    0.025345835834741592,
    -0.011023358441889286,
    0.0006365146837197244,
    0.024499541148543358,
    0.007466048467904329,
    0.006630511023104191,
    0.03353625535964966,
    -0.019923806190490723,
    0.013519213534891605,
    0.0008924653520807624,
    -0.01988077536225319,
    -0.009058231487870216,
    0.0110305305570364,
    -0.010112514719367027,
    0.02728227525949478,
    -0.002427720930427313,
    0.024499541148543358,
    0.0009771845070645213,
    0.021731149405241013,
    -0.010105343535542488,
    0.02623516321182251,
    -0.041769709438085556,
    0.038728781044483185,
    0.023710621520876884,
    -0.015305040404200554,
    -0.000175601860973984,
    0.06242505833506584,
    0.01963692717254162,
    -0.01757139153778553,
    -0.006279082968831062,
    0.01762876845896244,
    0.00035927220596931875,
    -0.007161238696426153,
    -0.0036684763617813587,
    0.010148375295102596,
    0.0004800755123142153,
    -0.011962890625,
    0.030667457729578018,
    -0.014860376715660095,
    -0.009839979000389576,
    -0.005335965659469366,
    -0.016352152451872826,
    0.04446638002991676,
    0.03072483278810978,
    0.005002467427402735,
    0.010851230472326279,
    -0.02548927627503872,
    -0.015132912434637547,
    -0.08095749467611313,
    -0.029634689912199974,
    0.025145020335912704,
    0.009165811352431774,
    -0.041167259216308594,
    -0.01993815042078495,
    -0.005131563637405634,
    0.03244611248373985,
    -0.012328661978244781,
    0.017772207036614418,
    -0.020583629608154297,
    0.003483797423541546,
    -0.008606395684182644,
    0.01536241639405489,
    -0.012909593991935253,
    -0.014946441166102886,
    -0.02429872378706932,
    -0.017427951097488403,
    0.0002877763763535768,
    0.004755033645778894,
    -0.020526254549622536,
    0.005949171259999275,
    0.011317410506308079,
    0.011037702672183514,
    0.01408580131828785,
    0.0024815108627080917,
    -0.0187475997954607,
    0.009746743366122246,
    0.004457395989447832,
    0.009481379762291908,
    0.011044874787330627,
    -0.021458614617586136,
    0.017169760540127754,
    -0.005959928967058659,
    -0.0077672721818089485,
    -0.029433874413371086,
    -0.01432964950799942,
    -0.024140940979123116,
    0.02798513136804104,
    -0.00646555470302701,
    -0.00781747605651617,
    0.0018189976690337062,
    0.032819055020809174,
    0.018718911334872246,
    -0.04466719552874565,
    -0.014494605362415314,
    -0.024140940979123116,
    0.037409134209156036,
    0.034110017120838165,
    -0.049945782870054245,
    -0.018145151436328888,
    -0.029017897322773933,
    0.002271729987114668,
    0.002449236810207367,
    0.022950388491153717,
    -0.00029203473241068423,
    -0.004256580024957657,
    -3.154557998641394e-05,
    0.01047111488878727,
    -0.006956836674362421,
    -0.018518095836043358,
    0.002863419707864523,
    0.015132912434637547,
    0.0043677459470927715,
    0.017743520438671112,
    0.010765166953206062,
    -0.00568380719050765,
    -0.025647059082984924,
    0.03431083261966705,
    -0.009553099051117897,
    -0.013246677815914154,
    0.021171733736991882,
    -0.007552112452685833,
    0.011891170404851437,
    -0.04613028094172478,
    0.012156534008681774,
    0.000751266663428396,
    -0.004686899948865175,
    0.017843928188085556,
    -0.0068169827573001385,
    -0.0036003421992063522,
    -0.0159505195915699,
    0.006623338907957077,
    -0.008692460134625435,
    0.013834781013429165,
    0.014860376715660095,
    0.002069120993837714,
    -0.010671931318938732,
    0.03347887843847275,
    -0.02728227525949478,
    0.015778392553329468,
    -0.024097908288240433,
    0.03236004710197449,
    -0.031442031264305115,
    -0.001945404103025794,
    -0.01639518328011036,
    -0.018403343856334686,
    -0.01602224074304104,
    -0.017915647476911545,
    0.027755627408623695,
    -0.05619976669549942,
    -0.021802868694067,
    -0.08956389129161835,
    0.035917360335588455,
    0.004335471894592047,
    -0.012106330133974552,
    -0.0011448299046605825,
    -0.04024924337863922,
    0.01945045404136181,
    -0.02997894585132599,
    -0.0026357087772339582,
    -0.009043887257575989,
    -0.02666548267006874,
    -0.009452691301703453,
    -0.01100184302777052,
    -0.004740689881145954,
    0.004859027452766895,
    -0.03431083261966705,
    0.025216739624738693,
    0.011546914465725422,
    0.059097252786159515,
    0.011066391132771969,
    0.002033261116594076,
    0.031241217628121376,
    0.037351757287979126,
    0.009323595091700554,
    -0.04374917969107628,
    -0.01838899962604046,
    -0.01062889862805605,
    0.017356231808662415,
    -0.014408540911972523,
    -0.007143308408558369,
    0.03388051316142082,
    -0.01980905421078205,
    0.013942361809313297,
    0.02929043397307396,
    -0.0004912817385047674,
    -0.021831557154655457,
    0.027927754446864128,
    0.0022771088406443596,
    0.014143177308142185,
    0.009237531572580338,
    -0.029864193871617317,
    -0.02044019103050232,
    0.03345019370317459,
    0.0247290451079607,
    0.0144874332472682,
    0.010277471505105495,
    0.013834781013429165,
    -0.022591788321733475,
    0.035056717693805695,
    0.01583576761186123,
    0.0340239517390728,
    0.008534676395356655,
    -0.005526023451238871,
    -0.04265903681516647,
    0.02150164544582367,
    0.0018736841157078743,
    0.020712725818157196,
    0.0068887025117874146,
    0.002576539758592844,
    -0.010743650607764721,
    0.007910712622106075,
    0.010664759203791618,
    0.027468746528029442,
    0.007351296488195658,
    0.010729307308793068,
    -0.00568380719050765,
    -0.043031979352235794,
    -0.00922318734228611,
    -0.0047048297710716724,
    -0.028185946866869926,
    -0.008448611944913864,
    -0.033622320741415024,
    0.047507304698228836,
    0.017843928188085556,
    0.03115515224635601,
    -0.010506974533200264,
    0.026522044092416763,
    0.0009395315428264439,
    -0.021458614617586136,
    0.0058882092125713825,
    0.02055494301021099,
    -0.020956574007868767,
    -0.018862351775169373,
    -0.004145414102822542,
    0.02455691620707512,
    -0.018288591876626015,
    -0.027827346697449684,
    -0.0012434448581188917,
    0.019421767443418503,
    0.016854191198945045,
    0.003991215955466032,
    0.03247480094432831,
    0.018862351775169373,
    0.010270299389958382,
    -0.016223056241869926,
    0.0024259279016405344,
    -0.004887715447694063,
    -0.0008095391094684601,
    0.02167377434670925,
    0.007494736462831497,
    0.015061193145811558,
    0.0114967105910182,
    0.014673905447125435,
    -0.009165811352431774,
    -0.020655350759625435,
    -0.011805105954408646,
    -0.018302936106920242,
    -0.01111659500747919,
    -0.000928773544728756,
    0.017313199117779732,
    0.023897092789411545,
    -0.013483353890478611,
    -0.0221901573240757,
    -0.001150208991020918,
    -0.008484471589326859,
    0.0024994409177452326,
    0.004916403442621231,
    -0.0010040794732049108,
    -0.018518095836043358,
    0.007688380312174559,
    -0.007387156598269939,
    0.014932096935808659,
    0.03608948737382889,
    -0.010514146648347378,
    0.029376497492194176,
    0.02056928537786007,
    0.020483221858739853,
    0.008204763755202293,
    0.021085670217871666,
    -0.017729176208376884,
    -0.0061248852871358395,
    -0.004991709720343351,
    -0.019364390522241592,
    0.006393834948539734,
    -0.0011797933839261532,
    -0.02411225251853466,
    -0.023940125480294228,
    0.02735399454832077,
    -0.006978352554142475,
    0.08342466503381729,
    -0.005364653654396534,
    -0.000550002499949187,
    -0.024083564057946205,
    -0.02992156893014908,
    -0.0016423872439190745,
    -0.005956343375146389,
    0.01626608893275261,
    -0.01838899962604046,
    -0.04088038206100464,
    -0.009316423907876015,
    -0.022821292281150818,
    -0.04329017177224159,
    0.00027141525060869753,
    -0.01805908791720867,
    -0.006067509297281504,
    -0.032302673906087875,
    0.03236004710197449,
    -0.008419924415647984,
    0.02647901140153408,
    0.03499934449791908,
    0.0077170683071017265,
    -0.0007817476289346814,
    0.006999868433922529,
    -0.03551572561264038,
    -0.01243624184280634,
    0.021042637526988983,
    -0.008211935870349407,
    0.010356362909078598,
    -0.035114094614982605,
    0.01850375160574913,
    0.008627912029623985,
    -0.03459770977497101,
    -0.028300698846578598,
    -0.006644854787737131,
    -0.008584880270063877,
    0.0011457264190539718,
    -0.026149099692702293,
    0.003037340473383665,
    0.008886103518307209,
    0.010119686834514141,
    0.0019687130115926266,
    -0.01370568573474884,
    -0.02416962757706642,
    -0.006160744931548834,
    -0.020856166258454323,
    -0.023839715868234634,
    -0.003327806480228901,
    -0.02092788554728031
  ]
}