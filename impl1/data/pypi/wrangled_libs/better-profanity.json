{
  "classifiers": [
    "license :: osi approved :: mit license",
    "operating system :: os independent",
    "programming language :: python :: 3"
  ],
  "description": "# better_profanity\n*blazingly fast cleaning swear words (and their leetspeak) in strings*\n\n[![release](https://img.shields.io/badge/dynamic/json.svg?label=release&url=https%3a%2f%2fpypi.org%2fpypi%2fbetter-profanity%2fjson&query=%24.info.version&colorb=blue)](https://github.com/snguyenthanh/better_profanity/releases/latest)\n[![build status](https://travis-ci.com/snguyenthanh/better_profanity.svg?branch=master)](https://travis-ci.com/snguyenthanh/better_profanity)\n![python](https://img.shields.io/badge/python-3-blue.svg)\n[![license](https://img.shields.io/github/license/mashape/apistatus.svg?style=popout)](https://github.com/snguyenthanh/better_profanity/blob/master/license)\n\n\ninspired from package [profanity](https://github.com/ben174/profanity) of [ben friedland](https://github.com/ben174), this library is significantly faster than the original one, by using string comparison instead of regex.\n\nit supports [modified spellings](https://en.wikipedia.org/wiki/leet) (such as `p0rn`, `h4ndjob`, `handj0b` and `b*tch`).\n\n## requirements\nthis package works with `python 3.4+` and `pypy3`.\n\n## installation\n```\n$ pip install better_profanity\n```\n\n## unicode characters\n\nonly unicode characters from categories `ll`, `lu`, `mc` and `mn` are added. more on unicode categories can be found [here][unicode category link].\n\n[unicode category link]: https://en.wikipedia.org/wiki/template:general_category_(unicode)\n\nnot all languages are supported yet, such as *chinese*.\n\n## usage\n\n```\nfrom better_profanity import profanity\n\nif __name__ == \"__main__\":\n    profanity.load_censor_words()\n\n    text = \"you p1ec3 of shit.\"\n    censored_text = profanity.censor(text)\n    print(censored_text)\n    # you **** of ****.\n```\n\nall modified spellings of words in [profanity_wordlist.txt](./better_profanity/profanity_wordlist.txt) will be generated. for example, the word `handjob` would be loaded into:\n\n```\n'handjob', 'handj*b', 'handj0b', 'handj@b', 'h@ndjob', 'h@ndj*b', 'h@ndj0b', 'h@ndj@b',\n'h*ndjob', 'h*ndj*b', 'h*ndj0b', 'h*ndj@b', 'h4ndjob', 'h4ndj*b', 'h4ndj0b', 'h4ndj@b'\n```\n\nthe full mapping of the library can be found in [profanity.py](./better_profanity/better_profanity.py#l18-l26).\n\n### 1. censor swear words from a text\nby default, `profanity` replaces each swear words with 4 asterisks `****`.\n\n```\nfrom better_profanity import profanity\n\nif __name__ == \"__main__\":\n    text = \"you p1ec3 of shit.\"\n\n    censored_text = profanity.censor(text)\n    print(censored_text)\n    # you **** of ****.\n```\n\n### 2. censor doesn't care about word dividers\nthe function `.censor()` also hide words separated not just by an empty space ` ` but also other dividers, such as `_`, `,` and `.`. except for `@, $, *, \", '`.\n\n```\nfrom better_profanity import profanity\n\nif __name__ == \"__main__\":\n    text = \"...sh1t...hello_cat_fuck,,,,123\"\n\n    censored_text = profanity.censor(text)\n    print(censored_text)\n    # \"...****...hello_cat_****,,,,123\"\n```\n\n### 3. censor swear words with custom character\n4 instances of the character in second parameter in `.censor()` will be used to replace the swear words.\n\n```\nfrom better_profanity import profanity\n\nif __name__ == \"__main__\":\n    text = \"you p1ec3 of shit.\"\n\n    censored_text = profanity.censor(text, '-')\n    print(censored_text)\n    # you ---- of ----.\n```\n\n### 4. check if the string contains any swear words\nfunction `.contains_profanity()` return `true` if any words in the given string has a word existing in the wordlist.\n\n```\nfrom better_profanity import profanity\n\nif __name__ == \"__main__\":\n    dirty_text = \"that l3sbi4n did a very good h4ndjob.\"\n\n    profanity.contains_profanity(dirty_text)\n    # true\n```\n\n### 5. censor swear words with a custom wordlist\n\n#### 5.1. wordlist as a `list`\nfunction `load_censor_words` takes a `list` of strings as censored words.\nthe provided list will replace the default wordlist.\n\n```\nfrom better_profanity import profanity\n\nif __name__ == \"__main__\":\n    custom_badwords = ['happy', 'jolly', 'merry']\n    profanity.load_censor_words(custom_badwords)\n\n    print(profanity.contains_profanity(\"have a merry day! :)\"))\n    # have a **** day! :)\n```\n\n#### 5.2. wordlist as a file\nfunction `load_censor_words_from_file takes a filename, which is a text file and each word is separated by lines.\n\n```\nfrom better_profanity import profanity\n\nif __name__ == \"__main__\":\n    profanity.load_censor_words_from_file('/path/to/my/project/my_wordlist.txt')\n```\n\n### 6. whitelist\n\nfunction `load_censor_words` and `load_censor_words_from_file` takes a keyword argument `whitelist_words` to ignore words in a wordlist.\n\nit is best used when there are only a few words that you would like to ignore in the wordlist.\n\n```\n# use the default wordlist\nprofanity.load_censor_words(whitelist_words=['happy', 'merry'])\n\n# or with your custom words as a list\ncustom_badwords = ['happy', 'jolly', 'merry']\nprofanity.load_censor_words(custom_badwords, whitelist_words=['merry'])\n\n# or with your custom words as a text file\nprofanity.load_censor_words_from_file('/path/to/my/project/my_wordlist.txt', whitelist_words=['merry'])\n```\n\n### 7. add more censor words\n```\nfrom better_profanity import profanity\n\nif __name__ == \"__main__\":\n    custom_badwords = ['happy', 'jolly', 'merry']\n    profanity.add_censor_words(custom_badwords)\n\n    print(profanity.contains_profanity(\"happy you, fuck!\"))\n    # **** you, ****!\n```\n\n## limitations\n\n1. as the library compares each word by characters, the censor could easily be bypassed by adding any character(s) to the word:\n\n```\nprofanity.censor('i just have sexx')\n# returns 'i just have sexx'\n\nprofanity.censor('jerkk off')\n# returns 'jerkk off'\n```\n\n2. any word in [wordlist](https://github.com/snguyenthanh/better_profanity/blob/master/better_profanity/profanity_wordlist.txt) that have non-space separators cannot be recognised, such as `s & m`, and therefore, it won't be filtered out. this problem was raised in [#5](https://github.com/snguyenthanh/better_profanity/issues/5).\n\n## testing\n```\n$ python tests.py\n```\n\n## contributing\nplease read [contributing.md](./contributing.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## license\nthis project is licensed under the mit license - see the [license.md](license.md) file for details\n\n## special thanks to\n- [andrew grinevich](https://github.com/derfirm) - add support for unicode characters.\n- [jaclyn brockschmidt](https://github.com/jcbrockschmidt) - optimize string comparison.\n## acknowledgments\n- [ben friedland](https://github.com/ben174) - for the inspiring package [profanity](https://github.com/ben174/profanity).\n\n\n",
  "docs_url": null,
  "keywords": "",
  "license": "",
  "name": "better-profanity",
  "package_url": "https://pypi.org/project/better-profanity/",
  "project_url": "https://pypi.org/project/better-profanity/",
  "project_urls": {
    "Homepage": "https://github.com/snguyenthanh/better_profanity"
  },
  "release_url": "https://pypi.org/project/better-profanity/0.7.0/",
  "requires_dist": [],
  "requires_python": "==3.*",
  "summary": "blazingly fast cleaning swear words (and their leetspeak) in strings",
  "version": "0.7.0",
  "releases": [],
  "developers": [
    "son_nguyen_thanh",
    "thanhson16198@gmail.com"
  ],
  "kwds": "better_profanity contains_profanity profanity_wordlist add_censor_words load_censor_words",
  "license_kwds": "",
  "libtype": "pypi",
  "id": "pypi_better_profanity",
  "homepage": "https://github.com/snguyenthanh/better_profanity",
  "release_count": 12,
  "dependency_ids": []
}