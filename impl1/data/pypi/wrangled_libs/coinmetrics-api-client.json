{
  "classifiers": [
    "license :: osi approved :: mit license",
    "programming language :: python :: 3",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9"
  ],
  "description": "# coin metrics python api v4 client library\n\nthis is an official python api client for coin metrics api v4.\n\n## installation and updates\nto install the client you can run the following command:\n```\npip install coinmetrics-api-client\n```\n\nnote that the client is updated regularly to reflect the changes made in [api v4](https://docs.coinmetrics.io/api/v4). ensure that your latest version matches with what's in [pypi](https://pypi.org/project/coinmetrics-api-client/) \n\nto update your version, run the following command:\n```\npip install coinmetrics-api-client -u\n```\n\n## introduction\nyou can use this client for querying all kinds of data with your api.\n\nto initialize the client you should use your api key, and the coinmetricsclient class like the following.\n```\nfrom coinmetrics.api_client import coinmetricsclient\n\nclient = coinmetricsclient(\"<cm_api_key>\")\n\n# or to use community api:\nclient = coinmetricsclient()\n```\n\nafter that you can use the client object for getting information such as available market trades as a list of dictionaries:\n```\nprint(client.catalog_market_trades_v2().to_list())\n```\n\nor to iterate over each page of data:\n\n```python\nfor data in client.catalog_market_trades_v2():\n    print(data)\n```\n\n\nyou can also use filters for the catalog endpoints like this:\n\n```\nprint(client.catalog_market_trades_v2(exchange=\"binance\").to_list())\n```\n\nall the catalog v2 endpoints meant to help access the historical data served by other endpoints. for example, you can\nget all the btc market trades for a certain day from binance like this:\n\n```python\nimport os\nfrom coinmetrics.api_client import coinmetricsclient\nclient = coinmetricsclient(os.environ['cm_api_key'])\nbtc_binance_markets = [market['market'] for market in client.catalog_market_trades_v2(exchange=\"binance\", asset=\"btc\").to_list()]\nstart_time = \"2023-01-01\"\nend_time = \"2023-01-02\"\nbinance_market_trades = client.get_market_trades(markets=btc_binance_markets, start_time=start_time, end_time=end_time, page_size=1000).export_to_csv(\"binance_trades.csv\")\n```\nin this case you would get all the information markets that trade on binance only. \n\nyou can use this client to connect to our api v4 and get catalog or timeseries data from python environment. it natively supports paging over the data so you can use it to iterate over timeseries entries seamlessly.\n\nthe client can be used to query both pro and community data.\n\nthe full list of methods can be found in the [api client spec](https://coinmetrics.github.io/api-client-python/site/api_client.html).\n\n\nif you'd like a more holistic view of what is offered from an api endpoint you can use the `to_dataframe()` function \nassociated with our catalog endpoints. the code snippet below shows getting a dataframe of information on all the \nassets that data is provided for:\n```python\nprint(client.catalog_market_metrics_v2(exchange=\"binance\", page_size=1000).to_dataframe())\n```\n\noutput:\n```commandline\n                             market                                            metrics\n0       binance-1000bttcusdt-future  [{'metric': 'liquidity_depth_0_1_percent_ask_v...\n1      binance-1000flokiusdt-future  [{'metric': 'liquidations_reported_future_buy_...\n2       binance-1000luncbusd-future  [{'metric': 'liquidations_reported_future_buy_...\n3       binance-1000luncusdt-future  [{'metric': 'liquidations_reported_future_buy_...\n4       binance-1000pepeusdt-future  [{'metric': 'liquidations_reported_future_buy_...\n```\n\nnow you can use the pandas dataframe functionality to do useful transformations, such as filtering out the assets \nwithout metrics available, then saving that data to a csv file:\n```python\nimport pandas as pd\nimport os\nfrom coinmetrics.api_client import coinmetricsclient\nfrom datetime import timedelta\nclient = coinmetricsclient(os.environ['cm_api_key'])\nbinance_markets = client.catalog_market_trades_v2(exchange=\"binance\", page_size=1000).to_dataframe()\nbinance_markets['max_time'] = pd.to_datetime(binance_markets['max_time'], utc=true)\ncurrent_utc_time = pd.timestamp.now(tz='utc')\none_day_ago = current_utc_time - timedelta(days=1)\nfiltered_binance_markets = binance_markets[binance_markets['max_time'] > one_day_ago]\n```\n\n## parallel execution for faster data export\nthere are times when it may be useful to pull in large amounts of data at once. the most effective way to do this \nwhen calling the coinmetrics api is to split your request into many different queries. this functionality is now \nbuilt into the api client directly to allow for faster data export:\n\n```python\nimport os\nfrom coinmetrics.api_client import coinmetricsclient\n\n\nif __name__ == '__main__':\n    client = coinmetricsclient(os.environ['cm_api_key'])\n    binance_eth_markets = [market['market'] for market in client.catalog_market_candles(exchange=\"binance\", base=\"eth\")]\n    start_time = \"2022-03-01\"\n    end_time = \"2023-05-01\"\n    client.get_market_candles(markets=binance_eth_markets, start_time=start_time, end_time=end_time, page_size=1000).parallel().export_to_json_files()\n```\n\nwhat this feature does is rather request all the data in one thread, it will split into many threads or processes and \neither store them in separate files in the case of `.parallel().export_to_csv_files()` and `.parallel().export_to_json_files`\nor combine them all into one file or data structure in the case of `.parallel().to_list()`, `.parallel().to_dataframe()`,\n`.parallel().export_to_json()`. it's important to know that in order to send more requests per second to the coinmetrics\nthis uses the [parallel tasks features in python's concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)\npackage. this means when using this feature, the api client will use significantly more resources and may approach\nthe [coin metrics rate limits](https://docs.python.org/3/library/concurrent.futures.html). \n\nin terms of resource usage and speed, these usages are in order from most performant to least:\n* `.export_to_json_files()`\n* `.export_to_csv_files()`\n* `.to_list()`\n* `.export_to_json()`\n* `.to_dataframe()`\n\n### splitting single parameter queries into many requests for increased performance\nthere is a feature `time_increment` that can be used to split a single query into many based on time range, and then \ncombine them later. consider this example where we speed up getting a 2 months worth of btc referencerateusd data into\nmany parallel threads to create a dataframe faster: \n```python\nimport datetime\nimport os\nfrom coinmetrics.api_client import coinmetricsclient\nfrom dateutil.relativedelta import relativedelta\nclient = coinmetricsclient(os.environ.get(\"cm_api_key\"))\nstart_time = datetime.datetime.now()\nassets = [\"btc\", \"eth\", \"algo\"]\nif __name__ == '__main__':\n    client.get_asset_metrics(\n        assets=assets,\n        metrics=\"referencerateusd\",\n        frequency=\"1m\",\n        start_time=\"2022-03-01\",\n        end_time=\"2023-03-01\",\n        page_size=1000,\n        end_inclusive=false).parallel(\n        time_increment=relativedelta(months=1)).export_to_csv(\"btcrrs.csv\")\n    print(f\"time taken parallel: {datetime.datetime.now() - start_time}\")\n    start_time = datetime.datetime.now()\n    client.get_asset_metrics(\n        assets=assets,\n        metrics=\"referencerateusd\",\n        frequency=\"1m\",\n        start_time=\"2022-03-01\",\n        end_time=\"2023-03-01\",\n        page_size=1000,\n        end_inclusive=false).export_to_csv(\"btcrrsnormal.csv\")\n```\nnotice we pass in the `time_increment=relativedelta(months=1)` so that means we will split the threads up by month, in\naddition to by asset. so this will run a total 36 separate threads, 12 threads for each month x 3 threads for each asset.\nthe difference it takes in time is dramatic:\n```commandline\nexporting to dataframe type: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 36/36 [00:00<00:00, 54.62it/s]\ntime taken parallel: 0:00:36.654147\ntime taken normal: 0:05:20.073826\n```\n\nplease note that for short time periods you can pass in a `time_increment` with `datetime.timedelta` to specify up to \nseveral weeks, for larger time frames you can use `dateutil.relativedelta.relativedelta` in order to split requests\nup by increments of months or years.\n\n\n### to keep in mind when using using parallel feature or generally writing high performance code using api client:\n* if you are using a small `page_size` and trying to export a large number amount of, this will be your biggest bottleneck.\ngenerally the fastest `page_size` is `1000` to `10000`\n* if you are unsure why an action is taking a long time, running the coinmetricsclient using `verbose=true` or `debug=true`\ncan give better insight into what is happening under the hood\n* the parallel feature is best used when you are exporting a large amount of data, that can be split by query params into \nmany smaller requests. a good example of this is market candles over a long time frame - if you are querying hundreds\nof markets and are sure there will be data, using `.parallel().export_to_csv_files(\"...\")` can have a huge performance \nincrease, if you are just querying a single market you will not see a difference\n* the parallel feature is highly configurable, there is several configuration options that may be suitable for advanced\nusers like tweaking the `max_workers` parameter, or changing the default `processpoolexecutor` to a `threadpoolexectuor`\n* using multithreaded code is inherently more complex, it will be harder to debug issues with long running queries \nwhen running parallel exports compared to normal single threaded code\n* for that reason, this tool is best suited for exporting historical data rather than supporting a real time production\nsystem\n* the methods that create separate files for each thread will be the safest and most performant to use - `.export_to_csv_files()`\nand `.export_to_json_files()`. using the methods that return a single output - `.export_to_csv()`, `export_to_list()`, and\n`.export_to_dataframe()` need to join the data from many threads before it can be returned, this may use a lot of memory\nif you are accessing data types like market orderbooks or market trades and could fail altogether\n* if you get the error `brokenprocesspool` it [might be because you're missing a main() function](https://stackoverflow.com/questions/15900366/all-example-concurrent-futures-code-is-failing-with-brokenprocesspool)\n\n## examples\nthe api client allows you to chain together workflows for importing, transforming, then exporting coin metrics data.\nbelow are examples of common use-cases that can be altered to tailor your specific needs. in addition to the examples \nlisted below, there's examples covering all the api methods, found in the [examples directory](https://github.com/coinmetrics/api-client-python/tree/master/examples).\n\n**[example notebooks](https://github.com/coinmetrics/api-client-python/tree/master/examples/notebooks)**\n\n* `walkthrough_community.ipynb`: walks through the basic functionality available using the community client.\n\n**[asset metrics](https://github.com/coinmetrics/api-client-python/tree/master/examples/asset_metrics)**\n\n* `bbb_metrics_csv_exporter_using_plain_requests.py`: queries block-by-block metrics using the `requests` library and exports the output into a csv file.\n* `bbb_metrics_json_exporter.py`: queries block-by-block metrics and exports the output into a json file.\n* `eod_metrics_csv_exporter.py`: exports a set of user-defined metrics and assets published at end-of-day and exports the output into a csv file.\n* `reference_rates_json_exporter.py`: queries coin metrics reference rates at a user-defined frequency for a set of assets, then exports the output into a json file.\n\n**[market data](https://github.com/coinmetrics/api-client-python/tree/master/examples/market_data)** \n\n* `books_json_exporter.py`: queries market orderbook data then exports the output into a json file.\n* `candles_json_exporter.py`: queries market candles data then exports the output into a json file.\n* `funding_rates_json_exporter.py`: queries market funding rates data then exports the output into a json file.\n* `trades_csv_exporter.py`: queries market trades data then exports the output into a csv file.\n* `trades_json_exporter.py`: queries market trades data then exports the output into a json file.\n\n**[parallel processing exports](https://github.com/coinmetrics/api-client-python/tree/master/examples/parallel_data_export)\n* `candles_csv_export.py`: exports market candles in parallel to many separate csv files\n* `candles_json_export.py`: exports market candles in parallel to many separate json files\n* `market_trades_list.py`: creates a list of market trades, using `.parallel()` feature to improve performance\n* `market_orderbooks.py`: exports market orderbooks to many csv files\n* `candles_csv_export_manual.py`: example of parallelism using the api client without using the `.parallel()` feature\n* `btc_1m_metrics_export.py`: example of splitting a large request for asset metrics by metric to improve performance, exporting a\nsingle csv and also separate csv.\n* `market_orderbooks_csv_exporter_by_day.py`: example of splitting a market orderbook export up by day, to increase \nexport performance\n\n## getting timeseries data\n\nfor getting timeseries data you want to use methods of the client class that start with `get_`. it's important to note\nthat the timeseries endpoints return data of a parent class type `datacollection`. the `datacollection` class is meant\nto support a variety of different data export and data manipulation use cases, so just calling one of the client\nmethods such as `data = client.get_market_trades(markets=\"coinbase-btc-usd-spot\")` will not actually retrieve the data related\nto this api call. you must then call a function on this `datacollection` such as `data.export_to_csv(\"coinbase_btc_usd_spot_trades.csv)`\nor `data.to_dataframe()` in order to access the data. there is more explicit examples below.if you are curious to see\nhow the api calls are being made and with what parameters, instantiating the client with the `verbose` argument like \n`coinmetricsclient(api_key=<your_api_key>, verbose=true)` will print the api calls as well as information on performance to console. \n\nfor example if you want to get a bunch of market data trades for coinbase btc-usd pair you can run something similar to the following:\n\n```\nfor trade in client.get_market_trades(\n    markets='coinbase-btc-usd-spot', \n    start_time='2020-01-01', \n    end_time='2020-01-03',\n    limit_per_market=10\n):\n    print(trade)\n```\nthis example uses the `datacollection` as a python iterator, so with each iteration of the python for loop it will\ncall the coin metrics api and return data. the default `page_size` for calls to the api is 100, so each call will return\n100 trades until it reaches the end of the query. to get more trades in each api call, you can add the parameter\n`page_size` to the `.get_market_trades()` method call, up to a maximum of 10000. \n\nor if you want to see daily btc asset metrics you can use something like this:\n\n```\nfor metric_data in client.get_asset_metrics(assets='btc', \n                                            metrics=['referencerateusd', 'blkhgt', 'adractcnt',  \n                                                     'adractreccnt', 'flowoutbfxusd'], \n                                            frequency='1d',\n                                            limit_per_asset=10):\n    print(metric_data)\n```\nthis will print you the requested metrics for all the days where we have any of the metrics present.\n\n\n### dataframes\n_(new in >=`2021.9.30.14.30`)_\n\ntimeseries data can be transformed into a pandas dataframe by using the `to_dataframe()` method. the code snippet below shows how:\n```\nimport pandas as pd\nfrom coinmetrics.api_client import coinmetricsclient\nfrom os import environ\n\nclient = coinmetricsclient()\ntrades = client.get_market_trades(\n    markets='coinbase-btc-usd-spot', \n    start_time='2021-09-19t00:00:00z', \n    limit_per_market=10\n)\ntrades_df = trades.to_dataframe()\nprint(trades_df.head())\n\n```\nif you want to use dataframes, then you will need to install pandas\n\n**notes**\n\n- this only works with requests that return the type `datacollection`. thus, `catalog` requests, which return lists cannot be returned as dataframes.\n  please see the [api client spec](https://coinmetrics.github.io/api-client-python/site/api_client.html) for a full list\n  of requests and their return types.\n- api restrictions apply. some requests may return empty results due to limited access to the api from you api key.\n\n#### type conversion \n_(new in >=`2021.12.17.18.00`)_\n\nas of version `2021.12.17.18.00` or later, outputs from the  `to_dataframe` function automatically convert the dtypes for a dataframe to the optimal pandas types.\n```python\nmetrics_list = ['volume_trusted_spot_usd_1d', 'splyff', 'adrbalusd1cnt']\nasset_list = ['btc','xmr']\nstart_time='2021-12-01'\ndf_metrics = client.get_asset_metrics(\n  assets=asset_list, metrics=metrics_list, start_time=start_time, limit_per_asset=3\n).to_dataframe()\nprint(df_metrics.dtypes)\n```\n\n```\nasset                          string\ntime                           datetime64[ns, tzutc()]\nadrbalusd1cnt                   int64\nsplyff                        float64\nvolume_trusted_spot_usd_1d    float64\ndtype: object\n```\n\nthis can be turned off by setting `optimize_pandas_types=false`\n\nalternatively, you can manually enter your own type conversion by passing in a dictionary for `dtype_mapper`. this can be done in conjunction with pandas' built in type optimizations.\n```python\nmapper = {\n  'splyff': 'float64',\n  'adrbalusd1cnt': 'int64',\n}\ndf_mapped = client.get_asset_metrics(\n  assets=asset_list, metrics=metrics_list, start_time=start_time, limit_per_asset=3\n).to_dataframe(dtype_mapper=mapper, optimize_pandas_types=true)\nprint(df_mapped.dtypes)\n```\n\n```\nasset                                          object\ntime                          datetime64[ns, tzutc()]\nadrbalusd1cnt                                   int64\nsplyff                                        float64\nvolume_trusted_spot_usd_1d                    float64\ndtype: object\n```\n\nor as strictly the only types in the dataframe\n\n```python\ndtype_mapper = {\n    'referencerateusd': np.float64,\n    'time': np.datetime64\n}\ndf = client.get_asset_metrics(\n  assets='btc', metrics='referencerateusd', start_time='2022-06-15', limit_per_asset=1\n).to_dataframe(dtype_mapper=dtype_mapper, optimize_pandas_types=false)\ndf.info()\n```\n```\nrangeindex: 1 entries, 0 to 0\ndata columns (total 3 columns):\n #   column            non-null count  dtype         \n---  ------            --------------  -----         \n 0   asset             1 non-null      object        \n 1   time              1 non-null      datetime64[ns]\n 2   referencerateusd  1 non-null      float64       \ndtypes: datetime64[ns](1), float64(1), object(1)\nmemory usage: 152.0+ bytes\n```\n\nnote that in order to pass a custom datetime object, setting a dtype_mapper is mandatory.\n\npandas type conversion tends to be more performant. but if there are custom operations that must be done using numpy datatypes, this option will let you perform them.\n\n### exporting to csv and json files:\nyou can also easily export timeseries data to csv and json files with builtin functions on the `datacollection` type. \nfor example this script will export coinbase btc and eth trades for a date to csv and json files respectively:\n```python\n    start_date = datetime.date(year=2022, month=1, day=1)\n    end_date = datetime.datetime(year=2022, month=1, day=1)\n    market_trades_btc = client.get_market_trades(page_size=1000, markets=\"coinbase-btc-usd-spot\", start_time=start_date, end_time=end_date)\n    market_trades_btc.export_to_csv(\"jan_1_2022_coinbase_btc_trades.csv\")\n    market_trades_eth = client.get_market_trades(page_size=1000, markets=\"coinbase-eth-usd-spot\", start_time=start_date, end_time=end_date)\n    market_trades_eth.export_to_json(\"jan_1_2022_coinbase_eth.json\")\n```\n\n### paging\nyou can make the datapoints to iterate from start (default) or from end.\n\nfor that you should use a paging_from argument like the following:\n```\nfrom coinmetrics.api_client import coinmetricsclient\nfrom coinmetrics.constants import pagingfrom\n\nclient = coinmetricsclient()\n\nfor metric_data in client.get_asset_metrics(assets='btc', metrics=['referencerateusd'],\n                                            paging_from=pagingfrom.start):\n    print(metric_data)\n```\n\npagingfrom.end: is available but by default it will page from the start.\n\n\n### debugging the api client\nthere are two additional options for the api client - `debug_mode` and `verbose`. these two options log network calls \nto the console, and in the case of `debug_mode` it will generate a log file of all the network requests and the time\nit takes to call them. these tools can be used to diagnose issues in your code and also to get a better understanding \nof request times so that users can write more performant code. for example, running the below code:\n```python\nimport os\n\nfrom coinmetrics.api_client import coinmetricsclient\n\napi_key = os.environ['cm_api_key']\n\nif __name__ == '__main__':\n    client = coinmetricsclient(api_key=api_key, debug_mode=true)\n    reference_rates_example = client.get_asset_metrics(assets=['btc', 'algo', 'eth'], metrics=['referencerateusd'])\n    for data in reference_rates_example:\n        continue\n```\n\nthe console output will look like:\n```commandline\n[debug] 2023-01-09 11:01:02,044 - starting api client debugging session. logging to stdout and cm_api_client_debug_2023_01_09_11_01_02.txt\n[debug] 2023-01-09 11:01:02,044 - using coinmetrics version 2022.11.14.16\n[debug] 2023-01-09 11:01:02,044 - current state of api client, excluding api key: {'_verify_ssl_certs': true, '_api_base_url': 'https://api.coinmetrics.io/v4', '_ws_api_base_url': 'wss://api.coinmetrics.io/v4', '_http_header': {'api-client-version': '2022.11.14.16'}, '_proxies': {'http': none, 'https': none}, 'debug_mode': true, 'verbose': false}\n[debug] 2023-01-09 11:01:02,044 - attempting to call url: timeseries/asset-metrics with params: {'assets': ['btc', 'algo', 'eth'], 'metrics': ['referencerateusd'], 'frequency': none, 'page_size': none, 'paging_from': 'start', 'start_time': none, 'end_time': none, 'start_height': none, 'end_height': none, 'start_inclusive': none, 'end_inclusive': none, 'timezone': none, 'sort': none, 'limit_per_asset': none}\n[debug] 2023-01-09 11:01:02,387 - response status code: 200 for url: https://api.coinmetrics.io/v4/timeseries/asset-metrics?api_key=[redacted]&assets=btc%2calgo%2ceth&metrics=referencerateusd&paging_from=start took: 0:00:00.342874 response body size (bytes): 9832\n[debug] 2023-01-09 11:01:02,388 - attempting to call url: timeseries/asset-metrics with params: {'assets': ['btc', 'algo', 'eth'], 'metrics': ['referencerateusd'], 'frequency': none, 'page_size': none, 'paging_from': 'start', 'start_time': none, 'end_time': none, 'start_height': none, 'end_height': none, 'start_inclusive': none, 'end_inclusive': none, 'timezone': none, 'sort': none, 'limit_per_asset': none, 'next_page_token': '0.mjaxos0wos0zmfqwmdowmdowmfo'}\n[debug] 2023-01-09 11:01:02,559 - response status code: 200 for url: https://api.coinmetrics.io/v4/timeseries/asset-metrics?api_key=[redacted]&assets=btc%2calgo%2ceth&metrics=referencerateusd&paging_from=start&next_page_token=0.mjaxos0wos0zmfqwmdowmdowmfo took: 0:00:00.171487 response body size (bytes): 9857\n```\nthen it can be easier to understand what network calls the api client is making, and where any issues may exist. if you\nwish to dig even deeper, you may consider modifying the `_send_request()` method of the api client to log additional \ndata about the state of your environment, or anything else that would help diagnose issues. you will notice a log file\ngenerated in the format `cm_api_client_debug_2023_01_09_11_01_02.txt`. this log file might be helpful for your own use\nor to give more context if you are working with coin metrics customer success. \n\n### ssl certs verification\n\nsometimes your organization network have special rules on ssl certs verification and in this case you might face the\nfollowing error when running the script:\n```text\nsslerror: httpsconnectionpool(host='api.coinmetrics.io', port=443): max retries exceeded with url: <some_url_path> (caused by sslerror(sslcertverificationerror(1, '[ssl: certificate_verify_failed] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1123)')))\n```\n\nin this case, you can pass an option during client initialization to disable ssl verification for requests like this:\n\n```python\n\nclient = coinmetricsclient(verify_ssl_certs=false)\n```\n\nwe don't recommend setting it to false by default and you should make sure you understand the security risks of disabling ssl certs verification.\n\nadditionally, you may choose to specify the path to the ssl certificates on your machine. this may cause errors where \npython is unable to locate the certificates on your machine, particularly when using python virtual environments. \n\n```python\nfrom coinmetrics.api_client import coinmetricsclient\nssl_cert_location = '/users/<user_name>/library/python/3.8/lib/python/site-packages/certifi/cacert.pem'\nclient = coinmetricsclient(verify_ssl_certs=ssl_cert_location)\n```\n\na quick way to find the certs on your machine is:  \n`python3 -c \"import requests; print(requests.certs.where())\"`  \nand note that this will change based on whether or not you are using a [python virtual environment or not](https://realpython.com/python-virtual-environments-a-primer/)\n\n### installing and running coinmetrics package and other python packages behind a secure python network\nrelated to ssl certs verification, you may have trouble installing and updating pypi packages to your local environment.\nso you may need to choose the best solution for your company and environment - either using package managers or\ninstalling offline.\n\n#### installing using package managers\nfull instructions for setting up your environment to use conda, pip, yarn, npm, etc. can be [found here](https://medium.com/@iffi33/dealing-with-ssl-authentication-on-a-secure-corporate-network-pip-conda-git-npm-yarn-bower-73e5b93fd4b2).\nadditionally, a workaround to disable ssl verification when installing a trusted python package is this:  \n```commandline\npip install --trusted-host pypi.python.org <packagename>\n```  \nalthough it is important to make sure you understand the risks associated with disabling ssl verification and ensure \ncompliance with company policies.\n\n\n\n#### installing python packages locally/ offline\nit may be easier to download and install the package locally. steps:  \n1. download the files for the [coin metrics api client from pypi](https://pypi.org/project/coinmetrics-api-client/#files)\n2. [install it locally](https://packaging.python.org/en/latest/tutorials/installing-packages/#installing-from-local-archives)\n\n### requests proxy\nsometimes your organization has special rules on making requests to third parties and you have to use proxies in order to comply with the rules.\n\nfor proxies that don't require auth you can specify them similar to this example:\n```python\n\nclient = coinmetricsclient(proxy_url=f'http://<hostname>:<port>')\n```\n\nfor proxies that require auth, you should be able to specify username and password similar to this example:\n```python\n\nclient = coinmetricsclient(proxy_url=f'http://<username>:<password>@<hostname>:<port>')\n```\n\n## extended documentation\n\nfor more information about the available methods in the client please reference [api client spec](https://coinmetrics.github.io/api-client-python/site/api_client.html)\n\n",
  "docs_url": null,
  "keywords": "coin metrics,coin,metrics,crypto,bitcoin,network-data,market-data,api,handy",
  "license": "mit",
  "name": "coinmetrics-api-client",
  "package_url": "https://pypi.org/project/coinmetrics-api-client/",
  "project_url": "https://pypi.org/project/coinmetrics-api-client/",
  "project_urls": {
    "Documentation": "https://coinmetrics.github.io/api-client-python/site/index.html",
    "Homepage": "https://coinmetrics.github.io/api-client-python/site/index.html",
    "Repository": "https://github.com/coinmetrics/api-client-python"
  },
  "release_url": "https://pypi.org/project/coinmetrics-api-client/2023.11.27.17/",
  "requires_dist": [
    "requests (>=2.24.0,<3.0.0)",
    "orjson (>=3.6.0,<4.0.0)",
    "pandas (>=1.3.3,<2.0.0) ; extra == \"pandas\"",
    "websocket-client (>=1.2.1,<2.0.0)",
    "python-dateutil (>=2.8.2,<3.0.0)",
    "typer (>=0.7.0,<0.8.0)",
    "tqdm (>=4.64.1,<5.0.0)"
  ],
  "requires_python": ">=3.7.1,<4.0.0",
  "summary": "python client for coin metrics api v4.",
  "version": "2023.11.27.17",
  "releases": [],
  "developers": [
    "coin_metrics",
    "info@coinmetrics.io"
  ],
  "kwds": "pypi coinmetricsclient binance_eth_markets coinmetrics your_api_key",
  "license_kwds": "mit",
  "libtype": "pypi",
  "id": "pypi_coinmetrics_api_client",
  "homepage": "https://coinmetrics.github.io/api-client-python/site/index.html",
  "release_count": 91,
  "dependency_ids": [
    "pypi_orjson",
    "pypi_pandas",
    "pypi_python_dateutil",
    "pypi_requests",
    "pypi_tqdm",
    "pypi_typer",
    "pypi_websocket_client"
  ]
}