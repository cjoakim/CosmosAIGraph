{
  "classifiers": [
    "development status :: 4 - beta",
    "intended audience :: developers",
    "intended audience :: science/research",
    "license :: osi approved :: gnu lesser general public license v2 or later (lgplv2+)",
    "programming language :: cython",
    "programming language :: python",
    "programming language :: python :: 2",
    "programming language :: python :: 2.7",
    "programming language :: python :: 3",
    "programming language :: python :: 3.4",
    "programming language :: python :: 3.5",
    "programming language :: python :: 3.6",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: implementation :: cpython",
    "topic :: scientific/engineering :: information analysis",
    "topic :: software development :: libraries :: python modules",
    "topic :: text processing :: linguistic"
  ],
  "description": "datrie |travis| |appveyor|\n==========================\n\n.. |travis| image:: https://travis-ci.org/pytries/datrie.svg\n   :target: https://travis-ci.org/pytries/datrie\n\n.. |appveyor| image:: https://ci.appveyor.com/api/projects/status/6bpvhllpjhlau7x0?svg=true\n   :target: https://ci.appveyor.com/project/superbobry/datrie\n\nsuper-fast, efficiently stored trie for python (2.x and 3.x).\nuses `libdatrie`_.\n\n.. _libdatrie: https://linux.thai.net/~thep/datrie/datrie.html\n\ninstallation\n============\n\n::\n\n    pip install datrie\n\nusage\n=====\n\ncreate a new trie capable of storing items with lower-case ascii keys::\n\n    >>> import string\n    >>> import datrie\n    >>> trie = datrie.trie(string.ascii_lowercase)\n\n``trie`` variable is a dict-like object that can have unicode keys of\ncertain ranges and python objects as values.\n\nin addition to implementing the mapping interface, tries facilitate\nfinding the items for a given prefix, and vice versa, finding the\nitems whose keys are prefixes of a given string. as a common special\ncase, finding the longest-prefix item is also supported.\n\n.. warning::\n\n    for efficiency you must define allowed character range(s) while\n    creating trie. ``datrie`` doesn't check if keys are in allowed\n    ranges at runtime, so be careful! invalid keys are ok at lookup time\n    but values won't be stored correctly for such keys.\n\nadd some values to it (datrie keys must be unicode; the examples\nare for python 2.x)::\n\n    >>> trie[u'foo'] = 5\n    >>> trie[u'foobar'] = 10\n    >>> trie[u'bar'] = 'bar value'\n    >>> trie.setdefault(u'foobar', 15)\n    10\n\ncheck if u'foo' is in trie::\n\n    >>> u'foo' in trie\n    true\n\nget a value::\n\n    >>> trie[u'foo']\n    5\n\nfind all prefixes of a word::\n\n    >>> trie.prefixes(u'foobarbaz')\n    [u'foo', u'foobar']\n\n    >>> trie.prefix_items(u'foobarbaz')\n    [(u'foo', 5), (u'foobar', 10)]\n\n    >>> trie.iter_prefixes(u'foobarbaz')\n    <generator object ...>\n\n    >>> trie.iter_prefix_items(u'foobarbaz')\n    <generator object ...>\n\nfind the longest prefix of a word::\n\n    >>> trie.longest_prefix(u'foo')\n    u'foo'\n\n    >>> trie.longest_prefix(u'foobarbaz')\n    u'foobar'\n\n    >>> trie.longest_prefix(u'gaz')\n    keyerror: u'gaz'\n\n    >>> trie.longest_prefix(u'gaz', default=u'vasia')\n    u'vasia'\n\n    >>> trie.longest_prefix_item(u'foobarbaz')\n    (u'foobar', 10)\n\ncheck if the trie has keys with a given prefix::\n\n    >>> trie.has_keys_with_prefix(u'fo')\n    true\n\n    >>> trie.has_keys_with_prefix(u'fo')\n    false\n\nget all items with a given prefix from a trie::\n\n    >>> trie.keys(u'fo')\n    [u'foo', u'foobar']\n\n    >>> trie.items(u'ba')\n    [(u'bar', 'bar value')]\n\n    >>> trie.values(u'foob')\n    [10]\n\nget all suffixes of certain word starting with a given prefix from a trie::\n\n    >>> trie.suffixes()\n    [u'pro', u'producer', u'producers', u'product', u'production', u'productivity', u'prof']\n    >>> trie.suffixes(u'prod')\n    [u'ucer', u'ucers', u'uct', u'uction', u'uctivity']\n\n\nsave & load a trie (values must be picklable)::\n\n    >>> trie.save('my.trie')\n    >>> trie2 = datrie.trie.load('my.trie')\n\n\n\ntrie and basetrie\n=================\n\nthere are two trie classes in datrie package: ``datrie.trie`` and\n``datrie.basetrie``. ``datrie.basetrie`` is slightly faster and uses less\nmemory but it can store only integer numbers -2147483648 <= x <= 2147483647.\n``datrie.trie`` is a bit slower but can store any python object as a value.\n\nif you don't need values or integer values are ok then use ``datrie.basetrie``::\n\n    import datrie\n    import string\n    trie = datrie.basetrie(string.ascii_lowercase)\n\ncustom iteration\n================\n\nif the built-in trie methods don't fit you can use ``datrie.state`` and\n``datrie.iterator`` to implement custom traversal.\n\n.. note::\n\n    if you use ``datrie.basetrie`` you need ``datrie.basestate`` and\n    ``datrie.baseiterator`` for custom traversal.\n\n\nfor example, let's find all suffixes of ``'fo'`` for our trie and get\nthe values::\n\n    >>> state = datrie.state(trie)\n    >>> state.walk(u'foo')\n    >>> it = datrie.iterator(state)\n    >>> while it.next():\n    ...     print(it.key())\n    ...     print(it.data))\n    o\n    5\n    obar\n    10\n\nperformance\n===========\n\nperformance is measured for ``datrie.trie`` against python's dict with\n100k unique unicode words (english and russian) as keys and '1' numbers\nas values.\n\n``datrie.trie`` uses about 5m memory for 100k words; python's dict\nuses about 22m for this according to my unscientific tests.\n\nthis trie implementation is 2-6 times slower than python's dict\non __getitem__. benchmark results (macbook air i5 1.8ghz,\n\"1.000m ops/sec\" == \"1 000 000 operations per second\")::\n\n    python 2.6:\n    dict __getitem__: 7.107m ops/sec\n    trie __getitem__: 2.478m ops/sec\n\n    python 2.7:\n    dict __getitem__: 6.550m ops/sec\n    trie __getitem__: 2.474m ops/sec\n\n    python 3.2:\n    dict __getitem__: 8.185m ops/sec\n    trie __getitem__: 2.684m ops/sec\n\n    python 3.3:\n    dict __getitem__: 7.050m ops/sec\n    trie __getitem__: 2.755m ops/sec\n\nlooking for prefixes of a given word is almost as fast as\n``__getitem__`` (results are for python 3.3)::\n\n    trie.iter_prefix_items (hits):      0.461m ops/sec\n    trie.prefix_items (hits):           0.743m ops/sec\n    trie.prefix_items loop (hits):      0.629m ops/sec\n    trie.iter_prefixes (hits):          0.759m ops/sec\n    trie.iter_prefixes (misses):        1.538m ops/sec\n    trie.iter_prefixes (mixed):         1.359m ops/sec\n    trie.has_keys_with_prefix (hits):   1.896m ops/sec\n    trie.has_keys_with_prefix (misses): 2.590m ops/sec\n    trie.longest_prefix (hits):         1.710m ops/sec\n    trie.longest_prefix (misses):       1.506m ops/sec\n    trie.longest_prefix (mixed):        1.520m ops/sec\n    trie.longest_prefix_item (hits):    1.276m ops/sec\n    trie.longest_prefix_item (misses):  1.292m ops/sec\n    trie.longest_prefix_item (mixed):   1.379m ops/sec\n\nlooking for all words starting with a given prefix is mostly limited\nby overall result count (this can be improved in future because a\nlot of time is spent decoding strings from utf_32_le to python's\nunicode)::\n\n    trie.items(prefix=\"xxx\"), avg_len(res)==415:        0.609k ops/sec\n    trie.keys(prefix=\"xxx\"), avg_len(res)==415:         0.642k ops/sec\n    trie.values(prefix=\"xxx\"), avg_len(res)==415:       4.974k ops/sec\n    trie.items(prefix=\"xxxxx\"), avg_len(res)==17:       14.781k ops/sec\n    trie.keys(prefix=\"xxxxx\"), avg_len(res)==17:        15.766k ops/sec\n    trie.values(prefix=\"xxxxx\"), avg_len(res)==17:      96.456k ops/sec\n    trie.items(prefix=\"xxxxxxxx\"), avg_len(res)==3:     75.165k ops/sec\n    trie.keys(prefix=\"xxxxxxxx\"), avg_len(res)==3:      77.225k ops/sec\n    trie.values(prefix=\"xxxxxxxx\"), avg_len(res)==3:    320.755k ops/sec\n    trie.items(prefix=\"xxxxx..xx\"), avg_len(res)==1.4:  173.591k ops/sec\n    trie.keys(prefix=\"xxxxx..xx\"), avg_len(res)==1.4:   180.678k ops/sec\n    trie.values(prefix=\"xxxxx..xx\"), avg_len(res)==1.4: 503.392k ops/sec\n    trie.items(prefix=\"xxx\"), non_existing:             2023.647k ops/sec\n    trie.keys(prefix=\"xxx\"), non_existing:              1976.928k ops/sec\n    trie.values(prefix=\"xxx\"), non_existing:            2060.372k ops/sec\n\nrandom insert time is very slow compared to dict, this is the limitation\nof double-array tries; updates are quite fast. if you want to build a trie,\nconsider sorting keys before the insertion::\n\n    dict __setitem__ (updates):            6.497m ops/sec\n    trie __setitem__ (updates):            2.633m ops/sec\n    dict __setitem__ (inserts, random):    5.808m ops/sec\n    trie __setitem__ (inserts, random):    0.053m ops/sec\n    dict __setitem__ (inserts, sorted):    5.749m ops/sec\n    trie __setitem__ (inserts, sorted):    0.624m ops/sec\n    dict setdefault (updates):             3.455m ops/sec\n    trie setdefault (updates):             1.910m ops/sec\n    dict setdefault (inserts):             3.466m ops/sec\n    trie setdefault (inserts):             0.053m ops/sec\n\nother results (note that ``len(trie)`` is currently implemented\nusing trie traversal)::\n\n    dict __contains__ (hits):    6.801m ops/sec\n    trie __contains__ (hits):    2.816m ops/sec\n    dict __contains__ (misses):  5.470m ops/sec\n    trie __contains__ (misses):  4.224m ops/sec\n    dict __len__:                334336.269 ops/sec\n    trie __len__:                22.900 ops/sec\n    dict values():               406.507 ops/sec\n    trie values():               20.864 ops/sec\n    dict keys():                 189.298 ops/sec\n    trie keys():                 2.773 ops/sec\n    dict items():                48.734 ops/sec\n    trie items():                2.611 ops/sec\n\nplease take this benchmark results with a grain of salt; this\nis a very simple benchmark and may not cover your use case.\n\ncurrent limitations\n===================\n\n* keys must be unicode (no implicit conversion for byte strings\n  under python 2.x, sorry);\n* there are no iterator versions of keys/values/items (this is not\n  implemented yet);\n* it is painfully slow and maybe buggy under pypy;\n* library is not tested with narrow python builds.\n\ncontributing\n============\n\ndevelopment happens at github: https://github.com/pytries/datrie.\n\nfeel free to submit ideas, bugs, pull requests.\n\nrunning tests and benchmarks\n----------------------------\n\nmake sure `tox`_ is installed and run\n\n::\n\n    $ tox\n\nfrom the source checkout. tests should pass under python 2.7 and 3.4+.\n\n::\n\n    $ tox -c tox-bench.ini\n\nruns benchmarks.\n\nif you've changed anything in the source code then\nmake sure `cython`_ is installed and run\n\n::\n\n    $ update_c.sh\n\nbefore each ``tox`` command.\n\nplease note that benchmarks are not included in the release\ntar.gz's because benchmark data is large and this\nsaves a lot of bandwidth; use source checkouts from\ngithub or bitbucket for the benchmarks.\n\n.. _cython: https://cython.org/\n.. _tox: https://tox.readthedocs.io/\n\nauthors & contributors\n----------------------\n\nsee https://github.com/pytries/datrie/graphs/contributors.\n\nthis module is based on `libdatrie`_ c library by theppitak karoonboonyanan\nand is inspired by `fast_trie`_ ruby bindings, `pytrie`_ pure\npython implementation and `tree::trie`_ perl implementation;\nsome docs and api ideas are borrowed from these projects.\n\n.. _fast_trie: https://github.com/tyler/trie\n.. _pytrie: https://github.com/gsakkis/pytrie\n.. _tree::trie: https://metacpan.org/pod/release/avif/tree-trie-1.9/trie.pm\n\nlicense\n=======\n\nlicensed under lgpl v2.1.\nchanges\n=======\n\n0.8.2 (2020-03-25)\n------------------\n* future-proof python support by making cython a build time dependency and\n  removing cython generated c files from the repo (and sdist).\n* fix collections.abc.mutablemapping import\n* ci and test updates\n* adjust library name to unbreak some linkers\n\n0.8.1 (skipped)\n---------------\nthis version intentionally skipped\n\n0.8 (2019-07-03)\n----------------\n* python 3.7 compatibility; extension is rebuilt with cython 0.29.11.\n* trie.get function;\n* python 2.6 and 3.3 support is dropped;\n* removed patch to libdatrie which is no longer required;\n* testing and ci fixes.\n\n0.7.1 (2016-03-12)\n------------------\n\n* updated the bundled c library to version 0.2.9;\n* implemented ``trie.__len__`` in terms of ``trie_enumerate``;\n* rebuilt cython wrapper with cython 0.23.4;\n* changed ``trie`` to implement ``collections.abc.mutablemapping``;\n* fixed ``trie`` pickling, which segfaulted on python2.x.\n\n0.7 (2014-02-18)\n----------------\n\n* bundled libdatrie c library is updated to version 0.2.8;\n* new `.suffixes()` method (thanks ahmed t. youssef);\n* wrapper is rebuilt with cython 0.20.1.\n\n0.6.1 (2013-09-21)\n------------------\n\n* fixed build for visual studio (thanks gabi davar).\n\n0.6 (2013-07-09)\n----------------\n\n* datrie is rebuilt with cython 0.19.1;\n* ``iter_prefix_values``, ``prefix_values`` and ``longest_prefix_value``\n  methods for ``datrie.basetrie`` and ``datrie.trie`` (thanks jared suttles).\n\n0.5.1 (2013-01-30)\n------------------\n\n* recently introduced memory leak in ``longest_prefix``\n  and ``longest_prefix_item`` is fixed.\n\n0.5 (2013-01-29)\n----------------\n\n* ``longest_prefix`` and ``longest_prefix_item`` methods are fixed;\n* datrie is rebuilt with cython 0.18;\n* misleading benchmark results in readme are fixed;\n* state._walk is renamed to state.walk_char.\n\n0.4.2 (2012-09-02)\n------------------\n\n* update to latest libdatrie; this makes ``.keys()`` method a bit slower but\n  removes a keys length limitation.\n\n0.4.1 (2012-07-29)\n------------------\n\n* cpickle is used for saving/loading ``datrie.trie`` if it is available.\n\n0.4 (2012-07-27)\n----------------\n\n* ``libdatrie`` improvements and bugfixes, including c iterator api support;\n* custom iteration support using ``datrie.state`` and ``datrie.iterator``.\n* speed improvements: ``__length__``, ``keys``, ``values`` and\n  ``items`` methods should be up to 2x faster.\n* keys longer than 32768 are not supported in this release.\n\n\n0.3 (2012-07-21)\n----------------\n\nthere are no new features or speed improvements in this release.\n\n* ``datrie.new`` is deprecated; use ``datrie.trie`` with the same arguments;\n* small test & benchmark improvements.\n\n0.2 (2012-07-16)\n----------------\n\n* ``datrie.trie`` items can have any python object as a value\n  (``trie`` from 0.1.x becomes ``datrie.basetrie``);\n* ``longest_prefix`` and ``longest_prefix_items`` are fixed;\n* ``save`` & ``load`` are rewritten;\n* ``setdefault`` method.\n\n\n0.1.1 (2012-07-13)\n------------------\n\n* windows support (upstream libdatrie changes are merged);\n* license is changed from lgpl v3 to lgpl v2.1 to match the libdatrie license.\n\n0.1 (2012-07-12)\n----------------\n\ninitial release.",
  "docs_url": null,
  "keywords": "",
  "license": "lgplv2+",
  "name": "datrie",
  "package_url": "https://pypi.org/project/datrie/",
  "project_url": "https://pypi.org/project/datrie/",
  "project_urls": {
    "Homepage": "https://github.com/kmike/datrie"
  },
  "release_url": "https://pypi.org/project/datrie/0.8.2/",
  "requires_dist": [],
  "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*",
  "summary": "super-fast, efficiently stored trie for python.",
  "version": "0.8.2",
  "releases": [],
  "developers": [
    "kmike84@gmail.com",
    "mikhail_korobov"
  ],
  "kwds": "trie fast_trie _fast_trie trie2 trie_enumerate",
  "license_kwds": "lgplv2+",
  "libtype": "pypi",
  "id": "pypi_datrie",
  "homepage": "https://github.com/kmike/datrie",
  "release_count": 15,
  "dependency_ids": []
}