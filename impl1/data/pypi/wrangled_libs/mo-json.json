{
  "classifiers": [
    "development status :: 4 - beta",
    "license :: osi approved :: mozilla public license 2.0 (mpl 2.0)",
    "programming language :: python :: 3.10",
    "programming language :: python :: 3.11",
    "programming language :: python :: 3.7",
    "programming language :: python :: 3.8",
    "programming language :: python :: 3.9",
    "topic :: software development :: libraries",
    "topic :: software development :: libraries :: python modules"
  ],
  "description": "# more json tools\r\n\r\n\r\n[![pypi latest release](https://img.shields.io/pypi/v/mo-json.svg)](https://pypi.org/project/mo-json/)\r\n[![build status](https://app.travis-ci.com/klahnakoski/mo-json.svg?branch=master)](https://travis-ci.com/github/klahnakoski/mo-json)\r\n [![coverage status](https://coveralls.io/repos/github/klahnakoski/mo-json/badge.svg?branch=dev)](https://coveralls.io/github/klahnakoski/mo-json?branch=dev)\r\n[![downloads](https://pepy.tech/badge/mo-json)](https://pepy.tech/project/mo-json)\r\n\r\n\r\nthis set of modules provides the following benefits:\r\n\r\n* serialize more datastructures into json\r\n* more flexibility  in what's accepted as \"json\"\r\n* iterate over massive json easily (`mo_json.stream`)\r\n* provide a bijection between strictly typed json, and dynamic typed json.\r\n\r\n\r\n## recent changes\r\n\r\n* **version 6.x.x** - typed encoder no longer encodes to typed multivalues, rather, encodes to array of typed values.  for example, instead of \r\n\r\n      {\"a\":{\"~n~\":[1, 2]}}\r\n  we get \r\n      \r\n      {\"a\":[{\"~n~\":1},{\"~n~\":2}]} \r\n\r\n## usage\r\n\r\n### encode using `__json__`\r\n\r\nadd a `__json__` method to any class you wish to serialize to json. it is incumbent on you to ensure valid json is emitted:\r\n\r\n    class myclass(object):\r\n        def __init__(self, a, b):\r\n            self.a = a\r\n            self.b = b\r\n\r\n        def __json__(self):\r\n            separator = \"{\"\r\n            for k, v in self.__dict__.items():\r\n                yield separator\r\n                separator = \",\"\r\n                yield value2json(k)+\": \"+value2json(v)\r\n            yield \"}\"\r\n\r\nwith the `__json__` function defined, you may use the `value2json` function:\r\n\r\n    from mo_json import value2json\r\n    \r\n    result = value2json(myclass(a=\"name\", b=42))    \r\n\r\n\r\n### encode using `__data__`\r\n\r\nadd a `__data__` method that will convert your class into some json-serializable data structures.  you may find this easier to implement than emitting pure json.  **if both `__data__` and `__json__` exist, then `__json__` is used.**   \r\n\r\n    from mo_json import value2json\r\n\r\n    class myclass(object):\r\n        def __init__(self, a, b):\r\n            self.a = a\r\n            self.b = b\r\n\r\n        def __data__(self):\r\n            return self.__dict__\r\n   \r\n    result = value2json(myclass(a=\"name\", b=42))    \r\n\r\n\r\n### decoding\r\n\r\nthe `json2value` function provides a couple of options\r\n\r\n* `flexible` - will be very forgiving of json accepted (see [hjson](https://pypi.org/project/hjson/))\r\n* `leaves` - will interpret keys with dots (\"`.`\") as dot-delimited paths\r\n\r\n\r\n```\r\nfrom mo_json import json2value\r\n\r\nresult = json2value(\r\n    \"http.headers.referer: http://example.com\", \r\n    flexible=true, \r\n    leaves=true\r\n)\r\nassert result=={'http': {'headers': {'referer': 'http://example.com'}}}\r\n```\r\n \r\nnotice the lack of quotes in the json (hjson) and the deep structure created by the dot-delimited path name\r\n\r\n## running tests\r\n\r\n    pip install -r tests/requirements.txt\r\n    set pythonpath=.    \r\n    python.exe -m unittest discover tests\r\n\r\n\r\n## module details\r\n\r\n### method `mo_json.scrub()`\r\n\r\nremove, or convert, a number of objects from a structure that are not json-izable. it is faster to `scrub` and use the default (aka c-based) python encoder than it is to use `default` serializer that forces the use of an interpreted python encoder. \r\n\r\n----------------------\r\n\r\n### module `mo_json.stream`\r\n\r\na module that supports queries over very large json\r\nstrings. the overall objective is to make a large json document appear like\r\na hierarchical database, where arrays of any depth, can be queried like\r\ntables. \r\n\r\n\r\n#### limitations\r\n\r\nthis is not a generic streaming json parser. it is only intended to breakdown the top-level array, or object for less memory usage.  \r\n\r\n*  **array values must be the last object property** - if you query into a \r\n   nested array, all sibling properties found after that array must be ignored \r\n   (must not be in the `expected_vars`). the code will raise an exception if\r\n   you can not extract all expected variables.\r\n\r\n----------------------\r\n\r\n### method `mo_json.stream.parse()`\r\n\r\nwill return an iterator over all objects found in the json stream.\r\n\r\n**parameters:**\r\n\r\n* **json** - a parameter-less function, when called returns some number of\r\n  bytes from the json stream. it can also be a string.\r\n* **path** - a dot-delimited string specifying the path to the nested json. use \r\n  `\".\"` if your json starts with `[`, and is a list.\r\n* **expected_vars** - a list of strings specifying the full property names \r\n  required (all other properties are ignored)\r\n\r\n#### common usage\r\n\r\nthe most common use of `parse()` is to iterate over all the objects in a large, top-level, array:\r\n\r\n    parse(json, path=\".\", required_vars=[\".\"]}\r\n\r\nfor example, given the following json: \r\n\r\n    [\r\n        {\"a\": 1},\r\n        {\"a\": 2},\r\n        {\"a\": 3},\r\n        {\"a\": 4}\r\n    ]\r\n\r\nreturns a generator that provides\r\n\r\n    {\"a\": 1}\r\n    {\"a\": 2}\r\n    {\"a\": 3}\r\n    {\"a\": 4}\r\n\r\n\r\n#### examples\r\n\r\n**simple iteration**\r\n\r\n    json = {\"b\": \"done\", \"a\": [1, 2, 3]}\r\n    parse(json, path=\"a\", required_vars=[\"a\", \"b\"]}\r\n\r\nwe will iterate through the array found on property `a`, and return both `a` and `b` variables. it will return the following values:\r\n\r\n    {\"b\": \"done\", \"a\": 1}\r\n    {\"b\": \"done\", \"a\": 2}\r\n    {\"b\": \"done\", \"a\": 3}\r\n\r\n\r\n**bad - property follows array**\r\n\r\nthe same query, but different json with `b` following `a`:\r\n\r\n    json = {\"a\": [1, 2, 3], \"b\": \"done\"}\r\n    parse(json, path=\"a\", required_vars=[\"a\", \"b\"]}\r\n\r\nsince property `b` follows the array we're iterating over, this will raise an error.\r\n\r\n**good - no need for following properties**\r\n\r\nthe same json, but different query, which does not require `b`:\r\n\r\n    json = {\"a\": [1, 2, 3], \"b\": \"done\"}\r\n    parse(json, path=\"a\", required_vars=[\"a\"]}\r\n\r\nif we do not require `b`, then streaming will proceed just fine:\r\n\r\n    {\"a\": 1}\r\n    {\"a\": 2}\r\n    {\"a\": 3}\r\n\r\n**complex objects**\r\n\r\nthis streamer was meant for very long lists of complex objects. use dot-delimited naming to refer to full name of the property\r\n\r\n    json = [{\"a\": {\"b\": 1, \"c\": 2}}, {\"a\": {\"b\": 3, \"c\": 4}}, ...\r\n    parse(json, path=\".\", required_vars=[\"a.c\"])\r\n\r\nthe dot (`.`) can be used to refer to the top-most array. notice the structure is maintained, but only includes the required variables.\r\n\r\n    {\"a\": {\"c\": 2}}\r\n    {\"a\": {\"c\": 4}}\r\n    ...\r\n\r\n**nested arrays**\r\n\r\nnested array iteration is meant to mimic a left-join from parent to child table;\r\nas such, it includes every record in the parent. \r\n\r\n    json = [\r\n        {\"o\": 1: \"a\": [{\"b\": 1}: {\"b\": 2}: {\"b\": 3}: {\"b\": 4}]},\r\n        {\"o\": 2: \"a\": {\"b\": 5}},\r\n        {\"o\": 3}\r\n    ]\r\n    parse(json, path=[\".\", \"a\"], required_vars=[\"o\", \"a.b\"])\r\n\r\nthe `path` parameter can be a list, which is used to indicate which properties\r\nare expected to have an array, and to iterate over them. please notice if no\r\narray is found, it is treated like a singleton array, and missing arrays still\r\nproduce a result.\r\n\r\n    {\"o\": 1, \"a\": {\"b\": 1}}\r\n    {\"o\": 1, \"a\": {\"b\": 2}}\r\n    {\"o\": 1, \"a\": {\"b\": 3}}\r\n    {\"o\": 1, \"a\": {\"b\": 4}}\r\n    {\"o\": 2, \"a\": {\"b\": 5}}\r\n    {\"o\": 3}\r\n\r\n**large top-level objects**\r\n\r\nsome json is a single large object, rather than an array of objects. in these cases, you can use the `items` operator to iterate through all name/value pairs of an object:\r\n\r\n    json = {\r\n        \"a\": \"test\",\r\n        \"b\": 2,\r\n        \"c\": [1, 2]\r\n    }\r\n    parse(json, {\"items\":\".\"}, {\"name\", \"value\"})   \r\n\r\nproduces an iterator of\r\n\r\n    {\"name\": \"a\", \"value\":\"test\"} \r\n    {\"name\": \"b\", \"value\":2} \r\n    {\"name\": \"c\", \"value\":[1,2]} \r\n\r\n----------------------\r\n\r\n### module `typed_encoder`\r\n\r\n\r\none reason that nosql documents stores are wonderful is their schema can automatically expand to accept new properties. unfortunately, this flexibility is not limitless; a string assigned to property prevents an object being assigned to the same, or visa-versa. this flexibility is under attack by the strict-typing zealots; who, in their self righteous delusion, believe explicit types are better. they make the lives of humans worse; as we are forced to toil over endless schema modifications.\r\n\r\nthis module translates json documents into \"typed\" form; which allows document containers to store both objects and primitives in the same property. this also enables the storage of values with no containing object! \r\n\r\nthe typed json has a different form than the original, and queries into the document store must take this into account. this conversion is intended to be hidden behind a query abstraction layer that can understand this format.\r\n\r\n#### how it works\r\n\r\nthere are three main conversions:\r\n\r\n1. primitive values are replaced with single-property objects, where the property name indicates the data type of the value stored:\r\n```\r\n    {\"a\": true} -> {\"a\": {\"~b~\": true}} \r\n    {\"a\": 1   } -> {\"a\": {\"~n~\": 1   }} \r\n    {\"a\": \"1\" } -> {\"a\": {\"~s~\": \"1\" }}\r\n```\r\n2. json objects get an additional property, `~e~`, to mark existence. this allows us to query for object existence, and to count the number of objects.\r\n```    \r\n    {\"a\": {}} -> {\"a\": {}, \"~e~\": 1}  \r\n```\r\n3. json arrays are contained in a new object, along with `~e~` to count the number of elements in the array:\r\n```    \r\n    {\"a\": [1, 2, 3]} -> {\"a\": {\r\n        \"~e~\": 3, \r\n        \"~n~\":[\r\n            {\"~n~\": 1},\r\n            {\"~n~\": 2},\r\n            {\"~n~\": 3}\r\n        ]\r\n    }}\r\n```\r\nplease notice the sum of `a.~e~` works for both objects and arrays; letting us interpret sub-objects as single-value nested object arrays. \r\n\r\n### function `typed_encode()`\r\n\r\naccepts a `dict`, `list`, or primitive value, and generates the typed json that can be inserted into a document store.\r\n\r\n### function `json2typed()`\r\n\r\nconverts an existing json unicode string and returns the typed json unicode string for the same.\r\n\r\n\r\n----------------------\r\n\r\n\r\n### module `mo_json.encode`\r\n\r\n### function: `mo_json.encode.json_encoder()`\r\n\r\n----------------------\r\n\r\n**update mar2016** - *pypy version 5.x appears to have improved c integration to\r\nthe point that the c library callbacks are no longer a significant overhead:\r\nthis pure python json encoder is no longer faster than a compound c/python\r\nsolution.*\r\n\r\nfast json encoder used in `convert.value2json()` when running in pypy. run the\r\n[speed test](https://github.com/klahnakoski/mo-json/blob/dev/tests/speedtest_json.py)\r\nto compare with default implementation and ujson\r\n\r\n",
  "docs_url": null,
  "keywords": "",
  "license": "mpl 2.0",
  "name": "mo-json",
  "package_url": "https://pypi.org/project/mo-json/",
  "project_url": "https://pypi.org/project/mo-json/",
  "project_urls": {
    "Homepage": "https://github.com/klahnakoski/mo-json"
  },
  "release_url": "https://pypi.org/project/mo-json/6.458.23316/",
  "requires_dist": [
    "hjson",
    "mo-dots ==9.455.23316",
    "mo-future ==7.449.23304",
    "mo-logs ==8.456.23316",
    "mo-times ==5.458.23316",
    "mo-testing ; extra == 'tests'",
    "mo-threads ; extra == 'tests'"
  ],
  "requires_python": "",
  "summary": "more json tools!",
  "version": "6.458.23316",
  "releases": [],
  "developers": [
    "kyle@lahnakoski.com",
    "kyle_lahnakoski"
  ],
  "kwds": "mo_json __json__ json json_encoder speedtest_json",
  "license_kwds": "mpl 2.0",
  "libtype": "pypi",
  "id": "pypi_mo_json",
  "homepage": "https://github.com/klahnakoski/mo-json",
  "release_count": 91,
  "dependency_ids": [
    "pypi_hjson",
    "pypi_mo_dots",
    "pypi_mo_future",
    "pypi_mo_logs",
    "pypi_mo_testing",
    "pypi_mo_threads",
    "pypi_mo_times"
  ]
}