{
  "libtype": "pypi",
  "libname": "timm",
  "url": "https://github.com/huggingface/pytorch-image-models",
  "html": "<!DOCTYPE html><html  lang=\"en\"    data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-theme=\"dark\"  data-a11y-animated-images=\"system\" data-a11y-link-underlines=\"true\"  >  <head>    <meta charset=\"utf-8\">  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">  <link rel=\"preconnect\" href=\"https://github.githubassets.com\" crossorigin>  <link rel=\"preconnect\" href=\"https://avatars.githubusercontent.com\">    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/light-0eace2597ca3.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/dark-a167e256da9c.css\" /><link data-color-theme=\"dark_dimmed\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_dimmed-d11f2cf8009b.css\" /><link data-color-theme=\"dark_high_contrast\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_high_contrast-ea7373db06c8.css\" /><link data-color-theme=\"dark_colorblind\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_colorblind-afa99dcf40f7.css\" /><link data-color-theme=\"light_colorblind\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_colorblind-af6c685139ba.css\" /><link data-color-theme=\"light_high_contrast\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_high_contrast-578cdbc8a5a9.css\" /><link data-color-theme=\"light_tritanopia\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/light_tritanopia-5cb699a7e247.css\" /><link data-color-theme=\"dark_tritanopia\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.githubassets.com/assets/dark_tritanopia-9b32204967c6.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/primer-primitives-2ef2a46b27ee.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/primer-711f412bb361.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/global-4803cd254267.css\" />    <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/github-f4d857cbc96a.css\" />  <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/repository-6247ca238fd4.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/code-6d7b4ef0ea51.css\" />    <script type=\"application/json\" id=\"client-env\">{\"locale\":\"en\",\"featureFlags\":[\"code_vulnerability_scanning\",\"copilot_conversational_ux_history_refs\",\"copilot_chat_attach_knowledge\",\"copilot_chat_knowledge_base_copy\",\"copilot_smell_icebreaker_ux\",\"copilot_implicit_context\",\"docset_management_ui\",\"copilot_chat_settings\",\"failbot_handle_non_errors\",\"geojson_azure_maps\",\"image_metric_tracking\",\"marketing_forms_api_integration_contact_request\",\"marketing_pages_search_explore_provider\",\"turbo_experiment_risky\",\"sample_network_conn_type\",\"no_character_key_shortcuts_in_inputs\",\"custom_inp\",\"remove_child_patch\"]}</script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/wp-runtime-47578fb192fd.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_dompurify_dist_purify_js-6890e890956f.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_stacktrace-parser_dist_stack-trace-parser_esm_js-node_modules_github_bro-a4c183-79f9611c275b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_hydro-analytics-client_dist_analytics-client_js-node_modules_gith-6a10dd-e66ebda625fb.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_failbot_failbot_ts-479802999bcc.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/environment-fe7570f3bc38.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_selector-observer_dist_index_esm_js-9f960d9b217c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_focus-zone_js-086f7a27bac0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_relative-time-element_dist_index_js-c76945c5961a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_details-dialog-elemen-29dc30-a2a71f11a507.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_auto-complete-element_dist_index_js-12366198e7a5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_text-expander-element_dist_index_js-8a621df59e80.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-b7d8f4-654130b7cde5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_primer_view-co-5dccdf-e5e2b9fa3c0c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/github-elements-e4eda4896b4e.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/element-registry-b99c9d8fad1d.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_catalyst_lib_index_js-node_modules_github_hydro-analytics-client_-978abc0-add939c751ce.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_lit-html_lit-html_js-5b376145beff.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_alive-client_dist-bf5aa2-1b562c29ab8e.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_morphdom_dist_morphdom-esm_js-5bff297a06de.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_turbo_dist_turbo_es2017-esm_js-c91f4ad18b62.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_color-convert_index_js-72c9fbde5ad4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_scroll-anchoring_dist_scro-231ccf-aa129238d13b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_dimensions_js-node_modules_github_jtml_lib_index_js-95b84ee6bc34.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_session-resume_dist_index_js-node_modules_primer_behaviors_dist_e-da6ec6-3f39339c9d98.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_paste-markdown_dist_index_esm_js-node_modules_github_quote-select-67e0dc-1aa35af077a4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_updatable-content_ts-ee3fc84d7fb0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_task-list_ts-app_assets_modules_github_onfocus_ts-app_ass-421cec-9de4213015af.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_sticky-scroll-into-view_ts-94209c43e6af.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_ajax-error_ts-app_assets_modules_github_behaviors_include-467754-f9bd433e9591.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_behaviors_commenting_edit_ts-app_assets_modules_github_behaviors_ht-83c235-9285faa0e011.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_blob-anchor_ts-app_assets_modules_github_filter-sort_ts-app_assets_-c96432-da3733f430b8.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/behaviors-1fb9e5061509.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_catalyst_lib_index_js-d0256ebff5cd.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/notifications-global-352d84c6cc82.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_virtualized-list_es_index_js-node_modules_github_template-parts_lib_index_js-878844713bc9.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-c537341-c7f6a41a084c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_github_ref-selector_ts-b593b93f23f5.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/codespaces-1a8626dd714a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_mini-throt-08ab15-3e0517baca99.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_github_mini-th-55cf52-e14cb4b719b4.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/repositories-69068e0899f9.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/code-menu-614feb194539.js\"></script>    <title>GitHub - huggingface/pytorch-image-models: PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more</title>  <meta name=\"route-pattern\" content=\"/:user_id/:repository\" data-turbo-transient>  <meta name=\"route-controller\" content=\"files\" data-turbo-transient>  <meta name=\"route-action\" content=\"disambiguate\" data-turbo-transient>      <meta name=\"current-catalog-service-hash\" content=\"82c569b93da5c18ed649ebd4c2c79437db4611a6a1373e805a3cb001c64130b7\">  <meta name=\"request-id\" content=\"C19C:7B6A:B79945:10F1F88:65E78CB9\" data-pjax-transient=\"true\"/><meta name=\"html-safe-nonce\" content=\"f9922bc13713aba4358182ba1d7c0b2a6ce9707a3dfbda654a415ce55305bebc\" data-pjax-transient=\"true\"/><meta name=\"visitor-payload\" content=\"eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJDMTlDOjdCNkE6Qjc5OTQ1OjEwRjFGODg6NjVFNzhDQjkiLCJ2aXNpdG9yX2lkIjoiNDkyNTM1NTk0NzE0NDQ4MTk3NyIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9\" data-pjax-transient=\"true\"/><meta name=\"visitor-hmac\" content=\"6a13318ef8e4591afa4ff9292ab1bd9f7e445c0dc2e36b2a54d05c69554987be\" data-pjax-transient=\"true\"/>    <meta name=\"hovercard-subject-tag\" content=\"repository:168799526\" data-turbo-transient>  <meta name=\"github-keyboard-shortcuts\" content=\"repository,copilot\" data-turbo-transient=\"true\" />    <meta name=\"selected-link\" value=\"repo_source\" data-turbo-transient>  <link rel=\"assets\" href=\"https://github.githubassets.com/\">    <meta name=\"google-site-verification\" content=\"c1kuD-K2HIVF635lypcsWPoD4kilo5-jA_wBFyT4uMY\">  <meta name=\"google-site-verification\" content=\"KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU\">  <meta name=\"google-site-verification\" content=\"ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA\">  <meta name=\"google-site-verification\" content=\"GXs5KoUUkNCoaAZn7wPN-t01Pywp9M3sEjnt_3_ZWPc\">  <meta name=\"google-site-verification\" content=\"Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I\"><meta name=\"octolytics-url\" content=\"https://collector.github.com/github/collect\" />  <meta name=\"analytics-location\" content=\"/&lt;user-name&gt;/&lt;repo-name&gt;\" data-turbo-transient=\"true\" />        <meta name=\"user-login\" content=\"\">      <meta name=\"viewport\" content=\"width=device-width\">          <meta name=\"description\" content=\"PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more - huggingface/pytorch-image-models\">      <link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/opensearch.xml\" title=\"GitHub\">    <link rel=\"fluid-icon\" href=\"https://github.com/fluidicon.png\" title=\"GitHub\">    <meta property=\"fb:app_id\" content=\"1401488693436528\">    <meta name=\"apple-itunes-app\" content=\"app-id=1477376905, app-argument=https://github.com/huggingface/pytorch-image-models\" />      <meta name=\"twitter:image:src\" content=\"https://opengraph.githubassets.com/0a82bfdb3b88b6da1c5594c812213c5c23cf5f9427e0ea5f7dda84904673e36d/huggingface/pytorch-image-models\" /><meta name=\"twitter:site\" content=\"@github\" /><meta name=\"twitter:card\" content=\"summary_large_image\" /><meta name=\"twitter:title\" content=\"GitHub - huggingface/pytorch-image-models: PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more\" /><meta name=\"twitter:description\" content=\"PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeX...\" />      <meta property=\"og:image\" content=\"https://opengraph.githubassets.com/0a82bfdb3b88b6da1c5594c812213c5c23cf5f9427e0ea5f7dda84904673e36d/huggingface/pytorch-image-models\" /><meta property=\"og:image:alt\" content=\"PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeX...\" /><meta property=\"og:image:width\" content=\"1200\" /><meta property=\"og:image:height\" content=\"600\" /><meta property=\"og:site_name\" content=\"GitHub\" /><meta property=\"og:type\" content=\"object\" /><meta property=\"og:title\" content=\"GitHub - huggingface/pytorch-image-models: PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more\" /><meta property=\"og:url\" content=\"https://github.com/huggingface/pytorch-image-models\" /><meta property=\"og:description\" content=\"PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeX...\" />              <meta name=\"hostname\" content=\"github.com\">        <meta name=\"expected-hostname\" content=\"github.com\">  <meta http-equiv=\"x-pjax-version\" content=\"b9fa4cafade57d606c6dcfafff1d08bd597980af7b9837ed473fdf0cdea8a3bc\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-csp-version\" content=\"5dcfbec3488c5fd5a334e287ce6a17058b7d4beb91db2d4d184e4d55bbf1d7d7\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-css-version\" content=\"d33c7c2fcff40783f3002896023f41e2c17ec62b12ddbe7434e2001d743fb853\" data-turbo-track=\"reload\">  <meta http-equiv=\"x-pjax-js-version\" content=\"4ba4a7cc07194c8d5f24291dea4fbc790ffd83ba40beacaf8d0117187b571b4d\" data-turbo-track=\"reload\">  <meta name=\"turbo-cache-control\" content=\"no-preview\" data-turbo-transient=\"\">      <meta data-hydrostats=\"publish\">  <meta name=\"go-import\" content=\"github.com/huggingface/pytorch-image-models git https://github.com/huggingface/pytorch-image-models.git\">  <meta name=\"octolytics-dimension-user_id\" content=\"25720743\" /><meta name=\"octolytics-dimension-user_login\" content=\"huggingface\" /><meta name=\"octolytics-dimension-repository_id\" content=\"168799526\" /><meta name=\"octolytics-dimension-repository_nwo\" content=\"huggingface/pytorch-image-models\" /><meta name=\"octolytics-dimension-repository_public\" content=\"true\" /><meta name=\"octolytics-dimension-repository_is_fork\" content=\"false\" /><meta name=\"octolytics-dimension-repository_network_root_id\" content=\"168799526\" /><meta name=\"octolytics-dimension-repository_network_root_nwo\" content=\"huggingface/pytorch-image-models\" />    <link rel=\"canonical\" href=\"https://github.com/huggingface/pytorch-image-models\" data-turbo-transient>  <meta name=\"turbo-body-classes\" content=\"logged-out env-production page-responsive\">  <meta name=\"browser-stats-url\" content=\"https://api.github.com/_private/browser/stats\">  <meta name=\"browser-errors-url\" content=\"https://api.github.com/_private/browser/errors\">  <link rel=\"mask-icon\" href=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" color=\"#000000\">  <link rel=\"alternate icon\" class=\"js-site-favicon\" type=\"image/png\" href=\"https://github.githubassets.com/favicons/favicon.png\">  <link rel=\"icon\" class=\"js-site-favicon\" type=\"image/svg+xml\" href=\"https://github.githubassets.com/favicons/favicon.svg\"><meta name=\"theme-color\" content=\"#1e2327\"><meta name=\"color-scheme\" content=\"light dark\" />  <link rel=\"manifest\" href=\"/manifest.json\" crossOrigin=\"use-credentials\">  </head>  <body class=\"logged-out env-production page-responsive\" style=\"word-wrap: break-word;\">    <div data-turbo-body class=\"logged-out env-production page-responsive\" style=\"word-wrap: break-word;\">          <div class=\"position-relative js-header-wrapper \">      <a href=\"#start-of-content\" class=\"px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content\">Skip to content</a>      <span data-view-component=\"true\" class=\"progress-pjax-loader Progress position-fixed width-full\">    <span style=\"width: 0%;\" data-view-component=\"true\" class=\"Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis\"></span></span>              <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Button_IconButton_js-node_modules_primer_react_lib--23bcad-a89698f38643.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/keyboard-shortcuts-dialog-a23eda2bcf8d.js\"></script><react-partial  partial-name=\"keyboard-shortcuts-dialog\"  data-ssr=\"false\">    <script type=\"application/json\" data-target=\"react-partial.embeddedData\">{\"props\":{}}</script>  <div data-target=\"react-partial.reactRoot\"></div></react-partial>                          <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-94fd67-99519581d0f8.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/sessions-585a7232e50a.js\"></script><header class=\"Header-old header-logged-out js-details-container Details position-relative f4 py-3\" role=\"banner\" data-color-mode=light data-light-theme=light data-dark-theme=dark>  <button type=\"button\" class=\"Header-backdrop d-lg-none border-0 position-fixed top-0 left-0 width-full height-full js-details-target\" aria-label=\"Toggle navigation\">    <span class=\"d-none\">Toggle navigation</span>  </button>  <div class=\" d-flex flex-column flex-lg-row flex-items-center p-responsive height-full position-relative z-1\">    <div class=\"d-flex flex-justify-between flex-items-center width-full width-lg-auto\">      <a class=\"mr-lg-3 color-fg-inherit flex-order-2\" href=\"https://github.com/\" aria-label=\"Homepage\" data-ga-click=\"(Logged out) Header, go to homepage, icon:logo-wordmark\">        <svg height=\"32\" aria-hidden=\"true\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"32\" data-view-component=\"true\" class=\"octicon octicon-mark-github\">    <path d=\"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z\"></path></svg>      </a>      <div class=\"flex-1\">        <a href=\"/login?return_to=https%3A%2F%2Fgithub.com%2Fhuggingface%2Fpytorch-image-models\"          class=\"d-inline-block d-lg-none flex-order-1 f5 no-underline border color-border-default rounded-2 px-2 py-1 color-fg-inherit\"          data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/huggingface/pytorch-image-models&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"f1957a6a3dd8668fce3eee055123d2da65f519d99bdc5d9b59fd01ed9f4d3040\"          data-ga-click=\"(Logged out) Header, clicked Sign in, text:sign-in\">          Sign in        </a>      </div>      <div class=\"flex-1 flex-order-2 text-right\">        <button aria-label=\"Toggle navigation\" aria-expanded=\"false\" type=\"button\" data-view-component=\"true\" class=\"js-details-target Button--link Button--medium Button d-lg-none color-fg-inherit p-1\">  <span class=\"Button-content\">    <span class=\"Button-label\"><div class=\"HeaderMenu-toggle-bar rounded my-1\"></div>            <div class=\"HeaderMenu-toggle-bar rounded my-1\"></div>            <div class=\"HeaderMenu-toggle-bar rounded my-1\"></div></span>  </span></button>      </div>    </div>    <div class=\"HeaderMenu--logged-out p-responsive height-fit position-lg-relative d-lg-flex flex-column flex-auto pt-7 pb-4 top-0\">      <div class=\"header-menu-wrapper d-flex flex-column flex-self-end flex-lg-row flex-justify-between flex-auto p-3 p-lg-0 rounded rounded-lg-0 mt-3 mt-lg-0\">          <nav class=\"mt-0 px-3 px-lg-0 mb-3 mb-lg-0\" aria-label=\"Global\">            <ul class=\"d-lg-flex list-style-none\">                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Product        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 d-lg-flex dropdown-menu-wide\">          <div class=\"px-lg-4 border-lg-right mb-4 mb-lg-0 pr-lg-7\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}\" href=\"/features/actions\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-workflow color-fg-subtle mr-3\">    <path d=\"M1 3a2 2 0 0 1 2-2h6.5a2 2 0 0 1 2 2v6.5a2 2 0 0 1-2 2H7v4.063C7 16.355 7.644 17 8.438 17H12.5v-2.5a2 2 0 0 1 2-2H21a2 2 0 0 1 2 2V21a2 2 0 0 1-2 2h-6.5a2 2 0 0 1-2-2v-2.5H8.437A2.939 2.939 0 0 1 5.5 15.562V11.5H3a2 2 0 0 1-2-2Zm2-.5a.5.5 0 0 0-.5.5v6.5a.5.5 0 0 0 .5.5h6.5a.5.5 0 0 0 .5-.5V3a.5.5 0 0 0-.5-.5ZM14.5 14a.5.5 0 0 0-.5.5V21a.5.5 0 0 0 .5.5H21a.5.5 0 0 0 .5-.5v-6.5a.5.5 0 0 0-.5-.5Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Actions</div>        Automate any workflow      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}\" href=\"/features/packages\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-package color-fg-subtle mr-3\">    <path d=\"M12.876.64V.639l8.25 4.763c.541.313.875.89.875 1.515v9.525a1.75 1.75 0 0 1-.875 1.516l-8.25 4.762a1.748 1.748 0 0 1-1.75 0l-8.25-4.763a1.75 1.75 0 0 1-.875-1.515V6.917c0-.625.334-1.202.875-1.515L11.126.64a1.748 1.748 0 0 1 1.75 0Zm-1 1.298L4.251 6.34l7.75 4.474 7.75-4.474-7.625-4.402a.248.248 0 0 0-.25 0Zm.875 19.123 7.625-4.402a.25.25 0 0 0 .125-.216V7.639l-7.75 4.474ZM3.501 7.64v8.803c0 .09.048.172.125.216l7.625 4.402v-8.947Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Packages</div>        Host and manage packages      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}\" href=\"/features/security\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-shield-check color-fg-subtle mr-3\">    <path d=\"M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z\"></path><path d=\"m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Security</div>        Find and fix vulnerabilities      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}\" href=\"/features/codespaces\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-codespaces color-fg-subtle mr-3\">    <path d=\"M3.5 3.75C3.5 2.784 4.284 2 5.25 2h13.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 18.75 13H5.25a1.75 1.75 0 0 1-1.75-1.75Zm-2 12c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v4a1.75 1.75 0 0 1-1.75 1.75H3.25a1.75 1.75 0 0 1-1.75-1.75ZM5.25 3.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h13.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Zm-2 12a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h17.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25Z\"></path><path d=\"M10 17.75a.75.75 0 0 1 .75-.75h6.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Codespaces</div>        Instant dev environments      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}\" href=\"/features/copilot\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-copilot color-fg-subtle mr-3\">    <path d=\"M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z\"></path><path d=\"M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Copilot</div>        Write better code with AI      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}\" href=\"/features/code-review\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-code-review color-fg-subtle mr-3\">    <path d=\"M10.3 6.74a.75.75 0 0 1-.04 1.06l-2.908 2.7 2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z\"></path><path d=\"M1.5 4.25c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v12.5a1.75 1.75 0 0 1-1.75 1.75h-9.69l-3.573 3.573A1.458 1.458 0 0 1 5 21.043V18.5H3.25a1.75 1.75 0 0 1-1.75-1.75ZM3.25 4a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h2.5a.75.75 0 0 1 .75.75v3.19l3.72-3.72a.749.749 0 0 1 .53-.22h10a.25.25 0 0 0 .25-.25V4.25a.25.25 0 0 0-.25-.25Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Code review</div>        Manage code changes      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center pb-lg-3\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}\" href=\"/features/issues\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-issue-opened color-fg-subtle mr-3\">    <path d=\"M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1ZM2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5 9.5 9.5 0 0 0 2.5 12Zm9.5 2a2 2 0 1 1-.001-3.999A2 2 0 0 1 12 14Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Issues</div>        Plan and track work      </div>    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}\" href=\"/features/discussions\">      <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-comment-discussion color-fg-subtle mr-3\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z\"></path><path d=\"M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z\"></path></svg>      <div>        <div class=\"color-fg-default h4\">Discussions</div>        Collaborate outside of code      </div>    </a></li>            </ul>          </div>          <div class=\"px-lg-4\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"product-explore-heading\">Explore</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"product-explore-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to All features&quot;,&quot;label&quot;:&quot;ref_cta:All features;&quot;}\" href=\"/features\">      All features    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Documentation&quot;,&quot;label&quot;:&quot;ref_cta:Documentation;&quot;}\" href=\"https://docs.github.com\">      Documentation    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Skills&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Skills;&quot;}\" href=\"https://skills.github.com/\">      GitHub Skills    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Blog&quot;,&quot;label&quot;:&quot;ref_cta:Blog;&quot;}\" href=\"https://github.blog\">      Blog    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Solutions        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 px-lg-4\">          <div class=\"border-bottom pb-3 mb-3\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-for-heading\">For</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-for-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Enterprise&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise;&quot;}\" href=\"/enterprise\">      Enterprise    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Teams&quot;,&quot;label&quot;:&quot;ref_cta:Teams;&quot;}\" href=\"/team\">      Teams    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Startups&quot;,&quot;label&quot;:&quot;ref_cta:Startups;&quot;}\" href=\"/enterprise/startups\">      Startups    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Education&quot;,&quot;label&quot;:&quot;ref_cta:Education;&quot;}\" href=\"https://education.github.com\">      Education    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>          <div class=\"border-bottom pb-3 mb-3\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-by-solution-heading\">By Solution</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-by-solution-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to CI/CD &amp;amp; Automation&quot;,&quot;label&quot;:&quot;ref_cta:CI/CD &amp;amp; Automation;&quot;}\" href=\"/solutions/ci-cd/\">      CI/CD &amp; Automation    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevOps&quot;,&quot;label&quot;:&quot;ref_cta:DevOps;&quot;}\" href=\"/solutions/devops/\">      DevOps    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevSecOps&quot;,&quot;label&quot;:&quot;ref_cta:DevSecOps;&quot;}\" href=\"https://resources.github.com/devops/fundamentals/devsecops/\">      DevSecOps    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>          <div class=\"\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"solutions-resources-heading\">Resources</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"solutions-resources-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Learning Pathways&quot;,&quot;label&quot;:&quot;ref_cta:Learning Pathways;&quot;}\" href=\"https://resources.github.com/learn/pathways/\">      Learning Pathways    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}\" href=\"https://resources.github.com/\">      White papers, Ebooks, Webinars    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}\" href=\"/customer-stories\">      Customer Stories    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" target=\"_blank\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}\" href=\"https://partner.github.com/\">      Partners    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle\">    <path d=\"M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z\"></path></svg></a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">      <button type=\"button\" class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\" aria-expanded=\"false\">        Open Source        <svg opacity=\"0.5\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-chevron-down HeaderMenu-icon ml-1\">    <path d=\"M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z\"></path></svg>      </button>      <div class=\"HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 py-2 py-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 px-lg-4\">          <div class=\"border-bottom pb-3 mb-3\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}\" href=\"/sponsors\">            <div>        <div class=\"color-fg-default h4\">GitHub Sponsors</div>        Fund open source developers      </div>    </a></li>            </ul>          </div>          <div class=\"border-bottom pb-3 mb-3\">            <ul class=\"list-style-none f5\" >                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}\" href=\"/readme\">            <div>        <div class=\"color-fg-default h4\">The ReadME Project</div>        GitHub community articles      </div>    </a></li>            </ul>          </div>          <div class=\"\">              <span class=\"d-block h4 color-fg-default my-1\" id=\"open-source-repositories-heading\">Repositories</span>            <ul class=\"list-style-none f5\" aria-labelledby=\"open-source-repositories-heading\">                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Topics&quot;,&quot;label&quot;:&quot;ref_cta:Topics;&quot;}\" href=\"/topics\">      Topics    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Trending&quot;,&quot;label&quot;:&quot;ref_cta:Trending;&quot;}\" href=\"/trending\">      Trending    </a></li>                <li>  <a class=\"HeaderMenu-dropdown-link lh-condensed d-block no-underline position-relative py-2 Link--secondary\" data-analytics-event=\"{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Collections&quot;,&quot;label&quot;:&quot;ref_cta:Collections;&quot;}\" href=\"/collections\">      Collections    </a></li>            </ul>          </div>      </div></li>                <li class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\">    <a class=\"HeaderMenu-link no-underline px-0 px-lg-2 py-3 py-lg-2 d-block d-lg-inline-block\" data-analytics-event=\"{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}\" href=\"/pricing\">Pricing</a></li>            </ul>          </nav>        <div class=\"d-lg-flex flex-items-center mb-3 mb-lg-0 text-center text-lg-left ml-3\" style=\"\">                <qbsearch-input class=\"search-input\" data-scope=\"repo:huggingface/pytorch-image-models\" data-custom-scopes-path=\"/search/custom_scopes\" data-delete-custom-scopes-csrf=\"zZkuK0g3Ra6llOhMGwF-a5uzjpg0qJfrZM8XrPBYaTnKj2fRzffYZ9xhEPmP4f4KY5Sx22Eoq4Hp-yF7UidFbg\" data-max-custom-scopes=\"10\" data-header-redesign-enabled=\"false\" data-initial-value=\"\" data-blackbird-suggestions-path=\"/search/suggestions\" data-jump-to-suggestions-path=\"/_graphql/GetSuggestedNavigationDestinations\" data-current-repository=\"huggingface/pytorch-image-models\" data-current-org=\"huggingface\" data-current-owner=\"\" data-logged-in=\"false\" data-copilot-chat-enabled=\"false\" data-blackbird-indexed-repo-csrf=\"<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=2RxUtpkaUtL6rwZWL8Wj%2FOKd8KF1FuBqy%2F4P8jNOCs%2FDvmIGsSDndqGgzvualMrVALkgMpA9boV82l0Mi7IwJOJTQWV5nTSnGRtfnArlMOfVJ7bx41z7hlgijc%2BQg%2FplbU6bZdBTIyh%2B1ztmIbY1G4LyDm%2FY%2BOY3it3TCHRaDVgFkbbnNXeKLYnbdSDl9rK2zox0o4wAO2uOtWu%2B1b2%2FQYKl3Bt40vCHvrSKEKVZmxBCrhAA6q81PPPQPjlqi%2BIJ%2FkbVlJX5zs9zidqRML0w3T0Bl2ZK9UzTv7Nzpeb9si%2Fe%2F8mvYXnle%2B%2BrS7CaI6aIb%2Bl8%2FrXDgg0hfhuZsfQDZ%2F1KbYIcP5dp2mc%2BMJWgf%2B8KN7ayUe84rHi21FqAal5jG%2FKcZk%2F3yJsKyfqkpgfxTo34unswrj%2B7MSkulHusLpmP4uCHtPzayx61viK2yGk5a9q4wJAQ0zi3LVbTNE%2FAIkmxjdBHgVkjLEQl2PLfsF5LgxnMVTQ0WkgPT9%2FR%2Bdm9WbYVI2SsBKpuu7UZH4lAKx%2B9Dil89IV%2Fk5D5KNR9zoysOQ%3D%3D--K8SYSiblOTRDwSRj--5gFA%2B%2FvP76VC5gvKswTCfg%3D%3D&quot; />\">  <div    class=\"search-input-container search-with-dialog position-relative d-flex flex-row flex-items-center mr-4 rounded\"    data-action=\"click:qbsearch-input#searchInputContainerClicked\"  >      <button        type=\"button\"        class=\"header-search-button placeholder  input-button form-control d-flex flex-1 flex-self-stretch flex-items-center no-wrap width-full py-0 pl-2 pr-0 text-left border-0 box-shadow-none\"        data-target=\"qbsearch-input.inputButton\"        placeholder=\"Search or jump to...\"        data-hotkey=s,/        autocapitalize=\"off\"        data-action=\"click:qbsearch-input#handleExpand\"      >        <div class=\"mr-2 color-fg-muted\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg>        </div>        <span class=\"flex-1\" data-target=\"qbsearch-input.inputButtonText\">Search or jump to...</span>          <div class=\"d-flex\" data-target=\"qbsearch-input.hotkeyIndicator\">            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"22\" height=\"20\" aria-hidden=\"true\" class=\"mr-1\"><path fill=\"none\" stroke=\"#979A9C\" opacity=\".4\" d=\"M3.5.5h12c1.7 0 3 1.3 3 3v13c0 1.7-1.3 3-3 3h-12c-1.7 0-3-1.3-3-3v-13c0-1.7 1.3-3 3-3z\"></path><path fill=\"#979A9C\" d=\"M11.8 6L8 15.1h-.9L10.8 6h1z\"></path></svg>          </div>      </button>    <input type=\"hidden\" name=\"type\" class=\"js-site-search-type-field\">    <div class=\"Overlay--hidden \" data-modal-dialog-overlay>  <modal-dialog data-action=\"close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose\" data-target=\"qbsearch-input.searchSuggestionsDialog\" role=\"dialog\" id=\"search-suggestions-dialog\" aria-modal=\"true\" aria-labelledby=\"search-suggestions-dialog-header\" data-view-component=\"true\" class=\"Overlay Overlay--width-large Overlay--height-auto\">      <h1 id=\"search-suggestions-dialog-header\" class=\"sr-only\">Search code, repositories, users, issues, pull requests...</h1>    <div class=\"Overlay-body Overlay-body--paddingNone\">                <div data-view-component=\"true\">        <div class=\"search-suggestions position-fixed width-full color-shadow-large border color-fg-default color-bg-default overflow-hidden d-flex flex-column query-builder-container\"          style=\"border-radius: 12px;\"          data-target=\"qbsearch-input.queryBuilderContainer\"          hidden        >          <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"query-builder-test-form\" action=\"\" accept-charset=\"UTF-8\" method=\"get\">  <query-builder data-target=\"qbsearch-input.queryBuilder\" id=\"query-builder-query-builder-test\" data-filter-key=\":\" data-view-component=\"true\" class=\"QueryBuilder search-query-builder\">    <div class=\"FormControl FormControl--fullWidth\">      <label id=\"query-builder-test-label\" for=\"query-builder-test\" class=\"FormControl-label sr-only\">        Search      </label>      <div        class=\"QueryBuilder-StyledInput width-fit \"        data-target=\"query-builder.styledInput\"      >          <span id=\"query-builder-test-leadingvisual-wrap\" class=\"FormControl-input-leadingVisualWrap QueryBuilder-leadingVisualWrap\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search FormControl-input-leadingVisual\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg>          </span>        <div data-target=\"query-builder.styledInputContainer\" class=\"QueryBuilder-StyledInputContainer\">          <div            aria-hidden=\"true\"            class=\"QueryBuilder-StyledInputContent\"            data-target=\"query-builder.styledInputContent\"          ></div>          <div class=\"QueryBuilder-InputWrapper\">            <div aria-hidden=\"true\" class=\"QueryBuilder-Sizer\" data-target=\"query-builder.sizer\"></div>            <input id=\"query-builder-test\" name=\"query-builder-test\" value=\"\" autocomplete=\"off\" type=\"text\" role=\"combobox\" spellcheck=\"false\" aria-expanded=\"false\" aria-describedby=\"validation-10a39e9e-f75d-4cd2-a6bd-c125abe682ea\" data-target=\"query-builder.input\" data-action=\"          input:query-builder#inputChange          blur:query-builder#inputBlur          keydown:query-builder#inputKeydown          focus:query-builder#inputFocus        \" data-view-component=\"true\" class=\"FormControl-input QueryBuilder-Input FormControl-medium\" />          </div>        </div>          <span class=\"sr-only\" id=\"query-builder-test-clear\">Clear</span>          <button role=\"button\" id=\"query-builder-test-clear-button\" aria-labelledby=\"query-builder-test-clear query-builder-test-label\" data-target=\"query-builder.clearButton\" data-action=\"                click:query-builder#clear                focus:query-builder#clearButtonFocus                blur:query-builder#clearButtonBlur              \" variant=\"small\" hidden=\"hidden\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--invisible Button--medium mr-1 px-2 py-0 d-flex flex-items-center rounded-1 color-fg-muted\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x-circle-fill Button-visual\">    <path d=\"M2.343 13.657A8 8 0 1 1 13.658 2.343 8 8 0 0 1 2.343 13.657ZM6.03 4.97a.751.751 0 0 0-1.042.018.751.751 0 0 0-.018 1.042L6.94 8 4.97 9.97a.749.749 0 0 0 .326 1.275.749.749 0 0 0 .734-.215L8 9.06l1.97 1.97a.749.749 0 0 0 1.275-.326.749.749 0 0 0-.215-.734L9.06 8l1.97-1.97a.749.749 0 0 0-.326-1.275.749.749 0 0 0-.734.215L8 6.94Z\"></path></svg></button>      </div>      <template id=\"search-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search\">    <path d=\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\"></path></svg></template><template id=\"code-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg></template><template id=\"file-code-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-file-code\">    <path d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg></template><template id=\"history-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-history\">    <path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></template><template id=\"repo-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo\">    <path d=\"M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z\"></path></svg></template><template id=\"bookmark-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bookmark\">    <path d=\"M3 2.75C3 1.784 3.784 1 4.75 1h6.5c.966 0 1.75.784 1.75 1.75v11.5a.75.75 0 0 1-1.227.579L8 11.722l-3.773 3.107A.751.751 0 0 1 3 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.91l3.023-2.489a.75.75 0 0 1 .954 0l3.023 2.49V2.75a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"plus-circle-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-plus-circle\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm7.25-3.25v2.5h2.5a.75.75 0 0 1 0 1.5h-2.5v2.5a.75.75 0 0 1-1.5 0v-2.5h-2.5a.75.75 0 0 1 0-1.5h2.5v-2.5a.75.75 0 0 1 1.5 0Z\"></path></svg></template><template id=\"circle-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg></template><template id=\"trash-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-trash\">    <path d=\"M11 1.75V3h2.25a.75.75 0 0 1 0 1.5H2.75a.75.75 0 0 1 0-1.5H5V1.75C5 .784 5.784 0 6.75 0h2.5C10.216 0 11 .784 11 1.75ZM4.496 6.675l.66 6.6a.25.25 0 0 0 .249.225h5.19a.25.25 0 0 0 .249-.225l.66-6.6a.75.75 0 0 1 1.492.149l-.66 6.6A1.748 1.748 0 0 1 10.595 15h-5.19a1.75 1.75 0 0 1-1.741-1.575l-.66-6.6a.75.75 0 1 1 1.492-.15ZM6.5 1.75V3h3V1.75a.25.25 0 0 0-.25-.25h-2.5a.25.25 0 0 0-.25.25Z\"></path></svg></template><template id=\"team-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-people\">    <path d=\"M2 5.5a3.5 3.5 0 1 1 5.898 2.549 5.508 5.508 0 0 1 3.034 4.084.75.75 0 1 1-1.482.235 4 4 0 0 0-7.9 0 .75.75 0 0 1-1.482-.236A5.507 5.507 0 0 1 3.102 8.05 3.493 3.493 0 0 1 2 5.5ZM11 4a3.001 3.001 0 0 1 2.22 5.018 5.01 5.01 0 0 1 2.56 3.012.749.749 0 0 1-.885.954.752.752 0 0 1-.549-.514 3.507 3.507 0 0 0-2.522-2.372.75.75 0 0 1-.574-.73v-.352a.75.75 0 0 1 .416-.672A1.5 1.5 0 0 0 11 5.5.75.75 0 0 1 11 4Zm-5.5-.5a2 2 0 1 0-.001 3.999A2 2 0 0 0 5.5 3.5Z\"></path></svg></template><template id=\"project-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-project\">    <path d=\"M1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0ZM1.5 1.75v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25ZM11.75 3a.75.75 0 0 1 .75.75v7.5a.75.75 0 0 1-1.5 0v-7.5a.75.75 0 0 1 .75-.75Zm-8.25.75a.75.75 0 0 1 1.5 0v5.5a.75.75 0 0 1-1.5 0ZM8 3a.75.75 0 0 1 .75.75v3.5a.75.75 0 0 1-1.5 0v-3.5A.75.75 0 0 1 8 3Z\"></path></svg></template><template id=\"pencil-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pencil\">    <path d=\"M11.013 1.427a1.75 1.75 0 0 1 2.474 0l1.086 1.086a1.75 1.75 0 0 1 0 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 0 1-.927-.928l.929-3.25c.081-.286.235-.547.445-.758l8.61-8.61Zm.176 4.823L9.75 4.81l-6.286 6.287a.253.253 0 0 0-.064.108l-.558 1.953 1.953-.558a.253.253 0 0 0 .108-.064Zm1.238-3.763a.25.25 0 0 0-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 0 0 0-.354Z\"></path></svg></template><template id=\"copilot-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copilot\">    <path d=\"M7.998 15.035c-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.201-.508-.254-1.084-.254-1.656 0-.87.128-1.769.693-2.484.579-.733 1.494-1.124 2.724-1.261 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095v1.872c0 .766-3.351 3.795-8.002 3.795Zm0-1.485c2.28 0 4.584-1.11 5.002-1.433V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-1.146 0-2.059-.327-2.71-.991A3.222 3.222 0 0 1 8 6.303a3.24 3.24 0 0 1-.544.743c-.65.664-1.563.991-2.71.991-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433ZM6.762 2.83c-.193-.206-.637-.413-1.682-.297-1.019.113-1.479.404-1.713.7-.247.312-.369.789-.369 1.554 0 .793.129 1.171.308 1.371.162.181.519.379 1.442.379.853 0 1.339-.235 1.638-.54.315-.322.527-.827.617-1.553.117-.935-.037-1.395-.241-1.614Zm4.155-.297c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Z\"></path><path d=\"M6.25 9.037a.75.75 0 0 1 .75.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 .75-.75Zm4.25.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 1.5 0Z\"></path></svg></template><template id=\"workflow-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-workflow\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h3.5C6.216 0 7 .784 7 1.75v3.5A1.75 1.75 0 0 1 5.25 7H4v4a1 1 0 0 0 1 1h4v-1.25C9 9.784 9.784 9 10.75 9h3.5c.966 0 1.75.784 1.75 1.75v3.5A1.75 1.75 0 0 1 14.25 16h-3.5A1.75 1.75 0 0 1 9 14.25v-.75H5A2.5 2.5 0 0 1 2.5 11V7h-.75A1.75 1.75 0 0 1 0 5.25Zm1.75-.25a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Zm9 9a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"book-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-book\">    <path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg></template><template id=\"code-review-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code-review\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 13H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25v-8.5C0 1.784.784 1 1.75 1ZM1.5 2.75v8.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm5.28 1.72a.75.75 0 0 1 0 1.06L5.31 7l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.75.75 0 0 1 1.06 0Zm2.44 0a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L10.69 7 9.22 5.53a.75.75 0 0 1 0-1.06Z\"></path></svg></template><template id=\"codespaces-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-codespaces\">    <path d=\"M0 11.25c0-.966.784-1.75 1.75-1.75h12.5c.966 0 1.75.784 1.75 1.75v3A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm2-9.5C2 .784 2.784 0 3.75 0h8.5C13.216 0 14 .784 14 1.75v5a1.75 1.75 0 0 1-1.75 1.75h-8.5A1.75 1.75 0 0 1 2 6.75Zm1.75-.25a.25.25 0 0 0-.25.25v5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-5a.25.25 0 0 0-.25-.25Zm-2 9.5a.25.25 0 0 0-.25.25v3c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-3a.25.25 0 0 0-.25-.25Z\"></path><path d=\"M7 12.75a.75.75 0 0 1 .75-.75h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z\"></path></svg></template><template id=\"comment-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-comment\">    <path d=\"M1 2.75C1 1.784 1.784 1 2.75 1h10.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 13.25 12H9.06l-2.573 2.573A1.458 1.458 0 0 1 4 13.543V12H2.75A1.75 1.75 0 0 1 1 10.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h4.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg></template><template id=\"comment-discussion-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-comment-discussion\">    <path d=\"M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z\"></path></svg></template><template id=\"organization-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-organization\">    <path d=\"M1.75 16A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0h8.5C11.216 0 12 .784 12 1.75v12.5c0 .085-.006.168-.018.25h2.268a.25.25 0 0 0 .25-.25V8.285a.25.25 0 0 0-.111-.208l-1.055-.703a.749.749 0 1 1 .832-1.248l1.055.703c.487.325.779.871.779 1.456v5.965A1.75 1.75 0 0 1 14.25 16h-3.5a.766.766 0 0 1-.197-.026c-.099.017-.2.026-.303.026h-3a.75.75 0 0 1-.75-.75V14h-1v1.25a.75.75 0 0 1-.75.75Zm-.25-1.75c0 .138.112.25.25.25H4v-1.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 .75.75v1.25h2.25a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM3.75 6h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 3.75A.75.75 0 0 1 3.75 3h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 3.75Zm4 3A.75.75 0 0 1 7.75 6h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 7 6.75ZM7.75 3h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 9.75A.75.75 0 0 1 3.75 9h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 9.75ZM7.75 9h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z\"></path></svg></template><template id=\"rocket-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-rocket\">    <path d=\"M14.064 0h.186C15.216 0 16 .784 16 1.75v.186a8.752 8.752 0 0 1-2.564 6.186l-.458.459c-.314.314-.641.616-.979.904v3.207c0 .608-.315 1.172-.833 1.49l-2.774 1.707a.749.749 0 0 1-1.11-.418l-.954-3.102a1.214 1.214 0 0 1-.145-.125L3.754 9.816a1.218 1.218 0 0 1-.124-.145L.528 8.717a.749.749 0 0 1-.418-1.11l1.71-2.774A1.748 1.748 0 0 1 3.31 4h3.204c.288-.338.59-.665.904-.979l.459-.458A8.749 8.749 0 0 1 14.064 0ZM8.938 3.623h-.002l-.458.458c-.76.76-1.437 1.598-2.02 2.5l-1.5 2.317 2.143 2.143 2.317-1.5c.902-.583 1.74-1.26 2.499-2.02l.459-.458a7.25 7.25 0 0 0 2.123-5.127V1.75a.25.25 0 0 0-.25-.25h-.186a7.249 7.249 0 0 0-5.125 2.123ZM3.56 14.56c-.732.732-2.334 1.045-3.005 1.148a.234.234 0 0 1-.201-.064.234.234 0 0 1-.064-.201c.103-.671.416-2.273 1.15-3.003a1.502 1.502 0 1 1 2.12 2.12Zm6.94-3.935c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 0 0 .119-.213ZM3.678 8.116 5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 0 0-.213.119l-1.2 1.95ZM12 5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg></template><template id=\"shield-check-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield-check\">    <path d=\"m8.533.133 5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667l5.25-1.68a1.748 1.748 0 0 1 1.066 0Zm-.61 1.429.001.001-5.25 1.68a.251.251 0 0 0-.174.237V7c0 1.36.275 2.666 1.057 3.859.784 1.194 2.121 2.342 4.366 3.298a.196.196 0 0 0 .154 0c2.245-.957 3.582-2.103 4.366-3.297C13.225 9.666 13.5 8.358 13.5 7V3.48a.25.25 0 0 0-.174-.238l-5.25-1.68a.25.25 0 0 0-.153 0ZM11.28 6.28l-3.5 3.5a.75.75 0 0 1-1.06 0l-1.5-1.5a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l.97.97 2.97-2.97a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg></template><template id=\"heart-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-heart\">    <path d=\"m8 14.25.345.666a.75.75 0 0 1-.69 0l-.008-.004-.018-.01a7.152 7.152 0 0 1-.31-.17 22.055 22.055 0 0 1-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.066 22.066 0 0 1-3.744 2.584l-.018.01-.006.003h-.002ZM4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.58 20.58 0 0 0 8 13.393a20.58 20.58 0 0 0 3.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.749.749 0 0 1-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5Z\"></path></svg></template><template id=\"server-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-server\">    <path d=\"M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v4c0 .372-.116.717-.314 1 .198.283.314.628.314 1v4a1.75 1.75 0 0 1-1.75 1.75H1.75A1.75 1.75 0 0 1 0 12.75v-4c0-.358.109-.707.314-1a1.739 1.739 0 0 1-.314-1v-4C0 1.784.784 1 1.75 1ZM1.5 2.75v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm.25 5.75a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25ZM7 4.75A.75.75 0 0 1 7.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5A.75.75 0 0 1 7 4.75ZM7.75 10h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM3 4.75A.75.75 0 0 1 3.75 4h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 4.75ZM3.75 10h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z\"></path></svg></template><template id=\"globe-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-globe\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM5.78 8.75a9.64 9.64 0 0 0 1.363 4.177c.255.426.542.832.857 1.215.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a9.927 9.927 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.507 6.507 0 0 0 4.666 5.5c-.123-.181-.24-.365-.352-.552-.715-1.192-1.437-2.874-1.581-4.948Zm-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948.12-.197.237-.381.353-.552a6.507 6.507 0 0 0-4.666 5.5Zm10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948-.12.197-.237.381-.353.552a6.507 6.507 0 0 0 4.666-5.5Zm2.733-1.5a6.507 6.507 0 0 0-4.666-5.5c.123.181.24.365.353.552.714 1.192 1.436 2.874 1.58 4.948Z\"></path></svg></template><template id=\"issue-opened-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg></template><template id=\"device-mobile-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-device-mobile\">    <path d=\"M3.75 0h8.5C13.216 0 14 .784 14 1.75v12.5A1.75 1.75 0 0 1 12.25 16h-8.5A1.75 1.75 0 0 1 2 14.25V1.75C2 .784 2.784 0 3.75 0ZM3.5 1.75v12.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM8 13a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z\"></path></svg></template><template id=\"package-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-package\">    <path d=\"m8.878.392 5.25 3.045c.54.314.872.89.872 1.514v6.098a1.75 1.75 0 0 1-.872 1.514l-5.25 3.045a1.75 1.75 0 0 1-1.756 0l-5.25-3.045A1.75 1.75 0 0 1 1 11.049V4.951c0-.624.332-1.201.872-1.514L7.122.392a1.75 1.75 0 0 1 1.756 0ZM7.875 1.69l-4.63 2.685L8 7.133l4.755-2.758-4.63-2.685a.248.248 0 0 0-.25 0ZM2.5 5.677v5.372c0 .09.047.171.125.216l4.625 2.683V8.432Zm6.25 8.271 4.625-2.683a.25.25 0 0 0 .125-.216V5.677L8.75 8.432Z\"></path></svg></template><template id=\"credit-card-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-credit-card\">    <path d=\"M10.75 9a.75.75 0 0 0 0 1.5h1.5a.75.75 0 0 0 0-1.5h-1.5Z\"></path><path d=\"M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25ZM14.5 6.5h-13v5.75c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25Zm0-2.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25V5h13Z\"></path></svg></template><template id=\"play-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg></template><template id=\"gift-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-gift\">    <path d=\"M2 2.75A2.75 2.75 0 0 1 4.75 0c.983 0 1.873.42 2.57 1.232.268.318.497.668.68 1.042.183-.375.411-.725.68-1.044C9.376.42 10.266 0 11.25 0a2.75 2.75 0 0 1 2.45 4h.55c.966 0 1.75.784 1.75 1.75v2c0 .698-.409 1.301-1 1.582v4.918A1.75 1.75 0 0 1 13.25 16H2.75A1.75 1.75 0 0 1 1 14.25V9.332C.409 9.05 0 8.448 0 7.75v-2C0 4.784.784 4 1.75 4h.55c-.192-.375-.3-.8-.3-1.25ZM7.25 9.5H2.5v4.75c0 .138.112.25.25.25h4.5Zm1.5 0v5h4.5a.25.25 0 0 0 .25-.25V9.5Zm0-4V8h5.5a.25.25 0 0 0 .25-.25v-2a.25.25 0 0 0-.25-.25Zm-7 0a.25.25 0 0 0-.25.25v2c0 .138.112.25.25.25h5.5V5.5h-5.5Zm3-4a1.25 1.25 0 0 0 0 2.5h2.309c-.233-.818-.542-1.401-.878-1.793-.43-.502-.915-.707-1.431-.707ZM8.941 4h2.309a1.25 1.25 0 0 0 0-2.5c-.516 0-1 .205-1.43.707-.337.392-.646.975-.879 1.793Z\"></path></svg></template><template id=\"code-square-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code-square\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25Zm7.47 3.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L10.69 8 9.22 6.53a.75.75 0 0 1 0-1.06ZM6.78 6.53 5.31 8l1.47 1.47a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg></template><template id=\"device-desktop-icon\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-device-desktop\">    <path d=\"M14.25 1c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 14.25 12h-3.727c.099 1.041.52 1.872 1.292 2.757A.752.752 0 0 1 11.25 16h-6.5a.75.75 0 0 1-.565-1.243c.772-.885 1.192-1.716 1.292-2.757H1.75A1.75 1.75 0 0 1 0 10.25v-7.5C0 1.784.784 1 1.75 1ZM1.75 2.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25ZM9.018 12H6.982a5.72 5.72 0 0 1-.765 2.5h3.566a5.72 5.72 0 0 1-.765-2.5Z\"></path></svg></template>        <div class=\"position-relative\">                <ul                  role=\"listbox\"                  class=\"ActionListWrap QueryBuilder-ListWrap\"                  aria-label=\"Suggestions\"                  data-action=\"                    combobox-commit:query-builder#comboboxCommit                    mousedown:query-builder#resultsMousedown                  \"                  data-target=\"query-builder.resultsList\"                  data-persist-list=false                  id=\"query-builder-test-results\"                ></ul>        </div>      <div class=\"FormControl-inlineValidation\" id=\"validation-10a39e9e-f75d-4cd2-a6bd-c125abe682ea\" hidden=\"hidden\">        <span class=\"FormControl-inlineValidation--visual\">          <svg aria-hidden=\"true\" height=\"12\" viewBox=\"0 0 12 12\" version=\"1.1\" width=\"12\" data-view-component=\"true\" class=\"octicon octicon-alert-fill\">    <path d=\"M4.855.708c.5-.896 1.79-.896 2.29 0l4.675 8.351a1.312 1.312 0 0 1-1.146 1.954H1.33A1.313 1.313 0 0 1 .183 9.058ZM7 7V3H5v4Zm-1 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z\"></path></svg>        </span>        <span></span></div>    </div>    <div data-target=\"query-builder.screenReaderFeedback\" aria-live=\"polite\" aria-atomic=\"true\" class=\"sr-only\"></div></query-builder></form>          <div class=\"d-flex flex-row color-fg-muted px-3 text-small color-bg-default search-feedback-prompt\">            <a target=\"_blank\" href=\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\" data-view-component=\"true\" class=\"Link color-fg-accent text-normal ml-2\">              Search syntax tips</a>            <div class=\"d-flex flex-1\"></div>          </div>        </div></div>    </div></modal-dialog></div>  </div>  <div data-action=\"click:qbsearch-input#retract\" class=\"dark-backdrop position-fixed\" hidden data-target=\"qbsearch-input.darkBackdrop\"></div>  <div class=\"color-fg-default\">    <dialog-helper>  <dialog data-target=\"qbsearch-input.feedbackDialog\" data-action=\"close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose\" id=\"feedback-dialog\" aria-modal=\"true\" aria-labelledby=\"feedback-dialog-title\" aria-describedby=\"feedback-dialog-description\" data-view-component=\"true\" class=\"Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade\">    <div data-view-component=\"true\" class=\"Overlay-header\">  <div class=\"Overlay-headerContentWrap\">    <div class=\"Overlay-titleWrap\">      <h1 class=\"Overlay-title \" id=\"feedback-dialog-title\">        Provide feedback      </h1>    </div>    <div class=\"Overlay-actionWrap\">      <button data-close-dialog-id=\"feedback-dialog\" aria-label=\"Close\" type=\"button\" data-view-component=\"true\" class=\"close-button Overlay-closeButton\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button>    </div>  </div></div>      <scrollable-region data-labelled-by=\"feedback-dialog-title\">        <div data-view-component=\"true\" class=\"Overlay-body\">        <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"code-search-feedback-form\" data-turbo=\"false\" action=\"/search/feedback\" accept-charset=\"UTF-8\" method=\"post\"><input type=\"hidden\" data-csrf=\"true\" name=\"authenticity_token\" value=\"tXv8q+XiD97F2IhSg1zG4H2fr91wztPEDdI2G6c67awddaDROG9Xzt8/qesszEWdGVnknc5x/sv03BKTCdqfTg==\" />          <p>We read every piece of feedback, and take your input very seriously.</p>          <textarea name=\"feedback\" class=\"form-control width-full mb-2\" style=\"height: 120px\" id=\"feedback\"></textarea>          <input name=\"include_email\" id=\"include_email\" aria-label=\"Include my email address so I can be contacted\" class=\"form-control mr-2\" type=\"checkbox\">          <label for=\"include_email\" style=\"font-weight: normal\">Include my email address so I can be contacted</label></form></div>      </scrollable-region>      <div data-view-component=\"true\" class=\"Overlay-footer Overlay-footer--alignEnd\">          <button data-close-dialog-id=\"feedback-dialog\" type=\"button\" data-view-component=\"true\" class=\"btn\">    Cancel</button>          <button form=\"code-search-feedback-form\" data-action=\"click:qbsearch-input#submitFeedback\" type=\"submit\" data-view-component=\"true\" class=\"btn-primary btn\">    Submit feedback</button></div></dialog></dialog-helper>    <custom-scopes data-target=\"qbsearch-input.customScopesManager\">    <dialog-helper>  <dialog data-target=\"custom-scopes.customScopesModalDialog\" data-action=\"close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose\" id=\"custom-scopes-dialog\" aria-modal=\"true\" aria-labelledby=\"custom-scopes-dialog-title\" aria-describedby=\"custom-scopes-dialog-description\" data-view-component=\"true\" class=\"Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade\">    <div data-view-component=\"true\" class=\"Overlay-header Overlay-header--divided\">  <div class=\"Overlay-headerContentWrap\">    <div class=\"Overlay-titleWrap\">      <h1 class=\"Overlay-title \" id=\"custom-scopes-dialog-title\">        Saved searches      </h1>        <h2 id=\"custom-scopes-dialog-description\" class=\"Overlay-description\">Use saved searches to filter your results more quickly</h2>    </div>    <div class=\"Overlay-actionWrap\">      <button data-close-dialog-id=\"custom-scopes-dialog\" aria-label=\"Close\" type=\"button\" data-view-component=\"true\" class=\"close-button Overlay-closeButton\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button>    </div>  </div></div>      <scrollable-region data-labelled-by=\"custom-scopes-dialog-title\">        <div data-view-component=\"true\" class=\"Overlay-body\">        <div data-target=\"custom-scopes.customScopesModalDialogFlash\"></div>        <div hidden class=\"create-custom-scope-form\" data-target=\"custom-scopes.createCustomScopeForm\">        <!-- '\"` --><!-- </textarea></xmp> --></option></form><form id=\"custom-scopes-dialog-form\" data-turbo=\"false\" action=\"/search/custom_scopes\" accept-charset=\"UTF-8\" method=\"post\"><input type=\"hidden\" data-csrf=\"true\" name=\"authenticity_token\" value=\"AqSAiQAtI6Vc9Fns+bUqnZU1vK9/wlPoEYaCIr6/DYHCrLKlPGSZnPCp0rF6oDTnn7ICIJnzHdZxaVBmA3Faxg==\" />          <div data-target=\"custom-scopes.customScopesModalDialogFlash\"></div>          <input type=\"hidden\" id=\"custom_scope_id\" name=\"custom_scope_id\" data-target=\"custom-scopes.customScopesIdField\">          <div class=\"form-group\">            <label for=\"custom_scope_name\">Name</label>            <auto-check src=\"/search/custom_scopes/check_name\" required>              <input                type=\"text\"                name=\"custom_scope_name\"                id=\"custom_scope_name\"                data-target=\"custom-scopes.customScopesNameField\"                class=\"form-control\"                autocomplete=\"off\"                placeholder=\"github-ruby\"                required                maxlength=\"50\">              <input type=\"hidden\" data-csrf=\"true\" value=\"ujxh6/k9T12i8joQNeVcwXDn/p5LJCHvz/0Rr95HvHOItOp7PJKbYURaavwapxhaPwka+Mx4N9kANlNQBtqyEg==\" />            </auto-check>          </div>          <div class=\"form-group\">            <label for=\"custom_scope_query\">Query</label>            <input              type=\"text\"              name=\"custom_scope_query\"              id=\"custom_scope_query\"              data-target=\"custom-scopes.customScopesQueryField\"              class=\"form-control\"              autocomplete=\"off\"              placeholder=\"(repo:mona/a OR repo:mona/b) AND lang:python\"              required              maxlength=\"500\">          </div>          <p class=\"text-small color-fg-muted\">            To see all available qualifiers, see our <a class=\"Link--inTextBlock\" href=\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\">documentation</a>.          </p></form>        </div>        <div data-target=\"custom-scopes.manageCustomScopesForm\">          <div data-target=\"custom-scopes.list\"></div>        </div></div>      </scrollable-region>      <div data-view-component=\"true\" class=\"Overlay-footer Overlay-footer--alignEnd Overlay-footer--divided\">          <button data-action=\"click:custom-scopes#customScopesCancel\" type=\"button\" data-view-component=\"true\" class=\"btn\">    Cancel</button>          <button form=\"custom-scopes-dialog-form\" data-action=\"click:custom-scopes#customScopesSubmit\" data-target=\"custom-scopes.customScopesSubmitButton\" type=\"submit\" data-view-component=\"true\" class=\"btn-primary btn\">    Create saved search</button></div></dialog></dialog-helper>    </custom-scopes>  </div></qbsearch-input><input type=\"hidden\" data-csrf=\"true\" class=\"js-data-jump-to-suggestions-path-csrf\" value=\"LH+5WeAkPyJRzrscXUAJr0b7AsM3cEwRGnbp7zD+5J07MH2YVRiZ7E/3OxX3ugOAm8rmYJAbdb46wJ8zQuFzlA==\" />          <div class=\"position-relative mr-lg-3 d-lg-inline-block\">            <a href=\"/login?return_to=https%3A%2F%2Fgithub.com%2Fhuggingface%2Fpytorch-image-models\"              class=\"HeaderMenu-link HeaderMenu-link--sign-in flex-shrink-0 no-underline d-block d-lg-inline-block border border-lg-0 rounded rounded-lg-0 p-2 p-lg-0\"              data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/huggingface/pytorch-image-models&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"f1957a6a3dd8668fce3eee055123d2da65f519d99bdc5d9b59fd01ed9f4d3040\"              data-ga-click=\"(Logged out) Header, clicked Sign in, text:sign-in\">              Sign in            </a>          </div>            <a href=\"/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=huggingface%2Fpytorch-image-models\"              class=\"HeaderMenu-link HeaderMenu-link--sign-up flex-shrink-0 d-none d-lg-inline-block no-underline border color-border-default rounded px-2 py-1\"              data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/huggingface/pytorch-image-models&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"f1957a6a3dd8668fce3eee055123d2da65f519d99bdc5d9b59fd01ed9f4d3040\"              data-analytics-event=\"{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/&lt;user-name&gt;/&lt;repo-name&gt;;ref_cta:Sign up;ref_loc:header logged out&quot;}\"            >              Sign up            </a>        </div>      </div>    </div>  </div></header>      <div hidden=\"hidden\" data-view-component=\"true\" class=\"js-stale-session-flash stale-session-flash flash flash-warn flash-full mb-3\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        <span class=\"js-stale-session-flash-signed-in\" hidden>You signed in with another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>        <span class=\"js-stale-session-flash-signed-out\" hidden>You signed out in another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>        <span class=\"js-stale-session-flash-switched\" hidden>You switched accounts on another tab or window. <a class=\"Link--inTextBlock\" href=\"\">Reload</a> to refresh your session.</span>    <button id=\"icon-button-8888b4d3-0380-45af-8552-5f2ce2961ecf\" aria-labelledby=\"tooltip-e56e7f67-d47f-4215-b6fe-06b50aaa7823\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--invisible Button--medium flash-close js-flash-close\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x Button-visual\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg></button><tool-tip id=\"tooltip-e56e7f67-d47f-4215-b6fe-06b50aaa7823\" for=\"icon-button-8888b4d3-0380-45af-8552-5f2ce2961ecf\" popover=\"manual\" data-direction=\"s\" data-type=\"label\" data-view-component=\"true\" class=\"sr-only position-absolute\">Dismiss alert</tool-tip>  </div>    </div>  <div id=\"start-of-content\" class=\"show-on-focus\"></div>    <div id=\"js-flash-container\" data-turbo-replace>  <template class=\"js-flash-template\">    <div class=\"flash flash-full   {{ className }}\">  <div class=\"px-2\" >    <button autofocus class=\"flash-close js-flash-close\" type=\"button\" aria-label=\"Dismiss this message\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>    </button>    <div aria-atomic=\"true\" role=\"alert\" class=\"js-flash-alert\">            <div>{{ message }}</div>    </div>  </div></div>  </template></div>        <include-fragment class=\"js-notification-shelf-include-fragment\" data-base-src=\"https://github.com/notifications/beta/shelf\"></include-fragment>  <div    class=\"application-main \"    data-commit-hovercards-enabled    data-discussion-hovercards-enabled    data-issue-and-pr-hovercards-enabled  >        <div itemscope itemtype=\"http://schema.org/SoftwareSourceCode\" class=\"\">    <main id=\"js-repo-pjax-container\" >                        <div id=\"repository-container-header\"  class=\"pt-3 hide-full-screen\" style=\"background-color: var(--page-header-bgColor, var(--color-page-header-bg));\" data-turbo-replace>      <div class=\"d-flex flex-wrap flex-justify-end mb-3  px-3 px-md-4 px-lg-5\" style=\"gap: 1rem;\">        <div class=\"flex-auto min-width-0 width-fit mr-3\">              <div class=\" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo color-fg-muted mr-2\">    <path d=\"M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z\"></path></svg>        <span class=\"author flex-self-stretch\" itemprop=\"author\">      <a class=\"url fn\" rel=\"author\" data-hovercard-type=\"organization\" data-hovercard-url=\"/orgs/huggingface/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"/huggingface\">        huggingface</a>    </span>    <span class=\"mx-1 flex-self-stretch color-fg-muted\">/</span>    <strong itemprop=\"name\" class=\"mr-2 flex-self-stretch\">      <a data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" href=\"/huggingface/pytorch-image-models\">pytorch-image-models</a>    </strong>    <span></span><span class=\"Label Label--secondary v-align-middle mr-1\">Public</span>  </div>        </div>        <div id=\"repository-details-container\" data-turbo-replace>            <ul class=\"pagehead-actions flex-shrink-0 d-none d-md-inline\" style=\"padding: 2px 0;\">            <li>          <include-fragment src=\"/huggingface/pytorch-image-models/sponsor_button\"></include-fragment>        </li>        <li>            <a href=\"/login?return_to=%2Fhuggingface%2Fpytorch-image-models\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/huggingface/pytorch-image-models&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"113a8dd6ebd5ab9d66c16414d1c2df7e1d1ae722e78931f7cb3f6c427d18f6db\" aria-label=\"You must be signed in to change notification settings\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bell mr-2\">    <path d=\"M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z\"></path></svg>Notifications</a>  </li>  <li>          <a icon=\"repo-forked\" id=\"fork-button\" href=\"/login?return_to=%2Fhuggingface%2Fpytorch-image-models\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:168799526,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/huggingface/pytorch-image-models&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"792720146959bc3f2d3bb85c8be02de1d64bbc0fb2ca9eb5e3dad7698f92fb9c\" data-view-component=\"true\" class=\"btn-sm btn\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-2\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>Fork    <span id=\"repo-network-counter\" data-pjax-replace=\"true\" data-turbo-replace=\"true\" title=\"4,509\" data-view-component=\"true\" class=\"Counter\">4.5k</span></a>  </li>  <li>        <div data-view-component=\"true\" class=\"BtnGroup d-flex\">        <a href=\"/login?return_to=%2Fhuggingface%2Fpytorch-image-models\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:168799526,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/huggingface/pytorch-image-models&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"76077feafe2ba57e99aa897b39ce2dbcc638d71dc331f276e3b79e8f2a8332a1\" aria-label=\"You must be signed in to star a repository\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn BtnGroup-item\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star v-align-text-bottom d-inline-block mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg><span data-view-component=\"true\" class=\"d-inline\">          Star</span>          <span id=\"repo-stars-counter-star\" aria-label=\"28964 users starred this repository\" data-singular-suffix=\"user starred this repository\" data-plural-suffix=\"users starred this repository\" data-turbo-replace=\"true\" title=\"28,964\" data-view-component=\"true\" class=\"Counter js-social-count\">29k</span></a>        <button aria-label=\"You must be signed in to add this repository to a list\" type=\"button\" disabled=\"disabled\" data-view-component=\"true\" class=\"btn-sm btn BtnGroup-item px-2\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-triangle-down\">    <path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></button></div>  </li>    <li>            </li></ul>        </div>      </div>        <div id=\"responsive-meta-container\" data-turbo-replace>      <div class=\"d-block d-md-none mb-2 px-3 px-md-4 px-lg-5\">      <p class=\"f4 mb-3 \">        PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more      </p>      <div class=\"mb-2 d-flex flex-items-center Link--secondary\">        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link flex-shrink-0 mr-2\">    <path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg>        <span class=\"flex-auto min-width-0 css-truncate css-truncate-target width-fit\">          <a title=\"https://huggingface.co/docs/timm\" role=\"link\" target=\"_blank\" class=\"text-bold\" rel=\"noopener noreferrer\" href=\"https://huggingface.co/docs/timm\">huggingface.co/docs/timm</a>        </span>      </div>          <h3 class=\"sr-only\">License</h3>  <div class=\"mb-2\">    <a href=\"/huggingface/pytorch-image-models/blob/main/LICENSE\"      class=\"Link--muted\"            data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}\"    >      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-law mr-2\">    <path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg>     Apache-2.0 license    </a>  </div>    <div class=\"mb-3\">        <a class=\"Link--secondary no-underline mr-3\" href=\"/huggingface/pytorch-image-models/stargazers\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star mr-1\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg>          <span class=\"text-bold\">29k</span>          stars</a>        <a class=\"Link--secondary no-underline mr-3\" href=\"/huggingface/pytorch-image-models/forks\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-1\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>          <span class=\"text-bold\">4.5k</span>          forks</a>          <a class=\"Link--secondary no-underline mr-3 d-inline-block\" href=\"/huggingface/pytorch-image-models/branches\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-branch mr-1\">    <path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg>            <span>Branches</span></a>          <a class=\"Link--secondary no-underline d-inline-block\" href=\"/huggingface/pytorch-image-models/tags\">            <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-tag mr-1\">    <path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg>            <span>Tags</span></a>        <a class=\"Link--secondary no-underline d-inline-block\" href=\"/huggingface/pytorch-image-models/activity\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pulse mr-1\">    <path d=\"M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z\"></path></svg>          <span>Activity</span></a>    </div>      <div class=\"d-flex flex-wrap gap-2\">        <div class=\"flex-1\">            <div data-view-component=\"true\" class=\"BtnGroup d-flex\">        <a href=\"/login?return_to=%2Fhuggingface%2Fpytorch-image-models\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:168799526,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/huggingface/pytorch-image-models&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"76077feafe2ba57e99aa897b39ce2dbcc638d71dc331f276e3b79e8f2a8332a1\" aria-label=\"You must be signed in to star a repository\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn btn-block BtnGroup-item\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star v-align-text-bottom d-inline-block mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg><span data-view-component=\"true\" class=\"d-inline\">          Star</span></a>        <button aria-label=\"You must be signed in to add this repository to a list\" type=\"button\" disabled=\"disabled\" data-view-component=\"true\" class=\"btn-sm btn BtnGroup-item px-2\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-triangle-down\">    <path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></button></div>        </div>        <div class=\"flex-1\">                <a href=\"/login?return_to=%2Fhuggingface%2Fpytorch-image-models\" rel=\"nofollow\" data-hydro-click=\"{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/huggingface/pytorch-image-models&quot;,&quot;user_id&quot;:null}}\" data-hydro-click-hmac=\"113a8dd6ebd5ab9d66c16414d1c2df7e1d1ae722e78931f7cb3f6c427d18f6db\" aria-label=\"You must be signed in to change notification settings\" data-view-component=\"true\" class=\"tooltipped tooltipped-s btn-sm btn btn-block\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bell mr-2\">    <path d=\"M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z\"></path></svg>Notifications</a>        </div>          <span>                      </span>      </div>  </div></div>          <nav data-pjax=\"#js-repo-pjax-container\" aria-label=\"Repository\" data-view-component=\"true\" class=\"js-repo-nav js-sidenav-container-pjax js-responsive-underlinenav overflow-hidden UnderlineNav px-3 px-md-4 px-lg-5\">  <ul data-view-component=\"true\" class=\"UnderlineNav-body list-style-none\">      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"code-tab\" href=\"/huggingface/pytorch-image-models\" data-tab-item=\"i0code-tab\" data-selected-links=\"repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments repo_attestations /huggingface/pytorch-image-models\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g c\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" aria-current=\"page\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item selected\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg>        <span data-content=\"Code\">Code</span>          <span id=\"code-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"issues-tab\" href=\"/huggingface/pytorch-image-models/issues\" data-tab-item=\"i1issues-tab\" data-selected-links=\"repo_issues repo_labels repo_milestones /huggingface/pytorch-image-models/issues\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g i\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg>        <span data-content=\"Issues\">Issues</span>          <span id=\"issues-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"71\" data-view-component=\"true\" class=\"Counter\">71</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"pull-requests-tab\" href=\"/huggingface/pytorch-image-models/pulls\" data-tab-item=\"i2pull-requests-tab\" data-selected-links=\"repo_pulls checks /huggingface/pytorch-image-models/pulls\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g p\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-pull-request UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z\"></path></svg>        <span data-content=\"Pull requests\">Pull requests</span>          <span id=\"pull-requests-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"24\" data-view-component=\"true\" class=\"Counter\">24</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"discussions-tab\" href=\"/huggingface/pytorch-image-models/discussions\" data-tab-item=\"i3discussions-tab\" data-selected-links=\"repo_discussions /huggingface/pytorch-image-models/discussions\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g g\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Discussions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-comment-discussion UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z\"></path></svg>        <span data-content=\"Discussions\">Discussions</span>          <span id=\"discussions-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"actions-tab\" href=\"/huggingface/pytorch-image-models/actions\" data-tab-item=\"i4actions-tab\" data-selected-links=\"repo_actions /huggingface/pytorch-image-models/actions\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g a\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg>        <span data-content=\"Actions\">Actions</span>          <span id=\"actions-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"projects-tab\" href=\"/huggingface/pytorch-image-models/projects\" data-tab-item=\"i5projects-tab\" data-selected-links=\"repo_projects new_repo_project repo_project /huggingface/pytorch-image-models/projects\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g b\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-table UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z\"></path></svg>        <span data-content=\"Projects\">Projects</span>          <span id=\"projects-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"0\" hidden=\"hidden\" data-view-component=\"true\" class=\"Counter\">0</span>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"security-tab\" href=\"/huggingface/pytorch-image-models/security\" data-tab-item=\"i6security-tab\" data-selected-links=\"security overview alerts policy token_scanning code_scanning /huggingface/pytorch-image-models/security\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-hotkey=\"g s\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        <span data-content=\"Security\">Security</span>          <include-fragment src=\"/huggingface/pytorch-image-models/security/overall-count\" accept=\"text/fragment+html\"></include-fragment>    </a></li>      <li data-view-component=\"true\" class=\"d-inline-flex\">  <a id=\"insights-tab\" href=\"/huggingface/pytorch-image-models/pulse\" data-tab-item=\"i7insights-tab\" data-selected-links=\"repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /huggingface/pytorch-image-models/pulse\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" data-analytics-event=\"{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}\" data-view-component=\"true\" class=\"UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item\">                  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-graph UnderlineNav-octicon d-none d-sm-inline\">    <path d=\"M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg>        <span data-content=\"Insights\">Insights</span>          <span id=\"insights-repo-tab-count\" data-pjax-replace=\"\" data-turbo-replace=\"\" title=\"Not available\" data-view-component=\"true\" class=\"Counter\"></span>    </a></li></ul>    <div style=\"visibility:hidden;\" data-view-component=\"true\" class=\"UnderlineNav-actions js-responsive-underlinenav-overflow position-absolute pr-3 pr-md-4 pr-lg-5 right-0\">      <action-menu data-select-variant=\"none\" data-view-component=\"true\">  <focus-group direction=\"vertical\" mnemonics retain>    <button id=\"action-menu-44fd914e-2f97-43ac-addd-c4d6591538b4-button\" popovertarget=\"action-menu-44fd914e-2f97-43ac-addd-c4d6591538b4-overlay\" aria-controls=\"action-menu-44fd914e-2f97-43ac-addd-c4d6591538b4-list\" aria-haspopup=\"true\" aria-labelledby=\"tooltip-7b9ad0b9-2178-440d-b738-31534bdd0eff\" type=\"button\" data-view-component=\"true\" class=\"Button Button--iconOnly Button--secondary Button--medium UnderlineNav-item\">  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-kebab-horizontal Button-visual\">    <path d=\"M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path></svg></button><tool-tip id=\"tooltip-7b9ad0b9-2178-440d-b738-31534bdd0eff\" for=\"action-menu-44fd914e-2f97-43ac-addd-c4d6591538b4-button\" popover=\"manual\" data-direction=\"s\" data-type=\"label\" data-view-component=\"true\" class=\"sr-only position-absolute\">Additional navigation options</tool-tip><anchored-position id=\"action-menu-44fd914e-2f97-43ac-addd-c4d6591538b4-overlay\" anchor=\"action-menu-44fd914e-2f97-43ac-addd-c4d6591538b4-button\" align=\"start\" side=\"outside-bottom\" anchor-offset=\"normal\" popover=\"auto\" data-view-component=\"true\">  <div data-view-component=\"true\" class=\"Overlay Overlay--size-auto\">          <div data-view-component=\"true\" class=\"Overlay-body Overlay-body--paddingNone\">          <div data-view-component=\"true\">  <ul aria-labelledby=\"action-menu-44fd914e-2f97-43ac-addd-c4d6591538b4-button\" id=\"action-menu-44fd914e-2f97-43ac-addd-c4d6591538b4-list\" role=\"menu\" data-view-component=\"true\" class=\"ActionListWrap--inset ActionListWrap\">      <li hidden=\"hidden\" data-menu-item=\"i0code-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-8a7b1758-3af0-44be-8450-761db6284876\" href=\"/huggingface/pytorch-image-models\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-code\">    <path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Code</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i1issues-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-4783575f-7469-4f33-8d97-4614e2865bee\" href=\"/huggingface/pytorch-image-models/issues\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-issue-opened\">    <path d=\"M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path><path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Issues</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i2pull-requests-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-3a9cc23d-f043-41e6-9e0c-9ee5e0d57408\" href=\"/huggingface/pytorch-image-models/pulls\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-git-pull-request\">    <path d=\"M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Pull requests</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i3discussions-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-b914f3aa-f972-487a-acd7-80761cc2f937\" href=\"/huggingface/pytorch-image-models/discussions\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-comment-discussion\">    <path d=\"M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Discussions</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i4actions-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-24082835-7610-40d4-a998-dd21d7e19eef\" href=\"/huggingface/pytorch-image-models/actions\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-play\">    <path d=\"M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Actions</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i5projects-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-13d0c74c-1a13-4841-8ffd-d346073fb97d\" href=\"/huggingface/pytorch-image-models/projects\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-table\">    <path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Projects</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i6security-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-7f12b65d-c44f-4cde-9606-54015e4f3d04\" href=\"/huggingface/pytorch-image-models/security\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-shield\">    <path d=\"M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Security</span></a>    </li>      <li hidden=\"hidden\" data-menu-item=\"i7insights-tab\" data-targets=\"action-list.items action-list.items\" role=\"none\" data-view-component=\"true\" class=\"ActionListItem\">        <a tabindex=\"-1\" id=\"item-2552e73c-b807-4ddf-8cbc-0fa6816e8cde\" href=\"/huggingface/pytorch-image-models/pulse\" role=\"menuitem\" data-view-component=\"true\" class=\"ActionListContent ActionListContent--visual16\">        <span class=\"ActionListItem-visual ActionListItem-visual--leading\">          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-graph\">    <path d=\"M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z\"></path></svg>        </span>              <span data-view-component=\"true\" class=\"ActionListItem-label\">          Insights</span></a>    </li></ul>  </div></div>      </div></anchored-position>  </focus-group></action-menu></div></nav>  </div>  <turbo-frame id=\"repo-content-turbo-frame\" target=\"_top\" data-turbo-action=\"advance\" class=\"\">    <div id=\"repo-content-pjax-container\" class=\"repository-content \" >                <h1 class='sr-only'>huggingface/pytorch-image-models</h1>  <div class=\"clearfix container-xl px-md-4 px-lg-5 px-3\">    <div>  <div id=\"spoof-warning\" class=\"mt-0 pb-3\" hidden aria-hidden>  <div data-view-component=\"true\" class=\"flash flash-warn mt-0 clearfix\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert float-left mt-1\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>      <div class=\"overflow-hidden\">This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.</div>  </div></div>  <include-fragment src=\"/huggingface/pytorch-image-models/spoofed_commit_check/6e6f3686a7e06bcba37bbd3b7c755f04a516a1e7\" data-test-selector=\"spoofed-commit-check\"></include-fragment>  <div style=\"max-width: 100%\" data-view-component=\"true\" class=\"Layout Layout--flowRow-until-md react-repos-overview-margin Layout--sidebarPosition-end Layout--sidebarPosition-flowRow-end\">  <div data-view-component=\"true\" class=\"Layout-main\">        <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/react-lib-1fbfc5be2c18.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_octicons-react_dist_index_esm_js-node_modules_primer_react_lib-es-2e8e7c-adc8451a70cf.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Box_Box_js-8f8c5e2a2cbf.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Button_Button_js-67fe00b5266a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_ActionList_index_js-2dd4d13d3ae6.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Overlay_Overlay_js-node_modules_primer_react_lib-es-fa1130-829932cf63db.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Text_Text_js-node_modules_primer_react_lib-esm_Text-85a14b-236dc9716ad0.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_ActionMenu_ActionMenu_js-eaf74522e470.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_react-router-dom_dist_index_js-3b41341d50fe.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_Dialog_js-node_modules_primer_react_lib-esm_Label_L-857e1c-77794958a54a.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_UnderlineNav_index_js-89fa5806aa3c.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_primer_react_lib-esm_AvatarStack_AvatarStack_js-node_modules_primer_reac-e445e7-175b51e43dcc.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_react-core_create-browser-history_ts-ui_packages_react-core_AppContextProvider_ts-809ab9-bf008735d0bb.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_paths_index_ts-7137b25aa38b.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_ref-selector_RefSelector_tsx-dbbdef4348e2.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/ui_packages_commit-attribution_index_ts-ui_packages_commit-checks-status_index_ts-ui_packages-ffbe33-4c4ddf7d268d.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/app_assets_modules_react-code-view_components_directory_DirectoryContent_index_ts-app_assets_-1fd1f5-c96303590595.js\"></script><script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/repos-overview-523b8f59ec33.js\"></script><react-partial  partial-name=\"repos-overview\"  data-ssr=\"true\">    <script type=\"application/json\" data-target=\"react-partial.embeddedData\">{\"props\":{\"initialPayload\":{\"allShortcutsEnabled\":false,\"path\":\"/\",\"repo\":{\"id\":168799526,\"defaultBranch\":\"main\",\"name\":\"pytorch-image-models\",\"ownerLogin\":\"huggingface\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2019-02-02T05:51:12.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/25720743?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":true},\"currentUser\":null,\"refInfo\":{\"name\":\"main\",\"listCacheKey\":\"v0:1708371321.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"6e6f3686a7e06bcba37bbd3b7c755f04a516a1e7\"},\"tree\":{\"items\":[{\"name\":\".github\",\"path\":\".github\",\"contentType\":\"directory\"},{\"name\":\"convert\",\"path\":\"convert\",\"contentType\":\"directory\"},{\"name\":\"docs\",\"path\":\"docs\",\"contentType\":\"directory\"},{\"name\":\"hfdocs\",\"path\":\"hfdocs\",\"contentType\":\"directory\"},{\"name\":\"results\",\"path\":\"results\",\"contentType\":\"directory\"},{\"name\":\"tests\",\"path\":\"tests\",\"contentType\":\"directory\"},{\"name\":\"timm\",\"path\":\"timm\",\"contentType\":\"directory\"},{\"name\":\".gitattributes\",\"path\":\".gitattributes\",\"contentType\":\"file\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\"CONTRIBUTING.md\",\"path\":\"CONTRIBUTING.md\",\"contentType\":\"file\"},{\"name\":\"LICENSE\",\"path\":\"LICENSE\",\"contentType\":\"file\"},{\"name\":\"MANIFEST.in\",\"path\":\"MANIFEST.in\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"avg_checkpoints.py\",\"path\":\"avg_checkpoints.py\",\"contentType\":\"file\"},{\"name\":\"benchmark.py\",\"path\":\"benchmark.py\",\"contentType\":\"file\"},{\"name\":\"bulk_runner.py\",\"path\":\"bulk_runner.py\",\"contentType\":\"file\"},{\"name\":\"clean_checkpoint.py\",\"path\":\"clean_checkpoint.py\",\"contentType\":\"file\"},{\"name\":\"distributed_train.sh\",\"path\":\"distributed_train.sh\",\"contentType\":\"file\"},{\"name\":\"hubconf.py\",\"path\":\"hubconf.py\",\"contentType\":\"file\"},{\"name\":\"inference.py\",\"path\":\"inference.py\",\"contentType\":\"file\"},{\"name\":\"mkdocs.yml\",\"path\":\"mkdocs.yml\",\"contentType\":\"file\"},{\"name\":\"model-index.yml\",\"path\":\"model-index.yml\",\"contentType\":\"file\"},{\"name\":\"onnx_export.py\",\"path\":\"onnx_export.py\",\"contentType\":\"file\"},{\"name\":\"onnx_validate.py\",\"path\":\"onnx_validate.py\",\"contentType\":\"file\"},{\"name\":\"pyproject.toml\",\"path\":\"pyproject.toml\",\"contentType\":\"file\"},{\"name\":\"requirements-dev.txt\",\"path\":\"requirements-dev.txt\",\"contentType\":\"file\"},{\"name\":\"requirements.txt\",\"path\":\"requirements.txt\",\"contentType\":\"file\"},{\"name\":\"setup.cfg\",\"path\":\"setup.cfg\",\"contentType\":\"file\"},{\"name\":\"train.py\",\"path\":\"train.py\",\"contentType\":\"file\"},{\"name\":\"validate.py\",\"path\":\"validate.py\",\"contentType\":\"file\"}],\"templateDirectorySuggestionUrl\":null,\"readme\":null,\"totalCount\":30,\"showBranchInfobar\":false},\"fileTree\":null,\"fileTreeProcessingTime\":null,\"foldersToFetch\":[],\"treeExpanded\":false,\"symbolsExpanded\":false,\"isOverview\":true,\"overview\":{\"banners\":{\"shouldRecommendReadme\":false,\"isPersonalRepo\":false,\"showUseActionBanner\":false,\"actionSlug\":null,\"actionId\":null,\"showProtectBranchBanner\":false,\"recentlyTouchedDataChannel\":null,\"publishBannersInfo\":{\"dismissActionNoticePath\":\"/settings/dismiss-notice/publish_action_from_repo\",\"releasePath\":\"/huggingface/pytorch-image-models/releases/new?marketplace=true\",\"showPublishActionBanner\":false},\"interactionLimitBanner\":null,\"showInvitationBanner\":false,\"inviterName\":null},\"codeButton\":{\"contactPath\":\"/contact\",\"isEnterprise\":false,\"local\":{\"protocolInfo\":{\"httpAvailable\":true,\"sshAvailable\":null,\"httpUrl\":\"https://github.com/huggingface/pytorch-image-models.git\",\"showCloneWarning\":null,\"sshUrl\":null,\"sshCertificatesRequired\":null,\"sshCertificatesAvailable\":null,\"ghCliUrl\":\"gh repo clone huggingface/pytorch-image-models\",\"defaultProtocol\":\"http\",\"newSshKeyUrl\":\"/settings/ssh/new\",\"setProtocolPath\":\"/users/set_protocol\"},\"platformInfo\":{\"cloneUrl\":\"https://desktop.github.com\",\"showVisualStudioCloneButton\":false,\"visualStudioCloneUrl\":\"https://windows.github.com\",\"showXcodeCloneButton\":false,\"xcodeCloneUrl\":\"https://developer.apple.com\",\"zipballUrl\":\"/huggingface/pytorch-image-models/archive/refs/heads/main.zip\"}},\"newCodespacePath\":\"/codespaces/new?hide_repo_select=true\\u0026repo=168799526\"},\"popovers\":{\"rename\":null,\"renamedParentRepo\":null},\"commitCount\":\"2,172\",\"overviewFiles\":[{\"displayName\":\"README.md\",\"repoName\":\"pytorch-image-models\",\"refName\":\"main\",\"path\":\"README.md\",\"preferredFileType\":\"readme\",\"tabName\":\"README\",\"richText\":\"\\u003carticle class=\\\"markdown-body entry-content container-lg\\\" itemprop=\\\"text\\\"\\u003e\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch1 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003ePyTorch Image Models\\u003c/h1\\u003e\\u003ca id=\\\"user-content-pytorch-image-models\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: PyTorch Image Models\\\" href=\\\"#pytorch-image-models\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#whats-new\\\"\\u003eWhat's New\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#introduction\\\"\\u003eIntroduction\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#models\\\"\\u003eModels\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#features\\\"\\u003eFeatures\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#results\\\"\\u003eResults\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#getting-started-documentation\\\"\\u003eGetting Started (Documentation)\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#train-validation-inference-scripts\\\"\\u003eTrain, Validation, Inference Scripts\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#awesome-pytorch-resources\\\"\\u003eAwesome PyTorch Resources\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#licenses\\\"\\u003eLicenses\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"#citing\\\"\\u003eCiting\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eWhat's New\\u003c/h2\\u003e\\u003ca id=\\\"user-content-whats-new\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: What's New\\\" href=\\\"#whats-new\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\u2757Updates after Oct 10, 2022 are available in version \\u0026gt;= 0.9\u2757\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eMany changes since the last 0.6.x stable releases. They were previewed in 0.8.x dev releases but not everyone transitioned.\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003etimm.models.layers\\u003c/code\\u003e moved to \\u003ccode\\u003etimm.layers\\u003c/code\\u003e:\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003efrom timm.models.layers import name\\u003c/code\\u003e will still work via deprecation mapping (but please transition to \\u003ccode\\u003etimm.layers\\u003c/code\\u003e).\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eimport timm.models.layers.module\\u003c/code\\u003e or \\u003ccode\\u003efrom timm.models.layers.module import name\\u003c/code\\u003e needs to be changed now.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eBuilder, helper, non-model modules in \\u003ccode\\u003etimm.models\\u003c/code\\u003e have a \\u003ccode\\u003e_\\u003c/code\\u003e prefix added, ie \\u003ccode\\u003etimm.models.helpers\\u003c/code\\u003e -\\u0026gt; \\u003ccode\\u003etimm.models._helpers\\u003c/code\\u003e, there are temporary deprecation mapping files but those will be removed.\\u003c/li\\u003e\\n\\u003cli\\u003eAll models now support \\u003ccode\\u003earchitecture.pretrained_tag\\u003c/code\\u003e naming (ex \\u003ccode\\u003eresnet50.rsb_a1\\u003c/code\\u003e).\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eThe pretrained_tag is the specific weight variant (different head) for the architecture.\\u003c/li\\u003e\\n\\u003cli\\u003eUsing only \\u003ccode\\u003earchitecture\\u003c/code\\u003e defaults to the first weights in the default_cfgs for that model architecture.\\u003c/li\\u003e\\n\\u003cli\\u003eIn adding pretrained tags, many model names that existed to differentiate were renamed to use the tag  (ex: \\u003ccode\\u003evit_base_patch16_224_in21k\\u003c/code\\u003e -\\u0026gt; \\u003ccode\\u003evit_base_patch16_224.augreg_in21k\\u003c/code\\u003e). There are deprecation mappings for these.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eA number of models had their checkpoints remaped to match architecture changes needed to better support \\u003ccode\\u003efeatures_only=True\\u003c/code\\u003e, there are \\u003ccode\\u003echeckpoint_filter_fn\\u003c/code\\u003e methods in any model module that was remapped. These can be passed to \\u003ccode\\u003etimm.models.load_checkpoint(..., filter_fn=timm.models.swin_transformer_v2.checkpoint_filter_fn)\\u003c/code\\u003e to remap your existing checkpoint.\\u003c/li\\u003e\\n\\u003cli\\u003eThe Hugging Face Hub (\\u003ca href=\\\"https://huggingface.co/timm\\\" rel=\\\"nofollow\\\"\\u003ehttps://huggingface.co/timm\\u003c/a\\u003e) is now the primary source for \\u003ccode\\u003etimm\\u003c/code\\u003e weights. Model cards include link to papers, original source, license.\\u003c/li\\u003e\\n\\u003cli\\u003ePrevious 0.6.x can be cloned from \\u003ca href=\\\"https://github.com/rwightman/pytorch-image-models/tree/0.6.x\\\"\\u003e0.6.x\\u003c/a\\u003e branch or installed via pip with version.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFeb 19, 2024\\u003c/h3\\u003e\\u003ca id=\\\"user-content-feb-19-2024\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Feb 19, 2024\\\" href=\\\"#feb-19-2024\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eNext-ViT models added. Adapted from \\u003ca href=\\\"https://github.com/bytedance/Next-ViT\\\"\\u003ehttps://github.com/bytedance/Next-ViT\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eHGNet and PP-HGNetV2 models added. Adapted from \\u003ca href=\\\"https://github.com/PaddlePaddle/PaddleClas\\\"\\u003ehttps://github.com/PaddlePaddle/PaddleClas\\u003c/a\\u003e by \\u003ca href=\\\"https://github.com/seefun\\\"\\u003eSeeFun\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eRemoved setup.py, moved to pyproject.toml based build supported by PDM\\u003c/li\\u003e\\n\\u003cli\\u003eAdd updated model EMA impl using _for_each for less overhead\\u003c/li\\u003e\\n\\u003cli\\u003eSupport device args in train script for non GPU devices\\u003c/li\\u003e\\n\\u003cli\\u003eOther misc fixes and small additions\\u003c/li\\u003e\\n\\u003cli\\u003eMin supported Python version increased to 3.8\\u003c/li\\u003e\\n\\u003cli\\u003eRelease 0.9.16\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eJan 8, 2024\\u003c/h3\\u003e\\u003ca id=\\\"user-content-jan-8-2024\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Jan 8, 2024\\\" href=\\\"#jan-8-2024\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eDatasets \\u0026amp; transform refactoring\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eHuggingFace streaming (iterable) dataset support (\\u003ccode\\u003e--dataset hfids:org/dataset\\u003c/code\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eWebdataset wrapper tweaks for improved split info fetching, can auto fetch splits from supported HF hub webdataset\\u003c/li\\u003e\\n\\u003cli\\u003eTested HF \\u003ccode\\u003edatasets\\u003c/code\\u003e and webdataset wrapper streaming from HF hub with recent \\u003ccode\\u003etimm\\u003c/code\\u003e ImageNet uploads to \\u003ca href=\\\"https://huggingface.co/timm\\\" rel=\\\"nofollow\\\"\\u003ehttps://huggingface.co/timm\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMake input \\u0026amp; target column/field keys consistent across datasets and pass via args\\u003c/li\\u003e\\n\\u003cli\\u003eFull monochrome support when using e:g: \\u003ccode\\u003e--input-size 1 224 224\\u003c/code\\u003e or \\u003ccode\\u003e--in-chans 1\\u003c/code\\u003e, sets PIL image conversion appropriately in dataset\\u003c/li\\u003e\\n\\u003cli\\u003eImproved several alternate crop \\u0026amp; resize transforms (ResizeKeepRatio, RandomCropOrPad, etc) for use in PixParse document AI project\\u003c/li\\u003e\\n\\u003cli\\u003eAdd SimCLR style color jitter prob along with grayscale and gaussian blur options to augmentations and args\\u003c/li\\u003e\\n\\u003cli\\u003eAllow train without validation set (\\u003ccode\\u003e--val-split ''\\u003c/code\\u003e) in train script\\u003c/li\\u003e\\n\\u003cli\\u003eAdd \\u003ccode\\u003e--bce-sum\\u003c/code\\u003e (sum over class dim) and \\u003ccode\\u003e--bce-pos-weight\\u003c/code\\u003e (positive weighting) args for training as they're common BCE loss tweaks I was often hard coding\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eNov 23, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-nov-23-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Nov 23, 2023\\\" href=\\\"#nov-23-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdded EfficientViT-Large models, thanks \\u003ca href=\\\"https://github.com/seefun\\\"\\u003eSeeFun\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eFix Python 3.7 compat, will be dropping support for it soon\\u003c/li\\u003e\\n\\u003cli\\u003eOther misc fixes\\u003c/li\\u003e\\n\\u003cli\\u003eRelease 0.9.12\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eNov 20, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-nov-20-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Nov 20, 2023\\\" href=\\\"#nov-20-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdded significant flexibility for Hugging Face Hub based timm models via \\u003ccode\\u003emodel_args\\u003c/code\\u003e config entry. \\u003ccode\\u003emodel_args\\u003c/code\\u003e will be passed as kwargs through to models on creation.\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eSee example at \\u003ca href=\\\"https://huggingface.co/gaunernst/vit_base_patch16_1024_128.audiomae_as2m_ft_as20k/blob/main/config.json\\\" rel=\\\"nofollow\\\"\\u003ehttps://huggingface.co/gaunernst/vit_base_patch16_1024_128.audiomae_as2m_ft_as20k/blob/main/config.json\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eUsage: \\u003ca class=\\\"issue-link js-issue-link\\\" data-error-text=\\\"Failed to load title\\\" data-id=\\\"5862092\\\" data-permission-text=\\\"Title is private\\\" data-url=\\\"https://github.com/huggingface/pytorch-image-models/discussions/2035\\\" data-hovercard-type=\\\"discussion\\\" data-hovercard-url=\\\"/huggingface/pytorch-image-models/discussions/2035/hovercard\\\" href=\\\"https://github.com/huggingface/pytorch-image-models/discussions/2035\\\"\\u003e#2035\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eUpdated imagenet eval and test set csv files with latest models\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003evision_transformer.py\\u003c/code\\u003e typing and doc cleanup by \\u003ca href=\\\"https://github.com/Laurent2916\\\"\\u003eLaure\u03b7t\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e0.9.11 release\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eNov 3, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-nov-3-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Nov 3, 2023\\\" href=\\\"#nov-3-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://huggingface.co/papers/2309.17425\\\" rel=\\\"nofollow\\\"\\u003eDFN (Data Filtering Networks)\\u003c/a\\u003e and \\u003ca href=\\\"https://huggingface.co/papers/2309.16671\\\" rel=\\\"nofollow\\\"\\u003eMetaCLIP\\u003c/a\\u003e ViT weights added\\u003c/li\\u003e\\n\\u003cli\\u003eDINOv2 'register' ViT model weights added (\\u003ca href=\\\"https://huggingface.co/papers/2309.16588\\\" rel=\\\"nofollow\\\"\\u003ehttps://huggingface.co/papers/2309.16588\\u003c/a\\u003e, \\u003ca href=\\\"https://huggingface.co/papers/2304.07193\\\" rel=\\\"nofollow\\\"\\u003ehttps://huggingface.co/papers/2304.07193\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eAdd \\u003ccode\\u003equickgelu\\u003c/code\\u003e ViT variants for OpenAI, DFN, MetaCLIP weights that use it (less efficient)\\u003c/li\\u003e\\n\\u003cli\\u003eImproved typing added to ResNet, MobileNet-v3 thanks to \\u003ca href=\\\"https://github.com/a-r-r-o-w\\\"\\u003eAryan\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eImageNet-12k fine-tuned (from LAION-2B CLIP) \\u003ccode\\u003econvnext_xxlarge\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e0.9.9 release\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eOct 20, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-oct-20-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Oct 20, 2023\\\" href=\\\"#oct-20-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://huggingface.co/papers/2303.15343\\\" rel=\\\"nofollow\\\"\\u003eSigLIP\\u003c/a\\u003e image tower weights supported in \\u003ccode\\u003evision_transformer.py\\u003c/code\\u003e.\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eGreat potential for fine-tune and downstream feature use.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eExperimental 'register' support in vit models as per \\u003ca href=\\\"https://huggingface.co/papers/2309.16588\\\" rel=\\\"nofollow\\\"\\u003eVision Transformers Need Registers\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eUpdated RepViT with new weight release. Thanks \\u003ca href=\\\"https://github.com/jameslahm\\\"\\u003ewangao\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eAdd patch resizing support (on pretrained weight load) to Swin models\\u003c/li\\u003e\\n\\u003cli\\u003e0.9.8 release pending\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eSep 1, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-sep-1-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Sep 1, 2023\\\" href=\\\"#sep-1-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eTinyViT added by \\u003ca href=\\\"https://github.com/seefun\\\"\\u003eSeeFun\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eFix EfficientViT (MIT) to use torch.autocast so it works back to PT 1.10\\u003c/li\\u003e\\n\\u003cli\\u003e0.9.7 release\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAug 28, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-aug-28-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Aug 28, 2023\\\" href=\\\"#aug-28-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdd dynamic img size support to models in \\u003ccode\\u003evision_transformer.py\\u003c/code\\u003e, \\u003ccode\\u003evision_transformer_hybrid.py\\u003c/code\\u003e, \\u003ccode\\u003edeit.py\\u003c/code\\u003e, and \\u003ccode\\u003eeva.py\\u003c/code\\u003e w/o breaking backward compat.\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdd \\u003ccode\\u003edynamic_img_size=True\\u003c/code\\u003e to args at model creation time to allow changing the grid size (interpolate abs and/or ROPE pos embed each forward pass).\\u003c/li\\u003e\\n\\u003cli\\u003eAdd \\u003ccode\\u003edynamic_img_pad=True\\u003c/code\\u003e to allow image sizes that aren't divisible by patch size (pad bottom right to patch size each forward pass).\\u003c/li\\u003e\\n\\u003cli\\u003eEnabling either dynamic mode will break FX tracing unless PatchEmbed module added as leaf.\\u003c/li\\u003e\\n\\u003cli\\u003eExisting method of resizing position embedding by passing different \\u003ccode\\u003eimg_size\\u003c/code\\u003e (interpolate pretrained embed weights once) on creation still works.\\u003c/li\\u003e\\n\\u003cli\\u003eExisting method of changing \\u003ccode\\u003epatch_size\\u003c/code\\u003e (resize pretrained patch_embed weights once) on creation still works.\\u003c/li\\u003e\\n\\u003cli\\u003eExample validation cmd \\u003ccode\\u003epython validate.py /imagenet --model vit_base_patch16_224 --amp --amp-dtype bfloat16 --img-size 255 --crop-pct 1.0 --model-kwargs dynamic_img_size=True dyamic_img_pad=True\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAug 25, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-aug-25-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Aug 25, 2023\\\" href=\\\"#aug-25-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eMany new models since last release\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eFastViT - \\u003ca href=\\\"https://arxiv.org/abs/2303.14189\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2303.14189\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMobileOne - \\u003ca href=\\\"https://arxiv.org/abs/2206.04040\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2206.04040\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eInceptionNeXt - \\u003ca href=\\\"https://arxiv.org/abs/2303.16900\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2303.16900\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eRepGhostNet - \\u003ca href=\\\"https://arxiv.org/abs/2211.06088\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2211.06088\\u003c/a\\u003e (thanks \\u003ca href=\\\"https://github.com/ChengpengChen\\\"\\u003ehttps://github.com/ChengpengChen\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eGhostNetV2 - \\u003ca href=\\\"https://arxiv.org/abs/2211.12905\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2211.12905\\u003c/a\\u003e (thanks \\u003ca href=\\\"https://github.com/yehuitang\\\"\\u003ehttps://github.com/yehuitang\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientViT (MSRA) - \\u003ca href=\\\"https://arxiv.org/abs/2305.07027\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2305.07027\\u003c/a\\u003e (thanks \\u003ca href=\\\"https://github.com/seefun\\\"\\u003ehttps://github.com/seefun\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientViT (MIT) - \\u003ca href=\\\"https://arxiv.org/abs/2205.14756\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2205.14756\\u003c/a\\u003e (thanks \\u003ca href=\\\"https://github.com/seefun\\\"\\u003ehttps://github.com/seefun\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eAdd \\u003ccode\\u003e--reparam\\u003c/code\\u003e arg to \\u003ccode\\u003ebenchmark.py\\u003c/code\\u003e, \\u003ccode\\u003eonnx_export.py\\u003c/code\\u003e, and \\u003ccode\\u003evalidate.py\\u003c/code\\u003e to trigger layer reparameterization / fusion for models with any one of \\u003ccode\\u003ereparameterize()\\u003c/code\\u003e, \\u003ccode\\u003eswitch_to_deploy()\\u003c/code\\u003e or \\u003ccode\\u003efuse()\\u003c/code\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eIncluding FastViT, MobileOne, RepGhostNet, EfficientViT (MSRA), RepViT, RepVGG, and LeViT\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003ePreparing 0.9.6 'back to school' release\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAug 11, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-aug-11-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Aug 11, 2023\\\" href=\\\"#aug-11-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eSwin, MaxViT, CoAtNet, and BEiT models support resizing of image/window size on creation with adaptation of pretrained weights\\u003c/li\\u003e\\n\\u003cli\\u003eExample validation cmd to test w/ non-square resize \\u003ccode\\u003epython validate.py /imagenet --model swin_base_patch4_window7_224.ms_in22k_ft_in1k --amp --amp-dtype bfloat16 --input-size 3 256 320 --model-kwargs window_size=8,10 img_size=256,320\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAug 3, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-aug-3-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Aug 3, 2023\\\" href=\\\"#aug-3-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdd GluonCV weights for HRNet w18_small and w18_small_v2. Converted by \\u003ca href=\\\"https://github.com/seefun\\\"\\u003eSeeFun\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eFix \\u003ccode\\u003eselecsls*\\u003c/code\\u003e model naming regression\\u003c/li\\u003e\\n\\u003cli\\u003ePatch and position embedding for ViT/EVA works for bfloat16/float16 weights on load (or activations for on-the-fly resize)\\u003c/li\\u003e\\n\\u003cli\\u003ev0.9.5 release prep\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eJuly 27, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-july-27-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: July 27, 2023\\\" href=\\\"#july-27-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdded timm trained \\u003ccode\\u003eseresnextaa201d_32x8d.sw_in12k_ft_in1k_384\\u003c/code\\u003e weights (and \\u003ccode\\u003e.sw_in12k\\u003c/code\\u003e pretrain) with 87.3% top-1 on ImageNet-1k, best ImageNet ResNet family model I'm aware of.\\u003c/li\\u003e\\n\\u003cli\\u003eRepViT model and weights (\\u003ca href=\\\"https://arxiv.org/abs/2307.09283\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2307.09283\\u003c/a\\u003e) added by \\u003ca href=\\\"https://github.com/jameslahm\\\"\\u003ewangao\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eI-JEPA ViT feature weights (no classifier) added by \\u003ca href=\\\"https://github.com/seefun\\\"\\u003eSeeFun\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSAM-ViT (segment anything) feature weights (no classifier) added by \\u003ca href=\\\"https://github.com/seefun\\\"\\u003eSeeFun\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eAdd support for alternative feat extraction methods and -ve indices to EfficientNet\\u003c/li\\u003e\\n\\u003cli\\u003eAdd NAdamW optimizer\\u003c/li\\u003e\\n\\u003cli\\u003eMisc fixes\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eMay 11, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-may-11-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: May 11, 2023\\\" href=\\\"#may-11-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003etimm\\u003c/code\\u003e 0.9 released, transition from 0.8.xdev releases\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eMay 10, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-may-10-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: May 10, 2023\\\" href=\\\"#may-10-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eHugging Face Hub downloading is now default, 1132 models on \\u003ca href=\\\"https://huggingface.co/timm\\\" rel=\\\"nofollow\\\"\\u003ehttps://huggingface.co/timm\\u003c/a\\u003e, 1163 weights in \\u003ccode\\u003etimm\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eDINOv2 vit feature backbone weights added thanks to \\u003ca href=\\\"https://github.com/leng-yue\\\"\\u003eLeng Yue\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eFB MAE vit feature backbone weights added\\u003c/li\\u003e\\n\\u003cli\\u003eOpenCLIP DataComp-XL L/14 feat backbone weights added\\u003c/li\\u003e\\n\\u003cli\\u003eMetaFormer (poolformer-v2, caformer, convformer, updated poolformer (v1)) w/ weights added by \\u003ca href=\\\"https://github.com/fffffgggg54\\\"\\u003eFredo Guan\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eExperimental \\u003ccode\\u003eget_intermediate_layers\\u003c/code\\u003e function on vit/deit models for grabbing hidden states (inspired by DINO impl). This is WIP and may change significantly... feedback welcome.\\u003c/li\\u003e\\n\\u003cli\\u003eModel creation throws error if \\u003ccode\\u003epretrained=True\\u003c/code\\u003e and no weights exist (instead of continuing with random initialization)\\u003c/li\\u003e\\n\\u003cli\\u003eFix regression with inception / nasnet TF sourced weights with 1001 classes in original classifiers\\u003c/li\\u003e\\n\\u003cli\\u003ebitsandbytes (\\u003ca href=\\\"https://github.com/TimDettmers/bitsandbytes\\\"\\u003ehttps://github.com/TimDettmers/bitsandbytes\\u003c/a\\u003e) optimizers added to factory, use \\u003ccode\\u003ebnb\\u003c/code\\u003e prefix, ie \\u003ccode\\u003ebnbadam8bit\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMisc cleanup and fixes\\u003c/li\\u003e\\n\\u003cli\\u003eFinal testing before switching to a 0.9 and bringing \\u003ccode\\u003etimm\\u003c/code\\u003e out of pre-release state\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eApril 27, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-april-27-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: April 27, 2023\\\" href=\\\"#april-27-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e97% of \\u003ccode\\u003etimm\\u003c/code\\u003e models uploaded to HF Hub and almost all updated to support multi-weight pretrained configs\\u003c/li\\u003e\\n\\u003cli\\u003eMinor cleanup and refactoring of another batch of models as multi-weight added. More fused_attn (F.sdpa) and features_only support, and torchscript fixes.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eApril 21, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-april-21-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: April 21, 2023\\\" href=\\\"#april-21-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eGradient accumulation support added to train script and tested (\\u003ccode\\u003e--grad-accum-steps\\u003c/code\\u003e), thanks \\u003ca href=\\\"https://github.com/voidbag\\\"\\u003eTaeksang Kim\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMore weights on HF Hub (cspnet, cait, volo, xcit, tresnet, hardcorenas, densenet, dpn, vovnet, xception_aligned)\\u003c/li\\u003e\\n\\u003cli\\u003eAdded \\u003ccode\\u003e--head-init-scale\\u003c/code\\u003e and \\u003ccode\\u003e--head-init-bias\\u003c/code\\u003e to train.py to scale classiifer head and set fixed bias for fine-tune\\u003c/li\\u003e\\n\\u003cli\\u003eRemove all InplaceABN (\\u003ccode\\u003einplace_abn\\u003c/code\\u003e) use, replaced use in tresnet with standard BatchNorm (modified weights accordingly).\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eApril 12, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-april-12-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: April 12, 2023\\\" href=\\\"#april-12-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdd ONNX export script, validate script, helpers that I've had kicking around for along time. Tweak 'same' padding for better export w/ recent ONNX + pytorch.\\u003c/li\\u003e\\n\\u003cli\\u003eRefactor dropout args for vit and vit-like models, separate drop_rate into \\u003ccode\\u003edrop_rate\\u003c/code\\u003e (classifier dropout), \\u003ccode\\u003eproj_drop_rate\\u003c/code\\u003e (block mlp / out projections), \\u003ccode\\u003epos_drop_rate\\u003c/code\\u003e (position embedding drop), \\u003ccode\\u003eattn_drop_rate\\u003c/code\\u003e (attention dropout). Also add patch dropout (FLIP) to vit and eva models.\\u003c/li\\u003e\\n\\u003cli\\u003efused F.scaled_dot_product_attention support to more vit models, add env var (TIMM_FUSED_ATTN) to control, and config interface to enable/disable\\u003c/li\\u003e\\n\\u003cli\\u003eAdd EVA-CLIP backbones w/ image tower weights, all the way up to 4B param 'enormous' model, and 336x336 OpenAI ViT mode that was missed.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eApril 5, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-april-5-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: April 5, 2023\\\" href=\\\"#april-5-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eALL ResNet models pushed to Hugging Face Hub with multi-weight support\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAll past \\u003ccode\\u003etimm\\u003c/code\\u003e trained weights added with recipe based tags to differentiate\\u003c/li\\u003e\\n\\u003cli\\u003eAll ResNet strikes back A1/A2/A3 (seed 0) and R50 example B/C1/C2/D weights available\\u003c/li\\u003e\\n\\u003cli\\u003eAdd torchvision v2 recipe weights to existing torchvision originals\\u003c/li\\u003e\\n\\u003cli\\u003eSee comparison table in \\u003ca href=\\\"https://huggingface.co/timm/seresnextaa101d_32x8d.sw_in12k_ft_in1k_288#model-comparison\\\" rel=\\\"nofollow\\\"\\u003ehttps://huggingface.co/timm/seresnextaa101d_32x8d.sw_in12k_ft_in1k_288#model-comparison\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eNew ImageNet-12k + ImageNet-1k fine-tunes available for a few anti-aliased ResNet models\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnetaa50d.sw_in12k_ft_in1k\\u003c/code\\u003e - 81.7 @ 224, 82.6 @ 288\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eresnetaa101d.sw_in12k_ft_in1k\\u003c/code\\u003e - 83.5 @ 224, 84.1 @ 288\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eseresnextaa101d_32x8d.sw_in12k_ft_in1k\\u003c/code\\u003e - 86.0 @ 224, 86.5 @ 288\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eseresnextaa101d_32x8d.sw_in12k_ft_in1k_288\\u003c/code\\u003e - 86.5 @ 288, 86.7 @ 320\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eMarch 31, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-march-31-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: March 31, 2023\\\" href=\\\"#march-31-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdd first ConvNext-XXLarge CLIP -\\u0026gt; IN-1k fine-tune and IN-12k intermediate fine-tunes for convnext-base/large CLIP models.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003ctable\\u003e\\n\\u003cthead\\u003e\\n\\u003ctr\\u003e\\n\\u003cth\\u003emodel\\u003c/th\\u003e\\n\\u003cth\\u003etop1\\u003c/th\\u003e\\n\\u003cth\\u003etop5\\u003c/th\\u003e\\n\\u003cth\\u003eimg_size\\u003c/th\\u003e\\n\\u003cth\\u003eparam_count\\u003c/th\\u003e\\n\\u003cth\\u003egmacs\\u003c/th\\u003e\\n\\u003cth\\u003emacts\\u003c/th\\u003e\\n\\u003c/tr\\u003e\\n\\u003c/thead\\u003e\\n\\u003ctbody\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://huggingface.co/timm/convnext_xxlarge.clip_laion2b_soup_ft_in1k\\\" rel=\\\"nofollow\\\"\\u003econvnext_xxlarge.clip_laion2b_soup_ft_in1k\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e88.612\\u003c/td\\u003e\\n\\u003ctd\\u003e98.704\\u003c/td\\u003e\\n\\u003ctd\\u003e256\\u003c/td\\u003e\\n\\u003ctd\\u003e846.47\\u003c/td\\u003e\\n\\u003ctd\\u003e198.09\\u003c/td\\u003e\\n\\u003ctd\\u003e124.45\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003econvnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384\\u003c/td\\u003e\\n\\u003ctd\\u003e88.312\\u003c/td\\u003e\\n\\u003ctd\\u003e98.578\\u003c/td\\u003e\\n\\u003ctd\\u003e384\\u003c/td\\u003e\\n\\u003ctd\\u003e200.13\\u003c/td\\u003e\\n\\u003ctd\\u003e101.11\\u003c/td\\u003e\\n\\u003ctd\\u003e126.74\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003econvnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320\\u003c/td\\u003e\\n\\u003ctd\\u003e87.968\\u003c/td\\u003e\\n\\u003ctd\\u003e98.47\\u003c/td\\u003e\\n\\u003ctd\\u003e320\\u003c/td\\u003e\\n\\u003ctd\\u003e200.13\\u003c/td\\u003e\\n\\u003ctd\\u003e70.21\\u003c/td\\u003e\\n\\u003ctd\\u003e88.02\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003econvnext_base.clip_laion2b_augreg_ft_in12k_in1k_384\\u003c/td\\u003e\\n\\u003ctd\\u003e87.138\\u003c/td\\u003e\\n\\u003ctd\\u003e98.212\\u003c/td\\u003e\\n\\u003ctd\\u003e384\\u003c/td\\u003e\\n\\u003ctd\\u003e88.59\\u003c/td\\u003e\\n\\u003ctd\\u003e45.21\\u003c/td\\u003e\\n\\u003ctd\\u003e84.49\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003econvnext_base.clip_laion2b_augreg_ft_in12k_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e86.344\\u003c/td\\u003e\\n\\u003ctd\\u003e97.97\\u003c/td\\u003e\\n\\u003ctd\\u003e256\\u003c/td\\u003e\\n\\u003ctd\\u003e88.59\\u003c/td\\u003e\\n\\u003ctd\\u003e20.09\\u003c/td\\u003e\\n\\u003ctd\\u003e37.55\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003c/tbody\\u003e\\n\\u003c/table\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdd EVA-02 MIM pretrained and fine-tuned weights, push to HF hub and update model cards for all EVA models. First model over 90% top-1 (99% top-5)! Check out the original code \\u0026amp; weights at \\u003ca href=\\\"https://github.com/baaivision/EVA\\\"\\u003ehttps://github.com/baaivision/EVA\\u003c/a\\u003e for more details on their work blending MIM, CLIP w/ many model, dataset, and train recipe tweaks.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003ctable\\u003e\\n\\u003cthead\\u003e\\n\\u003ctr\\u003e\\n\\u003cth\\u003emodel\\u003c/th\\u003e\\n\\u003cth\\u003etop1\\u003c/th\\u003e\\n\\u003cth\\u003etop5\\u003c/th\\u003e\\n\\u003cth\\u003eparam_count\\u003c/th\\u003e\\n\\u003cth\\u003eimg_size\\u003c/th\\u003e\\n\\u003c/tr\\u003e\\n\\u003c/thead\\u003e\\n\\u003ctbody\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003e\\u003ca href=\\\"https://huggingface.co/timm/eva02_large_patch14_448.mim_m38m_ft_in1k\\\" rel=\\\"nofollow\\\"\\u003eeva02_large_patch14_448.mim_m38m_ft_in22k_in1k\\u003c/a\\u003e\\u003c/td\\u003e\\n\\u003ctd\\u003e90.054\\u003c/td\\u003e\\n\\u003ctd\\u003e99.042\\u003c/td\\u003e\\n\\u003ctd\\u003e305.08\\u003c/td\\u003e\\n\\u003ctd\\u003e448\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva02_large_patch14_448.mim_in22k_ft_in22k_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e89.946\\u003c/td\\u003e\\n\\u003ctd\\u003e99.01\\u003c/td\\u003e\\n\\u003ctd\\u003e305.08\\u003c/td\\u003e\\n\\u003ctd\\u003e448\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva_giant_patch14_560.m30m_ft_in22k_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e89.792\\u003c/td\\u003e\\n\\u003ctd\\u003e98.992\\u003c/td\\u003e\\n\\u003ctd\\u003e1014.45\\u003c/td\\u003e\\n\\u003ctd\\u003e560\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva02_large_patch14_448.mim_in22k_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e89.626\\u003c/td\\u003e\\n\\u003ctd\\u003e98.954\\u003c/td\\u003e\\n\\u003ctd\\u003e305.08\\u003c/td\\u003e\\n\\u003ctd\\u003e448\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva02_large_patch14_448.mim_m38m_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e89.57\\u003c/td\\u003e\\n\\u003ctd\\u003e98.918\\u003c/td\\u003e\\n\\u003ctd\\u003e305.08\\u003c/td\\u003e\\n\\u003ctd\\u003e448\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva_giant_patch14_336.m30m_ft_in22k_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e89.56\\u003c/td\\u003e\\n\\u003ctd\\u003e98.956\\u003c/td\\u003e\\n\\u003ctd\\u003e1013.01\\u003c/td\\u003e\\n\\u003ctd\\u003e336\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva_giant_patch14_336.clip_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e89.466\\u003c/td\\u003e\\n\\u003ctd\\u003e98.82\\u003c/td\\u003e\\n\\u003ctd\\u003e1013.01\\u003c/td\\u003e\\n\\u003ctd\\u003e336\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva_large_patch14_336.in22k_ft_in22k_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e89.214\\u003c/td\\u003e\\n\\u003ctd\\u003e98.854\\u003c/td\\u003e\\n\\u003ctd\\u003e304.53\\u003c/td\\u003e\\n\\u003ctd\\u003e336\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva_giant_patch14_224.clip_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e88.882\\u003c/td\\u003e\\n\\u003ctd\\u003e98.678\\u003c/td\\u003e\\n\\u003ctd\\u003e1012.56\\u003c/td\\u003e\\n\\u003ctd\\u003e224\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva02_base_patch14_448.mim_in22k_ft_in22k_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e88.692\\u003c/td\\u003e\\n\\u003ctd\\u003e98.722\\u003c/td\\u003e\\n\\u003ctd\\u003e87.12\\u003c/td\\u003e\\n\\u003ctd\\u003e448\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva_large_patch14_336.in22k_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e88.652\\u003c/td\\u003e\\n\\u003ctd\\u003e98.722\\u003c/td\\u003e\\n\\u003ctd\\u003e304.53\\u003c/td\\u003e\\n\\u003ctd\\u003e336\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva_large_patch14_196.in22k_ft_in22k_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e88.592\\u003c/td\\u003e\\n\\u003ctd\\u003e98.656\\u003c/td\\u003e\\n\\u003ctd\\u003e304.14\\u003c/td\\u003e\\n\\u003ctd\\u003e196\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva02_base_patch14_448.mim_in22k_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e88.23\\u003c/td\\u003e\\n\\u003ctd\\u003e98.564\\u003c/td\\u003e\\n\\u003ctd\\u003e87.12\\u003c/td\\u003e\\n\\u003ctd\\u003e448\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva_large_patch14_196.in22k_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e87.934\\u003c/td\\u003e\\n\\u003ctd\\u003e98.504\\u003c/td\\u003e\\n\\u003ctd\\u003e304.14\\u003c/td\\u003e\\n\\u003ctd\\u003e196\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva02_small_patch14_336.mim_in22k_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e85.74\\u003c/td\\u003e\\n\\u003ctd\\u003e97.614\\u003c/td\\u003e\\n\\u003ctd\\u003e22.13\\u003c/td\\u003e\\n\\u003ctd\\u003e336\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003ctr\\u003e\\n\\u003ctd\\u003eeva02_tiny_patch14_336.mim_in22k_ft_in1k\\u003c/td\\u003e\\n\\u003ctd\\u003e80.658\\u003c/td\\u003e\\n\\u003ctd\\u003e95.524\\u003c/td\\u003e\\n\\u003ctd\\u003e5.76\\u003c/td\\u003e\\n\\u003ctd\\u003e336\\u003c/td\\u003e\\n\\u003c/tr\\u003e\\n\\u003c/tbody\\u003e\\n\\u003c/table\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eMulti-weight and HF hub for DeiT and MLP-Mixer based models\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eMarch 22, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-march-22-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: March 22, 2023\\\" href=\\\"#march-22-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eMore weights pushed to HF hub along with multi-weight support, including: \\u003ccode\\u003eregnet.py\\u003c/code\\u003e, \\u003ccode\\u003erexnet.py\\u003c/code\\u003e, \\u003ccode\\u003ebyobnet.py\\u003c/code\\u003e, \\u003ccode\\u003eresnetv2.py\\u003c/code\\u003e, \\u003ccode\\u003eswin_transformer.py\\u003c/code\\u003e, \\u003ccode\\u003eswin_transformer_v2.py\\u003c/code\\u003e, \\u003ccode\\u003eswin_transformer_v2_cr.py\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSwin Transformer models support feature extraction (NCHW feat maps for \\u003ccode\\u003eswinv2_cr_*\\u003c/code\\u003e, and NHWC for all others) and spatial embedding outputs.\\u003c/li\\u003e\\n\\u003cli\\u003eFocalNet (from \\u003ca href=\\\"https://github.com/microsoft/FocalNet\\\"\\u003ehttps://github.com/microsoft/FocalNet\\u003c/a\\u003e) models and weights added with significant refactoring, feature extraction, no fixed resolution / sizing constraint\\u003c/li\\u003e\\n\\u003cli\\u003eRegNet weights increased with HF hub push, SWAG, SEER, and torchvision v2 weights. SEER is pretty poor wrt to performance for model size, but possibly useful.\\u003c/li\\u003e\\n\\u003cli\\u003eMore ImageNet-12k pretrained and 1k fine-tuned \\u003ccode\\u003etimm\\u003c/code\\u003e weights:\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003erexnetr_200.sw_in12k_ft_in1k\\u003c/code\\u003e - 82.6 @ 224, 83.2 @ 288\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003erexnetr_300.sw_in12k_ft_in1k\\u003c/code\\u003e - 84.0 @ 224, 84.5 @ 288\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eregnety_120.sw_in12k_ft_in1k\\u003c/code\\u003e - 85.0 @ 224, 85.4 @ 288\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eregnety_160.lion_in12k_ft_in1k\\u003c/code\\u003e - 85.6 @ 224, 86.0 @ 288\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eregnety_160.sw_in12k_ft_in1k\\u003c/code\\u003e - 85.6 @ 224, 86.0 @ 288  (compare to SWAG PT + 1k FT this is same BUT much lower res, blows SEER FT away)\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eModel name deprecation + remapping functionality added (a milestone for bringing 0.8.x out of pre-release). Mappings being added...\\u003c/li\\u003e\\n\\u003cli\\u003eMinor bug fixes and improvements.\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFeb 26, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-feb-26-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Feb 26, 2023\\\" href=\\\"#feb-26-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdd ConvNeXt-XXLarge CLIP pretrained image tower weights for fine-tune \\u0026amp; features (fine-tuning TBD) -- see \\u003ca href=\\\"https://huggingface.co/laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-soup\\\" rel=\\\"nofollow\\\"\\u003emodel card\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eUpdate \\u003ccode\\u003econvnext_xxlarge\\u003c/code\\u003e default LayerNorm eps to 1e-5 (for CLIP weights, improved stability)\\u003c/li\\u003e\\n\\u003cli\\u003e0.8.15dev0\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFeb 20, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-feb-20-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Feb 20, 2023\\\" href=\\\"#feb-20-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAdd 320x320 \\u003ccode\\u003econvnext_large_mlp.clip_laion2b_ft_320\\u003c/code\\u003e and \\u003ccode\\u003econvnext_lage_mlp.clip_laion2b_ft_soup_320\\u003c/code\\u003e CLIP image tower weights for features \\u0026amp; fine-tune\\u003c/li\\u003e\\n\\u003cli\\u003e0.8.13dev0 pypi release for latest changes w/ move to huggingface org\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFeb 16, 2023\\u003c/h3\\u003e\\u003ca id=\\\"user-content-feb-16-2023\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Feb 16, 2023\\\" href=\\\"#feb-16-2023\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003esafetensor\\u003c/code\\u003e checkpoint support added\\u003c/li\\u003e\\n\\u003cli\\u003eAdd ideas from 'Scaling Vision Transformers to 22 B. Params' (\\u003ca href=\\\"https://arxiv.org/abs/2302.05442\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2302.05442\\u003c/a\\u003e) -- qk norm, RmsNorm, parallel block\\u003c/li\\u003e\\n\\u003cli\\u003eAdd F.scaled_dot_product_attention support (PyTorch 2.0 only) to \\u003ccode\\u003evit_*\\u003c/code\\u003e, \\u003ccode\\u003evit_relpos*\\u003c/code\\u003e, \\u003ccode\\u003ecoatnet\\u003c/code\\u003e / \\u003ccode\\u003emaxxvit\\u003c/code\\u003e (to start)\\u003c/li\\u003e\\n\\u003cli\\u003eLion optimizer (w/ multi-tensor option) added (\\u003ca href=\\\"https://arxiv.org/abs/2302.06675\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2302.06675\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003egradient checkpointing works with \\u003ccode\\u003efeatures_only=True\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eIntroduction\\u003c/h2\\u003e\\u003ca id=\\\"user-content-introduction\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Introduction\\\" href=\\\"#introduction\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003ePy\\u003cstrong\\u003eT\\u003c/strong\\u003eorch \\u003cstrong\\u003eIm\\u003c/strong\\u003eage \\u003cstrong\\u003eM\\u003c/strong\\u003eodels (\\u003ccode\\u003etimm\\u003c/code\\u003e) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe work of many others is present here. I've tried to make sure all source material is acknowledged via links to github, arxiv papers, etc in the README, documentation, and code docstrings. Please let me know if I missed anything.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eFeatures\\u003c/h2\\u003e\\u003ca id=\\\"user-content-features\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Features\\\" href=\\\"#features\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eModels\\u003c/h3\\u003e\\u003ca id=\\\"user-content-models\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Models\\\" href=\\\"#models\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eAll model architecture families include variants with pretrained weights. There are specific model variants without any weights, it is NOT a bug. Help training new or better weights is always appreciated.\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAggregating Nested Transformers - \\u003ca href=\\\"https://arxiv.org/abs/2105.12723\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2105.12723\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eBEiT - \\u003ca href=\\\"https://arxiv.org/abs/2106.08254\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2106.08254\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eBig Transfer ResNetV2 (BiT) - \\u003ca href=\\\"https://arxiv.org/abs/1912.11370\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1912.11370\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eBottleneck Transformers - \\u003ca href=\\\"https://arxiv.org/abs/2101.11605\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2101.11605\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eCaiT (Class-Attention in Image Transformers) - \\u003ca href=\\\"https://arxiv.org/abs/2103.17239\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.17239\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eCoaT (Co-Scale Conv-Attentional Image Transformers) - \\u003ca href=\\\"https://arxiv.org/abs/2104.06399\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2104.06399\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eCoAtNet (Convolution and Attention) - \\u003ca href=\\\"https://arxiv.org/abs/2106.04803\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2106.04803\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eConvNeXt - \\u003ca href=\\\"https://arxiv.org/abs/2201.03545\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2201.03545\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eConvNeXt-V2 - \\u003ca href=\\\"http://arxiv.org/abs/2301.00808\\\" rel=\\\"nofollow\\\"\\u003ehttp://arxiv.org/abs/2301.00808\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eConViT (Soft Convolutional Inductive Biases Vision Transformers)- \\u003ca href=\\\"https://arxiv.org/abs/2103.10697\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.10697\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eCspNet (Cross-Stage Partial Networks) - \\u003ca href=\\\"https://arxiv.org/abs/1911.11929\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1911.11929\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eDeiT - \\u003ca href=\\\"https://arxiv.org/abs/2012.12877\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2012.12877\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eDeiT-III - \\u003ca href=\\\"https://arxiv.org/pdf/2204.07118.pdf\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/pdf/2204.07118.pdf\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eDenseNet - \\u003ca href=\\\"https://arxiv.org/abs/1608.06993\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1608.06993\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eDLA - \\u003ca href=\\\"https://arxiv.org/abs/1707.06484\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1707.06484\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eDPN (Dual-Path Network) - \\u003ca href=\\\"https://arxiv.org/abs/1707.01629\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1707.01629\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEdgeNeXt - \\u003ca href=\\\"https://arxiv.org/abs/2206.10589\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2206.10589\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientFormer - \\u003ca href=\\\"https://arxiv.org/abs/2206.01191\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2206.01191\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientNet (MBConvNet Family)\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eEfficientNet NoisyStudent (B0-B7, L2) - \\u003ca href=\\\"https://arxiv.org/abs/1911.04252\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1911.04252\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientNet AdvProp (B0-B8) - \\u003ca href=\\\"https://arxiv.org/abs/1911.09665\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1911.09665\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientNet (B0-B7) - \\u003ca href=\\\"https://arxiv.org/abs/1905.11946\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1905.11946\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientNet-EdgeTPU (S, M, L) - \\u003ca href=\\\"https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html\\\" rel=\\\"nofollow\\\"\\u003ehttps://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientNet V2 - \\u003ca href=\\\"https://arxiv.org/abs/2104.00298\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2104.00298\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eFBNet-C - \\u003ca href=\\\"https://arxiv.org/abs/1812.03443\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1812.03443\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMixNet - \\u003ca href=\\\"https://arxiv.org/abs/1907.09595\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1907.09595\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMNASNet B1, A1 (Squeeze-Excite), and Small - \\u003ca href=\\\"https://arxiv.org/abs/1807.11626\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1807.11626\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMobileNet-V2 - \\u003ca href=\\\"https://arxiv.org/abs/1801.04381\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1801.04381\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSingle-Path NAS - \\u003ca href=\\\"https://arxiv.org/abs/1904.02877\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1904.02877\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eTinyNet - \\u003ca href=\\\"https://arxiv.org/abs/2010.14819\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2010.14819\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientViT (MIT) - \\u003ca href=\\\"https://arxiv.org/abs/2205.14756\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2205.14756\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientViT (MSRA) - \\u003ca href=\\\"https://arxiv.org/abs/2305.07027\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2305.07027\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEVA - \\u003ca href=\\\"https://arxiv.org/abs/2211.07636\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2211.07636\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEVA-02 - \\u003ca href=\\\"https://arxiv.org/abs/2303.11331\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2303.11331\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eFastViT - \\u003ca href=\\\"https://arxiv.org/abs/2303.14189\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2303.14189\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eFlexiViT - \\u003ca href=\\\"https://arxiv.org/abs/2212.08013\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2212.08013\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eFocalNet (Focal Modulation Networks) - \\u003ca href=\\\"https://arxiv.org/abs/2203.11926\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2203.11926\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eGCViT (Global Context Vision Transformer) - \\u003ca href=\\\"https://arxiv.org/abs/2206.09959\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2206.09959\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eGhostNet - \\u003ca href=\\\"https://arxiv.org/abs/1911.11907\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1911.11907\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eGhostNet-V2 - \\u003ca href=\\\"https://arxiv.org/abs/2211.12905\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2211.12905\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003egMLP - \\u003ca href=\\\"https://arxiv.org/abs/2105.08050\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2105.08050\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eGPU-Efficient Networks - \\u003ca href=\\\"https://arxiv.org/abs/2006.14090\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2006.14090\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eHalo Nets - \\u003ca href=\\\"https://arxiv.org/abs/2103.12731\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.12731\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eHGNet / HGNet-V2 - TBD\\u003c/li\\u003e\\n\\u003cli\\u003eHRNet - \\u003ca href=\\\"https://arxiv.org/abs/1908.07919\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1908.07919\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eInceptionNeXt - \\u003ca href=\\\"https://arxiv.org/abs/2303.16900\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2303.16900\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eInception-V3 - \\u003ca href=\\\"https://arxiv.org/abs/1512.00567\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1512.00567\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eInception-ResNet-V2 and Inception-V4 - \\u003ca href=\\\"https://arxiv.org/abs/1602.07261\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1602.07261\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eLambda Networks - \\u003ca href=\\\"https://arxiv.org/abs/2102.08602\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2102.08602\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eLeViT (Vision Transformer in ConvNet's Clothing) - \\u003ca href=\\\"https://arxiv.org/abs/2104.01136\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2104.01136\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMaxViT (Multi-Axis Vision Transformer) - \\u003ca href=\\\"https://arxiv.org/abs/2204.01697\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2204.01697\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMetaFormer (PoolFormer-v2, ConvFormer, CAFormer) - \\u003ca href=\\\"https://arxiv.org/abs/2210.13452\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2210.13452\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMLP-Mixer - \\u003ca href=\\\"https://arxiv.org/abs/2105.01601\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2105.01601\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMobileNet-V3 (MBConvNet w/ Efficient Head) - \\u003ca href=\\\"https://arxiv.org/abs/1905.02244\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1905.02244\\u003c/a\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eFBNet-V3 - \\u003ca href=\\\"https://arxiv.org/abs/2006.02049\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2006.02049\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eHardCoRe-NAS - \\u003ca href=\\\"https://arxiv.org/abs/2102.11646\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2102.11646\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eLCNet - \\u003ca href=\\\"https://arxiv.org/abs/2109.15099\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2109.15099\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eMobileOne - \\u003ca href=\\\"https://arxiv.org/abs/2206.04040\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2206.04040\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMobileViT - \\u003ca href=\\\"https://arxiv.org/abs/2110.02178\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2110.02178\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMobileViT-V2 - \\u003ca href=\\\"https://arxiv.org/abs/2206.02680\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2206.02680\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eMViT-V2 (Improved Multiscale Vision Transformer) - \\u003ca href=\\\"https://arxiv.org/abs/2112.01526\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2112.01526\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eNASNet-A - \\u003ca href=\\\"https://arxiv.org/abs/1707.07012\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1707.07012\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eNesT - \\u003ca href=\\\"https://arxiv.org/abs/2105.12723\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2105.12723\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eNext-ViT - \\u003ca href=\\\"https://arxiv.org/abs/2207.05501\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2207.05501\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eNFNet-F - \\u003ca href=\\\"https://arxiv.org/abs/2102.06171\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2102.06171\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eNF-RegNet / NF-ResNet - \\u003ca href=\\\"https://arxiv.org/abs/2101.08692\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2101.08692\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003ePNasNet - \\u003ca href=\\\"https://arxiv.org/abs/1712.00559\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1712.00559\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003ePoolFormer (MetaFormer) - \\u003ca href=\\\"https://arxiv.org/abs/2111.11418\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2111.11418\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003ePooling-based Vision Transformer (PiT) - \\u003ca href=\\\"https://arxiv.org/abs/2103.16302\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.16302\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003ePVT-V2 (Improved Pyramid Vision Transformer) - \\u003ca href=\\\"https://arxiv.org/abs/2106.13797\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2106.13797\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eRegNet - \\u003ca href=\\\"https://arxiv.org/abs/2003.13678\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2003.13678\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eRegNetZ - \\u003ca href=\\\"https://arxiv.org/abs/2103.06877\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.06877\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eRepVGG - \\u003ca href=\\\"https://arxiv.org/abs/2101.03697\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2101.03697\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eRepGhostNet - \\u003ca href=\\\"https://arxiv.org/abs/2211.06088\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2211.06088\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eRepViT - \\u003ca href=\\\"https://arxiv.org/abs/2307.09283\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2307.09283\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eResMLP - \\u003ca href=\\\"https://arxiv.org/abs/2105.03404\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2105.03404\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eResNet/ResNeXt\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eResNet (v1b/v1.5) - \\u003ca href=\\\"https://arxiv.org/abs/1512.03385\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1512.03385\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eResNeXt - \\u003ca href=\\\"https://arxiv.org/abs/1611.05431\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1611.05431\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e'Bag of Tricks' / Gluon C, D, E, S variations - \\u003ca href=\\\"https://arxiv.org/abs/1812.01187\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1812.01187\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eWeakly-supervised (WSL) Instagram pretrained / ImageNet tuned ResNeXt101 - \\u003ca href=\\\"https://arxiv.org/abs/1805.00932\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1805.00932\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSemi-supervised (SSL) / Semi-weakly Supervised (SWSL) ResNet/ResNeXts - \\u003ca href=\\\"https://arxiv.org/abs/1905.00546\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1905.00546\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eECA-Net (ECAResNet) - \\u003ca href=\\\"https://arxiv.org/abs/1910.03151v4\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1910.03151v4\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSqueeze-and-Excitation Networks (SEResNet) - \\u003ca href=\\\"https://arxiv.org/abs/1709.01507\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1709.01507\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eResNet-RS - \\u003ca href=\\\"https://arxiv.org/abs/2103.07579\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.07579\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eRes2Net - \\u003ca href=\\\"https://arxiv.org/abs/1904.01169\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1904.01169\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eResNeSt - \\u003ca href=\\\"https://arxiv.org/abs/2004.08955\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2004.08955\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eReXNet - \\u003ca href=\\\"https://arxiv.org/abs/2007.00992\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2007.00992\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSelecSLS - \\u003ca href=\\\"https://arxiv.org/abs/1907.00837\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1907.00837\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSelective Kernel Networks - \\u003ca href=\\\"https://arxiv.org/abs/1903.06586\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1903.06586\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSequencer2D - \\u003ca href=\\\"https://arxiv.org/abs/2205.01972\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2205.01972\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSwin S3 (AutoFormerV2) - \\u003ca href=\\\"https://arxiv.org/abs/2111.14725\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2111.14725\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSwin Transformer - \\u003ca href=\\\"https://arxiv.org/abs/2103.14030\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.14030\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSwin Transformer V2 - \\u003ca href=\\\"https://arxiv.org/abs/2111.09883\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2111.09883\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eTransformer-iN-Transformer (TNT) - \\u003ca href=\\\"https://arxiv.org/abs/2103.00112\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.00112\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eTResNet - \\u003ca href=\\\"https://arxiv.org/abs/2003.13630\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2003.13630\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eTwins (Spatial Attention in Vision Transformers) - \\u003ca href=\\\"https://arxiv.org/pdf/2104.13840.pdf\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/pdf/2104.13840.pdf\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eVisformer - \\u003ca href=\\\"https://arxiv.org/abs/2104.12533\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2104.12533\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eVision Transformer - \\u003ca href=\\\"https://arxiv.org/abs/2010.11929\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2010.11929\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eVOLO (Vision Outlooker) - \\u003ca href=\\\"https://arxiv.org/abs/2106.13112\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2106.13112\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eVovNet V2 and V1 - \\u003ca href=\\\"https://arxiv.org/abs/1911.06667\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1911.06667\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eXception - \\u003ca href=\\\"https://arxiv.org/abs/1610.02357\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1610.02357\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eXception (Modified Aligned, Gluon) - \\u003ca href=\\\"https://arxiv.org/abs/1802.02611\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1802.02611\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eXception (Modified Aligned, TF) - \\u003ca href=\\\"https://arxiv.org/abs/1802.02611\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1802.02611\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eXCiT (Cross-Covariance Image Transformers) - \\u003ca href=\\\"https://arxiv.org/abs/2106.09681\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2106.09681\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eOptimizers\\u003c/h3\\u003e\\u003ca id=\\\"user-content-optimizers\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Optimizers\\\" href=\\\"#optimizers\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eIncluded optimizers available via \\u003ccode\\u003ecreate_optimizer\\u003c/code\\u003e / \\u003ccode\\u003ecreate_optimizer_v2\\u003c/code\\u003e factory methods:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eadabelief\\u003c/code\\u003e an implementation of AdaBelief adapted from \\u003ca href=\\\"https://github.com/juntang-zhuang/Adabelief-Optimizer\\\"\\u003ehttps://github.com/juntang-zhuang/Adabelief-Optimizer\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/2010.07468\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2010.07468\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eadafactor\\u003c/code\\u003e adapted from \\u003ca href=\\\"https://github.com/pytorch/fairseq/blob/master/fairseq/optim/adafactor.py\\\"\\u003eFAIRSeq impl\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/1804.04235\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1804.04235\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eadahessian\\u003c/code\\u003e by \\u003ca href=\\\"https://github.com/davda54/ada-hessian\\\"\\u003eDavid Samuel\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/2006.00719\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2006.00719\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eadamp\\u003c/code\\u003e and \\u003ccode\\u003esgdp\\u003c/code\\u003e by \\u003ca href=\\\"https://github.com/clovaai\\\"\\u003eNaver ClovAI\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/2006.08217\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2006.08217\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eadan\\u003c/code\\u003e an implementation of Adan adapted from \\u003ca href=\\\"https://github.com/sail-sg/Adan\\\"\\u003ehttps://github.com/sail-sg/Adan\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/2208.06677\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2208.06677\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003elamb\\u003c/code\\u003e an implementation of Lamb and LambC (w/ trust-clipping) cleaned up and modified to support use with XLA - \\u003ca href=\\\"https://arxiv.org/abs/1904.00962\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1904.00962\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003elars\\u003c/code\\u003e an implementation of LARS and LARC (w/ trust-clipping) - \\u003ca href=\\\"https://arxiv.org/abs/1708.03888\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1708.03888\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003elion\\u003c/code\\u003e and implementation of Lion adapted from \\u003ca href=\\\"https://github.com/google/automl/tree/master/lion\\\"\\u003ehttps://github.com/google/automl/tree/master/lion\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/2302.06675\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2302.06675\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003elookahead\\u003c/code\\u003e adapted from impl by \\u003ca href=\\\"https://github.com/alphadl/lookahead.pytorch\\\"\\u003eLiam\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/1907.08610\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1907.08610\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003emadgrad\\u003c/code\\u003e - and implementation of MADGRAD adapted from \\u003ca href=\\\"https://github.com/facebookresearch/madgrad\\\"\\u003ehttps://github.com/facebookresearch/madgrad\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/2101.11075\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2101.11075\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003enadam\\u003c/code\\u003e an implementation of Adam w/ Nesterov momentum\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003enadamw\\u003c/code\\u003e an impementation of AdamW (Adam w/ decoupled weight-decay) w/ Nesterov momentum. A simplified impl based on \\u003ca href=\\\"https://github.com/mlcommons/algorithmic-efficiency\\\"\\u003ehttps://github.com/mlcommons/algorithmic-efficiency\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003enovograd\\u003c/code\\u003e by \\u003ca href=\\\"https://github.com/convergence-lab/novograd\\\"\\u003eMasashi Kimura\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/1905.11286\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1905.11286\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eradam\\u003c/code\\u003e by \\u003ca href=\\\"https://github.com/LiyuanLucasLiu/RAdam\\\"\\u003eLiyuan Liu\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/1908.03265\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1908.03265\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ermsprop_tf\\u003c/code\\u003e adapted from PyTorch RMSProp by myself. Reproduces much improved Tensorflow RMSProp behaviour\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003esgdw\\u003c/code\\u003e and implementation of SGD w/ decoupled weight-decay\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003efused\\u0026lt;name\\u0026gt;\\u003c/code\\u003e optimizers by name with \\u003ca href=\\\"https://github.com/NVIDIA/apex/tree/master/apex/optimizers\\\"\\u003eNVIDIA Apex\\u003c/a\\u003e installed\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ebits\\u0026lt;name\\u0026gt;\\u003c/code\\u003e optimizers by name with \\u003ca href=\\\"https://github.com/TimDettmers/bitsandbytes\\\"\\u003eBitsAndBytes\\u003c/a\\u003e installed\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAugmentations\\u003c/h3\\u003e\\u003ca id=\\\"user-content-augmentations\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Augmentations\\\" href=\\\"#augmentations\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eRandom Erasing from \\u003ca href=\\\"https://github.com/zhunzhong07/Random-Erasing/blob/master/transforms.py\\\"\\u003eZhun Zhong\\u003c/a\\u003e - \\u003ca href=\\\"https://arxiv.org/abs/1708.04896\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1708.04896\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eMixup - \\u003ca href=\\\"https://arxiv.org/abs/1710.09412\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1710.09412\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eCutMix - \\u003ca href=\\\"https://arxiv.org/abs/1905.04899\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1905.04899\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eAutoAugment (\\u003ca href=\\\"https://arxiv.org/abs/1805.09501\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1805.09501\\u003c/a\\u003e) and RandAugment (\\u003ca href=\\\"https://arxiv.org/abs/1909.13719\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1909.13719\\u003c/a\\u003e) ImageNet configurations modeled after impl for EfficientNet training (\\u003ca href=\\\"https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py\\\"\\u003ehttps://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eAugMix w/ JSD loss, JSD w/ clean + augmented mixing support works with AutoAugment and RandAugment as well - \\u003ca href=\\\"https://arxiv.org/abs/1912.02781\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1912.02781\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSplitBachNorm - allows splitting batch norm layers between clean and augmented (auxiliary batch norm) data\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eRegularization\\u003c/h3\\u003e\\u003ca id=\\\"user-content-regularization\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Regularization\\\" href=\\\"#regularization\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eDropPath aka \\\"Stochastic Depth\\\" - \\u003ca href=\\\"https://arxiv.org/abs/1603.09382\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1603.09382\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eDropBlock - \\u003ca href=\\\"https://arxiv.org/abs/1810.12890\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1810.12890\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eBlur Pooling - \\u003ca href=\\\"https://arxiv.org/abs/1904.11486\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1904.11486\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eOther\\u003c/h3\\u003e\\u003ca id=\\\"user-content-other\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Other\\\" href=\\\"#other\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSeveral (less common) features that I often utilize in my projects are included. Many of their additions are the reason why I maintain my own set of models, instead of using others' via PIP:\\u003c/p\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAll models have a common default configuration interface and API for\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eaccessing/changing the classifier - \\u003ccode\\u003eget_classifier\\u003c/code\\u003e and \\u003ccode\\u003ereset_classifier\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003edoing a forward pass on just the features - \\u003ccode\\u003eforward_features\\u003c/code\\u003e (see \\u003ca href=\\\"https://huggingface.co/docs/timm/feature_extraction\\\" rel=\\\"nofollow\\\"\\u003edocumentation\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003ethese makes it easy to write consistent network wrappers that work with any of the models\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eAll models support multi-scale feature map extraction (feature pyramids) via create_model (see \\u003ca href=\\\"https://huggingface.co/docs/timm/feature_extraction\\\" rel=\\\"nofollow\\\"\\u003edocumentation\\u003c/a\\u003e)\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003ecreate_model(name, features_only=True, out_indices=..., output_stride=...)\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eout_indices\\u003c/code\\u003e creation arg specifies which feature maps to return, these indices are 0 based and generally correspond to the \\u003ccode\\u003eC(i + 1)\\u003c/code\\u003e feature level.\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ccode\\u003eoutput_stride\\u003c/code\\u003e creation arg controls output stride of the network by using dilated convolutions. Most networks are stride 32 by default. Not all networks support this.\\u003c/li\\u003e\\n\\u003cli\\u003efeature map channel counts, reduction level (stride) can be queried AFTER model creation via the \\u003ccode\\u003e.feature_info\\u003c/code\\u003e member\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eAll models have a consistent pretrained weight loader that adapts last linear if necessary, and from 3 to 1 channel input if desired\\u003c/li\\u003e\\n\\u003cli\\u003eHigh performance \\u003ca href=\\\"https://huggingface.co/docs/timm/training_script\\\" rel=\\\"nofollow\\\"\\u003ereference training, validation, and inference scripts\\u003c/a\\u003e that work in several process/GPU modes:\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eNVIDIA DDP w/ a single GPU per process, multiple processes with APEX present (AMP mixed-precision optional)\\u003c/li\\u003e\\n\\u003cli\\u003ePyTorch DistributedDataParallel w/ multi-gpu, single process (AMP disabled as it crashes when enabled)\\u003c/li\\u003e\\n\\u003cli\\u003ePyTorch w/ single GPU single process (AMP optional)\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eA dynamic global pool implementation that allows selecting from average pooling, max pooling, average + max, or concat([average, max]) at model creation. All global pooling is adaptive average by default and compatible with pretrained weights.\\u003c/li\\u003e\\n\\u003cli\\u003eA 'Test Time Pool' wrapper that can wrap any of the included models and usually provides improved performance doing inference with input images larger than the training size. Idea adapted from original DPN implementation when I ported (\\u003ca href=\\\"https://github.com/cypw/DPNs\\\"\\u003ehttps://github.com/cypw/DPNs\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eLearning rate schedulers\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eIdeas adopted from\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/allenai/allennlp/tree/master/allennlp/training/learning_rate_schedulers\\\"\\u003eAllenNLP schedulers\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003ca href=\\\"https://github.com/pytorch/fairseq/tree/master/fairseq/optim/lr_scheduler\\\"\\u003eFAIRseq lr_scheduler\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSGDR: Stochastic Gradient Descent with Warm Restarts (\\u003ca href=\\\"https://arxiv.org/abs/1608.03983\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1608.03983\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eSchedulers include \\u003ccode\\u003estep\\u003c/code\\u003e, \\u003ccode\\u003ecosine\\u003c/code\\u003e w/ restarts, \\u003ccode\\u003etanh\\u003c/code\\u003e w/ restarts, \\u003ccode\\u003eplateau\\u003c/code\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003cli\\u003eSpace-to-Depth by \\u003ca href=\\\"https://github.com/mrT23/TResNet/blob/master/src/models/tresnet/layers/space_to_depth.py\\\"\\u003emrT23\\u003c/a\\u003e (\\u003ca href=\\\"https://arxiv.org/abs/1801.04590\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1801.04590\\u003c/a\\u003e) -- original paper?\\u003c/li\\u003e\\n\\u003cli\\u003eAdaptive Gradient Clipping (\\u003ca href=\\\"https://arxiv.org/abs/2102.06171\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2102.06171\\u003c/a\\u003e, \\u003ca href=\\\"https://github.com/deepmind/deepmind-research/tree/master/nfnets\\\"\\u003ehttps://github.com/deepmind/deepmind-research/tree/master/nfnets\\u003c/a\\u003e)\\u003c/li\\u003e\\n\\u003cli\\u003eAn extensive selection of channel and/or spatial attention modules:\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eBottleneck Transformer - \\u003ca href=\\\"https://arxiv.org/abs/2101.11605\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2101.11605\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eCBAM - \\u003ca href=\\\"https://arxiv.org/abs/1807.06521\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1807.06521\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEffective Squeeze-Excitation (ESE) - \\u003ca href=\\\"https://arxiv.org/abs/1911.06667\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1911.06667\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficient Channel Attention (ECA) - \\u003ca href=\\\"https://arxiv.org/abs/1910.03151\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1910.03151\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eGather-Excite (GE) - \\u003ca href=\\\"https://arxiv.org/abs/1810.12348\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1810.12348\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eGlobal Context (GC) - \\u003ca href=\\\"https://arxiv.org/abs/1904.11492\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1904.11492\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eHalo - \\u003ca href=\\\"https://arxiv.org/abs/2103.12731\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.12731\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eInvolution - \\u003ca href=\\\"https://arxiv.org/abs/2103.06255\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.06255\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eLambda Layer - \\u003ca href=\\\"https://arxiv.org/abs/2102.08602\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2102.08602\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eNon-Local (NL) -  \\u003ca href=\\\"https://arxiv.org/abs/1711.07971\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1711.07971\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSqueeze-and-Excitation (SE) - \\u003ca href=\\\"https://arxiv.org/abs/1709.01507\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1709.01507\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSelective Kernel (SK) - (\\u003ca href=\\\"https://arxiv.org/abs/1903.06586\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/1903.06586\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSplit (SPLAT) - \\u003ca href=\\\"https://arxiv.org/abs/2004.08955\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2004.08955\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eShifted Window (SWIN) - \\u003ca href=\\\"https://arxiv.org/abs/2103.14030\\\" rel=\\\"nofollow\\\"\\u003ehttps://arxiv.org/abs/2103.14030\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eResults\\u003c/h2\\u003e\\u003ca id=\\\"user-content-results\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Results\\\" href=\\\"#results\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eModel validation results can be found in the \\u003ca href=\\\"/huggingface/pytorch-image-models/blob/main/results/README.md\\\"\\u003eresults tables\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eGetting Started (Documentation)\\u003c/h2\\u003e\\u003ca id=\\\"user-content-getting-started-documentation\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Getting Started (Documentation)\\\" href=\\\"#getting-started-documentation\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe official documentation can be found at \\u003ca href=\\\"https://huggingface.co/docs/hub/timm\\\" rel=\\\"nofollow\\\"\\u003ehttps://huggingface.co/docs/hub/timm\\u003c/a\\u003e. Documentation contributions are welcome.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca href=\\\"https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055\\\" rel=\\\"nofollow\\\"\\u003eGetting Started with PyTorch Image Models (timm): A Practitioner\u2019s Guide\\u003c/a\\u003e by \\u003ca href=\\\"https://github.com/Chris-hughes10\\\"\\u003eChris Hughes\\u003c/a\\u003e is an extensive blog post covering many aspects of \\u003ccode\\u003etimm\\u003c/code\\u003e in detail.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca href=\\\"http://timm.fast.ai/\\\" rel=\\\"nofollow\\\"\\u003etimmdocs\\u003c/a\\u003e is an alternate set of documentation for \\u003ccode\\u003etimm\\u003c/code\\u003e. A big thanks to \\u003ca href=\\\"https://github.com/amaarora\\\"\\u003eAman Arora\\u003c/a\\u003e for his efforts creating timmdocs.\\u003c/p\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca href=\\\"https://paperswithcode.com/lib/timm\\\" rel=\\\"nofollow\\\"\\u003epaperswithcode\\u003c/a\\u003e is a good resource for browsing the models within \\u003ccode\\u003etimm\\u003c/code\\u003e.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eTrain, Validation, Inference Scripts\\u003c/h2\\u003e\\u003ca id=\\\"user-content-train-validation-inference-scripts\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Train, Validation, Inference Scripts\\\" href=\\\"#train-validation-inference-scripts\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe root folder of the repository contains reference train, validation, and inference scripts that work with the included models and other features of this repository. They are adaptable for other datasets and use cases with a little hacking. See \\u003ca href=\\\"https://huggingface.co/docs/timm/training_script\\\" rel=\\\"nofollow\\\"\\u003edocumentation\\u003c/a\\u003e.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eAwesome PyTorch Resources\\u003c/h2\\u003e\\u003ca id=\\\"user-content-awesome-pytorch-resources\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Awesome PyTorch Resources\\\" href=\\\"#awesome-pytorch-resources\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eOne of the greatest assets of PyTorch is the community and their contributions. A few of my favourite resources that pair well with the models and components here are listed below.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eObject Detection, Instance and Semantic Segmentation\\u003c/h3\\u003e\\u003ca id=\\\"user-content-object-detection-instance-and-semantic-segmentation\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Object Detection, Instance and Semantic Segmentation\\\" href=\\\"#object-detection-instance-and-semantic-segmentation\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eDetectron2 - \\u003ca href=\\\"https://github.com/facebookresearch/detectron2\\\"\\u003ehttps://github.com/facebookresearch/detectron2\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eSegmentation Models (Semantic) - \\u003ca href=\\\"https://github.com/qubvel/segmentation_models.pytorch\\\"\\u003ehttps://github.com/qubvel/segmentation_models.pytorch\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eEfficientDet (Obj Det, Semantic soon) - \\u003ca href=\\\"https://github.com/rwightman/efficientdet-pytorch\\\"\\u003ehttps://github.com/rwightman/efficientdet-pytorch\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eComputer Vision / Image Augmentation\\u003c/h3\\u003e\\u003ca id=\\\"user-content-computer-vision--image-augmentation\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Computer Vision / Image Augmentation\\\" href=\\\"#computer-vision--image-augmentation\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eAlbumentations - \\u003ca href=\\\"https://github.com/albumentations-team/albumentations\\\"\\u003ehttps://github.com/albumentations-team/albumentations\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003eKornia - \\u003ca href=\\\"https://github.com/kornia/kornia\\\"\\u003ehttps://github.com/kornia/kornia\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eKnowledge Distillation\\u003c/h3\\u003e\\u003ca id=\\\"user-content-knowledge-distillation\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Knowledge Distillation\\\" href=\\\"#knowledge-distillation\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003eRepDistiller - \\u003ca href=\\\"https://github.com/HobbitLong/RepDistiller\\\"\\u003ehttps://github.com/HobbitLong/RepDistiller\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003etorchdistill - \\u003ca href=\\\"https://github.com/yoshitomo-matsubara/torchdistill\\\"\\u003ehttps://github.com/yoshitomo-matsubara/torchdistill\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eMetric Learning\\u003c/h3\\u003e\\u003ca id=\\\"user-content-metric-learning\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Metric Learning\\\" href=\\\"#metric-learning\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003ePyTorch Metric Learning - \\u003ca href=\\\"https://github.com/KevinMusgrave/pytorch-metric-learning\\\"\\u003ehttps://github.com/KevinMusgrave/pytorch-metric-learning\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eTraining / Frameworks\\u003c/h3\\u003e\\u003ca id=\\\"user-content-training--frameworks\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Training / Frameworks\\\" href=\\\"#training--frameworks\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cul dir=\\\"auto\\\"\\u003e\\n\\u003cli\\u003efastai - \\u003ca href=\\\"https://github.com/fastai/fastai\\\"\\u003ehttps://github.com/fastai/fastai\\u003c/a\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eLicenses\\u003c/h2\\u003e\\u003ca id=\\\"user-content-licenses\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Licenses\\\" href=\\\"#licenses\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCode\\u003c/h3\\u003e\\u003ca id=\\\"user-content-code\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Code\\\" href=\\\"#code\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eThe code here is licensed Apache 2.0. I've taken care to make sure any third party code included or adapted has compatible (permissive) licenses such as MIT, BSD, etc. I've made an effort to avoid any GPL / LGPL conflicts. That said, it is your responsibility to ensure you comply with licenses here and conditions of any dependent licenses. Where applicable, I've linked the sources/references for various components in docstrings. If you think I've missed anything please create an issue.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003ePretrained Weights\\u003c/h3\\u003e\\u003ca id=\\\"user-content-pretrained-weights\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Pretrained Weights\\\" href=\\\"#pretrained-weights\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSo far all of the pretrained weights available here are pretrained on ImageNet with a select few that have some additional pretraining (see extra note below). ImageNet was released for non-commercial research purposes only (\\u003ca href=\\\"https://image-net.org/download\\\" rel=\\\"nofollow\\\"\\u003ehttps://image-net.org/download\\u003c/a\\u003e). It's not clear what the implications of that are for the use of pretrained weights from that dataset. Any models I have trained with ImageNet are done for research purposes and one should assume that the original dataset license applies to the weights. It's best to seek legal advice if you intend to use the pretrained weights in a commercial product.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch4 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003ePretrained on more than ImageNet\\u003c/h4\\u003e\\u003ca id=\\\"user-content-pretrained-on-more-than-imagenet\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Pretrained on more than ImageNet\\\" href=\\\"#pretrained-on-more-than-imagenet\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003eSeveral weights included or references here were pretrained with proprietary datasets that I do not have access to. These include the Facebook WSL, SSL, SWSL ResNe(Xt) and the Google Noisy Student EfficientNet models. The Facebook models have an explicit non-commercial license (CC-BY-NC 4.0, \\u003ca href=\\\"https://github.com/facebookresearch/semi-supervised-ImageNet1K-models\\\"\\u003ehttps://github.com/facebookresearch/semi-supervised-ImageNet1K-models\\u003c/a\\u003e, \\u003ca href=\\\"https://github.com/facebookresearch/WSL-Images\\\"\\u003ehttps://github.com/facebookresearch/WSL-Images\\u003c/a\\u003e). The Google models do not appear to have any restriction beyond the Apache 2.0 license (and ImageNet concerns). In either case, you should contact Facebook or Google with any questions.\\u003c/p\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch2 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eCiting\\u003c/h2\\u003e\\u003ca id=\\\"user-content-citing\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Citing\\\" href=\\\"#citing\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eBibTeX\\u003c/h3\\u003e\\u003ca id=\\\"user-content-bibtex\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: BibTeX\\\" href=\\\"#bibtex\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"highlight highlight-text-bibtex notranslate position-relative overflow-auto\\\" dir=\\\"auto\\\" data-snippet-clipboard-copy-content=\\\"@misc{rw2019timm,\\n  author = {Ross Wightman},\\n  title = {PyTorch Image Models},\\n  year = {2019},\\n  publisher = {GitHub},\\n  journal = {GitHub repository},\\n  doi = {10.5281/zenodo.4414861},\\n  howpublished = {\\\\url{https://github.com/rwightman/pytorch-image-models}}\\n}\\\"\\u003e\\u003cpre\\u003e\\u003cspan class=\\\"pl-k\\\"\\u003e@misc\\u003c/span\\u003e{\\u003cspan class=\\\"pl-en\\\"\\u003erw2019timm\\u003c/span\\u003e,\\n  \\u003cspan class=\\\"pl-s\\\"\\u003eauthor\\u003c/span\\u003e = \\u003cspan class=\\\"pl-s\\\"\\u003e\\u003cspan class=\\\"pl-pds\\\"\\u003e{\\u003c/span\\u003eRoss Wightman\\u003cspan class=\\\"pl-pds\\\"\\u003e}\\u003c/span\\u003e\\u003c/span\\u003e,\\n  \\u003cspan class=\\\"pl-s\\\"\\u003etitle\\u003c/span\\u003e = \\u003cspan class=\\\"pl-s\\\"\\u003e\\u003cspan class=\\\"pl-pds\\\"\\u003e{\\u003c/span\\u003ePyTorch Image Models\\u003cspan class=\\\"pl-pds\\\"\\u003e}\\u003c/span\\u003e\\u003c/span\\u003e,\\n  \\u003cspan class=\\\"pl-s\\\"\\u003eyear\\u003c/span\\u003e = \\u003cspan class=\\\"pl-s\\\"\\u003e\\u003cspan class=\\\"pl-pds\\\"\\u003e{\\u003c/span\\u003e2019\\u003cspan class=\\\"pl-pds\\\"\\u003e}\\u003c/span\\u003e\\u003c/span\\u003e,\\n  \\u003cspan class=\\\"pl-s\\\"\\u003epublisher\\u003c/span\\u003e = \\u003cspan class=\\\"pl-s\\\"\\u003e\\u003cspan class=\\\"pl-pds\\\"\\u003e{\\u003c/span\\u003eGitHub\\u003cspan class=\\\"pl-pds\\\"\\u003e}\\u003c/span\\u003e\\u003c/span\\u003e,\\n  \\u003cspan class=\\\"pl-s\\\"\\u003ejournal\\u003c/span\\u003e = \\u003cspan class=\\\"pl-s\\\"\\u003e\\u003cspan class=\\\"pl-pds\\\"\\u003e{\\u003c/span\\u003eGitHub repository\\u003cspan class=\\\"pl-pds\\\"\\u003e}\\u003c/span\\u003e\\u003c/span\\u003e,\\n  \\u003cspan class=\\\"pl-s\\\"\\u003edoi\\u003c/span\\u003e = \\u003cspan class=\\\"pl-s\\\"\\u003e\\u003cspan class=\\\"pl-pds\\\"\\u003e{\\u003c/span\\u003e10.5281/zenodo.4414861\\u003cspan class=\\\"pl-pds\\\"\\u003e}\\u003c/span\\u003e\\u003c/span\\u003e,\\n  \\u003cspan class=\\\"pl-s\\\"\\u003ehowpublished\\u003c/span\\u003e = \\u003cspan class=\\\"pl-s\\\"\\u003e\\u003cspan class=\\\"pl-pds\\\"\\u003e{\\u003c/span\\u003e\\\\url{https://github.com/rwightman/pytorch-image-models}\\u003cspan class=\\\"pl-pds\\\"\\u003e}\\u003c/span\\u003e\\u003c/span\\u003e\\n}\\u003c/pre\\u003e\\u003c/div\\u003e\\n\\u003cdiv class=\\\"markdown-heading\\\" dir=\\\"auto\\\"\\u003e\\u003ch3 tabindex=\\\"-1\\\" class=\\\"heading-element\\\" dir=\\\"auto\\\"\\u003eLatest DOI\\u003c/h3\\u003e\\u003ca id=\\\"user-content-latest-doi\\\" class=\\\"anchor-element\\\" aria-label=\\\"Permalink: Latest DOI\\\" href=\\\"#latest-doi\\\"\\u003e\\u003csvg class=\\\"octicon octicon-link\\\" viewBox=\\\"0 0 16 16\\\" version=\\\"1.1\\\" width=\\\"16\\\" height=\\\"16\\\" aria-hidden=\\\"true\\\"\\u003e\\u003cpath d=\\\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\\\"\\u003e\\u003c/path\\u003e\\u003c/svg\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n\\u003cp dir=\\\"auto\\\"\\u003e\\u003ca href=\\\"https://zenodo.org/badge/latestdoi/168799526\\\" rel=\\\"nofollow\\\"\\u003e\\u003cimg src=\\\"https://camo.githubusercontent.com/8d3ff9146e8c7599db7b387602b07be7ca57e1a40302c1ad85f4444e0ece6e09/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3136383739393532362e737667\\\" alt=\\\"DOI\\\" data-canonical-src=\\\"https://zenodo.org/badge/168799526.svg\\\" style=\\\"max-width: 100%;\\\"\\u003e\\u003c/a\\u003e\\u003c/p\\u003e\\n\\u003c/article\\u003e\",\"loaded\":true,\"timedOut\":false,\"errorMessage\":null,\"headerInfo\":{\"toc\":[{\"level\":1,\"text\":\"PyTorch Image Models\",\"anchor\":\"pytorch-image-models\",\"htmlText\":\"PyTorch Image Models\"},{\"level\":2,\"text\":\"What's New\",\"anchor\":\"whats-new\",\"htmlText\":\"What's New\"},{\"level\":3,\"text\":\"Feb 19, 2024\",\"anchor\":\"feb-19-2024\",\"htmlText\":\"Feb 19, 2024\"},{\"level\":3,\"text\":\"Jan 8, 2024\",\"anchor\":\"jan-8-2024\",\"htmlText\":\"Jan 8, 2024\"},{\"level\":3,\"text\":\"Nov 23, 2023\",\"anchor\":\"nov-23-2023\",\"htmlText\":\"Nov 23, 2023\"},{\"level\":3,\"text\":\"Nov 20, 2023\",\"anchor\":\"nov-20-2023\",\"htmlText\":\"Nov 20, 2023\"},{\"level\":3,\"text\":\"Nov 3, 2023\",\"anchor\":\"nov-3-2023\",\"htmlText\":\"Nov 3, 2023\"},{\"level\":3,\"text\":\"Oct 20, 2023\",\"anchor\":\"oct-20-2023\",\"htmlText\":\"Oct 20, 2023\"},{\"level\":3,\"text\":\"Sep 1, 2023\",\"anchor\":\"sep-1-2023\",\"htmlText\":\"Sep 1, 2023\"},{\"level\":3,\"text\":\"Aug 28, 2023\",\"anchor\":\"aug-28-2023\",\"htmlText\":\"Aug 28, 2023\"},{\"level\":3,\"text\":\"Aug 25, 2023\",\"anchor\":\"aug-25-2023\",\"htmlText\":\"Aug 25, 2023\"},{\"level\":3,\"text\":\"Aug 11, 2023\",\"anchor\":\"aug-11-2023\",\"htmlText\":\"Aug 11, 2023\"},{\"level\":3,\"text\":\"Aug 3, 2023\",\"anchor\":\"aug-3-2023\",\"htmlText\":\"Aug 3, 2023\"},{\"level\":3,\"text\":\"July 27, 2023\",\"anchor\":\"july-27-2023\",\"htmlText\":\"July 27, 2023\"},{\"level\":3,\"text\":\"May 11, 2023\",\"anchor\":\"may-11-2023\",\"htmlText\":\"May 11, 2023\"},{\"level\":3,\"text\":\"May 10, 2023\",\"anchor\":\"may-10-2023\",\"htmlText\":\"May 10, 2023\"},{\"level\":3,\"text\":\"April 27, 2023\",\"anchor\":\"april-27-2023\",\"htmlText\":\"April 27, 2023\"},{\"level\":3,\"text\":\"April 21, 2023\",\"anchor\":\"april-21-2023\",\"htmlText\":\"April 21, 2023\"},{\"level\":3,\"text\":\"April 12, 2023\",\"anchor\":\"april-12-2023\",\"htmlText\":\"April 12, 2023\"},{\"level\":3,\"text\":\"April 5, 2023\",\"anchor\":\"april-5-2023\",\"htmlText\":\"April 5, 2023\"},{\"level\":3,\"text\":\"March 31, 2023\",\"anchor\":\"march-31-2023\",\"htmlText\":\"March 31, 2023\"},{\"level\":3,\"text\":\"March 22, 2023\",\"anchor\":\"march-22-2023\",\"htmlText\":\"March 22, 2023\"},{\"level\":3,\"text\":\"Feb 26, 2023\",\"anchor\":\"feb-26-2023\",\"htmlText\":\"Feb 26, 2023\"},{\"level\":3,\"text\":\"Feb 20, 2023\",\"anchor\":\"feb-20-2023\",\"htmlText\":\"Feb 20, 2023\"},{\"level\":3,\"text\":\"Feb 16, 2023\",\"anchor\":\"feb-16-2023\",\"htmlText\":\"Feb 16, 2023\"},{\"level\":2,\"text\":\"Introduction\",\"anchor\":\"introduction\",\"htmlText\":\"Introduction\"},{\"level\":2,\"text\":\"Features\",\"anchor\":\"features\",\"htmlText\":\"Features\"},{\"level\":3,\"text\":\"Models\",\"anchor\":\"models\",\"htmlText\":\"Models\"},{\"level\":3,\"text\":\"Optimizers\",\"anchor\":\"optimizers\",\"htmlText\":\"Optimizers\"},{\"level\":3,\"text\":\"Augmentations\",\"anchor\":\"augmentations\",\"htmlText\":\"Augmentations\"},{\"level\":3,\"text\":\"Regularization\",\"anchor\":\"regularization\",\"htmlText\":\"Regularization\"},{\"level\":3,\"text\":\"Other\",\"anchor\":\"other\",\"htmlText\":\"Other\"},{\"level\":2,\"text\":\"Results\",\"anchor\":\"results\",\"htmlText\":\"Results\"},{\"level\":2,\"text\":\"Getting Started (Documentation)\",\"anchor\":\"getting-started-documentation\",\"htmlText\":\"Getting Started (Documentation)\"},{\"level\":2,\"text\":\"Train, Validation, Inference Scripts\",\"anchor\":\"train-validation-inference-scripts\",\"htmlText\":\"Train, Validation, Inference Scripts\"},{\"level\":2,\"text\":\"Awesome PyTorch Resources\",\"anchor\":\"awesome-pytorch-resources\",\"htmlText\":\"Awesome PyTorch Resources\"},{\"level\":3,\"text\":\"Object Detection, Instance and Semantic Segmentation\",\"anchor\":\"object-detection-instance-and-semantic-segmentation\",\"htmlText\":\"Object Detection, Instance and Semantic Segmentation\"},{\"level\":3,\"text\":\"Computer Vision / Image Augmentation\",\"anchor\":\"computer-vision--image-augmentation\",\"htmlText\":\"Computer Vision / Image Augmentation\"},{\"level\":3,\"text\":\"Knowledge Distillation\",\"anchor\":\"knowledge-distillation\",\"htmlText\":\"Knowledge Distillation\"},{\"level\":3,\"text\":\"Metric Learning\",\"anchor\":\"metric-learning\",\"htmlText\":\"Metric Learning\"},{\"level\":3,\"text\":\"Training / Frameworks\",\"anchor\":\"training--frameworks\",\"htmlText\":\"Training / Frameworks\"},{\"level\":2,\"text\":\"Licenses\",\"anchor\":\"licenses\",\"htmlText\":\"Licenses\"},{\"level\":3,\"text\":\"Code\",\"anchor\":\"code\",\"htmlText\":\"Code\"},{\"level\":3,\"text\":\"Pretrained Weights\",\"anchor\":\"pretrained-weights\",\"htmlText\":\"Pretrained Weights\"},{\"level\":4,\"text\":\"Pretrained on more than ImageNet\",\"anchor\":\"pretrained-on-more-than-imagenet\",\"htmlText\":\"Pretrained on more than ImageNet\"},{\"level\":2,\"text\":\"Citing\",\"anchor\":\"citing\",\"htmlText\":\"Citing\"},{\"level\":3,\"text\":\"BibTeX\",\"anchor\":\"bibtex\",\"htmlText\":\"BibTeX\"},{\"level\":3,\"text\":\"Latest DOI\",\"anchor\":\"latest-doi\",\"htmlText\":\"Latest DOI\"}],\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fhuggingface%2Fpytorch-image-models\"}},{\"displayName\":\"LICENSE\",\"repoName\":\"pytorch-image-models\",\"refName\":\"main\",\"path\":\"LICENSE\",\"preferredFileType\":\"license\",\"tabName\":\"Apache-2.0\",\"richText\":null,\"loaded\":false,\"timedOut\":false,\"errorMessage\":null,\"headerInfo\":{\"toc\":null,\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fhuggingface%2Fpytorch-image-models\"}}],\"overviewFilesProcessingTime\":130.734107}},\"appPayload\":{\"helpUrl\":\"https://docs.github.com\",\"findFileWorkerPath\":\"/assets-cdn/worker/find-file-worker-32bb159cc57c.js\",\"findInFileWorkerPath\":\"/assets-cdn/worker/find-in-file-worker-c6704d501c10.js\",\"githubDevUrl\":null,\"enabled_features\":{\"code_nav_ui_events\":false,\"copilot_conversational_ux\":false,\"copilot_conversational_ux_embedding_update\":false,\"copilot_popover_file_editor_header\":false,\"copilot_smell_icebreaker_ux\":true,\"copilot_workspace\":false,\"codeview_firefox_inert\":true}}}}</script>  <div data-target=\"react-partial.reactRoot\"><style data-styled=\"true\" data-styled-version=\"5.3.6\">.cgQnMS{font-weight:600;font-size:32px;margin:0;}/*!sc*/data-styled.g1[id=\"Heading__StyledHeading-sc-1c1dgg0-0\"]{content:\"cgQnMS,\"}/*!sc*/.izjvBm{margin-top:16px;margin-bottom:16px;}/*!sc*/.rPQgy{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/.eUMEDg{margin-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;row-gap:16px;}/*!sc*/.eLcVee{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;padding-bottom:16px;padding-top:8px;}/*!sc*/.hsfLlq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;gap:8px;}/*!sc*/@media screen and (max-width:320px){.hsfLlq{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}}/*!sc*/.gpKoUz{position:relative;}/*!sc*/@media screen and (max-width:380px){.gpKoUz .ref-selector-button-text-container{max-width:80px;}}/*!sc*/@media screen and (max-width:320px){.gpKoUz{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}.gpKoUz .overview-ref-selector{width:100%;}.gpKoUz .overview-ref-selector > span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}.gpKoUz .overview-ref-selector > span > span[data-component=\"text\"]{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}}/*!sc*/.kkrdEu{-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/.bKgizp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;}/*!sc*/.iPGYsi{margin-right:4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.dKmYfk{font-size:14px;min-width:0;max-width:125px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}/*!sc*/.trpoQ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;pointer-events:none;}/*!sc*/.laYubZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (max-width:1079px){.laYubZ{display:none;}}/*!sc*/.swnaL{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:1080px){.swnaL{display:none;}}/*!sc*/@media screen and (max-width:543px){.swnaL{display:none;}}/*!sc*/.bWpuBf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:8px;gap:8px;}/*!sc*/.grHjNb{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;}/*!sc*/@media screen and (max-width:543px){.grHjNb{display:none;}}/*!sc*/.dXTsqj{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (max-width:1011px){.dXTsqj{display:none;}}/*!sc*/.dCOrmu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:1012px){.dCOrmu{display:none;}}/*!sc*/@media screen and (max-width:544px){.bVvbgP{display:none;}}/*!sc*/.bNDvfp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/@media screen and (min-width:544px){.bNDvfp{display:none;}}/*!sc*/.yfPnm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;gap:16px;}/*!sc*/.cAQuiW{width:100%;border-collapse:separate;border-spacing:0;border:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));border-radius:6px;table-layout:fixed;overflow:unset;}/*!sc*/.iiUlLN{height:0px;line-height:0px;}/*!sc*/.iiUlLN tr{height:0px;font-size:0px;}/*!sc*/.jmggSN{padding:16px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));font-size:12px;text-align:left;height:40px;}/*!sc*/.jmggSN th{padding-left:16px;background-color:var(--bgColor-muted,var(--color-canvas-subtle,#f6f8fa));}/*!sc*/.kvYunM{width:100%;border-top-left-radius:6px;}/*!sc*/@media screen and (min-width:544px){.kvYunM{display:none;}}/*!sc*/.hrLuxA{width:40%;border-top-left-radius:6px;}/*!sc*/@media screen and (max-width:543px){.hrLuxA{display:none;}}/*!sc*/@media screen and (max-width:543px){.ePjhhA{display:none;}}/*!sc*/.cuEKae{text-align:right;padding-right:16px;width:136px;border-top-right-radius:6px;}/*!sc*/.jEbBOT{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));font-size:12px;height:40px;}/*!sc*/.bTxCvM{background-color:var(--bgColor-muted,var(--color-canvas-subtle,#f6f8fa));padding:4px;border-top-left-radius:6px;border-top-right-radius:6px;}/*!sc*/.eYedVD{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:8px;min-width:273px;padding-right:8px;padding-left:16px;padding-top:8px;padding-bottom:8px;}/*!sc*/.jGfYmh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;}/*!sc*/.lhFvfi{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/.bqgLjk{display:inherit;}/*!sc*/@media screen and (min-width:544px){.bqgLjk{display:none;}}/*!sc*/@media screen and (min-width:768px){.bqgLjk{display:none;}}/*!sc*/.epsqEd{text-align:center;vertical-align:center;height:40px;border-top:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));}/*!sc*/.ldpruc{border-top:1px solid var(--borderColor-default,var(--color-border-default));cursor:pointer;}/*!sc*/.ehcSsh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;gap:16px;}/*!sc*/.iGmlUb{border:1px solid;border-color:var(--borderColor-default,var(--color-border-default,#d0d7de));border-radius:6px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}/*!sc*/@media screen and (max-width:543px){.iGmlUb{margin-left:-16px;margin-right:-16px;max-width:calc(100% + 32px);}}/*!sc*/@media screen and (min-width:544px){.iGmlUb{max-width:100%;}}/*!sc*/.iRQGXA{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-bottom:1px solid;border-bottom-color:var(--borderColor-default,var(--color-border-default,#d0d7de));-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-right:8px;position:-webkit-sticky;position:sticky;top:0;background-color:var(--bgColor-default,var(--color-canvas-default,#ffffff));z-index:1;border-top-left-radius:6px;border-top-right-radius:6px;}/*!sc*/.dvTdPK{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:8px;padding-right:8px;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;border-bottom:none;border-bottom-color:var(--borderColor-muted,var(--color-border-muted,hsla(210,18%,87%,1)));align:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-height:48px;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;max-width:100%;}/*!sc*/.gwuIGu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/.kOxwQs{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;margin-right:8px;}/*!sc*/.kOgeFj{font-weight:600;}/*!sc*/.bJMeLZ{padding:32px;overflow:auto;}/*!sc*/data-styled.g2[id=\"Box-sc-g0xbh4-0\"]{content:\"izjvBm,rPQgy,eUMEDg,eLcVee,hsfLlq,gpKoUz,kkrdEu,bKgizp,iPGYsi,dKmYfk,trpoQ,laYubZ,swnaL,bWpuBf,grHjNb,dXTsqj,dCOrmu,bVvbgP,bNDvfp,yfPnm,cAQuiW,iiUlLN,jmggSN,kvYunM,hrLuxA,ePjhhA,cuEKae,jEbBOT,bTxCvM,eYedVD,jGfYmh,lhFvfi,bqgLjk,epsqEd,ldpruc,ehcSsh,iGmlUb,iRQGXA,dvTdPK,gwuIGu,kOxwQs,kOgeFj,bJMeLZ,\"}/*!sc*/.bOMzPg{min-width:0;}/*!sc*/.eUGNHp{font-weight:600;}/*!sc*/.dALsKK{color:var(--fgColor-default,var(--color-fg-default,#1F2328));}/*!sc*/data-styled.g6[id=\"Text-sc-17v1xeu-0\"]{content:\"bOMzPg,eUGNHp,dALsKK,\"}/*!sc*/.dheQRw{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.dheQRw:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.dheQRw:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.vLMkZ{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;position:relative;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;color:var(--fgColor-default,var(--color-fg-default,#1F2328));text-align:center;-webkit-text-decoration:none;text-decoration:none;line-height:calc(20/14);border-radius:6px;font-size:14px;padding-left:8px;padding-right:8px;padding-top:calc((2rem - 1.25rem) / 2);padding-bottom:calc((2rem - 1.25rem) / 2);}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.vLMkZ:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.vLMkZ:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.vLMkZ span[data-component=\"icon\"]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/@media (hover:hover){.vLMkZ:hover{background-color:var(--bgColor-neutral-muted,var(--color-neutral-muted,rgba(175,184,193,0.2)));-webkit-transition:background .12s ease-out;transition:background .12s ease-out;-webkit-text-decoration:none;text-decoration:none;}}/*!sc*/.vLMkZ:focus{outline:2px solid transparent;}/*!sc*/.vLMkZ:focus{box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.vLMkZ:focus:not(:focus-visible){box-shadow:none;}/*!sc*/.vLMkZ:focus-visible{outline:2px solid transparent;box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.vLMkZ span[data-content]::before{content:attr(data-content);display:block;height:0;font-weight:600;visibility:hidden;white-space:nowrap;}/*!sc*/.vLMkZ::after{position:absolute;right:50%;bottom:calc(50% - 25px);width:100%;height:2px;content:\"\";background-color:var(--underlineNav-borderColor-active,var(--color-primer-border-active,#fd8c73));border-radius:0;-webkit-transform:translate(50%,-50%);-ms-transform:translate(50%,-50%);transform:translate(50%,-50%);}/*!sc*/@media (forced-colors:active){.vLMkZ::after{background-color:LinkText;}}/*!sc*/.bhqztV{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));-webkit-text-decoration:none;text-decoration:none;position:relative;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;color:var(--fgColor-default,var(--color-fg-default,#1F2328));text-align:center;-webkit-text-decoration:none;text-decoration:none;line-height:calc(20/14);border-radius:6px;font-size:14px;padding-left:8px;padding-right:8px;padding-top:calc((2rem - 1.25rem) / 2);padding-bottom:calc((2rem - 1.25rem) / 2);}/*!sc*/[data-a11y-link-underlines='true'] .Link__StyledLink-sc-14289xe-0[data-inline='true']{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.bhqztV:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/.bhqztV:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/.bhqztV span[data-component=\"icon\"]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/@media (hover:hover){.bhqztV:hover{background-color:var(--bgColor-neutral-muted,var(--color-neutral-muted,rgba(175,184,193,0.2)));-webkit-transition:background .12s ease-out;transition:background .12s ease-out;-webkit-text-decoration:none;text-decoration:none;}}/*!sc*/.bhqztV:focus{outline:2px solid transparent;}/*!sc*/.bhqztV:focus{box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.bhqztV:focus:not(:focus-visible){box-shadow:none;}/*!sc*/.bhqztV:focus-visible{outline:2px solid transparent;box-shadow:inset 0 0 0 2px var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.bhqztV span[data-content]::before{content:attr(data-content);display:block;height:0;font-weight:600;visibility:hidden;white-space:nowrap;}/*!sc*/.bhqztV::after{position:absolute;right:50%;bottom:calc(50% - 25px);width:100%;height:2px;content:\"\";background-color:transparent;border-radius:0;-webkit-transform:translate(50%,-50%);-ms-transform:translate(50%,-50%);transform:translate(50%,-50%);}/*!sc*/@media (forced-colors:active){.bhqztV::after{background-color:transparent;}}/*!sc*/data-styled.g8[id=\"Link__StyledLink-sc-14289xe-0\"]{content:\"dheQRw,vLMkZ,bhqztV,\"}/*!sc*/.izDscS{border-radius:6px;border:1px solid;border-color:var(--button-default-borderColor-rest,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:var(--button-default-bgColor-rest,var(--color-btn-bg,#f6f8fa));box-shadow:var(--button-default-shadow-resting,var(--color-btn-shadow,0 1px 0 rgba(31,35,40,0.04))),var(--button-default-shadow-inset,var(--color-btn-inset-shadow,inset 0 1px 0 rgba(255,255,255,0.25)));}/*!sc*/.izDscS:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.izDscS:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.izDscS:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.izDscS[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.izDscS[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.izDscS:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.izDscS:active{-webkit-transition:none;transition:none;}/*!sc*/.izDscS[data-inactive]{cursor:auto;}/*!sc*/.izDscS:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));border-color:var(--button-default-borderColor-disabled,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.izDscS:focus{outline:solid 1px transparent;}}/*!sc*/.izDscS [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-default-bgColor-rest,var(--color-btn-counter-bg,rgba(31,35,40,0.08)));}/*!sc*/.izDscS[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.izDscS[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.izDscS[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.izDscS[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.izDscS[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.izDscS[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.izDscS[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.izDscS[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.izDscS[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.izDscS[data-block=\"block\"]{width:100%;}/*!sc*/.izDscS[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.izDscS[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.izDscS [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.izDscS [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.izDscS [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.izDscS [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.izDscS [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.izDscS [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.izDscS:hover:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-hover,var(--color-btn-hover-bg,#f3f4f6));border-color:var(--button-default-borderColor-hover,var(--button-default-borderColor-hover,var(--color-btn-hover-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS:active:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS[aria-expanded=true]{background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.izDscS [data-component=\"leadingVisual\"],.izDscS [data-component=\"trailingVisual\"],.izDscS [data-component=\"trailingAction\"]{color:var(--button-color,var(--fgColor-muted,var(--color-fg-muted,#656d76)));}/*!sc*/.izDscS{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/.izDscS svg{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.izDscS > span{width:inherit;}/*!sc*/.cuOWTR{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.cuOWTR:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.cuOWTR:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.cuOWTR:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.cuOWTR[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.cuOWTR[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.cuOWTR:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.cuOWTR:active{-webkit-transition:none;transition:none;}/*!sc*/.cuOWTR[data-inactive]{cursor:auto;}/*!sc*/.cuOWTR:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.cuOWTR:disabled [data-component=ButtonCounter],.cuOWTR:disabled [data-component=\"leadingVisual\"],.cuOWTR:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.cuOWTR:focus{outline:solid 1px transparent;}}/*!sc*/.cuOWTR [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.cuOWTR[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.cuOWTR[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.cuOWTR[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.cuOWTR[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.cuOWTR[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.cuOWTR[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.cuOWTR[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.cuOWTR[data-block=\"block\"]{width:100%;}/*!sc*/.cuOWTR[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.cuOWTR[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.cuOWTR [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.cuOWTR [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.cuOWTR [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.cuOWTR [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.cuOWTR:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.cuOWTR:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.cuOWTR[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.cuOWTR[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.cuOWTR[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.cuOWTR:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.cuOWTR:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.cuOWTR:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.cuOWTR{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));padding-left:4px;padding-right:4px;}/*!sc*/.cuOWTR span[data-component=\"leadingVisual\"]{margin-right:4px !important;}/*!sc*/.tDSzd{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.tDSzd:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.tDSzd:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.tDSzd:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.tDSzd[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.tDSzd[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.tDSzd:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.tDSzd:active{-webkit-transition:none;transition:none;}/*!sc*/.tDSzd[data-inactive]{cursor:auto;}/*!sc*/.tDSzd:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.tDSzd:disabled [data-component=ButtonCounter],.tDSzd:disabled [data-component=\"leadingVisual\"],.tDSzd:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.tDSzd:focus{outline:solid 1px transparent;}}/*!sc*/.tDSzd [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.tDSzd[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.tDSzd[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.tDSzd[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.tDSzd[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.tDSzd[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.tDSzd[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.tDSzd[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.tDSzd[data-block=\"block\"]{width:100%;}/*!sc*/.tDSzd[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.tDSzd[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.tDSzd [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.tDSzd [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.tDSzd [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.tDSzd [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.tDSzd:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.tDSzd:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.tDSzd[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.tDSzd[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd[data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.tDSzd:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.tDSzd:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.tDSzd:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.ftZGca{border-radius:6px;border:1px solid;border-color:var(--button-default-borderColor-rest,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:var(--button-default-bgColor-rest,var(--color-btn-bg,#f6f8fa));box-shadow:var(--button-default-shadow-resting,var(--color-btn-shadow,0 1px 0 rgba(31,35,40,0.04))),var(--button-default-shadow-inset,var(--color-btn-inset-shadow,inset 0 1px 0 rgba(255,255,255,0.25)));}/*!sc*/.ftZGca:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.ftZGca:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.ftZGca:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.ftZGca[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.ftZGca[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.ftZGca:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.ftZGca:active{-webkit-transition:none;transition:none;}/*!sc*/.ftZGca[data-inactive]{cursor:auto;}/*!sc*/.ftZGca:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));border-color:var(--button-default-borderColor-disabled,var(--button-default-borderColor-rest,var(--color-btn-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.ftZGca:focus{outline:solid 1px transparent;}}/*!sc*/.ftZGca [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-default-bgColor-rest,var(--color-btn-counter-bg,rgba(31,35,40,0.08)));}/*!sc*/.ftZGca[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.ftZGca[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.ftZGca[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.ftZGca[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.ftZGca[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.ftZGca[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.ftZGca[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.ftZGca[data-block=\"block\"]{width:100%;}/*!sc*/.ftZGca[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.ftZGca[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.ftZGca [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.ftZGca [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.ftZGca [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.ftZGca [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.ftZGca [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.ftZGca [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.ftZGca:hover:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-hover,var(--color-btn-hover-bg,#f3f4f6));border-color:var(--button-default-borderColor-hover,var(--button-default-borderColor-hover,var(--color-btn-hover-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca:active:not([disabled]):not([data-inactive]){background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca[aria-expanded=true]{background-color:var(--button-default-bgColor-active,var(--color-btn-active-bg,hsla(220,14%,93%,1)));border-color:var(--button-default-borderColor-active,var(--button-default-borderColor-active,var(--color-btn-active-border,rgba(31,35,40,0.15))));}/*!sc*/.ftZGca [data-component=\"leadingVisual\"],.ftZGca [data-component=\"trailingVisual\"],.ftZGca [data-component=\"trailingAction\"]{color:var(--button-color,var(--fgColor-muted,var(--color-fg-muted,#656d76)));}/*!sc*/.gYvpXq{border-radius:6px;border:1px solid;border-color:var(--button-primary-borderColor-rest,var(--color-btn-primary-border,rgba(31,35,40,0.15)));font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-primary-fgColor-rest,var(--color-btn-primary-text,#ffffff));background-color:var(--button-primary-bgColor-rest,var(--color-btn-primary-bg,#1f883d));box-shadow:var(--shadow-resting-small,var(--color-btn-primary-shadow,0 1px 0 rgba(31,35,40,0.1)));}/*!sc*/.gYvpXq:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.gYvpXq:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.gYvpXq:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.gYvpXq[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.gYvpXq[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.gYvpXq:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.gYvpXq:active{-webkit-transition:none;transition:none;}/*!sc*/.gYvpXq[data-inactive]{cursor:auto;}/*!sc*/.gYvpXq:disabled{cursor:not-allowed;box-shadow:none;color:var(--button-primary-fgColor-disabled,var(--color-btn-primary-disabled-text,rgba(255,255,255,0.8)));background-color:var(--button-primary-bgColor-disabled,var(--color-btn-primary-disabled-bg,#94d3a2));border-color:var(--button-primary-borderColor-disabled,var(--color-btn-primary-disabled-border,rgba(31,35,40,0.15)));}/*!sc*/.gYvpXq:disabled [data-component=ButtonCounter]{color:inherit;}/*!sc*/@media (forced-colors:active){.gYvpXq:focus{outline:solid 1px transparent;}}/*!sc*/.gYvpXq [data-component=ButtonCounter]{font-size:12px;background-color:var(--buttonCounter-primary-bgColor-rest,var(--color-btn-primary-counter-bg,rgba(0,45,17,0.2)));color:var(--button-primary-fgColor-rest,var(--color-btn-primary-text,#ffffff));}/*!sc*/.gYvpXq[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.gYvpXq[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.gYvpXq[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.gYvpXq[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.gYvpXq[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.gYvpXq[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.gYvpXq[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.gYvpXq[data-block=\"block\"]{width:100%;}/*!sc*/.gYvpXq[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.gYvpXq[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.gYvpXq [data-component=\"leadingVisual\"]{grid-area:leadingVisual;}/*!sc*/.gYvpXq [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.gYvpXq [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.gYvpXq [data-component=\"trailingAction\"]{margin-right:-4px;}/*!sc*/.gYvpXq [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.gYvpXq [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.gYvpXq:hover:not([disabled]):not([data-inactive]){color:btn.primary.hoverText;background-color:var(--button-primary-bgColor-hover,var(--color-btn-primary-hover-bg,#1a7f37));}/*!sc*/.gYvpXq:focus:not([disabled]){box-shadow:inset 0 0 0 3px;}/*!sc*/.gYvpXq:focus-visible:not([disabled]){box-shadow:inset 0 0 0 3px;}/*!sc*/.gYvpXq:active:not([disabled]):not([data-inactive]){background-color:var(--button-primary-bgColor-active,var(--color-btn-primary-selected-bg,hsla(137,66%,28%,1)));box-shadow:var(--button-primary-shadow-selected,var(--color-btn-primary-selected-shadow,inset 0 1px 0 rgba(0,45,17,0.2)));}/*!sc*/.gYvpXq[aria-expanded=true]{background-color:var(--button-primary-bgColor-active,var(--color-btn-primary-selected-bg,hsla(137,66%,28%,1)));box-shadow:var(--button-primary-shadow-selected,var(--color-btn-primary-selected-shadow,inset 0 1px 0 rgba(0,45,17,0.2)));}/*!sc*/.gYvpXq svg{color:fg.primary;}/*!sc*/.fAkXQN{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--fgColor-default,var(--color-fg-default,#1F2328));background-color:transparent;box-shadow:none;}/*!sc*/.fAkXQN:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.fAkXQN:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.fAkXQN:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.fAkXQN[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.fAkXQN[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.fAkXQN:active{-webkit-transition:none;transition:none;}/*!sc*/.fAkXQN[data-inactive]{cursor:auto;}/*!sc*/.fAkXQN:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.fAkXQN:disabled [data-component=ButtonCounter],.fAkXQN:disabled [data-component=\"leadingVisual\"],.fAkXQN:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.fAkXQN:focus{outline:solid 1px transparent;}}/*!sc*/.fAkXQN [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.fAkXQN[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.fAkXQN[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.fAkXQN[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.fAkXQN[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.fAkXQN[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.fAkXQN[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.fAkXQN[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.fAkXQN[data-block=\"block\"]{width:100%;}/*!sc*/.fAkXQN[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.fAkXQN[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.fAkXQN [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.fAkXQN [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.fAkXQN [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.fAkXQN [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.fAkXQN:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.fAkXQN[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.fAkXQN[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.fAkXQN[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.fAkXQN:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.fAkXQN:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.fAkXQN:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.fAkXQN:focus:not([disabled]){-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.jPraEl{border-radius:6px;border:1px solid;border-color:transparent;font-family:inherit;font-weight:500;font-size:14px;cursor:pointer;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:32px;padding:0 12px;gap:8px;min-width:-webkit-max-content;min-width:-moz-max-content;min-width:max-content;-webkit-transition:80ms cubic-bezier(0.65,0,0.35,1);transition:80ms cubic-bezier(0.65,0,0.35,1);-webkit-transition-property:color,fill,background-color,border-color;transition-property:color,fill,background-color,border-color;color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));background-color:transparent;box-shadow:none;}/*!sc*/.jPraEl:focus:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.jPraEl:focus:not(:disabled):not(:focus-visible){outline:solid 1px transparent;}/*!sc*/.jPraEl:focus-visible:not(:disabled){box-shadow:none;outline:2px solid var(--fgColor-accent,var(--color-accent-fg,#0969da));outline-offset:-2px;}/*!sc*/.jPraEl[href]{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}/*!sc*/.jPraEl[href]:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/.jPraEl:hover{-webkit-transition-duration:80ms;transition-duration:80ms;}/*!sc*/.jPraEl:active{-webkit-transition:none;transition:none;}/*!sc*/.jPraEl[data-inactive]{cursor:auto;}/*!sc*/.jPraEl:disabled{cursor:not-allowed;box-shadow:none;color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.jPraEl:disabled [data-component=ButtonCounter],.jPraEl:disabled [data-component=\"leadingVisual\"],.jPraEl:disabled [data-component=\"trailingAction\"]{color:inherit;}/*!sc*/@media (forced-colors:active){.jPraEl:focus{outline:solid 1px transparent;}}/*!sc*/.jPraEl [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.jPraEl[data-component=IconButton]{display:inline-grid;padding:unset;place-content:center;width:32px;min-width:unset;}/*!sc*/.jPraEl[data-size=\"small\"]{padding:0 8px;height:28px;gap:4px;font-size:12px;}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=\"text\"]{line-height:calc(20 / 12);}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=ButtonCounter]{font-size:12px;}/*!sc*/.jPraEl[data-size=\"small\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:4px;}/*!sc*/.jPraEl[data-size=\"small\"][data-component=IconButton]{width:28px;padding:unset;}/*!sc*/.jPraEl[data-size=\"large\"]{padding:0 16px;height:40px;gap:8px;}/*!sc*/.jPraEl[data-size=\"large\"] [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.jPraEl[data-size=\"large\"][data-component=IconButton]{width:40px;padding:unset;}/*!sc*/.jPraEl[data-block=\"block\"]{width:100%;}/*!sc*/.jPraEl[data-inactive]:not([disabled]){background-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));border-color:var(--button-inactive-bgColor,var(--button-inactive-bgColor-rest,var(--color-btn-inactive-bg,#eaeef2)));color:var(--button-inactive-fgColor,var(--button-inactive-fgColor-rest,var(--color-btn-inactive-text,#57606a)));}/*!sc*/.jPraEl[data-inactive]:not([disabled]):focus-visible{box-shadow:none;}/*!sc*/.jPraEl [data-component=\"leadingVisual\"]{grid-area:leadingVisual;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl [data-component=\"text\"]{grid-area:text;line-height:calc(20/14);white-space:nowrap;}/*!sc*/.jPraEl [data-component=\"trailingVisual\"]{grid-area:trailingVisual;}/*!sc*/.jPraEl [data-component=\"trailingAction\"]{margin-right:-4px;color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl [data-component=\"buttonContent\"]{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:grid;grid-template-areas:\"leadingVisual text trailingVisual\";grid-template-columns:min-content minmax(0,auto) min-content;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/.jPraEl [data-component=\"buttonContent\"] > :not(:last-child){margin-right:8px;}/*!sc*/.jPraEl:hover:not([disabled]){background-color:var(--control-transparent-bgColor-hover,var(--color-action-list-item-default-hover-bg,rgba(208,215,222,0.32)));}/*!sc*/.jPraEl:active:not([disabled]){background-color:var(--control-transparent-bgColor-active,var(--color-action-list-item-default-active-bg,rgba(208,215,222,0.48)));}/*!sc*/.jPraEl[aria-expanded=true]{background-color:var(--control-transparent-bgColor-selected,var(--color-action-list-item-default-selected-bg,rgba(208,215,222,0.24)));}/*!sc*/.jPraEl[data-component=\"IconButton\"][data-no-visuals]{color:var(--fgColor-muted,var(--color-fg-muted,#656d76));}/*!sc*/.jPraEl[data-no-visuals]{color:var(--fgColor-accent,var(--color-accent-fg,#0969da));}/*!sc*/.jPraEl:has([data-component=\"ButtonCounter\"]){color:var(--button-default-fgColor-rest,var(--color-btn-text,#24292f));}/*!sc*/.jPraEl:disabled[data-no-visuals]{color:var(--fgColor-disabled,var(--color-primer-fg-disabled,#8c959f));}/*!sc*/.jPraEl:disabled[data-no-visuals] [data-component=ButtonCounter]{color:inherit;}/*!sc*/.jPraEl{color:var(--fgColor-muted,var(--color-fg-subtle,#6e7781));padding-left:8px;padding-right:8px;}/*!sc*/data-styled.g9[id=\"types__StyledButton-sc-ws60qy-0\"]{content:\"izDscS,cuOWTR,tDSzd,ftZGca,gYvpXq,fAkXQN,jPraEl,\"}/*!sc*/.rTZSs{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;-webkit-clip:rect(0,0,0,0);clip:rect(0,0,0,0);white-space:nowrap;border-width:0;}/*!sc*/data-styled.g10[id=\"_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0\"]{content:\"rTZSs,\"}/*!sc*/.fUpWeN{display:inline-block;overflow:hidden;text-overflow:ellipsis;vertical-align:top;white-space:nowrap;max-width:125px;max-width:100%;}/*!sc*/data-styled.g15[id=\"Truncate__StyledTruncate-sc-23o1d2-0\"]{content:\"fUpWeN,\"}/*!sc*/.dMjscx{position:relative;display:inline-block;}/*!sc*/.dMjscx::before{position:absolute;z-index:1000001;display:none;width:0px;height:0px;color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));pointer-events:none;content:'';border:6px solid transparent;opacity:0;}/*!sc*/.dMjscx::after{position:absolute;z-index:1000000;display:none;padding:0.5em 0.75em;font:normal normal 11px/1.5 -apple-system,BlinkMacSystemFont,\"Segoe UI\",\"Noto Sans\",Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\";-webkit-font-smoothing:subpixel-antialiased;color:var(--fgColor-onEmphasis,var(--color-fg-on-emphasis,#ffffff));text-align:center;-webkit-text-decoration:none;text-decoration:none;text-shadow:none;text-transform:none;-webkit-letter-spacing:normal;-moz-letter-spacing:normal;-ms-letter-spacing:normal;letter-spacing:normal;word-wrap:break-word;white-space:pre;pointer-events:none;content:attr(aria-label);background:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));border-radius:6px;opacity:0;}/*!sc*/@-webkit-keyframes tooltip-appear{from{opacity:0;}to{opacity:1;}}/*!sc*/@keyframes tooltip-appear{from{opacity:0;}to{opacity:1;}}/*!sc*/.dMjscx:hover::before,.dMjscx:active::before,.dMjscx:focus::before,.dMjscx:focus-within::before,.dMjscx:hover::after,.dMjscx:active::after,.dMjscx:focus::after,.dMjscx:focus-within::after{display:inline-block;-webkit-text-decoration:none;text-decoration:none;-webkit-animation-name:tooltip-appear;animation-name:tooltip-appear;-webkit-animation-duration:0.1s;animation-duration:0.1s;-webkit-animation-fill-mode:forwards;animation-fill-mode:forwards;-webkit-animation-timing-function:ease-in;animation-timing-function:ease-in;-webkit-animation-delay:0.4s;animation-delay:0.4s;}/*!sc*/.dMjscx.tooltipped-no-delay:hover::before,.dMjscx.tooltipped-no-delay:active::before,.dMjscx.tooltipped-no-delay:focus::before,.dMjscx.tooltipped-no-delay:focus-within::before,.dMjscx.tooltipped-no-delay:hover::after,.dMjscx.tooltipped-no-delay:active::after,.dMjscx.tooltipped-no-delay:focus::after,.dMjscx.tooltipped-no-delay:focus-within::after{-webkit-animation-delay:0s;animation-delay:0s;}/*!sc*/.dMjscx.tooltipped-multiline:hover::after,.dMjscx.tooltipped-multiline:active::after,.dMjscx.tooltipped-multiline:focus::after,.dMjscx.tooltipped-multiline:focus-within::after{display:table-cell;}/*!sc*/.dMjscx.tooltipped-s::after,.dMjscx.tooltipped-se::after,.dMjscx.tooltipped-sw::after{top:100%;right:50%;margin-top:6px;}/*!sc*/.dMjscx.tooltipped-s::before,.dMjscx.tooltipped-se::before,.dMjscx.tooltipped-sw::before{top:auto;right:50%;bottom:-7px;margin-right:-6px;border-bottom-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-se::after{right:auto;left:50%;margin-left:-16px;}/*!sc*/.dMjscx.tooltipped-sw::after{margin-right:-16px;}/*!sc*/.dMjscx.tooltipped-n::after,.dMjscx.tooltipped-ne::after,.dMjscx.tooltipped-nw::after{right:50%;bottom:100%;margin-bottom:6px;}/*!sc*/.dMjscx.tooltipped-n::before,.dMjscx.tooltipped-ne::before,.dMjscx.tooltipped-nw::before{top:-7px;right:50%;bottom:auto;margin-right:-6px;border-top-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-ne::after{right:auto;left:50%;margin-left:-16px;}/*!sc*/.dMjscx.tooltipped-nw::after{margin-right:-16px;}/*!sc*/.dMjscx.tooltipped-s::after,.dMjscx.tooltipped-n::after{-webkit-transform:translateX(50%);-ms-transform:translateX(50%);transform:translateX(50%);}/*!sc*/.dMjscx.tooltipped-w::after{right:100%;bottom:50%;margin-right:6px;-webkit-transform:translateY(50%);-ms-transform:translateY(50%);transform:translateY(50%);}/*!sc*/.dMjscx.tooltipped-w::before{top:50%;bottom:50%;left:-7px;margin-top:-6px;border-left-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-e::after{bottom:50%;left:100%;margin-left:6px;-webkit-transform:translateY(50%);-ms-transform:translateY(50%);transform:translateY(50%);}/*!sc*/.dMjscx.tooltipped-e::before{top:50%;right:-7px;bottom:50%;margin-top:-6px;border-right-color:var(--bgColor-emphasis,var(--color-neutral-emphasis-plus,#24292f));}/*!sc*/.dMjscx.tooltipped-multiline::after{width:-webkit-max-content;width:-moz-max-content;width:max-content;max-width:250px;word-wrap:break-word;white-space:pre-line;border-collapse:separate;}/*!sc*/.dMjscx.tooltipped-multiline.tooltipped-s::after,.dMjscx.tooltipped-multiline.tooltipped-n::after{right:auto;left:50%;-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%);transform:translateX(-50%);}/*!sc*/.dMjscx.tooltipped-multiline.tooltipped-w::after,.dMjscx.tooltipped-multiline.tooltipped-e::after{right:100%;}/*!sc*/.dMjscx.tooltipped-align-right-2::after{right:0;margin-right:0;}/*!sc*/.dMjscx.tooltipped-align-right-2::before{right:15px;}/*!sc*/.dMjscx.tooltipped-align-left-2::after{left:0;margin-left:0;}/*!sc*/.dMjscx.tooltipped-align-left-2::before{left:10px;}/*!sc*/data-styled.g18[id=\"Tooltip__TooltipBase-sc-17tf59c-0\"]{content:\"dMjscx,\"}/*!sc*/.bPgibo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;list-style:none;white-space:nowrap;padding-top:0;padding-bottom:0;padding-left:0;padding-right:0;margin:0;margin-bottom:-1px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:8px;position:relative;}/*!sc*/data-styled.g103[id=\"UnderlineNav__NavigationList-sc-1jfr31k-0\"]{content:\"bPgibo,\"}/*!sc*/</style> <!-- --> <!-- --> <div class=\"Box-sc-g0xbh4-0 izjvBm\"><div class=\"Box-sc-g0xbh4-0 rPQgy\"><div class=\"Box-sc-g0xbh4-0 eUMEDg\"></div></div><div class=\"Box-sc-g0xbh4-0 eLcVee\"><div class=\"Box-sc-g0xbh4-0 hsfLlq\"><div class=\"Box-sc-g0xbh4-0 gpKoUz\"><button type=\"button\" id=\"branch-picker-repos-header-ref-selector\" aria-haspopup=\"true\" tabindex=\"0\" aria-label=\"main branch\" data-testid=\"anchor-button\" class=\"types__StyledButton-sc-ws60qy-0 izDscS overview-ref-selector\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"text\"><div class=\"Box-sc-g0xbh4-0 bKgizp\"><div class=\"Box-sc-g0xbh4-0 iPGYsi\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></div><div class=\"Box-sc-g0xbh4-0 dKmYfk ref-selector-button-text-container\"><span class=\"Text-sc-17v1xeu-0 bOMzPg\">\u00a0<!-- -->main</span></div></div></span><span data-component=\"trailingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-triangle-down\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></span></span></button><button hidden=\"\" data-hotkey-scope=\"read-only-cursor-text-area\"></button></div><div class=\"Box-sc-g0xbh4-0 laYubZ\"><a style=\"--button-color:fg.muted\" type=\"button\" href=\"/huggingface/pytorch-image-models/branches\" class=\"types__StyledButton-sc-ws60qy-0 cuOWTR\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></span><span data-component=\"text\">Branches</span></span></a><a style=\"--button-color:fg.muted\" type=\"button\" href=\"/huggingface/pytorch-image-models/tags\" class=\"types__StyledButton-sc-ws60qy-0 cuOWTR\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-tag\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg></span><span data-component=\"text\">Tags</span></span></a></div><div class=\"Box-sc-g0xbh4-0 swnaL\"><a style=\"--button-color:fg.muted\" type=\"button\" aria-label=\"Go to Branches page\" href=\"/huggingface/pytorch-image-models/branches\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 tDSzd\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-git-branch\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\"></path></svg></a><a style=\"--button-color:fg.muted\" type=\"button\" aria-label=\"Go to Tags page\" href=\"/huggingface/pytorch-image-models/tags\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 tDSzd\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-tag\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg></a></div></div><div class=\"Box-sc-g0xbh4-0 bWpuBf\"><div class=\"Box-sc-g0xbh4-0 grHjNb\"><div class=\"Box-sc-g0xbh4-0 dXTsqj\"><!--$!--><template></template><!--/$--></div><div class=\"Box-sc-g0xbh4-0 dCOrmu\"><button type=\"button\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 ftZGca\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"text\">Go to file</span></span></button></div><div class=\"react-directory-add-file-icon\"></div><div class=\"react-directory-remove-file-icon\"></div></div><button type=\"button\" id=\":R2il5:\" aria-haspopup=\"true\" tabindex=\"0\" class=\"types__StyledButton-sc-ws60qy-0 gYvpXq\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><div class=\"Box-sc-g0xbh4-0 bVvbgP\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-code\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\"></path></svg></div></span><span data-component=\"text\">Code</span></span><span data-component=\"trailingAction\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-triangle-down\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\"></path></svg></span></button><div class=\"Box-sc-g0xbh4-0 bNDvfp\"><button data-component=\"IconButton\" type=\"button\" aria-label=\"Open more actions menu\" id=\":R3il5:\" aria-haspopup=\"true\" tabindex=\"0\" data-no-visuals=\"true\" class=\"types__StyledButton-sc-ws60qy-0 ftZGca\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-kebab-horizontal\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\"></path></svg></button></div></div></div><div class=\"Box-sc-g0xbh4-0 yfPnm\"><div data-hpc=\"true\" class=\"Box-sc-g0xbh4-0\"><button hidden=\"\" data-testid=\"focus-next-element-button\" data-hotkey=\"j\" data-hotkey-scope=\"read-only-cursor-text-area\"></button><button hidden=\"\" data-hotkey=\"j\"></button><button hidden=\"\" data-testid=\"focus-previous-element-button\" data-hotkey=\"k\" data-hotkey-scope=\"read-only-cursor-text-area\"></button><button hidden=\"\" data-hotkey=\"k\"></button><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\" id=\"folders-and-files\">Folders and files</h2><table aria-labelledby=\"folders-and-files\" class=\"Box-sc-g0xbh4-0 cAQuiW\"><thead class=\"Box-sc-g0xbh4-0 iiUlLN\"><tr class=\"Box-sc-g0xbh4-0 jmggSN\"><th colSpan=\"2\" class=\"Box-sc-g0xbh4-0 kvYunM\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Name</span></th><th colSpan=\"1\" class=\"Box-sc-g0xbh4-0 hrLuxA\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Name</span></th><th class=\"Box-sc-g0xbh4-0 ePjhhA\"><div title=\"Last commit message\" class=\"Truncate__StyledTruncate-sc-23o1d2-0 fUpWeN\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Last commit message</span></div></th><th colSpan=\"1\" class=\"Box-sc-g0xbh4-0 cuEKae\"><div title=\"Last commit date\" class=\"Truncate__StyledTruncate-sc-23o1d2-0 fUpWeN\"><span class=\"Text-sc-17v1xeu-0 eUGNHp\">Last commit date</span></div></th></tr></thead><tbody><tr class=\"Box-sc-g0xbh4-0 jEbBOT\"><td colSpan=\"3\" class=\"Box-sc-g0xbh4-0 bTxCvM\"><div class=\"Box-sc-g0xbh4-0 eYedVD\"><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\">Latest commit</h2><div style=\"width:120px\" class=\"Skeleton Skeleton--text\" data-testid=\"loading\">\u00a0</div><div class=\"Box-sc-g0xbh4-0 jGfYmh\"><div data-testid=\"latest-commit-details\" class=\"Box-sc-g0xbh4-0 lhFvfi\"></div><h2 class=\"Heading__StyledHeading-sc-1c1dgg0-0 cgQnMS sr-only\" data-testid=\"screen-reader-heading\">History</h2><a class=\"types__StyledButton-sc-ws60qy-0 fAkXQN react-last-commit-history-group\" href=\"/huggingface/pytorch-image-models/commits/main/\" data-size=\"small\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-history\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></span><span data-component=\"text\"><span class=\"Text-sc-17v1xeu-0 dALsKK\">2,172 Commits</span></span></span></a><div class=\"Box-sc-g0xbh4-0 bqgLjk\"></div><span role=\"tooltip\" aria-label=\"Commit history\" class=\"Tooltip__TooltipBase-sc-17tf59c-0 dMjscx tooltipped-n\"><a class=\"types__StyledButton-sc-ws60qy-0 fAkXQN react-last-commit-history-icon\" href=\"/huggingface/pytorch-image-models/commits/main/\"><span data-component=\"buttonContent\" class=\"Box-sc-g0xbh4-0 kkrdEu\"><span data-component=\"leadingVisual\" class=\"Box-sc-g0xbh4-0 trpoQ\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-history\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\"></path></svg></span></span></a></span></div></div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-0\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".github\" aria-label=\".github, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/.github\">.github</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".github\" aria-label=\".github, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/.github\">.github</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-1\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"convert\" aria-label=\"convert, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/convert\">convert</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"convert\" aria-label=\"convert, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/convert\">convert</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-2\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"docs\" aria-label=\"docs, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/docs\">docs</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"docs\" aria-label=\"docs, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/docs\">docs</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-3\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"hfdocs\" aria-label=\"hfdocs, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/hfdocs\">hfdocs</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"hfdocs\" aria-label=\"hfdocs, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/hfdocs\">hfdocs</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-4\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"results\" aria-label=\"results, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/results\">results</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"results\" aria-label=\"results, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/results\">results</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-5\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"tests\" aria-label=\"tests, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/tests\">tests</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"tests\" aria-label=\"tests, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/tests\">tests</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-6\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"timm\" aria-label=\"timm, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/timm\">timm</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"icon-directory\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"timm\" aria-label=\"timm, (Directory)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/tree/main/timm\">timm</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-7\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".gitattributes\" aria-label=\".gitattributes, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/.gitattributes\">.gitattributes</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".gitattributes\" aria-label=\".gitattributes, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/.gitattributes\">.gitattributes</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-8\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".gitignore\" aria-label=\".gitignore, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/.gitignore\">.gitignore</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\".gitignore\" aria-label=\".gitignore, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/.gitignore\">.gitignore</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row undefined\" id=\"folder-row-9\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"CONTRIBUTING.md\" aria-label=\"CONTRIBUTING.md, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/CONTRIBUTING.md\">CONTRIBUTING.md</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"CONTRIBUTING.md\" aria-label=\"CONTRIBUTING.md, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/CONTRIBUTING.md\">CONTRIBUTING.md</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-10\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"LICENSE\" aria-label=\"LICENSE, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/LICENSE\">LICENSE</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"LICENSE\" aria-label=\"LICENSE, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/LICENSE\">LICENSE</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-11\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"MANIFEST.in\" aria-label=\"MANIFEST.in, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/MANIFEST.in\">MANIFEST.in</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"MANIFEST.in\" aria-label=\"MANIFEST.in, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/MANIFEST.in\">MANIFEST.in</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-12\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"README.md\" aria-label=\"README.md, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/README.md\">README.md</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"README.md\" aria-label=\"README.md, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/README.md\">README.md</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-13\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"avg_checkpoints.py\" aria-label=\"avg_checkpoints.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/avg_checkpoints.py\">avg_checkpoints.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"avg_checkpoints.py\" aria-label=\"avg_checkpoints.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/avg_checkpoints.py\">avg_checkpoints.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-14\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"benchmark.py\" aria-label=\"benchmark.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/benchmark.py\">benchmark.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"benchmark.py\" aria-label=\"benchmark.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/benchmark.py\">benchmark.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-15\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"bulk_runner.py\" aria-label=\"bulk_runner.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/bulk_runner.py\">bulk_runner.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"bulk_runner.py\" aria-label=\"bulk_runner.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/bulk_runner.py\">bulk_runner.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-16\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"clean_checkpoint.py\" aria-label=\"clean_checkpoint.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/clean_checkpoint.py\">clean_checkpoint.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"clean_checkpoint.py\" aria-label=\"clean_checkpoint.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/clean_checkpoint.py\">clean_checkpoint.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-17\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"distributed_train.sh\" aria-label=\"distributed_train.sh, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/distributed_train.sh\">distributed_train.sh</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"distributed_train.sh\" aria-label=\"distributed_train.sh, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/distributed_train.sh\">distributed_train.sh</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-18\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"hubconf.py\" aria-label=\"hubconf.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/hubconf.py\">hubconf.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"hubconf.py\" aria-label=\"hubconf.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/hubconf.py\">hubconf.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-19\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"inference.py\" aria-label=\"inference.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/inference.py\">inference.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"inference.py\" aria-label=\"inference.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/inference.py\">inference.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-20\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"mkdocs.yml\" aria-label=\"mkdocs.yml, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/mkdocs.yml\">mkdocs.yml</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"mkdocs.yml\" aria-label=\"mkdocs.yml, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/mkdocs.yml\">mkdocs.yml</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-21\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"model-index.yml\" aria-label=\"model-index.yml, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/model-index.yml\">model-index.yml</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"model-index.yml\" aria-label=\"model-index.yml, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/model-index.yml\">model-index.yml</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-22\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"onnx_export.py\" aria-label=\"onnx_export.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/onnx_export.py\">onnx_export.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"onnx_export.py\" aria-label=\"onnx_export.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/onnx_export.py\">onnx_export.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-23\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"onnx_validate.py\" aria-label=\"onnx_validate.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/onnx_validate.py\">onnx_validate.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"onnx_validate.py\" aria-label=\"onnx_validate.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/onnx_validate.py\">onnx_validate.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-24\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"pyproject.toml\" aria-label=\"pyproject.toml, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/pyproject.toml\">pyproject.toml</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"pyproject.toml\" aria-label=\"pyproject.toml, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/pyproject.toml\">pyproject.toml</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-25\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"requirements-dev.txt\" aria-label=\"requirements-dev.txt, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/requirements-dev.txt\">requirements-dev.txt</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"requirements-dev.txt\" aria-label=\"requirements-dev.txt, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/requirements-dev.txt\">requirements-dev.txt</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-26\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"requirements.txt\" aria-label=\"requirements.txt, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/requirements.txt\">requirements.txt</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"requirements.txt\" aria-label=\"requirements.txt, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/requirements.txt\">requirements.txt</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-27\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"setup.cfg\" aria-label=\"setup.cfg, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/setup.cfg\">setup.cfg</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"setup.cfg\" aria-label=\"setup.cfg, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/setup.cfg\">setup.cfg</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-28\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"train.py\" aria-label=\"train.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/train.py\">train.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"train.py\" aria-label=\"train.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/train.py\">train.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"react-directory-row truncate-for-mobile\" id=\"folder-row-29\"><td class=\"react-directory-row-name-cell-small-screen\" colSpan=\"2\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"validate.py\" aria-label=\"validate.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/validate.py\">validate.py</a></div></h3></div></div></td><td class=\"react-directory-row-name-cell-large-screen\" colSpan=\"1\"><div class=\"react-directory-filename-column\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"color-fg-muted\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\"></path></svg><div class=\"overflow-hidden\"><h3><div class=\"react-directory-truncate\"><a title=\"validate.py\" aria-label=\"validate.py, (File)\" class=\"Link--primary\" href=\"/huggingface/pytorch-image-models/blob/main/validate.py\">validate.py</a></div></h3></div></div></td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\u00a0</div></td><td><div class=\"Skeleton Skeleton--text\">\u00a0</div></td></tr><tr class=\"Box-sc-g0xbh4-0 epsqEd show-for-mobile\" data-testid=\"view-all-files-row\"><td colSpan=\"3\" class=\"Box-sc-g0xbh4-0 ldpruc\"><div><button class=\"Link__StyledLink-sc-14289xe-0 dheQRw\">View all files</button></div></td></tr></tbody></table></div><div class=\"Box-sc-g0xbh4-0 ehcSsh\"><div class=\"Box-sc-g0xbh4-0 iGmlUb\"><div class=\"Box-sc-g0xbh4-0 iRQGXA\"><h2 class=\"_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0 rTZSs\">Repository files navigation</h2><nav aria-label=\"Repository files\" class=\"Box-sc-g0xbh4-0 dvTdPK\"><ul role=\"list\" class=\"UnderlineNav__NavigationList-sc-1jfr31k-0 bPgibo\"><li class=\"Box-sc-g0xbh4-0 gwuIGu\"><a href=\"#\" aria-current=\"page\" class=\"Link__StyledLink-sc-14289xe-0 vLMkZ\"><span data-component=\"icon\" class=\"Box-sc-g0xbh4-0 kOxwQs\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-book\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg></span><span data-component=\"text\" data-content=\"README\" class=\"Box-sc-g0xbh4-0 kOgeFj\">README</span></a></li><li class=\"Box-sc-g0xbh4-0 gwuIGu\"><a href=\"#\" class=\"Link__StyledLink-sc-14289xe-0 bhqztV\"><span data-component=\"icon\" class=\"Box-sc-g0xbh4-0 kOxwQs\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-law\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg></span><span data-component=\"text\" data-content=\"Apache-2.0 license\" class=\"Box-sc-g0xbh4-0\">Apache-2.0 license</span></a></li></ul></nav><button style=\"--button-color:fg.subtle\" type=\"button\" aria-label=\"Outline\" id=\":Rdkl5:\" aria-haspopup=\"true\" tabindex=\"0\" class=\"types__StyledButton-sc-ws60qy-0 jPraEl\"><svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-list-unordered\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path d=\"M5.75 2.5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2 14a1 1 0 1 1 0-2 1 1 0 0 1 0 2Zm1-6a1 1 0 1 1-2 0 1 1 0 0 1 2 0ZM2 4a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z\"></path></svg></button></div><div class=\"Box-sc-g0xbh4-0 bJMeLZ js-snippet-clipboard-copy-unpositioned\" data-hpc=\"true\"><article class=\"markdown-body entry-content container-lg\" itemprop=\"text\"><div class=\"markdown-heading\" dir=\"auto\"><h1 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">PyTorch Image Models</h1><a id=\"user-content-pytorch-image-models\" class=\"anchor-element\" aria-label=\"Permalink: PyTorch Image Models\" href=\"#pytorch-image-models\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li><a href=\"#whats-new\">What's New</a></li><li><a href=\"#introduction\">Introduction</a></li><li><a href=\"#models\">Models</a></li><li><a href=\"#features\">Features</a></li><li><a href=\"#results\">Results</a></li><li><a href=\"#getting-started-documentation\">Getting Started (Documentation)</a></li><li><a href=\"#train-validation-inference-scripts\">Train, Validation, Inference Scripts</a></li><li><a href=\"#awesome-pytorch-resources\">Awesome PyTorch Resources</a></li><li><a href=\"#licenses\">Licenses</a></li><li><a href=\"#citing\">Citing</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">What's New</h2><a id=\"user-content-whats-new\" class=\"anchor-element\" aria-label=\"Permalink: What's New\" href=\"#whats-new\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">\u2757Updates after Oct 10, 2022 are available in version &gt;= 0.9\u2757</p><ul dir=\"auto\"><li>Many changes since the last 0.6.x stable releases. They were previewed in 0.8.x dev releases but not everyone transitioned.</li><li><code>timm.models.layers</code> moved to <code>timm.layers</code>:<ul dir=\"auto\"><li><code>from timm.models.layers import name</code> will still work via deprecation mapping (but please transition to <code>timm.layers</code>).</li><li><code>import timm.models.layers.module</code> or <code>from timm.models.layers.module import name</code> needs to be changed now.</li></ul></li><li>Builder, helper, non-model modules in <code>timm.models</code> have a <code>_</code> prefix added, ie <code>timm.models.helpers</code> -&gt; <code>timm.models._helpers</code>, there are temporary deprecation mapping files but those will be removed.</li><li>All models now support <code>architecture.pretrained_tag</code> naming (ex <code>resnet50.rsb_a1</code>).<ul dir=\"auto\"><li>The pretrained_tag is the specific weight variant (different head) for the architecture.</li><li>Using only <code>architecture</code> defaults to the first weights in the default_cfgs for that model architecture.</li><li>In adding pretrained tags, many model names that existed to differentiate were renamed to use the tag  (ex: <code>vit_base_patch16_224_in21k</code> -&gt; <code>vit_base_patch16_224.augreg_in21k</code>). There are deprecation mappings for these.</li></ul></li><li>A number of models had their checkpoints remaped to match architecture changes needed to better support <code>features_only=True</code>, there are <code>checkpoint_filter_fn</code> methods in any model module that was remapped. These can be passed to <code>timm.models.load_checkpoint(..., filter_fn=timm.models.swin_transformer_v2.checkpoint_filter_fn)</code> to remap your existing checkpoint.</li><li>The Hugging Face Hub (<a href=\"https://huggingface.co/timm\" rel=\"nofollow\">https://huggingface.co/timm</a>) is now the primary source for <code>timm</code> weights. Model cards include link to papers, original source, license.</li><li>Previous 0.6.x can be cloned from <a href=\"https://github.com/rwightman/pytorch-image-models/tree/0.6.x\">0.6.x</a> branch or installed via pip with version.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Feb 19, 2024</h3><a id=\"user-content-feb-19-2024\" class=\"anchor-element\" aria-label=\"Permalink: Feb 19, 2024\" href=\"#feb-19-2024\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Next-ViT models added. Adapted from <a href=\"https://github.com/bytedance/Next-ViT\">https://github.com/bytedance/Next-ViT</a></li><li>HGNet and PP-HGNetV2 models added. Adapted from <a href=\"https://github.com/PaddlePaddle/PaddleClas\">https://github.com/PaddlePaddle/PaddleClas</a> by <a href=\"https://github.com/seefun\">SeeFun</a></li><li>Removed setup.py, moved to pyproject.toml based build supported by PDM</li><li>Add updated model EMA impl using _for_each for less overhead</li><li>Support device args in train script for non GPU devices</li><li>Other misc fixes and small additions</li><li>Min supported Python version increased to 3.8</li><li>Release 0.9.16</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Jan 8, 2024</h3><a id=\"user-content-jan-8-2024\" class=\"anchor-element\" aria-label=\"Permalink: Jan 8, 2024\" href=\"#jan-8-2024\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Datasets &amp; transform refactoring</p><ul dir=\"auto\"><li>HuggingFace streaming (iterable) dataset support (<code>--dataset hfids:org/dataset</code>)</li><li>Webdataset wrapper tweaks for improved split info fetching, can auto fetch splits from supported HF hub webdataset</li><li>Tested HF <code>datasets</code> and webdataset wrapper streaming from HF hub with recent <code>timm</code> ImageNet uploads to <a href=\"https://huggingface.co/timm\" rel=\"nofollow\">https://huggingface.co/timm</a></li><li>Make input &amp; target column/field keys consistent across datasets and pass via args</li><li>Full monochrome support when using e:g: <code>--input-size 1 224 224</code> or <code>--in-chans 1</code>, sets PIL image conversion appropriately in dataset</li><li>Improved several alternate crop &amp; resize transforms (ResizeKeepRatio, RandomCropOrPad, etc) for use in PixParse document AI project</li><li>Add SimCLR style color jitter prob along with grayscale and gaussian blur options to augmentations and args</li><li>Allow train without validation set (<code>--val-split ''</code>) in train script</li><li>Add <code>--bce-sum</code> (sum over class dim) and <code>--bce-pos-weight</code> (positive weighting) args for training as they're common BCE loss tweaks I was often hard coding</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Nov 23, 2023</h3><a id=\"user-content-nov-23-2023\" class=\"anchor-element\" aria-label=\"Permalink: Nov 23, 2023\" href=\"#nov-23-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Added EfficientViT-Large models, thanks <a href=\"https://github.com/seefun\">SeeFun</a></li><li>Fix Python 3.7 compat, will be dropping support for it soon</li><li>Other misc fixes</li><li>Release 0.9.12</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Nov 20, 2023</h3><a id=\"user-content-nov-20-2023\" class=\"anchor-element\" aria-label=\"Permalink: Nov 20, 2023\" href=\"#nov-20-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Added significant flexibility for Hugging Face Hub based timm models via <code>model_args</code> config entry. <code>model_args</code> will be passed as kwargs through to models on creation.<ul dir=\"auto\"><li>See example at <a href=\"https://huggingface.co/gaunernst/vit_base_patch16_1024_128.audiomae_as2m_ft_as20k/blob/main/config.json\" rel=\"nofollow\">https://huggingface.co/gaunernst/vit_base_patch16_1024_128.audiomae_as2m_ft_as20k/blob/main/config.json</a></li><li>Usage: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"5862092\" data-permission-text=\"Title is private\" data-url=\"https://github.com/huggingface/pytorch-image-models/discussions/2035\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/huggingface/pytorch-image-models/discussions/2035/hovercard\" href=\"https://github.com/huggingface/pytorch-image-models/discussions/2035\">#2035</a></li></ul></li><li>Updated imagenet eval and test set csv files with latest models</li><li><code>vision_transformer.py</code> typing and doc cleanup by <a href=\"https://github.com/Laurent2916\">Laure\u03b7t</a></li><li>0.9.11 release</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Nov 3, 2023</h3><a id=\"user-content-nov-3-2023\" class=\"anchor-element\" aria-label=\"Permalink: Nov 3, 2023\" href=\"#nov-3-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li><a href=\"https://huggingface.co/papers/2309.17425\" rel=\"nofollow\">DFN (Data Filtering Networks)</a> and <a href=\"https://huggingface.co/papers/2309.16671\" rel=\"nofollow\">MetaCLIP</a> ViT weights added</li><li>DINOv2 'register' ViT model weights added (<a href=\"https://huggingface.co/papers/2309.16588\" rel=\"nofollow\">https://huggingface.co/papers/2309.16588</a>, <a href=\"https://huggingface.co/papers/2304.07193\" rel=\"nofollow\">https://huggingface.co/papers/2304.07193</a>)</li><li>Add <code>quickgelu</code> ViT variants for OpenAI, DFN, MetaCLIP weights that use it (less efficient)</li><li>Improved typing added to ResNet, MobileNet-v3 thanks to <a href=\"https://github.com/a-r-r-o-w\">Aryan</a></li><li>ImageNet-12k fine-tuned (from LAION-2B CLIP) <code>convnext_xxlarge</code></li><li>0.9.9 release</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Oct 20, 2023</h3><a id=\"user-content-oct-20-2023\" class=\"anchor-element\" aria-label=\"Permalink: Oct 20, 2023\" href=\"#oct-20-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li><a href=\"https://huggingface.co/papers/2303.15343\" rel=\"nofollow\">SigLIP</a> image tower weights supported in <code>vision_transformer.py</code>.<ul dir=\"auto\"><li>Great potential for fine-tune and downstream feature use.</li></ul></li><li>Experimental 'register' support in vit models as per <a href=\"https://huggingface.co/papers/2309.16588\" rel=\"nofollow\">Vision Transformers Need Registers</a></li><li>Updated RepViT with new weight release. Thanks <a href=\"https://github.com/jameslahm\">wangao</a></li><li>Add patch resizing support (on pretrained weight load) to Swin models</li><li>0.9.8 release pending</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Sep 1, 2023</h3><a id=\"user-content-sep-1-2023\" class=\"anchor-element\" aria-label=\"Permalink: Sep 1, 2023\" href=\"#sep-1-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>TinyViT added by <a href=\"https://github.com/seefun\">SeeFun</a></li><li>Fix EfficientViT (MIT) to use torch.autocast so it works back to PT 1.10</li><li>0.9.7 release</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Aug 28, 2023</h3><a id=\"user-content-aug-28-2023\" class=\"anchor-element\" aria-label=\"Permalink: Aug 28, 2023\" href=\"#aug-28-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Add dynamic img size support to models in <code>vision_transformer.py</code>, <code>vision_transformer_hybrid.py</code>, <code>deit.py</code>, and <code>eva.py</code> w/o breaking backward compat.<ul dir=\"auto\"><li>Add <code>dynamic_img_size=True</code> to args at model creation time to allow changing the grid size (interpolate abs and/or ROPE pos embed each forward pass).</li><li>Add <code>dynamic_img_pad=True</code> to allow image sizes that aren't divisible by patch size (pad bottom right to patch size each forward pass).</li><li>Enabling either dynamic mode will break FX tracing unless PatchEmbed module added as leaf.</li><li>Existing method of resizing position embedding by passing different <code>img_size</code> (interpolate pretrained embed weights once) on creation still works.</li><li>Existing method of changing <code>patch_size</code> (resize pretrained patch_embed weights once) on creation still works.</li><li>Example validation cmd <code>python validate.py /imagenet --model vit_base_patch16_224 --amp --amp-dtype bfloat16 --img-size 255 --crop-pct 1.0 --model-kwargs dynamic_img_size=True dyamic_img_pad=True</code></li></ul></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Aug 25, 2023</h3><a id=\"user-content-aug-25-2023\" class=\"anchor-element\" aria-label=\"Permalink: Aug 25, 2023\" href=\"#aug-25-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Many new models since last release<ul dir=\"auto\"><li>FastViT - <a href=\"https://arxiv.org/abs/2303.14189\" rel=\"nofollow\">https://arxiv.org/abs/2303.14189</a></li><li>MobileOne - <a href=\"https://arxiv.org/abs/2206.04040\" rel=\"nofollow\">https://arxiv.org/abs/2206.04040</a></li><li>InceptionNeXt - <a href=\"https://arxiv.org/abs/2303.16900\" rel=\"nofollow\">https://arxiv.org/abs/2303.16900</a></li><li>RepGhostNet - <a href=\"https://arxiv.org/abs/2211.06088\" rel=\"nofollow\">https://arxiv.org/abs/2211.06088</a> (thanks <a href=\"https://github.com/ChengpengChen\">https://github.com/ChengpengChen</a>)</li><li>GhostNetV2 - <a href=\"https://arxiv.org/abs/2211.12905\" rel=\"nofollow\">https://arxiv.org/abs/2211.12905</a> (thanks <a href=\"https://github.com/yehuitang\">https://github.com/yehuitang</a>)</li><li>EfficientViT (MSRA) - <a href=\"https://arxiv.org/abs/2305.07027\" rel=\"nofollow\">https://arxiv.org/abs/2305.07027</a> (thanks <a href=\"https://github.com/seefun\">https://github.com/seefun</a>)</li><li>EfficientViT (MIT) - <a href=\"https://arxiv.org/abs/2205.14756\" rel=\"nofollow\">https://arxiv.org/abs/2205.14756</a> (thanks <a href=\"https://github.com/seefun\">https://github.com/seefun</a>)</li></ul></li><li>Add <code>--reparam</code> arg to <code>benchmark.py</code>, <code>onnx_export.py</code>, and <code>validate.py</code> to trigger layer reparameterization / fusion for models with any one of <code>reparameterize()</code>, <code>switch_to_deploy()</code> or <code>fuse()</code><ul dir=\"auto\"><li>Including FastViT, MobileOne, RepGhostNet, EfficientViT (MSRA), RepViT, RepVGG, and LeViT</li></ul></li><li>Preparing 0.9.6 'back to school' release</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Aug 11, 2023</h3><a id=\"user-content-aug-11-2023\" class=\"anchor-element\" aria-label=\"Permalink: Aug 11, 2023\" href=\"#aug-11-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Swin, MaxViT, CoAtNet, and BEiT models support resizing of image/window size on creation with adaptation of pretrained weights</li><li>Example validation cmd to test w/ non-square resize <code>python validate.py /imagenet --model swin_base_patch4_window7_224.ms_in22k_ft_in1k --amp --amp-dtype bfloat16 --input-size 3 256 320 --model-kwargs window_size=8,10 img_size=256,320</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Aug 3, 2023</h3><a id=\"user-content-aug-3-2023\" class=\"anchor-element\" aria-label=\"Permalink: Aug 3, 2023\" href=\"#aug-3-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Add GluonCV weights for HRNet w18_small and w18_small_v2. Converted by <a href=\"https://github.com/seefun\">SeeFun</a></li><li>Fix <code>selecsls*</code> model naming regression</li><li>Patch and position embedding for ViT/EVA works for bfloat16/float16 weights on load (or activations for on-the-fly resize)</li><li>v0.9.5 release prep</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">July 27, 2023</h3><a id=\"user-content-july-27-2023\" class=\"anchor-element\" aria-label=\"Permalink: July 27, 2023\" href=\"#july-27-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Added timm trained <code>seresnextaa201d_32x8d.sw_in12k_ft_in1k_384</code> weights (and <code>.sw_in12k</code> pretrain) with 87.3% top-1 on ImageNet-1k, best ImageNet ResNet family model I'm aware of.</li><li>RepViT model and weights (<a href=\"https://arxiv.org/abs/2307.09283\" rel=\"nofollow\">https://arxiv.org/abs/2307.09283</a>) added by <a href=\"https://github.com/jameslahm\">wangao</a></li><li>I-JEPA ViT feature weights (no classifier) added by <a href=\"https://github.com/seefun\">SeeFun</a></li><li>SAM-ViT (segment anything) feature weights (no classifier) added by <a href=\"https://github.com/seefun\">SeeFun</a></li><li>Add support for alternative feat extraction methods and -ve indices to EfficientNet</li><li>Add NAdamW optimizer</li><li>Misc fixes</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">May 11, 2023</h3><a id=\"user-content-may-11-2023\" class=\"anchor-element\" aria-label=\"Permalink: May 11, 2023\" href=\"#may-11-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li><code>timm</code> 0.9 released, transition from 0.8.xdev releases</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">May 10, 2023</h3><a id=\"user-content-may-10-2023\" class=\"anchor-element\" aria-label=\"Permalink: May 10, 2023\" href=\"#may-10-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Hugging Face Hub downloading is now default, 1132 models on <a href=\"https://huggingface.co/timm\" rel=\"nofollow\">https://huggingface.co/timm</a>, 1163 weights in <code>timm</code></li><li>DINOv2 vit feature backbone weights added thanks to <a href=\"https://github.com/leng-yue\">Leng Yue</a></li><li>FB MAE vit feature backbone weights added</li><li>OpenCLIP DataComp-XL L/14 feat backbone weights added</li><li>MetaFormer (poolformer-v2, caformer, convformer, updated poolformer (v1)) w/ weights added by <a href=\"https://github.com/fffffgggg54\">Fredo Guan</a></li><li>Experimental <code>get_intermediate_layers</code> function on vit/deit models for grabbing hidden states (inspired by DINO impl). This is WIP and may change significantly... feedback welcome.</li><li>Model creation throws error if <code>pretrained=True</code> and no weights exist (instead of continuing with random initialization)</li><li>Fix regression with inception / nasnet TF sourced weights with 1001 classes in original classifiers</li><li>bitsandbytes (<a href=\"https://github.com/TimDettmers/bitsandbytes\">https://github.com/TimDettmers/bitsandbytes</a>) optimizers added to factory, use <code>bnb</code> prefix, ie <code>bnbadam8bit</code></li><li>Misc cleanup and fixes</li><li>Final testing before switching to a 0.9 and bringing <code>timm</code> out of pre-release state</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">April 27, 2023</h3><a id=\"user-content-april-27-2023\" class=\"anchor-element\" aria-label=\"Permalink: April 27, 2023\" href=\"#april-27-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>97% of <code>timm</code> models uploaded to HF Hub and almost all updated to support multi-weight pretrained configs</li><li>Minor cleanup and refactoring of another batch of models as multi-weight added. More fused_attn (F.sdpa) and features_only support, and torchscript fixes.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">April 21, 2023</h3><a id=\"user-content-april-21-2023\" class=\"anchor-element\" aria-label=\"Permalink: April 21, 2023\" href=\"#april-21-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Gradient accumulation support added to train script and tested (<code>--grad-accum-steps</code>), thanks <a href=\"https://github.com/voidbag\">Taeksang Kim</a></li><li>More weights on HF Hub (cspnet, cait, volo, xcit, tresnet, hardcorenas, densenet, dpn, vovnet, xception_aligned)</li><li>Added <code>--head-init-scale</code> and <code>--head-init-bias</code> to train.py to scale classiifer head and set fixed bias for fine-tune</li><li>Remove all InplaceABN (<code>inplace_abn</code>) use, replaced use in tresnet with standard BatchNorm (modified weights accordingly).</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">April 12, 2023</h3><a id=\"user-content-april-12-2023\" class=\"anchor-element\" aria-label=\"Permalink: April 12, 2023\" href=\"#april-12-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Add ONNX export script, validate script, helpers that I've had kicking around for along time. Tweak 'same' padding for better export w/ recent ONNX + pytorch.</li><li>Refactor dropout args for vit and vit-like models, separate drop_rate into <code>drop_rate</code> (classifier dropout), <code>proj_drop_rate</code> (block mlp / out projections), <code>pos_drop_rate</code> (position embedding drop), <code>attn_drop_rate</code> (attention dropout). Also add patch dropout (FLIP) to vit and eva models.</li><li>fused F.scaled_dot_product_attention support to more vit models, add env var (TIMM_FUSED_ATTN) to control, and config interface to enable/disable</li><li>Add EVA-CLIP backbones w/ image tower weights, all the way up to 4B param 'enormous' model, and 336x336 OpenAI ViT mode that was missed.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">April 5, 2023</h3><a id=\"user-content-april-5-2023\" class=\"anchor-element\" aria-label=\"Permalink: April 5, 2023\" href=\"#april-5-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>ALL ResNet models pushed to Hugging Face Hub with multi-weight support<ul dir=\"auto\"><li>All past <code>timm</code> trained weights added with recipe based tags to differentiate</li><li>All ResNet strikes back A1/A2/A3 (seed 0) and R50 example B/C1/C2/D weights available</li><li>Add torchvision v2 recipe weights to existing torchvision originals</li><li>See comparison table in <a href=\"https://huggingface.co/timm/seresnextaa101d_32x8d.sw_in12k_ft_in1k_288#model-comparison\" rel=\"nofollow\">https://huggingface.co/timm/seresnextaa101d_32x8d.sw_in12k_ft_in1k_288#model-comparison</a></li></ul></li><li>New ImageNet-12k + ImageNet-1k fine-tunes available for a few anti-aliased ResNet models<ul dir=\"auto\"><li><code>resnetaa50d.sw_in12k_ft_in1k</code> - 81.7 @ 224, 82.6 @ 288</li><li><code>resnetaa101d.sw_in12k_ft_in1k</code> - 83.5 @ 224, 84.1 @ 288</li><li><code>seresnextaa101d_32x8d.sw_in12k_ft_in1k</code> - 86.0 @ 224, 86.5 @ 288</li><li><code>seresnextaa101d_32x8d.sw_in12k_ft_in1k_288</code> - 86.5 @ 288, 86.7 @ 320</li></ul></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">March 31, 2023</h3><a id=\"user-content-march-31-2023\" class=\"anchor-element\" aria-label=\"Permalink: March 31, 2023\" href=\"#march-31-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Add first ConvNext-XXLarge CLIP -&gt; IN-1k fine-tune and IN-12k intermediate fine-tunes for convnext-base/large CLIP models.</li></ul><table><thead><tr><th>model</th><th>top1</th><th>top5</th><th>img_size</th><th>param_count</th><th>gmacs</th><th>macts</th></tr></thead><tbody><tr><td><a href=\"https://huggingface.co/timm/convnext_xxlarge.clip_laion2b_soup_ft_in1k\" rel=\"nofollow\">convnext_xxlarge.clip_laion2b_soup_ft_in1k</a></td><td>88.612</td><td>98.704</td><td>256</td><td>846.47</td><td>198.09</td><td>124.45</td></tr><tr><td>convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384</td><td>88.312</td><td>98.578</td><td>384</td><td>200.13</td><td>101.11</td><td>126.74</td></tr><tr><td>convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320</td><td>87.968</td><td>98.47</td><td>320</td><td>200.13</td><td>70.21</td><td>88.02</td></tr><tr><td>convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384</td><td>87.138</td><td>98.212</td><td>384</td><td>88.59</td><td>45.21</td><td>84.49</td></tr><tr><td>convnext_base.clip_laion2b_augreg_ft_in12k_in1k</td><td>86.344</td><td>97.97</td><td>256</td><td>88.59</td><td>20.09</td><td>37.55</td></tr></tbody></table><ul dir=\"auto\"><li>Add EVA-02 MIM pretrained and fine-tuned weights, push to HF hub and update model cards for all EVA models. First model over 90% top-1 (99% top-5)! Check out the original code &amp; weights at <a href=\"https://github.com/baaivision/EVA\">https://github.com/baaivision/EVA</a> for more details on their work blending MIM, CLIP w/ many model, dataset, and train recipe tweaks.</li></ul><table><thead><tr><th>model</th><th>top1</th><th>top5</th><th>param_count</th><th>img_size</th></tr></thead><tbody><tr><td><a href=\"https://huggingface.co/timm/eva02_large_patch14_448.mim_m38m_ft_in1k\" rel=\"nofollow\">eva02_large_patch14_448.mim_m38m_ft_in22k_in1k</a></td><td>90.054</td><td>99.042</td><td>305.08</td><td>448</td></tr><tr><td>eva02_large_patch14_448.mim_in22k_ft_in22k_in1k</td><td>89.946</td><td>99.01</td><td>305.08</td><td>448</td></tr><tr><td>eva_giant_patch14_560.m30m_ft_in22k_in1k</td><td>89.792</td><td>98.992</td><td>1014.45</td><td>560</td></tr><tr><td>eva02_large_patch14_448.mim_in22k_ft_in1k</td><td>89.626</td><td>98.954</td><td>305.08</td><td>448</td></tr><tr><td>eva02_large_patch14_448.mim_m38m_ft_in1k</td><td>89.57</td><td>98.918</td><td>305.08</td><td>448</td></tr><tr><td>eva_giant_patch14_336.m30m_ft_in22k_in1k</td><td>89.56</td><td>98.956</td><td>1013.01</td><td>336</td></tr><tr><td>eva_giant_patch14_336.clip_ft_in1k</td><td>89.466</td><td>98.82</td><td>1013.01</td><td>336</td></tr><tr><td>eva_large_patch14_336.in22k_ft_in22k_in1k</td><td>89.214</td><td>98.854</td><td>304.53</td><td>336</td></tr><tr><td>eva_giant_patch14_224.clip_ft_in1k</td><td>88.882</td><td>98.678</td><td>1012.56</td><td>224</td></tr><tr><td>eva02_base_patch14_448.mim_in22k_ft_in22k_in1k</td><td>88.692</td><td>98.722</td><td>87.12</td><td>448</td></tr><tr><td>eva_large_patch14_336.in22k_ft_in1k</td><td>88.652</td><td>98.722</td><td>304.53</td><td>336</td></tr><tr><td>eva_large_patch14_196.in22k_ft_in22k_in1k</td><td>88.592</td><td>98.656</td><td>304.14</td><td>196</td></tr><tr><td>eva02_base_patch14_448.mim_in22k_ft_in1k</td><td>88.23</td><td>98.564</td><td>87.12</td><td>448</td></tr><tr><td>eva_large_patch14_196.in22k_ft_in1k</td><td>87.934</td><td>98.504</td><td>304.14</td><td>196</td></tr><tr><td>eva02_small_patch14_336.mim_in22k_ft_in1k</td><td>85.74</td><td>97.614</td><td>22.13</td><td>336</td></tr><tr><td>eva02_tiny_patch14_336.mim_in22k_ft_in1k</td><td>80.658</td><td>95.524</td><td>5.76</td><td>336</td></tr></tbody></table><ul dir=\"auto\"><li>Multi-weight and HF hub for DeiT and MLP-Mixer based models</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">March 22, 2023</h3><a id=\"user-content-march-22-2023\" class=\"anchor-element\" aria-label=\"Permalink: March 22, 2023\" href=\"#march-22-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>More weights pushed to HF hub along with multi-weight support, including: <code>regnet.py</code>, <code>rexnet.py</code>, <code>byobnet.py</code>, <code>resnetv2.py</code>, <code>swin_transformer.py</code>, <code>swin_transformer_v2.py</code>, <code>swin_transformer_v2_cr.py</code></li><li>Swin Transformer models support feature extraction (NCHW feat maps for <code>swinv2_cr_*</code>, and NHWC for all others) and spatial embedding outputs.</li><li>FocalNet (from <a href=\"https://github.com/microsoft/FocalNet\">https://github.com/microsoft/FocalNet</a>) models and weights added with significant refactoring, feature extraction, no fixed resolution / sizing constraint</li><li>RegNet weights increased with HF hub push, SWAG, SEER, and torchvision v2 weights. SEER is pretty poor wrt to performance for model size, but possibly useful.</li><li>More ImageNet-12k pretrained and 1k fine-tuned <code>timm</code> weights:<ul dir=\"auto\"><li><code>rexnetr_200.sw_in12k_ft_in1k</code> - 82.6 @ 224, 83.2 @ 288</li><li><code>rexnetr_300.sw_in12k_ft_in1k</code> - 84.0 @ 224, 84.5 @ 288</li><li><code>regnety_120.sw_in12k_ft_in1k</code> - 85.0 @ 224, 85.4 @ 288</li><li><code>regnety_160.lion_in12k_ft_in1k</code> - 85.6 @ 224, 86.0 @ 288</li><li><code>regnety_160.sw_in12k_ft_in1k</code> - 85.6 @ 224, 86.0 @ 288  (compare to SWAG PT + 1k FT this is same BUT much lower res, blows SEER FT away)</li></ul></li><li>Model name deprecation + remapping functionality added (a milestone for bringing 0.8.x out of pre-release). Mappings being added...</li><li>Minor bug fixes and improvements.</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Feb 26, 2023</h3><a id=\"user-content-feb-26-2023\" class=\"anchor-element\" aria-label=\"Permalink: Feb 26, 2023\" href=\"#feb-26-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Add ConvNeXt-XXLarge CLIP pretrained image tower weights for fine-tune &amp; features (fine-tuning TBD) -- see <a href=\"https://huggingface.co/laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-soup\" rel=\"nofollow\">model card</a></li><li>Update <code>convnext_xxlarge</code> default LayerNorm eps to 1e-5 (for CLIP weights, improved stability)</li><li>0.8.15dev0</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Feb 20, 2023</h3><a id=\"user-content-feb-20-2023\" class=\"anchor-element\" aria-label=\"Permalink: Feb 20, 2023\" href=\"#feb-20-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Add 320x320 <code>convnext_large_mlp.clip_laion2b_ft_320</code> and <code>convnext_lage_mlp.clip_laion2b_ft_soup_320</code> CLIP image tower weights for features &amp; fine-tune</li><li>0.8.13dev0 pypi release for latest changes w/ move to huggingface org</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Feb 16, 2023</h3><a id=\"user-content-feb-16-2023\" class=\"anchor-element\" aria-label=\"Permalink: Feb 16, 2023\" href=\"#feb-16-2023\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li><code>safetensor</code> checkpoint support added</li><li>Add ideas from 'Scaling Vision Transformers to 22 B. Params' (<a href=\"https://arxiv.org/abs/2302.05442\" rel=\"nofollow\">https://arxiv.org/abs/2302.05442</a>) -- qk norm, RmsNorm, parallel block</li><li>Add F.scaled_dot_product_attention support (PyTorch 2.0 only) to <code>vit_*</code>, <code>vit_relpos*</code>, <code>coatnet</code> / <code>maxxvit</code> (to start)</li><li>Lion optimizer (w/ multi-tensor option) added (<a href=\"https://arxiv.org/abs/2302.06675\" rel=\"nofollow\">https://arxiv.org/abs/2302.06675</a>)</li><li>gradient checkpointing works with <code>features_only=True</code></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Introduction</h2><a id=\"user-content-introduction\" class=\"anchor-element\" aria-label=\"Permalink: Introduction\" href=\"#introduction\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Py<strong>T</strong>orch <strong>Im</strong>age <strong>M</strong>odels (<code>timm</code>) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.</p><p dir=\"auto\">The work of many others is present here. I've tried to make sure all source material is acknowledged via links to github, arxiv papers, etc in the README, documentation, and code docstrings. Please let me know if I missed anything.</p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Features</h2><a id=\"user-content-features\" class=\"anchor-element\" aria-label=\"Permalink: Features\" href=\"#features\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Models</h3><a id=\"user-content-models\" class=\"anchor-element\" aria-label=\"Permalink: Models\" href=\"#models\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">All model architecture families include variants with pretrained weights. There are specific model variants without any weights, it is NOT a bug. Help training new or better weights is always appreciated.</p><ul dir=\"auto\"><li>Aggregating Nested Transformers - <a href=\"https://arxiv.org/abs/2105.12723\" rel=\"nofollow\">https://arxiv.org/abs/2105.12723</a></li><li>BEiT - <a href=\"https://arxiv.org/abs/2106.08254\" rel=\"nofollow\">https://arxiv.org/abs/2106.08254</a></li><li>Big Transfer ResNetV2 (BiT) - <a href=\"https://arxiv.org/abs/1912.11370\" rel=\"nofollow\">https://arxiv.org/abs/1912.11370</a></li><li>Bottleneck Transformers - <a href=\"https://arxiv.org/abs/2101.11605\" rel=\"nofollow\">https://arxiv.org/abs/2101.11605</a></li><li>CaiT (Class-Attention in Image Transformers) - <a href=\"https://arxiv.org/abs/2103.17239\" rel=\"nofollow\">https://arxiv.org/abs/2103.17239</a></li><li>CoaT (Co-Scale Conv-Attentional Image Transformers) - <a href=\"https://arxiv.org/abs/2104.06399\" rel=\"nofollow\">https://arxiv.org/abs/2104.06399</a></li><li>CoAtNet (Convolution and Attention) - <a href=\"https://arxiv.org/abs/2106.04803\" rel=\"nofollow\">https://arxiv.org/abs/2106.04803</a></li><li>ConvNeXt - <a href=\"https://arxiv.org/abs/2201.03545\" rel=\"nofollow\">https://arxiv.org/abs/2201.03545</a></li><li>ConvNeXt-V2 - <a href=\"http://arxiv.org/abs/2301.00808\" rel=\"nofollow\">http://arxiv.org/abs/2301.00808</a></li><li>ConViT (Soft Convolutional Inductive Biases Vision Transformers)- <a href=\"https://arxiv.org/abs/2103.10697\" rel=\"nofollow\">https://arxiv.org/abs/2103.10697</a></li><li>CspNet (Cross-Stage Partial Networks) - <a href=\"https://arxiv.org/abs/1911.11929\" rel=\"nofollow\">https://arxiv.org/abs/1911.11929</a></li><li>DeiT - <a href=\"https://arxiv.org/abs/2012.12877\" rel=\"nofollow\">https://arxiv.org/abs/2012.12877</a></li><li>DeiT-III - <a href=\"https://arxiv.org/pdf/2204.07118.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/2204.07118.pdf</a></li><li>DenseNet - <a href=\"https://arxiv.org/abs/1608.06993\" rel=\"nofollow\">https://arxiv.org/abs/1608.06993</a></li><li>DLA - <a href=\"https://arxiv.org/abs/1707.06484\" rel=\"nofollow\">https://arxiv.org/abs/1707.06484</a></li><li>DPN (Dual-Path Network) - <a href=\"https://arxiv.org/abs/1707.01629\" rel=\"nofollow\">https://arxiv.org/abs/1707.01629</a></li><li>EdgeNeXt - <a href=\"https://arxiv.org/abs/2206.10589\" rel=\"nofollow\">https://arxiv.org/abs/2206.10589</a></li><li>EfficientFormer - <a href=\"https://arxiv.org/abs/2206.01191\" rel=\"nofollow\">https://arxiv.org/abs/2206.01191</a></li><li>EfficientNet (MBConvNet Family)<ul dir=\"auto\"><li>EfficientNet NoisyStudent (B0-B7, L2) - <a href=\"https://arxiv.org/abs/1911.04252\" rel=\"nofollow\">https://arxiv.org/abs/1911.04252</a></li><li>EfficientNet AdvProp (B0-B8) - <a href=\"https://arxiv.org/abs/1911.09665\" rel=\"nofollow\">https://arxiv.org/abs/1911.09665</a></li><li>EfficientNet (B0-B7) - <a href=\"https://arxiv.org/abs/1905.11946\" rel=\"nofollow\">https://arxiv.org/abs/1905.11946</a></li><li>EfficientNet-EdgeTPU (S, M, L) - <a href=\"https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html\" rel=\"nofollow\">https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html</a></li><li>EfficientNet V2 - <a href=\"https://arxiv.org/abs/2104.00298\" rel=\"nofollow\">https://arxiv.org/abs/2104.00298</a></li><li>FBNet-C - <a href=\"https://arxiv.org/abs/1812.03443\" rel=\"nofollow\">https://arxiv.org/abs/1812.03443</a></li><li>MixNet - <a href=\"https://arxiv.org/abs/1907.09595\" rel=\"nofollow\">https://arxiv.org/abs/1907.09595</a></li><li>MNASNet B1, A1 (Squeeze-Excite), and Small - <a href=\"https://arxiv.org/abs/1807.11626\" rel=\"nofollow\">https://arxiv.org/abs/1807.11626</a></li><li>MobileNet-V2 - <a href=\"https://arxiv.org/abs/1801.04381\" rel=\"nofollow\">https://arxiv.org/abs/1801.04381</a></li><li>Single-Path NAS - <a href=\"https://arxiv.org/abs/1904.02877\" rel=\"nofollow\">https://arxiv.org/abs/1904.02877</a></li><li>TinyNet - <a href=\"https://arxiv.org/abs/2010.14819\" rel=\"nofollow\">https://arxiv.org/abs/2010.14819</a></li></ul></li><li>EfficientViT (MIT) - <a href=\"https://arxiv.org/abs/2205.14756\" rel=\"nofollow\">https://arxiv.org/abs/2205.14756</a></li><li>EfficientViT (MSRA) - <a href=\"https://arxiv.org/abs/2305.07027\" rel=\"nofollow\">https://arxiv.org/abs/2305.07027</a></li><li>EVA - <a href=\"https://arxiv.org/abs/2211.07636\" rel=\"nofollow\">https://arxiv.org/abs/2211.07636</a></li><li>EVA-02 - <a href=\"https://arxiv.org/abs/2303.11331\" rel=\"nofollow\">https://arxiv.org/abs/2303.11331</a></li><li>FastViT - <a href=\"https://arxiv.org/abs/2303.14189\" rel=\"nofollow\">https://arxiv.org/abs/2303.14189</a></li><li>FlexiViT - <a href=\"https://arxiv.org/abs/2212.08013\" rel=\"nofollow\">https://arxiv.org/abs/2212.08013</a></li><li>FocalNet (Focal Modulation Networks) - <a href=\"https://arxiv.org/abs/2203.11926\" rel=\"nofollow\">https://arxiv.org/abs/2203.11926</a></li><li>GCViT (Global Context Vision Transformer) - <a href=\"https://arxiv.org/abs/2206.09959\" rel=\"nofollow\">https://arxiv.org/abs/2206.09959</a></li><li>GhostNet - <a href=\"https://arxiv.org/abs/1911.11907\" rel=\"nofollow\">https://arxiv.org/abs/1911.11907</a></li><li>GhostNet-V2 - <a href=\"https://arxiv.org/abs/2211.12905\" rel=\"nofollow\">https://arxiv.org/abs/2211.12905</a></li><li>gMLP - <a href=\"https://arxiv.org/abs/2105.08050\" rel=\"nofollow\">https://arxiv.org/abs/2105.08050</a></li><li>GPU-Efficient Networks - <a href=\"https://arxiv.org/abs/2006.14090\" rel=\"nofollow\">https://arxiv.org/abs/2006.14090</a></li><li>Halo Nets - <a href=\"https://arxiv.org/abs/2103.12731\" rel=\"nofollow\">https://arxiv.org/abs/2103.12731</a></li><li>HGNet / HGNet-V2 - TBD</li><li>HRNet - <a href=\"https://arxiv.org/abs/1908.07919\" rel=\"nofollow\">https://arxiv.org/abs/1908.07919</a></li><li>InceptionNeXt - <a href=\"https://arxiv.org/abs/2303.16900\" rel=\"nofollow\">https://arxiv.org/abs/2303.16900</a></li><li>Inception-V3 - <a href=\"https://arxiv.org/abs/1512.00567\" rel=\"nofollow\">https://arxiv.org/abs/1512.00567</a></li><li>Inception-ResNet-V2 and Inception-V4 - <a href=\"https://arxiv.org/abs/1602.07261\" rel=\"nofollow\">https://arxiv.org/abs/1602.07261</a></li><li>Lambda Networks - <a href=\"https://arxiv.org/abs/2102.08602\" rel=\"nofollow\">https://arxiv.org/abs/2102.08602</a></li><li>LeViT (Vision Transformer in ConvNet's Clothing) - <a href=\"https://arxiv.org/abs/2104.01136\" rel=\"nofollow\">https://arxiv.org/abs/2104.01136</a></li><li>MaxViT (Multi-Axis Vision Transformer) - <a href=\"https://arxiv.org/abs/2204.01697\" rel=\"nofollow\">https://arxiv.org/abs/2204.01697</a></li><li>MetaFormer (PoolFormer-v2, ConvFormer, CAFormer) - <a href=\"https://arxiv.org/abs/2210.13452\" rel=\"nofollow\">https://arxiv.org/abs/2210.13452</a></li><li>MLP-Mixer - <a href=\"https://arxiv.org/abs/2105.01601\" rel=\"nofollow\">https://arxiv.org/abs/2105.01601</a></li><li>MobileNet-V3 (MBConvNet w/ Efficient Head) - <a href=\"https://arxiv.org/abs/1905.02244\" rel=\"nofollow\">https://arxiv.org/abs/1905.02244</a><ul dir=\"auto\"><li>FBNet-V3 - <a href=\"https://arxiv.org/abs/2006.02049\" rel=\"nofollow\">https://arxiv.org/abs/2006.02049</a></li><li>HardCoRe-NAS - <a href=\"https://arxiv.org/abs/2102.11646\" rel=\"nofollow\">https://arxiv.org/abs/2102.11646</a></li><li>LCNet - <a href=\"https://arxiv.org/abs/2109.15099\" rel=\"nofollow\">https://arxiv.org/abs/2109.15099</a></li></ul></li><li>MobileOne - <a href=\"https://arxiv.org/abs/2206.04040\" rel=\"nofollow\">https://arxiv.org/abs/2206.04040</a></li><li>MobileViT - <a href=\"https://arxiv.org/abs/2110.02178\" rel=\"nofollow\">https://arxiv.org/abs/2110.02178</a></li><li>MobileViT-V2 - <a href=\"https://arxiv.org/abs/2206.02680\" rel=\"nofollow\">https://arxiv.org/abs/2206.02680</a></li><li>MViT-V2 (Improved Multiscale Vision Transformer) - <a href=\"https://arxiv.org/abs/2112.01526\" rel=\"nofollow\">https://arxiv.org/abs/2112.01526</a></li><li>NASNet-A - <a href=\"https://arxiv.org/abs/1707.07012\" rel=\"nofollow\">https://arxiv.org/abs/1707.07012</a></li><li>NesT - <a href=\"https://arxiv.org/abs/2105.12723\" rel=\"nofollow\">https://arxiv.org/abs/2105.12723</a></li><li>Next-ViT - <a href=\"https://arxiv.org/abs/2207.05501\" rel=\"nofollow\">https://arxiv.org/abs/2207.05501</a></li><li>NFNet-F - <a href=\"https://arxiv.org/abs/2102.06171\" rel=\"nofollow\">https://arxiv.org/abs/2102.06171</a></li><li>NF-RegNet / NF-ResNet - <a href=\"https://arxiv.org/abs/2101.08692\" rel=\"nofollow\">https://arxiv.org/abs/2101.08692</a></li><li>PNasNet - <a href=\"https://arxiv.org/abs/1712.00559\" rel=\"nofollow\">https://arxiv.org/abs/1712.00559</a></li><li>PoolFormer (MetaFormer) - <a href=\"https://arxiv.org/abs/2111.11418\" rel=\"nofollow\">https://arxiv.org/abs/2111.11418</a></li><li>Pooling-based Vision Transformer (PiT) - <a href=\"https://arxiv.org/abs/2103.16302\" rel=\"nofollow\">https://arxiv.org/abs/2103.16302</a></li><li>PVT-V2 (Improved Pyramid Vision Transformer) - <a href=\"https://arxiv.org/abs/2106.13797\" rel=\"nofollow\">https://arxiv.org/abs/2106.13797</a></li><li>RegNet - <a href=\"https://arxiv.org/abs/2003.13678\" rel=\"nofollow\">https://arxiv.org/abs/2003.13678</a></li><li>RegNetZ - <a href=\"https://arxiv.org/abs/2103.06877\" rel=\"nofollow\">https://arxiv.org/abs/2103.06877</a></li><li>RepVGG - <a href=\"https://arxiv.org/abs/2101.03697\" rel=\"nofollow\">https://arxiv.org/abs/2101.03697</a></li><li>RepGhostNet - <a href=\"https://arxiv.org/abs/2211.06088\" rel=\"nofollow\">https://arxiv.org/abs/2211.06088</a></li><li>RepViT - <a href=\"https://arxiv.org/abs/2307.09283\" rel=\"nofollow\">https://arxiv.org/abs/2307.09283</a></li><li>ResMLP - <a href=\"https://arxiv.org/abs/2105.03404\" rel=\"nofollow\">https://arxiv.org/abs/2105.03404</a></li><li>ResNet/ResNeXt<ul dir=\"auto\"><li>ResNet (v1b/v1.5) - <a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow\">https://arxiv.org/abs/1512.03385</a></li><li>ResNeXt - <a href=\"https://arxiv.org/abs/1611.05431\" rel=\"nofollow\">https://arxiv.org/abs/1611.05431</a></li><li>'Bag of Tricks' / Gluon C, D, E, S variations - <a href=\"https://arxiv.org/abs/1812.01187\" rel=\"nofollow\">https://arxiv.org/abs/1812.01187</a></li><li>Weakly-supervised (WSL) Instagram pretrained / ImageNet tuned ResNeXt101 - <a href=\"https://arxiv.org/abs/1805.00932\" rel=\"nofollow\">https://arxiv.org/abs/1805.00932</a></li><li>Semi-supervised (SSL) / Semi-weakly Supervised (SWSL) ResNet/ResNeXts - <a href=\"https://arxiv.org/abs/1905.00546\" rel=\"nofollow\">https://arxiv.org/abs/1905.00546</a></li><li>ECA-Net (ECAResNet) - <a href=\"https://arxiv.org/abs/1910.03151v4\" rel=\"nofollow\">https://arxiv.org/abs/1910.03151v4</a></li><li>Squeeze-and-Excitation Networks (SEResNet) - <a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">https://arxiv.org/abs/1709.01507</a></li><li>ResNet-RS - <a href=\"https://arxiv.org/abs/2103.07579\" rel=\"nofollow\">https://arxiv.org/abs/2103.07579</a></li></ul></li><li>Res2Net - <a href=\"https://arxiv.org/abs/1904.01169\" rel=\"nofollow\">https://arxiv.org/abs/1904.01169</a></li><li>ResNeSt - <a href=\"https://arxiv.org/abs/2004.08955\" rel=\"nofollow\">https://arxiv.org/abs/2004.08955</a></li><li>ReXNet - <a href=\"https://arxiv.org/abs/2007.00992\" rel=\"nofollow\">https://arxiv.org/abs/2007.00992</a></li><li>SelecSLS - <a href=\"https://arxiv.org/abs/1907.00837\" rel=\"nofollow\">https://arxiv.org/abs/1907.00837</a></li><li>Selective Kernel Networks - <a href=\"https://arxiv.org/abs/1903.06586\" rel=\"nofollow\">https://arxiv.org/abs/1903.06586</a></li><li>Sequencer2D - <a href=\"https://arxiv.org/abs/2205.01972\" rel=\"nofollow\">https://arxiv.org/abs/2205.01972</a></li><li>Swin S3 (AutoFormerV2) - <a href=\"https://arxiv.org/abs/2111.14725\" rel=\"nofollow\">https://arxiv.org/abs/2111.14725</a></li><li>Swin Transformer - <a href=\"https://arxiv.org/abs/2103.14030\" rel=\"nofollow\">https://arxiv.org/abs/2103.14030</a></li><li>Swin Transformer V2 - <a href=\"https://arxiv.org/abs/2111.09883\" rel=\"nofollow\">https://arxiv.org/abs/2111.09883</a></li><li>Transformer-iN-Transformer (TNT) - <a href=\"https://arxiv.org/abs/2103.00112\" rel=\"nofollow\">https://arxiv.org/abs/2103.00112</a></li><li>TResNet - <a href=\"https://arxiv.org/abs/2003.13630\" rel=\"nofollow\">https://arxiv.org/abs/2003.13630</a></li><li>Twins (Spatial Attention in Vision Transformers) - <a href=\"https://arxiv.org/pdf/2104.13840.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/2104.13840.pdf</a></li><li>Visformer - <a href=\"https://arxiv.org/abs/2104.12533\" rel=\"nofollow\">https://arxiv.org/abs/2104.12533</a></li><li>Vision Transformer - <a href=\"https://arxiv.org/abs/2010.11929\" rel=\"nofollow\">https://arxiv.org/abs/2010.11929</a></li><li>VOLO (Vision Outlooker) - <a href=\"https://arxiv.org/abs/2106.13112\" rel=\"nofollow\">https://arxiv.org/abs/2106.13112</a></li><li>VovNet V2 and V1 - <a href=\"https://arxiv.org/abs/1911.06667\" rel=\"nofollow\">https://arxiv.org/abs/1911.06667</a></li><li>Xception - <a href=\"https://arxiv.org/abs/1610.02357\" rel=\"nofollow\">https://arxiv.org/abs/1610.02357</a></li><li>Xception (Modified Aligned, Gluon) - <a href=\"https://arxiv.org/abs/1802.02611\" rel=\"nofollow\">https://arxiv.org/abs/1802.02611</a></li><li>Xception (Modified Aligned, TF) - <a href=\"https://arxiv.org/abs/1802.02611\" rel=\"nofollow\">https://arxiv.org/abs/1802.02611</a></li><li>XCiT (Cross-Covariance Image Transformers) - <a href=\"https://arxiv.org/abs/2106.09681\" rel=\"nofollow\">https://arxiv.org/abs/2106.09681</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Optimizers</h3><a id=\"user-content-optimizers\" class=\"anchor-element\" aria-label=\"Permalink: Optimizers\" href=\"#optimizers\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Included optimizers available via <code>create_optimizer</code> / <code>create_optimizer_v2</code> factory methods:</p><ul dir=\"auto\"><li><code>adabelief</code> an implementation of AdaBelief adapted from <a href=\"https://github.com/juntang-zhuang/Adabelief-Optimizer\">https://github.com/juntang-zhuang/Adabelief-Optimizer</a> - <a href=\"https://arxiv.org/abs/2010.07468\" rel=\"nofollow\">https://arxiv.org/abs/2010.07468</a></li><li><code>adafactor</code> adapted from <a href=\"https://github.com/pytorch/fairseq/blob/master/fairseq/optim/adafactor.py\">FAIRSeq impl</a> - <a href=\"https://arxiv.org/abs/1804.04235\" rel=\"nofollow\">https://arxiv.org/abs/1804.04235</a></li><li><code>adahessian</code> by <a href=\"https://github.com/davda54/ada-hessian\">David Samuel</a> - <a href=\"https://arxiv.org/abs/2006.00719\" rel=\"nofollow\">https://arxiv.org/abs/2006.00719</a></li><li><code>adamp</code> and <code>sgdp</code> by <a href=\"https://github.com/clovaai\">Naver ClovAI</a> - <a href=\"https://arxiv.org/abs/2006.08217\" rel=\"nofollow\">https://arxiv.org/abs/2006.08217</a></li><li><code>adan</code> an implementation of Adan adapted from <a href=\"https://github.com/sail-sg/Adan\">https://github.com/sail-sg/Adan</a> - <a href=\"https://arxiv.org/abs/2208.06677\" rel=\"nofollow\">https://arxiv.org/abs/2208.06677</a></li><li><code>lamb</code> an implementation of Lamb and LambC (w/ trust-clipping) cleaned up and modified to support use with XLA - <a href=\"https://arxiv.org/abs/1904.00962\" rel=\"nofollow\">https://arxiv.org/abs/1904.00962</a></li><li><code>lars</code> an implementation of LARS and LARC (w/ trust-clipping) - <a href=\"https://arxiv.org/abs/1708.03888\" rel=\"nofollow\">https://arxiv.org/abs/1708.03888</a></li><li><code>lion</code> and implementation of Lion adapted from <a href=\"https://github.com/google/automl/tree/master/lion\">https://github.com/google/automl/tree/master/lion</a> - <a href=\"https://arxiv.org/abs/2302.06675\" rel=\"nofollow\">https://arxiv.org/abs/2302.06675</a></li><li><code>lookahead</code> adapted from impl by <a href=\"https://github.com/alphadl/lookahead.pytorch\">Liam</a> - <a href=\"https://arxiv.org/abs/1907.08610\" rel=\"nofollow\">https://arxiv.org/abs/1907.08610</a></li><li><code>madgrad</code> - and implementation of MADGRAD adapted from <a href=\"https://github.com/facebookresearch/madgrad\">https://github.com/facebookresearch/madgrad</a> - <a href=\"https://arxiv.org/abs/2101.11075\" rel=\"nofollow\">https://arxiv.org/abs/2101.11075</a></li><li><code>nadam</code> an implementation of Adam w/ Nesterov momentum</li><li><code>nadamw</code> an impementation of AdamW (Adam w/ decoupled weight-decay) w/ Nesterov momentum. A simplified impl based on <a href=\"https://github.com/mlcommons/algorithmic-efficiency\">https://github.com/mlcommons/algorithmic-efficiency</a></li><li><code>novograd</code> by <a href=\"https://github.com/convergence-lab/novograd\">Masashi Kimura</a> - <a href=\"https://arxiv.org/abs/1905.11286\" rel=\"nofollow\">https://arxiv.org/abs/1905.11286</a></li><li><code>radam</code> by <a href=\"https://github.com/LiyuanLucasLiu/RAdam\">Liyuan Liu</a> - <a href=\"https://arxiv.org/abs/1908.03265\" rel=\"nofollow\">https://arxiv.org/abs/1908.03265</a></li><li><code>rmsprop_tf</code> adapted from PyTorch RMSProp by myself. Reproduces much improved Tensorflow RMSProp behaviour</li><li><code>sgdw</code> and implementation of SGD w/ decoupled weight-decay</li><li><code>fused&lt;name&gt;</code> optimizers by name with <a href=\"https://github.com/NVIDIA/apex/tree/master/apex/optimizers\">NVIDIA Apex</a> installed</li><li><code>bits&lt;name&gt;</code> optimizers by name with <a href=\"https://github.com/TimDettmers/bitsandbytes\">BitsAndBytes</a> installed</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Augmentations</h3><a id=\"user-content-augmentations\" class=\"anchor-element\" aria-label=\"Permalink: Augmentations\" href=\"#augmentations\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Random Erasing from <a href=\"https://github.com/zhunzhong07/Random-Erasing/blob/master/transforms.py\">Zhun Zhong</a> - <a href=\"https://arxiv.org/abs/1708.04896\" rel=\"nofollow\">https://arxiv.org/abs/1708.04896</a>)</li><li>Mixup - <a href=\"https://arxiv.org/abs/1710.09412\" rel=\"nofollow\">https://arxiv.org/abs/1710.09412</a></li><li>CutMix - <a href=\"https://arxiv.org/abs/1905.04899\" rel=\"nofollow\">https://arxiv.org/abs/1905.04899</a></li><li>AutoAugment (<a href=\"https://arxiv.org/abs/1805.09501\" rel=\"nofollow\">https://arxiv.org/abs/1805.09501</a>) and RandAugment (<a href=\"https://arxiv.org/abs/1909.13719\" rel=\"nofollow\">https://arxiv.org/abs/1909.13719</a>) ImageNet configurations modeled after impl for EfficientNet training (<a href=\"https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py\">https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py</a>)</li><li>AugMix w/ JSD loss, JSD w/ clean + augmented mixing support works with AutoAugment and RandAugment as well - <a href=\"https://arxiv.org/abs/1912.02781\" rel=\"nofollow\">https://arxiv.org/abs/1912.02781</a></li><li>SplitBachNorm - allows splitting batch norm layers between clean and augmented (auxiliary batch norm) data</li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Regularization</h3><a id=\"user-content-regularization\" class=\"anchor-element\" aria-label=\"Permalink: Regularization\" href=\"#regularization\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>DropPath aka \"Stochastic Depth\" - <a href=\"https://arxiv.org/abs/1603.09382\" rel=\"nofollow\">https://arxiv.org/abs/1603.09382</a></li><li>DropBlock - <a href=\"https://arxiv.org/abs/1810.12890\" rel=\"nofollow\">https://arxiv.org/abs/1810.12890</a></li><li>Blur Pooling - <a href=\"https://arxiv.org/abs/1904.11486\" rel=\"nofollow\">https://arxiv.org/abs/1904.11486</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Other</h3><a id=\"user-content-other\" class=\"anchor-element\" aria-label=\"Permalink: Other\" href=\"#other\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Several (less common) features that I often utilize in my projects are included. Many of their additions are the reason why I maintain my own set of models, instead of using others' via PIP:</p><ul dir=\"auto\"><li>All models have a common default configuration interface and API for<ul dir=\"auto\"><li>accessing/changing the classifier - <code>get_classifier</code> and <code>reset_classifier</code></li><li>doing a forward pass on just the features - <code>forward_features</code> (see <a href=\"https://huggingface.co/docs/timm/feature_extraction\" rel=\"nofollow\">documentation</a>)</li><li>these makes it easy to write consistent network wrappers that work with any of the models</li></ul></li><li>All models support multi-scale feature map extraction (feature pyramids) via create_model (see <a href=\"https://huggingface.co/docs/timm/feature_extraction\" rel=\"nofollow\">documentation</a>)<ul dir=\"auto\"><li><code>create_model(name, features_only=True, out_indices=..., output_stride=...)</code></li><li><code>out_indices</code> creation arg specifies which feature maps to return, these indices are 0 based and generally correspond to the <code>C(i + 1)</code> feature level.</li><li><code>output_stride</code> creation arg controls output stride of the network by using dilated convolutions. Most networks are stride 32 by default. Not all networks support this.</li><li>feature map channel counts, reduction level (stride) can be queried AFTER model creation via the <code>.feature_info</code> member</li></ul></li><li>All models have a consistent pretrained weight loader that adapts last linear if necessary, and from 3 to 1 channel input if desired</li><li>High performance <a href=\"https://huggingface.co/docs/timm/training_script\" rel=\"nofollow\">reference training, validation, and inference scripts</a> that work in several process/GPU modes:<ul dir=\"auto\"><li>NVIDIA DDP w/ a single GPU per process, multiple processes with APEX present (AMP mixed-precision optional)</li><li>PyTorch DistributedDataParallel w/ multi-gpu, single process (AMP disabled as it crashes when enabled)</li><li>PyTorch w/ single GPU single process (AMP optional)</li></ul></li><li>A dynamic global pool implementation that allows selecting from average pooling, max pooling, average + max, or concat([average, max]) at model creation. All global pooling is adaptive average by default and compatible with pretrained weights.</li><li>A 'Test Time Pool' wrapper that can wrap any of the included models and usually provides improved performance doing inference with input images larger than the training size. Idea adapted from original DPN implementation when I ported (<a href=\"https://github.com/cypw/DPNs\">https://github.com/cypw/DPNs</a>)</li><li>Learning rate schedulers<ul dir=\"auto\"><li>Ideas adopted from<ul dir=\"auto\"><li><a href=\"https://github.com/allenai/allennlp/tree/master/allennlp/training/learning_rate_schedulers\">AllenNLP schedulers</a></li><li><a href=\"https://github.com/pytorch/fairseq/tree/master/fairseq/optim/lr_scheduler\">FAIRseq lr_scheduler</a></li><li>SGDR: Stochastic Gradient Descent with Warm Restarts (<a href=\"https://arxiv.org/abs/1608.03983\" rel=\"nofollow\">https://arxiv.org/abs/1608.03983</a>)</li></ul></li><li>Schedulers include <code>step</code>, <code>cosine</code> w/ restarts, <code>tanh</code> w/ restarts, <code>plateau</code></li></ul></li><li>Space-to-Depth by <a href=\"https://github.com/mrT23/TResNet/blob/master/src/models/tresnet/layers/space_to_depth.py\">mrT23</a> (<a href=\"https://arxiv.org/abs/1801.04590\" rel=\"nofollow\">https://arxiv.org/abs/1801.04590</a>) -- original paper?</li><li>Adaptive Gradient Clipping (<a href=\"https://arxiv.org/abs/2102.06171\" rel=\"nofollow\">https://arxiv.org/abs/2102.06171</a>, <a href=\"https://github.com/deepmind/deepmind-research/tree/master/nfnets\">https://github.com/deepmind/deepmind-research/tree/master/nfnets</a>)</li><li>An extensive selection of channel and/or spatial attention modules:<ul dir=\"auto\"><li>Bottleneck Transformer - <a href=\"https://arxiv.org/abs/2101.11605\" rel=\"nofollow\">https://arxiv.org/abs/2101.11605</a></li><li>CBAM - <a href=\"https://arxiv.org/abs/1807.06521\" rel=\"nofollow\">https://arxiv.org/abs/1807.06521</a></li><li>Effective Squeeze-Excitation (ESE) - <a href=\"https://arxiv.org/abs/1911.06667\" rel=\"nofollow\">https://arxiv.org/abs/1911.06667</a></li><li>Efficient Channel Attention (ECA) - <a href=\"https://arxiv.org/abs/1910.03151\" rel=\"nofollow\">https://arxiv.org/abs/1910.03151</a></li><li>Gather-Excite (GE) - <a href=\"https://arxiv.org/abs/1810.12348\" rel=\"nofollow\">https://arxiv.org/abs/1810.12348</a></li><li>Global Context (GC) - <a href=\"https://arxiv.org/abs/1904.11492\" rel=\"nofollow\">https://arxiv.org/abs/1904.11492</a></li><li>Halo - <a href=\"https://arxiv.org/abs/2103.12731\" rel=\"nofollow\">https://arxiv.org/abs/2103.12731</a></li><li>Involution - <a href=\"https://arxiv.org/abs/2103.06255\" rel=\"nofollow\">https://arxiv.org/abs/2103.06255</a></li><li>Lambda Layer - <a href=\"https://arxiv.org/abs/2102.08602\" rel=\"nofollow\">https://arxiv.org/abs/2102.08602</a></li><li>Non-Local (NL) -  <a href=\"https://arxiv.org/abs/1711.07971\" rel=\"nofollow\">https://arxiv.org/abs/1711.07971</a></li><li>Squeeze-and-Excitation (SE) - <a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">https://arxiv.org/abs/1709.01507</a></li><li>Selective Kernel (SK) - (<a href=\"https://arxiv.org/abs/1903.06586\" rel=\"nofollow\">https://arxiv.org/abs/1903.06586</a></li><li>Split (SPLAT) - <a href=\"https://arxiv.org/abs/2004.08955\" rel=\"nofollow\">https://arxiv.org/abs/2004.08955</a></li><li>Shifted Window (SWIN) - <a href=\"https://arxiv.org/abs/2103.14030\" rel=\"nofollow\">https://arxiv.org/abs/2103.14030</a></li></ul></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Results</h2><a id=\"user-content-results\" class=\"anchor-element\" aria-label=\"Permalink: Results\" href=\"#results\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Model validation results can be found in the <a href=\"/huggingface/pytorch-image-models/blob/main/results/README.md\">results tables</a></p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Getting Started (Documentation)</h2><a id=\"user-content-getting-started-documentation\" class=\"anchor-element\" aria-label=\"Permalink: Getting Started (Documentation)\" href=\"#getting-started-documentation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">The official documentation can be found at <a href=\"https://huggingface.co/docs/hub/timm\" rel=\"nofollow\">https://huggingface.co/docs/hub/timm</a>. Documentation contributions are welcome.</p><p dir=\"auto\"><a href=\"https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055\" rel=\"nofollow\">Getting Started with PyTorch Image Models (timm): A Practitioner\u2019s Guide</a> by <a href=\"https://github.com/Chris-hughes10\">Chris Hughes</a> is an extensive blog post covering many aspects of <code>timm</code> in detail.</p><p dir=\"auto\"><a href=\"http://timm.fast.ai/\" rel=\"nofollow\">timmdocs</a> is an alternate set of documentation for <code>timm</code>. A big thanks to <a href=\"https://github.com/amaarora\">Aman Arora</a> for his efforts creating timmdocs.</p><p dir=\"auto\"><a href=\"https://paperswithcode.com/lib/timm\" rel=\"nofollow\">paperswithcode</a> is a good resource for browsing the models within <code>timm</code>.</p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Train, Validation, Inference Scripts</h2><a id=\"user-content-train-validation-inference-scripts\" class=\"anchor-element\" aria-label=\"Permalink: Train, Validation, Inference Scripts\" href=\"#train-validation-inference-scripts\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">The root folder of the repository contains reference train, validation, and inference scripts that work with the included models and other features of this repository. They are adaptable for other datasets and use cases with a little hacking. See <a href=\"https://huggingface.co/docs/timm/training_script\" rel=\"nofollow\">documentation</a>.</p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Awesome PyTorch Resources</h2><a id=\"user-content-awesome-pytorch-resources\" class=\"anchor-element\" aria-label=\"Permalink: Awesome PyTorch Resources\" href=\"#awesome-pytorch-resources\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">One of the greatest assets of PyTorch is the community and their contributions. A few of my favourite resources that pair well with the models and components here are listed below.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Object Detection, Instance and Semantic Segmentation</h3><a id=\"user-content-object-detection-instance-and-semantic-segmentation\" class=\"anchor-element\" aria-label=\"Permalink: Object Detection, Instance and Semantic Segmentation\" href=\"#object-detection-instance-and-semantic-segmentation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Detectron2 - <a href=\"https://github.com/facebookresearch/detectron2\">https://github.com/facebookresearch/detectron2</a></li><li>Segmentation Models (Semantic) - <a href=\"https://github.com/qubvel/segmentation_models.pytorch\">https://github.com/qubvel/segmentation_models.pytorch</a></li><li>EfficientDet (Obj Det, Semantic soon) - <a href=\"https://github.com/rwightman/efficientdet-pytorch\">https://github.com/rwightman/efficientdet-pytorch</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Computer Vision / Image Augmentation</h3><a id=\"user-content-computer-vision--image-augmentation\" class=\"anchor-element\" aria-label=\"Permalink: Computer Vision / Image Augmentation\" href=\"#computer-vision--image-augmentation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>Albumentations - <a href=\"https://github.com/albumentations-team/albumentations\">https://github.com/albumentations-team/albumentations</a></li><li>Kornia - <a href=\"https://github.com/kornia/kornia\">https://github.com/kornia/kornia</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Knowledge Distillation</h3><a id=\"user-content-knowledge-distillation\" class=\"anchor-element\" aria-label=\"Permalink: Knowledge Distillation\" href=\"#knowledge-distillation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>RepDistiller - <a href=\"https://github.com/HobbitLong/RepDistiller\">https://github.com/HobbitLong/RepDistiller</a></li><li>torchdistill - <a href=\"https://github.com/yoshitomo-matsubara/torchdistill\">https://github.com/yoshitomo-matsubara/torchdistill</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Metric Learning</h3><a id=\"user-content-metric-learning\" class=\"anchor-element\" aria-label=\"Permalink: Metric Learning\" href=\"#metric-learning\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>PyTorch Metric Learning - <a href=\"https://github.com/KevinMusgrave/pytorch-metric-learning\">https://github.com/KevinMusgrave/pytorch-metric-learning</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Training / Frameworks</h3><a id=\"user-content-training--frameworks\" class=\"anchor-element\" aria-label=\"Permalink: Training / Frameworks\" href=\"#training--frameworks\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><ul dir=\"auto\"><li>fastai - <a href=\"https://github.com/fastai/fastai\">https://github.com/fastai/fastai</a></li></ul><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Licenses</h2><a id=\"user-content-licenses\" class=\"anchor-element\" aria-label=\"Permalink: Licenses\" href=\"#licenses\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Code</h3><a id=\"user-content-code\" class=\"anchor-element\" aria-label=\"Permalink: Code\" href=\"#code\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">The code here is licensed Apache 2.0. I've taken care to make sure any third party code included or adapted has compatible (permissive) licenses such as MIT, BSD, etc. I've made an effort to avoid any GPL / LGPL conflicts. That said, it is your responsibility to ensure you comply with licenses here and conditions of any dependent licenses. Where applicable, I've linked the sources/references for various components in docstrings. If you think I've missed anything please create an issue.</p><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Pretrained Weights</h3><a id=\"user-content-pretrained-weights\" class=\"anchor-element\" aria-label=\"Permalink: Pretrained Weights\" href=\"#pretrained-weights\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">So far all of the pretrained weights available here are pretrained on ImageNet with a select few that have some additional pretraining (see extra note below). ImageNet was released for non-commercial research purposes only (<a href=\"https://image-net.org/download\" rel=\"nofollow\">https://image-net.org/download</a>). It's not clear what the implications of that are for the use of pretrained weights from that dataset. Any models I have trained with ImageNet are done for research purposes and one should assume that the original dataset license applies to the weights. It's best to seek legal advice if you intend to use the pretrained weights in a commercial product.</p><div class=\"markdown-heading\" dir=\"auto\"><h4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Pretrained on more than ImageNet</h4><a id=\"user-content-pretrained-on-more-than-imagenet\" class=\"anchor-element\" aria-label=\"Permalink: Pretrained on more than ImageNet\" href=\"#pretrained-on-more-than-imagenet\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\">Several weights included or references here were pretrained with proprietary datasets that I do not have access to. These include the Facebook WSL, SSL, SWSL ResNe(Xt) and the Google Noisy Student EfficientNet models. The Facebook models have an explicit non-commercial license (CC-BY-NC 4.0, <a href=\"https://github.com/facebookresearch/semi-supervised-ImageNet1K-models\">https://github.com/facebookresearch/semi-supervised-ImageNet1K-models</a>, <a href=\"https://github.com/facebookresearch/WSL-Images\">https://github.com/facebookresearch/WSL-Images</a>). The Google models do not appear to have any restriction beyond the Apache 2.0 license (and ImageNet concerns). In either case, you should contact Facebook or Google with any questions.</p><div class=\"markdown-heading\" dir=\"auto\"><h2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Citing</h2><a id=\"user-content-citing\" class=\"anchor-element\" aria-label=\"Permalink: Citing\" href=\"#citing\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">BibTeX</h3><a id=\"user-content-bibtex\" class=\"anchor-element\" aria-label=\"Permalink: BibTeX\" href=\"#bibtex\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><div class=\"highlight highlight-text-bibtex notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"@misc{rw2019timm,  author = {Ross Wightman},  title = {PyTorch Image Models},  year = {2019},  publisher = {GitHub},  journal = {GitHub repository},  doi = {10.5281/zenodo.4414861},  howpublished = {\\url{https://github.com/rwightman/pytorch-image-models}}}\"><pre><span class=\"pl-k\">@misc</span>{<span class=\"pl-en\">rw2019timm</span>,  <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"pl-pds\">{</span>Ross Wightman<span class=\"pl-pds\">}</span></span>,  <span class=\"pl-s\">title</span> = <span class=\"pl-s\"><span class=\"pl-pds\">{</span>PyTorch Image Models<span class=\"pl-pds\">}</span></span>,  <span class=\"pl-s\">year</span> = <span class=\"pl-s\"><span class=\"pl-pds\">{</span>2019<span class=\"pl-pds\">}</span></span>,  <span class=\"pl-s\">publisher</span> = <span class=\"pl-s\"><span class=\"pl-pds\">{</span>GitHub<span class=\"pl-pds\">}</span></span>,  <span class=\"pl-s\">journal</span> = <span class=\"pl-s\"><span class=\"pl-pds\">{</span>GitHub repository<span class=\"pl-pds\">}</span></span>,  <span class=\"pl-s\">doi</span> = <span class=\"pl-s\"><span class=\"pl-pds\">{</span>10.5281/zenodo.4414861<span class=\"pl-pds\">}</span></span>,  <span class=\"pl-s\">howpublished</span> = <span class=\"pl-s\"><span class=\"pl-pds\">{</span>\\url{https://github.com/rwightman/pytorch-image-models}<span class=\"pl-pds\">}</span></span>}</pre></div><div class=\"markdown-heading\" dir=\"auto\"><h3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\">Latest DOI</h3><a id=\"user-content-latest-doi\" class=\"anchor-element\" aria-label=\"Permalink: Latest DOI\" href=\"#latest-doi\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div><p dir=\"auto\"><a href=\"https://zenodo.org/badge/latestdoi/168799526\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d3ff9146e8c7599db7b387602b07be7ca57e1a40302c1ad85f4444e0ece6e09/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3136383739393532362e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/168799526.svg\" style=\"max-width: 100%;\"></a></p></article></div></div></div></div></div> <!-- --> <!-- --> <script type=\"application/json\" id=\"__PRIMER_DATA__\">{\"resolvedServerColorMode\":\"day\"}</script></div></react-partial>        <input type=\"hidden\" data-csrf=\"true\" value=\"kbiyrSt2PDdEjBTgOVzYAymx/fQUM1eFoAggYAPOsHenuCV9CoCHhSei1vaiplyamPW1pQoS7p8xQNLlZHhxNQ==\" /></div>  <div data-view-component=\"true\" class=\"Layout-sidebar\">            <div class=\"BorderGrid about-margin\" data-pjax>        <div class=\"BorderGrid-row\">          <div class=\"BorderGrid-cell\">            <div class=\"hide-sm hide-md\">  <h2 class=\"mb-3 h4\">About</h2>      <p class=\"f4 my-3\">        PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more      </p>      <div class=\"my-3 d-flex flex-items-center\">        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-link flex-shrink-0 mr-2\">    <path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg>        <span class=\"flex-auto min-width-0 css-truncate css-truncate-target width-fit\">          <a title=\"https://huggingface.co/docs/timm\" role=\"link\" target=\"_blank\" rel=\"noopener noreferrer nofollow\" class=\"text-bold\" href=\"https://huggingface.co/docs/timm\">huggingface.co/docs/timm</a>        </span>      </div>    <h3 class=\"sr-only\">Topics</h3>    <div class=\"my-3\">        <div class=\"f6\">      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:pytorch\" href=\"/topics/pytorch\" title=\"Topic: pytorch\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  pytorch</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:imagenet\" href=\"/topics/imagenet\" title=\"Topic: imagenet\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  imagenet</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:image-classification\" href=\"/topics/image-classification\" title=\"Topic: image-classification\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  image-classification</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:resnet\" href=\"/topics/resnet\" title=\"Topic: resnet\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  resnet</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:pretrained-models\" href=\"/topics/pretrained-models\" title=\"Topic: pretrained-models\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  pretrained-models</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:mixnet\" href=\"/topics/mixnet\" title=\"Topic: mixnet\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  mixnet</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:pretrained-weights\" href=\"/topics/pretrained-weights\" title=\"Topic: pretrained-weights\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  pretrained-weights</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:distributed-training\" href=\"/topics/distributed-training\" title=\"Topic: distributed-training\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  distributed-training</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:dual-path-networks\" href=\"/topics/dual-path-networks\" title=\"Topic: dual-path-networks\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  dual-path-networks</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:mobilenet-v2\" href=\"/topics/mobilenet-v2\" title=\"Topic: mobilenet-v2\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  mobilenet-v2</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:mobile-deep-learning\" href=\"/topics/mobile-deep-learning\" title=\"Topic: mobile-deep-learning\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  mobile-deep-learning</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:mobilenetv3\" href=\"/topics/mobilenetv3\" title=\"Topic: mobilenetv3\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  mobilenetv3</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:efficientnet\" href=\"/topics/efficientnet\" title=\"Topic: efficientnet\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  efficientnet</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:augmix\" href=\"/topics/augmix\" title=\"Topic: augmix\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  augmix</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:randaugment\" href=\"/topics/randaugment\" title=\"Topic: randaugment\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  randaugment</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:nfnets\" href=\"/topics/nfnets\" title=\"Topic: nfnets\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  nfnets</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:normalization-free-training\" href=\"/topics/normalization-free-training\" title=\"Topic: normalization-free-training\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  normalization-free-training</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:vision-transformer-models\" href=\"/topics/vision-transformer-models\" title=\"Topic: vision-transformer-models\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  vision-transformer-models</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:convnext\" href=\"/topics/convnext\" title=\"Topic: convnext\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  convnext</a>      <a data-ga-click=\"Topic, repository page\" data-octo-click=\"topic_click\" data-octo-dimensions=\"topic:maxvit\" href=\"/topics/maxvit\" title=\"Topic: maxvit\" data-view-component=\"true\" class=\"topic-tag topic-tag-link\">  maxvit</a>  </div>    </div>    <h3 class=\"sr-only\">Resources</h3>    <div class=\"mt-2\">      <a class=\"Link--muted\" data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}\" href=\"#readme-ov-file\">        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-book mr-2\">    <path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path></svg>        Readme</a>    </div>      <h3 class=\"sr-only\">License</h3>  <div class=\"mt-2\">    <a href=\"#Apache-2.0-1-ov-file\"      class=\"Link--muted\"            data-analytics-event=\"{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}\"    >      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-law mr-2\">    <path d=\"M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z\"></path></svg>     Apache-2.0 license    </a>  </div>  <include-fragment  src=\"/huggingface/pytorch-image-models/hovercards/citation/sidebar_partial?tree_name=main\">  </include-fragment>  <div class=\"mt-2\">    <a href=\"/huggingface/pytorch-image-models/activity\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg text=\"gray\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pulse mr-2\">    <path d=\"M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z\"></path></svg>      <span class=\"color-fg-muted\">Activity</span></a>  </div>    <div class=\"mt-2\">      <a href=\"/huggingface/pytorch-image-models/custom-properties\" data-view-component=\"true\" class=\"Link Link--muted\">        <svg text=\"gray\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-note mr-2\">    <path d=\"M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25Zm1.75-.25a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25ZM3.5 6.25a.75.75 0 0 1 .75-.75h7a.75.75 0 0 1 0 1.5h-7a.75.75 0 0 1-.75-.75Zm.75 2.25h4a.75.75 0 0 1 0 1.5h-4a.75.75 0 0 1 0-1.5Z\"></path></svg>        <span class=\"color-fg-muted\">Custom properties</span></a>    </div>  <h3 class=\"sr-only\">Stars</h3>  <div class=\"mt-2\">    <a href=\"/huggingface/pytorch-image-models/stargazers\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-star mr-2\">    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z\"></path></svg>      <strong>29k</strong>      stars</a>  </div>  <h3 class=\"sr-only\">Watchers</h3>  <div class=\"mt-2\">    <a href=\"/huggingface/pytorch-image-models/watchers\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-eye mr-2\">    <path d=\"M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z\"></path></svg>      <strong>308</strong>      watching</a>  </div>  <h3 class=\"sr-only\">Forks</h3>  <div class=\"mt-2\">    <a href=\"/huggingface/pytorch-image-models/forks\" data-view-component=\"true\" class=\"Link Link--muted\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-2\">    <path d=\"M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z\"></path></svg>      <strong>4.5k</strong>      forks</a>  </div>    <div class=\"mt-2\">      <a class=\"Link--muted\" href=\"/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Fpytorch-image-models&amp;report=huggingface+%28user%29\">          Report repository</a>    </div></div>          </div>        </div>                    <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\">  <a href=\"/huggingface/pytorch-image-models/releases\" data-view-component=\"true\" class=\"Link--primary no-underline Link\">    Releases      <span title=\"55\" data-view-component=\"true\" class=\"Counter\">55</span></a></h2>  <a class=\"Link--primary d-flex no-underline\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" href=\"/huggingface/pytorch-image-models/releases/tag/v0.9.16\">    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-tag flex-shrink-0 mt-1 color-fg-success\">    <path d=\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\"></path></svg>    <div class=\"ml-2 min-width-0\">      <div class=\"d-flex\">        <span class=\"css-truncate css-truncate-target text-bold mr-2\" style=\"max-width: none;\">Release v0.9.16</span>        <span title=\"Label: Latest\" data-view-component=\"true\" class=\"Label Label--success flex-shrink-0\">          Latest</span>      </div>      <div class=\"text-small color-fg-muted\"><relative-time datetime=\"2024-02-19T19:35:21Z\" class=\"no-wrap\">Feb 19, 2024</relative-time></div>    </div></a>    <div data-view-component=\"true\" class=\"mt-3\">      <a text=\"small\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\" href=\"/huggingface/pytorch-image-models/releases\" data-view-component=\"true\" class=\"Link\">        + 54 releases</a></div>              </div>            </div>                    <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">Sponsor this project</h2><include-fragment src=\"/huggingface/pytorch-image-models/sponsors_list?block_button=false&amp;current_repository=pytorch-image-models\" aria-busy=\"true\" aria-label=\"Loading sponsorable links\">        <ul class=\"list-style-none\">        </ul></include-fragment>              </div>            </div>                    <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">  <a href=\"/orgs/huggingface/packages?repo_name=pytorch-image-models\" data-view-component=\"true\" class=\"Link--primary no-underline Link d-flex flex-items-center\">    Packages      <span title=\"0\" hidden=\"hidden\" data-view-component=\"true\" class=\"Counter ml-1\">0</span></a></h2>      <div class=\"text-small color-fg-muted\">        No packages published <br>      </div>              </div>            </div>                    <div class=\"BorderGrid-row\" >              <div class=\"BorderGrid-cell\">                  <h2 class=\"h4 mb-3\">    <a href=\"/huggingface/pytorch-image-models/network/dependents\" data-view-component=\"true\" class=\"Link--primary no-underline Link\">      Used by <span title=\"23,443\" data-view-component=\"true\" class=\"Counter\">23.4k</span></a>  </h2>  <a class=\"d-flex flex-items-center\" href=\"/huggingface/pytorch-image-models/network/dependents\">    <ul class=\"hx_flex-avatar-stack list-style-none min-width-0\">          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/162299112?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@llmforcqa\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/25710682?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@AlexCejudo\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/28478805?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@ZCDu\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/127899720?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@SINGHGURDEEP19\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/49297003?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@GaiaNetDemo\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/98301455?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@liu681\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/71806971?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@HIT-leaderone\" />          </li>          <li class=\"hx_flex-avatar-stack-item\">            <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/85238808?s=64&amp;v=4\" width=\"32\" height=\"32\" alt=\"@Daxitdon\" />          </li>    </ul>      <span class=\"px-2 text-bold text-small no-wrap\">        + 23,435      </span>  </a>              </div>            </div>                    <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">  <a href=\"/huggingface/pytorch-image-models/graphs/contributors\" data-view-component=\"true\" class=\"Link--primary no-underline Link d-flex flex-items-center\">    Contributors      <span title=\"111\" data-view-component=\"true\" class=\"Counter ml-1\">111</span></a></h2>      <ul class=\"list-style-none d-flex flex-wrap mb-n2\">    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/rwightman\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/rwightman/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/5702664?s=64&amp;v=4\" alt=\"@rwightman\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/nateraw\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/nateraw/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/32437151?s=64&amp;v=4\" alt=\"@nateraw\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/alexander-soare\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/alexander-soare/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/16543381?s=64&amp;v=4\" alt=\"@alexander-soare\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/amaarora\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/amaarora/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/41290559?s=64&amp;v=4\" alt=\"@amaarora\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/seefun\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/seefun/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/19152032?s=64&amp;v=4\" alt=\"@seefun\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/ChristophReich1996\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/ChristophReich1996/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/34400551?s=64&amp;v=4\" alt=\"@ChristophReich1996\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/chris-ha458\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/chris-ha458/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/15088501?s=64&amp;v=4\" alt=\"@chris-ha458\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/fffffgggg54\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/fffffgggg54/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/13189380?s=64&amp;v=4\" alt=\"@fffffgggg54\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/kaczmarj\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/kaczmarj/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/17690870?s=64&amp;v=4\" alt=\"@kaczmarj\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/mrT23\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/mrT23/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/21198860?s=64&amp;v=4\" alt=\"@mrT23\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/kozistr\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/kozistr/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/15344796?s=64&amp;v=4\" alt=\"@kozistr\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/contrastive\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/contrastive/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/20089016?s=64&amp;v=4\" alt=\"@contrastive\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/morizin\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/morizin/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/50985248?s=64&amp;v=4\" alt=\"@morizin\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li>    <li class=\"mb-2 mr-2\"        >      <a href=\"https://github.com/kecsap\"          class=\"\"            data-hovercard-type=\"user\" data-hovercard-url=\"/users/kecsap/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\"                  >        <img src=\"https://avatars.githubusercontent.com/u/1132593?s=64&amp;v=4\" alt=\"@kecsap\" size=\"32\" height=\"32\" width=\"32\" data-view-component=\"true\" class=\"avatar circle\" />      </a>    </li></ul>  <div data-view-component=\"true\" class=\"mt-3\">    <a text=\"small\" href=\"/huggingface/pytorch-image-models/graphs/contributors\" data-view-component=\"true\" class=\"Link\">      + 97 contributors</a></div>              </div>            </div>                            <div class=\"BorderGrid-row\">              <div class=\"BorderGrid-cell\">                <h2 class=\"h4 mb-3\">Languages</h2><div class=\"mb-2\">  <span data-view-component=\"true\" class=\"Progress\">    <span style=\"background-color:#3572A5 !important;;width: 84.9%;\" itemprop=\"keywords\" aria-label=\"Python 84.9\" data-view-component=\"true\" class=\"Progress-item color-bg-success-emphasis\"></span>    <span style=\"background-color:#fcb32c !important;;width: 15.1%;\" itemprop=\"keywords\" aria-label=\"MDX 15.1\" data-view-component=\"true\" class=\"Progress-item color-bg-success-emphasis\"></span></span></div><ul class=\"list-style-none\">    <li class=\"d-inline\">        <a class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3\" href=\"/huggingface/pytorch-image-models/search?l=python\"  data-ga-click=\"Repository, language stats search click, location:repo overview\">          <svg style=\"color:#3572A5;\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill mr-2\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg>          <span class=\"color-fg-default text-bold mr-1\">Python</span>          <span>84.9%</span>        </a>    </li>    <li class=\"d-inline\">        <a class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3\" href=\"/huggingface/pytorch-image-models/search?l=mdx\"  data-ga-click=\"Repository, language stats search click, location:repo overview\">          <svg style=\"color:#fcb32c;\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-dot-fill mr-2\">    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z\"></path></svg>          <span class=\"color-fg-default text-bold mr-1\">MDX</span>          <span>15.1%</span>        </a>    </li></ul>              </div>            </div>              </div></div>  </div></div>  </div>  </div></turbo-frame>    </main>  </div>  </div>          <footer class=\"footer pt-8 pb-6 f6 color-fg-muted p-responsive\" role=\"contentinfo\" >  <h2 class='sr-only'>Footer</h2>    <div class=\"d-flex flex-justify-center flex-items-center flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap\">    <div class=\"d-flex flex-items-center flex-shrink-0 mx-2\">      <a aria-label=\"Homepage\" title=\"GitHub\" class=\"footer-octicon mr-2\" href=\"https://github.com\">        <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-mark-github\">    <path d=\"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z\"></path></svg></a>      <span>        &copy; 2024 GitHub,&nbsp;Inc.      </span>    </div>    <nav aria-label=\"Footer\">      <h3 class=\"sr-only\" id=\"sr-footer-heading\">Footer navigation</h3>      <ul class=\"list-style-none d-flex flex-justify-center flex-wrap mb-2 mb-lg-0\" aria-labelledby=\"sr-footer-heading\">          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to Terms&quot;,&quot;label&quot;:&quot;text:terms&quot;}\" href=\"https://docs.github.com/site-policy/github-terms/github-terms-of-service\" data-view-component=\"true\" class=\"Link--secondary Link\">Terms</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to privacy&quot;,&quot;label&quot;:&quot;text:privacy&quot;}\" href=\"https://docs.github.com/site-policy/privacy-policies/github-privacy-statement\" data-view-component=\"true\" class=\"Link--secondary Link\">Privacy</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to security&quot;,&quot;label&quot;:&quot;text:security&quot;}\" href=\"/security\" data-view-component=\"true\" class=\"Link--secondary Link\">Security</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to status&quot;,&quot;label&quot;:&quot;text:status&quot;}\" href=\"https://www.githubstatus.com/\" data-view-component=\"true\" class=\"Link--secondary Link\">Status</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to docs&quot;,&quot;label&quot;:&quot;text:docs&quot;}\" href=\"https://docs.github.com\" data-view-component=\"true\" class=\"Link--secondary Link\">Docs</a>          </li>          <li class=\"mx-2\">            <a data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to contact&quot;,&quot;label&quot;:&quot;text:contact&quot;}\" href=\"https://support.github.com?tags=dotcom-footer\" data-view-component=\"true\" class=\"Link--secondary Link\">Contact</a>          </li>          <li class=\"mx-2\" >  <cookie-consent-link>    <button type=\"button\" class=\"Link--secondary underline-on-hover border-0 p-0 color-bg-transparent\" data-action=\"click:cookie-consent-link#showConsentManagement\">      Manage cookies    </button>  </cookie-consent-link></li><li class=\"mx-2\">  <cookie-consent-link>    <button type=\"button\" class=\"Link--secondary underline-on-hover border-0 p-0 color-bg-transparent\" data-action=\"click:cookie-consent-link#showConsentManagement\">      Do not share my personal information    </button>  </cookie-consent-link></li>      </ul>    </nav>  </div></footer>    <cookie-consent id=\"cookie-consent-banner\" class=\"position-fixed bottom-0 left-0\" style=\"z-index: 999999\" data-initial-cookie-consent-allowed=\"\" data-cookie-consent-required=\"false\"></cookie-consent>  <div id=\"ajax-error-message\" class=\"ajax-error-message flash flash-error\" hidden>    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\">    <path d=\"M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>    <button type=\"button\" class=\"flash-close js-ajax-error-dismiss\" aria-label=\"Dismiss error\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>    </button>    You can\u2019t perform that action at this time.  </div>    <template id=\"site-details-dialog\">  <details class=\"details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm\" open>    <summary role=\"button\" aria-label=\"Close dialog\"></summary>    <details-dialog class=\"Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal\">      <button class=\"Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0\" type=\"button\" aria-label=\"Close dialog\" data-close-dialog>        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x\">    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path></svg>      </button>      <div class=\"octocat-spinner my-6 js-details-dialog-spinner\"></div>    </details-dialog>  </details></template>    <div class=\"Popover js-hovercard-content position-absolute\" style=\"display: none; outline: none;\" tabindex=\"0\">  <div class=\"Popover-message Popover-message--bottom-left Popover-message--large Box color-shadow-large\" style=\"width:360px;\">  </div></div>    <template id=\"snippet-clipboard-copy-button\">  <div class=\"zeroclipboard-container position-absolute right-0 top-0\">    <clipboard-copy aria-label=\"Copy\" class=\"ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copy js-clipboard-copy-icon m-2\">    <path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"></path><path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg>      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2\">    <path d=\"M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"></path></svg>    </clipboard-copy>  </div></template><template id=\"snippet-clipboard-copy-button-unpositioned\">  <div class=\"zeroclipboard-container\">    <clipboard-copy aria-label=\"Copy\" class=\"ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copy js-clipboard-copy-icon\">    <path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"></path><path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path></svg>      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none\">    <path d=\"M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"></path></svg>    </clipboard-copy>  </div></template>    </div>    <div id=\"js-global-screen-reader-notice\" class=\"sr-only\" aria-live=\"polite\" aria-atomic=\"true\" ></div>    <div id=\"js-global-screen-reader-notice-assertive\" class=\"sr-only\" aria-live=\"assertive\" aria-atomic=\"true\"></div>  </body></html>",
  "embeddings": []
}