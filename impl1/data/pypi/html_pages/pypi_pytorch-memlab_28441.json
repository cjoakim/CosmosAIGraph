{
  "libtype": "pypi",
  "libname": "pytorch-memlab",
  "url": "https://pypi.org/project/pytorch-memlab/",
  "html": "<!DOCTYPE html><html lang=\"en\" dir=\"ltr\">  <head>    <meta charset=\"utf-8\">    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">    <meta name=\"defaultLanguage\" content=\"en\">    <meta name=\"availableLanguages\" content=\"en, es, fr, ja, pt_BR, uk, el, de, zh_Hans, zh_Hant, ru, he, eo\">    <title>pytorch-memlab \u00b7 PyPI</title>    <meta name=\"description\" content=\"A lab to do simple and accurate memory experiments on pytorch\">    <link rel=\"stylesheet\" href=\"/static/css/warehouse-ltr.99b3104d.css\">    <link rel=\"stylesheet\" href=\"/static/css/fontawesome.b50b476c.css\">    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Source+Sans+3:400,400italic,600,600italic,700,700italic%7CSource+Code+Pro:500\">    <noscript>      <link rel=\"stylesheet\" href=\"/static/css/noscript.0673c9ea.css\">    </noscript>    <link rel=\"icon\" href=\"/static/images/favicon.35549fe8.ico\" type=\"image/x-icon\">    <link rel=\"alternate\" type=\"application/rss+xml\" title=\"RSS: 40 latest updates\" href=\"/rss/updates.xml\">    <link rel=\"alternate\" type=\"application/rss+xml\" title=\"RSS: 40 newest packages\" href=\"/rss/packages.xml\"><link rel=\"alternate\" type=\"application/rss+xml\" title=\"RSS: latest releases for pytorch-memlab\" href=\"/rss/project/pytorch-memlab/releases.xml\">    <link rel=\"canonical\" href=\"https://pypi.org/project/pytorch-memlab/\">    <meta property=\"og:url\" content=\"https://pypi.org/project/pytorch-memlab/\">    <meta property=\"og:site_name\" content=\"PyPI\">    <meta property=\"og:type\" content=\"website\">    <meta property=\"og:image\" content=\"https://pypi.org/static/images/twitter.abaf4b19.webp\">    <meta property=\"og:title\" content=\"pytorch-memlab\">    <meta property=\"og:description\" content=\"A lab to do simple and accurate memory experiments on pytorch\">    <link rel=\"search\" type=\"application/opensearchdescription+xml\" title=\"PyPI\" href=\"/opensearch.xml\">    <script asyncdata-ga-id=\"UA-55961911-1\"data-ga4-id=\"G-RW7D75DF8V\"            src=\"/static/js/warehouse.dd4295c4.js\">    </script><script>MathJax = {  tex: {    inlineMath: [['$', '$'], ['\\\\(', '\\\\)']]  },};</script><script async  src=\"https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-svg.js\"  integrity=\"sha256-1CldwzdEg2k1wTmf7s5RWVd7NMXI/7nxxjJM2C4DqII=\"  crossorigin=\"anonymous\"></script><script async src=\"https://www.googletagmanager.com/gtag/js?id=UA-55961911-1\"></script><script async src=\"https://www.googletagmanager.com/gtag/js?id=G-RW7D75DF8V\"></script><script defer src=\"https://www.fastly-insights.com/insights.js?k=6a52360a-f306-421e-8ed5-7417d0d4a4e9&dnt=true\"></script>    <script async        src=\"https://media.ethicalads.io/media/client/v1.4.0/ethicalads.min.js\"        integrity=\"sha256-U3hKDidudIaxBDEzwGJApJgPEf2mWk6cfMWghrAa6i0= sha384-UcmsCqcNRSLW/dV3Lo1oCi2/VaurXbib6p4HyUEOeIa/4OpsrnucrugAefzVZJfI sha512-q4t1L4xEjGV2R4hzqCa41P8jrgFUS8xTb8rdNv4FGvw7FpydVj/kkxBJHOiaoxHa8olCcx1Slk9K+3sNbsM4ug==\"        crossorigin=\"anonymous\"    ></script>  </head>  <body data-controller=\"viewport-toggle\">    <!-- Accessibility: this link should always be the first piece of content inside the body-->    <a href=\"#content\" class=\"skip-to-content\">Skip to main content</a>    <button type=\"button\" class=\"button button--primary button--switch-to-mobile hidden\" data-viewport-toggle-target=\"switchToMobile\" data-action=\"viewport-toggle#switchToMobile\">Switch to mobile version    </button>    <div id=\"sticky-notifications\" class=\"stick-to-top js-stick-to-top\">      <!-- Add browser warning. Will show for ie9 and below -->      <!--[if IE]>      <div class=\"notification-bar notification-bar--warning\" role=\"status\">        <span class=\"notification-bar__icon\">          <i class=\"fa fa-exclamation-triangle\" aria-hidden=\"true\"></i>          <span class=\"sr-only\">Warning</span>        </span>        <span class=\"notification-bar__message\">You are using an unsupported browser, upgrade to a newer version.</span>      </div>      <![endif]-->      <noscript>      <div class=\"notification-bar notification-bar--warning\" role=\"status\">        <span class=\"notification-bar__icon\">          <i class=\"fa fa-exclamation-triangle\" aria-hidden=\"true\"></i>          <span class=\"sr-only\">Warning</span>        </span>        <span class=\"notification-bar__message\">Some features may not work without JavaScript. Please try enabling it if you encounter problems.</span>      </div>      </noscript><div data-html-include=\"/_includes/notification-banners/\"></div>    </div><div data-html-include=\"/_includes/flash-messages/\"></div><div data-html-include=\"/_includes/session-notifications/\"></div>    <header class=\"site-header \">      <div class=\"site-container\">        <div class=\"split-layout\">          <div class=\"split-layout\">            <div>              <a class=\"site-header__logo\" href=\"/\">                <img alt=\"PyPI\" src=\"/static/images/logo-small.2a411bc6.svg\">              </a>            </div>            <form class=\"search-form search-form--primary\" action=\"/search/\" role=\"search\">              <label for=\"search\" class=\"sr-only\">Search PyPI</label>              <input id=\"search\" class=\"search-form__search\" type=\"text\" name=\"q\" placeholder=\"Search projects\" value=\"\" autocomplete=\"off\" autocapitalize=\"off\" spellcheck=\"false\" data-controller=\"search-focus\" data-action=\"keydown@window->search-focus#focusSearchField\" data-search-focus-target=\"searchField\">              <button type=\"submit\" class=\"search-form__button\">                <i class=\"fa fa-search\" aria-hidden=\"true\"></i>                <span class=\"sr-only\">Search</span>              </button>            </form>          </div><div data-html-include=\"/_includes/current-user-indicator/\">            <div id=\"user-indicator\" class=\"horizontal-menu horizontal-menu--light horizontal-menu--tall\">  <nav class=\"horizontal-menu horizontal-menu--light horizontal-menu--tall hide-on-tablet\" aria-label=\"Main navigation\">    <ul>      <li class=\"horizontal-menu__item\"><a href=\"/help/\" class=\"horizontal-menu__link\">Help</a></li>      <li class=\"horizontal-menu__item\"><a href=\"/sponsors/\" class=\"horizontal-menu__link\">Sponsors</a></li>      <li class=\"horizontal-menu__item\"><a href=\"/account/login/\" class=\"horizontal-menu__link\">Log in</a></li>      <li class=\"horizontal-menu__item\"><a href=\"/account/register/\" class=\"horizontal-menu__link\">Register</a></li>    </ul>  </nav>  <nav class=\"dropdown dropdown--on-menu hidden show-on-tablet\" aria-label=\"Main navigation\">    <button type=\"button\" class=\"horizontal-menu__link dropdown__trigger\" aria-haspopup=\"true\" aria-expanded=\"false\" aria-label=\"View menu\">Menu      <span class=\"dropdown__trigger-caret\">        <i class=\"fa fa-caret-down\" aria-hidden=\"true\"></i>      </span>    </button>    <ul class=\"dropdown__content\" aria-hidden=\"true\" aria-label=\"Main menu\">      <li><a class=\"dropdown__link\" href=\"/help/\">Help</a></li>      <li><a class=\"dropdown__link\" href=\"/sponsors/\">Sponsors</a></li>      <li><a class=\"dropdown__link\" href=\"/account/login/\">Log in</a></li>      <li><a class=\"dropdown__link\" href=\"/account/register/\">Register</a></li>    </ul>  </nav></div></div>        </div>      </div>    </header>    <div class=\"mobile-search\">      <form class=\"search-form search-form--fullwidth\" action=\"/search/\" role=\"search\">        <label for=\"mobile-search\" class=\"sr-only\">Search PyPI</label>        <input id=\"mobile-search\" class=\"search-form__search\" type=\"text\" name=\"q\" placeholder=\"Search projects\" value=\"\" autocomplete=\"off\" autocapitalize=\"off\" spellcheck=\"false\">                <button type=\"submit\" class=\"search-form__button\">          <i class=\"fa fa-search\" aria-hidden=\"true\"></i>          <span class=\"sr-only\">Search</span>        </button>      </form>    </div>    <main id=\"content\"><div class=\"hidden\"  data-controller=\"github-repo-stats\"  data-github-repo-stats-github-repo-info-outlet=\".github-repo-info\"  data-github-repo-stats-url-value=\"https://api.github.com/repos/Stonesjtu/pytorch_memlab\"  data-github-repo-stats-issue-url-value=\"https://api.github.com/search/issues?q=repo:Stonesjtu/pytorch_memlab+type:issue+state:open&amp;per_page=1\"></div><div class=\"banner\">  <div class=\"package-header\">    <div class=\"package-header__left\">      <h1 class=\"package-header__name\">        pytorch-memlab 0.3.0      </h1>      <div data-controller=\"clipboard\">        <p class=\"package-header__pip-instructions\">          <span id=\"pip-command\" data-clipboard-target=\"source\">pip install pytorch-memlab</span>          <button type=\"button\" class=\"copy-tooltip copy-tooltip-s\" data-action=\"clipboard#copy\" data-clipboard-target=\"tooltip\" data-clipboard-tooltip-value=\"Copy to clipboard\">            <i class=\"fa fa-copy\" aria-hidden=\"true\"></i>            <span class=\"sr-only\">Copy PIP instructions</span>          </button>        </p>      </div>    </div>    <div class=\"package-header__right\">      <a class=\"status-badge status-badge--good\" href=\"/project/pytorch-memlab/\">        <span>Latest version</span>      </a>      <p class=\"package-header__date\">Released: <time datetime=\"2023-07-29T13:27:13+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Jul 29, 2023</time>      </p>    </div>  </div></div><div class=\"horizontal-section horizontal-section--grey horizontal-section--thin\">  <div class=\"site-container\"><div data-html-include=\"/_includes/administer-project-include/pytorch-memlab\"></div>    <div class=\"split-layout split-layout--middle package-description\">      <p class=\"package-description__summary\">A lab to do simple and accurate memory experiments on pytorch</p><div data-html-include=\"/_includes/edit-project-button/pytorch-memlab\"></div>    </div>  </div></div><div data-controller=\"project-tabs\">  <div class=\"tabs-container\">    <div class=\"vertical-tabs\">      <div class=\"vertical-tabs__tabs\">        <div class=\"sidebar-section\">          <h3 class=\"sidebar-section__title\">Navigation</h3>          <nav aria-label=\"Navigation for pytorch-memlab\">            <ul class=\"vertical-tabs__list\" role=\"tablist\">              <li role=\"tab\">                <a id=\"description-tab\" href=\"#description\" data-project-tabs-target=\"tab\" data-action=\"project-tabs#onTabClick\" class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--is-active\" aria-selected=\"true\" aria-label=\"Project description. Focus will be moved to the description.\">                  <i class=\"fa fa-align-left\" aria-hidden=\"true\"></i>Project description                </a>              </li>              <li role=\"tab\">                <a id=\"history-tab\" href=\"#history\" data-project-tabs-target=\"tab\" data-action=\"project-tabs#onTabClick\" class=\"vertical-tabs__tab vertical-tabs__tab--with-icon\" aria-label=\"Release history. Focus will be moved to the history panel.\">                  <i class=\"fa fa-history\" aria-hidden=\"true\"></i>Release history                </a>              </li>              <li role=\"tab\">                <a id=\"files-tab\" href=\"#files\" data-project-tabs-target=\"tab\" data-action=\"project-tabs#onTabClick\" class=\"vertical-tabs__tab vertical-tabs__tab--with-icon\" aria-label=\"Download files. Focus will be moved to the project files.\">                  <i class=\"fa fa-download\" aria-hidden=\"true\"></i>Download files                </a>              </li>            </ul>          </nav>        </div><div class=\"sidebar-section\">  <h3 class=\"sidebar-section__title\">Project links</h3>  <ul class=\"vertical-tabs__list\">    <li>      <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\" href=\"https://github.com/Stonesjtu/pytorch_memlab\" rel=\"nofollow\">        <i class=\"fas fa-home\" aria-hidden=\"true\"></i>Homepage      </a>    </li>  </ul></div><div class=\"sidebar-section\">  <h3 class=\"sidebar-section__title\">Statistics</h3>  <div class=\"hidden github-repo-info\" data-controller=\"github-repo-info\">GitHub statistics:    <ul class=\"vertical-tabs__list\">      <li>        <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\"           data-github-repo-info-target=\"stargazersUrl\" rel=\"noopener\">          <i class=\"fa fa-star\" aria-hidden=\"true\"></i>          <strong>Stars:</strong>          <span data-github-repo-info-target=\"stargazersCount\"></span>        </a>      </li>      <li>        <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\"           data-github-repo-info-target=\"forksUrl\" rel=\"noopener\">          <i class=\"fa fa-code-branch\" aria-hidden=\"true\"></i>          <strong>Forks:</strong>          <span data-github-repo-info-target=\"forksCount\"></span>        </a>      </li>      <li>        <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\"           data-github-repo-info-target=\"openIssuesUrl\" rel=\"noopener\">          <i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>          <strong>Open issues:</strong>          <span data-github-repo-info-target=\"openIssuesCount\"></span>        </a>      </li>      <li>        <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\"           data-github-repo-info-target=\"openPRsUrl\" rel=\"noopener\">          <i class=\"fa fa-code-pull-request\" aria-hidden=\"true\"></i>          <strong>Open PRs:</strong>          <span data-github-repo-info-target=\"openPRsCount\"></span>        </a>      </li>    </ul>  </div>  <p>View statistics for this project via <a href=\"https://libraries.io/pypi/pytorch-memlab\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Libraries.io</a>, or by using <a href=\"https://packaging.python.org/guides/analyzing-pypi-package-downloads/\" target=\"_blank\" rel=\"noopener\">our public dataset on Google BigQuery</a>  </p></div><div class=\"sidebar-section\">  <h3 class=\"sidebar-section__title\">Meta</h3>  <p><strong>License:</strong> MIT</p>    <p><strong>Author:</strong> <a href=\"mailto:skyisno.1@gmail.com\">Kaiyu Shi</a></p>  <p class=\"tags\">    <i class=\"fa fa-tags\" aria-hidden=\"true\"></i>    <span class=\"sr-only\">Tags</span>    <span class=\"package-keyword\">      pytorch,    </span>    <span class=\"package-keyword\">      memory,    </span>    <span class=\"package-keyword\">      profile    </span>  </p></div><div class=\"sidebar-section\">    <h3 class=\"sidebar-section__title\">Maintainers</h3>      <span class=\"sidebar-section__maintainer\">        <a href=\"/user/yoursky/\" aria-label=\"yoursky\">          <span class=\"sidebar-section__user-gravatar\">            <img src=\"https://pypi-camo.freetls.fastly.net/aefb17b7ab3569d72f38ff328d42cf84b38fe48c/68747470733a2f2f7365637572652e67726176617461722e636f6d2f6176617461722f31366362353335616566643433383166666439313837643831376664333236313f73697a653d3530\" height=\"50\" width=\"50\" alt=\"Avatar for yoursky from gravatar.com\" title=\"Avatar for yoursky from gravatar.com\">          </span>          <span class=\"sidebar-section__user-gravatar-text\">            yoursky          </span>        </a>      </span></div><div class=\"sidebar-section\">  <h3 class=\"sidebar-section__title\">Classifiers</h3>  <ul class=\"sidebar-section__classifiers\">    <li>      <strong>Programming Language</strong>      <ul>        <li>          <a href=\"/search/?c=Programming+Language+%3A%3A+Python\">            Python          </a>        </li>      </ul>    </li>    <li>      <strong>Topic</strong>      <ul>        <li>          <a href=\"/search/?c=Topic+%3A%3A+Software+Development+%3A%3A+Libraries+%3A%3A+Python+Modules\">            Software Development :: Libraries :: Python Modules          </a>        </li>      </ul>    </li>  </ul></div><div class=\"sidebar-section\" data-ea-publisher=\"psf\" data-ea-type=\"psf\" data-ea-keywords=\"pypi-sidebar\"></div>      </div>      <div class=\"vertical-tabs__panel\">        <!-- mobile menu -->        <nav aria-label=\"Navigation for pytorch-memlab\">          <ul class=\"vertical-tabs__list\" role=\"tablist\">            <li role=\"tab\">              <a id=\"mobile-description-tab\" href=\"#description\" data-project-tabs-target=\"mobileTab\" data-action=\"project-tabs#onTabClick\" class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--mobile vertical-tabs__tab--no-top-border vertical-tabs__tab--is-active\" aria-selected=\"true\" aria-label=\"Project description. Focus will be moved to the description.\">                <i class=\"fa fa-align-left\" aria-hidden=\"true\"></i>Project description              </a>            </li>            <li role=\"tab\">              <a id=\"mobile-data-tab\" href=\"#data\" data-project-tabs-target=\"mobileTab\" data-action=\"project-tabs#onTabClick\" class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--mobile\" aria-label=\"Project details. Focus will be moved to the project details.\">                <i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>Project details              </a>            </li>            <li role=\"tab\">              <a id=\"mobile-history-tab\" href=\"#history\" data-project-tabs-target=\"mobileTab\" data-action=\"project-tabs#onTabClick\" class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--mobile\" aria-label=\"Release history. Focus will be moved to the history panel.\">              <i class=\"fa fa-history\" aria-hidden=\"true\"></i>Release history            </a>            </li>            <li role=\"tab\">              <a id=\"mobile-files-tab\" href=\"#files\" data-project-tabs-target=\"mobileTab\" data-action=\"project-tabs#onTabClick\" class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--mobile\" aria-label=\"Download files. Focus will be moved to the project files.\">                <i class=\"fa fa-download\" aria-hidden=\"true\"></i>Download files              </a>            </li>          </ul>        </nav>        <div id=\"description\" data-project-tabs-target=\"content\" class=\"vertical-tabs__content\" role=\"tabpanel\" aria-labelledby=\"description-tab mobile-description-tab\" tabindex=\"-1\">          <h2 class=\"page-title\">Project description</h2>          <div class=\"project-description\">            <h1>pytorch_memlab</h1><p><a href=\"https://travis-ci.com/Stonesjtu/pytorch_memlab\" rel=nofollow><img src=\"https://pypi-camo.freetls.fastly.net/e87d25d6537f8a463e7fd8fa72ff7e9e6ad93933/68747470733a2f2f7472617669732d63692e636f6d2f53746f6e65736a74752f7079746f7263685f6d656d6c61622e7376673f746f6b656e3d7679546478486269315043527a56366469734870266272616e63683d6d6173746572\" alt=\"Build Status\"></a><img src=\"https://pypi-camo.freetls.fastly.net/e3c1e9d0df2e053969e3b87efabae4de490d6215/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7079746f7263685f6d656d6c61622e737667\" alt=PyPI><a href=\"https://github.com/Stonesjtu/pytorch_memlab/actions/workflows/github-code-scanning/codeql\" rel=nofollow><img src=\"https://pypi-camo.freetls.fastly.net/f1e71e9aef6cf37c12ce76a42b952ca0a78597ee/68747470733a2f2f6769746875622e636f6d2f53746f6e65736a74752f7079746f7263685f6d656d6c61622f616374696f6e732f776f726b666c6f77732f6769746875622d636f64652d7363616e6e696e672f636f6465716c2f62616467652e737667\" alt=\"CodeQL: Python\"></a><img src=\"https://pypi-camo.freetls.fastly.net/219f5c9dd9f458428ef96d4d972e8077d8ec5430/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f7079746f7263685f6d656d6c61622e737667\" alt=\"PyPI - Downloads\"></p><p>A simple and accurate <strong>CUDA</strong> memory management laboratory for pytorch,it consists of different parts about the memory:</p><ul><li><p>Features:</p><ul><li>Memory Profiler: A <code>line_profiler</code> style CUDA memory profiler with simple API.</li><li>Memory Reporter: A reporter to inspect tensors occupying the CUDA memory.</li><li>Courtesy: An interesting feature to temporarily move all the CUDA tensors intoCPU memory for courtesy, and of course the backward transferring.</li><li>IPython support through <code>%mlrun</code>/<code>%%mlrun</code> line/cell magiccommands.</li></ul></li><li><p>Table of Contents</p><ul><li><a href=#installation rel=nofollow>Installation</a></li><li><a href=#user-doc rel=nofollow>User-Doc</a><ul><li><a href=#memory-profiler rel=nofollow>Memory Profiler</a></li><li><a href=#ipython-support rel=nofollow>IPython support</a></li><li><a href=#memory-reporter rel=nofollow>Memory Reporter</a></li><li><a href=#courtesy rel=nofollow>Courtesy</a></li><li><a href=#ack rel=nofollow>ACK</a></li></ul></li><li><a href=#changes rel=nofollow>CHANGES</a></li></ul></li></ul><h2>Installation</h2><ul><li>Released version:</li></ul><pre lang=bash>pip<span class=w> </span>install<span class=w> </span>pytorch_memlab</pre><ul><li>Newest version:</li></ul><pre lang=bash>pip<span class=w> </span>install<span class=w> </span>git+https://github.com/stonesjtu/pytorch_memlab</pre><h2>What's for</h2><p>Out-Of-Memory errors in pytorch happen frequently, for new-bees andexperienced programmers. A common reason is that most people don't reallylearn the underlying memory management philosophy of pytorch and GPUs.They wrote memory in-efficient codes and complained about pytorch eating toomuch CUDA memory.</p><p>In this repo, I'm going to share some useful tools to help debugging OOM, orto inspect the underlying mechanism if anyone is interested in.</p><h2>User-Doc</h2><h3>Memory Profiler</h3><p>The memory profiler is a modification of python's <code>line_profiler</code>, it givesthe memory usage info for each line of code in the specified function/method.</p><h4>Sample:</h4><pre lang=python3><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>LineProfiler</span><span class=k>def</span> <span class=nf>inner</span><span class=p>():</span>    <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=k>def</span> <span class=nf>outer</span><span class=p>():</span>    <span class=n>linear</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>    <span class=n>linear2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>    <span class=n>linear3</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=n>work</span><span class=p>()</span></pre><p>After the script finishes or interrupted by keyboard, it gives the followingprofiling info if you're in a Jupyter notebook:</p><p align=center><img src=\"https://pypi-camo.freetls.fastly.net/f808a529d281c4a7dcfc7878bc5f5a553b1a5766/726561646d652d6f75747075742e706e67\" width=640></p><p>or the following info if you're in a text-only terminal:</p><pre><code>## outeractive_bytes reserved_bytes line  code         all            all        peak           peak       0.00B          0.00B    7  def outer():      40.00K          2.00M    8      linear = torch.nn.Linear(100, 100).cuda()      80.00K          2.00M    9      linear2 = torch.nn.Linear(100, 100).cuda()     120.00K          2.00M   10      inner()## inneractive_bytes reserved_bytes line  code         all            all        peak           peak      80.00K          2.00M    4  def inner():     120.00K          2.00M    5      torch.nn.Linear(100, 100).cuda()</code></pre><p>An explanation of what each column means can be found in the <a href=\"https://pytorch.org/docs/stable/cuda.html#torch.cuda.memory_stats\" rel=nofollow>Torch documentation</a>. The name of any field from <code>memory_stats()</code>can be passed to <code>display()</code> to view the corresponding statistic.</p><p>If you use <code>profile</code> decorator, the memory statistics are collected duringmultiple runs and only the maximum one is displayed at the end.We also provide a more flexible API called <code>profile_every</code> which prints thememory info every <em>N</em> times of function execution. You can simply replace<code>@profile</code> with <code>@profile_every(1)</code> to print the memory usage for eachexecution.</p><p>The <code>@profile</code> and <code>@profile_every</code> can also be mixed to gain more controlof the debugging granularity.</p><ul><li>You can also add the decorator in the module class:</li></ul><pre lang=python3><span class=k>class</span> <span class=nc>Net</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>    <span class=nd>@profile</span>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inp</span><span class=p>):</span>        <span class=c1>#do_something</span></pre><ul><li>The <em>Line Profiler</em> profiles the memory usage of CUDA device 0 by default,you may want to switch the device to profile by <code>set_target_gpu</code>. The gpuselection is globally,  which means you have to remember which gpu you areprofiling on during the whole process:</li></ul><pre lang=python3><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>profile</span><span class=p>,</span> <span class=n>set_target_gpu</span><span class=nd>@profile</span><span class=k>def</span> <span class=nf>func</span><span class=p>():</span>    <span class=n>net1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>    <span class=n>set_target_gpu</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>    <span class=n>net2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>    <span class=n>set_target_gpu</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>    <span class=n>net3</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=n>func</span><span class=p>()</span></pre><p>More samples can be found in <code>test/test_line_profiler.py</code></p><h3>IPython support</h3><p>Make sure you have <code>IPython</code> installed, or have installed <code>pytorch-memlab</code> with<code>pip install pytorch-memlab[ipython]</code>.</p><p>First, load the extension:</p><pre lang=python3><span class=o>%</span><span class=n>load_ext</span> <span class=n>pytorch_memlab</span></pre><p>This makes the <code>%mlrun</code> and <code>%%mlrun</code> line/cell magics available for use. Forexample, in a new cell run the following to profile an entire cell</p><pre lang=python3><span class=o>%%</span><span class=n>mlrun</span> <span class=o>-</span><span class=n>f</span> <span class=n>func</span><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>profile</span><span class=p>,</span> <span class=n>set_target_gpu</span><span class=k>def</span> <span class=nf>func</span><span class=p>():</span>    <span class=n>net1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>    <span class=n>set_target_gpu</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>    <span class=n>net2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>    <span class=n>set_target_gpu</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>    <span class=n>net3</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span></pre><p>Or you can invoke the profiler for a single statement on via the <code>%mlrun</code> cellmagic.</p><pre lang=python3><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>profile</span><span class=p>,</span> <span class=n>set_target_gpu</span><span class=k>def</span> <span class=nf>func</span><span class=p>(</span><span class=n>input_size</span><span class=p>):</span>    <span class=n>net1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_size</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>%</span><span class=n>mlrun</span> <span class=o>-</span><span class=n>f</span> <span class=n>func</span> <span class=n>func</span><span class=p>(</span><span class=mi>2048</span><span class=p>)</span></pre><p>See <code>%mlrun?</code> for help on what arguments are supported. You can set the GPUdevice to profile, dump profiling results to a file, and return the<code>LineProfiler</code> object for post-profile inspection.</p><p>Find out more by checking out the <a href=\"./demo.ipynb\" rel=nofollow>demo Jupyter notebook</a></p><h3>Memory Reporter</h3><p>As <em>Memory Profiler</em> only gives the overall memory usage information by lines,a more low-level memory usage information can be obtained by <em>Memory Reporter</em>.</p><p><em>Memory reporter</em> iterates all the <code>Tensor</code> objects and gets the underlying<code>Storage</code> object to get the actual memory usage instead of the surface<code>Tensor.size</code>.</p><h4>Sample</h4><ul><li>A minimal one:</li></ul><pre lang=python3><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>MemReporter</span><span class=n>linear</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=n>reporter</span> <span class=o>=</span> <span class=n>MemReporter</span><span class=p>()</span><span class=n>reporter</span><span class=o>.</span><span class=n>report</span><span class=p>()</span></pre><p>outputs:</p><pre><code>Element type                                            Size  Used MEM-------------------------------------------------------------------------------Storage on cuda:0Parameter0                                      (1024, 1024)     4.00MParameter1                                           (1024,)     4.00K-------------------------------------------------------------------------------Total Tensors: 1049600  Used Memory: 4.00MThe allocated memory on cuda:0: 4.00M-------------------------------------------------------------------------------</code></pre><ul><li>You can also pass in a model object for automatically name inference.</li></ul><pre lang=python3><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>MemReporter</span><span class=n>linear</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=n>inp</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=c1># pass in a model to automatically infer the tensor names</span><span class=n>reporter</span> <span class=o>=</span> <span class=n>MemReporter</span><span class=p>(</span><span class=n>linear</span><span class=p>)</span><span class=n>out</span> <span class=o>=</span> <span class=n>linear</span><span class=p>(</span><span class=n>inp</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=nb>print</span><span class=p>(</span><span class=s1>'========= before backward ========='</span><span class=p>)</span><span class=n>reporter</span><span class=o>.</span><span class=n>report</span><span class=p>()</span><span class=n>out</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span><span class=nb>print</span><span class=p>(</span><span class=s1>'========= after backward ========='</span><span class=p>)</span><span class=n>reporter</span><span class=o>.</span><span class=n>report</span><span class=p>()</span></pre><p>outputs:</p><pre><code>========= before backward =========Element type                                            Size  Used MEM-------------------------------------------------------------------------------Storage on cuda:0weight                                          (1024, 1024)     4.00Mbias                                                 (1024,)     4.00KTensor0                                          (512, 1024)     2.00MTensor1                                                 (1,)   512.00B-------------------------------------------------------------------------------Total Tensors: 1573889  Used Memory: 6.00MThe allocated memory on cuda:0: 6.00M-------------------------------------------------------------------------------========= after backward =========Element type                                            Size  Used MEM-------------------------------------------------------------------------------Storage on cuda:0weight                                          (1024, 1024)     4.00Mweight.grad                                     (1024, 1024)     4.00Mbias                                                 (1024,)     4.00Kbias.grad                                            (1024,)     4.00KTensor0                                          (512, 1024)     2.00MTensor1                                                 (1,)   512.00B-------------------------------------------------------------------------------Total Tensors: 2623489  Used Memory: 10.01MThe allocated memory on cuda:0: 10.01M-------------------------------------------------------------------------------</code></pre><ul><li>The reporter automatically deals with the sharing weights parameters:</li></ul><pre lang=python3><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>MemReporter</span><span class=n>linear</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=n>linear2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=n>linear2</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=n>linear</span><span class=o>.</span><span class=n>weight</span><span class=n>container</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>    <span class=n>linear</span><span class=p>,</span> <span class=n>linear2</span><span class=p>)</span><span class=n>inp</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=c1># pass in a model to automatically infer the tensor names</span><span class=n>out</span> <span class=o>=</span> <span class=n>container</span><span class=p>(</span><span class=n>inp</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=n>out</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span><span class=c1># verbose shows how storage is shared across multiple Tensors</span><span class=n>reporter</span> <span class=o>=</span> <span class=n>MemReporter</span><span class=p>(</span><span class=n>container</span><span class=p>)</span><span class=n>reporter</span><span class=o>.</span><span class=n>report</span><span class=p>(</span><span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></pre><p>outputs:</p><pre><code>Element type                                            Size  Used MEM-------------------------------------------------------------------------------Storage on cuda:00.weight                                        (1024, 1024)     4.00M0.weight.grad                                   (1024, 1024)     4.00M0.bias                                               (1024,)     4.00K0.bias.grad                                          (1024,)     4.00K1.bias                                               (1024,)     4.00K1.bias.grad                                          (1024,)     4.00KTensor0                                          (512, 1024)     2.00MTensor1                                                 (1,)   512.00B-------------------------------------------------------------------------------Total Tensors: 2625537  Used Memory: 10.02MThe allocated memory on cuda:0: 10.02M-------------------------------------------------------------------------------</code></pre><ul><li>You can better understand the memory layout for more complicated module:</li></ul><pre lang=python3><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>MemReporter</span><span class=n>lstm</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>LSTM</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=n>reporter</span> <span class=o>=</span> <span class=n>MemReporter</span><span class=p>(</span><span class=n>lstm</span><span class=p>)</span><span class=n>reporter</span><span class=o>.</span><span class=n>report</span><span class=p>(</span><span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=n>inp</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=n>out</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>lstm</span><span class=p>(</span><span class=n>inp</span><span class=p>)</span><span class=n>out</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span><span class=n>reporter</span><span class=o>.</span><span class=n>report</span><span class=p>(</span><span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></pre><p>As shown below, the <code>(-&gt;)</code> indicates the re-use of the same storage back-endoutputs:</p><pre><code>Element type                                            Size  Used MEM-------------------------------------------------------------------------------Storage on cuda:0weight_ih_l0                                    (4096, 1024)    32.03Mweight_hh_l0(-&gt;weight_ih_l0)                    (4096, 1024)     0.00Bbias_ih_l0(-&gt;weight_ih_l0)                           (4096,)     0.00Bbias_hh_l0(-&gt;weight_ih_l0)                           (4096,)     0.00BTensor0                                       (10, 10, 1024)   400.00K-------------------------------------------------------------------------------Total Tensors: 8499200  Used Memory: 32.42MThe allocated memory on cuda:0: 32.52MMemory differs due to the matrix alignment-------------------------------------------------------------------------------Element type                                            Size  Used MEM-------------------------------------------------------------------------------Storage on cuda:0weight_ih_l0                                    (4096, 1024)    32.03Mweight_ih_l0.grad                               (4096, 1024)    32.03Mweight_hh_l0(-&gt;weight_ih_l0)                    (4096, 1024)     0.00Bweight_hh_l0.grad(-&gt;weight_ih_l0.grad)          (4096, 1024)     0.00Bbias_ih_l0(-&gt;weight_ih_l0)                           (4096,)     0.00Bbias_ih_l0.grad(-&gt;weight_ih_l0.grad)                 (4096,)     0.00Bbias_hh_l0(-&gt;weight_ih_l0)                           (4096,)     0.00Bbias_hh_l0.grad(-&gt;weight_ih_l0.grad)                 (4096,)     0.00BTensor0                                       (10, 10, 1024)   400.00KTensor1                                       (10, 10, 1024)   400.00KTensor2                                        (1, 10, 1024)    40.00KTensor3                                        (1, 10, 1024)    40.00K-------------------------------------------------------------------------------Total Tensors: 17018880         Used Memory: 64.92MThe allocated memory on cuda:0: 65.11MMemory differs due to the matrix alignment-------------------------------------------------------------------------------</code></pre><p>NOTICE:</p><blockquote><p>When forwarding with <code>grad_mode=True</code>, pytorch maintains tensor buffers forfuture Back-Propagation, in C level. So these buffers are not going to bemanaged or collected by pytorch. But if you store these intermediate resultsas python variables, then they will be reported.</p></blockquote><ul><li><p>You can also filter the device to report on by passing extra arguments:<code>report(device=torch.device(0))</code></p></li><li><p>A failed example due to pytorch's C side tensor buffers</p></li></ul><p>In the following example, a temp buffer is created at <code>inp * (inp + 2)</code> tostore both <code>inp</code> and <code>inp + 2</code>, unfortunately python only knows the existenceof inp, so we have <em>2M</em> memory lost, which is the same size of Tensor <code>inp</code>.</p><pre lang=python3><span class=kn>import</span> <span class=nn>torch</span><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>MemReporter</span><span class=n>linear</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=n>inp</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=c1># pass in a model to automatically infer the tensor names</span><span class=n>reporter</span> <span class=o>=</span> <span class=n>MemReporter</span><span class=p>(</span><span class=n>linear</span><span class=p>)</span><span class=n>out</span> <span class=o>=</span> <span class=n>linear</span><span class=p>(</span><span class=n>inp</span> <span class=o>*</span> <span class=p>(</span><span class=n>inp</span> <span class=o>+</span> <span class=mi>2</span><span class=p>))</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=n>reporter</span><span class=o>.</span><span class=n>report</span><span class=p>()</span></pre><p>outputs:</p><pre><code>Element type                                            Size  Used MEM-------------------------------------------------------------------------------Storage on cuda:0weight                                          (1024, 1024)     4.00Mbias                                                 (1024,)     4.00KTensor0                                          (512, 1024)     2.00MTensor1                                                 (1,)   512.00B-------------------------------------------------------------------------------Total Tensors: 1573889  Used Memory: 6.00MThe allocated memory on cuda:0: 8.00MMemory differs due to the matrix alignment or invisible gradient buffer tensors-------------------------------------------------------------------------------</code></pre><h3>Courtesy</h3><p>Sometimes people would like to preempt your running task, but you don't wantto save checkpoint and then load, actually all they need is GPU resources (typically CPU resources and CPU memory is always spare in GPU clusters), soyou can move all your workspaces from GPU to CPU and then halt your task untila restart signal is triggered, instead of saving&amp;loading checkpoints andbootstrapping from scratch.</p><p>Still developing..... But you can have fun with:</p><pre lang=python3><span class=kn>from</span> <span class=nn>pytorch_memlab</span> <span class=kn>import</span> <span class=n>Courtesy</span><span class=n>iamcourtesy</span> <span class=o>=</span> <span class=n>Courtesy</span><span class=p>()</span><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_iteration</span><span class=p>):</span>    <span class=k>if</span> <span class=n>something_happens</span><span class=p>:</span>        <span class=n>iamcourtesy</span><span class=o>.</span><span class=n>yield_memory</span><span class=p>()</span>        <span class=n>wait_for_restart_signal</span><span class=p>()</span>        <span class=n>iamcourtesy</span><span class=o>.</span><span class=n>restore</span><span class=p>()</span></pre><h4>Known Issues</h4><ul><li>As is stated above in <code>Memory_Reporter</code>, intermediate tensors are not coveredproperly, so you may want to insert such courtesy logics after <code>backward</code> orbefore <code>forward</code>.</li><li>Currently the CUDA context of pytorch requires about 1 GB CUDA memory, whichmeans even all Tensors are on CPU, 1GB of CUDA memory is wasted, :-(. Howeverit's still under investigation if I can fully destroy the context and thenre-init.</li></ul><h3>ACK</h3><p>I suffered a lot debugging weird memory usage during my 3-years of developingefficient Deep Learning models, and of course learned a lot from the greatopen source community.</p><h2>CHANGES</h2><h5>0.2.4 (2021-10-28)</h5><ul><li>Fix colab error (#35)</li><li>Support python3.8 (#38)</li><li>Support sparse tensor (#30)</li></ul><h5>0.2.3 (2020-12-01)</h5><ul><li>Fix name mapping in <code>MemReporter</code> (#24)</li><li>Fix reporter without model input (#22 #25)</li></ul><h5>0.2.2 (2020-10-23)</h5><ul><li>Fix memory leak in <code>MemReporter</code></li></ul><h5>0.2.1 (2020-06-18)</h5><ul><li>Fix <code>line_profiler</code> not found</li></ul><h5>0.2.0 (2020-06-15)</h5><ul><li>Add jupyter notebook figure and ipython support</li></ul><h5>0.1.0 (2020-04-17)</h5><ul><li>Add ipython magic support (#8)</li></ul><h5>0.0.4 (2019-10-08)</h5><ul><li>Add gpu switch for line-profiler(#2)</li><li>Add device filter for reporter</li></ul><h5>0.0.3 (2019-06-15)</h5><ul><li>Install dependency for pip installation</li></ul><h5>0.0.2 (2019-06-04)</h5><ul><li>Fix statistics shift in loop</li></ul><h5>0.0.1 (2019-05-28)</h5><ul><li>initial release</li></ul>          </div>        </div>        <div id=\"data\" data-project-tabs-target=\"content\" class=\"vertical-tabs__content\" role=\"tabpanel\" aria-labelledby=\"mobile-data-tab\" tabindex=\"-1\">          <h2 class=\"page-title\">Project details</h2><div class=\"sidebar-section\">  <h3 class=\"sidebar-section__title\">Project links</h3>  <ul class=\"vertical-tabs__list\">    <li>      <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\" href=\"https://github.com/Stonesjtu/pytorch_memlab\" rel=\"nofollow\">        <i class=\"fas fa-home\" aria-hidden=\"true\"></i>Homepage      </a>    </li>  </ul></div><div class=\"sidebar-section\">  <h3 class=\"sidebar-section__title\">Statistics</h3>  <div class=\"hidden github-repo-info\" data-controller=\"github-repo-info\">GitHub statistics:    <ul class=\"vertical-tabs__list\">      <li>        <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\"           data-github-repo-info-target=\"stargazersUrl\" rel=\"noopener\">          <i class=\"fa fa-star\" aria-hidden=\"true\"></i>          <strong>Stars:</strong>          <span data-github-repo-info-target=\"stargazersCount\"></span>        </a>      </li>      <li>        <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\"           data-github-repo-info-target=\"forksUrl\" rel=\"noopener\">          <i class=\"fa fa-code-branch\" aria-hidden=\"true\"></i>          <strong>Forks:</strong>          <span data-github-repo-info-target=\"forksCount\"></span>        </a>      </li>      <li>        <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\"           data-github-repo-info-target=\"openIssuesUrl\" rel=\"noopener\">          <i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>          <strong>Open issues:</strong>          <span data-github-repo-info-target=\"openIssuesCount\"></span>        </a>      </li>      <li>        <a class=\"vertical-tabs__tab vertical-tabs__tab--with-icon vertical-tabs__tab--condensed\"           data-github-repo-info-target=\"openPRsUrl\" rel=\"noopener\">          <i class=\"fa fa-code-pull-request\" aria-hidden=\"true\"></i>          <strong>Open PRs:</strong>          <span data-github-repo-info-target=\"openPRsCount\"></span>        </a>      </li>    </ul>  </div>  <p>View statistics for this project via <a href=\"https://libraries.io/pypi/pytorch-memlab\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Libraries.io</a>, or by using <a href=\"https://packaging.python.org/guides/analyzing-pypi-package-downloads/\" target=\"_blank\" rel=\"noopener\">our public dataset on Google BigQuery</a>  </p></div><div class=\"sidebar-section\">  <h3 class=\"sidebar-section__title\">Meta</h3>  <p><strong>License:</strong> MIT</p>    <p><strong>Author:</strong> <a href=\"mailto:skyisno.1@gmail.com\">Kaiyu Shi</a></p>  <p class=\"tags\">    <i class=\"fa fa-tags\" aria-hidden=\"true\"></i>    <span class=\"sr-only\">Tags</span>    <span class=\"package-keyword\">      pytorch,    </span>    <span class=\"package-keyword\">      memory,    </span>    <span class=\"package-keyword\">      profile    </span>  </p></div><div class=\"sidebar-section\">    <h3 class=\"sidebar-section__title\">Maintainers</h3>      <span class=\"sidebar-section__maintainer\">        <a href=\"/user/yoursky/\" aria-label=\"yoursky\">          <span class=\"sidebar-section__user-gravatar\">            <img src=\"https://pypi-camo.freetls.fastly.net/aefb17b7ab3569d72f38ff328d42cf84b38fe48c/68747470733a2f2f7365637572652e67726176617461722e636f6d2f6176617461722f31366362353335616566643433383166666439313837643831376664333236313f73697a653d3530\" height=\"50\" width=\"50\" alt=\"Avatar for yoursky from gravatar.com\" title=\"Avatar for yoursky from gravatar.com\">          </span>          <span class=\"sidebar-section__user-gravatar-text\">            yoursky          </span>        </a>      </span></div><div class=\"sidebar-section\">  <h3 class=\"sidebar-section__title\">Classifiers</h3>  <ul class=\"sidebar-section__classifiers\">    <li>      <strong>Programming Language</strong>      <ul>        <li>          <a href=\"/search/?c=Programming+Language+%3A%3A+Python\">            Python          </a>        </li>      </ul>    </li>    <li>      <strong>Topic</strong>      <ul>        <li>          <a href=\"/search/?c=Topic+%3A%3A+Software+Development+%3A%3A+Libraries+%3A%3A+Python+Modules\">            Software Development :: Libraries :: Python Modules          </a>        </li>      </ul>    </li>  </ul></div>          <br>        </div>        <div id=\"history\" data-project-tabs-target=\"content\" class=\"vertical-tabs__content\" role=\"tabpanel\" aria-labelledby=\"history-tab mobile-history-tab\" tabindex=\"-1\">          <h2 class=\"page-title split-layout\">            <span>Release history</span>            <span class=\"reset-text margin-top\">              <a href=\"/help/#project-release-notifications\">Release notifications</a> |              <a href=\"/rss/project/pytorch-memlab/releases.xml\">RSS feed <i class=\"fa fa-rss\" aria-hidden=\"true\"></i></a>            </span>          </h2>          <div class=\"release-timeline\">            <div class=\"release release--latest release--current\">              <div class=\"release__meta\">                <span class=\"badge\">This version</span>              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/blue-cube.572a5bfb.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.3.0/\">                <p class=\"release__version\">                  0.3.0                </p>                <p class=\"release__version-date\">                  <time datetime=\"2023-07-29T13:27:13+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Jul 29, 2023</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.2.4/\">                <p class=\"release__version\">                  0.2.4                </p>                <p class=\"release__version-date\">                  <time datetime=\"2021-10-28T05:58:54+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Oct 28, 2021</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.2.3/\">                <p class=\"release__version\">                  0.2.3                </p>                <p class=\"release__version-date\">                  <time datetime=\"2020-12-01T10:22:08+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Dec 1, 2020</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.2.2/\">                <p class=\"release__version\">                  0.2.2                </p>                <p class=\"release__version-date\">                  <time datetime=\"2020-10-23T11:32:08+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Oct 23, 2020</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.2.1/\">                <p class=\"release__version\">                  0.2.1                </p>                <p class=\"release__version-date\">                  <time datetime=\"2020-06-18T02:52:13+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Jun 18, 2020</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.2.0/\">                <p class=\"release__version\">                  0.2.0                </p>                <p class=\"release__version-date\">                  <time datetime=\"2020-06-15T11:08:36+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Jun 15, 2020</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.1.0/\">                <p class=\"release__version\">                  0.1.0                </p>                <p class=\"release__version-date\">                  <time datetime=\"2020-04-17T08:02:40+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Apr 17, 2020</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.0.4/\">                <p class=\"release__version\">                  0.0.4                </p>                <p class=\"release__version-date\">                  <time datetime=\"2019-10-08T06:29:14+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Oct 8, 2019</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.0.3/\">                <p class=\"release__version\">                  0.0.3                </p>                <p class=\"release__version-date\">                  <time datetime=\"2019-06-16T01:23:44+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Jun 16, 2019</time>                </p>              </a>            </div>            <div class=\"release\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.0.2/\">                <p class=\"release__version\">                  0.0.2                </p>                <p class=\"release__version-date\">                  <time datetime=\"2019-06-04T19:19:36+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Jun 4, 2019</time>                </p>              </a>            </div>            <div class=\"release release--oldest\">              <div class=\"release__meta\">              </div>              <div class=\"release__graphic\">                <div class=\"release__line\"></div>                <img class=\"release__node\" alt=\"\" src=\"https://pypi.org/static/images/white-cube.2351a86c.svg\">              </div>              <a class=\"card release__card\" href=\"/project/pytorch-memlab/0.0.1/\">                <p class=\"release__version\">                  0.0.1                </p>                <p class=\"release__version-date\">                  <time datetime=\"2019-05-28T01:44:04+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  May 28, 2019</time>                </p>              </a>            </div>          </div>        </div>          <div id=\"files\" data-project-tabs-target=\"content\" class=\"vertical-tabs__content\" role=\"tabpanel\" aria-labelledby=\"files-tab mobile-files-tab\" tabindex=\"-1\">            <h2 class=\"page-title\">Download files</h2>            <p>Download the file for your platform. If you're not sure which to choose, learn more about <a href=\"https://packaging.python.org/tutorials/installing-packages/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">installing packages</a>.</p>            <h3>Source Distribution            </h3>                  <div class=\"file\">      <div class=\"file__graphic\">        <i class=\"far fa-file\" aria-hidden=\"true\"></i>      </div>      <div class=\"card file__card\">        <a href=\"https://files.pythonhosted.org/packages/7f/8e/528f7ebccdd855aa0769c118548f77535fa33286ca6a0a833b92435c74fd/pytorch-memlab-0.3.0.tar.gz\">          pytorch-memlab-0.3.0.tar.gz        </a>        (22.6 kB        <a href=\"#copy-hash-modal-fd2ed3fc-fe1a-4b4b-b576-57820ccde593\">view hashes</a>)        <p class=\"file__meta\">          Uploaded <time datetime=\"2023-07-29T13:27:13+0000\" data-controller=\"localized-time\" data-localized-time-relative=\"true\" data-localized-time-show-time=\"false\">  Jul 29, 2023</time>          <code>source</code>        </p>      </div>    </div>          </div><div id=\"copy-hash-modal-fd2ed3fc-fe1a-4b4b-b576-57820ccde593\" class=\"modal modal--wide\">  <div class=\"modal__content\" role=\"dialog\">    <a href=\"#modal-close\" title=\"Close\" class=\"modal__close\">      <i class=\"fa fa-times\" aria-hidden=\"true\"></i>      <span class=\"sr-only\">Close</span>    </a>    <div class=\"modal__body\">      <h3 class=\"modal__title\"><a href=\"https://pip.pypa.io/en/stable/topics/secure-installs/#hash-checking-mode\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Hashes</a> for pytorch-memlab-0.3.0.tar.gz      </h3>      <table class=\"table table--hashes\">        <caption class=\"sr-only\">Hashes for pytorch-memlab-0.3.0.tar.gz</caption>        <thead>          <tr>            <th scope=\"col\">Algorithm</th>            <th scope=\"col\">Hash digest</th>            <th></th>          </tr>        </thead>        <tbody>          <tr data-controller=\"clipboard\">            <th scope=\"row\">SHA256</th>            <td><code data-clipboard-target=\"source\">4c80a9cf2ba4246e23352c408147fe8b1cec3a96bc69d81a63d67eb3fab16ab4</code></td>            <td class=\"table__align-right\">              <button type=\"button\" class=\"button button--small copy-tooltip copy-tooltip-w\" data-action=\"clipboard#copy\" data-clipboard-target=\"tooltip\" data-clipboard-tooltip-value=\"Copy to clipboard\">Copy              </button>            </td>          </tr>          <tr data-controller=\"clipboard\">            <th scope=\"row\">MD5</th>            <td><code data-clipboard-target=\"source\">7232a9a3253732e8dcdc9d4e30b39d27</code></td>            <td class=\"table__align-right\">              <button type=\"button\" class=\"button button--small copy-tooltip copy-tooltip-w\" data-action=\"clipboard#copy\" data-clipboard-target=\"tooltip\" data-clipboard-tooltip-value=\"Copy to clipboard\">Copy              </button>            </td>          </tr>          <tr data-controller=\"clipboard\">            <th scope=\"row\">BLAKE2b-256</th>            <td><code data-clipboard-target=\"source\">7f8e528f7ebccdd855aa0769c118548f77535fa33286ca6a0a833b92435c74fd</code></td>            <td class=\"table__align-right\">              <button type=\"button\" class=\"button button--small copy-tooltip copy-tooltip-w\" data-action=\"clipboard#copy\" data-clipboard-target=\"tooltip\" data-clipboard-tooltip-value=\"Copy to clipboard\">Copy              </button>            </td>          </tr>        </tbody>      </table>    </div>    <div class=\"modal__footer\">      <a href=\"#modal-close\" class=\"button button--primary modal__action\">Close</a>    </div>  </div></div>      </div>    </div>  </div></div>    </main>    <footer class=\"footer\">      <div class=\"footer__logo\">        <img src=\"/static/images/white-cube.2351a86c.svg\" alt=\"\" class=\"-js-white-cube\">      </div>      <div class=\"footer__menus\">        <div class=\"footer__menu\">          <h2>Help</h2>          <nav aria-label=\"Help navigation\">            <ul>              <li><a href=\"https://packaging.python.org/tutorials/installing-packages/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Installing packages</a></li>              <li><a href=\"https://packaging.python.org/tutorials/packaging-projects/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Uploading packages</a></li>              <li><a href=\"https://packaging.python.org/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">User guide</a></li>              <li><a href=\"https://www.python.org/dev/peps/pep-0541/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Project name retention</a></li>              <li><a href=\"/help/\">FAQs</a></li>            </ul>          </nav>        </div>        <div class=\"footer__menu\">          <h2>About PyPI</h2>          <nav aria-label=\"About PyPI navigation\">            <ul>              <li><a href=\"https://twitter.com/PyPI\" title=\"External link\" target=\"_blank\" rel=\"noopener\">PyPI on Twitter</a></li>              <li><a href=\"https://dtdg.co/pypi\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Infrastructure dashboard</a></li>              <li><a href=\"/stats/\">Statistics</a></li>              <li><a href=\"/trademarks/\">Logos & trademarks</a></li>              <li><a href=\"/sponsors/\">Our sponsors</a></li>            </ul>          </nav>        </div>        <div class=\"footer__menu\">          <h2>Contributing to PyPI</h2>          <nav aria-label=\"How to contribute navigation\">            <ul>              <li><a href=\"/help/#feedback\">Bugs and feedback</a></li>              <li><a href=\"https://github.com/pypi/warehouse\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Contribute on GitHub</a></li>              <li><a href=\"https://hosted.weblate.org/projects/pypa/warehouse/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Translate PyPI</a></li>              <li><a href=\"/sponsors/\">Sponsor PyPI</a></li>              <li><a href=\"https://github.com/pypi/warehouse/graphs/contributors\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Development credits</a></li>            </ul>          </nav>        </div>        <div class=\"footer__menu\">          <h2>Using PyPI</h2>          <nav aria-label=\"Using PyPI navigation\">            <ul>              <li><a href=\"https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Code of conduct</a></li>              <li><a href=\"/security/\">Report security issue</a></li>              <li><a href=\"https://www.python.org/privacy/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Privacy policy</a></li>              <li><a href=\"/policy/terms-of-use/\">Terms of use</a></li>              <li><a href=\"/policy/acceptable-use-policy/\">Acceptable Use Policy</a></li>            </ul>          </nav>        </div>      </div>      <hr class=\"footer__divider\">      <div class=\"footer__text\">        <p>Status:<a href=\"https://status.python.org/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">          <span data-statuspage-domain=\"https://2p66nmmycsj3.statuspage.io\">all systems operational</span></a>        </p>        <p>Developed and maintained by the Python community, for the Python community.          <br>          <a href=\"https://donate.pypi.org\">Donate today!</a>        </p>        <p>          \"PyPI\", \"Python Package Index\", and the blocks logos are registered <a href=\"/trademarks/\">trademarks</a> of the <a href=\"https://python.org/psf-landing\" target=\"_blank\" rel=\"noopener\">Python Software Foundation</a>.<br>        </p>        <p>          \u00a9 2024 <a href=\"https://www.python.org/psf-landing/\" title=\"External link\" target=\"_blank\" rel=\"noopener\">Python Software Foundation</a><br>          <a href=\"/sitemap/\">Site map</a>        </p>      </div>      <div class=\"centered hide-on-desktop\">        <button type=\"button\" class=\"button button--switch-to-desktop hidden\" data-viewport-toggle-target=\"switchToDesktop\" data-action=\"viewport-toggle#switchToDesktop\">Switch to desktop version        </button>      </div>    </footer>    <div class=\"language-switcher\">      <form action=\"/locale/\">        <ul>          <li>            <button              class=\"language-switcher__selected\"              name=\"locale_id\" value=\"en\" type=\"submit\"            >              English            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"es\" type=\"submit\"            >              espa\u00f1ol            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"fr\" type=\"submit\"            >              fran\u00e7ais            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"ja\" type=\"submit\"            >              \u65e5\u672c\u8a9e            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"pt_BR\" type=\"submit\"            >              portugu\u00eas (Brasil)            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"uk\" type=\"submit\"            >              \u0443\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"el\" type=\"submit\"            >              \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"de\" type=\"submit\"            >              Deutsch            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"zh_Hans\" type=\"submit\"            >              \u4e2d\u6587 (\u7b80\u4f53)            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"zh_Hant\" type=\"submit\"            >              \u4e2d\u6587 (\u7e41\u9ad4)            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"ru\" type=\"submit\"            >              \u0440\u0443\u0441\u0441\u043a\u0438\u0439            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"he\" type=\"submit\"            >              \u05e2\u05d1\u05e8\u05d9\u05ea            </button>          </li>          <li>            <button              name=\"locale_id\" value=\"eo\" type=\"submit\"            >              esperanto            </button>          </li>        </ul>      </form>    </div><div class=\"sponsors\">  <p class=\"sponsors__title\">Supported by</p>  <div class=\"sponsors__divider\"></div>        <a class=\"sponsors__sponsor\" target=\"_blank\" rel=\"noopener\" href=\"https://aws.amazon.com/\">          <img class=sponsors__image src=\"https://pypi-camo.freetls.fastly.net/ed7074cadad1a06f56bc520ad9bd3e00d0704c5b/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f707970692d6173736574732f73706f6e736f726c6f676f732f6177732d77686974652d6c6f676f2d7443615473387a432e706e67\" alt=AWS loading=lazy>          <span class=\"sponsors__name\">AWS</span>          <span class=\"sponsors__service\">            Cloud computing and Security Sponsor          </span>        </a>        <a class=\"sponsors__sponsor\" target=\"_blank\" rel=\"noopener\" href=\"https://www.datadoghq.com/\">          <img class=sponsors__image src=\"https://pypi-camo.freetls.fastly.net/8855f7c063a3bdb5b0ce8d91bfc50cf851cc5c51/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f707970692d6173736574732f73706f6e736f726c6f676f732f64617461646f672d77686974652d6c6f676f2d6668644c4e666c6f2e706e67\" alt=Datadog loading=lazy>          <span class=\"sponsors__name\">Datadog</span>          <span class=\"sponsors__service\">            Monitoring          </span>        </a>        <a class=\"sponsors__sponsor\" target=\"_blank\" rel=\"noopener\" href=\"https://www.fastly.com/\">          <img class=sponsors__image src=\"https://pypi-camo.freetls.fastly.net/df6fe8829cbff2d7f668d98571df1fd011f36192/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f707970692d6173736574732f73706f6e736f726c6f676f732f666173746c792d77686974652d6c6f676f2d65684d3077735f6f2e706e67\" alt=Fastly loading=lazy>          <span class=\"sponsors__name\">Fastly</span>          <span class=\"sponsors__service\">            CDN          </span>        </a>        <a class=\"sponsors__sponsor\" target=\"_blank\" rel=\"noopener\" href=\"https://careers.google.com/\">          <img class=sponsors__image src=\"https://pypi-camo.freetls.fastly.net/420cc8cf360bac879e24c923b2f50ba7d1314fb0/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f707970692d6173736574732f73706f6e736f726c6f676f732f676f6f676c652d77686974652d6c6f676f2d616734424e3774332e706e67\" alt=Google loading=lazy>          <span class=\"sponsors__name\">Google</span>          <span class=\"sponsors__service\">            Download Analytics          </span>        </a>        <a class=\"sponsors__sponsor\" target=\"_blank\" rel=\"noopener\" href=\"https://www.python.org/psf/sponsors/#microsoft\">          <img class=sponsors__image src=\"https://pypi-camo.freetls.fastly.net/524d1ce72f7772294ca4c1fe05d21dec8fa3f8ea/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f707970692d6173736574732f73706f6e736f726c6f676f732f6d6963726f736f66742d77686974652d6c6f676f2d5a443172685444462e706e67\" alt=Microsoft loading=lazy>          <span class=\"sponsors__name\">Microsoft</span>          <span class=\"sponsors__service\">            PSF Sponsor          </span>        </a>        <a class=\"sponsors__sponsor\" target=\"_blank\" rel=\"noopener\" href=\"https://www.pingdom.com/\">          <img class=sponsors__image src=\"https://pypi-camo.freetls.fastly.net/d01053c02f3a626b73ffcb06b96367fdbbf9e230/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f707970692d6173736574732f73706f6e736f726c6f676f732f70696e67646f6d2d77686974652d6c6f676f2d67355831547546362e706e67\" alt=Pingdom loading=lazy>          <span class=\"sponsors__name\">Pingdom</span>          <span class=\"sponsors__service\">            Monitoring          </span>        </a>        <a class=\"sponsors__sponsor\" target=\"_blank\" rel=\"noopener\" href=\"https://getsentry.com/for/python\">          <img class=sponsors__image src=\"https://pypi-camo.freetls.fastly.net/67af7117035e2345bacb5a82e9aa8b5b3e70701d/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f707970692d6173736574732f73706f6e736f726c6f676f732f73656e7472792d77686974652d6c6f676f2d4a2d6b64742d706e2e706e67\" alt=Sentry loading=lazy>          <span class=\"sponsors__name\">Sentry</span>          <span class=\"sponsors__service\">            Error logging          </span>        </a>        <a class=\"sponsors__sponsor\" target=\"_blank\" rel=\"noopener\" href=\"https://statuspage.io\">          <img class=sponsors__image src=\"https://pypi-camo.freetls.fastly.net/b611884ff90435a0575dbab7d9b0d3e60f136466/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f707970692d6173736574732f73706f6e736f726c6f676f732f737461747573706167652d77686974652d6c6f676f2d5467476c6a4a2d502e706e67\" alt=StatusPage loading=lazy>          <span class=\"sponsors__name\">StatusPage</span>          <span class=\"sponsors__service\">            Status page          </span>        </a></div>  </body></html>",
  "embeddings": []
}