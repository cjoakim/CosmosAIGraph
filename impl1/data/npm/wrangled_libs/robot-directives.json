{
  "name": "robot-directives",
  "description": "parse robot directives within html meta and/or http headers.",
  "keywords": [
    "crawlers",
    "header",
    "html",
    "http",
    "meta",
    "metadata",
    "nofollow",
    "noindex",
    "robots",
    "robots.txt",
    "seo",
    "spiders"
  ],
  "license": "mit",
  "homepage": "https://github.com/stevenvachon/robot-directives#readme",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/stevenvachon/robot-directives.git"
  },
  "version": "0.4.0",
  "dependencies": {
    "deep-freeze-node": "^1.1.2",
    "isbot": "^2.0.3",
    "useragent": "^2.1.13"
  },
  "devDependencies": {
    "chai": "^3.5.0",
    "coveralls": "^2.13.1",
    "mocha": "^3.3.0",
    "nyc": "^10.3.2"
  },
  "users": [],
  "readme": "",
  "peerDependencies": {},
  "developers": [
    "contact@svachon.com"
  ],
  "kwds": "parse robot directives within html meta and/or http headers. crawlers header html http meta metadata nofollow noindex robots robots.txt seo spiders",
  "license_kwds": "mit",
  "libtype": "npm",
  "id": "npm_robot_directives",
  "dependency_ids": [
    "npm_chai",
    "npm_coveralls",
    "npm_deep_freeze_node",
    "npm_isbot",
    "npm_mocha",
    "npm_nyc",
    "npm_useragent"
  ]
}